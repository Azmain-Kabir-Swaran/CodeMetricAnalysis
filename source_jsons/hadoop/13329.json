{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeManager.java",
  "functionName": "handleHeartbeat",
  "functionId": "handleHeartbeat___nodeReg-DatanodeRegistration__reports-StorageReport[]__blockPoolId-String(modifiers-final)__cacheCapacity-long__cacheUsed-long__xceiverCount-int__maxTransfers-int__failedVolumes-int__volumeFailureSummary-VolumeFailureSummary__slowPeers-SlowPeerReports(annotations-@Nonnull)__slowDisks-SlowDiskReports(annotations-@Nonnull)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
  "functionStartLine": 1673,
  "functionEndLine": 1807,
  "numCommitsSeen": 529,
  "timeTaken": 17108,
  "changeHistory": [
    "0695f7a538fb81cc5e36d0b9187df39822bb24f4",
    "a98352ced18e51003b443e1a652d19ec00b2f2d2",
    "39ed3a66dbb01383ed16b141183fc48bfd2e613d",
    "c561cb316e365ef674784cd6cf0b12c0fbc271a3",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
    "e34331c31d68cb22891db48011db5b36ad178af1",
    "19b5aee3e42cd1d6c77a58ab2eea185b5afd60b2",
    "e2a15d18bbbb86c20003c4e34d85244996a4cc3b",
    "b29894889742dda654cd88a7ce72a4e51fccb328",
    "144753e87f4a9daa51200be05ff2bb760bf38169",
    "28cdc5a8dc37ade1f45bda3aede589ee8593945e",
    "e7c8da614c37e36fb8081234f4c639d6054f6082",
    "b57368b6f893cb27d77fc9425e116f1312f4790f",
    "4ae543fdcd6dcfbe32257b1e72a405df9aa73e17",
    "f741476146574550a1a208d58ef8be76639e5ddc",
    "8602692338d6f493647205e0241e4116211fab75",
    "e287e7d14b838a866ba03d895fa35819999d7c09",
    "be7a0add8b6561d3c566237cc0370b06e7f32bb4",
    "164cbe643988f878f0f4100a4de51783e5b6738e",
    "e535e0f05b5fbd087c93238deb888cc985254b4c",
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
    "2ffd84273ac490724fe7e7825664bb6d09ef0e99",
    "c17439c2ddd921b63b1635e6f1cba634b8da8557",
    "a1c9425265d2c94bfc6afb39ab2c16b4ef9e874e",
    "146ce7a9784e52432b76164009336a4b2cf2860e",
    "57a84c0d149b693c913416975cafe6de4e23c321",
    "75ead273bea8a7dad61c4f99c3a16cab2697c498",
    "9729b244de50322c2cc889c97c2ffb2b4675cf77",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
    "08ac06283a3e9bf0d49d873823aabd419b08e41f",
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2"
  ],
  "changeHistoryShort": {
    "0695f7a538fb81cc5e36d0b9187df39822bb24f4": "Ybodychange",
    "a98352ced18e51003b443e1a652d19ec00b2f2d2": "Ybodychange",
    "39ed3a66dbb01383ed16b141183fc48bfd2e613d": "Ybodychange",
    "c561cb316e365ef674784cd6cf0b12c0fbc271a3": "Ybodychange",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": "Ybodychange",
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064": "Ybodychange",
    "e34331c31d68cb22891db48011db5b36ad178af1": "Ybodychange",
    "19b5aee3e42cd1d6c77a58ab2eea185b5afd60b2": "Ybodychange",
    "e2a15d18bbbb86c20003c4e34d85244996a4cc3b": "Ybodychange",
    "b29894889742dda654cd88a7ce72a4e51fccb328": "Ybodychange",
    "144753e87f4a9daa51200be05ff2bb760bf38169": "Ybodychange",
    "28cdc5a8dc37ade1f45bda3aede589ee8593945e": "Ybodychange",
    "e7c8da614c37e36fb8081234f4c639d6054f6082": "Yparameterchange",
    "b57368b6f893cb27d77fc9425e116f1312f4790f": "Ymultichange(Yparameterchange,Ybodychange)",
    "4ae543fdcd6dcfbe32257b1e72a405df9aa73e17": "Ybodychange",
    "f741476146574550a1a208d58ef8be76639e5ddc": "Ybodychange",
    "8602692338d6f493647205e0241e4116211fab75": "Ybodychange",
    "e287e7d14b838a866ba03d895fa35819999d7c09": "Ybodychange",
    "be7a0add8b6561d3c566237cc0370b06e7f32bb4": "Ybodychange",
    "164cbe643988f878f0f4100a4de51783e5b6738e": "Ybodychange",
    "e535e0f05b5fbd087c93238deb888cc985254b4c": "Ybodychange",
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835": "Ybodychange",
    "2ffd84273ac490724fe7e7825664bb6d09ef0e99": "Ybodychange",
    "c17439c2ddd921b63b1635e6f1cba634b8da8557": "Ybodychange",
    "a1c9425265d2c94bfc6afb39ab2c16b4ef9e874e": "Ybodychange",
    "146ce7a9784e52432b76164009336a4b2cf2860e": "Ybodychange",
    "57a84c0d149b693c913416975cafe6de4e23c321": "Ybodychange",
    "75ead273bea8a7dad61c4f99c3a16cab2697c498": "Ybodychange",
    "9729b244de50322c2cc889c97c2ffb2b4675cf77": "Ymultichange(Yparameterchange,Ybodychange)",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": "Ybodychange",
    "08ac06283a3e9bf0d49d873823aabd419b08e41f": "Ybodychange",
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2": "Ybodychange"
  },
  "changeHistoryDetails": {
    "0695f7a538fb81cc5e36d0b9187df39822bb24f4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14612. SlowDiskReport won\u0027t update when SlowDisks is always empty in heartbeat. Contributed by Haibin Huang.\n",
      "commitDate": "12/03/20 5:22 PM",
      "commitName": "0695f7a538fb81cc5e36d0b9187df39822bb24f4",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "13/02/20 3:27 AM",
      "commitNameOld": "a98352ced18e51003b443e1a652d19ec00b2f2d2",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 28.54,
      "commitsBetweenForRepo": 96,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,134 +1,135 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks) throws IOException {\n     final DatanodeDescriptor nodeinfo;\n     try {\n       nodeinfo \u003d getDatanode(nodeReg);\n     } catch (UnregisteredNodeException e) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n \n     // Check if this datanode should actually be shutdown instead.\n     if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n       setDatanodeDead(nodeinfo);\n       throw new DisallowedDatanodeException(nodeinfo);\n     }\n \n     if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n     heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n         cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n     // If we are in safemode, do not send back any recovery / replication\n     // requests. Don\u0027t even drain the existing queue of work.\n     if (namesystem.isInSafeMode()) {\n       return new DatanodeCommand[0];\n     }\n \n     // block recovery command\n     final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n         nodeinfo);\n     if (brCommand !\u003d null) {\n       return new DatanodeCommand[]{brCommand};\n     }\n \n     final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n     // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n     // NN chooses pending tasks based on the ratio between the lengths of\n     // replication and erasure-coded block queues.\n     int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n     int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n     int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n     if (totalBlocks \u003e 0) {\n       int numReplicationTasks \u003d (int) Math.ceil(\n           (double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n       int numECTasks \u003d (int) Math.ceil(\n           (double) (totalECBlocks * maxTransfers) / totalBlocks);\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n             + \" erasure-coded tasks: \" + numECTasks);\n       }\n       // check pending replication tasks\n       List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n           numReplicationTasks);\n       if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n         // If the block is deleted, the block size will become\n         // BlockCommand.NO_ACK (LONG.MAX_VALUE) . This kind of block we don\u0027t\n         // need\n         // to send for replication or reconstruction\n         Iterator\u003cBlockTargetPair\u003e iterator \u003d pendingList.iterator();\n         while (iterator.hasNext()) {\n           BlockTargetPair cmd \u003d iterator.next();\n           if (cmd.block !\u003d null\n               \u0026\u0026 cmd.block.getNumBytes() \u003d\u003d BlockCommand.NO_ACK) {\n             // block deleted\n             DatanodeStorageInfo.decrementBlocksScheduled(cmd.targets);\n             iterator.remove();\n           }\n         }\n         if (!pendingList.isEmpty()) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n               pendingList));\n         }\n       }\n       // check pending erasure coding tasks\n       List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n           .getErasureCodeCommand(numECTasks);\n       if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n         cmds.add(new BlockECReconstructionCommand(\n             DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n       }\n     }\n \n     // check block invalidation\n     Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n     if (blks !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n           blks));\n     }\n     // cache commands\n     addCacheCommands(blockPoolId, nodeinfo, cmds);\n     // key update command\n     blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n     // check for balancer bandwidth update\n     if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n       cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n       // set back to 0 to indicate that datanode has been sent the new value\n       nodeinfo.setBalancerBandwidth(0);\n     }\n \n     if (slowPeerTracker !\u003d null) {\n       final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n       if (!slowPeersMap.isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n               slowPeersMap);\n         }\n         for (String slowNodeId : slowPeersMap.keySet()) {\n           slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n         }\n       }\n     }\n \n     if (slowDiskTracker !\u003d null) {\n       if (!slowDisks.getSlowDisks().isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n               slowDisks.getSlowDisks());\n         }\n         slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n       }\n+      slowDiskTracker.checkAndUpdateReportIfNecessary();\n     }\n \n     if (!cmds.isEmpty()) {\n       return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n    // NN chooses pending tasks based on the ratio between the lengths of\n    // replication and erasure-coded block queues.\n    int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n    int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n    int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n    if (totalBlocks \u003e 0) {\n      int numReplicationTasks \u003d (int) Math.ceil(\n          (double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n      int numECTasks \u003d (int) Math.ceil(\n          (double) (totalECBlocks * maxTransfers) / totalBlocks);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n            + \" erasure-coded tasks: \" + numECTasks);\n      }\n      // check pending replication tasks\n      List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n          numReplicationTasks);\n      if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n        // If the block is deleted, the block size will become\n        // BlockCommand.NO_ACK (LONG.MAX_VALUE) . This kind of block we don\u0027t\n        // need\n        // to send for replication or reconstruction\n        Iterator\u003cBlockTargetPair\u003e iterator \u003d pendingList.iterator();\n        while (iterator.hasNext()) {\n          BlockTargetPair cmd \u003d iterator.next();\n          if (cmd.block !\u003d null\n              \u0026\u0026 cmd.block.getNumBytes() \u003d\u003d BlockCommand.NO_ACK) {\n            // block deleted\n            DatanodeStorageInfo.decrementBlocksScheduled(cmd.targets);\n            iterator.remove();\n          }\n        }\n        if (!pendingList.isEmpty()) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n      }\n      // check pending erasure coding tasks\n      List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n          .getErasureCodeCommand(numECTasks);\n      if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n        cmds.add(new BlockECReconstructionCommand(\n            DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n      }\n    }\n\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (slowPeerTracker !\u003d null) {\n      final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n      if (!slowPeersMap.isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n              slowPeersMap);\n        }\n        for (String slowNodeId : slowPeersMap.keySet()) {\n          slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n        }\n      }\n    }\n\n    if (slowDiskTracker !\u003d null) {\n      if (!slowDisks.getSlowDisks().isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n              slowDisks.getSlowDisks());\n        }\n        slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n      }\n      slowDiskTracker.checkAndUpdateReportIfNecessary();\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "a98352ced18e51003b443e1a652d19ec00b2f2d2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15086. Block scheduled counter never get decremet if the block got deleted before replication. Contributed by hemanthboyina.\n",
      "commitDate": "13/02/20 3:27 AM",
      "commitName": "a98352ced18e51003b443e1a652d19ec00b2f2d2",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "15/11/19 12:16 PM",
      "commitNameOld": "c892a879ddce3abfd51c8609c81148bf6e4f9daa",
      "commitAuthorOld": "He Xiaoqiao",
      "daysBetweenCommits": 89.63,
      "commitsBetweenForRepo": 311,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,118 +1,134 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks) throws IOException {\n     final DatanodeDescriptor nodeinfo;\n     try {\n       nodeinfo \u003d getDatanode(nodeReg);\n     } catch (UnregisteredNodeException e) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n \n     // Check if this datanode should actually be shutdown instead.\n     if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n       setDatanodeDead(nodeinfo);\n       throw new DisallowedDatanodeException(nodeinfo);\n     }\n \n     if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n     heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n         cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n     // If we are in safemode, do not send back any recovery / replication\n     // requests. Don\u0027t even drain the existing queue of work.\n     if (namesystem.isInSafeMode()) {\n       return new DatanodeCommand[0];\n     }\n \n     // block recovery command\n     final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n         nodeinfo);\n     if (brCommand !\u003d null) {\n       return new DatanodeCommand[]{brCommand};\n     }\n \n     final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n     // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n     // NN chooses pending tasks based on the ratio between the lengths of\n     // replication and erasure-coded block queues.\n     int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n     int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n     int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n     if (totalBlocks \u003e 0) {\n       int numReplicationTasks \u003d (int) Math.ceil(\n           (double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n       int numECTasks \u003d (int) Math.ceil(\n           (double) (totalECBlocks * maxTransfers) / totalBlocks);\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n             + \" erasure-coded tasks: \" + numECTasks);\n       }\n       // check pending replication tasks\n       List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n           numReplicationTasks);\n       if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n-        cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n-            pendingList));\n+        // If the block is deleted, the block size will become\n+        // BlockCommand.NO_ACK (LONG.MAX_VALUE) . This kind of block we don\u0027t\n+        // need\n+        // to send for replication or reconstruction\n+        Iterator\u003cBlockTargetPair\u003e iterator \u003d pendingList.iterator();\n+        while (iterator.hasNext()) {\n+          BlockTargetPair cmd \u003d iterator.next();\n+          if (cmd.block !\u003d null\n+              \u0026\u0026 cmd.block.getNumBytes() \u003d\u003d BlockCommand.NO_ACK) {\n+            // block deleted\n+            DatanodeStorageInfo.decrementBlocksScheduled(cmd.targets);\n+            iterator.remove();\n+          }\n+        }\n+        if (!pendingList.isEmpty()) {\n+          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n+              pendingList));\n+        }\n       }\n       // check pending erasure coding tasks\n       List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n           .getErasureCodeCommand(numECTasks);\n       if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n         cmds.add(new BlockECReconstructionCommand(\n             DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n       }\n     }\n \n     // check block invalidation\n     Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n     if (blks !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n           blks));\n     }\n     // cache commands\n     addCacheCommands(blockPoolId, nodeinfo, cmds);\n     // key update command\n     blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n     // check for balancer bandwidth update\n     if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n       cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n       // set back to 0 to indicate that datanode has been sent the new value\n       nodeinfo.setBalancerBandwidth(0);\n     }\n \n     if (slowPeerTracker !\u003d null) {\n       final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n       if (!slowPeersMap.isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n               slowPeersMap);\n         }\n         for (String slowNodeId : slowPeersMap.keySet()) {\n           slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n         }\n       }\n     }\n \n     if (slowDiskTracker !\u003d null) {\n       if (!slowDisks.getSlowDisks().isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n               slowDisks.getSlowDisks());\n         }\n         slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n       }\n     }\n \n     if (!cmds.isEmpty()) {\n       return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n    // NN chooses pending tasks based on the ratio between the lengths of\n    // replication and erasure-coded block queues.\n    int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n    int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n    int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n    if (totalBlocks \u003e 0) {\n      int numReplicationTasks \u003d (int) Math.ceil(\n          (double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n      int numECTasks \u003d (int) Math.ceil(\n          (double) (totalECBlocks * maxTransfers) / totalBlocks);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n            + \" erasure-coded tasks: \" + numECTasks);\n      }\n      // check pending replication tasks\n      List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n          numReplicationTasks);\n      if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n        // If the block is deleted, the block size will become\n        // BlockCommand.NO_ACK (LONG.MAX_VALUE) . This kind of block we don\u0027t\n        // need\n        // to send for replication or reconstruction\n        Iterator\u003cBlockTargetPair\u003e iterator \u003d pendingList.iterator();\n        while (iterator.hasNext()) {\n          BlockTargetPair cmd \u003d iterator.next();\n          if (cmd.block !\u003d null\n              \u0026\u0026 cmd.block.getNumBytes() \u003d\u003d BlockCommand.NO_ACK) {\n            // block deleted\n            DatanodeStorageInfo.decrementBlocksScheduled(cmd.targets);\n            iterator.remove();\n          }\n        }\n        if (!pendingList.isEmpty()) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n      }\n      // check pending erasure coding tasks\n      List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n          .getErasureCodeCommand(numECTasks);\n      if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n        cmds.add(new BlockECReconstructionCommand(\n            DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n      }\n    }\n\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (slowPeerTracker !\u003d null) {\n      final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n      if (!slowPeersMap.isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n              slowPeersMap);\n        }\n        for (String slowNodeId : slowPeersMap.keySet()) {\n          slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n        }\n      }\n    }\n\n    if (slowDiskTracker !\u003d null) {\n      if (!slowDisks.getSlowDisks().isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n              slowDisks.getSlowDisks());\n        }\n        slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n      }\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "39ed3a66dbb01383ed16b141183fc48bfd2e613d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13076: [SPS]: Cleanup work for HDFS-10285 merge. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "39ed3a66dbb01383ed16b141183fc48bfd2e613d",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "99594b48b8e040ab5a0939d7c3dbcfb34400e6fc",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,164 +1,118 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks) throws IOException {\n     final DatanodeDescriptor nodeinfo;\n     try {\n       nodeinfo \u003d getDatanode(nodeReg);\n     } catch (UnregisteredNodeException e) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n \n     // Check if this datanode should actually be shutdown instead.\n     if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n       setDatanodeDead(nodeinfo);\n       throw new DisallowedDatanodeException(nodeinfo);\n     }\n \n     if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n     heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n         cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n     // If we are in safemode, do not send back any recovery / replication\n     // requests. Don\u0027t even drain the existing queue of work.\n     if (namesystem.isInSafeMode()) {\n       return new DatanodeCommand[0];\n     }\n \n     // block recovery command\n     final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n         nodeinfo);\n     if (brCommand !\u003d null) {\n       return new DatanodeCommand[]{brCommand};\n     }\n \n     final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n     // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n     // NN chooses pending tasks based on the ratio between the lengths of\n-    // replication, erasure-coded block queues and block storage movement\n-    // queues.\n+    // replication and erasure-coded block queues.\n     int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n     int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n-    int totalBlocksToMove \u003d nodeinfo.getNumberOfBlocksToMoveStorages();\n     int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n-    if (totalBlocks \u003e 0 || totalBlocksToMove \u003e 0) {\n-      int numReplicationTasks \u003d 0;\n-      int numECTasks \u003d 0;\n-      int numBlocksToMoveTasks \u003d 0;\n-      // Check blocksToMoveLowPriority configuration is true/false. If false,\n-      // then equally sharing the max transfer. Otherwise gives high priority to\n-      // the pending_replica/erasure-coded tasks and only the delta streams will\n-      // be used for blocks to move tasks.\n-      if (!blocksToMoveLowPriority) {\n-        // add blocksToMove count to total blocks so that will get equal share\n-        totalBlocks \u003d totalBlocks + totalBlocksToMove;\n-        numReplicationTasks \u003d (int) Math\n-            .ceil((double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n-        numECTasks \u003d (int) Math\n-            .ceil((double) (totalECBlocks * maxTransfers) / totalBlocks);\n-        numBlocksToMoveTasks \u003d (int) Math\n-            .ceil((double) (totalBlocksToMove * maxTransfers) / totalBlocks);\n-      } else {\n-        // Calculate the replica and ec tasks, then pick blocksToMove if there\n-        // is any streams available.\n-        numReplicationTasks \u003d (int) Math\n-            .ceil((double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n-        numECTasks \u003d (int) Math\n-            .ceil((double) (totalECBlocks * maxTransfers) / totalBlocks);\n-        int numTasks \u003d numReplicationTasks + numECTasks;\n-        if (numTasks \u003c maxTransfers) {\n-          int remainingMaxTransfers \u003d maxTransfers - numTasks;\n-          numBlocksToMoveTasks \u003d Math.min(totalBlocksToMove,\n-              remainingMaxTransfers);\n-        }\n-      }\n+    if (totalBlocks \u003e 0) {\n+      int numReplicationTasks \u003d (int) Math.ceil(\n+          (double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n+      int numECTasks \u003d (int) Math.ceil(\n+          (double) (totalECBlocks * maxTransfers) / totalBlocks);\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n-            + \" erasure-coded tasks: \" + numECTasks + \" blocks to move tasks: \"\n-            + numBlocksToMoveTasks);\n+            + \" erasure-coded tasks: \" + numECTasks);\n       }\n       // check pending replication tasks\n       List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n           numReplicationTasks);\n       if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n         cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n             pendingList));\n       }\n       // check pending erasure coding tasks\n       List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n           .getErasureCodeCommand(numECTasks);\n       if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n         cmds.add(new BlockECReconstructionCommand(\n             DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n       }\n-      // check pending block storage movement tasks\n-      if (nodeinfo.shouldDropSPSWork()) {\n-        cmds.add(DropSPSWorkCommand.DNA_DROP_SPS_WORK_COMMAND);\n-        // Set back to false to indicate that the new value has been sent to the\n-        // datanode.\n-        nodeinfo.setDropSPSWork(false);\n-      } else {\n-        // Get pending block storage movement tasks\n-        BlockMovingInfo[] blkStorageMovementInfos \u003d nodeinfo\n-            .getBlocksToMoveStorages(numBlocksToMoveTasks);\n-\n-        if (blkStorageMovementInfos !\u003d null) {\n-          cmds.add(new BlockStorageMovementCommand(\n-              DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT, blockPoolId,\n-              Arrays.asList(blkStorageMovementInfos)));\n-        }\n-      }\n     }\n \n     // check block invalidation\n     Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n     if (blks !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n           blks));\n     }\n     // cache commands\n     addCacheCommands(blockPoolId, nodeinfo, cmds);\n     // key update command\n     blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n     // check for balancer bandwidth update\n     if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n       cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n       // set back to 0 to indicate that datanode has been sent the new value\n       nodeinfo.setBalancerBandwidth(0);\n     }\n \n     if (slowPeerTracker !\u003d null) {\n       final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n       if (!slowPeersMap.isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n               slowPeersMap);\n         }\n         for (String slowNodeId : slowPeersMap.keySet()) {\n           slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n         }\n       }\n     }\n \n     if (slowDiskTracker !\u003d null) {\n       if (!slowDisks.getSlowDisks().isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n               slowDisks.getSlowDisks());\n         }\n         slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n       }\n     }\n \n     if (!cmds.isEmpty()) {\n       return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n    // NN chooses pending tasks based on the ratio between the lengths of\n    // replication and erasure-coded block queues.\n    int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n    int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n    int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n    if (totalBlocks \u003e 0) {\n      int numReplicationTasks \u003d (int) Math.ceil(\n          (double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n      int numECTasks \u003d (int) Math.ceil(\n          (double) (totalECBlocks * maxTransfers) / totalBlocks);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n            + \" erasure-coded tasks: \" + numECTasks);\n      }\n      // check pending replication tasks\n      List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n          numReplicationTasks);\n      if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n        cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n            pendingList));\n      }\n      // check pending erasure coding tasks\n      List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n          .getErasureCodeCommand(numECTasks);\n      if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n        cmds.add(new BlockECReconstructionCommand(\n            DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n      }\n    }\n\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (slowPeerTracker !\u003d null) {\n      final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n      if (!slowPeersMap.isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n              slowPeersMap);\n        }\n        for (String slowNodeId : slowPeersMap.keySet()) {\n          slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n        }\n      }\n    }\n\n    if (slowDiskTracker !\u003d null) {\n      if (!slowDisks.getSlowDisks().isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n              slowDisks.getSlowDisks());\n        }\n        slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n      }\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "c561cb316e365ef674784cd6cf0b12c0fbc271a3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12106: [SPS]: Improve storage policy satisfier configurations. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "c561cb316e365ef674784cd6cf0b12c0fbc271a3",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,164 +1,164 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks) throws IOException {\n     final DatanodeDescriptor nodeinfo;\n     try {\n       nodeinfo \u003d getDatanode(nodeReg);\n     } catch (UnregisteredNodeException e) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n \n     // Check if this datanode should actually be shutdown instead.\n     if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n       setDatanodeDead(nodeinfo);\n       throw new DisallowedDatanodeException(nodeinfo);\n     }\n \n     if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n     heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n         cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n     // If we are in safemode, do not send back any recovery / replication\n     // requests. Don\u0027t even drain the existing queue of work.\n     if (namesystem.isInSafeMode()) {\n       return new DatanodeCommand[0];\n     }\n \n     // block recovery command\n     final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n         nodeinfo);\n     if (brCommand !\u003d null) {\n       return new DatanodeCommand[]{brCommand};\n     }\n \n     final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n     // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n     // NN chooses pending tasks based on the ratio between the lengths of\n     // replication, erasure-coded block queues and block storage movement\n     // queues.\n     int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n     int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n     int totalBlocksToMove \u003d nodeinfo.getNumberOfBlocksToMoveStorages();\n     int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n     if (totalBlocks \u003e 0 || totalBlocksToMove \u003e 0) {\n       int numReplicationTasks \u003d 0;\n       int numECTasks \u003d 0;\n       int numBlocksToMoveTasks \u003d 0;\n-      // Check blocksToMoveShareEqualRatio configuration is true/false. If true,\n+      // Check blocksToMoveLowPriority configuration is true/false. If false,\n       // then equally sharing the max transfer. Otherwise gives high priority to\n       // the pending_replica/erasure-coded tasks and only the delta streams will\n       // be used for blocks to move tasks.\n-      if (blocksToMoveShareEqualRatio) {\n+      if (!blocksToMoveLowPriority) {\n         // add blocksToMove count to total blocks so that will get equal share\n         totalBlocks \u003d totalBlocks + totalBlocksToMove;\n         numReplicationTasks \u003d (int) Math\n             .ceil((double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n         numECTasks \u003d (int) Math\n             .ceil((double) (totalECBlocks * maxTransfers) / totalBlocks);\n         numBlocksToMoveTasks \u003d (int) Math\n             .ceil((double) (totalBlocksToMove * maxTransfers) / totalBlocks);\n       } else {\n         // Calculate the replica and ec tasks, then pick blocksToMove if there\n         // is any streams available.\n         numReplicationTasks \u003d (int) Math\n             .ceil((double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n         numECTasks \u003d (int) Math\n             .ceil((double) (totalECBlocks * maxTransfers) / totalBlocks);\n         int numTasks \u003d numReplicationTasks + numECTasks;\n         if (numTasks \u003c maxTransfers) {\n           int remainingMaxTransfers \u003d maxTransfers - numTasks;\n           numBlocksToMoveTasks \u003d Math.min(totalBlocksToMove,\n               remainingMaxTransfers);\n         }\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n             + \" erasure-coded tasks: \" + numECTasks + \" blocks to move tasks: \"\n             + numBlocksToMoveTasks);\n       }\n       // check pending replication tasks\n       List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n           numReplicationTasks);\n       if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n         cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n             pendingList));\n       }\n       // check pending erasure coding tasks\n       List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n           .getErasureCodeCommand(numECTasks);\n       if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n         cmds.add(new BlockECReconstructionCommand(\n             DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n       }\n       // check pending block storage movement tasks\n       if (nodeinfo.shouldDropSPSWork()) {\n         cmds.add(DropSPSWorkCommand.DNA_DROP_SPS_WORK_COMMAND);\n         // Set back to false to indicate that the new value has been sent to the\n         // datanode.\n         nodeinfo.setDropSPSWork(false);\n       } else {\n         // Get pending block storage movement tasks\n         BlockMovingInfo[] blkStorageMovementInfos \u003d nodeinfo\n             .getBlocksToMoveStorages(numBlocksToMoveTasks);\n \n         if (blkStorageMovementInfos !\u003d null) {\n           cmds.add(new BlockStorageMovementCommand(\n               DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT, blockPoolId,\n               Arrays.asList(blkStorageMovementInfos)));\n         }\n       }\n     }\n \n     // check block invalidation\n     Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n     if (blks !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n           blks));\n     }\n     // cache commands\n     addCacheCommands(blockPoolId, nodeinfo, cmds);\n     // key update command\n     blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n     // check for balancer bandwidth update\n     if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n       cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n       // set back to 0 to indicate that datanode has been sent the new value\n       nodeinfo.setBalancerBandwidth(0);\n     }\n \n     if (slowPeerTracker !\u003d null) {\n       final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n       if (!slowPeersMap.isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n               slowPeersMap);\n         }\n         for (String slowNodeId : slowPeersMap.keySet()) {\n           slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n         }\n       }\n     }\n \n     if (slowDiskTracker !\u003d null) {\n       if (!slowDisks.getSlowDisks().isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n               slowDisks.getSlowDisks());\n         }\n         slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n       }\n     }\n \n     if (!cmds.isEmpty()) {\n       return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n    // NN chooses pending tasks based on the ratio between the lengths of\n    // replication, erasure-coded block queues and block storage movement\n    // queues.\n    int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n    int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n    int totalBlocksToMove \u003d nodeinfo.getNumberOfBlocksToMoveStorages();\n    int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n    if (totalBlocks \u003e 0 || totalBlocksToMove \u003e 0) {\n      int numReplicationTasks \u003d 0;\n      int numECTasks \u003d 0;\n      int numBlocksToMoveTasks \u003d 0;\n      // Check blocksToMoveLowPriority configuration is true/false. If false,\n      // then equally sharing the max transfer. Otherwise gives high priority to\n      // the pending_replica/erasure-coded tasks and only the delta streams will\n      // be used for blocks to move tasks.\n      if (!blocksToMoveLowPriority) {\n        // add blocksToMove count to total blocks so that will get equal share\n        totalBlocks \u003d totalBlocks + totalBlocksToMove;\n        numReplicationTasks \u003d (int) Math\n            .ceil((double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n        numECTasks \u003d (int) Math\n            .ceil((double) (totalECBlocks * maxTransfers) / totalBlocks);\n        numBlocksToMoveTasks \u003d (int) Math\n            .ceil((double) (totalBlocksToMove * maxTransfers) / totalBlocks);\n      } else {\n        // Calculate the replica and ec tasks, then pick blocksToMove if there\n        // is any streams available.\n        numReplicationTasks \u003d (int) Math\n            .ceil((double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n        numECTasks \u003d (int) Math\n            .ceil((double) (totalECBlocks * maxTransfers) / totalBlocks);\n        int numTasks \u003d numReplicationTasks + numECTasks;\n        if (numTasks \u003c maxTransfers) {\n          int remainingMaxTransfers \u003d maxTransfers - numTasks;\n          numBlocksToMoveTasks \u003d Math.min(totalBlocksToMove,\n              remainingMaxTransfers);\n        }\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n            + \" erasure-coded tasks: \" + numECTasks + \" blocks to move tasks: \"\n            + numBlocksToMoveTasks);\n      }\n      // check pending replication tasks\n      List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n          numReplicationTasks);\n      if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n        cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n            pendingList));\n      }\n      // check pending erasure coding tasks\n      List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n          .getErasureCodeCommand(numECTasks);\n      if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n        cmds.add(new BlockECReconstructionCommand(\n            DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n      }\n      // check pending block storage movement tasks\n      if (nodeinfo.shouldDropSPSWork()) {\n        cmds.add(DropSPSWorkCommand.DNA_DROP_SPS_WORK_COMMAND);\n        // Set back to false to indicate that the new value has been sent to the\n        // datanode.\n        nodeinfo.setDropSPSWork(false);\n      } else {\n        // Get pending block storage movement tasks\n        BlockMovingInfo[] blkStorageMovementInfos \u003d nodeinfo\n            .getBlocksToMoveStorages(numBlocksToMoveTasks);\n\n        if (blkStorageMovementInfos !\u003d null) {\n          cmds.add(new BlockStorageMovementCommand(\n              DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT, blockPoolId,\n              Arrays.asList(blkStorageMovementInfos)));\n        }\n      }\n    }\n\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (slowPeerTracker !\u003d null) {\n      final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n      if (!slowPeersMap.isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n              slowPeersMap);\n        }\n        for (String slowNodeId : slowPeersMap.keySet()) {\n          slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n        }\n      }\n    }\n\n    if (slowDiskTracker !\u003d null) {\n      if (!slowDisks.getSlowDisks().isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n              slowDisks.getSlowDisks());\n        }\n        slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n      }\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,137 +1,164 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks) throws IOException {\n     final DatanodeDescriptor nodeinfo;\n     try {\n       nodeinfo \u003d getDatanode(nodeReg);\n     } catch (UnregisteredNodeException e) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n \n     // Check if this datanode should actually be shutdown instead.\n     if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n       setDatanodeDead(nodeinfo);\n       throw new DisallowedDatanodeException(nodeinfo);\n     }\n \n     if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n     heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n         cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n     // If we are in safemode, do not send back any recovery / replication\n     // requests. Don\u0027t even drain the existing queue of work.\n     if (namesystem.isInSafeMode()) {\n       return new DatanodeCommand[0];\n     }\n \n     // block recovery command\n     final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n         nodeinfo);\n     if (brCommand !\u003d null) {\n       return new DatanodeCommand[]{brCommand};\n     }\n \n     final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n     // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n     // NN chooses pending tasks based on the ratio between the lengths of\n-    // replication and erasure-coded block queues.\n+    // replication, erasure-coded block queues and block storage movement\n+    // queues.\n     int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n     int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n+    int totalBlocksToMove \u003d nodeinfo.getNumberOfBlocksToMoveStorages();\n     int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n-    if (totalBlocks \u003e 0) {\n-      int numReplicationTasks \u003d (int) Math.ceil(\n-          (double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n-      int numECTasks \u003d (int) Math.ceil(\n-          (double) (totalECBlocks * maxTransfers) / totalBlocks);\n-\n+    if (totalBlocks \u003e 0 || totalBlocksToMove \u003e 0) {\n+      int numReplicationTasks \u003d 0;\n+      int numECTasks \u003d 0;\n+      int numBlocksToMoveTasks \u003d 0;\n+      // Check blocksToMoveShareEqualRatio configuration is true/false. If true,\n+      // then equally sharing the max transfer. Otherwise gives high priority to\n+      // the pending_replica/erasure-coded tasks and only the delta streams will\n+      // be used for blocks to move tasks.\n+      if (blocksToMoveShareEqualRatio) {\n+        // add blocksToMove count to total blocks so that will get equal share\n+        totalBlocks \u003d totalBlocks + totalBlocksToMove;\n+        numReplicationTasks \u003d (int) Math\n+            .ceil((double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n+        numECTasks \u003d (int) Math\n+            .ceil((double) (totalECBlocks * maxTransfers) / totalBlocks);\n+        numBlocksToMoveTasks \u003d (int) Math\n+            .ceil((double) (totalBlocksToMove * maxTransfers) / totalBlocks);\n+      } else {\n+        // Calculate the replica and ec tasks, then pick blocksToMove if there\n+        // is any streams available.\n+        numReplicationTasks \u003d (int) Math\n+            .ceil((double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n+        numECTasks \u003d (int) Math\n+            .ceil((double) (totalECBlocks * maxTransfers) / totalBlocks);\n+        int numTasks \u003d numReplicationTasks + numECTasks;\n+        if (numTasks \u003c maxTransfers) {\n+          int remainingMaxTransfers \u003d maxTransfers - numTasks;\n+          numBlocksToMoveTasks \u003d Math.min(totalBlocksToMove,\n+              remainingMaxTransfers);\n+        }\n+      }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n-            + \" erasure-coded tasks: \" + numECTasks);\n+            + \" erasure-coded tasks: \" + numECTasks + \" blocks to move tasks: \"\n+            + numBlocksToMoveTasks);\n       }\n       // check pending replication tasks\n       List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n           numReplicationTasks);\n       if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n         cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n             pendingList));\n       }\n       // check pending erasure coding tasks\n       List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n           .getErasureCodeCommand(numECTasks);\n       if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n         cmds.add(new BlockECReconstructionCommand(\n             DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n       }\n+      // check pending block storage movement tasks\n+      if (nodeinfo.shouldDropSPSWork()) {\n+        cmds.add(DropSPSWorkCommand.DNA_DROP_SPS_WORK_COMMAND);\n+        // Set back to false to indicate that the new value has been sent to the\n+        // datanode.\n+        nodeinfo.setDropSPSWork(false);\n+      } else {\n+        // Get pending block storage movement tasks\n+        BlockMovingInfo[] blkStorageMovementInfos \u003d nodeinfo\n+            .getBlocksToMoveStorages(numBlocksToMoveTasks);\n+\n+        if (blkStorageMovementInfos !\u003d null) {\n+          cmds.add(new BlockStorageMovementCommand(\n+              DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT, blockPoolId,\n+              Arrays.asList(blkStorageMovementInfos)));\n+        }\n+      }\n     }\n \n     // check block invalidation\n     Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n     if (blks !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n           blks));\n     }\n     // cache commands\n     addCacheCommands(blockPoolId, nodeinfo, cmds);\n     // key update command\n     blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n     // check for balancer bandwidth update\n     if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n       cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n       // set back to 0 to indicate that datanode has been sent the new value\n       nodeinfo.setBalancerBandwidth(0);\n     }\n \n     if (slowPeerTracker !\u003d null) {\n       final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n       if (!slowPeersMap.isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n               slowPeersMap);\n         }\n         for (String slowNodeId : slowPeersMap.keySet()) {\n           slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n         }\n       }\n     }\n \n     if (slowDiskTracker !\u003d null) {\n       if (!slowDisks.getSlowDisks().isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n               slowDisks.getSlowDisks());\n         }\n         slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n       }\n     }\n \n-    if (nodeinfo.shouldDropSPSWork()) {\n-      cmds.add(DropSPSWorkCommand.DNA_DROP_SPS_WORK_COMMAND);\n-      // Set back to false to indicate that the new value has been sent to the\n-      // datanode.\n-      nodeinfo.setDropSPSWork(false);\n-    }\n-\n-    // check pending block storage movement tasks\n-    BlockStorageMovementInfosBatch blkStorageMovementInfosBatch \u003d nodeinfo\n-        .getBlocksToMoveStorages();\n-\n-    if (blkStorageMovementInfosBatch !\u003d null) {\n-      cmds.add(new BlockStorageMovementCommand(\n-          DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT,\n-          blkStorageMovementInfosBatch.getTrackID(), blockPoolId,\n-          blkStorageMovementInfosBatch.getBlockMovingInfo()));\n-    }\n-\n     if (!cmds.isEmpty()) {\n       return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n    // NN chooses pending tasks based on the ratio between the lengths of\n    // replication, erasure-coded block queues and block storage movement\n    // queues.\n    int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n    int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n    int totalBlocksToMove \u003d nodeinfo.getNumberOfBlocksToMoveStorages();\n    int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n    if (totalBlocks \u003e 0 || totalBlocksToMove \u003e 0) {\n      int numReplicationTasks \u003d 0;\n      int numECTasks \u003d 0;\n      int numBlocksToMoveTasks \u003d 0;\n      // Check blocksToMoveShareEqualRatio configuration is true/false. If true,\n      // then equally sharing the max transfer. Otherwise gives high priority to\n      // the pending_replica/erasure-coded tasks and only the delta streams will\n      // be used for blocks to move tasks.\n      if (blocksToMoveShareEqualRatio) {\n        // add blocksToMove count to total blocks so that will get equal share\n        totalBlocks \u003d totalBlocks + totalBlocksToMove;\n        numReplicationTasks \u003d (int) Math\n            .ceil((double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n        numECTasks \u003d (int) Math\n            .ceil((double) (totalECBlocks * maxTransfers) / totalBlocks);\n        numBlocksToMoveTasks \u003d (int) Math\n            .ceil((double) (totalBlocksToMove * maxTransfers) / totalBlocks);\n      } else {\n        // Calculate the replica and ec tasks, then pick blocksToMove if there\n        // is any streams available.\n        numReplicationTasks \u003d (int) Math\n            .ceil((double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n        numECTasks \u003d (int) Math\n            .ceil((double) (totalECBlocks * maxTransfers) / totalBlocks);\n        int numTasks \u003d numReplicationTasks + numECTasks;\n        if (numTasks \u003c maxTransfers) {\n          int remainingMaxTransfers \u003d maxTransfers - numTasks;\n          numBlocksToMoveTasks \u003d Math.min(totalBlocksToMove,\n              remainingMaxTransfers);\n        }\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n            + \" erasure-coded tasks: \" + numECTasks + \" blocks to move tasks: \"\n            + numBlocksToMoveTasks);\n      }\n      // check pending replication tasks\n      List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n          numReplicationTasks);\n      if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n        cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n            pendingList));\n      }\n      // check pending erasure coding tasks\n      List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n          .getErasureCodeCommand(numECTasks);\n      if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n        cmds.add(new BlockECReconstructionCommand(\n            DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n      }\n      // check pending block storage movement tasks\n      if (nodeinfo.shouldDropSPSWork()) {\n        cmds.add(DropSPSWorkCommand.DNA_DROP_SPS_WORK_COMMAND);\n        // Set back to false to indicate that the new value has been sent to the\n        // datanode.\n        nodeinfo.setDropSPSWork(false);\n      } else {\n        // Get pending block storage movement tasks\n        BlockMovingInfo[] blkStorageMovementInfos \u003d nodeinfo\n            .getBlocksToMoveStorages(numBlocksToMoveTasks);\n\n        if (blkStorageMovementInfos !\u003d null) {\n          cmds.add(new BlockStorageMovementCommand(\n              DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT, blockPoolId,\n              Arrays.asList(blkStorageMovementInfos)));\n        }\n      }\n    }\n\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (slowPeerTracker !\u003d null) {\n      final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n      if (!slowPeersMap.isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n              slowPeersMap);\n        }\n        for (String slowNodeId : slowPeersMap.keySet()) {\n          slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n        }\n      }\n    }\n\n    if (slowDiskTracker !\u003d null) {\n      if (!slowDisks.getSlowDisks().isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n              slowDisks.getSlowDisks());\n        }\n        slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n      }\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12225: [SPS]: Optimize extended attributes for tracking SPS movements. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "695a402fcad20c711c5d845e0664c43fd6b06286",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,137 +1,137 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks) throws IOException {\n     final DatanodeDescriptor nodeinfo;\n     try {\n       nodeinfo \u003d getDatanode(nodeReg);\n     } catch (UnregisteredNodeException e) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n \n     // Check if this datanode should actually be shutdown instead.\n     if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n       setDatanodeDead(nodeinfo);\n       throw new DisallowedDatanodeException(nodeinfo);\n     }\n \n     if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n     heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n         cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n     // If we are in safemode, do not send back any recovery / replication\n     // requests. Don\u0027t even drain the existing queue of work.\n     if (namesystem.isInSafeMode()) {\n       return new DatanodeCommand[0];\n     }\n \n     // block recovery command\n     final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n         nodeinfo);\n     if (brCommand !\u003d null) {\n       return new DatanodeCommand[]{brCommand};\n     }\n \n     final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n     // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n     // NN chooses pending tasks based on the ratio between the lengths of\n     // replication and erasure-coded block queues.\n     int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n     int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n     int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n     if (totalBlocks \u003e 0) {\n       int numReplicationTasks \u003d (int) Math.ceil(\n           (double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n       int numECTasks \u003d (int) Math.ceil(\n           (double) (totalECBlocks * maxTransfers) / totalBlocks);\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n             + \" erasure-coded tasks: \" + numECTasks);\n       }\n       // check pending replication tasks\n       List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n           numReplicationTasks);\n       if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n         cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n             pendingList));\n       }\n       // check pending erasure coding tasks\n       List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n           .getErasureCodeCommand(numECTasks);\n       if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n         cmds.add(new BlockECReconstructionCommand(\n             DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n       }\n     }\n \n     // check block invalidation\n     Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n     if (blks !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n           blks));\n     }\n     // cache commands\n     addCacheCommands(blockPoolId, nodeinfo, cmds);\n     // key update command\n     blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n     // check for balancer bandwidth update\n     if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n       cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n       // set back to 0 to indicate that datanode has been sent the new value\n       nodeinfo.setBalancerBandwidth(0);\n     }\n \n     if (slowPeerTracker !\u003d null) {\n       final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n       if (!slowPeersMap.isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n               slowPeersMap);\n         }\n         for (String slowNodeId : slowPeersMap.keySet()) {\n           slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n         }\n       }\n     }\n \n     if (slowDiskTracker !\u003d null) {\n       if (!slowDisks.getSlowDisks().isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n               slowDisks.getSlowDisks());\n         }\n         slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n       }\n     }\n \n+    if (nodeinfo.shouldDropSPSWork()) {\n+      cmds.add(DropSPSWorkCommand.DNA_DROP_SPS_WORK_COMMAND);\n+      // Set back to false to indicate that the new value has been sent to the\n+      // datanode.\n+      nodeinfo.setDropSPSWork(false);\n+    }\n+\n     // check pending block storage movement tasks\n     BlockStorageMovementInfosBatch blkStorageMovementInfosBatch \u003d nodeinfo\n         .getBlocksToMoveStorages();\n \n     if (blkStorageMovementInfosBatch !\u003d null) {\n       cmds.add(new BlockStorageMovementCommand(\n           DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT,\n           blkStorageMovementInfosBatch.getTrackID(), blockPoolId,\n           blkStorageMovementInfosBatch.getBlockMovingInfo()));\n     }\n \n-    if (nodeinfo.shouldDropSPSWork()) {\n-      cmds.add(DropSPSWorkCommand.DNA_DROP_SPS_WORK_COMMAND);\n-      // Set back to false to indicate that the new value has been sent to the\n-      // datanode.\n-      nodeinfo.setDropSPSWork(false);\n-    }\n-\n     if (!cmds.isEmpty()) {\n       return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n    // NN chooses pending tasks based on the ratio between the lengths of\n    // replication and erasure-coded block queues.\n    int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n    int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n    int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n    if (totalBlocks \u003e 0) {\n      int numReplicationTasks \u003d (int) Math.ceil(\n          (double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n      int numECTasks \u003d (int) Math.ceil(\n          (double) (totalECBlocks * maxTransfers) / totalBlocks);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n            + \" erasure-coded tasks: \" + numECTasks);\n      }\n      // check pending replication tasks\n      List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n          numReplicationTasks);\n      if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n        cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n            pendingList));\n      }\n      // check pending erasure coding tasks\n      List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n          .getErasureCodeCommand(numECTasks);\n      if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n        cmds.add(new BlockECReconstructionCommand(\n            DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n      }\n    }\n\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (slowPeerTracker !\u003d null) {\n      final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n      if (!slowPeersMap.isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n              slowPeersMap);\n        }\n        for (String slowNodeId : slowPeersMap.keySet()) {\n          slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n        }\n      }\n    }\n\n    if (slowDiskTracker !\u003d null) {\n      if (!slowDisks.getSlowDisks().isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n              slowDisks.getSlowDisks());\n        }\n        slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n      }\n    }\n\n    if (nodeinfo.shouldDropSPSWork()) {\n      cmds.add(DropSPSWorkCommand.DNA_DROP_SPS_WORK_COMMAND);\n      // Set back to false to indicate that the new value has been sent to the\n      // datanode.\n      nodeinfo.setDropSPSWork(false);\n    }\n\n    // check pending block storage movement tasks\n    BlockStorageMovementInfosBatch blkStorageMovementInfosBatch \u003d nodeinfo\n        .getBlocksToMoveStorages();\n\n    if (blkStorageMovementInfosBatch !\u003d null) {\n      cmds.add(new BlockStorageMovementCommand(\n          DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT,\n          blkStorageMovementInfosBatch.getTrackID(), blockPoolId,\n          blkStorageMovementInfosBatch.getBlockMovingInfo()));\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "e34331c31d68cb22891db48011db5b36ad178af1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11243. [SPS]: Add a protocol command from NN to DN for dropping the SPS work and queues. Contributed by Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "e34331c31d68cb22891db48011db5b36ad178af1",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "19b5aee3e42cd1d6c77a58ab2eea185b5afd60b2",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,130 +1,137 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks) throws IOException {\n     final DatanodeDescriptor nodeinfo;\n     try {\n       nodeinfo \u003d getDatanode(nodeReg);\n     } catch (UnregisteredNodeException e) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n \n     // Check if this datanode should actually be shutdown instead.\n     if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n       setDatanodeDead(nodeinfo);\n       throw new DisallowedDatanodeException(nodeinfo);\n     }\n \n     if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n     heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n         cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n     // If we are in safemode, do not send back any recovery / replication\n     // requests. Don\u0027t even drain the existing queue of work.\n     if (namesystem.isInSafeMode()) {\n       return new DatanodeCommand[0];\n     }\n \n     // block recovery command\n     final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n         nodeinfo);\n     if (brCommand !\u003d null) {\n       return new DatanodeCommand[]{brCommand};\n     }\n \n     final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n     // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n     // NN chooses pending tasks based on the ratio between the lengths of\n     // replication and erasure-coded block queues.\n     int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n     int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n     int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n     if (totalBlocks \u003e 0) {\n       int numReplicationTasks \u003d (int) Math.ceil(\n           (double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n       int numECTasks \u003d (int) Math.ceil(\n           (double) (totalECBlocks * maxTransfers) / totalBlocks);\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n             + \" erasure-coded tasks: \" + numECTasks);\n       }\n       // check pending replication tasks\n       List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n           numReplicationTasks);\n       if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n         cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n             pendingList));\n       }\n       // check pending erasure coding tasks\n       List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n           .getErasureCodeCommand(numECTasks);\n       if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n         cmds.add(new BlockECReconstructionCommand(\n             DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n       }\n     }\n \n     // check block invalidation\n     Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n     if (blks !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n           blks));\n     }\n     // cache commands\n     addCacheCommands(blockPoolId, nodeinfo, cmds);\n     // key update command\n     blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n     // check for balancer bandwidth update\n     if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n       cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n       // set back to 0 to indicate that datanode has been sent the new value\n       nodeinfo.setBalancerBandwidth(0);\n     }\n \n     if (slowPeerTracker !\u003d null) {\n       final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n       if (!slowPeersMap.isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n               slowPeersMap);\n         }\n         for (String slowNodeId : slowPeersMap.keySet()) {\n           slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n         }\n       }\n     }\n \n     if (slowDiskTracker !\u003d null) {\n       if (!slowDisks.getSlowDisks().isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n               slowDisks.getSlowDisks());\n         }\n         slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n       }\n     }\n \n     // check pending block storage movement tasks\n     BlockStorageMovementInfosBatch blkStorageMovementInfosBatch \u003d nodeinfo\n         .getBlocksToMoveStorages();\n \n     if (blkStorageMovementInfosBatch !\u003d null) {\n       cmds.add(new BlockStorageMovementCommand(\n           DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT,\n           blkStorageMovementInfosBatch.getTrackID(), blockPoolId,\n           blkStorageMovementInfosBatch.getBlockMovingInfo()));\n     }\n \n+    if (nodeinfo.shouldDropSPSWork()) {\n+      cmds.add(DropSPSWorkCommand.DNA_DROP_SPS_WORK_COMMAND);\n+      // Set back to false to indicate that the new value has been sent to the\n+      // datanode.\n+      nodeinfo.setDropSPSWork(false);\n+    }\n+\n     if (!cmds.isEmpty()) {\n       return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n    // NN chooses pending tasks based on the ratio between the lengths of\n    // replication and erasure-coded block queues.\n    int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n    int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n    int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n    if (totalBlocks \u003e 0) {\n      int numReplicationTasks \u003d (int) Math.ceil(\n          (double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n      int numECTasks \u003d (int) Math.ceil(\n          (double) (totalECBlocks * maxTransfers) / totalBlocks);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n            + \" erasure-coded tasks: \" + numECTasks);\n      }\n      // check pending replication tasks\n      List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n          numReplicationTasks);\n      if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n        cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n            pendingList));\n      }\n      // check pending erasure coding tasks\n      List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n          .getErasureCodeCommand(numECTasks);\n      if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n        cmds.add(new BlockECReconstructionCommand(\n            DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n      }\n    }\n\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (slowPeerTracker !\u003d null) {\n      final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n      if (!slowPeersMap.isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n              slowPeersMap);\n        }\n        for (String slowNodeId : slowPeersMap.keySet()) {\n          slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n        }\n      }\n    }\n\n    if (slowDiskTracker !\u003d null) {\n      if (!slowDisks.getSlowDisks().isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n              slowDisks.getSlowDisks());\n        }\n        slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n      }\n    }\n\n    // check pending block storage movement tasks\n    BlockStorageMovementInfosBatch blkStorageMovementInfosBatch \u003d nodeinfo\n        .getBlocksToMoveStorages();\n\n    if (blkStorageMovementInfosBatch !\u003d null) {\n      cmds.add(new BlockStorageMovementCommand(\n          DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT,\n          blkStorageMovementInfosBatch.getTrackID(), blockPoolId,\n          blkStorageMovementInfosBatch.getBlockMovingInfo()));\n    }\n\n    if (nodeinfo.shouldDropSPSWork()) {\n      cmds.add(DropSPSWorkCommand.DNA_DROP_SPS_WORK_COMMAND);\n      // Set back to false to indicate that the new value has been sent to the\n      // datanode.\n      nodeinfo.setDropSPSWork(false);\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "19b5aee3e42cd1d6c77a58ab2eea185b5afd60b2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11068: [SPS]: Provide unique trackID to track the block movement sends to coordinator. Contributed by Rakesh R\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "19b5aee3e42cd1d6c77a58ab2eea185b5afd60b2",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "e2a15d18bbbb86c20003c4e34d85244996a4cc3b",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,132 +1,130 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks) throws IOException {\n     final DatanodeDescriptor nodeinfo;\n     try {\n       nodeinfo \u003d getDatanode(nodeReg);\n     } catch (UnregisteredNodeException e) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n \n     // Check if this datanode should actually be shutdown instead.\n     if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n       setDatanodeDead(nodeinfo);\n       throw new DisallowedDatanodeException(nodeinfo);\n     }\n \n     if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n     heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n         cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n     // If we are in safemode, do not send back any recovery / replication\n     // requests. Don\u0027t even drain the existing queue of work.\n     if (namesystem.isInSafeMode()) {\n       return new DatanodeCommand[0];\n     }\n \n     // block recovery command\n     final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n         nodeinfo);\n     if (brCommand !\u003d null) {\n       return new DatanodeCommand[]{brCommand};\n     }\n \n     final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n     // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n     // NN chooses pending tasks based on the ratio between the lengths of\n     // replication and erasure-coded block queues.\n     int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n     int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n     int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n     if (totalBlocks \u003e 0) {\n       int numReplicationTasks \u003d (int) Math.ceil(\n           (double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n       int numECTasks \u003d (int) Math.ceil(\n           (double) (totalECBlocks * maxTransfers) / totalBlocks);\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n             + \" erasure-coded tasks: \" + numECTasks);\n       }\n       // check pending replication tasks\n       List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n           numReplicationTasks);\n       if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n         cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n             pendingList));\n       }\n       // check pending erasure coding tasks\n       List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n           .getErasureCodeCommand(numECTasks);\n       if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n         cmds.add(new BlockECReconstructionCommand(\n             DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n       }\n     }\n \n     // check block invalidation\n     Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n     if (blks !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n           blks));\n     }\n     // cache commands\n     addCacheCommands(blockPoolId, nodeinfo, cmds);\n     // key update command\n     blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n     // check for balancer bandwidth update\n     if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n       cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n       // set back to 0 to indicate that datanode has been sent the new value\n       nodeinfo.setBalancerBandwidth(0);\n     }\n \n     if (slowPeerTracker !\u003d null) {\n       final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n       if (!slowPeersMap.isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n               slowPeersMap);\n         }\n         for (String slowNodeId : slowPeersMap.keySet()) {\n           slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n         }\n       }\n     }\n \n     if (slowDiskTracker !\u003d null) {\n       if (!slowDisks.getSlowDisks().isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n               slowDisks.getSlowDisks());\n         }\n         slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n       }\n     }\n \n     // check pending block storage movement tasks\n-    List\u003cBlockMovingInfo\u003e pendingBlockMovementList \u003d nodeinfo\n+    BlockStorageMovementInfosBatch blkStorageMovementInfosBatch \u003d nodeinfo\n         .getBlocksToMoveStorages();\n-    if (pendingBlockMovementList !\u003d null) {\n-      // TODO: trackID is used to track the block movement sends to coordinator\n-      // datanode. Need to implement tracking logic. Temporarily, using a\n-      // constant value -1.\n-      long trackID \u003d -1;\n+\n+    if (blkStorageMovementInfosBatch !\u003d null) {\n       cmds.add(new BlockStorageMovementCommand(\n-          DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT, trackID, blockPoolId,\n-          pendingBlockMovementList));\n+          DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT,\n+          blkStorageMovementInfosBatch.getTrackID(), blockPoolId,\n+          blkStorageMovementInfosBatch.getBlockMovingInfo()));\n     }\n \n     if (!cmds.isEmpty()) {\n       return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n    // NN chooses pending tasks based on the ratio between the lengths of\n    // replication and erasure-coded block queues.\n    int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n    int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n    int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n    if (totalBlocks \u003e 0) {\n      int numReplicationTasks \u003d (int) Math.ceil(\n          (double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n      int numECTasks \u003d (int) Math.ceil(\n          (double) (totalECBlocks * maxTransfers) / totalBlocks);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n            + \" erasure-coded tasks: \" + numECTasks);\n      }\n      // check pending replication tasks\n      List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n          numReplicationTasks);\n      if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n        cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n            pendingList));\n      }\n      // check pending erasure coding tasks\n      List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n          .getErasureCodeCommand(numECTasks);\n      if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n        cmds.add(new BlockECReconstructionCommand(\n            DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n      }\n    }\n\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (slowPeerTracker !\u003d null) {\n      final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n      if (!slowPeersMap.isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n              slowPeersMap);\n        }\n        for (String slowNodeId : slowPeersMap.keySet()) {\n          slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n        }\n      }\n    }\n\n    if (slowDiskTracker !\u003d null) {\n      if (!slowDisks.getSlowDisks().isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n              slowDisks.getSlowDisks());\n        }\n        slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n      }\n    }\n\n    // check pending block storage movement tasks\n    BlockStorageMovementInfosBatch blkStorageMovementInfosBatch \u003d nodeinfo\n        .getBlocksToMoveStorages();\n\n    if (blkStorageMovementInfosBatch !\u003d null) {\n      cmds.add(new BlockStorageMovementCommand(\n          DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT,\n          blkStorageMovementInfosBatch.getTrackID(), blockPoolId,\n          blkStorageMovementInfosBatch.getBlockMovingInfo()));\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "e2a15d18bbbb86c20003c4e34d85244996a4cc3b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10801. [SPS]: Protocol buffer changes for sending storage movement commands from NN to DN. Contributed by Rakesh R\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "e2a15d18bbbb86c20003c4e34d85244996a4cc3b",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "1438da494424193e330f24edef823bbd60dc37d2",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,119 +1,132 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks) throws IOException {\n     final DatanodeDescriptor nodeinfo;\n     try {\n       nodeinfo \u003d getDatanode(nodeReg);\n     } catch (UnregisteredNodeException e) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n \n     // Check if this datanode should actually be shutdown instead.\n     if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n       setDatanodeDead(nodeinfo);\n       throw new DisallowedDatanodeException(nodeinfo);\n     }\n \n     if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n     heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n         cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n     // If we are in safemode, do not send back any recovery / replication\n     // requests. Don\u0027t even drain the existing queue of work.\n     if (namesystem.isInSafeMode()) {\n       return new DatanodeCommand[0];\n     }\n \n     // block recovery command\n     final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n         nodeinfo);\n     if (brCommand !\u003d null) {\n       return new DatanodeCommand[]{brCommand};\n     }\n \n     final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n     // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n     // NN chooses pending tasks based on the ratio between the lengths of\n     // replication and erasure-coded block queues.\n     int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n     int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n     int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n     if (totalBlocks \u003e 0) {\n       int numReplicationTasks \u003d (int) Math.ceil(\n           (double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n       int numECTasks \u003d (int) Math.ceil(\n           (double) (totalECBlocks * maxTransfers) / totalBlocks);\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n             + \" erasure-coded tasks: \" + numECTasks);\n       }\n       // check pending replication tasks\n       List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n           numReplicationTasks);\n       if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n         cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n             pendingList));\n       }\n       // check pending erasure coding tasks\n       List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n           .getErasureCodeCommand(numECTasks);\n       if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n         cmds.add(new BlockECReconstructionCommand(\n             DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n       }\n     }\n \n     // check block invalidation\n     Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n     if (blks !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n           blks));\n     }\n     // cache commands\n     addCacheCommands(blockPoolId, nodeinfo, cmds);\n     // key update command\n     blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n     // check for balancer bandwidth update\n     if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n       cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n       // set back to 0 to indicate that datanode has been sent the new value\n       nodeinfo.setBalancerBandwidth(0);\n     }\n \n     if (slowPeerTracker !\u003d null) {\n       final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n       if (!slowPeersMap.isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n               slowPeersMap);\n         }\n         for (String slowNodeId : slowPeersMap.keySet()) {\n           slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n         }\n       }\n     }\n \n     if (slowDiskTracker !\u003d null) {\n       if (!slowDisks.getSlowDisks().isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n               slowDisks.getSlowDisks());\n         }\n         slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n       }\n     }\n \n+    // check pending block storage movement tasks\n+    List\u003cBlockMovingInfo\u003e pendingBlockMovementList \u003d nodeinfo\n+        .getBlocksToMoveStorages();\n+    if (pendingBlockMovementList !\u003d null) {\n+      // TODO: trackID is used to track the block movement sends to coordinator\n+      // datanode. Need to implement tracking logic. Temporarily, using a\n+      // constant value -1.\n+      long trackID \u003d -1;\n+      cmds.add(new BlockStorageMovementCommand(\n+          DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT, trackID, blockPoolId,\n+          pendingBlockMovementList));\n+    }\n+\n     if (!cmds.isEmpty()) {\n       return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n    // NN chooses pending tasks based on the ratio between the lengths of\n    // replication and erasure-coded block queues.\n    int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n    int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n    int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n    if (totalBlocks \u003e 0) {\n      int numReplicationTasks \u003d (int) Math.ceil(\n          (double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n      int numECTasks \u003d (int) Math.ceil(\n          (double) (totalECBlocks * maxTransfers) / totalBlocks);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n            + \" erasure-coded tasks: \" + numECTasks);\n      }\n      // check pending replication tasks\n      List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n          numReplicationTasks);\n      if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n        cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n            pendingList));\n      }\n      // check pending erasure coding tasks\n      List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n          .getErasureCodeCommand(numECTasks);\n      if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n        cmds.add(new BlockECReconstructionCommand(\n            DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n      }\n    }\n\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (slowPeerTracker !\u003d null) {\n      final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n      if (!slowPeersMap.isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n              slowPeersMap);\n        }\n        for (String slowNodeId : slowPeersMap.keySet()) {\n          slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n        }\n      }\n    }\n\n    if (slowDiskTracker !\u003d null) {\n      if (!slowDisks.getSlowDisks().isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n              slowDisks.getSlowDisks());\n        }\n        slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n      }\n    }\n\n    // check pending block storage movement tasks\n    List\u003cBlockMovingInfo\u003e pendingBlockMovementList \u003d nodeinfo\n        .getBlocksToMoveStorages();\n    if (pendingBlockMovementList !\u003d null) {\n      // TODO: trackID is used to track the block movement sends to coordinator\n      // datanode. Need to implement tracking logic. Temporarily, using a\n      // constant value -1.\n      long trackID \u003d -1;\n      cmds.add(new BlockStorageMovementCommand(\n          DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT, trackID, blockPoolId,\n          pendingBlockMovementList));\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "b29894889742dda654cd88a7ce72a4e51fccb328": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12072. Provide fairness between EC and non-EC recovery tasks. Contributed by Eddy Xu.\n",
      "commitDate": "17/08/17 3:26 PM",
      "commitName": "b29894889742dda654cd88a7ce72a4e51fccb328",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "10/08/17 11:13 PM",
      "commitNameOld": "f13ca94954072c9b898b142a5ff86f2c1f3ee55a",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 6.68,
      "commitsBetweenForRepo": 46,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,102 +1,119 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks) throws IOException {\n     final DatanodeDescriptor nodeinfo;\n     try {\n       nodeinfo \u003d getDatanode(nodeReg);\n     } catch (UnregisteredNodeException e) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n \n     // Check if this datanode should actually be shutdown instead.\n     if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n       setDatanodeDead(nodeinfo);\n       throw new DisallowedDatanodeException(nodeinfo);\n     }\n \n     if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n     heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n         cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n     // If we are in safemode, do not send back any recovery / replication\n     // requests. Don\u0027t even drain the existing queue of work.\n     if (namesystem.isInSafeMode()) {\n       return new DatanodeCommand[0];\n     }\n \n     // block recovery command\n     final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n         nodeinfo);\n     if (brCommand !\u003d null) {\n       return new DatanodeCommand[]{brCommand};\n     }\n \n     final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n-    // check pending replication\n-    List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n-        maxTransfers);\n-    if (pendingList !\u003d null) {\n-      cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n-          pendingList));\n-      maxTransfers -\u003d pendingList.size();\n+    // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n+    // NN chooses pending tasks based on the ratio between the lengths of\n+    // replication and erasure-coded block queues.\n+    int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n+    int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n+    int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n+    if (totalBlocks \u003e 0) {\n+      int numReplicationTasks \u003d (int) Math.ceil(\n+          (double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n+      int numECTasks \u003d (int) Math.ceil(\n+          (double) (totalECBlocks * maxTransfers) / totalBlocks);\n+\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n+            + \" erasure-coded tasks: \" + numECTasks);\n+      }\n+      // check pending replication tasks\n+      List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n+          numReplicationTasks);\n+      if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n+        cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n+            pendingList));\n+      }\n+      // check pending erasure coding tasks\n+      List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n+          .getErasureCodeCommand(numECTasks);\n+      if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n+        cmds.add(new BlockECReconstructionCommand(\n+            DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n+      }\n     }\n-    // check pending erasure coding tasks\n-    List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n-        .getErasureCodeCommand(maxTransfers);\n-    if (pendingECList !\u003d null) {\n-      cmds.add(new BlockECReconstructionCommand(\n-          DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n-    }\n+\n     // check block invalidation\n     Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n     if (blks !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n           blks));\n     }\n     // cache commands\n     addCacheCommands(blockPoolId, nodeinfo, cmds);\n     // key update command\n     blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n     // check for balancer bandwidth update\n     if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n       cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n       // set back to 0 to indicate that datanode has been sent the new value\n       nodeinfo.setBalancerBandwidth(0);\n     }\n \n     if (slowPeerTracker !\u003d null) {\n       final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n       if (!slowPeersMap.isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n               slowPeersMap);\n         }\n         for (String slowNodeId : slowPeersMap.keySet()) {\n           slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n         }\n       }\n     }\n \n     if (slowDiskTracker !\u003d null) {\n       if (!slowDisks.getSlowDisks().isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n               slowDisks.getSlowDisks());\n         }\n         slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n       }\n     }\n \n     if (!cmds.isEmpty()) {\n       return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // Allocate _approximately_ maxTransfers pending tasks to DataNode.\n    // NN chooses pending tasks based on the ratio between the lengths of\n    // replication and erasure-coded block queues.\n    int totalReplicateBlocks \u003d nodeinfo.getNumberOfReplicateBlocks();\n    int totalECBlocks \u003d nodeinfo.getNumberOfBlocksToBeErasureCoded();\n    int totalBlocks \u003d totalReplicateBlocks + totalECBlocks;\n    if (totalBlocks \u003e 0) {\n      int numReplicationTasks \u003d (int) Math.ceil(\n          (double) (totalReplicateBlocks * maxTransfers) / totalBlocks);\n      int numECTasks \u003d (int) Math.ceil(\n          (double) (totalECBlocks * maxTransfers) / totalBlocks);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Pending replication tasks: \" + numReplicationTasks\n            + \" erasure-coded tasks: \" + numECTasks);\n      }\n      // check pending replication tasks\n      List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n          numReplicationTasks);\n      if (pendingList !\u003d null \u0026\u0026 !pendingList.isEmpty()) {\n        cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n            pendingList));\n      }\n      // check pending erasure coding tasks\n      List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n          .getErasureCodeCommand(numECTasks);\n      if (pendingECList !\u003d null \u0026\u0026 !pendingECList.isEmpty()) {\n        cmds.add(new BlockECReconstructionCommand(\n            DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n      }\n    }\n\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (slowPeerTracker !\u003d null) {\n      final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n      if (!slowPeersMap.isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n              slowPeersMap);\n        }\n        for (String slowNodeId : slowPeersMap.keySet()) {\n          slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n        }\n      }\n    }\n\n    if (slowDiskTracker !\u003d null) {\n      if (!slowDisks.getSlowDisks().isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n              slowDisks.getSlowDisks());\n        }\n        slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n      }\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "144753e87f4a9daa51200be05ff2bb760bf38169": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12033. DatanodeManager picking EC recovery tasks should also consider the number of regular replication tasks. Contributed by Lei (Eddy) Xu.\n",
      "commitDate": "26/06/17 3:43 PM",
      "commitName": "144753e87f4a9daa51200be05ff2bb760bf38169",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "01/06/17 9:48 PM",
      "commitNameOld": "8d9084eb62f4593d4dfeb618abacf6ae89019109",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 24.75,
      "commitsBetweenForRepo": 108,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,101 +1,102 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks) throws IOException {\n     final DatanodeDescriptor nodeinfo;\n     try {\n       nodeinfo \u003d getDatanode(nodeReg);\n     } catch (UnregisteredNodeException e) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n \n     // Check if this datanode should actually be shutdown instead.\n     if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n       setDatanodeDead(nodeinfo);\n       throw new DisallowedDatanodeException(nodeinfo);\n     }\n \n     if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n     heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n         cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n     // If we are in safemode, do not send back any recovery / replication\n     // requests. Don\u0027t even drain the existing queue of work.\n     if (namesystem.isInSafeMode()) {\n       return new DatanodeCommand[0];\n     }\n \n     // block recovery command\n     final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n         nodeinfo);\n     if (brCommand !\u003d null) {\n       return new DatanodeCommand[]{brCommand};\n     }\n \n     final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n     // check pending replication\n     List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n         maxTransfers);\n     if (pendingList !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n           pendingList));\n+      maxTransfers -\u003d pendingList.size();\n     }\n     // check pending erasure coding tasks\n     List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n         .getErasureCodeCommand(maxTransfers);\n     if (pendingECList !\u003d null) {\n       cmds.add(new BlockECReconstructionCommand(\n           DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n     }\n     // check block invalidation\n     Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n     if (blks !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n           blks));\n     }\n     // cache commands\n     addCacheCommands(blockPoolId, nodeinfo, cmds);\n     // key update command\n     blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n     // check for balancer bandwidth update\n     if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n       cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n       // set back to 0 to indicate that datanode has been sent the new value\n       nodeinfo.setBalancerBandwidth(0);\n     }\n \n     if (slowPeerTracker !\u003d null) {\n       final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n       if (!slowPeersMap.isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n               slowPeersMap);\n         }\n         for (String slowNodeId : slowPeersMap.keySet()) {\n           slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n         }\n       }\n     }\n \n     if (slowDiskTracker !\u003d null) {\n       if (!slowDisks.getSlowDisks().isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n               slowDisks.getSlowDisks());\n         }\n         slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n       }\n     }\n \n     if (!cmds.isEmpty()) {\n       return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // check pending replication\n    List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n        maxTransfers);\n    if (pendingList !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n          pendingList));\n      maxTransfers -\u003d pendingList.size();\n    }\n    // check pending erasure coding tasks\n    List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n        .getErasureCodeCommand(maxTransfers);\n    if (pendingECList !\u003d null) {\n      cmds.add(new BlockECReconstructionCommand(\n          DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n    }\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (slowPeerTracker !\u003d null) {\n      final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n      if (!slowPeersMap.isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n              slowPeersMap);\n        }\n        for (String slowNodeId : slowPeersMap.keySet()) {\n          slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n        }\n      }\n    }\n\n    if (slowDiskTracker !\u003d null) {\n      if (!slowDisks.getSlowDisks().isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n              slowDisks.getSlowDisks());\n        }\n        slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n      }\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "28cdc5a8dc37ade1f45bda3aede589ee8593945e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11551. Handle SlowDiskReport from DataNode at the NameNode. Contributed by Hanisha Koneru.\n",
      "commitDate": "30/03/17 10:41 PM",
      "commitName": "28cdc5a8dc37ade1f45bda3aede589ee8593945e",
      "commitAuthor": "Hanisha Koneru",
      "commitDateOld": "20/03/17 9:54 PM",
      "commitNameOld": "e7c8da614c37e36fb8081234f4c639d6054f6082",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 10.03,
      "commitsBetweenForRepo": 73,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,91 +1,101 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks) throws IOException {\n     final DatanodeDescriptor nodeinfo;\n     try {\n       nodeinfo \u003d getDatanode(nodeReg);\n     } catch (UnregisteredNodeException e) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n \n     // Check if this datanode should actually be shutdown instead.\n     if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n       setDatanodeDead(nodeinfo);\n       throw new DisallowedDatanodeException(nodeinfo);\n     }\n \n     if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n     heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n         cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n     // If we are in safemode, do not send back any recovery / replication\n     // requests. Don\u0027t even drain the existing queue of work.\n     if (namesystem.isInSafeMode()) {\n       return new DatanodeCommand[0];\n     }\n \n     // block recovery command\n     final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n         nodeinfo);\n     if (brCommand !\u003d null) {\n       return new DatanodeCommand[]{brCommand};\n     }\n \n     final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n     // check pending replication\n     List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n         maxTransfers);\n     if (pendingList !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n           pendingList));\n     }\n     // check pending erasure coding tasks\n     List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n         .getErasureCodeCommand(maxTransfers);\n     if (pendingECList !\u003d null) {\n       cmds.add(new BlockECReconstructionCommand(\n           DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n     }\n     // check block invalidation\n     Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n     if (blks !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n           blks));\n     }\n     // cache commands\n     addCacheCommands(blockPoolId, nodeinfo, cmds);\n     // key update command\n     blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n     // check for balancer bandwidth update\n     if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n       cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n       // set back to 0 to indicate that datanode has been sent the new value\n       nodeinfo.setBalancerBandwidth(0);\n     }\n \n     if (slowPeerTracker !\u003d null) {\n       final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n       if (!slowPeersMap.isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n               slowPeersMap);\n         }\n         for (String slowNodeId : slowPeersMap.keySet()) {\n           slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n         }\n       }\n     }\n \n+    if (slowDiskTracker !\u003d null) {\n+      if (!slowDisks.getSlowDisks().isEmpty()) {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n+              slowDisks.getSlowDisks());\n+        }\n+        slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n+      }\n+    }\n+\n     if (!cmds.isEmpty()) {\n       return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // check pending replication\n    List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n        maxTransfers);\n    if (pendingList !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n          pendingList));\n    }\n    // check pending erasure coding tasks\n    List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n        .getErasureCodeCommand(maxTransfers);\n    if (pendingECList !\u003d null) {\n      cmds.add(new BlockECReconstructionCommand(\n          DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n    }\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (slowPeerTracker !\u003d null) {\n      final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n      if (!slowPeersMap.isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n              slowPeersMap);\n        }\n        for (String slowNodeId : slowPeersMap.keySet()) {\n          slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n        }\n      }\n    }\n\n    if (slowDiskTracker !\u003d null) {\n      if (!slowDisks.getSlowDisks().isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow disks: \" +\n              slowDisks.getSlowDisks());\n        }\n        slowDiskTracker.addSlowDiskReport(nodeReg.getIpcAddr(false), slowDisks);\n      }\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "e7c8da614c37e36fb8081234f4c639d6054f6082": {
      "type": "Yparameterchange",
      "commitMessage": "HDFS-11545. Propagate DataNode\u0027s slow disks info to the NameNode via Heartbeats. Contributed by Hanisha Koneru.\n",
      "commitDate": "20/03/17 9:54 PM",
      "commitName": "e7c8da614c37e36fb8081234f4c639d6054f6082",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "14/02/17 2:57 AM",
      "commitNameOld": "4164a2032a41e7318749efd0301751eb2b369cdc",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 34.75,
      "commitsBetweenForRepo": 214,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,91 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n-      @Nonnull SlowPeerReports slowPeers) throws IOException {\n+      @Nonnull SlowPeerReports slowPeers,\n+      @Nonnull SlowDiskReports slowDisks) throws IOException {\n     final DatanodeDescriptor nodeinfo;\n     try {\n       nodeinfo \u003d getDatanode(nodeReg);\n     } catch (UnregisteredNodeException e) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n \n     // Check if this datanode should actually be shutdown instead.\n     if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n       setDatanodeDead(nodeinfo);\n       throw new DisallowedDatanodeException(nodeinfo);\n     }\n \n     if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n     heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n         cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n     // If we are in safemode, do not send back any recovery / replication\n     // requests. Don\u0027t even drain the existing queue of work.\n     if (namesystem.isInSafeMode()) {\n       return new DatanodeCommand[0];\n     }\n \n     // block recovery command\n     final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n         nodeinfo);\n     if (brCommand !\u003d null) {\n       return new DatanodeCommand[]{brCommand};\n     }\n \n     final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n     // check pending replication\n     List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n         maxTransfers);\n     if (pendingList !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n           pendingList));\n     }\n     // check pending erasure coding tasks\n     List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n         .getErasureCodeCommand(maxTransfers);\n     if (pendingECList !\u003d null) {\n       cmds.add(new BlockECReconstructionCommand(\n           DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n     }\n     // check block invalidation\n     Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n     if (blks !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n           blks));\n     }\n     // cache commands\n     addCacheCommands(blockPoolId, nodeinfo, cmds);\n     // key update command\n     blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n     // check for balancer bandwidth update\n     if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n       cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n       // set back to 0 to indicate that datanode has been sent the new value\n       nodeinfo.setBalancerBandwidth(0);\n     }\n \n     if (slowPeerTracker !\u003d null) {\n       final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n       if (!slowPeersMap.isEmpty()) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n               slowPeersMap);\n         }\n         for (String slowNodeId : slowPeersMap.keySet()) {\n           slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n         }\n       }\n     }\n \n     if (!cmds.isEmpty()) {\n       return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // check pending replication\n    List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n        maxTransfers);\n    if (pendingList !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n          pendingList));\n    }\n    // check pending erasure coding tasks\n    List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n        .getErasureCodeCommand(maxTransfers);\n    if (pendingECList !\u003d null) {\n      cmds.add(new BlockECReconstructionCommand(\n          DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n    }\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (slowPeerTracker !\u003d null) {\n      final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n      if (!slowPeersMap.isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n              slowPeersMap);\n        }\n        for (String slowNodeId : slowPeersMap.keySet()) {\n          slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n        }\n      }\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldValue": "[nodeReg-DatanodeRegistration, reports-StorageReport[], blockPoolId-String(modifiers-final), cacheCapacity-long, cacheUsed-long, xceiverCount-int, maxTransfers-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, slowPeers-SlowPeerReports(annotations-@Nonnull)]",
        "newValue": "[nodeReg-DatanodeRegistration, reports-StorageReport[], blockPoolId-String(modifiers-final), cacheCapacity-long, cacheUsed-long, xceiverCount-int, maxTransfers-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, slowPeers-SlowPeerReports(annotations-@Nonnull), slowDisks-SlowDiskReports(annotations-@Nonnull)]"
      }
    },
    "b57368b6f893cb27d77fc9425e116f1312f4790f": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-11194. Maintain aggregated peer performance metrics on NameNode.\n",
      "commitDate": "24/01/17 4:58 PM",
      "commitName": "b57368b6f893cb27d77fc9425e116f1312f4790f",
      "commitAuthor": "Arpit Agarwal",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-11194. Maintain aggregated peer performance metrics on NameNode.\n",
          "commitDate": "24/01/17 4:58 PM",
          "commitName": "b57368b6f893cb27d77fc9425e116f1312f4790f",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "09/12/16 1:23 AM",
          "commitNameOld": "d1d4aba71b21871140b162583a4b94ce118e1fb3",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 46.65,
          "commitsBetweenForRepo": 212,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,76 +1,90 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n-      VolumeFailureSummary volumeFailureSummary) throws IOException {\n+      VolumeFailureSummary volumeFailureSummary,\n+      @Nonnull SlowPeerReports slowPeers) throws IOException {\n     final DatanodeDescriptor nodeinfo;\n     try {\n       nodeinfo \u003d getDatanode(nodeReg);\n     } catch (UnregisteredNodeException e) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n \n     // Check if this datanode should actually be shutdown instead.\n     if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n       setDatanodeDead(nodeinfo);\n       throw new DisallowedDatanodeException(nodeinfo);\n     }\n \n     if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n     heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n         cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n     // If we are in safemode, do not send back any recovery / replication\n     // requests. Don\u0027t even drain the existing queue of work.\n     if (namesystem.isInSafeMode()) {\n       return new DatanodeCommand[0];\n     }\n \n     // block recovery command\n     final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n         nodeinfo);\n     if (brCommand !\u003d null) {\n       return new DatanodeCommand[]{brCommand};\n     }\n \n     final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n     // check pending replication\n     List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n         maxTransfers);\n     if (pendingList !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n           pendingList));\n     }\n     // check pending erasure coding tasks\n     List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n         .getErasureCodeCommand(maxTransfers);\n     if (pendingECList !\u003d null) {\n       cmds.add(new BlockECReconstructionCommand(\n           DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n     }\n     // check block invalidation\n     Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n     if (blks !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n           blks));\n     }\n     // cache commands\n     addCacheCommands(blockPoolId, nodeinfo, cmds);\n     // key update command\n     blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n     // check for balancer bandwidth update\n     if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n       cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n       // set back to 0 to indicate that datanode has been sent the new value\n       nodeinfo.setBalancerBandwidth(0);\n     }\n \n+    if (slowPeerTracker !\u003d null) {\n+      final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n+      if (!slowPeersMap.isEmpty()) {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n+              slowPeersMap);\n+        }\n+        for (String slowNodeId : slowPeersMap.keySet()) {\n+          slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n+        }\n+      }\n+    }\n+\n     if (!cmds.isEmpty()) {\n       return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      @Nonnull SlowPeerReports slowPeers) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // check pending replication\n    List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n        maxTransfers);\n    if (pendingList !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n          pendingList));\n    }\n    // check pending erasure coding tasks\n    List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n        .getErasureCodeCommand(maxTransfers);\n    if (pendingECList !\u003d null) {\n      cmds.add(new BlockECReconstructionCommand(\n          DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n    }\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (slowPeerTracker !\u003d null) {\n      final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n      if (!slowPeersMap.isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n              slowPeersMap);\n        }\n        for (String slowNodeId : slowPeersMap.keySet()) {\n          slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n        }\n      }\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {
            "oldValue": "[nodeReg-DatanodeRegistration, reports-StorageReport[], blockPoolId-String(modifiers-final), cacheCapacity-long, cacheUsed-long, xceiverCount-int, maxTransfers-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary]",
            "newValue": "[nodeReg-DatanodeRegistration, reports-StorageReport[], blockPoolId-String(modifiers-final), cacheCapacity-long, cacheUsed-long, xceiverCount-int, maxTransfers-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, slowPeers-SlowPeerReports(annotations-@Nonnull)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-11194. Maintain aggregated peer performance metrics on NameNode.\n",
          "commitDate": "24/01/17 4:58 PM",
          "commitName": "b57368b6f893cb27d77fc9425e116f1312f4790f",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "09/12/16 1:23 AM",
          "commitNameOld": "d1d4aba71b21871140b162583a4b94ce118e1fb3",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 46.65,
          "commitsBetweenForRepo": 212,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,76 +1,90 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n-      VolumeFailureSummary volumeFailureSummary) throws IOException {\n+      VolumeFailureSummary volumeFailureSummary,\n+      @Nonnull SlowPeerReports slowPeers) throws IOException {\n     final DatanodeDescriptor nodeinfo;\n     try {\n       nodeinfo \u003d getDatanode(nodeReg);\n     } catch (UnregisteredNodeException e) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n \n     // Check if this datanode should actually be shutdown instead.\n     if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n       setDatanodeDead(nodeinfo);\n       throw new DisallowedDatanodeException(nodeinfo);\n     }\n \n     if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n     heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n         cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n     // If we are in safemode, do not send back any recovery / replication\n     // requests. Don\u0027t even drain the existing queue of work.\n     if (namesystem.isInSafeMode()) {\n       return new DatanodeCommand[0];\n     }\n \n     // block recovery command\n     final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n         nodeinfo);\n     if (brCommand !\u003d null) {\n       return new DatanodeCommand[]{brCommand};\n     }\n \n     final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n     // check pending replication\n     List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n         maxTransfers);\n     if (pendingList !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n           pendingList));\n     }\n     // check pending erasure coding tasks\n     List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n         .getErasureCodeCommand(maxTransfers);\n     if (pendingECList !\u003d null) {\n       cmds.add(new BlockECReconstructionCommand(\n           DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n     }\n     // check block invalidation\n     Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n     if (blks !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n           blks));\n     }\n     // cache commands\n     addCacheCommands(blockPoolId, nodeinfo, cmds);\n     // key update command\n     blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n     // check for balancer bandwidth update\n     if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n       cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n       // set back to 0 to indicate that datanode has been sent the new value\n       nodeinfo.setBalancerBandwidth(0);\n     }\n \n+    if (slowPeerTracker !\u003d null) {\n+      final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n+      if (!slowPeersMap.isEmpty()) {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n+              slowPeersMap);\n+        }\n+        for (String slowNodeId : slowPeersMap.keySet()) {\n+          slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n+        }\n+      }\n+    }\n+\n     if (!cmds.isEmpty()) {\n       return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      @Nonnull SlowPeerReports slowPeers) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // check pending replication\n    List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n        maxTransfers);\n    if (pendingList !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n          pendingList));\n    }\n    // check pending erasure coding tasks\n    List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n        .getErasureCodeCommand(maxTransfers);\n    if (pendingECList !\u003d null) {\n      cmds.add(new BlockECReconstructionCommand(\n          DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n    }\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (slowPeerTracker !\u003d null) {\n      final Map\u003cString, Double\u003e slowPeersMap \u003d slowPeers.getSlowPeers();\n      if (!slowPeersMap.isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"DataNode \" + nodeReg + \" reported slow peers: \" +\n              slowPeersMap);\n        }\n        for (String slowNodeId : slowPeersMap.keySet()) {\n          slowPeerTracker.addReport(slowNodeId, nodeReg.getIpcAddr(false));\n        }\n      }\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "4ae543fdcd6dcfbe32257b1e72a405df9aa73e17": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9731. Erasure Coding: Rename BlockECRecoveryCommand to BlockECReconstructionCommand. Contributed by Rakesh R.\n\nChange-Id: I405365a8395770e494b92bfe9651f4f0366d8f28\n",
      "commitDate": "02/02/16 12:32 PM",
      "commitName": "4ae543fdcd6dcfbe32257b1e72a405df9aa73e17",
      "commitAuthor": "zhezhang",
      "commitDateOld": "22/12/15 3:28 PM",
      "commitNameOld": "df83230948204ee2d2b06ecc66ce0163e2df27ef",
      "commitAuthorOld": "Benoy Antony",
      "daysBetweenCommits": 41.88,
      "commitsBetweenForRepo": 247,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,76 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary) throws IOException {\n     final DatanodeDescriptor nodeinfo;\n     try {\n       nodeinfo \u003d getDatanode(nodeReg);\n     } catch (UnregisteredNodeException e) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n \n     // Check if this datanode should actually be shutdown instead.\n     if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n       setDatanodeDead(nodeinfo);\n       throw new DisallowedDatanodeException(nodeinfo);\n     }\n \n     if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n     heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n         cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n     // If we are in safemode, do not send back any recovery / replication\n     // requests. Don\u0027t even drain the existing queue of work.\n     if (namesystem.isInSafeMode()) {\n       return new DatanodeCommand[0];\n     }\n \n     // block recovery command\n     final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n         nodeinfo);\n     if (brCommand !\u003d null) {\n       return new DatanodeCommand[]{brCommand};\n     }\n \n     final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n     // check pending replication\n     List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n         maxTransfers);\n     if (pendingList !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n           pendingList));\n     }\n     // check pending erasure coding tasks\n-    List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d nodeinfo.getErasureCodeCommand(\n-        maxTransfers);\n+    List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n+        .getErasureCodeCommand(maxTransfers);\n     if (pendingECList !\u003d null) {\n-      cmds.add(new BlockECRecoveryCommand(DNA_ERASURE_CODING_RECOVERY,\n-          pendingECList));\n+      cmds.add(new BlockECReconstructionCommand(\n+          DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n     }\n     // check block invalidation\n     Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n     if (blks !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n           blks));\n     }\n     // cache commands\n     addCacheCommands(blockPoolId, nodeinfo, cmds);\n     // key update command\n     blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n     // check for balancer bandwidth update\n     if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n       cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n       // set back to 0 to indicate that datanode has been sent the new value\n       nodeinfo.setBalancerBandwidth(0);\n     }\n \n     if (!cmds.isEmpty()) {\n       return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // check pending replication\n    List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n        maxTransfers);\n    if (pendingList !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n          pendingList));\n    }\n    // check pending erasure coding tasks\n    List\u003cBlockECReconstructionInfo\u003e pendingECList \u003d nodeinfo\n        .getErasureCodeCommand(maxTransfers);\n    if (pendingECList !\u003d null) {\n      cmds.add(new BlockECReconstructionCommand(\n          DNA_ERASURE_CODING_RECONSTRUCTION, pendingECList));\n    }\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "f741476146574550a1a208d58ef8be76639e5ddc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9198. Coalesce IBR processing in the NN. (Daryn Sharp via umamahesh)\n",
      "commitDate": "16/12/15 6:16 PM",
      "commitName": "f741476146574550a1a208d58ef8be76639e5ddc",
      "commitAuthor": "Uma Mahesh",
      "commitDateOld": "15/12/15 10:47 AM",
      "commitNameOld": "8602692338d6f493647205e0241e4116211fab75",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 1.31,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,76 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary) throws IOException {\n     final DatanodeDescriptor nodeinfo;\n     try {\n       nodeinfo \u003d getDatanode(nodeReg);\n     } catch (UnregisteredNodeException e) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n \n     // Check if this datanode should actually be shutdown instead.\n     if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n       setDatanodeDead(nodeinfo);\n       throw new DisallowedDatanodeException(nodeinfo);\n     }\n \n-    if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive()) {\n+    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n       return new DatanodeCommand[]{RegisterCommand.REGISTER};\n     }\n     heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n         cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n     // If we are in safemode, do not send back any recovery / replication\n     // requests. Don\u0027t even drain the existing queue of work.\n     if (namesystem.isInSafeMode()) {\n       return new DatanodeCommand[0];\n     }\n \n     // block recovery command\n     final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n         nodeinfo);\n     if (brCommand !\u003d null) {\n       return new DatanodeCommand[]{brCommand};\n     }\n \n     final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n     // check pending replication\n     List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n         maxTransfers);\n     if (pendingList !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n           pendingList));\n     }\n     // check pending erasure coding tasks\n     List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d nodeinfo.getErasureCodeCommand(\n         maxTransfers);\n     if (pendingECList !\u003d null) {\n       cmds.add(new BlockECRecoveryCommand(DNA_ERASURE_CODING_RECOVERY,\n           pendingECList));\n     }\n     // check block invalidation\n     Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n     if (blks !\u003d null) {\n       cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n           blks));\n     }\n     // cache commands\n     addCacheCommands(blockPoolId, nodeinfo, cmds);\n     // key update command\n     blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n     // check for balancer bandwidth update\n     if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n       cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n       // set back to 0 to indicate that datanode has been sent the new value\n       nodeinfo.setBalancerBandwidth(0);\n     }\n \n     if (!cmds.isEmpty()) {\n       return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isRegistered()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // check pending replication\n    List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n        maxTransfers);\n    if (pendingList !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n          pendingList));\n    }\n    // check pending erasure coding tasks\n    List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d nodeinfo.getErasureCodeCommand(\n        maxTransfers);\n    if (pendingECList !\u003d null) {\n      cmds.add(new BlockECRecoveryCommand(DNA_ERASURE_CODING_RECOVERY,\n          pendingECList));\n    }\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "8602692338d6f493647205e0241e4116211fab75": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9371. Code cleanup for DatanodeManager. Contributed by Jing Zhao.\n",
      "commitDate": "15/12/15 10:47 AM",
      "commitName": "8602692338d6f493647205e0241e4116211fab75",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "01/12/15 4:09 PM",
      "commitNameOld": "a49cc74b4c72195dee1dfb6f9548e5e411dff553",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 13.78,
      "commitsBetweenForRepo": 73,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,152 +1,76 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary) throws IOException {\n-    synchronized (heartbeatManager) {\n-      synchronized (datanodeMap) {\n-        DatanodeDescriptor nodeinfo;\n-        try {\n-          nodeinfo \u003d getDatanode(nodeReg);\n-        } catch(UnregisteredNodeException e) {\n-          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n-        }\n-        \n-        // Check if this datanode should actually be shutdown instead. \n-        if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n-          setDatanodeDead(nodeinfo);\n-          throw new DisallowedDatanodeException(nodeinfo);\n-        }\n+    final DatanodeDescriptor nodeinfo;\n+    try {\n+      nodeinfo \u003d getDatanode(nodeReg);\n+    } catch (UnregisteredNodeException e) {\n+      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n+    }\n \n-        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive()) {\n-          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n-        }\n+    // Check if this datanode should actually be shutdown instead.\n+    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n+      setDatanodeDead(nodeinfo);\n+      throw new DisallowedDatanodeException(nodeinfo);\n+    }\n \n-        heartbeatManager.updateHeartbeat(nodeinfo, reports,\n-                                         cacheCapacity, cacheUsed,\n-                                         xceiverCount, failedVolumes,\n-                                         volumeFailureSummary);\n+    if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive()) {\n+      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n+    }\n+    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n+        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n \n-        // If we are in safemode, do not send back any recovery / replication\n-        // requests. Don\u0027t even drain the existing queue of work.\n-        if(namesystem.isInSafeMode()) {\n-          return new DatanodeCommand[0];\n-        }\n+    // If we are in safemode, do not send back any recovery / replication\n+    // requests. Don\u0027t even drain the existing queue of work.\n+    if (namesystem.isInSafeMode()) {\n+      return new DatanodeCommand[0];\n+    }\n \n-        //check lease recovery\n-        BlockInfo[] blocks \u003d nodeinfo.getLeaseRecoveryCommand(Integer.MAX_VALUE);\n-        if (blocks !\u003d null) {\n-          BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n-              blocks.length);\n-          for (BlockInfo b : blocks) {\n-            BlockUnderConstructionFeature uc \u003d b.getUnderConstructionFeature();\n-            assert uc !\u003d null;\n-            final DatanodeStorageInfo[] storages \u003d uc.getExpectedStorageLocations();\n-            // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n-            final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n-                new ArrayList\u003c\u003e(storages.length);\n-            for (DatanodeStorageInfo storage : storages) {\n-              if (!storage.getDatanodeDescriptor().isStale(staleInterval)) {\n-                recoveryLocations.add(storage);\n-              }\n-            }\n-            // If we are performing a truncate recovery than set recovery fields\n-            // to old block.\n-            boolean truncateRecovery \u003d uc.getTruncateBlock() !\u003d null;\n-            boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n-                uc.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n-            ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n-                new ExtendedBlock(blockPoolId, uc.getTruncateBlock()) :\n-                new ExtendedBlock(blockPoolId, b);\n-            // If we only get 1 replica after eliminating stale nodes, then choose all\n-            // replicas for recovery and let the primary data node handle failures.\n-            DatanodeInfo[] recoveryInfos;\n-            if (recoveryLocations.size() \u003e 1) {\n-              if (recoveryLocations.size() !\u003d storages.length) {\n-                LOG.info(\"Skipped stale nodes for recovery : \" +\n-                    (storages.length - recoveryLocations.size()));\n-              }\n-              recoveryInfos \u003d\n-                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n-            } else {\n-              // If too many replicas are stale, then choose all replicas to participate\n-              // in block recovery.\n-              recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n-            }\n-            RecoveringBlock rBlock;\n-            if(truncateRecovery) {\n-              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n-                  uc.getTruncateBlock();\n-              rBlock \u003d new RecoveringBlock(primaryBlock, recoveryInfos,\n-                  recoveryBlock);\n-            } else {\n-              rBlock \u003d new RecoveringBlock(primaryBlock, recoveryInfos,\n-                  uc.getBlockRecoveryId());\n-            }\n-            brCommand.add(rBlock);\n-          }\n-          return new DatanodeCommand[] { brCommand };\n-        }\n+    // block recovery command\n+    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n+        nodeinfo);\n+    if (brCommand !\u003d null) {\n+      return new DatanodeCommand[]{brCommand};\n+    }\n \n-        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n-        //check pending replication\n-        List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n-              maxTransfers);\n-        if (pendingList !\u003d null) {\n-          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n-              pendingList));\n-        }\n-        // checking pending erasure coding tasks\n-        List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d\n-            nodeinfo.getErasureCodeCommand(maxTransfers);\n-        if (pendingECList !\u003d null) {\n-          cmds.add(new BlockECRecoveryCommand(DatanodeProtocol.DNA_ERASURE_CODING_RECOVERY,\n-              pendingECList));\n-        }\n-        //check block invalidation\n-        Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n-        if (blks !\u003d null) {\n-          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n-              blockPoolId, blks));\n-        }\n-        boolean sendingCachingCommands \u003d false;\n-        long nowMs \u003d monotonicNow();\n-        if (shouldSendCachingCommands \u0026\u0026 \n-            ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n-                timeBetweenResendingCachingDirectivesMs)) {\n-          DatanodeCommand pendingCacheCommand \u003d\n-              getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n-                DatanodeProtocol.DNA_CACHE, blockPoolId);\n-          if (pendingCacheCommand !\u003d null) {\n-            cmds.add(pendingCacheCommand);\n-            sendingCachingCommands \u003d true;\n-          }\n-          DatanodeCommand pendingUncacheCommand \u003d\n-              getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n-                DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n-          if (pendingUncacheCommand !\u003d null) {\n-            cmds.add(pendingUncacheCommand);\n-            sendingCachingCommands \u003d true;\n-          }\n-          if (sendingCachingCommands) {\n-            nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n-          }\n-        }\n+    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n+    // check pending replication\n+    List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n+        maxTransfers);\n+    if (pendingList !\u003d null) {\n+      cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n+          pendingList));\n+    }\n+    // check pending erasure coding tasks\n+    List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d nodeinfo.getErasureCodeCommand(\n+        maxTransfers);\n+    if (pendingECList !\u003d null) {\n+      cmds.add(new BlockECRecoveryCommand(DNA_ERASURE_CODING_RECOVERY,\n+          pendingECList));\n+    }\n+    // check block invalidation\n+    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n+    if (blks !\u003d null) {\n+      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n+          blks));\n+    }\n+    // cache commands\n+    addCacheCommands(blockPoolId, nodeinfo, cmds);\n+    // key update command\n+    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n-        blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n+    // check for balancer bandwidth update\n+    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n+      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n+      // set back to 0 to indicate that datanode has been sent the new value\n+      nodeinfo.setBalancerBandwidth(0);\n+    }\n \n-        // check for balancer bandwidth update\n-        if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n-          cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n-          // set back to 0 to indicate that datanode has been sent the new value\n-          nodeinfo.setBalancerBandwidth(0);\n-        }\n-\n-        if (!cmds.isEmpty()) {\n-          return cmds.toArray(new DatanodeCommand[cmds.size()]);\n-        }\n-      }\n+    if (!cmds.isEmpty()) {\n+      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    final DatanodeDescriptor nodeinfo;\n    try {\n      nodeinfo \u003d getDatanode(nodeReg);\n    } catch (UnregisteredNodeException e) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n\n    // Check if this datanode should actually be shutdown instead.\n    if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n      setDatanodeDead(nodeinfo);\n      throw new DisallowedDatanodeException(nodeinfo);\n    }\n\n    if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive()) {\n      return new DatanodeCommand[]{RegisterCommand.REGISTER};\n    }\n    heartbeatManager.updateHeartbeat(nodeinfo, reports, cacheCapacity,\n        cacheUsed, xceiverCount, failedVolumes, volumeFailureSummary);\n\n    // If we are in safemode, do not send back any recovery / replication\n    // requests. Don\u0027t even drain the existing queue of work.\n    if (namesystem.isInSafeMode()) {\n      return new DatanodeCommand[0];\n    }\n\n    // block recovery command\n    final BlockRecoveryCommand brCommand \u003d getBlockRecoveryCommand(blockPoolId,\n        nodeinfo);\n    if (brCommand !\u003d null) {\n      return new DatanodeCommand[]{brCommand};\n    }\n\n    final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n    // check pending replication\n    List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n        maxTransfers);\n    if (pendingList !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n          pendingList));\n    }\n    // check pending erasure coding tasks\n    List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d nodeinfo.getErasureCodeCommand(\n        maxTransfers);\n    if (pendingECList !\u003d null) {\n      cmds.add(new BlockECRecoveryCommand(DNA_ERASURE_CODING_RECOVERY,\n          pendingECList));\n    }\n    // check block invalidation\n    Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n    if (blks !\u003d null) {\n      cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE, blockPoolId,\n          blks));\n    }\n    // cache commands\n    addCacheCommands(blockPoolId, nodeinfo, cmds);\n    // key update command\n    blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n    // check for balancer bandwidth update\n    if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n      cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n      // set back to 0 to indicate that datanode has been sent the new value\n      nodeinfo.setBalancerBandwidth(0);\n    }\n\n    if (!cmds.isEmpty()) {\n      return cmds.toArray(new DatanodeCommand[cmds.size()]);\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "e287e7d14b838a866ba03d895fa35819999d7c09": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9255. Consolidate block recovery related implementation into a single class. Contributed by Walter Su.\n\nChange-Id: I7a1c03f50123d79ac0a78c981d9721617e3229d1\n",
      "commitDate": "28/10/15 7:34 AM",
      "commitName": "e287e7d14b838a866ba03d895fa35819999d7c09",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "21/10/15 8:06 AM",
      "commitNameOld": "e27c2ae8bafc94f18eb38f5d839dcef5652d424e",
      "commitAuthorOld": "Ming Ma",
      "daysBetweenCommits": 6.98,
      "commitsBetweenForRepo": 84,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,150 +1,152 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary) throws IOException {\n     synchronized (heartbeatManager) {\n       synchronized (datanodeMap) {\n         DatanodeDescriptor nodeinfo;\n         try {\n           nodeinfo \u003d getDatanode(nodeReg);\n         } catch(UnregisteredNodeException e) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n         \n         // Check if this datanode should actually be shutdown instead. \n         if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n           setDatanodeDead(nodeinfo);\n           throw new DisallowedDatanodeException(nodeinfo);\n         }\n \n         if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive()) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n \n         heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                          cacheCapacity, cacheUsed,\n                                          xceiverCount, failedVolumes,\n                                          volumeFailureSummary);\n \n         // If we are in safemode, do not send back any recovery / replication\n         // requests. Don\u0027t even drain the existing queue of work.\n         if(namesystem.isInSafeMode()) {\n           return new DatanodeCommand[0];\n         }\n \n         //check lease recovery\n         BlockInfo[] blocks \u003d nodeinfo.getLeaseRecoveryCommand(Integer.MAX_VALUE);\n         if (blocks !\u003d null) {\n           BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n               blocks.length);\n           for (BlockInfo b : blocks) {\n             BlockUnderConstructionFeature uc \u003d b.getUnderConstructionFeature();\n             assert uc !\u003d null;\n             final DatanodeStorageInfo[] storages \u003d uc.getExpectedStorageLocations();\n             // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n             final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                 new ArrayList\u003c\u003e(storages.length);\n             for (DatanodeStorageInfo storage : storages) {\n               if (!storage.getDatanodeDescriptor().isStale(staleInterval)) {\n                 recoveryLocations.add(storage);\n               }\n             }\n             // If we are performing a truncate recovery than set recovery fields\n             // to old block.\n             boolean truncateRecovery \u003d uc.getTruncateBlock() !\u003d null;\n             boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                 uc.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n             ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                 new ExtendedBlock(blockPoolId, uc.getTruncateBlock()) :\n                 new ExtendedBlock(blockPoolId, b);\n             // If we only get 1 replica after eliminating stale nodes, then choose all\n             // replicas for recovery and let the primary data node handle failures.\n             DatanodeInfo[] recoveryInfos;\n             if (recoveryLocations.size() \u003e 1) {\n               if (recoveryLocations.size() !\u003d storages.length) {\n                 LOG.info(\"Skipped stale nodes for recovery : \" +\n                     (storages.length - recoveryLocations.size()));\n               }\n               recoveryInfos \u003d\n                   DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n             } else {\n               // If too many replicas are stale, then choose all replicas to participate\n               // in block recovery.\n               recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n             }\n+            RecoveringBlock rBlock;\n             if(truncateRecovery) {\n               Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                   uc.getTruncateBlock();\n-              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n-                                                recoveryBlock));\n+              rBlock \u003d new RecoveringBlock(primaryBlock, recoveryInfos,\n+                  recoveryBlock);\n             } else {\n-              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n-                                                uc.getBlockRecoveryId()));\n+              rBlock \u003d new RecoveringBlock(primaryBlock, recoveryInfos,\n+                  uc.getBlockRecoveryId());\n             }\n+            brCommand.add(rBlock);\n           }\n           return new DatanodeCommand[] { brCommand };\n         }\n \n         final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n         //check pending replication\n         List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n               maxTransfers);\n         if (pendingList !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n               pendingList));\n         }\n         // checking pending erasure coding tasks\n         List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d\n             nodeinfo.getErasureCodeCommand(maxTransfers);\n         if (pendingECList !\u003d null) {\n           cmds.add(new BlockECRecoveryCommand(DatanodeProtocol.DNA_ERASURE_CODING_RECOVERY,\n               pendingECList));\n         }\n         //check block invalidation\n         Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n         if (blks !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n               blockPoolId, blks));\n         }\n         boolean sendingCachingCommands \u003d false;\n         long nowMs \u003d monotonicNow();\n         if (shouldSendCachingCommands \u0026\u0026 \n             ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                 timeBetweenResendingCachingDirectivesMs)) {\n           DatanodeCommand pendingCacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                 DatanodeProtocol.DNA_CACHE, blockPoolId);\n           if (pendingCacheCommand !\u003d null) {\n             cmds.add(pendingCacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           DatanodeCommand pendingUncacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                 DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n           if (pendingUncacheCommand !\u003d null) {\n             cmds.add(pendingUncacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           if (sendingCachingCommands) {\n             nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n           }\n         }\n \n         blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n         // check for balancer bandwidth update\n         if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n           cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n           // set back to 0 to indicate that datanode has been sent the new value\n           nodeinfo.setBalancerBandwidth(0);\n         }\n \n         if (!cmds.isEmpty()) {\n           return cmds.toArray(new DatanodeCommand[cmds.size()]);\n         }\n       }\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    synchronized (heartbeatManager) {\n      synchronized (datanodeMap) {\n        DatanodeDescriptor nodeinfo;\n        try {\n          nodeinfo \u003d getDatanode(nodeReg);\n        } catch(UnregisteredNodeException e) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n        \n        // Check if this datanode should actually be shutdown instead. \n        if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n          setDatanodeDead(nodeinfo);\n          throw new DisallowedDatanodeException(nodeinfo);\n        }\n\n        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive()) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n\n        heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                         cacheCapacity, cacheUsed,\n                                         xceiverCount, failedVolumes,\n                                         volumeFailureSummary);\n\n        // If we are in safemode, do not send back any recovery / replication\n        // requests. Don\u0027t even drain the existing queue of work.\n        if(namesystem.isInSafeMode()) {\n          return new DatanodeCommand[0];\n        }\n\n        //check lease recovery\n        BlockInfo[] blocks \u003d nodeinfo.getLeaseRecoveryCommand(Integer.MAX_VALUE);\n        if (blocks !\u003d null) {\n          BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n              blocks.length);\n          for (BlockInfo b : blocks) {\n            BlockUnderConstructionFeature uc \u003d b.getUnderConstructionFeature();\n            assert uc !\u003d null;\n            final DatanodeStorageInfo[] storages \u003d uc.getExpectedStorageLocations();\n            // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n            final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                new ArrayList\u003c\u003e(storages.length);\n            for (DatanodeStorageInfo storage : storages) {\n              if (!storage.getDatanodeDescriptor().isStale(staleInterval)) {\n                recoveryLocations.add(storage);\n              }\n            }\n            // If we are performing a truncate recovery than set recovery fields\n            // to old block.\n            boolean truncateRecovery \u003d uc.getTruncateBlock() !\u003d null;\n            boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                uc.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n            ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                new ExtendedBlock(blockPoolId, uc.getTruncateBlock()) :\n                new ExtendedBlock(blockPoolId, b);\n            // If we only get 1 replica after eliminating stale nodes, then choose all\n            // replicas for recovery and let the primary data node handle failures.\n            DatanodeInfo[] recoveryInfos;\n            if (recoveryLocations.size() \u003e 1) {\n              if (recoveryLocations.size() !\u003d storages.length) {\n                LOG.info(\"Skipped stale nodes for recovery : \" +\n                    (storages.length - recoveryLocations.size()));\n              }\n              recoveryInfos \u003d\n                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n            } else {\n              // If too many replicas are stale, then choose all replicas to participate\n              // in block recovery.\n              recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n            }\n            RecoveringBlock rBlock;\n            if(truncateRecovery) {\n              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                  uc.getTruncateBlock();\n              rBlock \u003d new RecoveringBlock(primaryBlock, recoveryInfos,\n                  recoveryBlock);\n            } else {\n              rBlock \u003d new RecoveringBlock(primaryBlock, recoveryInfos,\n                  uc.getBlockRecoveryId());\n            }\n            brCommand.add(rBlock);\n          }\n          return new DatanodeCommand[] { brCommand };\n        }\n\n        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n        //check pending replication\n        List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n              maxTransfers);\n        if (pendingList !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n        // checking pending erasure coding tasks\n        List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d\n            nodeinfo.getErasureCodeCommand(maxTransfers);\n        if (pendingECList !\u003d null) {\n          cmds.add(new BlockECRecoveryCommand(DatanodeProtocol.DNA_ERASURE_CODING_RECOVERY,\n              pendingECList));\n        }\n        //check block invalidation\n        Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n        if (blks !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n              blockPoolId, blks));\n        }\n        boolean sendingCachingCommands \u003d false;\n        long nowMs \u003d monotonicNow();\n        if (shouldSendCachingCommands \u0026\u0026 \n            ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                timeBetweenResendingCachingDirectivesMs)) {\n          DatanodeCommand pendingCacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                DatanodeProtocol.DNA_CACHE, blockPoolId);\n          if (pendingCacheCommand !\u003d null) {\n            cmds.add(pendingCacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          DatanodeCommand pendingUncacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n          if (pendingUncacheCommand !\u003d null) {\n            cmds.add(pendingUncacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          if (sendingCachingCommands) {\n            nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n          }\n        }\n\n        blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n        // check for balancer bandwidth update\n        if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n          cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n          // set back to 0 to indicate that datanode has been sent the new value\n          nodeinfo.setBalancerBandwidth(0);\n        }\n\n        if (!cmds.isEmpty()) {\n          return cmds.toArray(new DatanodeCommand[cmds.size()]);\n        }\n      }\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "be7a0add8b6561d3c566237cc0370b06e7f32bb4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9223. Code cleanup for DatanodeDescriptor and HeartbeatManager. Contributed by Jing Zhao.\n",
      "commitDate": "14/10/15 4:17 PM",
      "commitName": "be7a0add8b6561d3c566237cc0370b06e7f32bb4",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "29/09/15 1:39 AM",
      "commitNameOld": "8fd55202468b28422b0df888641c9b08906fe4a7",
      "commitAuthorOld": "",
      "daysBetweenCommits": 15.61,
      "commitsBetweenForRepo": 116,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,150 +1,150 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary) throws IOException {\n     synchronized (heartbeatManager) {\n       synchronized (datanodeMap) {\n         DatanodeDescriptor nodeinfo;\n         try {\n           nodeinfo \u003d getDatanode(nodeReg);\n         } catch(UnregisteredNodeException e) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n         \n         // Check if this datanode should actually be shutdown instead. \n         if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n           setDatanodeDead(nodeinfo);\n           throw new DisallowedDatanodeException(nodeinfo);\n         }\n \n-        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n+        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive()) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n \n         heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                          cacheCapacity, cacheUsed,\n                                          xceiverCount, failedVolumes,\n                                          volumeFailureSummary);\n \n         // If we are in safemode, do not send back any recovery / replication\n         // requests. Don\u0027t even drain the existing queue of work.\n         if(namesystem.isInSafeMode()) {\n           return new DatanodeCommand[0];\n         }\n \n         //check lease recovery\n         BlockInfo[] blocks \u003d nodeinfo.getLeaseRecoveryCommand(Integer.MAX_VALUE);\n         if (blocks !\u003d null) {\n           BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n               blocks.length);\n           for (BlockInfo b : blocks) {\n             BlockUnderConstructionFeature uc \u003d b.getUnderConstructionFeature();\n             assert uc !\u003d null;\n             final DatanodeStorageInfo[] storages \u003d uc.getExpectedStorageLocations();\n             // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n             final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                 new ArrayList\u003c\u003e(storages.length);\n             for (DatanodeStorageInfo storage : storages) {\n               if (!storage.getDatanodeDescriptor().isStale(staleInterval)) {\n                 recoveryLocations.add(storage);\n               }\n             }\n             // If we are performing a truncate recovery than set recovery fields\n             // to old block.\n             boolean truncateRecovery \u003d uc.getTruncateBlock() !\u003d null;\n             boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                 uc.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n             ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                 new ExtendedBlock(blockPoolId, uc.getTruncateBlock()) :\n                 new ExtendedBlock(blockPoolId, b);\n             // If we only get 1 replica after eliminating stale nodes, then choose all\n             // replicas for recovery and let the primary data node handle failures.\n             DatanodeInfo[] recoveryInfos;\n             if (recoveryLocations.size() \u003e 1) {\n               if (recoveryLocations.size() !\u003d storages.length) {\n                 LOG.info(\"Skipped stale nodes for recovery : \" +\n                     (storages.length - recoveryLocations.size()));\n               }\n               recoveryInfos \u003d\n                   DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n             } else {\n               // If too many replicas are stale, then choose all replicas to participate\n               // in block recovery.\n               recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n             }\n             if(truncateRecovery) {\n               Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                   uc.getTruncateBlock();\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 recoveryBlock));\n             } else {\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 uc.getBlockRecoveryId()));\n             }\n           }\n           return new DatanodeCommand[] { brCommand };\n         }\n \n         final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n         //check pending replication\n         List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n               maxTransfers);\n         if (pendingList !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n               pendingList));\n         }\n         // checking pending erasure coding tasks\n         List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d\n             nodeinfo.getErasureCodeCommand(maxTransfers);\n         if (pendingECList !\u003d null) {\n           cmds.add(new BlockECRecoveryCommand(DatanodeProtocol.DNA_ERASURE_CODING_RECOVERY,\n               pendingECList));\n         }\n         //check block invalidation\n         Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n         if (blks !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n               blockPoolId, blks));\n         }\n         boolean sendingCachingCommands \u003d false;\n         long nowMs \u003d monotonicNow();\n         if (shouldSendCachingCommands \u0026\u0026 \n             ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                 timeBetweenResendingCachingDirectivesMs)) {\n           DatanodeCommand pendingCacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                 DatanodeProtocol.DNA_CACHE, blockPoolId);\n           if (pendingCacheCommand !\u003d null) {\n             cmds.add(pendingCacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           DatanodeCommand pendingUncacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                 DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n           if (pendingUncacheCommand !\u003d null) {\n             cmds.add(pendingUncacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           if (sendingCachingCommands) {\n             nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n           }\n         }\n \n         blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n         // check for balancer bandwidth update\n         if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n           cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n           // set back to 0 to indicate that datanode has been sent the new value\n           nodeinfo.setBalancerBandwidth(0);\n         }\n \n         if (!cmds.isEmpty()) {\n           return cmds.toArray(new DatanodeCommand[cmds.size()]);\n         }\n       }\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    synchronized (heartbeatManager) {\n      synchronized (datanodeMap) {\n        DatanodeDescriptor nodeinfo;\n        try {\n          nodeinfo \u003d getDatanode(nodeReg);\n        } catch(UnregisteredNodeException e) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n        \n        // Check if this datanode should actually be shutdown instead. \n        if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n          setDatanodeDead(nodeinfo);\n          throw new DisallowedDatanodeException(nodeinfo);\n        }\n\n        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive()) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n\n        heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                         cacheCapacity, cacheUsed,\n                                         xceiverCount, failedVolumes,\n                                         volumeFailureSummary);\n\n        // If we are in safemode, do not send back any recovery / replication\n        // requests. Don\u0027t even drain the existing queue of work.\n        if(namesystem.isInSafeMode()) {\n          return new DatanodeCommand[0];\n        }\n\n        //check lease recovery\n        BlockInfo[] blocks \u003d nodeinfo.getLeaseRecoveryCommand(Integer.MAX_VALUE);\n        if (blocks !\u003d null) {\n          BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n              blocks.length);\n          for (BlockInfo b : blocks) {\n            BlockUnderConstructionFeature uc \u003d b.getUnderConstructionFeature();\n            assert uc !\u003d null;\n            final DatanodeStorageInfo[] storages \u003d uc.getExpectedStorageLocations();\n            // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n            final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                new ArrayList\u003c\u003e(storages.length);\n            for (DatanodeStorageInfo storage : storages) {\n              if (!storage.getDatanodeDescriptor().isStale(staleInterval)) {\n                recoveryLocations.add(storage);\n              }\n            }\n            // If we are performing a truncate recovery than set recovery fields\n            // to old block.\n            boolean truncateRecovery \u003d uc.getTruncateBlock() !\u003d null;\n            boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                uc.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n            ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                new ExtendedBlock(blockPoolId, uc.getTruncateBlock()) :\n                new ExtendedBlock(blockPoolId, b);\n            // If we only get 1 replica after eliminating stale nodes, then choose all\n            // replicas for recovery and let the primary data node handle failures.\n            DatanodeInfo[] recoveryInfos;\n            if (recoveryLocations.size() \u003e 1) {\n              if (recoveryLocations.size() !\u003d storages.length) {\n                LOG.info(\"Skipped stale nodes for recovery : \" +\n                    (storages.length - recoveryLocations.size()));\n              }\n              recoveryInfos \u003d\n                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n            } else {\n              // If too many replicas are stale, then choose all replicas to participate\n              // in block recovery.\n              recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n            }\n            if(truncateRecovery) {\n              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                  uc.getTruncateBlock();\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                recoveryBlock));\n            } else {\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                uc.getBlockRecoveryId()));\n            }\n          }\n          return new DatanodeCommand[] { brCommand };\n        }\n\n        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n        //check pending replication\n        List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n              maxTransfers);\n        if (pendingList !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n        // checking pending erasure coding tasks\n        List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d\n            nodeinfo.getErasureCodeCommand(maxTransfers);\n        if (pendingECList !\u003d null) {\n          cmds.add(new BlockECRecoveryCommand(DatanodeProtocol.DNA_ERASURE_CODING_RECOVERY,\n              pendingECList));\n        }\n        //check block invalidation\n        Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n        if (blks !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n              blockPoolId, blks));\n        }\n        boolean sendingCachingCommands \u003d false;\n        long nowMs \u003d monotonicNow();\n        if (shouldSendCachingCommands \u0026\u0026 \n            ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                timeBetweenResendingCachingDirectivesMs)) {\n          DatanodeCommand pendingCacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                DatanodeProtocol.DNA_CACHE, blockPoolId);\n          if (pendingCacheCommand !\u003d null) {\n            cmds.add(pendingCacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          DatanodeCommand pendingUncacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n          if (pendingUncacheCommand !\u003d null) {\n            cmds.add(pendingUncacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          if (sendingCachingCommands) {\n            nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n          }\n        }\n\n        blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n        // check for balancer bandwidth update\n        if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n          cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n          // set back to 0 to indicate that datanode has been sent the new value\n          nodeinfo.setBalancerBandwidth(0);\n        }\n\n        if (!cmds.isEmpty()) {\n          return cmds.toArray(new DatanodeCommand[cmds.size()]);\n        }\n      }\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "164cbe643988f878f0f4100a4de51783e5b6738e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8909. Erasure coding: update BlockInfoContiguousUC and BlockInfoStripedUC to use BlockUnderConstructionFeature. Contributed by Jing Zhao.\n",
      "commitDate": "27/08/15 1:02 AM",
      "commitName": "164cbe643988f878f0f4100a4de51783e5b6738e",
      "commitAuthor": "Walter Su",
      "commitDateOld": "24/08/15 12:59 PM",
      "commitNameOld": "6b6a63bbbda920315d3d24b61ed3344a78a981b6",
      "commitAuthorOld": "",
      "daysBetweenCommits": 2.5,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,149 +1,151 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary) throws IOException {\n     synchronized (heartbeatManager) {\n       synchronized (datanodeMap) {\n         DatanodeDescriptor nodeinfo;\n         try {\n           nodeinfo \u003d getDatanode(nodeReg);\n         } catch(UnregisteredNodeException e) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n         \n         // Check if this datanode should actually be shutdown instead. \n         if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n           setDatanodeDead(nodeinfo);\n           throw new DisallowedDatanodeException(nodeinfo);\n         }\n \n         if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n \n         heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                          cacheCapacity, cacheUsed,\n                                          xceiverCount, failedVolumes,\n                                          volumeFailureSummary);\n \n         // If we are in safemode, do not send back any recovery / replication\n         // requests. Don\u0027t even drain the existing queue of work.\n         if(namesystem.isInSafeMode()) {\n           return new DatanodeCommand[0];\n         }\n \n         //check lease recovery\n-        BlockInfoUnderConstruction[] blocks \u003d nodeinfo\n-            .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n+        BlockInfo[] blocks \u003d nodeinfo.getLeaseRecoveryCommand(Integer.MAX_VALUE);\n         if (blocks !\u003d null) {\n           BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n               blocks.length);\n-          for (BlockInfoUnderConstruction b : blocks) {\n-            final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n+          for (BlockInfo b : blocks) {\n+            final BlockUnderConstructionFeature uc \u003d\n+                b.getUnderConstructionFeature();\n+            assert uc !\u003d null;\n+            final DatanodeStorageInfo[] storages \u003d uc.getExpectedStorageLocations();\n             // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n             final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                 new ArrayList\u003c\u003e(storages.length);\n             for (DatanodeStorageInfo storage : storages) {\n               if (!storage.getDatanodeDescriptor().isStale(staleInterval)) {\n                 recoveryLocations.add(storage);\n               }\n             }\n             // If we are performing a truncate recovery than set recovery fields\n             // to old block.\n-            boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n+            boolean truncateRecovery \u003d uc.getTruncateBlock() !\u003d null;\n             boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n-                b.getTruncateBlock().getBlockId() !\u003d b.toBlock().getBlockId();\n+                uc.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n             ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n-                new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n-                new ExtendedBlock(blockPoolId, b.toBlock());\n+                new ExtendedBlock(blockPoolId, uc.getTruncateBlock()) :\n+                new ExtendedBlock(blockPoolId, b);\n             // If we only get 1 replica after eliminating stale nodes, then choose all\n             // replicas for recovery and let the primary data node handle failures.\n             DatanodeInfo[] recoveryInfos;\n             if (recoveryLocations.size() \u003e 1) {\n               if (recoveryLocations.size() !\u003d storages.length) {\n                 LOG.info(\"Skipped stale nodes for recovery : \" +\n                     (storages.length - recoveryLocations.size()));\n               }\n               recoveryInfos \u003d\n                   DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n             } else {\n               // If too many replicas are stale, then choose all replicas to participate\n               // in block recovery.\n               recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n             }\n             if(truncateRecovery) {\n-              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b.toBlock() :\n-                  b.getTruncateBlock();\n+              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n+                  uc.getTruncateBlock();\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 recoveryBlock));\n             } else {\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n-                                                b.getBlockRecoveryId()));\n+                                                uc.getBlockRecoveryId()));\n             }\n           }\n           return new DatanodeCommand[] { brCommand };\n         }\n \n         final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n         //check pending replication\n         List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n               maxTransfers);\n         if (pendingList !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n               pendingList));\n         }\n         // checking pending erasure coding tasks\n         List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d\n             nodeinfo.getErasureCodeCommand(maxTransfers);\n         if (pendingECList !\u003d null) {\n           cmds.add(new BlockECRecoveryCommand(DatanodeProtocol.DNA_ERASURE_CODING_RECOVERY,\n               pendingECList));\n         }\n         //check block invalidation\n         Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n         if (blks !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n               blockPoolId, blks));\n         }\n         boolean sendingCachingCommands \u003d false;\n         long nowMs \u003d monotonicNow();\n         if (shouldSendCachingCommands \u0026\u0026 \n             ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                 timeBetweenResendingCachingDirectivesMs)) {\n           DatanodeCommand pendingCacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                 DatanodeProtocol.DNA_CACHE, blockPoolId);\n           if (pendingCacheCommand !\u003d null) {\n             cmds.add(pendingCacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           DatanodeCommand pendingUncacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                 DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n           if (pendingUncacheCommand !\u003d null) {\n             cmds.add(pendingUncacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           if (sendingCachingCommands) {\n             nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n           }\n         }\n \n         blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n         // check for balancer bandwidth update\n         if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n           cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n           // set back to 0 to indicate that datanode has been sent the new value\n           nodeinfo.setBalancerBandwidth(0);\n         }\n \n         if (!cmds.isEmpty()) {\n           return cmds.toArray(new DatanodeCommand[cmds.size()]);\n         }\n       }\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    synchronized (heartbeatManager) {\n      synchronized (datanodeMap) {\n        DatanodeDescriptor nodeinfo;\n        try {\n          nodeinfo \u003d getDatanode(nodeReg);\n        } catch(UnregisteredNodeException e) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n        \n        // Check if this datanode should actually be shutdown instead. \n        if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n          setDatanodeDead(nodeinfo);\n          throw new DisallowedDatanodeException(nodeinfo);\n        }\n\n        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n\n        heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                         cacheCapacity, cacheUsed,\n                                         xceiverCount, failedVolumes,\n                                         volumeFailureSummary);\n\n        // If we are in safemode, do not send back any recovery / replication\n        // requests. Don\u0027t even drain the existing queue of work.\n        if(namesystem.isInSafeMode()) {\n          return new DatanodeCommand[0];\n        }\n\n        //check lease recovery\n        BlockInfo[] blocks \u003d nodeinfo.getLeaseRecoveryCommand(Integer.MAX_VALUE);\n        if (blocks !\u003d null) {\n          BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n              blocks.length);\n          for (BlockInfo b : blocks) {\n            final BlockUnderConstructionFeature uc \u003d\n                b.getUnderConstructionFeature();\n            assert uc !\u003d null;\n            final DatanodeStorageInfo[] storages \u003d uc.getExpectedStorageLocations();\n            // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n            final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                new ArrayList\u003c\u003e(storages.length);\n            for (DatanodeStorageInfo storage : storages) {\n              if (!storage.getDatanodeDescriptor().isStale(staleInterval)) {\n                recoveryLocations.add(storage);\n              }\n            }\n            // If we are performing a truncate recovery than set recovery fields\n            // to old block.\n            boolean truncateRecovery \u003d uc.getTruncateBlock() !\u003d null;\n            boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                uc.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n            ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                new ExtendedBlock(blockPoolId, uc.getTruncateBlock()) :\n                new ExtendedBlock(blockPoolId, b);\n            // If we only get 1 replica after eliminating stale nodes, then choose all\n            // replicas for recovery and let the primary data node handle failures.\n            DatanodeInfo[] recoveryInfos;\n            if (recoveryLocations.size() \u003e 1) {\n              if (recoveryLocations.size() !\u003d storages.length) {\n                LOG.info(\"Skipped stale nodes for recovery : \" +\n                    (storages.length - recoveryLocations.size()));\n              }\n              recoveryInfos \u003d\n                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n            } else {\n              // If too many replicas are stale, then choose all replicas to participate\n              // in block recovery.\n              recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n            }\n            if(truncateRecovery) {\n              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                  uc.getTruncateBlock();\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                recoveryBlock));\n            } else {\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                uc.getBlockRecoveryId()));\n            }\n          }\n          return new DatanodeCommand[] { brCommand };\n        }\n\n        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n        //check pending replication\n        List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n              maxTransfers);\n        if (pendingList !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n        // checking pending erasure coding tasks\n        List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d\n            nodeinfo.getErasureCodeCommand(maxTransfers);\n        if (pendingECList !\u003d null) {\n          cmds.add(new BlockECRecoveryCommand(DatanodeProtocol.DNA_ERASURE_CODING_RECOVERY,\n              pendingECList));\n        }\n        //check block invalidation\n        Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n        if (blks !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n              blockPoolId, blks));\n        }\n        boolean sendingCachingCommands \u003d false;\n        long nowMs \u003d monotonicNow();\n        if (shouldSendCachingCommands \u0026\u0026 \n            ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                timeBetweenResendingCachingDirectivesMs)) {\n          DatanodeCommand pendingCacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                DatanodeProtocol.DNA_CACHE, blockPoolId);\n          if (pendingCacheCommand !\u003d null) {\n            cmds.add(pendingCacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          DatanodeCommand pendingUncacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n          if (pendingUncacheCommand !\u003d null) {\n            cmds.add(pendingUncacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          if (sendingCachingCommands) {\n            nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n          }\n        }\n\n        blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n        // check for balancer bandwidth update\n        if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n          cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n          // set back to 0 to indicate that datanode has been sent the new value\n          nodeinfo.setBalancerBandwidth(0);\n        }\n\n        if (!cmds.isEmpty()) {\n          return cmds.toArray(new DatanodeCommand[cmds.size()]);\n        }\n      }\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "e535e0f05b5fbd087c93238deb888cc985254b4c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8801. Convert BlockInfoUnderConstruction as a feature. Contributed by Jing Zhao.\n",
      "commitDate": "17/08/15 11:28 AM",
      "commitName": "e535e0f05b5fbd087c93238deb888cc985254b4c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "06/08/15 10:21 AM",
      "commitNameOld": "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 11.05,
      "commitsBetweenForRepo": 46,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,142 +1,143 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary) throws IOException {\n     synchronized (heartbeatManager) {\n       synchronized (datanodeMap) {\n         DatanodeDescriptor nodeinfo;\n         try {\n           nodeinfo \u003d getDatanode(nodeReg);\n         } catch(UnregisteredNodeException e) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n         \n         // Check if this datanode should actually be shutdown instead. \n         if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n           setDatanodeDead(nodeinfo);\n           throw new DisallowedDatanodeException(nodeinfo);\n         }\n \n         if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n \n         heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                          cacheCapacity, cacheUsed,\n                                          xceiverCount, failedVolumes,\n                                          volumeFailureSummary);\n \n         // If we are in safemode, do not send back any recovery / replication\n         // requests. Don\u0027t even drain the existing queue of work.\n         if(namesystem.isInSafeMode()) {\n           return new DatanodeCommand[0];\n         }\n \n         //check lease recovery\n-        BlockInfoContiguousUnderConstruction[] blocks \u003d nodeinfo\n-            .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n+        BlockInfo[] blocks \u003d nodeinfo.getLeaseRecoveryCommand(Integer.MAX_VALUE);\n         if (blocks !\u003d null) {\n           BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n               blocks.length);\n-          for (BlockInfoContiguousUnderConstruction b : blocks) {\n-            final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n+          for (BlockInfo b : blocks) {\n+            BlockUnderConstructionFeature uc \u003d b.getUnderConstructionFeature();\n+            assert uc !\u003d null;\n+            final DatanodeStorageInfo[] storages \u003d uc.getExpectedStorageLocations();\n             // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n             final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                 new ArrayList\u003c\u003e(storages.length);\n             for (int i \u003d 0; i \u003c storages.length; i++) {\n               if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                 recoveryLocations.add(storages[i]);\n               }\n             }\n             // If we are performing a truncate recovery than set recovery fields\n             // to old block.\n-            boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n+            boolean truncateRecovery \u003d uc.getTruncateBlock() !\u003d null;\n             boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n-                b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n+                uc.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n             ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n-                new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n+                new ExtendedBlock(blockPoolId, uc.getTruncateBlock()) :\n                 new ExtendedBlock(blockPoolId, b);\n             // If we only get 1 replica after eliminating stale nodes, then choose all\n             // replicas for recovery and let the primary data node handle failures.\n             DatanodeInfo[] recoveryInfos;\n             if (recoveryLocations.size() \u003e 1) {\n               if (recoveryLocations.size() !\u003d storages.length) {\n                 LOG.info(\"Skipped stale nodes for recovery : \" +\n                     (storages.length - recoveryLocations.size()));\n               }\n               recoveryInfos \u003d\n                   DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n             } else {\n               // If too many replicas are stale, then choose all replicas to participate\n               // in block recovery.\n               recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n             }\n             if(truncateRecovery) {\n               Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n-                  b.getTruncateBlock();\n+                  uc.getTruncateBlock();\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 recoveryBlock));\n             } else {\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n-                                                b.getBlockRecoveryId()));\n+                                                uc.getBlockRecoveryId()));\n             }\n           }\n           return new DatanodeCommand[] { brCommand };\n         }\n \n         final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n         //check pending replication\n         List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n               maxTransfers);\n         if (pendingList !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n               pendingList));\n         }\n         //check block invalidation\n         Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n         if (blks !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n               blockPoolId, blks));\n         }\n         boolean sendingCachingCommands \u003d false;\n         long nowMs \u003d monotonicNow();\n         if (shouldSendCachingCommands \u0026\u0026 \n             ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                 timeBetweenResendingCachingDirectivesMs)) {\n           DatanodeCommand pendingCacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                 DatanodeProtocol.DNA_CACHE, blockPoolId);\n           if (pendingCacheCommand !\u003d null) {\n             cmds.add(pendingCacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           DatanodeCommand pendingUncacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                 DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n           if (pendingUncacheCommand !\u003d null) {\n             cmds.add(pendingUncacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           if (sendingCachingCommands) {\n             nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n           }\n         }\n \n         blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n         // check for balancer bandwidth update\n         if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n           cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n           // set back to 0 to indicate that datanode has been sent the new value\n           nodeinfo.setBalancerBandwidth(0);\n         }\n \n         if (!cmds.isEmpty()) {\n           return cmds.toArray(new DatanodeCommand[cmds.size()]);\n         }\n       }\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    synchronized (heartbeatManager) {\n      synchronized (datanodeMap) {\n        DatanodeDescriptor nodeinfo;\n        try {\n          nodeinfo \u003d getDatanode(nodeReg);\n        } catch(UnregisteredNodeException e) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n        \n        // Check if this datanode should actually be shutdown instead. \n        if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n          setDatanodeDead(nodeinfo);\n          throw new DisallowedDatanodeException(nodeinfo);\n        }\n\n        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n\n        heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                         cacheCapacity, cacheUsed,\n                                         xceiverCount, failedVolumes,\n                                         volumeFailureSummary);\n\n        // If we are in safemode, do not send back any recovery / replication\n        // requests. Don\u0027t even drain the existing queue of work.\n        if(namesystem.isInSafeMode()) {\n          return new DatanodeCommand[0];\n        }\n\n        //check lease recovery\n        BlockInfo[] blocks \u003d nodeinfo.getLeaseRecoveryCommand(Integer.MAX_VALUE);\n        if (blocks !\u003d null) {\n          BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n              blocks.length);\n          for (BlockInfo b : blocks) {\n            BlockUnderConstructionFeature uc \u003d b.getUnderConstructionFeature();\n            assert uc !\u003d null;\n            final DatanodeStorageInfo[] storages \u003d uc.getExpectedStorageLocations();\n            // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n            final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                new ArrayList\u003c\u003e(storages.length);\n            for (int i \u003d 0; i \u003c storages.length; i++) {\n              if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                recoveryLocations.add(storages[i]);\n              }\n            }\n            // If we are performing a truncate recovery than set recovery fields\n            // to old block.\n            boolean truncateRecovery \u003d uc.getTruncateBlock() !\u003d null;\n            boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                uc.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n            ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                new ExtendedBlock(blockPoolId, uc.getTruncateBlock()) :\n                new ExtendedBlock(blockPoolId, b);\n            // If we only get 1 replica after eliminating stale nodes, then choose all\n            // replicas for recovery and let the primary data node handle failures.\n            DatanodeInfo[] recoveryInfos;\n            if (recoveryLocations.size() \u003e 1) {\n              if (recoveryLocations.size() !\u003d storages.length) {\n                LOG.info(\"Skipped stale nodes for recovery : \" +\n                    (storages.length - recoveryLocations.size()));\n              }\n              recoveryInfos \u003d\n                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n            } else {\n              // If too many replicas are stale, then choose all replicas to participate\n              // in block recovery.\n              recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n            }\n            if(truncateRecovery) {\n              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                  uc.getTruncateBlock();\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                recoveryBlock));\n            } else {\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                uc.getBlockRecoveryId()));\n            }\n          }\n          return new DatanodeCommand[] { brCommand };\n        }\n\n        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n        //check pending replication\n        List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n              maxTransfers);\n        if (pendingList !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n        //check block invalidation\n        Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n        if (blks !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n              blockPoolId, blks));\n        }\n        boolean sendingCachingCommands \u003d false;\n        long nowMs \u003d monotonicNow();\n        if (shouldSendCachingCommands \u0026\u0026 \n            ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                timeBetweenResendingCachingDirectivesMs)) {\n          DatanodeCommand pendingCacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                DatanodeProtocol.DNA_CACHE, blockPoolId);\n          if (pendingCacheCommand !\u003d null) {\n            cmds.add(pendingCacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          DatanodeCommand pendingUncacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n          if (pendingUncacheCommand !\u003d null) {\n            cmds.add(pendingUncacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          if (sendingCachingCommands) {\n            nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n          }\n        }\n\n        blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n        // check for balancer bandwidth update\n        if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n          cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n          // set back to 0 to indicate that datanode has been sent the new value\n          nodeinfo.setBalancerBandwidth(0);\n        }\n\n        if (!cmds.isEmpty()) {\n          return cmds.toArray(new DatanodeCommand[cmds.size()]);\n        }\n      }\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang.\"\n\nThis reverts commit c17439c2ddd921b63b1635e6f1cba634b8da8557.\n",
      "commitDate": "06/08/15 10:21 AM",
      "commitName": "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "29/06/15 12:12 PM",
      "commitNameOld": "2ffd84273ac490724fe7e7825664bb6d09ef0e99",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 37.92,
      "commitsBetweenForRepo": 237,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,142 +1,142 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary) throws IOException {\n     synchronized (heartbeatManager) {\n       synchronized (datanodeMap) {\n         DatanodeDescriptor nodeinfo;\n         try {\n           nodeinfo \u003d getDatanode(nodeReg);\n         } catch(UnregisteredNodeException e) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n         \n         // Check if this datanode should actually be shutdown instead. \n         if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n           setDatanodeDead(nodeinfo);\n           throw new DisallowedDatanodeException(nodeinfo);\n         }\n \n         if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n \n         heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                          cacheCapacity, cacheUsed,\n                                          xceiverCount, failedVolumes,\n                                          volumeFailureSummary);\n \n         // If we are in safemode, do not send back any recovery / replication\n         // requests. Don\u0027t even drain the existing queue of work.\n         if(namesystem.isInSafeMode()) {\n           return new DatanodeCommand[0];\n         }\n \n         //check lease recovery\n-        BlockInfoUnderConstruction[] blocks \u003d nodeinfo\n+        BlockInfoContiguousUnderConstruction[] blocks \u003d nodeinfo\n             .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n         if (blocks !\u003d null) {\n           BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n               blocks.length);\n-          for (BlockInfoUnderConstruction b : blocks) {\n+          for (BlockInfoContiguousUnderConstruction b : blocks) {\n             final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n             // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n             final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                 new ArrayList\u003c\u003e(storages.length);\n             for (int i \u003d 0; i \u003c storages.length; i++) {\n               if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                 recoveryLocations.add(storages[i]);\n               }\n             }\n             // If we are performing a truncate recovery than set recovery fields\n             // to old block.\n             boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n             boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                 b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n             ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                 new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                 new ExtendedBlock(blockPoolId, b);\n             // If we only get 1 replica after eliminating stale nodes, then choose all\n             // replicas for recovery and let the primary data node handle failures.\n             DatanodeInfo[] recoveryInfos;\n             if (recoveryLocations.size() \u003e 1) {\n               if (recoveryLocations.size() !\u003d storages.length) {\n                 LOG.info(\"Skipped stale nodes for recovery : \" +\n                     (storages.length - recoveryLocations.size()));\n               }\n               recoveryInfos \u003d\n                   DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n             } else {\n               // If too many replicas are stale, then choose all replicas to participate\n               // in block recovery.\n               recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n             }\n             if(truncateRecovery) {\n               Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                   b.getTruncateBlock();\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 recoveryBlock));\n             } else {\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 b.getBlockRecoveryId()));\n             }\n           }\n           return new DatanodeCommand[] { brCommand };\n         }\n \n         final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n         //check pending replication\n         List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n               maxTransfers);\n         if (pendingList !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n               pendingList));\n         }\n         //check block invalidation\n         Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n         if (blks !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n               blockPoolId, blks));\n         }\n         boolean sendingCachingCommands \u003d false;\n         long nowMs \u003d monotonicNow();\n         if (shouldSendCachingCommands \u0026\u0026 \n             ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                 timeBetweenResendingCachingDirectivesMs)) {\n           DatanodeCommand pendingCacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                 DatanodeProtocol.DNA_CACHE, blockPoolId);\n           if (pendingCacheCommand !\u003d null) {\n             cmds.add(pendingCacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           DatanodeCommand pendingUncacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                 DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n           if (pendingUncacheCommand !\u003d null) {\n             cmds.add(pendingUncacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           if (sendingCachingCommands) {\n             nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n           }\n         }\n \n         blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n         // check for balancer bandwidth update\n         if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n           cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n           // set back to 0 to indicate that datanode has been sent the new value\n           nodeinfo.setBalancerBandwidth(0);\n         }\n \n         if (!cmds.isEmpty()) {\n           return cmds.toArray(new DatanodeCommand[cmds.size()]);\n         }\n       }\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    synchronized (heartbeatManager) {\n      synchronized (datanodeMap) {\n        DatanodeDescriptor nodeinfo;\n        try {\n          nodeinfo \u003d getDatanode(nodeReg);\n        } catch(UnregisteredNodeException e) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n        \n        // Check if this datanode should actually be shutdown instead. \n        if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n          setDatanodeDead(nodeinfo);\n          throw new DisallowedDatanodeException(nodeinfo);\n        }\n\n        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n\n        heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                         cacheCapacity, cacheUsed,\n                                         xceiverCount, failedVolumes,\n                                         volumeFailureSummary);\n\n        // If we are in safemode, do not send back any recovery / replication\n        // requests. Don\u0027t even drain the existing queue of work.\n        if(namesystem.isInSafeMode()) {\n          return new DatanodeCommand[0];\n        }\n\n        //check lease recovery\n        BlockInfoContiguousUnderConstruction[] blocks \u003d nodeinfo\n            .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n        if (blocks !\u003d null) {\n          BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n              blocks.length);\n          for (BlockInfoContiguousUnderConstruction b : blocks) {\n            final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n            // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n            final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                new ArrayList\u003c\u003e(storages.length);\n            for (int i \u003d 0; i \u003c storages.length; i++) {\n              if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                recoveryLocations.add(storages[i]);\n              }\n            }\n            // If we are performing a truncate recovery than set recovery fields\n            // to old block.\n            boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n            boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n            ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                new ExtendedBlock(blockPoolId, b);\n            // If we only get 1 replica after eliminating stale nodes, then choose all\n            // replicas for recovery and let the primary data node handle failures.\n            DatanodeInfo[] recoveryInfos;\n            if (recoveryLocations.size() \u003e 1) {\n              if (recoveryLocations.size() !\u003d storages.length) {\n                LOG.info(\"Skipped stale nodes for recovery : \" +\n                    (storages.length - recoveryLocations.size()));\n              }\n              recoveryInfos \u003d\n                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n            } else {\n              // If too many replicas are stale, then choose all replicas to participate\n              // in block recovery.\n              recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n            }\n            if(truncateRecovery) {\n              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                  b.getTruncateBlock();\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                recoveryBlock));\n            } else {\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                b.getBlockRecoveryId()));\n            }\n          }\n          return new DatanodeCommand[] { brCommand };\n        }\n\n        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n        //check pending replication\n        List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n              maxTransfers);\n        if (pendingList !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n        //check block invalidation\n        Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n        if (blks !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n              blockPoolId, blks));\n        }\n        boolean sendingCachingCommands \u003d false;\n        long nowMs \u003d monotonicNow();\n        if (shouldSendCachingCommands \u0026\u0026 \n            ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                timeBetweenResendingCachingDirectivesMs)) {\n          DatanodeCommand pendingCacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                DatanodeProtocol.DNA_CACHE, blockPoolId);\n          if (pendingCacheCommand !\u003d null) {\n            cmds.add(pendingCacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          DatanodeCommand pendingUncacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n          if (pendingUncacheCommand !\u003d null) {\n            cmds.add(pendingUncacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          if (sendingCachingCommands) {\n            nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n          }\n        }\n\n        blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n        // check for balancer bandwidth update\n        if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n          cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n          // set back to 0 to indicate that datanode has been sent the new value\n          nodeinfo.setBalancerBandwidth(0);\n        }\n\n        if (!cmds.isEmpty()) {\n          return cmds.toArray(new DatanodeCommand[cmds.size()]);\n        }\n      }\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "2ffd84273ac490724fe7e7825664bb6d09ef0e99": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8653. Code cleanup for DatanodeManager, DatanodeDescriptor and DatanodeStorageInfo. Contributed by Zhe Zhang.\n",
      "commitDate": "29/06/15 12:12 PM",
      "commitName": "2ffd84273ac490724fe7e7825664bb6d09ef0e99",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "12/06/15 11:38 AM",
      "commitNameOld": "c17439c2ddd921b63b1635e6f1cba634b8da8557",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 17.02,
      "commitsBetweenForRepo": 104,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,142 +1,142 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary) throws IOException {\n     synchronized (heartbeatManager) {\n       synchronized (datanodeMap) {\n-        DatanodeDescriptor nodeinfo \u003d null;\n+        DatanodeDescriptor nodeinfo;\n         try {\n           nodeinfo \u003d getDatanode(nodeReg);\n         } catch(UnregisteredNodeException e) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n         \n         // Check if this datanode should actually be shutdown instead. \n         if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n           setDatanodeDead(nodeinfo);\n           throw new DisallowedDatanodeException(nodeinfo);\n         }\n \n         if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n \n         heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                          cacheCapacity, cacheUsed,\n                                          xceiverCount, failedVolumes,\n                                          volumeFailureSummary);\n \n         // If we are in safemode, do not send back any recovery / replication\n         // requests. Don\u0027t even drain the existing queue of work.\n         if(namesystem.isInSafeMode()) {\n           return new DatanodeCommand[0];\n         }\n \n         //check lease recovery\n         BlockInfoUnderConstruction[] blocks \u003d nodeinfo\n             .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n         if (blocks !\u003d null) {\n           BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n               blocks.length);\n           for (BlockInfoUnderConstruction b : blocks) {\n             final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n             // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n             final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n-                new ArrayList\u003cDatanodeStorageInfo\u003e(storages.length);\n+                new ArrayList\u003c\u003e(storages.length);\n             for (int i \u003d 0; i \u003c storages.length; i++) {\n               if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                 recoveryLocations.add(storages[i]);\n               }\n             }\n             // If we are performing a truncate recovery than set recovery fields\n             // to old block.\n             boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n             boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                 b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n             ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                 new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                 new ExtendedBlock(blockPoolId, b);\n             // If we only get 1 replica after eliminating stale nodes, then choose all\n             // replicas for recovery and let the primary data node handle failures.\n             DatanodeInfo[] recoveryInfos;\n             if (recoveryLocations.size() \u003e 1) {\n               if (recoveryLocations.size() !\u003d storages.length) {\n                 LOG.info(\"Skipped stale nodes for recovery : \" +\n                     (storages.length - recoveryLocations.size()));\n               }\n               recoveryInfos \u003d\n                   DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n             } else {\n               // If too many replicas are stale, then choose all replicas to participate\n               // in block recovery.\n               recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n             }\n             if(truncateRecovery) {\n               Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                   b.getTruncateBlock();\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 recoveryBlock));\n             } else {\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 b.getBlockRecoveryId()));\n             }\n           }\n           return new DatanodeCommand[] { brCommand };\n         }\n \n-        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003cDatanodeCommand\u003e();\n+        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n         //check pending replication\n         List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n               maxTransfers);\n         if (pendingList !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n               pendingList));\n         }\n         //check block invalidation\n         Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n         if (blks !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n               blockPoolId, blks));\n         }\n         boolean sendingCachingCommands \u003d false;\n         long nowMs \u003d monotonicNow();\n         if (shouldSendCachingCommands \u0026\u0026 \n             ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                 timeBetweenResendingCachingDirectivesMs)) {\n           DatanodeCommand pendingCacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                 DatanodeProtocol.DNA_CACHE, blockPoolId);\n           if (pendingCacheCommand !\u003d null) {\n             cmds.add(pendingCacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           DatanodeCommand pendingUncacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                 DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n           if (pendingUncacheCommand !\u003d null) {\n             cmds.add(pendingUncacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           if (sendingCachingCommands) {\n             nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n           }\n         }\n \n         blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n         // check for balancer bandwidth update\n         if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n           cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n           // set back to 0 to indicate that datanode has been sent the new value\n           nodeinfo.setBalancerBandwidth(0);\n         }\n \n         if (!cmds.isEmpty()) {\n           return cmds.toArray(new DatanodeCommand[cmds.size()]);\n         }\n       }\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    synchronized (heartbeatManager) {\n      synchronized (datanodeMap) {\n        DatanodeDescriptor nodeinfo;\n        try {\n          nodeinfo \u003d getDatanode(nodeReg);\n        } catch(UnregisteredNodeException e) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n        \n        // Check if this datanode should actually be shutdown instead. \n        if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n          setDatanodeDead(nodeinfo);\n          throw new DisallowedDatanodeException(nodeinfo);\n        }\n\n        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n\n        heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                         cacheCapacity, cacheUsed,\n                                         xceiverCount, failedVolumes,\n                                         volumeFailureSummary);\n\n        // If we are in safemode, do not send back any recovery / replication\n        // requests. Don\u0027t even drain the existing queue of work.\n        if(namesystem.isInSafeMode()) {\n          return new DatanodeCommand[0];\n        }\n\n        //check lease recovery\n        BlockInfoUnderConstruction[] blocks \u003d nodeinfo\n            .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n        if (blocks !\u003d null) {\n          BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n              blocks.length);\n          for (BlockInfoUnderConstruction b : blocks) {\n            final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n            // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n            final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                new ArrayList\u003c\u003e(storages.length);\n            for (int i \u003d 0; i \u003c storages.length; i++) {\n              if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                recoveryLocations.add(storages[i]);\n              }\n            }\n            // If we are performing a truncate recovery than set recovery fields\n            // to old block.\n            boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n            boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n            ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                new ExtendedBlock(blockPoolId, b);\n            // If we only get 1 replica after eliminating stale nodes, then choose all\n            // replicas for recovery and let the primary data node handle failures.\n            DatanodeInfo[] recoveryInfos;\n            if (recoveryLocations.size() \u003e 1) {\n              if (recoveryLocations.size() !\u003d storages.length) {\n                LOG.info(\"Skipped stale nodes for recovery : \" +\n                    (storages.length - recoveryLocations.size()));\n              }\n              recoveryInfos \u003d\n                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n            } else {\n              // If too many replicas are stale, then choose all replicas to participate\n              // in block recovery.\n              recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n            }\n            if(truncateRecovery) {\n              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                  b.getTruncateBlock();\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                recoveryBlock));\n            } else {\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                b.getBlockRecoveryId()));\n            }\n          }\n          return new DatanodeCommand[] { brCommand };\n        }\n\n        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n        //check pending replication\n        List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n              maxTransfers);\n        if (pendingList !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n        //check block invalidation\n        Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n        if (blks !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n              blockPoolId, blks));\n        }\n        boolean sendingCachingCommands \u003d false;\n        long nowMs \u003d monotonicNow();\n        if (shouldSendCachingCommands \u0026\u0026 \n            ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                timeBetweenResendingCachingDirectivesMs)) {\n          DatanodeCommand pendingCacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                DatanodeProtocol.DNA_CACHE, blockPoolId);\n          if (pendingCacheCommand !\u003d null) {\n            cmds.add(pendingCacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          DatanodeCommand pendingUncacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n          if (pendingUncacheCommand !\u003d null) {\n            cmds.add(pendingUncacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          if (sendingCachingCommands) {\n            nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n          }\n        }\n\n        blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n        // check for balancer bandwidth update\n        if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n          cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n          // set back to 0 to indicate that datanode has been sent the new value\n          nodeinfo.setBalancerBandwidth(0);\n        }\n\n        if (!cmds.isEmpty()) {\n          return cmds.toArray(new DatanodeCommand[cmds.size()]);\n        }\n      }\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "c17439c2ddd921b63b1635e6f1cba634b8da8557": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang.\n",
      "commitDate": "12/06/15 11:38 AM",
      "commitName": "c17439c2ddd921b63b1635e6f1cba634b8da8557",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "12/06/15 11:17 AM",
      "commitNameOld": "12b5b06c063d93e6c683c9b6fac9a96912f59e59",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,142 +1,142 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary) throws IOException {\n     synchronized (heartbeatManager) {\n       synchronized (datanodeMap) {\n         DatanodeDescriptor nodeinfo \u003d null;\n         try {\n           nodeinfo \u003d getDatanode(nodeReg);\n         } catch(UnregisteredNodeException e) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n         \n         // Check if this datanode should actually be shutdown instead. \n         if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n           setDatanodeDead(nodeinfo);\n           throw new DisallowedDatanodeException(nodeinfo);\n         }\n \n         if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n \n         heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                          cacheCapacity, cacheUsed,\n                                          xceiverCount, failedVolumes,\n                                          volumeFailureSummary);\n \n         // If we are in safemode, do not send back any recovery / replication\n         // requests. Don\u0027t even drain the existing queue of work.\n         if(namesystem.isInSafeMode()) {\n           return new DatanodeCommand[0];\n         }\n \n         //check lease recovery\n-        BlockInfoContiguousUnderConstruction[] blocks \u003d nodeinfo\n+        BlockInfoUnderConstruction[] blocks \u003d nodeinfo\n             .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n         if (blocks !\u003d null) {\n           BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n               blocks.length);\n-          for (BlockInfoContiguousUnderConstruction b : blocks) {\n+          for (BlockInfoUnderConstruction b : blocks) {\n             final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n             // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n             final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                 new ArrayList\u003cDatanodeStorageInfo\u003e(storages.length);\n             for (int i \u003d 0; i \u003c storages.length; i++) {\n               if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                 recoveryLocations.add(storages[i]);\n               }\n             }\n             // If we are performing a truncate recovery than set recovery fields\n             // to old block.\n             boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n             boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                 b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n             ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                 new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                 new ExtendedBlock(blockPoolId, b);\n             // If we only get 1 replica after eliminating stale nodes, then choose all\n             // replicas for recovery and let the primary data node handle failures.\n             DatanodeInfo[] recoveryInfos;\n             if (recoveryLocations.size() \u003e 1) {\n               if (recoveryLocations.size() !\u003d storages.length) {\n                 LOG.info(\"Skipped stale nodes for recovery : \" +\n                     (storages.length - recoveryLocations.size()));\n               }\n               recoveryInfos \u003d\n                   DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n             } else {\n               // If too many replicas are stale, then choose all replicas to participate\n               // in block recovery.\n               recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n             }\n             if(truncateRecovery) {\n               Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                   b.getTruncateBlock();\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 recoveryBlock));\n             } else {\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 b.getBlockRecoveryId()));\n             }\n           }\n           return new DatanodeCommand[] { brCommand };\n         }\n \n         final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003cDatanodeCommand\u003e();\n         //check pending replication\n         List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n               maxTransfers);\n         if (pendingList !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n               pendingList));\n         }\n         //check block invalidation\n         Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n         if (blks !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n               blockPoolId, blks));\n         }\n         boolean sendingCachingCommands \u003d false;\n         long nowMs \u003d monotonicNow();\n         if (shouldSendCachingCommands \u0026\u0026 \n             ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                 timeBetweenResendingCachingDirectivesMs)) {\n           DatanodeCommand pendingCacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                 DatanodeProtocol.DNA_CACHE, blockPoolId);\n           if (pendingCacheCommand !\u003d null) {\n             cmds.add(pendingCacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           DatanodeCommand pendingUncacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                 DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n           if (pendingUncacheCommand !\u003d null) {\n             cmds.add(pendingUncacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           if (sendingCachingCommands) {\n             nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n           }\n         }\n \n         blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n         // check for balancer bandwidth update\n         if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n           cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n           // set back to 0 to indicate that datanode has been sent the new value\n           nodeinfo.setBalancerBandwidth(0);\n         }\n \n         if (!cmds.isEmpty()) {\n           return cmds.toArray(new DatanodeCommand[cmds.size()]);\n         }\n       }\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    synchronized (heartbeatManager) {\n      synchronized (datanodeMap) {\n        DatanodeDescriptor nodeinfo \u003d null;\n        try {\n          nodeinfo \u003d getDatanode(nodeReg);\n        } catch(UnregisteredNodeException e) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n        \n        // Check if this datanode should actually be shutdown instead. \n        if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n          setDatanodeDead(nodeinfo);\n          throw new DisallowedDatanodeException(nodeinfo);\n        }\n\n        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n\n        heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                         cacheCapacity, cacheUsed,\n                                         xceiverCount, failedVolumes,\n                                         volumeFailureSummary);\n\n        // If we are in safemode, do not send back any recovery / replication\n        // requests. Don\u0027t even drain the existing queue of work.\n        if(namesystem.isInSafeMode()) {\n          return new DatanodeCommand[0];\n        }\n\n        //check lease recovery\n        BlockInfoUnderConstruction[] blocks \u003d nodeinfo\n            .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n        if (blocks !\u003d null) {\n          BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n              blocks.length);\n          for (BlockInfoUnderConstruction b : blocks) {\n            final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n            // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n            final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                new ArrayList\u003cDatanodeStorageInfo\u003e(storages.length);\n            for (int i \u003d 0; i \u003c storages.length; i++) {\n              if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                recoveryLocations.add(storages[i]);\n              }\n            }\n            // If we are performing a truncate recovery than set recovery fields\n            // to old block.\n            boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n            boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n            ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                new ExtendedBlock(blockPoolId, b);\n            // If we only get 1 replica after eliminating stale nodes, then choose all\n            // replicas for recovery and let the primary data node handle failures.\n            DatanodeInfo[] recoveryInfos;\n            if (recoveryLocations.size() \u003e 1) {\n              if (recoveryLocations.size() !\u003d storages.length) {\n                LOG.info(\"Skipped stale nodes for recovery : \" +\n                    (storages.length - recoveryLocations.size()));\n              }\n              recoveryInfos \u003d\n                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n            } else {\n              // If too many replicas are stale, then choose all replicas to participate\n              // in block recovery.\n              recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n            }\n            if(truncateRecovery) {\n              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                  b.getTruncateBlock();\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                recoveryBlock));\n            } else {\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                b.getBlockRecoveryId()));\n            }\n          }\n          return new DatanodeCommand[] { brCommand };\n        }\n\n        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003cDatanodeCommand\u003e();\n        //check pending replication\n        List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n              maxTransfers);\n        if (pendingList !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n        //check block invalidation\n        Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n        if (blks !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n              blockPoolId, blks));\n        }\n        boolean sendingCachingCommands \u003d false;\n        long nowMs \u003d monotonicNow();\n        if (shouldSendCachingCommands \u0026\u0026 \n            ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                timeBetweenResendingCachingDirectivesMs)) {\n          DatanodeCommand pendingCacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                DatanodeProtocol.DNA_CACHE, blockPoolId);\n          if (pendingCacheCommand !\u003d null) {\n            cmds.add(pendingCacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          DatanodeCommand pendingUncacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n          if (pendingUncacheCommand !\u003d null) {\n            cmds.add(pendingUncacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          if (sendingCachingCommands) {\n            nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n          }\n        }\n\n        blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n        // check for balancer bandwidth update\n        if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n          cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n          // set back to 0 to indicate that datanode has been sent the new value\n          nodeinfo.setBalancerBandwidth(0);\n        }\n\n        if (!cmds.isEmpty()) {\n          return cmds.toArray(new DatanodeCommand[cmds.size()]);\n        }\n      }\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "a1c9425265d2c94bfc6afb39ab2c16b4ef9e874e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8146. Protobuf changes for BlockECRecoveryCommand and its fields for making it ready for transfer to DN (Contributed by Uma Maheswara Rao G)\n",
      "commitDate": "26/05/15 11:59 AM",
      "commitName": "a1c9425265d2c94bfc6afb39ab2c16b4ef9e874e",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "26/05/15 11:55 AM",
      "commitNameOld": "146ce7a9784e52432b76164009336a4b2cf2860e",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 29,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,149 +1,149 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary) throws IOException {\n     synchronized (heartbeatManager) {\n       synchronized (datanodeMap) {\n         DatanodeDescriptor nodeinfo;\n         try {\n           nodeinfo \u003d getDatanode(nodeReg);\n         } catch(UnregisteredNodeException e) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n         \n         // Check if this datanode should actually be shutdown instead. \n         if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n           setDatanodeDead(nodeinfo);\n           throw new DisallowedDatanodeException(nodeinfo);\n         }\n \n         if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n \n         heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                          cacheCapacity, cacheUsed,\n                                          xceiverCount, failedVolumes,\n                                          volumeFailureSummary);\n \n         // If we are in safemode, do not send back any recovery / replication\n         // requests. Don\u0027t even drain the existing queue of work.\n         if(namesystem.isInSafeMode()) {\n           return new DatanodeCommand[0];\n         }\n \n         //check lease recovery\n         BlockInfoUnderConstruction[] blocks \u003d nodeinfo\n             .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n         if (blocks !\u003d null) {\n           BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n               blocks.length);\n           for (BlockInfoUnderConstruction b : blocks) {\n             final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n             // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n             final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                 new ArrayList\u003c\u003e(storages.length);\n             for (DatanodeStorageInfo storage : storages) {\n               if (!storage.getDatanodeDescriptor().isStale(staleInterval)) {\n                 recoveryLocations.add(storage);\n               }\n             }\n             // If we are performing a truncate recovery than set recovery fields\n             // to old block.\n             boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n             boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                 b.getTruncateBlock().getBlockId() !\u003d b.toBlock().getBlockId();\n             ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                 new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                 new ExtendedBlock(blockPoolId, b.toBlock());\n             // If we only get 1 replica after eliminating stale nodes, then choose all\n             // replicas for recovery and let the primary data node handle failures.\n             DatanodeInfo[] recoveryInfos;\n             if (recoveryLocations.size() \u003e 1) {\n               if (recoveryLocations.size() !\u003d storages.length) {\n                 LOG.info(\"Skipped stale nodes for recovery : \" +\n                     (storages.length - recoveryLocations.size()));\n               }\n               recoveryInfos \u003d\n                   DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n             } else {\n               // If too many replicas are stale, then choose all replicas to participate\n               // in block recovery.\n               recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n             }\n             if(truncateRecovery) {\n               Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b.toBlock() :\n                   b.getTruncateBlock();\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 recoveryBlock));\n             } else {\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 b.getBlockRecoveryId()));\n             }\n           }\n           return new DatanodeCommand[] { brCommand };\n         }\n \n         final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n         //check pending replication\n         List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n               maxTransfers);\n         if (pendingList !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n               pendingList));\n         }\n         // checking pending erasure coding tasks\n         List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d\n             nodeinfo.getErasureCodeCommand(maxTransfers);\n         if (pendingECList !\u003d null) {\n-          cmds.add(new BlockECRecoveryCommand(DatanodeProtocol.DNA_CODEC,\n+          cmds.add(new BlockECRecoveryCommand(DatanodeProtocol.DNA_ERASURE_CODING_RECOVERY,\n               pendingECList));\n         }\n         //check block invalidation\n         Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n         if (blks !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n               blockPoolId, blks));\n         }\n         boolean sendingCachingCommands \u003d false;\n         long nowMs \u003d monotonicNow();\n         if (shouldSendCachingCommands \u0026\u0026 \n             ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                 timeBetweenResendingCachingDirectivesMs)) {\n           DatanodeCommand pendingCacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                 DatanodeProtocol.DNA_CACHE, blockPoolId);\n           if (pendingCacheCommand !\u003d null) {\n             cmds.add(pendingCacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           DatanodeCommand pendingUncacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                 DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n           if (pendingUncacheCommand !\u003d null) {\n             cmds.add(pendingUncacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           if (sendingCachingCommands) {\n             nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n           }\n         }\n \n         blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n         // check for balancer bandwidth update\n         if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n           cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n           // set back to 0 to indicate that datanode has been sent the new value\n           nodeinfo.setBalancerBandwidth(0);\n         }\n \n         if (!cmds.isEmpty()) {\n           return cmds.toArray(new DatanodeCommand[cmds.size()]);\n         }\n       }\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    synchronized (heartbeatManager) {\n      synchronized (datanodeMap) {\n        DatanodeDescriptor nodeinfo;\n        try {\n          nodeinfo \u003d getDatanode(nodeReg);\n        } catch(UnregisteredNodeException e) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n        \n        // Check if this datanode should actually be shutdown instead. \n        if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n          setDatanodeDead(nodeinfo);\n          throw new DisallowedDatanodeException(nodeinfo);\n        }\n\n        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n\n        heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                         cacheCapacity, cacheUsed,\n                                         xceiverCount, failedVolumes,\n                                         volumeFailureSummary);\n\n        // If we are in safemode, do not send back any recovery / replication\n        // requests. Don\u0027t even drain the existing queue of work.\n        if(namesystem.isInSafeMode()) {\n          return new DatanodeCommand[0];\n        }\n\n        //check lease recovery\n        BlockInfoUnderConstruction[] blocks \u003d nodeinfo\n            .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n        if (blocks !\u003d null) {\n          BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n              blocks.length);\n          for (BlockInfoUnderConstruction b : blocks) {\n            final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n            // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n            final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                new ArrayList\u003c\u003e(storages.length);\n            for (DatanodeStorageInfo storage : storages) {\n              if (!storage.getDatanodeDescriptor().isStale(staleInterval)) {\n                recoveryLocations.add(storage);\n              }\n            }\n            // If we are performing a truncate recovery than set recovery fields\n            // to old block.\n            boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n            boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                b.getTruncateBlock().getBlockId() !\u003d b.toBlock().getBlockId();\n            ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                new ExtendedBlock(blockPoolId, b.toBlock());\n            // If we only get 1 replica after eliminating stale nodes, then choose all\n            // replicas for recovery and let the primary data node handle failures.\n            DatanodeInfo[] recoveryInfos;\n            if (recoveryLocations.size() \u003e 1) {\n              if (recoveryLocations.size() !\u003d storages.length) {\n                LOG.info(\"Skipped stale nodes for recovery : \" +\n                    (storages.length - recoveryLocations.size()));\n              }\n              recoveryInfos \u003d\n                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n            } else {\n              // If too many replicas are stale, then choose all replicas to participate\n              // in block recovery.\n              recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n            }\n            if(truncateRecovery) {\n              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b.toBlock() :\n                  b.getTruncateBlock();\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                recoveryBlock));\n            } else {\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                b.getBlockRecoveryId()));\n            }\n          }\n          return new DatanodeCommand[] { brCommand };\n        }\n\n        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n        //check pending replication\n        List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n              maxTransfers);\n        if (pendingList !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n        // checking pending erasure coding tasks\n        List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d\n            nodeinfo.getErasureCodeCommand(maxTransfers);\n        if (pendingECList !\u003d null) {\n          cmds.add(new BlockECRecoveryCommand(DatanodeProtocol.DNA_ERASURE_CODING_RECOVERY,\n              pendingECList));\n        }\n        //check block invalidation\n        Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n        if (blks !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n              blockPoolId, blks));\n        }\n        boolean sendingCachingCommands \u003d false;\n        long nowMs \u003d monotonicNow();\n        if (shouldSendCachingCommands \u0026\u0026 \n            ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                timeBetweenResendingCachingDirectivesMs)) {\n          DatanodeCommand pendingCacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                DatanodeProtocol.DNA_CACHE, blockPoolId);\n          if (pendingCacheCommand !\u003d null) {\n            cmds.add(pendingCacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          DatanodeCommand pendingUncacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n          if (pendingUncacheCommand !\u003d null) {\n            cmds.add(pendingUncacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          if (sendingCachingCommands) {\n            nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n          }\n        }\n\n        blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n        // check for balancer bandwidth update\n        if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n          cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n          // set back to 0 to indicate that datanode has been sent the new value\n          nodeinfo.setBalancerBandwidth(0);\n        }\n\n        if (!cmds.isEmpty()) {\n          return cmds.toArray(new DatanodeCommand[cmds.size()]);\n        }\n      }\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "146ce7a9784e52432b76164009336a4b2cf2860e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7969. Erasure coding: NameNode support for lease recovery of striped block groups. Contributed by Zhe Zhang.\n",
      "commitDate": "26/05/15 11:55 AM",
      "commitName": "146ce7a9784e52432b76164009336a4b2cf2860e",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "26/05/15 11:43 AM",
      "commitNameOld": "57a84c0d149b693c913416975cafe6de4e23c321",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,149 +1,149 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary) throws IOException {\n     synchronized (heartbeatManager) {\n       synchronized (datanodeMap) {\n         DatanodeDescriptor nodeinfo;\n         try {\n           nodeinfo \u003d getDatanode(nodeReg);\n         } catch(UnregisteredNodeException e) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n         \n         // Check if this datanode should actually be shutdown instead. \n         if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n           setDatanodeDead(nodeinfo);\n           throw new DisallowedDatanodeException(nodeinfo);\n         }\n \n         if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n \n         heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                          cacheCapacity, cacheUsed,\n                                          xceiverCount, failedVolumes,\n                                          volumeFailureSummary);\n \n         // If we are in safemode, do not send back any recovery / replication\n         // requests. Don\u0027t even drain the existing queue of work.\n         if(namesystem.isInSafeMode()) {\n           return new DatanodeCommand[0];\n         }\n \n         //check lease recovery\n-        BlockInfoContiguousUnderConstruction[] blocks \u003d nodeinfo\n+        BlockInfoUnderConstruction[] blocks \u003d nodeinfo\n             .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n         if (blocks !\u003d null) {\n           BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n               blocks.length);\n-          for (BlockInfoContiguousUnderConstruction b : blocks) {\n+          for (BlockInfoUnderConstruction b : blocks) {\n             final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n             // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n             final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                 new ArrayList\u003c\u003e(storages.length);\n             for (DatanodeStorageInfo storage : storages) {\n               if (!storage.getDatanodeDescriptor().isStale(staleInterval)) {\n                 recoveryLocations.add(storage);\n               }\n             }\n             // If we are performing a truncate recovery than set recovery fields\n             // to old block.\n             boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n             boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n-                b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n+                b.getTruncateBlock().getBlockId() !\u003d b.toBlock().getBlockId();\n             ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                 new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n-                new ExtendedBlock(blockPoolId, b);\n+                new ExtendedBlock(blockPoolId, b.toBlock());\n             // If we only get 1 replica after eliminating stale nodes, then choose all\n             // replicas for recovery and let the primary data node handle failures.\n             DatanodeInfo[] recoveryInfos;\n             if (recoveryLocations.size() \u003e 1) {\n               if (recoveryLocations.size() !\u003d storages.length) {\n                 LOG.info(\"Skipped stale nodes for recovery : \" +\n                     (storages.length - recoveryLocations.size()));\n               }\n               recoveryInfos \u003d\n                   DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n             } else {\n               // If too many replicas are stale, then choose all replicas to participate\n               // in block recovery.\n               recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n             }\n             if(truncateRecovery) {\n-              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n+              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b.toBlock() :\n                   b.getTruncateBlock();\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 recoveryBlock));\n             } else {\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 b.getBlockRecoveryId()));\n             }\n           }\n           return new DatanodeCommand[] { brCommand };\n         }\n \n         final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n         //check pending replication\n         List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n               maxTransfers);\n         if (pendingList !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n               pendingList));\n         }\n         // checking pending erasure coding tasks\n         List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d\n             nodeinfo.getErasureCodeCommand(maxTransfers);\n         if (pendingECList !\u003d null) {\n           cmds.add(new BlockECRecoveryCommand(DatanodeProtocol.DNA_CODEC,\n               pendingECList));\n         }\n         //check block invalidation\n         Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n         if (blks !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n               blockPoolId, blks));\n         }\n         boolean sendingCachingCommands \u003d false;\n         long nowMs \u003d monotonicNow();\n         if (shouldSendCachingCommands \u0026\u0026 \n             ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                 timeBetweenResendingCachingDirectivesMs)) {\n           DatanodeCommand pendingCacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                 DatanodeProtocol.DNA_CACHE, blockPoolId);\n           if (pendingCacheCommand !\u003d null) {\n             cmds.add(pendingCacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           DatanodeCommand pendingUncacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                 DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n           if (pendingUncacheCommand !\u003d null) {\n             cmds.add(pendingUncacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           if (sendingCachingCommands) {\n             nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n           }\n         }\n \n         blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n         // check for balancer bandwidth update\n         if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n           cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n           // set back to 0 to indicate that datanode has been sent the new value\n           nodeinfo.setBalancerBandwidth(0);\n         }\n \n         if (!cmds.isEmpty()) {\n           return cmds.toArray(new DatanodeCommand[cmds.size()]);\n         }\n       }\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    synchronized (heartbeatManager) {\n      synchronized (datanodeMap) {\n        DatanodeDescriptor nodeinfo;\n        try {\n          nodeinfo \u003d getDatanode(nodeReg);\n        } catch(UnregisteredNodeException e) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n        \n        // Check if this datanode should actually be shutdown instead. \n        if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n          setDatanodeDead(nodeinfo);\n          throw new DisallowedDatanodeException(nodeinfo);\n        }\n\n        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n\n        heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                         cacheCapacity, cacheUsed,\n                                         xceiverCount, failedVolumes,\n                                         volumeFailureSummary);\n\n        // If we are in safemode, do not send back any recovery / replication\n        // requests. Don\u0027t even drain the existing queue of work.\n        if(namesystem.isInSafeMode()) {\n          return new DatanodeCommand[0];\n        }\n\n        //check lease recovery\n        BlockInfoUnderConstruction[] blocks \u003d nodeinfo\n            .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n        if (blocks !\u003d null) {\n          BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n              blocks.length);\n          for (BlockInfoUnderConstruction b : blocks) {\n            final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n            // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n            final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                new ArrayList\u003c\u003e(storages.length);\n            for (DatanodeStorageInfo storage : storages) {\n              if (!storage.getDatanodeDescriptor().isStale(staleInterval)) {\n                recoveryLocations.add(storage);\n              }\n            }\n            // If we are performing a truncate recovery than set recovery fields\n            // to old block.\n            boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n            boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                b.getTruncateBlock().getBlockId() !\u003d b.toBlock().getBlockId();\n            ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                new ExtendedBlock(blockPoolId, b.toBlock());\n            // If we only get 1 replica after eliminating stale nodes, then choose all\n            // replicas for recovery and let the primary data node handle failures.\n            DatanodeInfo[] recoveryInfos;\n            if (recoveryLocations.size() \u003e 1) {\n              if (recoveryLocations.size() !\u003d storages.length) {\n                LOG.info(\"Skipped stale nodes for recovery : \" +\n                    (storages.length - recoveryLocations.size()));\n              }\n              recoveryInfos \u003d\n                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n            } else {\n              // If too many replicas are stale, then choose all replicas to participate\n              // in block recovery.\n              recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n            }\n            if(truncateRecovery) {\n              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b.toBlock() :\n                  b.getTruncateBlock();\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                recoveryBlock));\n            } else {\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                b.getBlockRecoveryId()));\n            }\n          }\n          return new DatanodeCommand[] { brCommand };\n        }\n\n        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n        //check pending replication\n        List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n              maxTransfers);\n        if (pendingList !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n        // checking pending erasure coding tasks\n        List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d\n            nodeinfo.getErasureCodeCommand(maxTransfers);\n        if (pendingECList !\u003d null) {\n          cmds.add(new BlockECRecoveryCommand(DatanodeProtocol.DNA_CODEC,\n              pendingECList));\n        }\n        //check block invalidation\n        Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n        if (blks !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n              blockPoolId, blks));\n        }\n        boolean sendingCachingCommands \u003d false;\n        long nowMs \u003d monotonicNow();\n        if (shouldSendCachingCommands \u0026\u0026 \n            ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                timeBetweenResendingCachingDirectivesMs)) {\n          DatanodeCommand pendingCacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                DatanodeProtocol.DNA_CACHE, blockPoolId);\n          if (pendingCacheCommand !\u003d null) {\n            cmds.add(pendingCacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          DatanodeCommand pendingUncacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n          if (pendingUncacheCommand !\u003d null) {\n            cmds.add(pendingUncacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          if (sendingCachingCommands) {\n            nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n          }\n        }\n\n        blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n        // check for balancer bandwidth update\n        if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n          cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n          // set back to 0 to indicate that datanode has been sent the new value\n          nodeinfo.setBalancerBandwidth(0);\n        }\n\n        if (!cmds.isEmpty()) {\n          return cmds.toArray(new DatanodeCommand[cmds.size()]);\n        }\n      }\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "57a84c0d149b693c913416975cafe6de4e23c321": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7369. Erasure coding: distribute recovery work for striped blocks to DataNode. Contributed by Zhe Zhang.\n",
      "commitDate": "26/05/15 11:43 AM",
      "commitName": "57a84c0d149b693c913416975cafe6de4e23c321",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "19/05/15 10:50 AM",
      "commitNameOld": "470c87dbc6c24dd3b370f1ad9e7ab1f6dabd2080",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 7.04,
      "commitsBetweenForRepo": 65,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,142 +1,149 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary) throws IOException {\n     synchronized (heartbeatManager) {\n       synchronized (datanodeMap) {\n-        DatanodeDescriptor nodeinfo \u003d null;\n+        DatanodeDescriptor nodeinfo;\n         try {\n           nodeinfo \u003d getDatanode(nodeReg);\n         } catch(UnregisteredNodeException e) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n         \n         // Check if this datanode should actually be shutdown instead. \n         if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n           setDatanodeDead(nodeinfo);\n           throw new DisallowedDatanodeException(nodeinfo);\n         }\n \n         if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n \n         heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                          cacheCapacity, cacheUsed,\n                                          xceiverCount, failedVolumes,\n                                          volumeFailureSummary);\n \n         // If we are in safemode, do not send back any recovery / replication\n         // requests. Don\u0027t even drain the existing queue of work.\n         if(namesystem.isInSafeMode()) {\n           return new DatanodeCommand[0];\n         }\n \n         //check lease recovery\n         BlockInfoContiguousUnderConstruction[] blocks \u003d nodeinfo\n             .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n         if (blocks !\u003d null) {\n           BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n               blocks.length);\n           for (BlockInfoContiguousUnderConstruction b : blocks) {\n             final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n             // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n             final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n-                new ArrayList\u003cDatanodeStorageInfo\u003e(storages.length);\n-            for (int i \u003d 0; i \u003c storages.length; i++) {\n-              if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n-                recoveryLocations.add(storages[i]);\n+                new ArrayList\u003c\u003e(storages.length);\n+            for (DatanodeStorageInfo storage : storages) {\n+              if (!storage.getDatanodeDescriptor().isStale(staleInterval)) {\n+                recoveryLocations.add(storage);\n               }\n             }\n             // If we are performing a truncate recovery than set recovery fields\n             // to old block.\n             boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n             boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                 b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n             ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                 new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                 new ExtendedBlock(blockPoolId, b);\n             // If we only get 1 replica after eliminating stale nodes, then choose all\n             // replicas for recovery and let the primary data node handle failures.\n             DatanodeInfo[] recoveryInfos;\n             if (recoveryLocations.size() \u003e 1) {\n               if (recoveryLocations.size() !\u003d storages.length) {\n                 LOG.info(\"Skipped stale nodes for recovery : \" +\n                     (storages.length - recoveryLocations.size()));\n               }\n               recoveryInfos \u003d\n                   DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n             } else {\n               // If too many replicas are stale, then choose all replicas to participate\n               // in block recovery.\n               recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n             }\n             if(truncateRecovery) {\n               Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                   b.getTruncateBlock();\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 recoveryBlock));\n             } else {\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 b.getBlockRecoveryId()));\n             }\n           }\n           return new DatanodeCommand[] { brCommand };\n         }\n \n-        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003cDatanodeCommand\u003e();\n+        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n         //check pending replication\n         List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n               maxTransfers);\n         if (pendingList !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n               pendingList));\n         }\n+        // checking pending erasure coding tasks\n+        List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d\n+            nodeinfo.getErasureCodeCommand(maxTransfers);\n+        if (pendingECList !\u003d null) {\n+          cmds.add(new BlockECRecoveryCommand(DatanodeProtocol.DNA_CODEC,\n+              pendingECList));\n+        }\n         //check block invalidation\n         Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n         if (blks !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n               blockPoolId, blks));\n         }\n         boolean sendingCachingCommands \u003d false;\n         long nowMs \u003d monotonicNow();\n         if (shouldSendCachingCommands \u0026\u0026 \n             ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                 timeBetweenResendingCachingDirectivesMs)) {\n           DatanodeCommand pendingCacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                 DatanodeProtocol.DNA_CACHE, blockPoolId);\n           if (pendingCacheCommand !\u003d null) {\n             cmds.add(pendingCacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           DatanodeCommand pendingUncacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                 DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n           if (pendingUncacheCommand !\u003d null) {\n             cmds.add(pendingUncacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           if (sendingCachingCommands) {\n             nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n           }\n         }\n \n         blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n         // check for balancer bandwidth update\n         if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n           cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n           // set back to 0 to indicate that datanode has been sent the new value\n           nodeinfo.setBalancerBandwidth(0);\n         }\n \n         if (!cmds.isEmpty()) {\n           return cmds.toArray(new DatanodeCommand[cmds.size()]);\n         }\n       }\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    synchronized (heartbeatManager) {\n      synchronized (datanodeMap) {\n        DatanodeDescriptor nodeinfo;\n        try {\n          nodeinfo \u003d getDatanode(nodeReg);\n        } catch(UnregisteredNodeException e) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n        \n        // Check if this datanode should actually be shutdown instead. \n        if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n          setDatanodeDead(nodeinfo);\n          throw new DisallowedDatanodeException(nodeinfo);\n        }\n\n        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n\n        heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                         cacheCapacity, cacheUsed,\n                                         xceiverCount, failedVolumes,\n                                         volumeFailureSummary);\n\n        // If we are in safemode, do not send back any recovery / replication\n        // requests. Don\u0027t even drain the existing queue of work.\n        if(namesystem.isInSafeMode()) {\n          return new DatanodeCommand[0];\n        }\n\n        //check lease recovery\n        BlockInfoContiguousUnderConstruction[] blocks \u003d nodeinfo\n            .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n        if (blocks !\u003d null) {\n          BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n              blocks.length);\n          for (BlockInfoContiguousUnderConstruction b : blocks) {\n            final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n            // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n            final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                new ArrayList\u003c\u003e(storages.length);\n            for (DatanodeStorageInfo storage : storages) {\n              if (!storage.getDatanodeDescriptor().isStale(staleInterval)) {\n                recoveryLocations.add(storage);\n              }\n            }\n            // If we are performing a truncate recovery than set recovery fields\n            // to old block.\n            boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n            boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n            ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                new ExtendedBlock(blockPoolId, b);\n            // If we only get 1 replica after eliminating stale nodes, then choose all\n            // replicas for recovery and let the primary data node handle failures.\n            DatanodeInfo[] recoveryInfos;\n            if (recoveryLocations.size() \u003e 1) {\n              if (recoveryLocations.size() !\u003d storages.length) {\n                LOG.info(\"Skipped stale nodes for recovery : \" +\n                    (storages.length - recoveryLocations.size()));\n              }\n              recoveryInfos \u003d\n                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n            } else {\n              // If too many replicas are stale, then choose all replicas to participate\n              // in block recovery.\n              recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n            }\n            if(truncateRecovery) {\n              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                  b.getTruncateBlock();\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                recoveryBlock));\n            } else {\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                b.getBlockRecoveryId()));\n            }\n          }\n          return new DatanodeCommand[] { brCommand };\n        }\n\n        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003c\u003e();\n        //check pending replication\n        List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n              maxTransfers);\n        if (pendingList !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n        // checking pending erasure coding tasks\n        List\u003cBlockECRecoveryInfo\u003e pendingECList \u003d\n            nodeinfo.getErasureCodeCommand(maxTransfers);\n        if (pendingECList !\u003d null) {\n          cmds.add(new BlockECRecoveryCommand(DatanodeProtocol.DNA_CODEC,\n              pendingECList));\n        }\n        //check block invalidation\n        Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n        if (blks !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n              blockPoolId, blks));\n        }\n        boolean sendingCachingCommands \u003d false;\n        long nowMs \u003d monotonicNow();\n        if (shouldSendCachingCommands \u0026\u0026 \n            ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                timeBetweenResendingCachingDirectivesMs)) {\n          DatanodeCommand pendingCacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                DatanodeProtocol.DNA_CACHE, blockPoolId);\n          if (pendingCacheCommand !\u003d null) {\n            cmds.add(pendingCacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          DatanodeCommand pendingUncacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n          if (pendingUncacheCommand !\u003d null) {\n            cmds.add(pendingUncacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          if (sendingCachingCommands) {\n            nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n          }\n        }\n\n        blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n        // check for balancer bandwidth update\n        if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n          cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n          // set back to 0 to indicate that datanode has been sent the new value\n          nodeinfo.setBalancerBandwidth(0);\n        }\n\n        if (!cmds.isEmpty()) {\n          return cmds.toArray(new DatanodeCommand[cmds.size()]);\n        }\n      }\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "75ead273bea8a7dad61c4f99c3a16cab2697c498": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6841. Use Time.monotonicNow() wherever applicable instead of Time.now(). Contributed by Vinayakumar B\n",
      "commitDate": "20/03/15 12:02 PM",
      "commitName": "75ead273bea8a7dad61c4f99c3a16cab2697c498",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "08/03/15 6:31 PM",
      "commitNameOld": "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 11.73,
      "commitsBetweenForRepo": 118,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,142 +1,142 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary) throws IOException {\n     synchronized (heartbeatManager) {\n       synchronized (datanodeMap) {\n         DatanodeDescriptor nodeinfo \u003d null;\n         try {\n           nodeinfo \u003d getDatanode(nodeReg);\n         } catch(UnregisteredNodeException e) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n         \n         // Check if this datanode should actually be shutdown instead. \n         if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n           setDatanodeDead(nodeinfo);\n           throw new DisallowedDatanodeException(nodeinfo);\n         }\n \n         if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n \n         heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                          cacheCapacity, cacheUsed,\n                                          xceiverCount, failedVolumes,\n                                          volumeFailureSummary);\n \n         // If we are in safemode, do not send back any recovery / replication\n         // requests. Don\u0027t even drain the existing queue of work.\n         if(namesystem.isInSafeMode()) {\n           return new DatanodeCommand[0];\n         }\n \n         //check lease recovery\n         BlockInfoContiguousUnderConstruction[] blocks \u003d nodeinfo\n             .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n         if (blocks !\u003d null) {\n           BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n               blocks.length);\n           for (BlockInfoContiguousUnderConstruction b : blocks) {\n             final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n             // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n             final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                 new ArrayList\u003cDatanodeStorageInfo\u003e(storages.length);\n             for (int i \u003d 0; i \u003c storages.length; i++) {\n               if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                 recoveryLocations.add(storages[i]);\n               }\n             }\n             // If we are performing a truncate recovery than set recovery fields\n             // to old block.\n             boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n             boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                 b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n             ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                 new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                 new ExtendedBlock(blockPoolId, b);\n             // If we only get 1 replica after eliminating stale nodes, then choose all\n             // replicas for recovery and let the primary data node handle failures.\n             DatanodeInfo[] recoveryInfos;\n             if (recoveryLocations.size() \u003e 1) {\n               if (recoveryLocations.size() !\u003d storages.length) {\n                 LOG.info(\"Skipped stale nodes for recovery : \" +\n                     (storages.length - recoveryLocations.size()));\n               }\n               recoveryInfos \u003d\n                   DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n             } else {\n               // If too many replicas are stale, then choose all replicas to participate\n               // in block recovery.\n               recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n             }\n             if(truncateRecovery) {\n               Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                   b.getTruncateBlock();\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 recoveryBlock));\n             } else {\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 b.getBlockRecoveryId()));\n             }\n           }\n           return new DatanodeCommand[] { brCommand };\n         }\n \n         final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003cDatanodeCommand\u003e();\n         //check pending replication\n         List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n               maxTransfers);\n         if (pendingList !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n               pendingList));\n         }\n         //check block invalidation\n         Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n         if (blks !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n               blockPoolId, blks));\n         }\n         boolean sendingCachingCommands \u003d false;\n-        long nowMs \u003d Time.monotonicNow();\n+        long nowMs \u003d monotonicNow();\n         if (shouldSendCachingCommands \u0026\u0026 \n             ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                 timeBetweenResendingCachingDirectivesMs)) {\n           DatanodeCommand pendingCacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                 DatanodeProtocol.DNA_CACHE, blockPoolId);\n           if (pendingCacheCommand !\u003d null) {\n             cmds.add(pendingCacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           DatanodeCommand pendingUncacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                 DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n           if (pendingUncacheCommand !\u003d null) {\n             cmds.add(pendingUncacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           if (sendingCachingCommands) {\n             nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n           }\n         }\n \n         blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n         // check for balancer bandwidth update\n         if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n           cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n           // set back to 0 to indicate that datanode has been sent the new value\n           nodeinfo.setBalancerBandwidth(0);\n         }\n \n         if (!cmds.isEmpty()) {\n           return cmds.toArray(new DatanodeCommand[cmds.size()]);\n         }\n       }\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    synchronized (heartbeatManager) {\n      synchronized (datanodeMap) {\n        DatanodeDescriptor nodeinfo \u003d null;\n        try {\n          nodeinfo \u003d getDatanode(nodeReg);\n        } catch(UnregisteredNodeException e) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n        \n        // Check if this datanode should actually be shutdown instead. \n        if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n          setDatanodeDead(nodeinfo);\n          throw new DisallowedDatanodeException(nodeinfo);\n        }\n\n        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n\n        heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                         cacheCapacity, cacheUsed,\n                                         xceiverCount, failedVolumes,\n                                         volumeFailureSummary);\n\n        // If we are in safemode, do not send back any recovery / replication\n        // requests. Don\u0027t even drain the existing queue of work.\n        if(namesystem.isInSafeMode()) {\n          return new DatanodeCommand[0];\n        }\n\n        //check lease recovery\n        BlockInfoContiguousUnderConstruction[] blocks \u003d nodeinfo\n            .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n        if (blocks !\u003d null) {\n          BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n              blocks.length);\n          for (BlockInfoContiguousUnderConstruction b : blocks) {\n            final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n            // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n            final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                new ArrayList\u003cDatanodeStorageInfo\u003e(storages.length);\n            for (int i \u003d 0; i \u003c storages.length; i++) {\n              if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                recoveryLocations.add(storages[i]);\n              }\n            }\n            // If we are performing a truncate recovery than set recovery fields\n            // to old block.\n            boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n            boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n            ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                new ExtendedBlock(blockPoolId, b);\n            // If we only get 1 replica after eliminating stale nodes, then choose all\n            // replicas for recovery and let the primary data node handle failures.\n            DatanodeInfo[] recoveryInfos;\n            if (recoveryLocations.size() \u003e 1) {\n              if (recoveryLocations.size() !\u003d storages.length) {\n                LOG.info(\"Skipped stale nodes for recovery : \" +\n                    (storages.length - recoveryLocations.size()));\n              }\n              recoveryInfos \u003d\n                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n            } else {\n              // If too many replicas are stale, then choose all replicas to participate\n              // in block recovery.\n              recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n            }\n            if(truncateRecovery) {\n              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                  b.getTruncateBlock();\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                recoveryBlock));\n            } else {\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                b.getBlockRecoveryId()));\n            }\n          }\n          return new DatanodeCommand[] { brCommand };\n        }\n\n        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003cDatanodeCommand\u003e();\n        //check pending replication\n        List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n              maxTransfers);\n        if (pendingList !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n        //check block invalidation\n        Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n        if (blks !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n              blockPoolId, blks));\n        }\n        boolean sendingCachingCommands \u003d false;\n        long nowMs \u003d monotonicNow();\n        if (shouldSendCachingCommands \u0026\u0026 \n            ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                timeBetweenResendingCachingDirectivesMs)) {\n          DatanodeCommand pendingCacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                DatanodeProtocol.DNA_CACHE, blockPoolId);\n          if (pendingCacheCommand !\u003d null) {\n            cmds.add(pendingCacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          DatanodeCommand pendingUncacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n          if (pendingUncacheCommand !\u003d null) {\n            cmds.add(pendingUncacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          if (sendingCachingCommands) {\n            nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n          }\n        }\n\n        blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n        // check for balancer bandwidth update\n        if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n          cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n          // set back to 0 to indicate that datanode has been sent the new value\n          nodeinfo.setBalancerBandwidth(0);\n        }\n\n        if (!cmds.isEmpty()) {\n          return cmds.toArray(new DatanodeCommand[cmds.size()]);\n        }\n      }\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "9729b244de50322c2cc889c97c2ffb2b4675cf77": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7604. Track and display failed DataNode storage locations in NameNode. Contributed by Chris Nauroth.\n",
      "commitDate": "16/02/15 2:43 PM",
      "commitName": "9729b244de50322c2cc889c97c2ffb2b4675cf77",
      "commitAuthor": "cnauroth",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7604. Track and display failed DataNode storage locations in NameNode. Contributed by Chris Nauroth.\n",
          "commitDate": "16/02/15 2:43 PM",
          "commitName": "9729b244de50322c2cc889c97c2ffb2b4675cf77",
          "commitAuthor": "cnauroth",
          "commitDateOld": "12/02/15 5:40 PM",
          "commitNameOld": "46b6d23e8fbed4c2ba537dd752116c173805bca7",
          "commitAuthorOld": "Akira Ajisaka",
          "daysBetweenCommits": 3.88,
          "commitsBetweenForRepo": 29,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,141 +1,142 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n-      int maxTransfers, int failedVolumes\n-      ) throws IOException {\n+      int maxTransfers, int failedVolumes,\n+      VolumeFailureSummary volumeFailureSummary) throws IOException {\n     synchronized (heartbeatManager) {\n       synchronized (datanodeMap) {\n         DatanodeDescriptor nodeinfo \u003d null;\n         try {\n           nodeinfo \u003d getDatanode(nodeReg);\n         } catch(UnregisteredNodeException e) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n         \n         // Check if this datanode should actually be shutdown instead. \n         if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n           setDatanodeDead(nodeinfo);\n           throw new DisallowedDatanodeException(nodeinfo);\n         }\n \n         if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n \n         heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                          cacheCapacity, cacheUsed,\n-                                         xceiverCount, failedVolumes);\n+                                         xceiverCount, failedVolumes,\n+                                         volumeFailureSummary);\n \n         // If we are in safemode, do not send back any recovery / replication\n         // requests. Don\u0027t even drain the existing queue of work.\n         if(namesystem.isInSafeMode()) {\n           return new DatanodeCommand[0];\n         }\n \n         //check lease recovery\n         BlockInfoContiguousUnderConstruction[] blocks \u003d nodeinfo\n             .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n         if (blocks !\u003d null) {\n           BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n               blocks.length);\n           for (BlockInfoContiguousUnderConstruction b : blocks) {\n             final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n             // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n             final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                 new ArrayList\u003cDatanodeStorageInfo\u003e(storages.length);\n             for (int i \u003d 0; i \u003c storages.length; i++) {\n               if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                 recoveryLocations.add(storages[i]);\n               }\n             }\n             // If we are performing a truncate recovery than set recovery fields\n             // to old block.\n             boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n             boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                 b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n             ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                 new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                 new ExtendedBlock(blockPoolId, b);\n             // If we only get 1 replica after eliminating stale nodes, then choose all\n             // replicas for recovery and let the primary data node handle failures.\n             DatanodeInfo[] recoveryInfos;\n             if (recoveryLocations.size() \u003e 1) {\n               if (recoveryLocations.size() !\u003d storages.length) {\n                 LOG.info(\"Skipped stale nodes for recovery : \" +\n                     (storages.length - recoveryLocations.size()));\n               }\n               recoveryInfos \u003d\n                   DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n             } else {\n               // If too many replicas are stale, then choose all replicas to participate\n               // in block recovery.\n               recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n             }\n             if(truncateRecovery) {\n               Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                   b.getTruncateBlock();\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 recoveryBlock));\n             } else {\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 b.getBlockRecoveryId()));\n             }\n           }\n           return new DatanodeCommand[] { brCommand };\n         }\n \n         final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003cDatanodeCommand\u003e();\n         //check pending replication\n         List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n               maxTransfers);\n         if (pendingList !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n               pendingList));\n         }\n         //check block invalidation\n         Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n         if (blks !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n               blockPoolId, blks));\n         }\n         boolean sendingCachingCommands \u003d false;\n         long nowMs \u003d Time.monotonicNow();\n         if (shouldSendCachingCommands \u0026\u0026 \n             ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                 timeBetweenResendingCachingDirectivesMs)) {\n           DatanodeCommand pendingCacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                 DatanodeProtocol.DNA_CACHE, blockPoolId);\n           if (pendingCacheCommand !\u003d null) {\n             cmds.add(pendingCacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           DatanodeCommand pendingUncacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                 DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n           if (pendingUncacheCommand !\u003d null) {\n             cmds.add(pendingUncacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           if (sendingCachingCommands) {\n             nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n           }\n         }\n \n         blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n         // check for balancer bandwidth update\n         if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n           cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n           // set back to 0 to indicate that datanode has been sent the new value\n           nodeinfo.setBalancerBandwidth(0);\n         }\n \n         if (!cmds.isEmpty()) {\n           return cmds.toArray(new DatanodeCommand[cmds.size()]);\n         }\n       }\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    synchronized (heartbeatManager) {\n      synchronized (datanodeMap) {\n        DatanodeDescriptor nodeinfo \u003d null;\n        try {\n          nodeinfo \u003d getDatanode(nodeReg);\n        } catch(UnregisteredNodeException e) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n        \n        // Check if this datanode should actually be shutdown instead. \n        if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n          setDatanodeDead(nodeinfo);\n          throw new DisallowedDatanodeException(nodeinfo);\n        }\n\n        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n\n        heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                         cacheCapacity, cacheUsed,\n                                         xceiverCount, failedVolumes,\n                                         volumeFailureSummary);\n\n        // If we are in safemode, do not send back any recovery / replication\n        // requests. Don\u0027t even drain the existing queue of work.\n        if(namesystem.isInSafeMode()) {\n          return new DatanodeCommand[0];\n        }\n\n        //check lease recovery\n        BlockInfoContiguousUnderConstruction[] blocks \u003d nodeinfo\n            .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n        if (blocks !\u003d null) {\n          BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n              blocks.length);\n          for (BlockInfoContiguousUnderConstruction b : blocks) {\n            final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n            // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n            final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                new ArrayList\u003cDatanodeStorageInfo\u003e(storages.length);\n            for (int i \u003d 0; i \u003c storages.length; i++) {\n              if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                recoveryLocations.add(storages[i]);\n              }\n            }\n            // If we are performing a truncate recovery than set recovery fields\n            // to old block.\n            boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n            boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n            ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                new ExtendedBlock(blockPoolId, b);\n            // If we only get 1 replica after eliminating stale nodes, then choose all\n            // replicas for recovery and let the primary data node handle failures.\n            DatanodeInfo[] recoveryInfos;\n            if (recoveryLocations.size() \u003e 1) {\n              if (recoveryLocations.size() !\u003d storages.length) {\n                LOG.info(\"Skipped stale nodes for recovery : \" +\n                    (storages.length - recoveryLocations.size()));\n              }\n              recoveryInfos \u003d\n                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n            } else {\n              // If too many replicas are stale, then choose all replicas to participate\n              // in block recovery.\n              recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n            }\n            if(truncateRecovery) {\n              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                  b.getTruncateBlock();\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                recoveryBlock));\n            } else {\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                b.getBlockRecoveryId()));\n            }\n          }\n          return new DatanodeCommand[] { brCommand };\n        }\n\n        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003cDatanodeCommand\u003e();\n        //check pending replication\n        List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n              maxTransfers);\n        if (pendingList !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n        //check block invalidation\n        Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n        if (blks !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n              blockPoolId, blks));\n        }\n        boolean sendingCachingCommands \u003d false;\n        long nowMs \u003d Time.monotonicNow();\n        if (shouldSendCachingCommands \u0026\u0026 \n            ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                timeBetweenResendingCachingDirectivesMs)) {\n          DatanodeCommand pendingCacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                DatanodeProtocol.DNA_CACHE, blockPoolId);\n          if (pendingCacheCommand !\u003d null) {\n            cmds.add(pendingCacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          DatanodeCommand pendingUncacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n          if (pendingUncacheCommand !\u003d null) {\n            cmds.add(pendingUncacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          if (sendingCachingCommands) {\n            nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n          }\n        }\n\n        blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n        // check for balancer bandwidth update\n        if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n          cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n          // set back to 0 to indicate that datanode has been sent the new value\n          nodeinfo.setBalancerBandwidth(0);\n        }\n\n        if (!cmds.isEmpty()) {\n          return cmds.toArray(new DatanodeCommand[cmds.size()]);\n        }\n      }\n    }\n\n    return new DatanodeCommand[0];\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {
            "oldValue": "[nodeReg-DatanodeRegistration, reports-StorageReport[], blockPoolId-String(modifiers-final), cacheCapacity-long, cacheUsed-long, xceiverCount-int, maxTransfers-int, failedVolumes-int]",
            "newValue": "[nodeReg-DatanodeRegistration, reports-StorageReport[], blockPoolId-String(modifiers-final), cacheCapacity-long, cacheUsed-long, xceiverCount-int, maxTransfers-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7604. Track and display failed DataNode storage locations in NameNode. Contributed by Chris Nauroth.\n",
          "commitDate": "16/02/15 2:43 PM",
          "commitName": "9729b244de50322c2cc889c97c2ffb2b4675cf77",
          "commitAuthor": "cnauroth",
          "commitDateOld": "12/02/15 5:40 PM",
          "commitNameOld": "46b6d23e8fbed4c2ba537dd752116c173805bca7",
          "commitAuthorOld": "Akira Ajisaka",
          "daysBetweenCommits": 3.88,
          "commitsBetweenForRepo": 29,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,141 +1,142 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n-      int maxTransfers, int failedVolumes\n-      ) throws IOException {\n+      int maxTransfers, int failedVolumes,\n+      VolumeFailureSummary volumeFailureSummary) throws IOException {\n     synchronized (heartbeatManager) {\n       synchronized (datanodeMap) {\n         DatanodeDescriptor nodeinfo \u003d null;\n         try {\n           nodeinfo \u003d getDatanode(nodeReg);\n         } catch(UnregisteredNodeException e) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n         \n         // Check if this datanode should actually be shutdown instead. \n         if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n           setDatanodeDead(nodeinfo);\n           throw new DisallowedDatanodeException(nodeinfo);\n         }\n \n         if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n \n         heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                          cacheCapacity, cacheUsed,\n-                                         xceiverCount, failedVolumes);\n+                                         xceiverCount, failedVolumes,\n+                                         volumeFailureSummary);\n \n         // If we are in safemode, do not send back any recovery / replication\n         // requests. Don\u0027t even drain the existing queue of work.\n         if(namesystem.isInSafeMode()) {\n           return new DatanodeCommand[0];\n         }\n \n         //check lease recovery\n         BlockInfoContiguousUnderConstruction[] blocks \u003d nodeinfo\n             .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n         if (blocks !\u003d null) {\n           BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n               blocks.length);\n           for (BlockInfoContiguousUnderConstruction b : blocks) {\n             final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n             // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n             final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                 new ArrayList\u003cDatanodeStorageInfo\u003e(storages.length);\n             for (int i \u003d 0; i \u003c storages.length; i++) {\n               if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                 recoveryLocations.add(storages[i]);\n               }\n             }\n             // If we are performing a truncate recovery than set recovery fields\n             // to old block.\n             boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n             boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                 b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n             ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                 new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                 new ExtendedBlock(blockPoolId, b);\n             // If we only get 1 replica after eliminating stale nodes, then choose all\n             // replicas for recovery and let the primary data node handle failures.\n             DatanodeInfo[] recoveryInfos;\n             if (recoveryLocations.size() \u003e 1) {\n               if (recoveryLocations.size() !\u003d storages.length) {\n                 LOG.info(\"Skipped stale nodes for recovery : \" +\n                     (storages.length - recoveryLocations.size()));\n               }\n               recoveryInfos \u003d\n                   DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n             } else {\n               // If too many replicas are stale, then choose all replicas to participate\n               // in block recovery.\n               recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n             }\n             if(truncateRecovery) {\n               Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                   b.getTruncateBlock();\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 recoveryBlock));\n             } else {\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 b.getBlockRecoveryId()));\n             }\n           }\n           return new DatanodeCommand[] { brCommand };\n         }\n \n         final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003cDatanodeCommand\u003e();\n         //check pending replication\n         List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n               maxTransfers);\n         if (pendingList !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n               pendingList));\n         }\n         //check block invalidation\n         Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n         if (blks !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n               blockPoolId, blks));\n         }\n         boolean sendingCachingCommands \u003d false;\n         long nowMs \u003d Time.monotonicNow();\n         if (shouldSendCachingCommands \u0026\u0026 \n             ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                 timeBetweenResendingCachingDirectivesMs)) {\n           DatanodeCommand pendingCacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                 DatanodeProtocol.DNA_CACHE, blockPoolId);\n           if (pendingCacheCommand !\u003d null) {\n             cmds.add(pendingCacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           DatanodeCommand pendingUncacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                 DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n           if (pendingUncacheCommand !\u003d null) {\n             cmds.add(pendingUncacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           if (sendingCachingCommands) {\n             nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n           }\n         }\n \n         blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n         // check for balancer bandwidth update\n         if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n           cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n           // set back to 0 to indicate that datanode has been sent the new value\n           nodeinfo.setBalancerBandwidth(0);\n         }\n \n         if (!cmds.isEmpty()) {\n           return cmds.toArray(new DatanodeCommand[cmds.size()]);\n         }\n       }\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    synchronized (heartbeatManager) {\n      synchronized (datanodeMap) {\n        DatanodeDescriptor nodeinfo \u003d null;\n        try {\n          nodeinfo \u003d getDatanode(nodeReg);\n        } catch(UnregisteredNodeException e) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n        \n        // Check if this datanode should actually be shutdown instead. \n        if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n          setDatanodeDead(nodeinfo);\n          throw new DisallowedDatanodeException(nodeinfo);\n        }\n\n        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n\n        heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                         cacheCapacity, cacheUsed,\n                                         xceiverCount, failedVolumes,\n                                         volumeFailureSummary);\n\n        // If we are in safemode, do not send back any recovery / replication\n        // requests. Don\u0027t even drain the existing queue of work.\n        if(namesystem.isInSafeMode()) {\n          return new DatanodeCommand[0];\n        }\n\n        //check lease recovery\n        BlockInfoContiguousUnderConstruction[] blocks \u003d nodeinfo\n            .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n        if (blocks !\u003d null) {\n          BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n              blocks.length);\n          for (BlockInfoContiguousUnderConstruction b : blocks) {\n            final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n            // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n            final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                new ArrayList\u003cDatanodeStorageInfo\u003e(storages.length);\n            for (int i \u003d 0; i \u003c storages.length; i++) {\n              if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                recoveryLocations.add(storages[i]);\n              }\n            }\n            // If we are performing a truncate recovery than set recovery fields\n            // to old block.\n            boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n            boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n            ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                new ExtendedBlock(blockPoolId, b);\n            // If we only get 1 replica after eliminating stale nodes, then choose all\n            // replicas for recovery and let the primary data node handle failures.\n            DatanodeInfo[] recoveryInfos;\n            if (recoveryLocations.size() \u003e 1) {\n              if (recoveryLocations.size() !\u003d storages.length) {\n                LOG.info(\"Skipped stale nodes for recovery : \" +\n                    (storages.length - recoveryLocations.size()));\n              }\n              recoveryInfos \u003d\n                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n            } else {\n              // If too many replicas are stale, then choose all replicas to participate\n              // in block recovery.\n              recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n            }\n            if(truncateRecovery) {\n              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                  b.getTruncateBlock();\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                recoveryBlock));\n            } else {\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                b.getBlockRecoveryId()));\n            }\n          }\n          return new DatanodeCommand[] { brCommand };\n        }\n\n        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003cDatanodeCommand\u003e();\n        //check pending replication\n        List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n              maxTransfers);\n        if (pendingList !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n        //check block invalidation\n        Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n        if (blks !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n              blockPoolId, blks));\n        }\n        boolean sendingCachingCommands \u003d false;\n        long nowMs \u003d Time.monotonicNow();\n        if (shouldSendCachingCommands \u0026\u0026 \n            ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                timeBetweenResendingCachingDirectivesMs)) {\n          DatanodeCommand pendingCacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                DatanodeProtocol.DNA_CACHE, blockPoolId);\n          if (pendingCacheCommand !\u003d null) {\n            cmds.add(pendingCacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          DatanodeCommand pendingUncacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n          if (pendingUncacheCommand !\u003d null) {\n            cmds.add(pendingUncacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          if (sendingCachingCommands) {\n            nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n          }\n        }\n\n        blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n        // check for balancer bandwidth update\n        if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n          cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n          // set back to 0 to indicate that datanode has been sent the new value\n          nodeinfo.setBalancerBandwidth(0);\n        }\n\n        if (!cmds.isEmpty()) {\n          return cmds.toArray(new DatanodeCommand[cmds.size()]);\n        }\n      }\n    }\n\n    return new DatanodeCommand[0];\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7743. Code cleanup of BlockInfo and rename BlockInfo to BlockInfoContiguous. Contributed by Jing Zhao.\n",
      "commitDate": "08/02/15 11:51 AM",
      "commitName": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "03/02/15 3:01 PM",
      "commitNameOld": "3ae38ec7dfa1aaf451cf889cec6cf862379af32a",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 4.87,
      "commitsBetweenForRepo": 58,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,141 +1,141 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes\n       ) throws IOException {\n     synchronized (heartbeatManager) {\n       synchronized (datanodeMap) {\n         DatanodeDescriptor nodeinfo \u003d null;\n         try {\n           nodeinfo \u003d getDatanode(nodeReg);\n         } catch(UnregisteredNodeException e) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n         \n         // Check if this datanode should actually be shutdown instead. \n         if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n           setDatanodeDead(nodeinfo);\n           throw new DisallowedDatanodeException(nodeinfo);\n         }\n \n         if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n \n         heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                          cacheCapacity, cacheUsed,\n                                          xceiverCount, failedVolumes);\n \n         // If we are in safemode, do not send back any recovery / replication\n         // requests. Don\u0027t even drain the existing queue of work.\n         if(namesystem.isInSafeMode()) {\n           return new DatanodeCommand[0];\n         }\n \n         //check lease recovery\n-        BlockInfoUnderConstruction[] blocks \u003d nodeinfo\n+        BlockInfoContiguousUnderConstruction[] blocks \u003d nodeinfo\n             .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n         if (blocks !\u003d null) {\n           BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n               blocks.length);\n-          for (BlockInfoUnderConstruction b : blocks) {\n+          for (BlockInfoContiguousUnderConstruction b : blocks) {\n             final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n             // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n             final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                 new ArrayList\u003cDatanodeStorageInfo\u003e(storages.length);\n             for (int i \u003d 0; i \u003c storages.length; i++) {\n               if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                 recoveryLocations.add(storages[i]);\n               }\n             }\n             // If we are performing a truncate recovery than set recovery fields\n             // to old block.\n             boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n             boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                 b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n             ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                 new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                 new ExtendedBlock(blockPoolId, b);\n             // If we only get 1 replica after eliminating stale nodes, then choose all\n             // replicas for recovery and let the primary data node handle failures.\n             DatanodeInfo[] recoveryInfos;\n             if (recoveryLocations.size() \u003e 1) {\n               if (recoveryLocations.size() !\u003d storages.length) {\n                 LOG.info(\"Skipped stale nodes for recovery : \" +\n                     (storages.length - recoveryLocations.size()));\n               }\n               recoveryInfos \u003d\n                   DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n             } else {\n               // If too many replicas are stale, then choose all replicas to participate\n               // in block recovery.\n               recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n             }\n             if(truncateRecovery) {\n               Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                   b.getTruncateBlock();\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 recoveryBlock));\n             } else {\n               brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                 b.getBlockRecoveryId()));\n             }\n           }\n           return new DatanodeCommand[] { brCommand };\n         }\n \n         final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003cDatanodeCommand\u003e();\n         //check pending replication\n         List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n               maxTransfers);\n         if (pendingList !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n               pendingList));\n         }\n         //check block invalidation\n         Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n         if (blks !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n               blockPoolId, blks));\n         }\n         boolean sendingCachingCommands \u003d false;\n         long nowMs \u003d Time.monotonicNow();\n         if (shouldSendCachingCommands \u0026\u0026 \n             ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                 timeBetweenResendingCachingDirectivesMs)) {\n           DatanodeCommand pendingCacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                 DatanodeProtocol.DNA_CACHE, blockPoolId);\n           if (pendingCacheCommand !\u003d null) {\n             cmds.add(pendingCacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           DatanodeCommand pendingUncacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                 DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n           if (pendingUncacheCommand !\u003d null) {\n             cmds.add(pendingUncacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           if (sendingCachingCommands) {\n             nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n           }\n         }\n \n         blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n         // check for balancer bandwidth update\n         if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n           cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n           // set back to 0 to indicate that datanode has been sent the new value\n           nodeinfo.setBalancerBandwidth(0);\n         }\n \n         if (!cmds.isEmpty()) {\n           return cmds.toArray(new DatanodeCommand[cmds.size()]);\n         }\n       }\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes\n      ) throws IOException {\n    synchronized (heartbeatManager) {\n      synchronized (datanodeMap) {\n        DatanodeDescriptor nodeinfo \u003d null;\n        try {\n          nodeinfo \u003d getDatanode(nodeReg);\n        } catch(UnregisteredNodeException e) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n        \n        // Check if this datanode should actually be shutdown instead. \n        if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n          setDatanodeDead(nodeinfo);\n          throw new DisallowedDatanodeException(nodeinfo);\n        }\n\n        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n\n        heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                         cacheCapacity, cacheUsed,\n                                         xceiverCount, failedVolumes);\n\n        // If we are in safemode, do not send back any recovery / replication\n        // requests. Don\u0027t even drain the existing queue of work.\n        if(namesystem.isInSafeMode()) {\n          return new DatanodeCommand[0];\n        }\n\n        //check lease recovery\n        BlockInfoContiguousUnderConstruction[] blocks \u003d nodeinfo\n            .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n        if (blocks !\u003d null) {\n          BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n              blocks.length);\n          for (BlockInfoContiguousUnderConstruction b : blocks) {\n            final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n            // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n            final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                new ArrayList\u003cDatanodeStorageInfo\u003e(storages.length);\n            for (int i \u003d 0; i \u003c storages.length; i++) {\n              if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                recoveryLocations.add(storages[i]);\n              }\n            }\n            // If we are performing a truncate recovery than set recovery fields\n            // to old block.\n            boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n            boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n            ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                new ExtendedBlock(blockPoolId, b);\n            // If we only get 1 replica after eliminating stale nodes, then choose all\n            // replicas for recovery and let the primary data node handle failures.\n            DatanodeInfo[] recoveryInfos;\n            if (recoveryLocations.size() \u003e 1) {\n              if (recoveryLocations.size() !\u003d storages.length) {\n                LOG.info(\"Skipped stale nodes for recovery : \" +\n                    (storages.length - recoveryLocations.size()));\n              }\n              recoveryInfos \u003d\n                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n            } else {\n              // If too many replicas are stale, then choose all replicas to participate\n              // in block recovery.\n              recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n            }\n            if(truncateRecovery) {\n              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                  b.getTruncateBlock();\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                recoveryBlock));\n            } else {\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                b.getBlockRecoveryId()));\n            }\n          }\n          return new DatanodeCommand[] { brCommand };\n        }\n\n        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003cDatanodeCommand\u003e();\n        //check pending replication\n        List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n              maxTransfers);\n        if (pendingList !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n        //check block invalidation\n        Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n        if (blks !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n              blockPoolId, blks));\n        }\n        boolean sendingCachingCommands \u003d false;\n        long nowMs \u003d Time.monotonicNow();\n        if (shouldSendCachingCommands \u0026\u0026 \n            ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                timeBetweenResendingCachingDirectivesMs)) {\n          DatanodeCommand pendingCacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                DatanodeProtocol.DNA_CACHE, blockPoolId);\n          if (pendingCacheCommand !\u003d null) {\n            cmds.add(pendingCacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          DatanodeCommand pendingUncacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n          if (pendingUncacheCommand !\u003d null) {\n            cmds.add(pendingUncacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          if (sendingCachingCommands) {\n            nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n          }\n        }\n\n        blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n        // check for balancer bandwidth update\n        if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n          cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n          // set back to 0 to indicate that datanode has been sent the new value\n          nodeinfo.setBalancerBandwidth(0);\n        }\n\n        if (!cmds.isEmpty()) {\n          return cmds.toArray(new DatanodeCommand[cmds.size()]);\n        }\n      }\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "08ac06283a3e9bf0d49d873823aabd419b08e41f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7056. Snapshot support for truncate. Contributed by Konstantin Shvachko and Plamen Jeliazkov.",
      "commitDate": "13/01/15 12:24 AM",
      "commitName": "08ac06283a3e9bf0d49d873823aabd419b08e41f",
      "commitAuthor": "Konstantin V Shvachko",
      "commitDateOld": "12/01/15 10:50 PM",
      "commitNameOld": "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
      "commitAuthorOld": "Plamen Jeliazkov",
      "daysBetweenCommits": 0.07,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,130 +1,141 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes\n       ) throws IOException {\n     synchronized (heartbeatManager) {\n       synchronized (datanodeMap) {\n         DatanodeDescriptor nodeinfo \u003d null;\n         try {\n           nodeinfo \u003d getDatanode(nodeReg);\n         } catch(UnregisteredNodeException e) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n         \n         // Check if this datanode should actually be shutdown instead. \n         if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n           setDatanodeDead(nodeinfo);\n           throw new DisallowedDatanodeException(nodeinfo);\n         }\n \n         if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n \n         heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                          cacheCapacity, cacheUsed,\n                                          xceiverCount, failedVolumes);\n \n         // If we are in safemode, do not send back any recovery / replication\n         // requests. Don\u0027t even drain the existing queue of work.\n         if(namesystem.isInSafeMode()) {\n           return new DatanodeCommand[0];\n         }\n \n         //check lease recovery\n         BlockInfoUnderConstruction[] blocks \u003d nodeinfo\n             .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n         if (blocks !\u003d null) {\n           BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n               blocks.length);\n           for (BlockInfoUnderConstruction b : blocks) {\n             final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n             // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n             final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                 new ArrayList\u003cDatanodeStorageInfo\u003e(storages.length);\n             for (int i \u003d 0; i \u003c storages.length; i++) {\n               if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                 recoveryLocations.add(storages[i]);\n               }\n             }\n+            // If we are performing a truncate recovery than set recovery fields\n+            // to old block.\n+            boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n+            boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n+                b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n+            ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n+                new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n+                new ExtendedBlock(blockPoolId, b);\n             // If we only get 1 replica after eliminating stale nodes, then choose all\n             // replicas for recovery and let the primary data node handle failures.\n+            DatanodeInfo[] recoveryInfos;\n             if (recoveryLocations.size() \u003e 1) {\n               if (recoveryLocations.size() !\u003d storages.length) {\n                 LOG.info(\"Skipped stale nodes for recovery : \" +\n                     (storages.length - recoveryLocations.size()));\n               }\n-              boolean isTruncate \u003d b.getBlockUCState().equals(\n-                  HdfsServerConstants.BlockUCState.BEING_TRUNCATED);\n-              brCommand.add(new RecoveringBlock(\n-                  new ExtendedBlock(blockPoolId, b),\n-                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations),\n-                  b.getBlockRecoveryId(), isTruncate));\n+              recoveryInfos \u003d\n+                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n             } else {\n               // If too many replicas are stale, then choose all replicas to participate\n               // in block recovery.\n-              brCommand.add(new RecoveringBlock(\n-                  new ExtendedBlock(blockPoolId, b),\n-                  DatanodeStorageInfo.toDatanodeInfos(storages),\n-                  b.getBlockRecoveryId()));\n+              recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n+            }\n+            if(truncateRecovery) {\n+              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n+                  b.getTruncateBlock();\n+              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n+                                                recoveryBlock));\n+            } else {\n+              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n+                                                b.getBlockRecoveryId()));\n             }\n           }\n           return new DatanodeCommand[] { brCommand };\n         }\n \n         final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003cDatanodeCommand\u003e();\n         //check pending replication\n         List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n               maxTransfers);\n         if (pendingList !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n               pendingList));\n         }\n         //check block invalidation\n         Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n         if (blks !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n               blockPoolId, blks));\n         }\n         boolean sendingCachingCommands \u003d false;\n         long nowMs \u003d Time.monotonicNow();\n         if (shouldSendCachingCommands \u0026\u0026 \n             ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                 timeBetweenResendingCachingDirectivesMs)) {\n           DatanodeCommand pendingCacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                 DatanodeProtocol.DNA_CACHE, blockPoolId);\n           if (pendingCacheCommand !\u003d null) {\n             cmds.add(pendingCacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           DatanodeCommand pendingUncacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                 DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n           if (pendingUncacheCommand !\u003d null) {\n             cmds.add(pendingUncacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           if (sendingCachingCommands) {\n             nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n           }\n         }\n \n         blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n         // check for balancer bandwidth update\n         if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n           cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n           // set back to 0 to indicate that datanode has been sent the new value\n           nodeinfo.setBalancerBandwidth(0);\n         }\n \n         if (!cmds.isEmpty()) {\n           return cmds.toArray(new DatanodeCommand[cmds.size()]);\n         }\n       }\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes\n      ) throws IOException {\n    synchronized (heartbeatManager) {\n      synchronized (datanodeMap) {\n        DatanodeDescriptor nodeinfo \u003d null;\n        try {\n          nodeinfo \u003d getDatanode(nodeReg);\n        } catch(UnregisteredNodeException e) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n        \n        // Check if this datanode should actually be shutdown instead. \n        if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n          setDatanodeDead(nodeinfo);\n          throw new DisallowedDatanodeException(nodeinfo);\n        }\n\n        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n\n        heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                         cacheCapacity, cacheUsed,\n                                         xceiverCount, failedVolumes);\n\n        // If we are in safemode, do not send back any recovery / replication\n        // requests. Don\u0027t even drain the existing queue of work.\n        if(namesystem.isInSafeMode()) {\n          return new DatanodeCommand[0];\n        }\n\n        //check lease recovery\n        BlockInfoUnderConstruction[] blocks \u003d nodeinfo\n            .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n        if (blocks !\u003d null) {\n          BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n              blocks.length);\n          for (BlockInfoUnderConstruction b : blocks) {\n            final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n            // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n            final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                new ArrayList\u003cDatanodeStorageInfo\u003e(storages.length);\n            for (int i \u003d 0; i \u003c storages.length; i++) {\n              if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                recoveryLocations.add(storages[i]);\n              }\n            }\n            // If we are performing a truncate recovery than set recovery fields\n            // to old block.\n            boolean truncateRecovery \u003d b.getTruncateBlock() !\u003d null;\n            boolean copyOnTruncateRecovery \u003d truncateRecovery \u0026\u0026\n                b.getTruncateBlock().getBlockId() !\u003d b.getBlockId();\n            ExtendedBlock primaryBlock \u003d (copyOnTruncateRecovery) ?\n                new ExtendedBlock(blockPoolId, b.getTruncateBlock()) :\n                new ExtendedBlock(blockPoolId, b);\n            // If we only get 1 replica after eliminating stale nodes, then choose all\n            // replicas for recovery and let the primary data node handle failures.\n            DatanodeInfo[] recoveryInfos;\n            if (recoveryLocations.size() \u003e 1) {\n              if (recoveryLocations.size() !\u003d storages.length) {\n                LOG.info(\"Skipped stale nodes for recovery : \" +\n                    (storages.length - recoveryLocations.size()));\n              }\n              recoveryInfos \u003d\n                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);\n            } else {\n              // If too many replicas are stale, then choose all replicas to participate\n              // in block recovery.\n              recoveryInfos \u003d DatanodeStorageInfo.toDatanodeInfos(storages);\n            }\n            if(truncateRecovery) {\n              Block recoveryBlock \u003d (copyOnTruncateRecovery) ? b :\n                  b.getTruncateBlock();\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                recoveryBlock));\n            } else {\n              brCommand.add(new RecoveringBlock(primaryBlock, recoveryInfos,\n                                                b.getBlockRecoveryId()));\n            }\n          }\n          return new DatanodeCommand[] { brCommand };\n        }\n\n        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003cDatanodeCommand\u003e();\n        //check pending replication\n        List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n              maxTransfers);\n        if (pendingList !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n        //check block invalidation\n        Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n        if (blks !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n              blockPoolId, blks));\n        }\n        boolean sendingCachingCommands \u003d false;\n        long nowMs \u003d Time.monotonicNow();\n        if (shouldSendCachingCommands \u0026\u0026 \n            ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                timeBetweenResendingCachingDirectivesMs)) {\n          DatanodeCommand pendingCacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                DatanodeProtocol.DNA_CACHE, blockPoolId);\n          if (pendingCacheCommand !\u003d null) {\n            cmds.add(pendingCacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          DatanodeCommand pendingUncacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n          if (pendingUncacheCommand !\u003d null) {\n            cmds.add(pendingUncacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          if (sendingCachingCommands) {\n            nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n          }\n        }\n\n        blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n        // check for balancer bandwidth update\n        if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n          cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n          // set back to 0 to indicate that datanode has been sent the new value\n          nodeinfo.setBalancerBandwidth(0);\n        }\n\n        if (!cmds.isEmpty()) {\n          return cmds.toArray(new DatanodeCommand[cmds.size()]);\n        }\n      }\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3107. Introduce truncate. Contributed by Plamen Jeliazkov.",
      "commitDate": "12/01/15 10:50 PM",
      "commitName": "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
      "commitAuthor": "Plamen Jeliazkov",
      "commitDateOld": "16/12/14 8:30 AM",
      "commitNameOld": "b7923a356e9f111619375b94d12749d634069347",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 27.6,
      "commitsBetweenForRepo": 132,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,128 +1,130 @@\n   public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, final String blockPoolId,\n       long cacheCapacity, long cacheUsed, int xceiverCount, \n       int maxTransfers, int failedVolumes\n       ) throws IOException {\n     synchronized (heartbeatManager) {\n       synchronized (datanodeMap) {\n         DatanodeDescriptor nodeinfo \u003d null;\n         try {\n           nodeinfo \u003d getDatanode(nodeReg);\n         } catch(UnregisteredNodeException e) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n         \n         // Check if this datanode should actually be shutdown instead. \n         if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n           setDatanodeDead(nodeinfo);\n           throw new DisallowedDatanodeException(nodeinfo);\n         }\n \n         if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n           return new DatanodeCommand[]{RegisterCommand.REGISTER};\n         }\n \n         heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                          cacheCapacity, cacheUsed,\n                                          xceiverCount, failedVolumes);\n \n         // If we are in safemode, do not send back any recovery / replication\n         // requests. Don\u0027t even drain the existing queue of work.\n         if(namesystem.isInSafeMode()) {\n           return new DatanodeCommand[0];\n         }\n \n         //check lease recovery\n         BlockInfoUnderConstruction[] blocks \u003d nodeinfo\n             .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n         if (blocks !\u003d null) {\n           BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n               blocks.length);\n           for (BlockInfoUnderConstruction b : blocks) {\n             final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n             // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n             final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                 new ArrayList\u003cDatanodeStorageInfo\u003e(storages.length);\n             for (int i \u003d 0; i \u003c storages.length; i++) {\n               if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                 recoveryLocations.add(storages[i]);\n               }\n             }\n             // If we only get 1 replica after eliminating stale nodes, then choose all\n             // replicas for recovery and let the primary data node handle failures.\n             if (recoveryLocations.size() \u003e 1) {\n               if (recoveryLocations.size() !\u003d storages.length) {\n                 LOG.info(\"Skipped stale nodes for recovery : \" +\n                     (storages.length - recoveryLocations.size()));\n               }\n+              boolean isTruncate \u003d b.getBlockUCState().equals(\n+                  HdfsServerConstants.BlockUCState.BEING_TRUNCATED);\n               brCommand.add(new RecoveringBlock(\n                   new ExtendedBlock(blockPoolId, b),\n                   DatanodeStorageInfo.toDatanodeInfos(recoveryLocations),\n-                  b.getBlockRecoveryId()));\n+                  b.getBlockRecoveryId(), isTruncate));\n             } else {\n               // If too many replicas are stale, then choose all replicas to participate\n               // in block recovery.\n               brCommand.add(new RecoveringBlock(\n                   new ExtendedBlock(blockPoolId, b),\n                   DatanodeStorageInfo.toDatanodeInfos(storages),\n                   b.getBlockRecoveryId()));\n             }\n           }\n           return new DatanodeCommand[] { brCommand };\n         }\n \n         final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003cDatanodeCommand\u003e();\n         //check pending replication\n         List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n               maxTransfers);\n         if (pendingList !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n               pendingList));\n         }\n         //check block invalidation\n         Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n         if (blks !\u003d null) {\n           cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n               blockPoolId, blks));\n         }\n         boolean sendingCachingCommands \u003d false;\n         long nowMs \u003d Time.monotonicNow();\n         if (shouldSendCachingCommands \u0026\u0026 \n             ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                 timeBetweenResendingCachingDirectivesMs)) {\n           DatanodeCommand pendingCacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                 DatanodeProtocol.DNA_CACHE, blockPoolId);\n           if (pendingCacheCommand !\u003d null) {\n             cmds.add(pendingCacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           DatanodeCommand pendingUncacheCommand \u003d\n               getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                 DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n           if (pendingUncacheCommand !\u003d null) {\n             cmds.add(pendingUncacheCommand);\n             sendingCachingCommands \u003d true;\n           }\n           if (sendingCachingCommands) {\n             nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n           }\n         }\n \n         blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n \n         // check for balancer bandwidth update\n         if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n           cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n           // set back to 0 to indicate that datanode has been sent the new value\n           nodeinfo.setBalancerBandwidth(0);\n         }\n \n         if (!cmds.isEmpty()) {\n           return cmds.toArray(new DatanodeCommand[cmds.size()]);\n         }\n       }\n     }\n \n     return new DatanodeCommand[0];\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, final String blockPoolId,\n      long cacheCapacity, long cacheUsed, int xceiverCount, \n      int maxTransfers, int failedVolumes\n      ) throws IOException {\n    synchronized (heartbeatManager) {\n      synchronized (datanodeMap) {\n        DatanodeDescriptor nodeinfo \u003d null;\n        try {\n          nodeinfo \u003d getDatanode(nodeReg);\n        } catch(UnregisteredNodeException e) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n        \n        // Check if this datanode should actually be shutdown instead. \n        if (nodeinfo !\u003d null \u0026\u0026 nodeinfo.isDisallowed()) {\n          setDatanodeDead(nodeinfo);\n          throw new DisallowedDatanodeException(nodeinfo);\n        }\n\n        if (nodeinfo \u003d\u003d null || !nodeinfo.isAlive) {\n          return new DatanodeCommand[]{RegisterCommand.REGISTER};\n        }\n\n        heartbeatManager.updateHeartbeat(nodeinfo, reports,\n                                         cacheCapacity, cacheUsed,\n                                         xceiverCount, failedVolumes);\n\n        // If we are in safemode, do not send back any recovery / replication\n        // requests. Don\u0027t even drain the existing queue of work.\n        if(namesystem.isInSafeMode()) {\n          return new DatanodeCommand[0];\n        }\n\n        //check lease recovery\n        BlockInfoUnderConstruction[] blocks \u003d nodeinfo\n            .getLeaseRecoveryCommand(Integer.MAX_VALUE);\n        if (blocks !\u003d null) {\n          BlockRecoveryCommand brCommand \u003d new BlockRecoveryCommand(\n              blocks.length);\n          for (BlockInfoUnderConstruction b : blocks) {\n            final DatanodeStorageInfo[] storages \u003d b.getExpectedStorageLocations();\n            // Skip stale nodes during recovery - not heart beated for some time (30s by default).\n            final List\u003cDatanodeStorageInfo\u003e recoveryLocations \u003d\n                new ArrayList\u003cDatanodeStorageInfo\u003e(storages.length);\n            for (int i \u003d 0; i \u003c storages.length; i++) {\n              if (!storages[i].getDatanodeDescriptor().isStale(staleInterval)) {\n                recoveryLocations.add(storages[i]);\n              }\n            }\n            // If we only get 1 replica after eliminating stale nodes, then choose all\n            // replicas for recovery and let the primary data node handle failures.\n            if (recoveryLocations.size() \u003e 1) {\n              if (recoveryLocations.size() !\u003d storages.length) {\n                LOG.info(\"Skipped stale nodes for recovery : \" +\n                    (storages.length - recoveryLocations.size()));\n              }\n              boolean isTruncate \u003d b.getBlockUCState().equals(\n                  HdfsServerConstants.BlockUCState.BEING_TRUNCATED);\n              brCommand.add(new RecoveringBlock(\n                  new ExtendedBlock(blockPoolId, b),\n                  DatanodeStorageInfo.toDatanodeInfos(recoveryLocations),\n                  b.getBlockRecoveryId(), isTruncate));\n            } else {\n              // If too many replicas are stale, then choose all replicas to participate\n              // in block recovery.\n              brCommand.add(new RecoveringBlock(\n                  new ExtendedBlock(blockPoolId, b),\n                  DatanodeStorageInfo.toDatanodeInfos(storages),\n                  b.getBlockRecoveryId()));\n            }\n          }\n          return new DatanodeCommand[] { brCommand };\n        }\n\n        final List\u003cDatanodeCommand\u003e cmds \u003d new ArrayList\u003cDatanodeCommand\u003e();\n        //check pending replication\n        List\u003cBlockTargetPair\u003e pendingList \u003d nodeinfo.getReplicationCommand(\n              maxTransfers);\n        if (pendingList !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_TRANSFER, blockPoolId,\n              pendingList));\n        }\n        //check block invalidation\n        Block[] blks \u003d nodeinfo.getInvalidateBlocks(blockInvalidateLimit);\n        if (blks !\u003d null) {\n          cmds.add(new BlockCommand(DatanodeProtocol.DNA_INVALIDATE,\n              blockPoolId, blks));\n        }\n        boolean sendingCachingCommands \u003d false;\n        long nowMs \u003d Time.monotonicNow();\n        if (shouldSendCachingCommands \u0026\u0026 \n            ((nowMs - nodeinfo.getLastCachingDirectiveSentTimeMs()) \u003e\u003d\n                timeBetweenResendingCachingDirectivesMs)) {\n          DatanodeCommand pendingCacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingCached(), nodeinfo,\n                DatanodeProtocol.DNA_CACHE, blockPoolId);\n          if (pendingCacheCommand !\u003d null) {\n            cmds.add(pendingCacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          DatanodeCommand pendingUncacheCommand \u003d\n              getCacheCommand(nodeinfo.getPendingUncached(), nodeinfo,\n                DatanodeProtocol.DNA_UNCACHE, blockPoolId);\n          if (pendingUncacheCommand !\u003d null) {\n            cmds.add(pendingUncacheCommand);\n            sendingCachingCommands \u003d true;\n          }\n          if (sendingCachingCommands) {\n            nodeinfo.setLastCachingDirectiveSentTimeMs(nowMs);\n          }\n        }\n\n        blockManager.addKeyUpdateCommand(cmds, nodeinfo);\n\n        // check for balancer bandwidth update\n        if (nodeinfo.getBalancerBandwidth() \u003e 0) {\n          cmds.add(new BalancerBandwidthCommand(nodeinfo.getBalancerBandwidth()));\n          // set back to 0 to indicate that datanode has been sent the new value\n          nodeinfo.setBalancerBandwidth(0);\n        }\n\n        if (!cmds.isEmpty()) {\n          return cmds.toArray(new DatanodeCommand[cmds.size()]);\n        }\n      }\n    }\n\n    return new DatanodeCommand[0];\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    }
  }
}