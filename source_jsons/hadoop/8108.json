{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ImageServlet.java",
  "functionName": "run",
  "functionId": "run",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageServlet.java",
  "functionStartLine": 131,
  "functionEndLine": 179,
  "numCommitsSeen": 68,
  "timeTaken": 9464,
  "changeHistory": [
    "7bb902bc0d0c62d63a8960db444de3abb0a6ad22",
    "65c4660bcd897e139fc175ca438cff75ec0c6be8",
    "5e6cc6fe8a11a638ba98913ca402efdc988fe73a",
    "49dfad942970459297f72632ed8dfd353e0c86de",
    "d3268c4b10a0f728b554ddb6d69b666a9ca13f12",
    "193f11a7ab539c360ecd9f2015c0f46cd070a875",
    "94a1632fcb677fda6f4d812614026417f1d0a360",
    "dbd22b23c2d68b97b4da47215897906f06f978e3",
    "0f595915a388305edbb3ce928415571811d304e8",
    "e9a17c8ce0656a4e5d47401ca22a575c5f5f66db",
    "e3d2e4c156851de7dac16154521a2e06ea83ec7b",
    "4f9bbaa301194e3d20972a10f51638c7f4d121f0",
    "0fc2929d13435a71d759f29579a7a171dc05990d",
    "045dc880e13271737b3cf316296e92fb95806663",
    "45b9d19f9d2b14e4d3c386af9de3df817da3c9df",
    "3728d16160118a4b6e632a59fb1e2e0795ca6595",
    "8bab8b775240818b60935531dd2b27144ed8edc1",
    "5dbbe0e0a5d31689d3425e490865f95057dc051c",
    "cbc242429093ccabf76248f857de5e587a9682b0",
    "ce1a7ec9755f17527c29b0db713d7e01750e10c9",
    "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "7bb902bc0d0c62d63a8960db444de3abb0a6ad22": "Ybodychange",
    "65c4660bcd897e139fc175ca438cff75ec0c6be8": "Ybodychange",
    "5e6cc6fe8a11a638ba98913ca402efdc988fe73a": "Ybodychange",
    "49dfad942970459297f72632ed8dfd353e0c86de": "Ybodychange",
    "d3268c4b10a0f728b554ddb6d69b666a9ca13f12": "Ybodychange",
    "193f11a7ab539c360ecd9f2015c0f46cd070a875": "Ybodychange",
    "94a1632fcb677fda6f4d812614026417f1d0a360": "Ymultichange(Yfilerename,Ybodychange)",
    "dbd22b23c2d68b97b4da47215897906f06f978e3": "Ymultichange(Yfilerename,Ybodychange)",
    "0f595915a388305edbb3ce928415571811d304e8": "Ymultichange(Ymovefromfile,Ybodychange)",
    "e9a17c8ce0656a4e5d47401ca22a575c5f5f66db": "Ybodychange",
    "e3d2e4c156851de7dac16154521a2e06ea83ec7b": "Ybodychange",
    "4f9bbaa301194e3d20972a10f51638c7f4d121f0": "Ybodychange",
    "0fc2929d13435a71d759f29579a7a171dc05990d": "Ybodychange",
    "045dc880e13271737b3cf316296e92fb95806663": "Ybodychange",
    "45b9d19f9d2b14e4d3c386af9de3df817da3c9df": "Ybodychange",
    "3728d16160118a4b6e632a59fb1e2e0795ca6595": "Ybodychange",
    "8bab8b775240818b60935531dd2b27144ed8edc1": "Ybodychange",
    "5dbbe0e0a5d31689d3425e490865f95057dc051c": "Ybodychange",
    "cbc242429093ccabf76248f857de5e587a9682b0": "Ybodychange",
    "ce1a7ec9755f17527c29b0db713d7e01750e10c9": "Ybodychange",
    "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "7bb902bc0d0c62d63a8960db444de3abb0a6ad22": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15293. Relax the condition for accepting a fsimage when receiving a checkpoint. Contributed by Chen Liang\n",
      "commitDate": "18/05/20 10:58 AM",
      "commitName": "7bb902bc0d0c62d63a8960db444de3abb0a6ad22",
      "commitAuthor": "Chen Liang",
      "commitDateOld": "12/12/19 10:22 AM",
      "commitNameOld": "65c4660bcd897e139fc175ca438cff75ec0c6be8",
      "commitAuthorOld": "Chen Liang",
      "daysBetweenCommits": 157.98,
      "commitsBetweenForRepo": 520,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,117 +1,123 @@\n             public Void run() throws Exception {\n               // if its not the active NN, then we need to notify the caller it was was the wrong\n               // target (regardless of the fact that we got the image)\n               HAServiceProtocol.HAServiceState state \u003d NameNodeHttpServer\n                   .getNameNodeStateFromContext(getServletContext());\n               if (state !\u003d HAServiceProtocol.HAServiceState.ACTIVE \u0026\u0026\n                   state !\u003d HAServiceProtocol.HAServiceState.OBSERVER) {\n                 // we need a different response type here so the client can differentiate this\n                 // from the failure to upload due to (1) security, or (2) other checkpoints already\n                 // present\n                 response.sendError(HttpServletResponse.SC_EXPECTATION_FAILED,\n                     \"Nameode \"+request.getLocalAddr()+\" is currently not in a state which can \"\n                         + \"accept uploads of new fsimages. State: \"+state);\n                 return null;\n               }\n \n               final long txid \u003d parsedParams.getTxId();\n               String remoteAddr \u003d request.getRemoteAddr();\n               ImageUploadRequest imageRequest \u003d new ImageUploadRequest(txid, remoteAddr);\n \n               final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n \n               // if the node is attempting to upload an older transaction, we ignore it\n               SortedSet\u003cImageUploadRequest\u003e larger \u003d currentlyDownloadingCheckpoints.tailSet(imageRequest);\n               if (larger.size() \u003e 0) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Another checkpointer is already in the process of uploading a\" +\n                         \" checkpoint made up to transaction ID \" + larger.last());\n                 return null;\n               }\n \n               //make sure no one else has started uploading one\n               if (!currentlyDownloadingCheckpoints.add(imageRequest)) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Either current namenode is checkpointing or another\"\n                         + \" checkpointer is already in the process of \"\n                         + \"uploading a checkpoint made at transaction ID \"\n                         + txid);\n                 return null;\n               }\n \n               long now \u003d System.currentTimeMillis();\n               long lastCheckpointTime \u003d\n                   nnImage.getStorage().getMostRecentCheckpointTime();\n               long lastCheckpointTxid \u003d\n                   nnImage.getStorage().getMostRecentCheckpointTxId();\n \n               long checkpointPeriod \u003d\n                   conf.getTimeDuration(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n                       DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT, TimeUnit.SECONDS);\n+              checkpointPeriod \u003d Math.round(\n+                  checkpointPeriod * recentImageCheckTimePrecision);\n+\n               long checkpointTxnCount \u003d\n                   conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n                       DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n \n               long timeDelta \u003d TimeUnit.MILLISECONDS.toSeconds(\n                   now - lastCheckpointTime);\n \n               // Since the goal of the check below is to prevent overly\n               // frequent upload from Standby, the check should only be done\n               // for the periodical upload from Standby. For the other\n               // scenarios such as rollback image and ckpt file, they skip\n               // this check, see HDFS-15036 for more info.\n               if (checkRecentImageEnable \u0026\u0026\n                   NameNodeFile.IMAGE.equals(parsedParams.getNameNodeFile()) \u0026\u0026\n                   timeDelta \u003c checkpointPeriod \u0026\u0026\n                   txid - lastCheckpointTxid \u003c checkpointTxnCount) {\n                 // only when at least one of two conditions are met we accept\n                 // a new fsImage\n                 // 1. most recent image\u0027s txid is too far behind\n                 // 2. last checkpoint time was too old\n-                response.sendError(HttpServletResponse.SC_CONFLICT,\n-                    \"Most recent checkpoint is neither too far behind in \"\n-                        + \"txid, nor too old. New txnid cnt is \"\n-                        + (txid - lastCheckpointTxid)\n-                        + \", expecting at least \" + checkpointTxnCount\n-                        + \" unless too long since last upload.\");\n+                String message \u003d \"Rejecting a fsimage due to small time delta \"\n+                    + \"and txnid delta. Time since previous checkpoint is \"\n+                    + timeDelta + \" expecting at least \" + checkpointPeriod\n+                    + \" txnid delta since previous checkpoint is \" +\n+                    (txid - lastCheckpointTxid) + \" expecting at least \"\n+                    + checkpointTxnCount;\n+                LOG.info(message);\n+                response.sendError(HttpServletResponse.SC_CONFLICT, message);\n                 return null;\n               }\n \n               try {\n                 if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n-                  response.sendError(HttpServletResponse.SC_CONFLICT,\n-                      \"Either current namenode has checkpointed or \"\n-                          + \"another checkpointer already uploaded an \"\n-                          + \"checkpoint for txid \" + txid);\n+                  String message \u003d \"Either current namenode has checkpointed or \"\n+                      + \"another checkpointer already uploaded an \"\n+                      + \"checkpoint for txid \" + txid;\n+                  LOG.info(message);\n+                  response.sendError(HttpServletResponse.SC_CONFLICT, message);\n                   return null;\n                 }\n \n                 InputStream stream \u003d request.getInputStream();\n                 try {\n                   long start \u003d monotonicNow();\n                   MD5Hash downloadImageDigest \u003d TransferFsImage\n                       .handleUploadImageRequest(request, txid,\n                           nnImage.getStorage(), stream,\n                           parsedParams.getFileSize(), getThrottler(conf));\n                   nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                       downloadImageDigest);\n                   // Metrics non-null only when used inside name node\n                   if (metrics !\u003d null) {\n                     long elapsed \u003d monotonicNow() - start;\n                     metrics.addPutImage(elapsed);\n                   }\n                   // Now that we have a new checkpoint, we might be able to\n                   // remove some old ones.\n                   nnImage.purgeOldStorage(nnf);\n                 } finally {\n                   // remove the request once we\u0027ve processed it, or it threw an error, so we\n                   // aren\u0027t using it either\n                   currentlyDownloadingCheckpoints.remove(imageRequest);\n \n                   stream.close();\n                 }\n               } finally {\n                 nnImage.removeFromCheckpointing(txid);\n               }\n               return null;\n             }\n\\ No newline at end of file\n",
      "actualSource": "            public Void run() throws Exception {\n              // if its not the active NN, then we need to notify the caller it was was the wrong\n              // target (regardless of the fact that we got the image)\n              HAServiceProtocol.HAServiceState state \u003d NameNodeHttpServer\n                  .getNameNodeStateFromContext(getServletContext());\n              if (state !\u003d HAServiceProtocol.HAServiceState.ACTIVE \u0026\u0026\n                  state !\u003d HAServiceProtocol.HAServiceState.OBSERVER) {\n                // we need a different response type here so the client can differentiate this\n                // from the failure to upload due to (1) security, or (2) other checkpoints already\n                // present\n                response.sendError(HttpServletResponse.SC_EXPECTATION_FAILED,\n                    \"Nameode \"+request.getLocalAddr()+\" is currently not in a state which can \"\n                        + \"accept uploads of new fsimages. State: \"+state);\n                return null;\n              }\n\n              final long txid \u003d parsedParams.getTxId();\n              String remoteAddr \u003d request.getRemoteAddr();\n              ImageUploadRequest imageRequest \u003d new ImageUploadRequest(txid, remoteAddr);\n\n              final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n\n              // if the node is attempting to upload an older transaction, we ignore it\n              SortedSet\u003cImageUploadRequest\u003e larger \u003d currentlyDownloadingCheckpoints.tailSet(imageRequest);\n              if (larger.size() \u003e 0) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer is already in the process of uploading a\" +\n                        \" checkpoint made up to transaction ID \" + larger.last());\n                return null;\n              }\n\n              //make sure no one else has started uploading one\n              if (!currentlyDownloadingCheckpoints.add(imageRequest)) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Either current namenode is checkpointing or another\"\n                        + \" checkpointer is already in the process of \"\n                        + \"uploading a checkpoint made at transaction ID \"\n                        + txid);\n                return null;\n              }\n\n              long now \u003d System.currentTimeMillis();\n              long lastCheckpointTime \u003d\n                  nnImage.getStorage().getMostRecentCheckpointTime();\n              long lastCheckpointTxid \u003d\n                  nnImage.getStorage().getMostRecentCheckpointTxId();\n\n              long checkpointPeriod \u003d\n                  conf.getTimeDuration(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n                      DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT, TimeUnit.SECONDS);\n              checkpointPeriod \u003d Math.round(\n                  checkpointPeriod * recentImageCheckTimePrecision);\n\n              long checkpointTxnCount \u003d\n                  conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n                      DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n\n              long timeDelta \u003d TimeUnit.MILLISECONDS.toSeconds(\n                  now - lastCheckpointTime);\n\n              // Since the goal of the check below is to prevent overly\n              // frequent upload from Standby, the check should only be done\n              // for the periodical upload from Standby. For the other\n              // scenarios such as rollback image and ckpt file, they skip\n              // this check, see HDFS-15036 for more info.\n              if (checkRecentImageEnable \u0026\u0026\n                  NameNodeFile.IMAGE.equals(parsedParams.getNameNodeFile()) \u0026\u0026\n                  timeDelta \u003c checkpointPeriod \u0026\u0026\n                  txid - lastCheckpointTxid \u003c checkpointTxnCount) {\n                // only when at least one of two conditions are met we accept\n                // a new fsImage\n                // 1. most recent image\u0027s txid is too far behind\n                // 2. last checkpoint time was too old\n                String message \u003d \"Rejecting a fsimage due to small time delta \"\n                    + \"and txnid delta. Time since previous checkpoint is \"\n                    + timeDelta + \" expecting at least \" + checkpointPeriod\n                    + \" txnid delta since previous checkpoint is \" +\n                    (txid - lastCheckpointTxid) + \" expecting at least \"\n                    + checkpointTxnCount;\n                LOG.info(message);\n                response.sendError(HttpServletResponse.SC_CONFLICT, message);\n                return null;\n              }\n\n              try {\n                if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                  String message \u003d \"Either current namenode has checkpointed or \"\n                      + \"another checkpointer already uploaded an \"\n                      + \"checkpoint for txid \" + txid;\n                  LOG.info(message);\n                  response.sendError(HttpServletResponse.SC_CONFLICT, message);\n                  return null;\n                }\n\n                InputStream stream \u003d request.getInputStream();\n                try {\n                  long start \u003d monotonicNow();\n                  MD5Hash downloadImageDigest \u003d TransferFsImage\n                      .handleUploadImageRequest(request, txid,\n                          nnImage.getStorage(), stream,\n                          parsedParams.getFileSize(), getThrottler(conf));\n                  nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                      downloadImageDigest);\n                  // Metrics non-null only when used inside name node\n                  if (metrics !\u003d null) {\n                    long elapsed \u003d monotonicNow() - start;\n                    metrics.addPutImage(elapsed);\n                  }\n                  // Now that we have a new checkpoint, we might be able to\n                  // remove some old ones.\n                  nnImage.purgeOldStorage(nnf);\n                } finally {\n                  // remove the request once we\u0027ve processed it, or it threw an error, so we\n                  // aren\u0027t using it either\n                  currentlyDownloadingCheckpoints.remove(imageRequest);\n\n                  stream.close();\n                }\n              } finally {\n                nnImage.removeFromCheckpointing(txid);\n              }\n              return null;\n            }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageServlet.java",
      "extendedDetails": {}
    },
    "65c4660bcd897e139fc175ca438cff75ec0c6be8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15036. Active NameNode should not silently fail the image transfer. Contributed by Chen Liang.\n",
      "commitDate": "12/12/19 10:22 AM",
      "commitName": "65c4660bcd897e139fc175ca438cff75ec0c6be8",
      "commitAuthor": "Chen Liang",
      "commitDateOld": "17/07/19 2:37 PM",
      "commitNameOld": "5e6cc6fe8a11a638ba98913ca402efdc988fe73a",
      "commitAuthorOld": "Chen Liang",
      "daysBetweenCommits": 147.86,
      "commitsBetweenForRepo": 996,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,111 +1,117 @@\n             public Void run() throws Exception {\n               // if its not the active NN, then we need to notify the caller it was was the wrong\n               // target (regardless of the fact that we got the image)\n               HAServiceProtocol.HAServiceState state \u003d NameNodeHttpServer\n                   .getNameNodeStateFromContext(getServletContext());\n               if (state !\u003d HAServiceProtocol.HAServiceState.ACTIVE \u0026\u0026\n                   state !\u003d HAServiceProtocol.HAServiceState.OBSERVER) {\n                 // we need a different response type here so the client can differentiate this\n                 // from the failure to upload due to (1) security, or (2) other checkpoints already\n                 // present\n                 response.sendError(HttpServletResponse.SC_EXPECTATION_FAILED,\n                     \"Nameode \"+request.getLocalAddr()+\" is currently not in a state which can \"\n                         + \"accept uploads of new fsimages. State: \"+state);\n                 return null;\n               }\n \n               final long txid \u003d parsedParams.getTxId();\n               String remoteAddr \u003d request.getRemoteAddr();\n               ImageUploadRequest imageRequest \u003d new ImageUploadRequest(txid, remoteAddr);\n \n               final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n \n               // if the node is attempting to upload an older transaction, we ignore it\n               SortedSet\u003cImageUploadRequest\u003e larger \u003d currentlyDownloadingCheckpoints.tailSet(imageRequest);\n               if (larger.size() \u003e 0) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Another checkpointer is already in the process of uploading a\" +\n                         \" checkpoint made up to transaction ID \" + larger.last());\n                 return null;\n               }\n \n               //make sure no one else has started uploading one\n               if (!currentlyDownloadingCheckpoints.add(imageRequest)) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Either current namenode is checkpointing or another\"\n                         + \" checkpointer is already in the process of \"\n                         + \"uploading a checkpoint made at transaction ID \"\n                         + txid);\n                 return null;\n               }\n \n               long now \u003d System.currentTimeMillis();\n               long lastCheckpointTime \u003d\n                   nnImage.getStorage().getMostRecentCheckpointTime();\n               long lastCheckpointTxid \u003d\n                   nnImage.getStorage().getMostRecentCheckpointTxId();\n \n               long checkpointPeriod \u003d\n                   conf.getTimeDuration(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n                       DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT, TimeUnit.SECONDS);\n               long checkpointTxnCount \u003d\n                   conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n                       DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n \n               long timeDelta \u003d TimeUnit.MILLISECONDS.toSeconds(\n                   now - lastCheckpointTime);\n \n+              // Since the goal of the check below is to prevent overly\n+              // frequent upload from Standby, the check should only be done\n+              // for the periodical upload from Standby. For the other\n+              // scenarios such as rollback image and ckpt file, they skip\n+              // this check, see HDFS-15036 for more info.\n               if (checkRecentImageEnable \u0026\u0026\n+                  NameNodeFile.IMAGE.equals(parsedParams.getNameNodeFile()) \u0026\u0026\n                   timeDelta \u003c checkpointPeriod \u0026\u0026\n                   txid - lastCheckpointTxid \u003c checkpointTxnCount) {\n                 // only when at least one of two conditions are met we accept\n                 // a new fsImage\n                 // 1. most recent image\u0027s txid is too far behind\n                 // 2. last checkpoint time was too old\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Most recent checkpoint is neither too far behind in \"\n                         + \"txid, nor too old. New txnid cnt is \"\n                         + (txid - lastCheckpointTxid)\n                         + \", expecting at least \" + checkpointTxnCount\n                         + \" unless too long since last upload.\");\n                 return null;\n               }\n \n               try {\n                 if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                   response.sendError(HttpServletResponse.SC_CONFLICT,\n                       \"Either current namenode has checkpointed or \"\n                           + \"another checkpointer already uploaded an \"\n                           + \"checkpoint for txid \" + txid);\n                   return null;\n                 }\n \n                 InputStream stream \u003d request.getInputStream();\n                 try {\n                   long start \u003d monotonicNow();\n                   MD5Hash downloadImageDigest \u003d TransferFsImage\n                       .handleUploadImageRequest(request, txid,\n                           nnImage.getStorage(), stream,\n                           parsedParams.getFileSize(), getThrottler(conf));\n                   nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                       downloadImageDigest);\n                   // Metrics non-null only when used inside name node\n                   if (metrics !\u003d null) {\n                     long elapsed \u003d monotonicNow() - start;\n                     metrics.addPutImage(elapsed);\n                   }\n                   // Now that we have a new checkpoint, we might be able to\n                   // remove some old ones.\n                   nnImage.purgeOldStorage(nnf);\n                 } finally {\n                   // remove the request once we\u0027ve processed it, or it threw an error, so we\n                   // aren\u0027t using it either\n                   currentlyDownloadingCheckpoints.remove(imageRequest);\n \n                   stream.close();\n                 }\n               } finally {\n                 nnImage.removeFromCheckpointing(txid);\n               }\n               return null;\n             }\n\\ No newline at end of file\n",
      "actualSource": "            public Void run() throws Exception {\n              // if its not the active NN, then we need to notify the caller it was was the wrong\n              // target (regardless of the fact that we got the image)\n              HAServiceProtocol.HAServiceState state \u003d NameNodeHttpServer\n                  .getNameNodeStateFromContext(getServletContext());\n              if (state !\u003d HAServiceProtocol.HAServiceState.ACTIVE \u0026\u0026\n                  state !\u003d HAServiceProtocol.HAServiceState.OBSERVER) {\n                // we need a different response type here so the client can differentiate this\n                // from the failure to upload due to (1) security, or (2) other checkpoints already\n                // present\n                response.sendError(HttpServletResponse.SC_EXPECTATION_FAILED,\n                    \"Nameode \"+request.getLocalAddr()+\" is currently not in a state which can \"\n                        + \"accept uploads of new fsimages. State: \"+state);\n                return null;\n              }\n\n              final long txid \u003d parsedParams.getTxId();\n              String remoteAddr \u003d request.getRemoteAddr();\n              ImageUploadRequest imageRequest \u003d new ImageUploadRequest(txid, remoteAddr);\n\n              final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n\n              // if the node is attempting to upload an older transaction, we ignore it\n              SortedSet\u003cImageUploadRequest\u003e larger \u003d currentlyDownloadingCheckpoints.tailSet(imageRequest);\n              if (larger.size() \u003e 0) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer is already in the process of uploading a\" +\n                        \" checkpoint made up to transaction ID \" + larger.last());\n                return null;\n              }\n\n              //make sure no one else has started uploading one\n              if (!currentlyDownloadingCheckpoints.add(imageRequest)) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Either current namenode is checkpointing or another\"\n                        + \" checkpointer is already in the process of \"\n                        + \"uploading a checkpoint made at transaction ID \"\n                        + txid);\n                return null;\n              }\n\n              long now \u003d System.currentTimeMillis();\n              long lastCheckpointTime \u003d\n                  nnImage.getStorage().getMostRecentCheckpointTime();\n              long lastCheckpointTxid \u003d\n                  nnImage.getStorage().getMostRecentCheckpointTxId();\n\n              long checkpointPeriod \u003d\n                  conf.getTimeDuration(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n                      DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT, TimeUnit.SECONDS);\n              long checkpointTxnCount \u003d\n                  conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n                      DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n\n              long timeDelta \u003d TimeUnit.MILLISECONDS.toSeconds(\n                  now - lastCheckpointTime);\n\n              // Since the goal of the check below is to prevent overly\n              // frequent upload from Standby, the check should only be done\n              // for the periodical upload from Standby. For the other\n              // scenarios such as rollback image and ckpt file, they skip\n              // this check, see HDFS-15036 for more info.\n              if (checkRecentImageEnable \u0026\u0026\n                  NameNodeFile.IMAGE.equals(parsedParams.getNameNodeFile()) \u0026\u0026\n                  timeDelta \u003c checkpointPeriod \u0026\u0026\n                  txid - lastCheckpointTxid \u003c checkpointTxnCount) {\n                // only when at least one of two conditions are met we accept\n                // a new fsImage\n                // 1. most recent image\u0027s txid is too far behind\n                // 2. last checkpoint time was too old\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Most recent checkpoint is neither too far behind in \"\n                        + \"txid, nor too old. New txnid cnt is \"\n                        + (txid - lastCheckpointTxid)\n                        + \", expecting at least \" + checkpointTxnCount\n                        + \" unless too long since last upload.\");\n                return null;\n              }\n\n              try {\n                if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                  response.sendError(HttpServletResponse.SC_CONFLICT,\n                      \"Either current namenode has checkpointed or \"\n                          + \"another checkpointer already uploaded an \"\n                          + \"checkpoint for txid \" + txid);\n                  return null;\n                }\n\n                InputStream stream \u003d request.getInputStream();\n                try {\n                  long start \u003d monotonicNow();\n                  MD5Hash downloadImageDigest \u003d TransferFsImage\n                      .handleUploadImageRequest(request, txid,\n                          nnImage.getStorage(), stream,\n                          parsedParams.getFileSize(), getThrottler(conf));\n                  nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                      downloadImageDigest);\n                  // Metrics non-null only when used inside name node\n                  if (metrics !\u003d null) {\n                    long elapsed \u003d monotonicNow() - start;\n                    metrics.addPutImage(elapsed);\n                  }\n                  // Now that we have a new checkpoint, we might be able to\n                  // remove some old ones.\n                  nnImage.purgeOldStorage(nnf);\n                } finally {\n                  // remove the request once we\u0027ve processed it, or it threw an error, so we\n                  // aren\u0027t using it either\n                  currentlyDownloadingCheckpoints.remove(imageRequest);\n\n                  stream.close();\n                }\n              } finally {\n                nnImage.removeFromCheckpointing(txid);\n              }\n              return null;\n            }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageServlet.java",
      "extendedDetails": {}
    },
    "5e6cc6fe8a11a638ba98913ca402efdc988fe73a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12979. [SBN read] StandbyNode should upload FsImage to ObserverNode after checkpointing. Contributed by Chen Liang.\n",
      "commitDate": "17/07/19 2:37 PM",
      "commitName": "5e6cc6fe8a11a638ba98913ca402efdc988fe73a",
      "commitAuthor": "Chen Liang",
      "commitDateOld": "07/12/18 6:30 PM",
      "commitNameOld": "8fc0d04517912766a3102f3e611f7d0fabd2f815",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 221.8,
      "commitsBetweenForRepo": 1590,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,111 @@\n             public Void run() throws Exception {\n               // if its not the active NN, then we need to notify the caller it was was the wrong\n               // target (regardless of the fact that we got the image)\n               HAServiceProtocol.HAServiceState state \u003d NameNodeHttpServer\n                   .getNameNodeStateFromContext(getServletContext());\n-              if (state !\u003d HAServiceProtocol.HAServiceState.ACTIVE) {\n+              if (state !\u003d HAServiceProtocol.HAServiceState.ACTIVE \u0026\u0026\n+                  state !\u003d HAServiceProtocol.HAServiceState.OBSERVER) {\n                 // we need a different response type here so the client can differentiate this\n                 // from the failure to upload due to (1) security, or (2) other checkpoints already\n                 // present\n                 response.sendError(HttpServletResponse.SC_EXPECTATION_FAILED,\n                     \"Nameode \"+request.getLocalAddr()+\" is currently not in a state which can \"\n                         + \"accept uploads of new fsimages. State: \"+state);\n                 return null;\n               }\n \n               final long txid \u003d parsedParams.getTxId();\n               String remoteAddr \u003d request.getRemoteAddr();\n               ImageUploadRequest imageRequest \u003d new ImageUploadRequest(txid, remoteAddr);\n \n               final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n \n               // if the node is attempting to upload an older transaction, we ignore it\n               SortedSet\u003cImageUploadRequest\u003e larger \u003d currentlyDownloadingCheckpoints.tailSet(imageRequest);\n               if (larger.size() \u003e 0) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Another checkpointer is already in the process of uploading a\" +\n                         \" checkpoint made up to transaction ID \" + larger.last());\n                 return null;\n               }\n \n               //make sure no one else has started uploading one\n               if (!currentlyDownloadingCheckpoints.add(imageRequest)) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Either current namenode is checkpointing or another\"\n                         + \" checkpointer is already in the process of \"\n                         + \"uploading a checkpoint made at transaction ID \"\n                         + txid);\n                 return null;\n               }\n+\n+              long now \u003d System.currentTimeMillis();\n+              long lastCheckpointTime \u003d\n+                  nnImage.getStorage().getMostRecentCheckpointTime();\n+              long lastCheckpointTxid \u003d\n+                  nnImage.getStorage().getMostRecentCheckpointTxId();\n+\n+              long checkpointPeriod \u003d\n+                  conf.getTimeDuration(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n+                      DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT, TimeUnit.SECONDS);\n+              long checkpointTxnCount \u003d\n+                  conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n+                      DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n+\n+              long timeDelta \u003d TimeUnit.MILLISECONDS.toSeconds(\n+                  now - lastCheckpointTime);\n+\n+              if (checkRecentImageEnable \u0026\u0026\n+                  timeDelta \u003c checkpointPeriod \u0026\u0026\n+                  txid - lastCheckpointTxid \u003c checkpointTxnCount) {\n+                // only when at least one of two conditions are met we accept\n+                // a new fsImage\n+                // 1. most recent image\u0027s txid is too far behind\n+                // 2. last checkpoint time was too old\n+                response.sendError(HttpServletResponse.SC_CONFLICT,\n+                    \"Most recent checkpoint is neither too far behind in \"\n+                        + \"txid, nor too old. New txnid cnt is \"\n+                        + (txid - lastCheckpointTxid)\n+                        + \", expecting at least \" + checkpointTxnCount\n+                        + \" unless too long since last upload.\");\n+                return null;\n+              }\n+\n               try {\n                 if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                   response.sendError(HttpServletResponse.SC_CONFLICT,\n                       \"Either current namenode has checkpointed or \"\n                           + \"another checkpointer already uploaded an \"\n                           + \"checkpoint for txid \" + txid);\n                   return null;\n                 }\n \n                 InputStream stream \u003d request.getInputStream();\n                 try {\n                   long start \u003d monotonicNow();\n                   MD5Hash downloadImageDigest \u003d TransferFsImage\n                       .handleUploadImageRequest(request, txid,\n                           nnImage.getStorage(), stream,\n                           parsedParams.getFileSize(), getThrottler(conf));\n                   nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                       downloadImageDigest);\n                   // Metrics non-null only when used inside name node\n                   if (metrics !\u003d null) {\n                     long elapsed \u003d monotonicNow() - start;\n                     metrics.addPutImage(elapsed);\n                   }\n                   // Now that we have a new checkpoint, we might be able to\n                   // remove some old ones.\n                   nnImage.purgeOldStorage(nnf);\n                 } finally {\n                   // remove the request once we\u0027ve processed it, or it threw an error, so we\n                   // aren\u0027t using it either\n                   currentlyDownloadingCheckpoints.remove(imageRequest);\n \n                   stream.close();\n                 }\n               } finally {\n                 nnImage.removeFromCheckpointing(txid);\n               }\n               return null;\n             }\n\\ No newline at end of file\n",
      "actualSource": "            public Void run() throws Exception {\n              // if its not the active NN, then we need to notify the caller it was was the wrong\n              // target (regardless of the fact that we got the image)\n              HAServiceProtocol.HAServiceState state \u003d NameNodeHttpServer\n                  .getNameNodeStateFromContext(getServletContext());\n              if (state !\u003d HAServiceProtocol.HAServiceState.ACTIVE \u0026\u0026\n                  state !\u003d HAServiceProtocol.HAServiceState.OBSERVER) {\n                // we need a different response type here so the client can differentiate this\n                // from the failure to upload due to (1) security, or (2) other checkpoints already\n                // present\n                response.sendError(HttpServletResponse.SC_EXPECTATION_FAILED,\n                    \"Nameode \"+request.getLocalAddr()+\" is currently not in a state which can \"\n                        + \"accept uploads of new fsimages. State: \"+state);\n                return null;\n              }\n\n              final long txid \u003d parsedParams.getTxId();\n              String remoteAddr \u003d request.getRemoteAddr();\n              ImageUploadRequest imageRequest \u003d new ImageUploadRequest(txid, remoteAddr);\n\n              final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n\n              // if the node is attempting to upload an older transaction, we ignore it\n              SortedSet\u003cImageUploadRequest\u003e larger \u003d currentlyDownloadingCheckpoints.tailSet(imageRequest);\n              if (larger.size() \u003e 0) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer is already in the process of uploading a\" +\n                        \" checkpoint made up to transaction ID \" + larger.last());\n                return null;\n              }\n\n              //make sure no one else has started uploading one\n              if (!currentlyDownloadingCheckpoints.add(imageRequest)) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Either current namenode is checkpointing or another\"\n                        + \" checkpointer is already in the process of \"\n                        + \"uploading a checkpoint made at transaction ID \"\n                        + txid);\n                return null;\n              }\n\n              long now \u003d System.currentTimeMillis();\n              long lastCheckpointTime \u003d\n                  nnImage.getStorage().getMostRecentCheckpointTime();\n              long lastCheckpointTxid \u003d\n                  nnImage.getStorage().getMostRecentCheckpointTxId();\n\n              long checkpointPeriod \u003d\n                  conf.getTimeDuration(DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n                      DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT, TimeUnit.SECONDS);\n              long checkpointTxnCount \u003d\n                  conf.getLong(DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n                      DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n\n              long timeDelta \u003d TimeUnit.MILLISECONDS.toSeconds(\n                  now - lastCheckpointTime);\n\n              if (checkRecentImageEnable \u0026\u0026\n                  timeDelta \u003c checkpointPeriod \u0026\u0026\n                  txid - lastCheckpointTxid \u003c checkpointTxnCount) {\n                // only when at least one of two conditions are met we accept\n                // a new fsImage\n                // 1. most recent image\u0027s txid is too far behind\n                // 2. last checkpoint time was too old\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Most recent checkpoint is neither too far behind in \"\n                        + \"txid, nor too old. New txnid cnt is \"\n                        + (txid - lastCheckpointTxid)\n                        + \", expecting at least \" + checkpointTxnCount\n                        + \" unless too long since last upload.\");\n                return null;\n              }\n\n              try {\n                if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                  response.sendError(HttpServletResponse.SC_CONFLICT,\n                      \"Either current namenode has checkpointed or \"\n                          + \"another checkpointer already uploaded an \"\n                          + \"checkpoint for txid \" + txid);\n                  return null;\n                }\n\n                InputStream stream \u003d request.getInputStream();\n                try {\n                  long start \u003d monotonicNow();\n                  MD5Hash downloadImageDigest \u003d TransferFsImage\n                      .handleUploadImageRequest(request, txid,\n                          nnImage.getStorage(), stream,\n                          parsedParams.getFileSize(), getThrottler(conf));\n                  nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                      downloadImageDigest);\n                  // Metrics non-null only when used inside name node\n                  if (metrics !\u003d null) {\n                    long elapsed \u003d monotonicNow() - start;\n                    metrics.addPutImage(elapsed);\n                  }\n                  // Now that we have a new checkpoint, we might be able to\n                  // remove some old ones.\n                  nnImage.purgeOldStorage(nnf);\n                } finally {\n                  // remove the request once we\u0027ve processed it, or it threw an error, so we\n                  // aren\u0027t using it either\n                  currentlyDownloadingCheckpoints.remove(imageRequest);\n\n                  stream.close();\n                }\n              } finally {\n                nnImage.removeFromCheckpointing(txid);\n              }\n              return null;\n            }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageServlet.java",
      "extendedDetails": {}
    },
    "49dfad942970459297f72632ed8dfd353e0c86de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6440. Support more than 2 NameNodes. Contributed by Jesse Yates.\n",
      "commitDate": "23/06/15 5:26 PM",
      "commitName": "49dfad942970459297f72632ed8dfd353e0c86de",
      "commitAuthor": "Aaron T. Myers",
      "commitDateOld": "12/02/15 5:40 PM",
      "commitNameOld": "46b6d23e8fbed4c2ba537dd752116c173805bca7",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 130.95,
      "commitsBetweenForRepo": 1150,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,77 @@\n             public Void run() throws Exception {\n+              // if its not the active NN, then we need to notify the caller it was was the wrong\n+              // target (regardless of the fact that we got the image)\n+              HAServiceProtocol.HAServiceState state \u003d NameNodeHttpServer\n+                  .getNameNodeStateFromContext(getServletContext());\n+              if (state !\u003d HAServiceProtocol.HAServiceState.ACTIVE) {\n+                // we need a different response type here so the client can differentiate this\n+                // from the failure to upload due to (1) security, or (2) other checkpoints already\n+                // present\n+                response.sendError(HttpServletResponse.SC_EXPECTATION_FAILED,\n+                    \"Nameode \"+request.getLocalAddr()+\" is currently not in a state which can \"\n+                        + \"accept uploads of new fsimages. State: \"+state);\n+                return null;\n+              }\n \n               final long txid \u003d parsedParams.getTxId();\n+              String remoteAddr \u003d request.getRemoteAddr();\n+              ImageUploadRequest imageRequest \u003d new ImageUploadRequest(txid, remoteAddr);\n \n               final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n \n-              if (!nnImage.addToCheckpointing(txid)) {\n+              // if the node is attempting to upload an older transaction, we ignore it\n+              SortedSet\u003cImageUploadRequest\u003e larger \u003d currentlyDownloadingCheckpoints.tailSet(imageRequest);\n+              if (larger.size() \u003e 0) {\n+                response.sendError(HttpServletResponse.SC_CONFLICT,\n+                    \"Another checkpointer is already in the process of uploading a\" +\n+                        \" checkpoint made up to transaction ID \" + larger.last());\n+                return null;\n+              }\n+\n+              //make sure no one else has started uploading one\n+              if (!currentlyDownloadingCheckpoints.add(imageRequest)) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Either current namenode is checkpointing or another\"\n                         + \" checkpointer is already in the process of \"\n                         + \"uploading a checkpoint made at transaction ID \"\n                         + txid);\n                 return null;\n               }\n               try {\n                 if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                   response.sendError(HttpServletResponse.SC_CONFLICT,\n                       \"Either current namenode has checkpointed or \"\n                           + \"another checkpointer already uploaded an \"\n                           + \"checkpoint for txid \" + txid);\n                   return null;\n                 }\n \n                 InputStream stream \u003d request.getInputStream();\n                 try {\n                   long start \u003d monotonicNow();\n                   MD5Hash downloadImageDigest \u003d TransferFsImage\n                       .handleUploadImageRequest(request, txid,\n                           nnImage.getStorage(), stream,\n                           parsedParams.getFileSize(), getThrottler(conf));\n                   nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                       downloadImageDigest);\n                   // Metrics non-null only when used inside name node\n                   if (metrics !\u003d null) {\n                     long elapsed \u003d monotonicNow() - start;\n                     metrics.addPutImage(elapsed);\n                   }\n                   // Now that we have a new checkpoint, we might be able to\n                   // remove some old ones.\n                   nnImage.purgeOldStorage(nnf);\n                 } finally {\n+                  // remove the request once we\u0027ve processed it, or it threw an error, so we\n+                  // aren\u0027t using it either\n+                  currentlyDownloadingCheckpoints.remove(imageRequest);\n+\n                   stream.close();\n                 }\n               } finally {\n                 nnImage.removeFromCheckpointing(txid);\n               }\n               return null;\n             }\n\\ No newline at end of file\n",
      "actualSource": "            public Void run() throws Exception {\n              // if its not the active NN, then we need to notify the caller it was was the wrong\n              // target (regardless of the fact that we got the image)\n              HAServiceProtocol.HAServiceState state \u003d NameNodeHttpServer\n                  .getNameNodeStateFromContext(getServletContext());\n              if (state !\u003d HAServiceProtocol.HAServiceState.ACTIVE) {\n                // we need a different response type here so the client can differentiate this\n                // from the failure to upload due to (1) security, or (2) other checkpoints already\n                // present\n                response.sendError(HttpServletResponse.SC_EXPECTATION_FAILED,\n                    \"Nameode \"+request.getLocalAddr()+\" is currently not in a state which can \"\n                        + \"accept uploads of new fsimages. State: \"+state);\n                return null;\n              }\n\n              final long txid \u003d parsedParams.getTxId();\n              String remoteAddr \u003d request.getRemoteAddr();\n              ImageUploadRequest imageRequest \u003d new ImageUploadRequest(txid, remoteAddr);\n\n              final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n\n              // if the node is attempting to upload an older transaction, we ignore it\n              SortedSet\u003cImageUploadRequest\u003e larger \u003d currentlyDownloadingCheckpoints.tailSet(imageRequest);\n              if (larger.size() \u003e 0) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer is already in the process of uploading a\" +\n                        \" checkpoint made up to transaction ID \" + larger.last());\n                return null;\n              }\n\n              //make sure no one else has started uploading one\n              if (!currentlyDownloadingCheckpoints.add(imageRequest)) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Either current namenode is checkpointing or another\"\n                        + \" checkpointer is already in the process of \"\n                        + \"uploading a checkpoint made at transaction ID \"\n                        + txid);\n                return null;\n              }\n              try {\n                if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                  response.sendError(HttpServletResponse.SC_CONFLICT,\n                      \"Either current namenode has checkpointed or \"\n                          + \"another checkpointer already uploaded an \"\n                          + \"checkpoint for txid \" + txid);\n                  return null;\n                }\n\n                InputStream stream \u003d request.getInputStream();\n                try {\n                  long start \u003d monotonicNow();\n                  MD5Hash downloadImageDigest \u003d TransferFsImage\n                      .handleUploadImageRequest(request, txid,\n                          nnImage.getStorage(), stream,\n                          parsedParams.getFileSize(), getThrottler(conf));\n                  nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                      downloadImageDigest);\n                  // Metrics non-null only when used inside name node\n                  if (metrics !\u003d null) {\n                    long elapsed \u003d monotonicNow() - start;\n                    metrics.addPutImage(elapsed);\n                  }\n                  // Now that we have a new checkpoint, we might be able to\n                  // remove some old ones.\n                  nnImage.purgeOldStorage(nnf);\n                } finally {\n                  // remove the request once we\u0027ve processed it, or it threw an error, so we\n                  // aren\u0027t using it either\n                  currentlyDownloadingCheckpoints.remove(imageRequest);\n\n                  stream.close();\n                }\n              } finally {\n                nnImage.removeFromCheckpointing(txid);\n              }\n              return null;\n            }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageServlet.java",
      "extendedDetails": {}
    },
    "d3268c4b10a0f728b554ddb6d69b666a9ca13f12": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3519. Checkpoint upload may interfere with a concurrent saveNamespace. Contributed by Ming Ma.\n",
      "commitDate": "22/01/15 4:26 PM",
      "commitName": "d3268c4b10a0f728b554ddb6d69b666a9ca13f12",
      "commitAuthor": "cnauroth",
      "commitDateOld": "05/11/14 3:09 PM",
      "commitNameOld": "ba1d4ad25b301f7247f3f23df15e7f800e50feed",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 78.05,
      "commitsBetweenForRepo": 508,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,45 +1,48 @@\n             public Void run() throws Exception {\n \n               final long txid \u003d parsedParams.getTxId();\n \n               final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n \n-              if (!currentlyDownloadingCheckpoints.add(txid)) {\n+              if (!nnImage.addToCheckpointing(txid)) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n-                    \"Another checkpointer is already in the process of uploading a\"\n-                        + \" checkpoint made at transaction ID \" + txid);\n+                    \"Either current namenode is checkpointing or another\"\n+                        + \" checkpointer is already in the process of \"\n+                        + \"uploading a checkpoint made at transaction ID \"\n+                        + txid);\n                 return null;\n               }\n               try {\n                 if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                   response.sendError(HttpServletResponse.SC_CONFLICT,\n-                      \"Another checkpointer already uploaded an checkpoint \"\n-                          + \"for txid \" + txid);\n+                      \"Either current namenode has checkpointed or \"\n+                          + \"another checkpointer already uploaded an \"\n+                          + \"checkpoint for txid \" + txid);\n                   return null;\n                 }\n \n                 InputStream stream \u003d request.getInputStream();\n                 try {\n                   long start \u003d monotonicNow();\n                   MD5Hash downloadImageDigest \u003d TransferFsImage\n                       .handleUploadImageRequest(request, txid,\n                           nnImage.getStorage(), stream,\n                           parsedParams.getFileSize(), getThrottler(conf));\n                   nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                       downloadImageDigest);\n                   // Metrics non-null only when used inside name node\n                   if (metrics !\u003d null) {\n                     long elapsed \u003d monotonicNow() - start;\n                     metrics.addPutImage(elapsed);\n                   }\n                   // Now that we have a new checkpoint, we might be able to\n                   // remove some old ones.\n                   nnImage.purgeOldStorage(nnf);\n                 } finally {\n                   stream.close();\n                 }\n               } finally {\n-                currentlyDownloadingCheckpoints.remove(txid);\n+                nnImage.removeFromCheckpointing(txid);\n               }\n               return null;\n             }\n\\ No newline at end of file\n",
      "actualSource": "            public Void run() throws Exception {\n\n              final long txid \u003d parsedParams.getTxId();\n\n              final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n\n              if (!nnImage.addToCheckpointing(txid)) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Either current namenode is checkpointing or another\"\n                        + \" checkpointer is already in the process of \"\n                        + \"uploading a checkpoint made at transaction ID \"\n                        + txid);\n                return null;\n              }\n              try {\n                if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                  response.sendError(HttpServletResponse.SC_CONFLICT,\n                      \"Either current namenode has checkpointed or \"\n                          + \"another checkpointer already uploaded an \"\n                          + \"checkpoint for txid \" + txid);\n                  return null;\n                }\n\n                InputStream stream \u003d request.getInputStream();\n                try {\n                  long start \u003d monotonicNow();\n                  MD5Hash downloadImageDigest \u003d TransferFsImage\n                      .handleUploadImageRequest(request, txid,\n                          nnImage.getStorage(), stream,\n                          parsedParams.getFileSize(), getThrottler(conf));\n                  nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                      downloadImageDigest);\n                  // Metrics non-null only when used inside name node\n                  if (metrics !\u003d null) {\n                    long elapsed \u003d monotonicNow() - start;\n                    metrics.addPutImage(elapsed);\n                  }\n                  // Now that we have a new checkpoint, we might be able to\n                  // remove some old ones.\n                  nnImage.purgeOldStorage(nnf);\n                } finally {\n                  stream.close();\n                }\n              } finally {\n                nnImage.removeFromCheckpointing(txid);\n              }\n              return null;\n            }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageServlet.java",
      "extendedDetails": {}
    },
    "193f11a7ab539c360ecd9f2015c0f46cd070a875": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6236. ImageServlet should use Time#monotonicNow to measure latency. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1586902 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/04/14 2:38 PM",
      "commitName": "193f11a7ab539c360ecd9f2015c0f46cd070a875",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "07/04/14 11:55 AM",
      "commitNameOld": "a5b37c6ed14e92f5a7f7dd76a9a82b3f859fb6dd",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 5.11,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,45 +1,45 @@\n             public Void run() throws Exception {\n \n               final long txid \u003d parsedParams.getTxId();\n \n               final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n \n               if (!currentlyDownloadingCheckpoints.add(txid)) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Another checkpointer is already in the process of uploading a\"\n                         + \" checkpoint made at transaction ID \" + txid);\n                 return null;\n               }\n               try {\n                 if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                   response.sendError(HttpServletResponse.SC_CONFLICT,\n                       \"Another checkpointer already uploaded an checkpoint \"\n                           + \"for txid \" + txid);\n                   return null;\n                 }\n \n                 InputStream stream \u003d request.getInputStream();\n                 try {\n-                  long start \u003d now();\n+                  long start \u003d monotonicNow();\n                   MD5Hash downloadImageDigest \u003d TransferFsImage\n                       .handleUploadImageRequest(request, txid,\n                           nnImage.getStorage(), stream,\n                           parsedParams.getFileSize(), getThrottler(conf));\n                   nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                       downloadImageDigest);\n                   // Metrics non-null only when used inside name node\n                   if (metrics !\u003d null) {\n-                    long elapsed \u003d now() - start;\n+                    long elapsed \u003d monotonicNow() - start;\n                     metrics.addPutImage(elapsed);\n                   }\n                   // Now that we have a new checkpoint, we might be able to\n                   // remove some old ones.\n                   nnImage.purgeOldStorage(nnf);\n                 } finally {\n                   stream.close();\n                 }\n               } finally {\n                 currentlyDownloadingCheckpoints.remove(txid);\n               }\n               return null;\n             }\n\\ No newline at end of file\n",
      "actualSource": "            public Void run() throws Exception {\n\n              final long txid \u003d parsedParams.getTxId();\n\n              final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n\n              if (!currentlyDownloadingCheckpoints.add(txid)) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer is already in the process of uploading a\"\n                        + \" checkpoint made at transaction ID \" + txid);\n                return null;\n              }\n              try {\n                if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                  response.sendError(HttpServletResponse.SC_CONFLICT,\n                      \"Another checkpointer already uploaded an checkpoint \"\n                          + \"for txid \" + txid);\n                  return null;\n                }\n\n                InputStream stream \u003d request.getInputStream();\n                try {\n                  long start \u003d monotonicNow();\n                  MD5Hash downloadImageDigest \u003d TransferFsImage\n                      .handleUploadImageRequest(request, txid,\n                          nnImage.getStorage(), stream,\n                          parsedParams.getFileSize(), getThrottler(conf));\n                  nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                      downloadImageDigest);\n                  // Metrics non-null only when used inside name node\n                  if (metrics !\u003d null) {\n                    long elapsed \u003d monotonicNow() - start;\n                    metrics.addPutImage(elapsed);\n                  }\n                  // Now that we have a new checkpoint, we might be able to\n                  // remove some old ones.\n                  nnImage.purgeOldStorage(nnf);\n                } finally {\n                  stream.close();\n                }\n              } finally {\n                currentlyDownloadingCheckpoints.remove(txid);\n              }\n              return null;\n            }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageServlet.java",
      "extendedDetails": {}
    },
    "94a1632fcb677fda6f4d812614026417f1d0a360": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "HDFS-3405. Checkpointing should use HTTP POST or PUT instead of GET-GET to send merged fsimages. Contributed by Vinayakumar B.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1575611 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/03/14 1:25 PM",
      "commitName": "94a1632fcb677fda6f4d812614026417f1d0a360",
      "commitAuthor": "Andrew Wang",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "HDFS-3405. Checkpointing should use HTTP POST or PUT instead of GET-GET to send merged fsimages. Contributed by Vinayakumar B.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1575611 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "08/03/14 1:25 PM",
          "commitName": "94a1632fcb677fda6f4d812614026417f1d0a360",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "08/03/14 1:15 PM",
          "commitNameOld": "dbd22b23c2d68b97b4da47215897906f06f978e3",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,86 +1,45 @@\n-        public Void run() throws Exception {\n-          if (parsedParams.isGetImage()) {\n-            long txid \u003d parsedParams.getTxId();\n-            File imageFile \u003d null;\n-            String errorMessage \u003d \"Could not find image\";\n-            if (parsedParams.shouldFetchLatest()) {\n-              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n-            } else {\n-              errorMessage +\u003d \" with txid \" + txid;\n-              imageFile \u003d nnImage.getStorage().getFsImage(txid,\n-                  EnumSet.of(NameNodeFile.IMAGE, NameNodeFile.IMAGE_ROLLBACK));\n-            }\n-            if (imageFile \u003d\u003d null) {\n-              throw new IOException(errorMessage);\n-            }\n-            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n-            long start \u003d now();\n-            serveFile(imageFile);\n+            public Void run() throws Exception {\n \n-            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n-              long elapsed \u003d now() - start;\n-              metrics.addGetImage(elapsed);\n-            }\n-          } else if (parsedParams.isGetEdit()) {\n-            long startTxId \u003d parsedParams.getStartTxId();\n-            long endTxId \u003d parsedParams.getEndTxId();\n-            \n-            File editFile \u003d nnImage.getStorage()\n-                .findFinalizedEditsFile(startTxId, endTxId);\n-            long start \u003d now();\n-            serveFile(editFile);\n+              final long txid \u003d parsedParams.getTxId();\n \n-            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n-              long elapsed \u003d now() - start;\n-              metrics.addGetEdit(elapsed);\n-            }\n-          } else if (parsedParams.isPutImage()) {\n-            final long txid \u003d parsedParams.getTxId();\n-            final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n+              final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n \n-            if (! currentlyDownloadingCheckpoints.add(txid)) {\n-              response.sendError(HttpServletResponse.SC_CONFLICT,\n-                  \"Another checkpointer is already in the process of uploading a\" +\n-                  \" checkpoint made at transaction ID \" + txid);\n-              return null;\n-            }\n-\n-            try {\n-              if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n+              if (!currentlyDownloadingCheckpoints.add(txid)) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n-                    \"Another checkpointer already uploaded an checkpoint \" +\n-                    \"for txid \" + txid);\n+                    \"Another checkpointer is already in the process of uploading a\"\n+                        + \" checkpoint made at transaction ID \" + txid);\n                 return null;\n               }\n-              \n-              // We may have lost our ticket since last checkpoint, log in again, just in case\n-              if (UserGroupInformation.isSecurityEnabled()) {\n-                UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n-              }\n-              \n-              long start \u003d now();\n-              // issue a HTTP get request to download the new fsimage \n-              MD5Hash downloadImageDigest \u003d TransferFsImage\n-                  .downloadImageToStorage(parsedParams.getInfoServer(conf),\n-                      txid, nnImage.getStorage(), true);\n-              nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n-                  downloadImageDigest);\n-              if (nnf \u003d\u003d NameNodeFile.IMAGE_ROLLBACK) {\n-                    NameNodeHttpServer.getNameNodeFromContext(context)\n-                        .getNamesystem().setCreatedRollbackImages(true);\n-              }\n+              try {\n+                if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n+                  response.sendError(HttpServletResponse.SC_CONFLICT,\n+                      \"Another checkpointer already uploaded an checkpoint \"\n+                          + \"for txid \" + txid);\n+                  return null;\n+                }\n \n-              if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n-                long elapsed \u003d now() - start;\n-                metrics.addPutImage(elapsed);\n+                InputStream stream \u003d request.getInputStream();\n+                try {\n+                  long start \u003d now();\n+                  MD5Hash downloadImageDigest \u003d TransferFsImage\n+                      .handleUploadImageRequest(request, txid,\n+                          nnImage.getStorage(), stream,\n+                          parsedParams.getFileSize(), getThrottler(conf));\n+                  nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n+                      downloadImageDigest);\n+                  // Metrics non-null only when used inside name node\n+                  if (metrics !\u003d null) {\n+                    long elapsed \u003d now() - start;\n+                    metrics.addPutImage(elapsed);\n+                  }\n+                  // Now that we have a new checkpoint, we might be able to\n+                  // remove some old ones.\n+                  nnImage.purgeOldStorage(nnf);\n+                } finally {\n+                  stream.close();\n+                }\n+              } finally {\n+                currentlyDownloadingCheckpoints.remove(txid);\n               }\n-              \n-              // Now that we have a new checkpoint, we might be able to\n-              // remove some old ones.\n-              nnImage.purgeOldStorage(nnf);\n-            } finally {\n-              currentlyDownloadingCheckpoints.remove(txid);\n-            }\n-          }\n-          return null;\n-        }\n\\ No newline at end of file\n+              return null;\n+            }\n\\ No newline at end of file\n",
          "actualSource": "            public Void run() throws Exception {\n\n              final long txid \u003d parsedParams.getTxId();\n\n              final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n\n              if (!currentlyDownloadingCheckpoints.add(txid)) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer is already in the process of uploading a\"\n                        + \" checkpoint made at transaction ID \" + txid);\n                return null;\n              }\n              try {\n                if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                  response.sendError(HttpServletResponse.SC_CONFLICT,\n                      \"Another checkpointer already uploaded an checkpoint \"\n                          + \"for txid \" + txid);\n                  return null;\n                }\n\n                InputStream stream \u003d request.getInputStream();\n                try {\n                  long start \u003d now();\n                  MD5Hash downloadImageDigest \u003d TransferFsImage\n                      .handleUploadImageRequest(request, txid,\n                          nnImage.getStorage(), stream,\n                          parsedParams.getFileSize(), getThrottler(conf));\n                  nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                      downloadImageDigest);\n                  // Metrics non-null only when used inside name node\n                  if (metrics !\u003d null) {\n                    long elapsed \u003d now() - start;\n                    metrics.addPutImage(elapsed);\n                  }\n                  // Now that we have a new checkpoint, we might be able to\n                  // remove some old ones.\n                  nnImage.purgeOldStorage(nnf);\n                } finally {\n                  stream.close();\n                }\n              } finally {\n                currentlyDownloadingCheckpoints.remove(txid);\n              }\n              return null;\n            }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageServlet.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageServlet.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3405. Checkpointing should use HTTP POST or PUT instead of GET-GET to send merged fsimages. Contributed by Vinayakumar B.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1575611 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "08/03/14 1:25 PM",
          "commitName": "94a1632fcb677fda6f4d812614026417f1d0a360",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "08/03/14 1:15 PM",
          "commitNameOld": "dbd22b23c2d68b97b4da47215897906f06f978e3",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,86 +1,45 @@\n-        public Void run() throws Exception {\n-          if (parsedParams.isGetImage()) {\n-            long txid \u003d parsedParams.getTxId();\n-            File imageFile \u003d null;\n-            String errorMessage \u003d \"Could not find image\";\n-            if (parsedParams.shouldFetchLatest()) {\n-              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n-            } else {\n-              errorMessage +\u003d \" with txid \" + txid;\n-              imageFile \u003d nnImage.getStorage().getFsImage(txid,\n-                  EnumSet.of(NameNodeFile.IMAGE, NameNodeFile.IMAGE_ROLLBACK));\n-            }\n-            if (imageFile \u003d\u003d null) {\n-              throw new IOException(errorMessage);\n-            }\n-            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n-            long start \u003d now();\n-            serveFile(imageFile);\n+            public Void run() throws Exception {\n \n-            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n-              long elapsed \u003d now() - start;\n-              metrics.addGetImage(elapsed);\n-            }\n-          } else if (parsedParams.isGetEdit()) {\n-            long startTxId \u003d parsedParams.getStartTxId();\n-            long endTxId \u003d parsedParams.getEndTxId();\n-            \n-            File editFile \u003d nnImage.getStorage()\n-                .findFinalizedEditsFile(startTxId, endTxId);\n-            long start \u003d now();\n-            serveFile(editFile);\n+              final long txid \u003d parsedParams.getTxId();\n \n-            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n-              long elapsed \u003d now() - start;\n-              metrics.addGetEdit(elapsed);\n-            }\n-          } else if (parsedParams.isPutImage()) {\n-            final long txid \u003d parsedParams.getTxId();\n-            final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n+              final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n \n-            if (! currentlyDownloadingCheckpoints.add(txid)) {\n-              response.sendError(HttpServletResponse.SC_CONFLICT,\n-                  \"Another checkpointer is already in the process of uploading a\" +\n-                  \" checkpoint made at transaction ID \" + txid);\n-              return null;\n-            }\n-\n-            try {\n-              if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n+              if (!currentlyDownloadingCheckpoints.add(txid)) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n-                    \"Another checkpointer already uploaded an checkpoint \" +\n-                    \"for txid \" + txid);\n+                    \"Another checkpointer is already in the process of uploading a\"\n+                        + \" checkpoint made at transaction ID \" + txid);\n                 return null;\n               }\n-              \n-              // We may have lost our ticket since last checkpoint, log in again, just in case\n-              if (UserGroupInformation.isSecurityEnabled()) {\n-                UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n-              }\n-              \n-              long start \u003d now();\n-              // issue a HTTP get request to download the new fsimage \n-              MD5Hash downloadImageDigest \u003d TransferFsImage\n-                  .downloadImageToStorage(parsedParams.getInfoServer(conf),\n-                      txid, nnImage.getStorage(), true);\n-              nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n-                  downloadImageDigest);\n-              if (nnf \u003d\u003d NameNodeFile.IMAGE_ROLLBACK) {\n-                    NameNodeHttpServer.getNameNodeFromContext(context)\n-                        .getNamesystem().setCreatedRollbackImages(true);\n-              }\n+              try {\n+                if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n+                  response.sendError(HttpServletResponse.SC_CONFLICT,\n+                      \"Another checkpointer already uploaded an checkpoint \"\n+                          + \"for txid \" + txid);\n+                  return null;\n+                }\n \n-              if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n-                long elapsed \u003d now() - start;\n-                metrics.addPutImage(elapsed);\n+                InputStream stream \u003d request.getInputStream();\n+                try {\n+                  long start \u003d now();\n+                  MD5Hash downloadImageDigest \u003d TransferFsImage\n+                      .handleUploadImageRequest(request, txid,\n+                          nnImage.getStorage(), stream,\n+                          parsedParams.getFileSize(), getThrottler(conf));\n+                  nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n+                      downloadImageDigest);\n+                  // Metrics non-null only when used inside name node\n+                  if (metrics !\u003d null) {\n+                    long elapsed \u003d now() - start;\n+                    metrics.addPutImage(elapsed);\n+                  }\n+                  // Now that we have a new checkpoint, we might be able to\n+                  // remove some old ones.\n+                  nnImage.purgeOldStorage(nnf);\n+                } finally {\n+                  stream.close();\n+                }\n+              } finally {\n+                currentlyDownloadingCheckpoints.remove(txid);\n               }\n-              \n-              // Now that we have a new checkpoint, we might be able to\n-              // remove some old ones.\n-              nnImage.purgeOldStorage(nnf);\n-            } finally {\n-              currentlyDownloadingCheckpoints.remove(txid);\n-            }\n-          }\n-          return null;\n-        }\n\\ No newline at end of file\n+              return null;\n+            }\n\\ No newline at end of file\n",
          "actualSource": "            public Void run() throws Exception {\n\n              final long txid \u003d parsedParams.getTxId();\n\n              final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n\n              if (!currentlyDownloadingCheckpoints.add(txid)) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer is already in the process of uploading a\"\n                        + \" checkpoint made at transaction ID \" + txid);\n                return null;\n              }\n              try {\n                if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                  response.sendError(HttpServletResponse.SC_CONFLICT,\n                      \"Another checkpointer already uploaded an checkpoint \"\n                          + \"for txid \" + txid);\n                  return null;\n                }\n\n                InputStream stream \u003d request.getInputStream();\n                try {\n                  long start \u003d now();\n                  MD5Hash downloadImageDigest \u003d TransferFsImage\n                      .handleUploadImageRequest(request, txid,\n                          nnImage.getStorage(), stream,\n                          parsedParams.getFileSize(), getThrottler(conf));\n                  nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                      downloadImageDigest);\n                  // Metrics non-null only when used inside name node\n                  if (metrics !\u003d null) {\n                    long elapsed \u003d now() - start;\n                    metrics.addPutImage(elapsed);\n                  }\n                  // Now that we have a new checkpoint, we might be able to\n                  // remove some old ones.\n                  nnImage.purgeOldStorage(nnf);\n                } finally {\n                  stream.close();\n                }\n              } finally {\n                currentlyDownloadingCheckpoints.remove(txid);\n              }\n              return null;\n            }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageServlet.java",
          "extendedDetails": {}
        }
      ]
    },
    "dbd22b23c2d68b97b4da47215897906f06f978e3": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "Revert HDFS-3405 for recommit with correct renamed files\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1575610 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/03/14 1:15 PM",
      "commitName": "dbd22b23c2d68b97b4da47215897906f06f978e3",
      "commitAuthor": "Andrew Wang",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "Revert HDFS-3405 for recommit with correct renamed files\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1575610 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "08/03/14 1:15 PM",
          "commitName": "dbd22b23c2d68b97b4da47215897906f06f978e3",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "08/03/14 1:11 PM",
          "commitNameOld": "98594ab787d2e2a6b499f576e0cbda10767eaf15",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,45 +1,86 @@\n-            public Void run() throws Exception {\n+        public Void run() throws Exception {\n+          if (parsedParams.isGetImage()) {\n+            long txid \u003d parsedParams.getTxId();\n+            File imageFile \u003d null;\n+            String errorMessage \u003d \"Could not find image\";\n+            if (parsedParams.shouldFetchLatest()) {\n+              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n+            } else {\n+              errorMessage +\u003d \" with txid \" + txid;\n+              imageFile \u003d nnImage.getStorage().getFsImage(txid,\n+                  EnumSet.of(NameNodeFile.IMAGE, NameNodeFile.IMAGE_ROLLBACK));\n+            }\n+            if (imageFile \u003d\u003d null) {\n+              throw new IOException(errorMessage);\n+            }\n+            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n+            long start \u003d now();\n+            serveFile(imageFile);\n \n-              final long txid \u003d parsedParams.getTxId();\n+            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n+              long elapsed \u003d now() - start;\n+              metrics.addGetImage(elapsed);\n+            }\n+          } else if (parsedParams.isGetEdit()) {\n+            long startTxId \u003d parsedParams.getStartTxId();\n+            long endTxId \u003d parsedParams.getEndTxId();\n+            \n+            File editFile \u003d nnImage.getStorage()\n+                .findFinalizedEditsFile(startTxId, endTxId);\n+            long start \u003d now();\n+            serveFile(editFile);\n \n-              final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n+            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n+              long elapsed \u003d now() - start;\n+              metrics.addGetEdit(elapsed);\n+            }\n+          } else if (parsedParams.isPutImage()) {\n+            final long txid \u003d parsedParams.getTxId();\n+            final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n \n-              if (!currentlyDownloadingCheckpoints.add(txid)) {\n+            if (! currentlyDownloadingCheckpoints.add(txid)) {\n+              response.sendError(HttpServletResponse.SC_CONFLICT,\n+                  \"Another checkpointer is already in the process of uploading a\" +\n+                  \" checkpoint made at transaction ID \" + txid);\n+              return null;\n+            }\n+\n+            try {\n+              if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n-                    \"Another checkpointer is already in the process of uploading a\"\n-                        + \" checkpoint made at transaction ID \" + txid);\n+                    \"Another checkpointer already uploaded an checkpoint \" +\n+                    \"for txid \" + txid);\n                 return null;\n               }\n-              try {\n-                if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n-                  response.sendError(HttpServletResponse.SC_CONFLICT,\n-                      \"Another checkpointer already uploaded an checkpoint \"\n-                          + \"for txid \" + txid);\n-                  return null;\n-                }\n-\n-                InputStream stream \u003d request.getInputStream();\n-                try {\n-                  long start \u003d now();\n-                  MD5Hash downloadImageDigest \u003d TransferFsImage\n-                      .handleUploadImageRequest(request, txid,\n-                          nnImage.getStorage(), stream,\n-                          parsedParams.getFileSize(), getThrottler(conf));\n-                  nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n-                      downloadImageDigest);\n-                  // Metrics non-null only when used inside name node\n-                  if (metrics !\u003d null) {\n-                    long elapsed \u003d now() - start;\n-                    metrics.addPutImage(elapsed);\n-                  }\n-                  // Now that we have a new checkpoint, we might be able to\n-                  // remove some old ones.\n-                  nnImage.purgeOldStorage(nnf);\n-                } finally {\n-                  stream.close();\n-                }\n-              } finally {\n-                currentlyDownloadingCheckpoints.remove(txid);\n+              \n+              // We may have lost our ticket since last checkpoint, log in again, just in case\n+              if (UserGroupInformation.isSecurityEnabled()) {\n+                UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n               }\n-              return null;\n-            }\n\\ No newline at end of file\n+              \n+              long start \u003d now();\n+              // issue a HTTP get request to download the new fsimage \n+              MD5Hash downloadImageDigest \u003d TransferFsImage\n+                  .downloadImageToStorage(parsedParams.getInfoServer(conf),\n+                      txid, nnImage.getStorage(), true);\n+              nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n+                  downloadImageDigest);\n+              if (nnf \u003d\u003d NameNodeFile.IMAGE_ROLLBACK) {\n+                    NameNodeHttpServer.getNameNodeFromContext(context)\n+                        .getNamesystem().setCreatedRollbackImages(true);\n+              }\n+\n+              if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n+                long elapsed \u003d now() - start;\n+                metrics.addPutImage(elapsed);\n+              }\n+              \n+              // Now that we have a new checkpoint, we might be able to\n+              // remove some old ones.\n+              nnImage.purgeOldStorage(nnf);\n+            } finally {\n+              currentlyDownloadingCheckpoints.remove(txid);\n+            }\n+          }\n+          return null;\n+        }\n\\ No newline at end of file\n",
          "actualSource": "        public Void run() throws Exception {\n          if (parsedParams.isGetImage()) {\n            long txid \u003d parsedParams.getTxId();\n            File imageFile \u003d null;\n            String errorMessage \u003d \"Could not find image\";\n            if (parsedParams.shouldFetchLatest()) {\n              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n            } else {\n              errorMessage +\u003d \" with txid \" + txid;\n              imageFile \u003d nnImage.getStorage().getFsImage(txid,\n                  EnumSet.of(NameNodeFile.IMAGE, NameNodeFile.IMAGE_ROLLBACK));\n            }\n            if (imageFile \u003d\u003d null) {\n              throw new IOException(errorMessage);\n            }\n            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n            long start \u003d now();\n            serveFile(imageFile);\n\n            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n              long elapsed \u003d now() - start;\n              metrics.addGetImage(elapsed);\n            }\n          } else if (parsedParams.isGetEdit()) {\n            long startTxId \u003d parsedParams.getStartTxId();\n            long endTxId \u003d parsedParams.getEndTxId();\n            \n            File editFile \u003d nnImage.getStorage()\n                .findFinalizedEditsFile(startTxId, endTxId);\n            long start \u003d now();\n            serveFile(editFile);\n\n            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n              long elapsed \u003d now() - start;\n              metrics.addGetEdit(elapsed);\n            }\n          } else if (parsedParams.isPutImage()) {\n            final long txid \u003d parsedParams.getTxId();\n            final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n\n            if (! currentlyDownloadingCheckpoints.add(txid)) {\n              response.sendError(HttpServletResponse.SC_CONFLICT,\n                  \"Another checkpointer is already in the process of uploading a\" +\n                  \" checkpoint made at transaction ID \" + txid);\n              return null;\n            }\n\n            try {\n              if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer already uploaded an checkpoint \" +\n                    \"for txid \" + txid);\n                return null;\n              }\n              \n              // We may have lost our ticket since last checkpoint, log in again, just in case\n              if (UserGroupInformation.isSecurityEnabled()) {\n                UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n              }\n              \n              long start \u003d now();\n              // issue a HTTP get request to download the new fsimage \n              MD5Hash downloadImageDigest \u003d TransferFsImage\n                  .downloadImageToStorage(parsedParams.getInfoServer(conf),\n                      txid, nnImage.getStorage(), true);\n              nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                  downloadImageDigest);\n              if (nnf \u003d\u003d NameNodeFile.IMAGE_ROLLBACK) {\n                    NameNodeHttpServer.getNameNodeFromContext(context)\n                        .getNamesystem().setCreatedRollbackImages(true);\n              }\n\n              if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n                long elapsed \u003d now() - start;\n                metrics.addPutImage(elapsed);\n              }\n              \n              // Now that we have a new checkpoint, we might be able to\n              // remove some old ones.\n              nnImage.purgeOldStorage(nnf);\n            } finally {\n              currentlyDownloadingCheckpoints.remove(txid);\n            }\n          }\n          return null;\n        }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageServlet.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "Revert HDFS-3405 for recommit with correct renamed files\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1575610 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "08/03/14 1:15 PM",
          "commitName": "dbd22b23c2d68b97b4da47215897906f06f978e3",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "08/03/14 1:11 PM",
          "commitNameOld": "98594ab787d2e2a6b499f576e0cbda10767eaf15",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,45 +1,86 @@\n-            public Void run() throws Exception {\n+        public Void run() throws Exception {\n+          if (parsedParams.isGetImage()) {\n+            long txid \u003d parsedParams.getTxId();\n+            File imageFile \u003d null;\n+            String errorMessage \u003d \"Could not find image\";\n+            if (parsedParams.shouldFetchLatest()) {\n+              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n+            } else {\n+              errorMessage +\u003d \" with txid \" + txid;\n+              imageFile \u003d nnImage.getStorage().getFsImage(txid,\n+                  EnumSet.of(NameNodeFile.IMAGE, NameNodeFile.IMAGE_ROLLBACK));\n+            }\n+            if (imageFile \u003d\u003d null) {\n+              throw new IOException(errorMessage);\n+            }\n+            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n+            long start \u003d now();\n+            serveFile(imageFile);\n \n-              final long txid \u003d parsedParams.getTxId();\n+            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n+              long elapsed \u003d now() - start;\n+              metrics.addGetImage(elapsed);\n+            }\n+          } else if (parsedParams.isGetEdit()) {\n+            long startTxId \u003d parsedParams.getStartTxId();\n+            long endTxId \u003d parsedParams.getEndTxId();\n+            \n+            File editFile \u003d nnImage.getStorage()\n+                .findFinalizedEditsFile(startTxId, endTxId);\n+            long start \u003d now();\n+            serveFile(editFile);\n \n-              final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n+            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n+              long elapsed \u003d now() - start;\n+              metrics.addGetEdit(elapsed);\n+            }\n+          } else if (parsedParams.isPutImage()) {\n+            final long txid \u003d parsedParams.getTxId();\n+            final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n \n-              if (!currentlyDownloadingCheckpoints.add(txid)) {\n+            if (! currentlyDownloadingCheckpoints.add(txid)) {\n+              response.sendError(HttpServletResponse.SC_CONFLICT,\n+                  \"Another checkpointer is already in the process of uploading a\" +\n+                  \" checkpoint made at transaction ID \" + txid);\n+              return null;\n+            }\n+\n+            try {\n+              if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n-                    \"Another checkpointer is already in the process of uploading a\"\n-                        + \" checkpoint made at transaction ID \" + txid);\n+                    \"Another checkpointer already uploaded an checkpoint \" +\n+                    \"for txid \" + txid);\n                 return null;\n               }\n-              try {\n-                if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n-                  response.sendError(HttpServletResponse.SC_CONFLICT,\n-                      \"Another checkpointer already uploaded an checkpoint \"\n-                          + \"for txid \" + txid);\n-                  return null;\n-                }\n-\n-                InputStream stream \u003d request.getInputStream();\n-                try {\n-                  long start \u003d now();\n-                  MD5Hash downloadImageDigest \u003d TransferFsImage\n-                      .handleUploadImageRequest(request, txid,\n-                          nnImage.getStorage(), stream,\n-                          parsedParams.getFileSize(), getThrottler(conf));\n-                  nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n-                      downloadImageDigest);\n-                  // Metrics non-null only when used inside name node\n-                  if (metrics !\u003d null) {\n-                    long elapsed \u003d now() - start;\n-                    metrics.addPutImage(elapsed);\n-                  }\n-                  // Now that we have a new checkpoint, we might be able to\n-                  // remove some old ones.\n-                  nnImage.purgeOldStorage(nnf);\n-                } finally {\n-                  stream.close();\n-                }\n-              } finally {\n-                currentlyDownloadingCheckpoints.remove(txid);\n+              \n+              // We may have lost our ticket since last checkpoint, log in again, just in case\n+              if (UserGroupInformation.isSecurityEnabled()) {\n+                UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n               }\n-              return null;\n-            }\n\\ No newline at end of file\n+              \n+              long start \u003d now();\n+              // issue a HTTP get request to download the new fsimage \n+              MD5Hash downloadImageDigest \u003d TransferFsImage\n+                  .downloadImageToStorage(parsedParams.getInfoServer(conf),\n+                      txid, nnImage.getStorage(), true);\n+              nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n+                  downloadImageDigest);\n+              if (nnf \u003d\u003d NameNodeFile.IMAGE_ROLLBACK) {\n+                    NameNodeHttpServer.getNameNodeFromContext(context)\n+                        .getNamesystem().setCreatedRollbackImages(true);\n+              }\n+\n+              if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n+                long elapsed \u003d now() - start;\n+                metrics.addPutImage(elapsed);\n+              }\n+              \n+              // Now that we have a new checkpoint, we might be able to\n+              // remove some old ones.\n+              nnImage.purgeOldStorage(nnf);\n+            } finally {\n+              currentlyDownloadingCheckpoints.remove(txid);\n+            }\n+          }\n+          return null;\n+        }\n\\ No newline at end of file\n",
          "actualSource": "        public Void run() throws Exception {\n          if (parsedParams.isGetImage()) {\n            long txid \u003d parsedParams.getTxId();\n            File imageFile \u003d null;\n            String errorMessage \u003d \"Could not find image\";\n            if (parsedParams.shouldFetchLatest()) {\n              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n            } else {\n              errorMessage +\u003d \" with txid \" + txid;\n              imageFile \u003d nnImage.getStorage().getFsImage(txid,\n                  EnumSet.of(NameNodeFile.IMAGE, NameNodeFile.IMAGE_ROLLBACK));\n            }\n            if (imageFile \u003d\u003d null) {\n              throw new IOException(errorMessage);\n            }\n            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n            long start \u003d now();\n            serveFile(imageFile);\n\n            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n              long elapsed \u003d now() - start;\n              metrics.addGetImage(elapsed);\n            }\n          } else if (parsedParams.isGetEdit()) {\n            long startTxId \u003d parsedParams.getStartTxId();\n            long endTxId \u003d parsedParams.getEndTxId();\n            \n            File editFile \u003d nnImage.getStorage()\n                .findFinalizedEditsFile(startTxId, endTxId);\n            long start \u003d now();\n            serveFile(editFile);\n\n            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n              long elapsed \u003d now() - start;\n              metrics.addGetEdit(elapsed);\n            }\n          } else if (parsedParams.isPutImage()) {\n            final long txid \u003d parsedParams.getTxId();\n            final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n\n            if (! currentlyDownloadingCheckpoints.add(txid)) {\n              response.sendError(HttpServletResponse.SC_CONFLICT,\n                  \"Another checkpointer is already in the process of uploading a\" +\n                  \" checkpoint made at transaction ID \" + txid);\n              return null;\n            }\n\n            try {\n              if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer already uploaded an checkpoint \" +\n                    \"for txid \" + txid);\n                return null;\n              }\n              \n              // We may have lost our ticket since last checkpoint, log in again, just in case\n              if (UserGroupInformation.isSecurityEnabled()) {\n                UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n              }\n              \n              long start \u003d now();\n              // issue a HTTP get request to download the new fsimage \n              MD5Hash downloadImageDigest \u003d TransferFsImage\n                  .downloadImageToStorage(parsedParams.getInfoServer(conf),\n                      txid, nnImage.getStorage(), true);\n              nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                  downloadImageDigest);\n              if (nnf \u003d\u003d NameNodeFile.IMAGE_ROLLBACK) {\n                    NameNodeHttpServer.getNameNodeFromContext(context)\n                        .getNamesystem().setCreatedRollbackImages(true);\n              }\n\n              if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n                long elapsed \u003d now() - start;\n                metrics.addPutImage(elapsed);\n              }\n              \n              // Now that we have a new checkpoint, we might be able to\n              // remove some old ones.\n              nnImage.purgeOldStorage(nnf);\n            } finally {\n              currentlyDownloadingCheckpoints.remove(txid);\n            }\n          }\n          return null;\n        }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
          "extendedDetails": {}
        }
      ]
    },
    "0f595915a388305edbb3ce928415571811d304e8": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-3405. Checkpointing should use HTTP POST or PUT instead of GET-GET to send merged fsimages. Contributed by Vinayakumar B.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1575457 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/03/14 4:39 PM",
      "commitName": "0f595915a388305edbb3ce928415571811d304e8",
      "commitAuthor": "Andrew Wang",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-3405. Checkpointing should use HTTP POST or PUT instead of GET-GET to send merged fsimages. Contributed by Vinayakumar B.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1575457 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/03/14 4:39 PM",
          "commitName": "0f595915a388305edbb3ce928415571811d304e8",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "07/03/14 3:47 PM",
          "commitNameOld": "1f6c2b09c6a5dc07f5caa1cad7036e0e1465f33e",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,86 +1,45 @@\n-        public Void run() throws Exception {\n-          if (parsedParams.isGetImage()) {\n-            long txid \u003d parsedParams.getTxId();\n-            File imageFile \u003d null;\n-            String errorMessage \u003d \"Could not find image\";\n-            if (parsedParams.shouldFetchLatest()) {\n-              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n-            } else {\n-              errorMessage +\u003d \" with txid \" + txid;\n-              imageFile \u003d nnImage.getStorage().getFsImage(txid,\n-                  EnumSet.of(NameNodeFile.IMAGE, NameNodeFile.IMAGE_ROLLBACK));\n-            }\n-            if (imageFile \u003d\u003d null) {\n-              throw new IOException(errorMessage);\n-            }\n-            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n-            long start \u003d now();\n-            serveFile(imageFile);\n+            public Void run() throws Exception {\n \n-            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n-              long elapsed \u003d now() - start;\n-              metrics.addGetImage(elapsed);\n-            }\n-          } else if (parsedParams.isGetEdit()) {\n-            long startTxId \u003d parsedParams.getStartTxId();\n-            long endTxId \u003d parsedParams.getEndTxId();\n-            \n-            File editFile \u003d nnImage.getStorage()\n-                .findFinalizedEditsFile(startTxId, endTxId);\n-            long start \u003d now();\n-            serveFile(editFile);\n+              final long txid \u003d parsedParams.getTxId();\n \n-            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n-              long elapsed \u003d now() - start;\n-              metrics.addGetEdit(elapsed);\n-            }\n-          } else if (parsedParams.isPutImage()) {\n-            final long txid \u003d parsedParams.getTxId();\n-            final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n+              final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n \n-            if (! currentlyDownloadingCheckpoints.add(txid)) {\n-              response.sendError(HttpServletResponse.SC_CONFLICT,\n-                  \"Another checkpointer is already in the process of uploading a\" +\n-                  \" checkpoint made at transaction ID \" + txid);\n-              return null;\n-            }\n-\n-            try {\n-              if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n+              if (!currentlyDownloadingCheckpoints.add(txid)) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n-                    \"Another checkpointer already uploaded an checkpoint \" +\n-                    \"for txid \" + txid);\n+                    \"Another checkpointer is already in the process of uploading a\"\n+                        + \" checkpoint made at transaction ID \" + txid);\n                 return null;\n               }\n-              \n-              // We may have lost our ticket since last checkpoint, log in again, just in case\n-              if (UserGroupInformation.isSecurityEnabled()) {\n-                UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n-              }\n-              \n-              long start \u003d now();\n-              // issue a HTTP get request to download the new fsimage \n-              MD5Hash downloadImageDigest \u003d TransferFsImage\n-                  .downloadImageToStorage(parsedParams.getInfoServer(conf),\n-                      txid, nnImage.getStorage(), true);\n-              nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n-                  downloadImageDigest);\n-              if (nnf \u003d\u003d NameNodeFile.IMAGE_ROLLBACK) {\n-                    NameNodeHttpServer.getNameNodeFromContext(context)\n-                        .getNamesystem().setCreatedRollbackImages(true);\n-              }\n+              try {\n+                if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n+                  response.sendError(HttpServletResponse.SC_CONFLICT,\n+                      \"Another checkpointer already uploaded an checkpoint \"\n+                          + \"for txid \" + txid);\n+                  return null;\n+                }\n \n-              if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n-                long elapsed \u003d now() - start;\n-                metrics.addPutImage(elapsed);\n+                InputStream stream \u003d request.getInputStream();\n+                try {\n+                  long start \u003d now();\n+                  MD5Hash downloadImageDigest \u003d TransferFsImage\n+                      .handleUploadImageRequest(request, txid,\n+                          nnImage.getStorage(), stream,\n+                          parsedParams.getFileSize(), getThrottler(conf));\n+                  nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n+                      downloadImageDigest);\n+                  // Metrics non-null only when used inside name node\n+                  if (metrics !\u003d null) {\n+                    long elapsed \u003d now() - start;\n+                    metrics.addPutImage(elapsed);\n+                  }\n+                  // Now that we have a new checkpoint, we might be able to\n+                  // remove some old ones.\n+                  nnImage.purgeOldStorage(nnf);\n+                } finally {\n+                  stream.close();\n+                }\n+              } finally {\n+                currentlyDownloadingCheckpoints.remove(txid);\n               }\n-              \n-              // Now that we have a new checkpoint, we might be able to\n-              // remove some old ones.\n-              nnImage.purgeOldStorage(nnf);\n-            } finally {\n-              currentlyDownloadingCheckpoints.remove(txid);\n-            }\n-          }\n-          return null;\n-        }\n\\ No newline at end of file\n+              return null;\n+            }\n\\ No newline at end of file\n",
          "actualSource": "            public Void run() throws Exception {\n\n              final long txid \u003d parsedParams.getTxId();\n\n              final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n\n              if (!currentlyDownloadingCheckpoints.add(txid)) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer is already in the process of uploading a\"\n                        + \" checkpoint made at transaction ID \" + txid);\n                return null;\n              }\n              try {\n                if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                  response.sendError(HttpServletResponse.SC_CONFLICT,\n                      \"Another checkpointer already uploaded an checkpoint \"\n                          + \"for txid \" + txid);\n                  return null;\n                }\n\n                InputStream stream \u003d request.getInputStream();\n                try {\n                  long start \u003d now();\n                  MD5Hash downloadImageDigest \u003d TransferFsImage\n                      .handleUploadImageRequest(request, txid,\n                          nnImage.getStorage(), stream,\n                          parsedParams.getFileSize(), getThrottler(conf));\n                  nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                      downloadImageDigest);\n                  // Metrics non-null only when used inside name node\n                  if (metrics !\u003d null) {\n                    long elapsed \u003d now() - start;\n                    metrics.addPutImage(elapsed);\n                  }\n                  // Now that we have a new checkpoint, we might be able to\n                  // remove some old ones.\n                  nnImage.purgeOldStorage(nnf);\n                } finally {\n                  stream.close();\n                }\n              } finally {\n                currentlyDownloadingCheckpoints.remove(txid);\n              }\n              return null;\n            }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageServlet.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageServlet.java",
            "oldMethodName": "run",
            "newMethodName": "run"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3405. Checkpointing should use HTTP POST or PUT instead of GET-GET to send merged fsimages. Contributed by Vinayakumar B.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1575457 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/03/14 4:39 PM",
          "commitName": "0f595915a388305edbb3ce928415571811d304e8",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "07/03/14 3:47 PM",
          "commitNameOld": "1f6c2b09c6a5dc07f5caa1cad7036e0e1465f33e",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,86 +1,45 @@\n-        public Void run() throws Exception {\n-          if (parsedParams.isGetImage()) {\n-            long txid \u003d parsedParams.getTxId();\n-            File imageFile \u003d null;\n-            String errorMessage \u003d \"Could not find image\";\n-            if (parsedParams.shouldFetchLatest()) {\n-              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n-            } else {\n-              errorMessage +\u003d \" with txid \" + txid;\n-              imageFile \u003d nnImage.getStorage().getFsImage(txid,\n-                  EnumSet.of(NameNodeFile.IMAGE, NameNodeFile.IMAGE_ROLLBACK));\n-            }\n-            if (imageFile \u003d\u003d null) {\n-              throw new IOException(errorMessage);\n-            }\n-            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n-            long start \u003d now();\n-            serveFile(imageFile);\n+            public Void run() throws Exception {\n \n-            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n-              long elapsed \u003d now() - start;\n-              metrics.addGetImage(elapsed);\n-            }\n-          } else if (parsedParams.isGetEdit()) {\n-            long startTxId \u003d parsedParams.getStartTxId();\n-            long endTxId \u003d parsedParams.getEndTxId();\n-            \n-            File editFile \u003d nnImage.getStorage()\n-                .findFinalizedEditsFile(startTxId, endTxId);\n-            long start \u003d now();\n-            serveFile(editFile);\n+              final long txid \u003d parsedParams.getTxId();\n \n-            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n-              long elapsed \u003d now() - start;\n-              metrics.addGetEdit(elapsed);\n-            }\n-          } else if (parsedParams.isPutImage()) {\n-            final long txid \u003d parsedParams.getTxId();\n-            final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n+              final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n \n-            if (! currentlyDownloadingCheckpoints.add(txid)) {\n-              response.sendError(HttpServletResponse.SC_CONFLICT,\n-                  \"Another checkpointer is already in the process of uploading a\" +\n-                  \" checkpoint made at transaction ID \" + txid);\n-              return null;\n-            }\n-\n-            try {\n-              if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n+              if (!currentlyDownloadingCheckpoints.add(txid)) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n-                    \"Another checkpointer already uploaded an checkpoint \" +\n-                    \"for txid \" + txid);\n+                    \"Another checkpointer is already in the process of uploading a\"\n+                        + \" checkpoint made at transaction ID \" + txid);\n                 return null;\n               }\n-              \n-              // We may have lost our ticket since last checkpoint, log in again, just in case\n-              if (UserGroupInformation.isSecurityEnabled()) {\n-                UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n-              }\n-              \n-              long start \u003d now();\n-              // issue a HTTP get request to download the new fsimage \n-              MD5Hash downloadImageDigest \u003d TransferFsImage\n-                  .downloadImageToStorage(parsedParams.getInfoServer(conf),\n-                      txid, nnImage.getStorage(), true);\n-              nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n-                  downloadImageDigest);\n-              if (nnf \u003d\u003d NameNodeFile.IMAGE_ROLLBACK) {\n-                    NameNodeHttpServer.getNameNodeFromContext(context)\n-                        .getNamesystem().setCreatedRollbackImages(true);\n-              }\n+              try {\n+                if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n+                  response.sendError(HttpServletResponse.SC_CONFLICT,\n+                      \"Another checkpointer already uploaded an checkpoint \"\n+                          + \"for txid \" + txid);\n+                  return null;\n+                }\n \n-              if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n-                long elapsed \u003d now() - start;\n-                metrics.addPutImage(elapsed);\n+                InputStream stream \u003d request.getInputStream();\n+                try {\n+                  long start \u003d now();\n+                  MD5Hash downloadImageDigest \u003d TransferFsImage\n+                      .handleUploadImageRequest(request, txid,\n+                          nnImage.getStorage(), stream,\n+                          parsedParams.getFileSize(), getThrottler(conf));\n+                  nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n+                      downloadImageDigest);\n+                  // Metrics non-null only when used inside name node\n+                  if (metrics !\u003d null) {\n+                    long elapsed \u003d now() - start;\n+                    metrics.addPutImage(elapsed);\n+                  }\n+                  // Now that we have a new checkpoint, we might be able to\n+                  // remove some old ones.\n+                  nnImage.purgeOldStorage(nnf);\n+                } finally {\n+                  stream.close();\n+                }\n+              } finally {\n+                currentlyDownloadingCheckpoints.remove(txid);\n               }\n-              \n-              // Now that we have a new checkpoint, we might be able to\n-              // remove some old ones.\n-              nnImage.purgeOldStorage(nnf);\n-            } finally {\n-              currentlyDownloadingCheckpoints.remove(txid);\n-            }\n-          }\n-          return null;\n-        }\n\\ No newline at end of file\n+              return null;\n+            }\n\\ No newline at end of file\n",
          "actualSource": "            public Void run() throws Exception {\n\n              final long txid \u003d parsedParams.getTxId();\n\n              final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n\n              if (!currentlyDownloadingCheckpoints.add(txid)) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer is already in the process of uploading a\"\n                        + \" checkpoint made at transaction ID \" + txid);\n                return null;\n              }\n              try {\n                if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                  response.sendError(HttpServletResponse.SC_CONFLICT,\n                      \"Another checkpointer already uploaded an checkpoint \"\n                          + \"for txid \" + txid);\n                  return null;\n                }\n\n                InputStream stream \u003d request.getInputStream();\n                try {\n                  long start \u003d now();\n                  MD5Hash downloadImageDigest \u003d TransferFsImage\n                      .handleUploadImageRequest(request, txid,\n                          nnImage.getStorage(), stream,\n                          parsedParams.getFileSize(), getThrottler(conf));\n                  nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                      downloadImageDigest);\n                  // Metrics non-null only when used inside name node\n                  if (metrics !\u003d null) {\n                    long elapsed \u003d now() - start;\n                    metrics.addPutImage(elapsed);\n                  }\n                  // Now that we have a new checkpoint, we might be able to\n                  // remove some old ones.\n                  nnImage.purgeOldStorage(nnf);\n                } finally {\n                  stream.close();\n                }\n              } finally {\n                currentlyDownloadingCheckpoints.remove(txid);\n              }\n              return null;\n            }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageServlet.java",
          "extendedDetails": {}
        }
      ]
    },
    "e9a17c8ce0656a4e5d47401ca22a575c5f5f66db": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6029. Secondary NN fails to checkpoint after -rollingUpgrade prepare. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1572800 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/02/14 5:21 PM",
      "commitName": "e9a17c8ce0656a4e5d47401ca22a575c5f5f66db",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "25/02/14 1:58 PM",
      "commitNameOld": "e3d2e4c156851de7dac16154521a2e06ea83ec7b",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 2.14,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,86 @@\n         public Void run() throws Exception {\n           if (parsedParams.isGetImage()) {\n             long txid \u003d parsedParams.getTxId();\n-            final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n             File imageFile \u003d null;\n             String errorMessage \u003d \"Could not find image\";\n             if (parsedParams.shouldFetchLatest()) {\n               imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n             } else {\n               errorMessage +\u003d \" with txid \" + txid;\n-              imageFile \u003d nnImage.getStorage().getFsImageName(txid, nnf);\n+              imageFile \u003d nnImage.getStorage().getFsImage(txid,\n+                  EnumSet.of(NameNodeFile.IMAGE, NameNodeFile.IMAGE_ROLLBACK));\n             }\n             if (imageFile \u003d\u003d null) {\n               throw new IOException(errorMessage);\n             }\n             CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n             long start \u003d now();\n             serveFile(imageFile);\n \n             if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n               long elapsed \u003d now() - start;\n               metrics.addGetImage(elapsed);\n             }\n           } else if (parsedParams.isGetEdit()) {\n             long startTxId \u003d parsedParams.getStartTxId();\n             long endTxId \u003d parsedParams.getEndTxId();\n             \n             File editFile \u003d nnImage.getStorage()\n                 .findFinalizedEditsFile(startTxId, endTxId);\n             long start \u003d now();\n             serveFile(editFile);\n \n             if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n               long elapsed \u003d now() - start;\n               metrics.addGetEdit(elapsed);\n             }\n           } else if (parsedParams.isPutImage()) {\n             final long txid \u003d parsedParams.getTxId();\n             final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n \n             if (! currentlyDownloadingCheckpoints.add(txid)) {\n               response.sendError(HttpServletResponse.SC_CONFLICT,\n                   \"Another checkpointer is already in the process of uploading a\" +\n                   \" checkpoint made at transaction ID \" + txid);\n               return null;\n             }\n \n             try {\n               if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Another checkpointer already uploaded an checkpoint \" +\n                     \"for txid \" + txid);\n                 return null;\n               }\n               \n               // We may have lost our ticket since last checkpoint, log in again, just in case\n               if (UserGroupInformation.isSecurityEnabled()) {\n                 UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n               }\n               \n               long start \u003d now();\n               // issue a HTTP get request to download the new fsimage \n               MD5Hash downloadImageDigest \u003d TransferFsImage\n                   .downloadImageToStorage(parsedParams.getInfoServer(conf),\n-                      nnf, txid, nnImage.getStorage(), true);\n+                      txid, nnImage.getStorage(), true);\n               nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                   downloadImageDigest);\n               if (nnf \u003d\u003d NameNodeFile.IMAGE_ROLLBACK) {\n                     NameNodeHttpServer.getNameNodeFromContext(context)\n                         .getNamesystem().setCreatedRollbackImages(true);\n               }\n \n               if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n                 long elapsed \u003d now() - start;\n                 metrics.addPutImage(elapsed);\n               }\n               \n               // Now that we have a new checkpoint, we might be able to\n               // remove some old ones.\n               nnImage.purgeOldStorage(nnf);\n             } finally {\n               currentlyDownloadingCheckpoints.remove(txid);\n             }\n           }\n           return null;\n         }\n\\ No newline at end of file\n",
      "actualSource": "        public Void run() throws Exception {\n          if (parsedParams.isGetImage()) {\n            long txid \u003d parsedParams.getTxId();\n            File imageFile \u003d null;\n            String errorMessage \u003d \"Could not find image\";\n            if (parsedParams.shouldFetchLatest()) {\n              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n            } else {\n              errorMessage +\u003d \" with txid \" + txid;\n              imageFile \u003d nnImage.getStorage().getFsImage(txid,\n                  EnumSet.of(NameNodeFile.IMAGE, NameNodeFile.IMAGE_ROLLBACK));\n            }\n            if (imageFile \u003d\u003d null) {\n              throw new IOException(errorMessage);\n            }\n            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n            long start \u003d now();\n            serveFile(imageFile);\n\n            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n              long elapsed \u003d now() - start;\n              metrics.addGetImage(elapsed);\n            }\n          } else if (parsedParams.isGetEdit()) {\n            long startTxId \u003d parsedParams.getStartTxId();\n            long endTxId \u003d parsedParams.getEndTxId();\n            \n            File editFile \u003d nnImage.getStorage()\n                .findFinalizedEditsFile(startTxId, endTxId);\n            long start \u003d now();\n            serveFile(editFile);\n\n            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n              long elapsed \u003d now() - start;\n              metrics.addGetEdit(elapsed);\n            }\n          } else if (parsedParams.isPutImage()) {\n            final long txid \u003d parsedParams.getTxId();\n            final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n\n            if (! currentlyDownloadingCheckpoints.add(txid)) {\n              response.sendError(HttpServletResponse.SC_CONFLICT,\n                  \"Another checkpointer is already in the process of uploading a\" +\n                  \" checkpoint made at transaction ID \" + txid);\n              return null;\n            }\n\n            try {\n              if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer already uploaded an checkpoint \" +\n                    \"for txid \" + txid);\n                return null;\n              }\n              \n              // We may have lost our ticket since last checkpoint, log in again, just in case\n              if (UserGroupInformation.isSecurityEnabled()) {\n                UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n              }\n              \n              long start \u003d now();\n              // issue a HTTP get request to download the new fsimage \n              MD5Hash downloadImageDigest \u003d TransferFsImage\n                  .downloadImageToStorage(parsedParams.getInfoServer(conf),\n                      txid, nnImage.getStorage(), true);\n              nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                  downloadImageDigest);\n              if (nnf \u003d\u003d NameNodeFile.IMAGE_ROLLBACK) {\n                    NameNodeHttpServer.getNameNodeFromContext(context)\n                        .getNamesystem().setCreatedRollbackImages(true);\n              }\n\n              if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n                long elapsed \u003d now() - start;\n                metrics.addPutImage(elapsed);\n              }\n              \n              // Now that we have a new checkpoint, we might be able to\n              // remove some old ones.\n              nnImage.purgeOldStorage(nnf);\n            } finally {\n              currentlyDownloadingCheckpoints.remove(txid);\n            }\n          }\n          return null;\n        }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
      "extendedDetails": {}
    },
    "e3d2e4c156851de7dac16154521a2e06ea83ec7b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6000. Avoid saving namespace when starting rolling upgrade. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1571840 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/02/14 1:58 PM",
      "commitName": "e3d2e4c156851de7dac16154521a2e06ea83ec7b",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "13/02/14 12:04 AM",
      "commitNameOld": "4f9bbaa301194e3d20972a10f51638c7f4d121f0",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 12.58,
      "commitsBetweenForRepo": 123,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,86 @@\n         public Void run() throws Exception {\n           if (parsedParams.isGetImage()) {\n             long txid \u003d parsedParams.getTxId();\n+            final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n             File imageFile \u003d null;\n             String errorMessage \u003d \"Could not find image\";\n             if (parsedParams.shouldFetchLatest()) {\n               imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n             } else {\n               errorMessage +\u003d \" with txid \" + txid;\n-              imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n+              imageFile \u003d nnImage.getStorage().getFsImageName(txid, nnf);\n             }\n             if (imageFile \u003d\u003d null) {\n               throw new IOException(errorMessage);\n             }\n             CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n             long start \u003d now();\n             serveFile(imageFile);\n \n             if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n               long elapsed \u003d now() - start;\n               metrics.addGetImage(elapsed);\n             }\n           } else if (parsedParams.isGetEdit()) {\n             long startTxId \u003d parsedParams.getStartTxId();\n             long endTxId \u003d parsedParams.getEndTxId();\n             \n             File editFile \u003d nnImage.getStorage()\n                 .findFinalizedEditsFile(startTxId, endTxId);\n             long start \u003d now();\n             serveFile(editFile);\n \n             if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n               long elapsed \u003d now() - start;\n               metrics.addGetEdit(elapsed);\n             }\n           } else if (parsedParams.isPutImage()) {\n             final long txid \u003d parsedParams.getTxId();\n+            final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n \n             if (! currentlyDownloadingCheckpoints.add(txid)) {\n               response.sendError(HttpServletResponse.SC_CONFLICT,\n                   \"Another checkpointer is already in the process of uploading a\" +\n                   \" checkpoint made at transaction ID \" + txid);\n               return null;\n             }\n \n             try {\n-              if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n+              if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Another checkpointer already uploaded an checkpoint \" +\n                     \"for txid \" + txid);\n                 return null;\n               }\n               \n               // We may have lost our ticket since last checkpoint, log in again, just in case\n               if (UserGroupInformation.isSecurityEnabled()) {\n                 UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n               }\n               \n               long start \u003d now();\n               // issue a HTTP get request to download the new fsimage \n-              MD5Hash downloadImageDigest \u003d\n-                TransferFsImage.downloadImageToStorage(\n-                        parsedParams.getInfoServer(conf), txid,\n-                        nnImage.getStorage(), true);\n-              nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n+              MD5Hash downloadImageDigest \u003d TransferFsImage\n+                  .downloadImageToStorage(parsedParams.getInfoServer(conf),\n+                      nnf, txid, nnImage.getStorage(), true);\n+              nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n+                  downloadImageDigest);\n+              if (nnf \u003d\u003d NameNodeFile.IMAGE_ROLLBACK) {\n+                    NameNodeHttpServer.getNameNodeFromContext(context)\n+                        .getNamesystem().setCreatedRollbackImages(true);\n+              }\n \n               if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n                 long elapsed \u003d now() - start;\n                 metrics.addPutImage(elapsed);\n               }\n               \n               // Now that we have a new checkpoint, we might be able to\n               // remove some old ones.\n-              nnImage.purgeOldStorage(NameNodeFile.IMAGE);\n+              nnImage.purgeOldStorage(nnf);\n             } finally {\n               currentlyDownloadingCheckpoints.remove(txid);\n             }\n           }\n           return null;\n         }\n\\ No newline at end of file\n",
      "actualSource": "        public Void run() throws Exception {\n          if (parsedParams.isGetImage()) {\n            long txid \u003d parsedParams.getTxId();\n            final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n            File imageFile \u003d null;\n            String errorMessage \u003d \"Could not find image\";\n            if (parsedParams.shouldFetchLatest()) {\n              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n            } else {\n              errorMessage +\u003d \" with txid \" + txid;\n              imageFile \u003d nnImage.getStorage().getFsImageName(txid, nnf);\n            }\n            if (imageFile \u003d\u003d null) {\n              throw new IOException(errorMessage);\n            }\n            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n            long start \u003d now();\n            serveFile(imageFile);\n\n            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n              long elapsed \u003d now() - start;\n              metrics.addGetImage(elapsed);\n            }\n          } else if (parsedParams.isGetEdit()) {\n            long startTxId \u003d parsedParams.getStartTxId();\n            long endTxId \u003d parsedParams.getEndTxId();\n            \n            File editFile \u003d nnImage.getStorage()\n                .findFinalizedEditsFile(startTxId, endTxId);\n            long start \u003d now();\n            serveFile(editFile);\n\n            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n              long elapsed \u003d now() - start;\n              metrics.addGetEdit(elapsed);\n            }\n          } else if (parsedParams.isPutImage()) {\n            final long txid \u003d parsedParams.getTxId();\n            final NameNodeFile nnf \u003d parsedParams.getNameNodeFile();\n\n            if (! currentlyDownloadingCheckpoints.add(txid)) {\n              response.sendError(HttpServletResponse.SC_CONFLICT,\n                  \"Another checkpointer is already in the process of uploading a\" +\n                  \" checkpoint made at transaction ID \" + txid);\n              return null;\n            }\n\n            try {\n              if (nnImage.getStorage().findImageFile(nnf, txid) !\u003d null) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer already uploaded an checkpoint \" +\n                    \"for txid \" + txid);\n                return null;\n              }\n              \n              // We may have lost our ticket since last checkpoint, log in again, just in case\n              if (UserGroupInformation.isSecurityEnabled()) {\n                UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n              }\n              \n              long start \u003d now();\n              // issue a HTTP get request to download the new fsimage \n              MD5Hash downloadImageDigest \u003d TransferFsImage\n                  .downloadImageToStorage(parsedParams.getInfoServer(conf),\n                      nnf, txid, nnImage.getStorage(), true);\n              nnImage.saveDigestAndRenameCheckpointImage(nnf, txid,\n                  downloadImageDigest);\n              if (nnf \u003d\u003d NameNodeFile.IMAGE_ROLLBACK) {\n                    NameNodeHttpServer.getNameNodeFromContext(context)\n                        .getNamesystem().setCreatedRollbackImages(true);\n              }\n\n              if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n                long elapsed \u003d now() - start;\n                metrics.addPutImage(elapsed);\n              }\n              \n              // Now that we have a new checkpoint, we might be able to\n              // remove some old ones.\n              nnImage.purgeOldStorage(nnf);\n            } finally {\n              currentlyDownloadingCheckpoints.remove(txid);\n            }\n          }\n          return null;\n        }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
      "extendedDetails": {}
    },
    "4f9bbaa301194e3d20972a10f51638c7f4d121f0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5889. When starting rolling upgrade, create a fs image for rollback so that the standby namenode can create checkpoints during upgrade.  Contributed by szetszwo \u0026 jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1567861 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/02/14 12:04 AM",
      "commitName": "4f9bbaa301194e3d20972a10f51638c7f4d121f0",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "27/01/14 11:32 PM",
      "commitNameOld": "33a47743a5f4263bc21b345587370c5ecf43f5b4",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 16.02,
      "commitsBetweenForRepo": 93,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,80 @@\n         public Void run() throws Exception {\n           if (parsedParams.isGetImage()) {\n             long txid \u003d parsedParams.getTxId();\n             File imageFile \u003d null;\n             String errorMessage \u003d \"Could not find image\";\n             if (parsedParams.shouldFetchLatest()) {\n               imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n             } else {\n               errorMessage +\u003d \" with txid \" + txid;\n               imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n             }\n             if (imageFile \u003d\u003d null) {\n               throw new IOException(errorMessage);\n             }\n             CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n             long start \u003d now();\n             serveFile(imageFile);\n \n             if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n               long elapsed \u003d now() - start;\n               metrics.addGetImage(elapsed);\n             }\n           } else if (parsedParams.isGetEdit()) {\n             long startTxId \u003d parsedParams.getStartTxId();\n             long endTxId \u003d parsedParams.getEndTxId();\n             \n             File editFile \u003d nnImage.getStorage()\n                 .findFinalizedEditsFile(startTxId, endTxId);\n             long start \u003d now();\n             serveFile(editFile);\n \n             if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n               long elapsed \u003d now() - start;\n               metrics.addGetEdit(elapsed);\n             }\n           } else if (parsedParams.isPutImage()) {\n             final long txid \u003d parsedParams.getTxId();\n \n             if (! currentlyDownloadingCheckpoints.add(txid)) {\n               response.sendError(HttpServletResponse.SC_CONFLICT,\n                   \"Another checkpointer is already in the process of uploading a\" +\n                   \" checkpoint made at transaction ID \" + txid);\n               return null;\n             }\n \n             try {\n               if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Another checkpointer already uploaded an checkpoint \" +\n                     \"for txid \" + txid);\n                 return null;\n               }\n               \n               // We may have lost our ticket since last checkpoint, log in again, just in case\n               if (UserGroupInformation.isSecurityEnabled()) {\n                 UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n               }\n               \n               long start \u003d now();\n               // issue a HTTP get request to download the new fsimage \n               MD5Hash downloadImageDigest \u003d\n                 TransferFsImage.downloadImageToStorage(\n                         parsedParams.getInfoServer(conf), txid,\n                         nnImage.getStorage(), true);\n               nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n \n               if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n                 long elapsed \u003d now() - start;\n                 metrics.addPutImage(elapsed);\n               }\n               \n               // Now that we have a new checkpoint, we might be able to\n               // remove some old ones.\n-              nnImage.purgeOldStorage();\n+              nnImage.purgeOldStorage(NameNodeFile.IMAGE);\n             } finally {\n               currentlyDownloadingCheckpoints.remove(txid);\n             }\n           }\n           return null;\n         }\n\\ No newline at end of file\n",
      "actualSource": "        public Void run() throws Exception {\n          if (parsedParams.isGetImage()) {\n            long txid \u003d parsedParams.getTxId();\n            File imageFile \u003d null;\n            String errorMessage \u003d \"Could not find image\";\n            if (parsedParams.shouldFetchLatest()) {\n              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n            } else {\n              errorMessage +\u003d \" with txid \" + txid;\n              imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n            }\n            if (imageFile \u003d\u003d null) {\n              throw new IOException(errorMessage);\n            }\n            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n            long start \u003d now();\n            serveFile(imageFile);\n\n            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n              long elapsed \u003d now() - start;\n              metrics.addGetImage(elapsed);\n            }\n          } else if (parsedParams.isGetEdit()) {\n            long startTxId \u003d parsedParams.getStartTxId();\n            long endTxId \u003d parsedParams.getEndTxId();\n            \n            File editFile \u003d nnImage.getStorage()\n                .findFinalizedEditsFile(startTxId, endTxId);\n            long start \u003d now();\n            serveFile(editFile);\n\n            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n              long elapsed \u003d now() - start;\n              metrics.addGetEdit(elapsed);\n            }\n          } else if (parsedParams.isPutImage()) {\n            final long txid \u003d parsedParams.getTxId();\n\n            if (! currentlyDownloadingCheckpoints.add(txid)) {\n              response.sendError(HttpServletResponse.SC_CONFLICT,\n                  \"Another checkpointer is already in the process of uploading a\" +\n                  \" checkpoint made at transaction ID \" + txid);\n              return null;\n            }\n\n            try {\n              if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer already uploaded an checkpoint \" +\n                    \"for txid \" + txid);\n                return null;\n              }\n              \n              // We may have lost our ticket since last checkpoint, log in again, just in case\n              if (UserGroupInformation.isSecurityEnabled()) {\n                UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n              }\n              \n              long start \u003d now();\n              // issue a HTTP get request to download the new fsimage \n              MD5Hash downloadImageDigest \u003d\n                TransferFsImage.downloadImageToStorage(\n                        parsedParams.getInfoServer(conf), txid,\n                        nnImage.getStorage(), true);\n              nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n\n              if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n                long elapsed \u003d now() - start;\n                metrics.addPutImage(elapsed);\n              }\n              \n              // Now that we have a new checkpoint, we might be able to\n              // remove some old ones.\n              nnImage.purgeOldStorage(NameNodeFile.IMAGE);\n            } finally {\n              currentlyDownloadingCheckpoints.remove(txid);\n            }\n          }\n          return null;\n        }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
      "extendedDetails": {}
    },
    "0fc2929d13435a71d759f29579a7a171dc05990d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5350. Name Node should report fsimage transfer time as a metric. Contributed by Jimmy Xiang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1551415 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/12/13 4:30 PM",
      "commitName": "0fc2929d13435a71d759f29579a7a171dc05990d",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "06/12/13 10:01 AM",
      "commitNameOld": "045dc880e13271737b3cf316296e92fb95806663",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 10.27,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,80 @@\n         public Void run() throws Exception {\n           if (parsedParams.isGetImage()) {\n             long txid \u003d parsedParams.getTxId();\n             File imageFile \u003d null;\n             String errorMessage \u003d \"Could not find image\";\n             if (parsedParams.shouldFetchLatest()) {\n               imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n             } else {\n               errorMessage +\u003d \" with txid \" + txid;\n               imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n             }\n             if (imageFile \u003d\u003d null) {\n               throw new IOException(errorMessage);\n             }\n             CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n+            long start \u003d now();\n             serveFile(imageFile);\n+\n+            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n+              long elapsed \u003d now() - start;\n+              metrics.addGetImage(elapsed);\n+            }\n           } else if (parsedParams.isGetEdit()) {\n             long startTxId \u003d parsedParams.getStartTxId();\n             long endTxId \u003d parsedParams.getEndTxId();\n             \n             File editFile \u003d nnImage.getStorage()\n                 .findFinalizedEditsFile(startTxId, endTxId);\n+            long start \u003d now();\n             serveFile(editFile);\n+\n+            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n+              long elapsed \u003d now() - start;\n+              metrics.addGetEdit(elapsed);\n+            }\n           } else if (parsedParams.isPutImage()) {\n             final long txid \u003d parsedParams.getTxId();\n \n             if (! currentlyDownloadingCheckpoints.add(txid)) {\n               response.sendError(HttpServletResponse.SC_CONFLICT,\n                   \"Another checkpointer is already in the process of uploading a\" +\n                   \" checkpoint made at transaction ID \" + txid);\n               return null;\n             }\n \n             try {\n               if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Another checkpointer already uploaded an checkpoint \" +\n                     \"for txid \" + txid);\n                 return null;\n               }\n               \n               // We may have lost our ticket since last checkpoint, log in again, just in case\n               if (UserGroupInformation.isSecurityEnabled()) {\n                 UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n               }\n               \n+              long start \u003d now();\n               // issue a HTTP get request to download the new fsimage \n               MD5Hash downloadImageDigest \u003d\n                 TransferFsImage.downloadImageToStorage(\n                         parsedParams.getInfoServer(conf), txid,\n                         nnImage.getStorage(), true);\n               nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n+\n+              if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n+                long elapsed \u003d now() - start;\n+                metrics.addPutImage(elapsed);\n+              }\n               \n               // Now that we have a new checkpoint, we might be able to\n               // remove some old ones.\n               nnImage.purgeOldStorage();\n             } finally {\n               currentlyDownloadingCheckpoints.remove(txid);\n             }\n           }\n           return null;\n         }\n\\ No newline at end of file\n",
      "actualSource": "        public Void run() throws Exception {\n          if (parsedParams.isGetImage()) {\n            long txid \u003d parsedParams.getTxId();\n            File imageFile \u003d null;\n            String errorMessage \u003d \"Could not find image\";\n            if (parsedParams.shouldFetchLatest()) {\n              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n            } else {\n              errorMessage +\u003d \" with txid \" + txid;\n              imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n            }\n            if (imageFile \u003d\u003d null) {\n              throw new IOException(errorMessage);\n            }\n            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n            long start \u003d now();\n            serveFile(imageFile);\n\n            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n              long elapsed \u003d now() - start;\n              metrics.addGetImage(elapsed);\n            }\n          } else if (parsedParams.isGetEdit()) {\n            long startTxId \u003d parsedParams.getStartTxId();\n            long endTxId \u003d parsedParams.getEndTxId();\n            \n            File editFile \u003d nnImage.getStorage()\n                .findFinalizedEditsFile(startTxId, endTxId);\n            long start \u003d now();\n            serveFile(editFile);\n\n            if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n              long elapsed \u003d now() - start;\n              metrics.addGetEdit(elapsed);\n            }\n          } else if (parsedParams.isPutImage()) {\n            final long txid \u003d parsedParams.getTxId();\n\n            if (! currentlyDownloadingCheckpoints.add(txid)) {\n              response.sendError(HttpServletResponse.SC_CONFLICT,\n                  \"Another checkpointer is already in the process of uploading a\" +\n                  \" checkpoint made at transaction ID \" + txid);\n              return null;\n            }\n\n            try {\n              if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer already uploaded an checkpoint \" +\n                    \"for txid \" + txid);\n                return null;\n              }\n              \n              // We may have lost our ticket since last checkpoint, log in again, just in case\n              if (UserGroupInformation.isSecurityEnabled()) {\n                UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n              }\n              \n              long start \u003d now();\n              // issue a HTTP get request to download the new fsimage \n              MD5Hash downloadImageDigest \u003d\n                TransferFsImage.downloadImageToStorage(\n                        parsedParams.getInfoServer(conf), txid,\n                        nnImage.getStorage(), true);\n              nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n\n              if (metrics !\u003d null) { // Metrics non-null only when used inside name node\n                long elapsed \u003d now() - start;\n                metrics.addPutImage(elapsed);\n              }\n              \n              // Now that we have a new checkpoint, we might be able to\n              // remove some old ones.\n              nnImage.purgeOldStorage();\n            } finally {\n              currentlyDownloadingCheckpoints.remove(txid);\n            }\n          }\n          return null;\n        }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
      "extendedDetails": {}
    },
    "045dc880e13271737b3cf316296e92fb95806663": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5312. Generate HTTP/HTTPS URL in DFSUtil#getInfoServer() based on the configured http policy. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548629 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/12/13 10:01 AM",
      "commitName": "045dc880e13271737b3cf316296e92fb95806663",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "14/08/13 5:45 PM",
      "commitNameOld": "b32ace11f1fe4540767ee69f74e321977a9ae37a",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 113.72,
      "commitsBetweenForRepo": 706,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,62 @@\n         public Void run() throws Exception {\n           if (parsedParams.isGetImage()) {\n             long txid \u003d parsedParams.getTxId();\n             File imageFile \u003d null;\n             String errorMessage \u003d \"Could not find image\";\n             if (parsedParams.shouldFetchLatest()) {\n               imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n             } else {\n               errorMessage +\u003d \" with txid \" + txid;\n               imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n             }\n             if (imageFile \u003d\u003d null) {\n               throw new IOException(errorMessage);\n             }\n             CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n             serveFile(imageFile);\n           } else if (parsedParams.isGetEdit()) {\n             long startTxId \u003d parsedParams.getStartTxId();\n             long endTxId \u003d parsedParams.getEndTxId();\n             \n             File editFile \u003d nnImage.getStorage()\n                 .findFinalizedEditsFile(startTxId, endTxId);\n             serveFile(editFile);\n           } else if (parsedParams.isPutImage()) {\n             final long txid \u003d parsedParams.getTxId();\n \n             if (! currentlyDownloadingCheckpoints.add(txid)) {\n               response.sendError(HttpServletResponse.SC_CONFLICT,\n                   \"Another checkpointer is already in the process of uploading a\" +\n                   \" checkpoint made at transaction ID \" + txid);\n               return null;\n             }\n \n             try {\n               if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Another checkpointer already uploaded an checkpoint \" +\n                     \"for txid \" + txid);\n                 return null;\n               }\n               \n               // We may have lost our ticket since last checkpoint, log in again, just in case\n               if (UserGroupInformation.isSecurityEnabled()) {\n                 UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n               }\n               \n               // issue a HTTP get request to download the new fsimage \n               MD5Hash downloadImageDigest \u003d\n                 TransferFsImage.downloadImageToStorage(\n-                        parsedParams.getInfoServer(), txid,\n+                        parsedParams.getInfoServer(conf), txid,\n                         nnImage.getStorage(), true);\n               nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n               \n               // Now that we have a new checkpoint, we might be able to\n               // remove some old ones.\n               nnImage.purgeOldStorage();\n             } finally {\n               currentlyDownloadingCheckpoints.remove(txid);\n             }\n           }\n           return null;\n         }\n\\ No newline at end of file\n",
      "actualSource": "        public Void run() throws Exception {\n          if (parsedParams.isGetImage()) {\n            long txid \u003d parsedParams.getTxId();\n            File imageFile \u003d null;\n            String errorMessage \u003d \"Could not find image\";\n            if (parsedParams.shouldFetchLatest()) {\n              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n            } else {\n              errorMessage +\u003d \" with txid \" + txid;\n              imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n            }\n            if (imageFile \u003d\u003d null) {\n              throw new IOException(errorMessage);\n            }\n            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n            serveFile(imageFile);\n          } else if (parsedParams.isGetEdit()) {\n            long startTxId \u003d parsedParams.getStartTxId();\n            long endTxId \u003d parsedParams.getEndTxId();\n            \n            File editFile \u003d nnImage.getStorage()\n                .findFinalizedEditsFile(startTxId, endTxId);\n            serveFile(editFile);\n          } else if (parsedParams.isPutImage()) {\n            final long txid \u003d parsedParams.getTxId();\n\n            if (! currentlyDownloadingCheckpoints.add(txid)) {\n              response.sendError(HttpServletResponse.SC_CONFLICT,\n                  \"Another checkpointer is already in the process of uploading a\" +\n                  \" checkpoint made at transaction ID \" + txid);\n              return null;\n            }\n\n            try {\n              if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer already uploaded an checkpoint \" +\n                    \"for txid \" + txid);\n                return null;\n              }\n              \n              // We may have lost our ticket since last checkpoint, log in again, just in case\n              if (UserGroupInformation.isSecurityEnabled()) {\n                UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n              }\n              \n              // issue a HTTP get request to download the new fsimage \n              MD5Hash downloadImageDigest \u003d\n                TransferFsImage.downloadImageToStorage(\n                        parsedParams.getInfoServer(conf), txid,\n                        nnImage.getStorage(), true);\n              nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n              \n              // Now that we have a new checkpoint, we might be able to\n              // remove some old ones.\n              nnImage.purgeOldStorage();\n            } finally {\n              currentlyDownloadingCheckpoints.remove(txid);\n            }\n          }\n          return null;\n        }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
      "extendedDetails": {}
    },
    "45b9d19f9d2b14e4d3c386af9de3df817da3c9df": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4780. Use the correct relogin method for services. Contributed by Robert Parker.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1486974 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/05/13 8:47 AM",
      "commitName": "45b9d19f9d2b14e4d3c386af9de3df817da3c9df",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "15/07/12 7:58 PM",
      "commitNameOld": "0e8e499ff482c165d21c8e4f5ff9c33f306ca0d9",
      "commitAuthorOld": "Harsh J",
      "daysBetweenCommits": 316.53,
      "commitsBetweenForRepo": 1776,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,62 @@\n         public Void run() throws Exception {\n           if (parsedParams.isGetImage()) {\n             long txid \u003d parsedParams.getTxId();\n             File imageFile \u003d null;\n             String errorMessage \u003d \"Could not find image\";\n             if (parsedParams.shouldFetchLatest()) {\n               imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n             } else {\n               errorMessage +\u003d \" with txid \" + txid;\n               imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n             }\n             if (imageFile \u003d\u003d null) {\n               throw new IOException(errorMessage);\n             }\n             CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n             serveFile(imageFile);\n           } else if (parsedParams.isGetEdit()) {\n             long startTxId \u003d parsedParams.getStartTxId();\n             long endTxId \u003d parsedParams.getEndTxId();\n             \n             File editFile \u003d nnImage.getStorage()\n                 .findFinalizedEditsFile(startTxId, endTxId);\n             serveFile(editFile);\n           } else if (parsedParams.isPutImage()) {\n             final long txid \u003d parsedParams.getTxId();\n \n             if (! currentlyDownloadingCheckpoints.add(txid)) {\n               response.sendError(HttpServletResponse.SC_CONFLICT,\n                   \"Another checkpointer is already in the process of uploading a\" +\n                   \" checkpoint made at transaction ID \" + txid);\n               return null;\n             }\n \n             try {\n               if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Another checkpointer already uploaded an checkpoint \" +\n                     \"for txid \" + txid);\n                 return null;\n               }\n               \n               // We may have lost our ticket since last checkpoint, log in again, just in case\n               if (UserGroupInformation.isSecurityEnabled()) {\n-                UserGroupInformation.getCurrentUser().reloginFromKeytab();\n+                UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n               }\n               \n               // issue a HTTP get request to download the new fsimage \n               MD5Hash downloadImageDigest \u003d\n                 TransferFsImage.downloadImageToStorage(\n                         parsedParams.getInfoServer(), txid,\n                         nnImage.getStorage(), true);\n               nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n               \n               // Now that we have a new checkpoint, we might be able to\n               // remove some old ones.\n               nnImage.purgeOldStorage();\n             } finally {\n               currentlyDownloadingCheckpoints.remove(txid);\n             }\n           }\n           return null;\n         }\n\\ No newline at end of file\n",
      "actualSource": "        public Void run() throws Exception {\n          if (parsedParams.isGetImage()) {\n            long txid \u003d parsedParams.getTxId();\n            File imageFile \u003d null;\n            String errorMessage \u003d \"Could not find image\";\n            if (parsedParams.shouldFetchLatest()) {\n              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n            } else {\n              errorMessage +\u003d \" with txid \" + txid;\n              imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n            }\n            if (imageFile \u003d\u003d null) {\n              throw new IOException(errorMessage);\n            }\n            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n            serveFile(imageFile);\n          } else if (parsedParams.isGetEdit()) {\n            long startTxId \u003d parsedParams.getStartTxId();\n            long endTxId \u003d parsedParams.getEndTxId();\n            \n            File editFile \u003d nnImage.getStorage()\n                .findFinalizedEditsFile(startTxId, endTxId);\n            serveFile(editFile);\n          } else if (parsedParams.isPutImage()) {\n            final long txid \u003d parsedParams.getTxId();\n\n            if (! currentlyDownloadingCheckpoints.add(txid)) {\n              response.sendError(HttpServletResponse.SC_CONFLICT,\n                  \"Another checkpointer is already in the process of uploading a\" +\n                  \" checkpoint made at transaction ID \" + txid);\n              return null;\n            }\n\n            try {\n              if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer already uploaded an checkpoint \" +\n                    \"for txid \" + txid);\n                return null;\n              }\n              \n              // We may have lost our ticket since last checkpoint, log in again, just in case\n              if (UserGroupInformation.isSecurityEnabled()) {\n                UserGroupInformation.getCurrentUser().checkTGTAndReloginFromKeytab();\n              }\n              \n              // issue a HTTP get request to download the new fsimage \n              MD5Hash downloadImageDigest \u003d\n                TransferFsImage.downloadImageToStorage(\n                        parsedParams.getInfoServer(), txid,\n                        nnImage.getStorage(), true);\n              nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n              \n              // Now that we have a new checkpoint, we might be able to\n              // remove some old ones.\n              nnImage.purgeOldStorage();\n            } finally {\n              currentlyDownloadingCheckpoints.remove(txid);\n            }\n          }\n          return null;\n        }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
      "extendedDetails": {}
    },
    "3728d16160118a4b6e632a59fb1e2e0795ca6595": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3574. Fix small race and do some cleanup in GetImageServlet. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1356939 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/07/12 1:55 PM",
      "commitName": "3728d16160118a4b6e632a59fb1e2e0795ca6595",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "02/07/12 4:59 PM",
      "commitNameOld": "8dd3148e734fa9d1db761ce65410fdc49c0fe1d5",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.87,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,71 +1,62 @@\n         public Void run() throws Exception {\n           if (parsedParams.isGetImage()) {\n             long txid \u003d parsedParams.getTxId();\n             File imageFile \u003d null;\n             String errorMessage \u003d \"Could not find image\";\n             if (parsedParams.shouldFetchLatest()) {\n               imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n             } else {\n               errorMessage +\u003d \" with txid \" + txid;\n               imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n             }\n             if (imageFile \u003d\u003d null) {\n               throw new IOException(errorMessage);\n             }\n             CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n-            setFileNameHeaders(response, imageFile);\n-            setVerificationHeaders(response, imageFile);\n-            // send fsImage\n-            TransferFsImage.getFileServer(response.getOutputStream(), imageFile,\n-                getThrottler(conf)); \n+            serveFile(imageFile);\n           } else if (parsedParams.isGetEdit()) {\n             long startTxId \u003d parsedParams.getStartTxId();\n             long endTxId \u003d parsedParams.getEndTxId();\n             \n             File editFile \u003d nnImage.getStorage()\n                 .findFinalizedEditsFile(startTxId, endTxId);\n-            setVerificationHeaders(response, editFile);\n-            \n-            setFileNameHeaders(response, editFile);\n-            // send edits\n-            TransferFsImage.getFileServer(response.getOutputStream(), editFile,\n-                getThrottler(conf));\n+            serveFile(editFile);\n           } else if (parsedParams.isPutImage()) {\n             final long txid \u003d parsedParams.getTxId();\n \n             if (! currentlyDownloadingCheckpoints.add(txid)) {\n               response.sendError(HttpServletResponse.SC_CONFLICT,\n                   \"Another checkpointer is already in the process of uploading a\" +\n                   \" checkpoint made at transaction ID \" + txid);\n               return null;\n             }\n \n             try {\n               if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Another checkpointer already uploaded an checkpoint \" +\n                     \"for txid \" + txid);\n                 return null;\n               }\n               \n               // We may have lost our ticket since last checkpoint, log in again, just in case\n               if (UserGroupInformation.isSecurityEnabled()) {\n                 UserGroupInformation.getCurrentUser().reloginFromKeytab();\n               }\n               \n               // issue a HTTP get request to download the new fsimage \n               MD5Hash downloadImageDigest \u003d\n                 TransferFsImage.downloadImageToStorage(\n                         parsedParams.getInfoServer(), txid,\n                         nnImage.getStorage(), true);\n               nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n               \n               // Now that we have a new checkpoint, we might be able to\n               // remove some old ones.\n               nnImage.purgeOldStorage();\n             } finally {\n               currentlyDownloadingCheckpoints.remove(txid);\n             }\n           }\n           return null;\n         }\n\\ No newline at end of file\n",
      "actualSource": "        public Void run() throws Exception {\n          if (parsedParams.isGetImage()) {\n            long txid \u003d parsedParams.getTxId();\n            File imageFile \u003d null;\n            String errorMessage \u003d \"Could not find image\";\n            if (parsedParams.shouldFetchLatest()) {\n              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n            } else {\n              errorMessage +\u003d \" with txid \" + txid;\n              imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n            }\n            if (imageFile \u003d\u003d null) {\n              throw new IOException(errorMessage);\n            }\n            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n            serveFile(imageFile);\n          } else if (parsedParams.isGetEdit()) {\n            long startTxId \u003d parsedParams.getStartTxId();\n            long endTxId \u003d parsedParams.getEndTxId();\n            \n            File editFile \u003d nnImage.getStorage()\n                .findFinalizedEditsFile(startTxId, endTxId);\n            serveFile(editFile);\n          } else if (parsedParams.isPutImage()) {\n            final long txid \u003d parsedParams.getTxId();\n\n            if (! currentlyDownloadingCheckpoints.add(txid)) {\n              response.sendError(HttpServletResponse.SC_CONFLICT,\n                  \"Another checkpointer is already in the process of uploading a\" +\n                  \" checkpoint made at transaction ID \" + txid);\n              return null;\n            }\n\n            try {\n              if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer already uploaded an checkpoint \" +\n                    \"for txid \" + txid);\n                return null;\n              }\n              \n              // We may have lost our ticket since last checkpoint, log in again, just in case\n              if (UserGroupInformation.isSecurityEnabled()) {\n                UserGroupInformation.getCurrentUser().reloginFromKeytab();\n              }\n              \n              // issue a HTTP get request to download the new fsimage \n              MD5Hash downloadImageDigest \u003d\n                TransferFsImage.downloadImageToStorage(\n                        parsedParams.getInfoServer(), txid,\n                        nnImage.getStorage(), true);\n              nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n              \n              // Now that we have a new checkpoint, we might be able to\n              // remove some old ones.\n              nnImage.purgeOldStorage();\n            } finally {\n              currentlyDownloadingCheckpoints.remove(txid);\n            }\n          }\n          return null;\n        }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
      "extendedDetails": {}
    },
    "8bab8b775240818b60935531dd2b27144ed8edc1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3501. Checkpointing with security enabled will stop working after ticket lifetime expires. Contributed by Aaron T. Myers\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1346106 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/06/12 12:37 PM",
      "commitName": "8bab8b775240818b60935531dd2b27144ed8edc1",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "17/05/12 3:23 AM",
      "commitNameOld": "1377709b4c58172c2a3f8abf78319b5a73fe1578",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 18.39,
      "commitsBetweenForRepo": 78,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,71 @@\n         public Void run() throws Exception {\n           if (parsedParams.isGetImage()) {\n             long txid \u003d parsedParams.getTxId();\n             File imageFile \u003d null;\n             String errorMessage \u003d \"Could not find image\";\n             if (parsedParams.shouldFetchLatest()) {\n               imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n             } else {\n               errorMessage +\u003d \" with txid \" + txid;\n               imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n             }\n             if (imageFile \u003d\u003d null) {\n               throw new IOException(errorMessage);\n             }\n             CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n             setFileNameHeaders(response, imageFile);\n             setVerificationHeaders(response, imageFile);\n             // send fsImage\n             TransferFsImage.getFileServer(response.getOutputStream(), imageFile,\n                 getThrottler(conf)); \n           } else if (parsedParams.isGetEdit()) {\n             long startTxId \u003d parsedParams.getStartTxId();\n             long endTxId \u003d parsedParams.getEndTxId();\n             \n             File editFile \u003d nnImage.getStorage()\n                 .findFinalizedEditsFile(startTxId, endTxId);\n             setVerificationHeaders(response, editFile);\n             \n             setFileNameHeaders(response, editFile);\n             // send edits\n             TransferFsImage.getFileServer(response.getOutputStream(), editFile,\n                 getThrottler(conf));\n           } else if (parsedParams.isPutImage()) {\n             final long txid \u003d parsedParams.getTxId();\n \n             if (! currentlyDownloadingCheckpoints.add(txid)) {\n               response.sendError(HttpServletResponse.SC_CONFLICT,\n                   \"Another checkpointer is already in the process of uploading a\" +\n                   \" checkpoint made at transaction ID \" + txid);\n               return null;\n             }\n \n             try {\n               if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Another checkpointer already uploaded an checkpoint \" +\n                     \"for txid \" + txid);\n                 return null;\n               }\n               \n+              // We may have lost our ticket since last checkpoint, log in again, just in case\n+              if (UserGroupInformation.isSecurityEnabled()) {\n+                UserGroupInformation.getCurrentUser().reloginFromKeytab();\n+              }\n+              \n               // issue a HTTP get request to download the new fsimage \n               MD5Hash downloadImageDigest \u003d\n                 TransferFsImage.downloadImageToStorage(\n                         parsedParams.getInfoServer(), txid,\n                         nnImage.getStorage(), true);\n               nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n               \n               // Now that we have a new checkpoint, we might be able to\n               // remove some old ones.\n               nnImage.purgeOldStorage();\n             } finally {\n               currentlyDownloadingCheckpoints.remove(txid);\n             }\n           }\n           return null;\n         }\n\\ No newline at end of file\n",
      "actualSource": "        public Void run() throws Exception {\n          if (parsedParams.isGetImage()) {\n            long txid \u003d parsedParams.getTxId();\n            File imageFile \u003d null;\n            String errorMessage \u003d \"Could not find image\";\n            if (parsedParams.shouldFetchLatest()) {\n              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n            } else {\n              errorMessage +\u003d \" with txid \" + txid;\n              imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n            }\n            if (imageFile \u003d\u003d null) {\n              throw new IOException(errorMessage);\n            }\n            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n            setFileNameHeaders(response, imageFile);\n            setVerificationHeaders(response, imageFile);\n            // send fsImage\n            TransferFsImage.getFileServer(response.getOutputStream(), imageFile,\n                getThrottler(conf)); \n          } else if (parsedParams.isGetEdit()) {\n            long startTxId \u003d parsedParams.getStartTxId();\n            long endTxId \u003d parsedParams.getEndTxId();\n            \n            File editFile \u003d nnImage.getStorage()\n                .findFinalizedEditsFile(startTxId, endTxId);\n            setVerificationHeaders(response, editFile);\n            \n            setFileNameHeaders(response, editFile);\n            // send edits\n            TransferFsImage.getFileServer(response.getOutputStream(), editFile,\n                getThrottler(conf));\n          } else if (parsedParams.isPutImage()) {\n            final long txid \u003d parsedParams.getTxId();\n\n            if (! currentlyDownloadingCheckpoints.add(txid)) {\n              response.sendError(HttpServletResponse.SC_CONFLICT,\n                  \"Another checkpointer is already in the process of uploading a\" +\n                  \" checkpoint made at transaction ID \" + txid);\n              return null;\n            }\n\n            try {\n              if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer already uploaded an checkpoint \" +\n                    \"for txid \" + txid);\n                return null;\n              }\n              \n              // We may have lost our ticket since last checkpoint, log in again, just in case\n              if (UserGroupInformation.isSecurityEnabled()) {\n                UserGroupInformation.getCurrentUser().reloginFromKeytab();\n              }\n              \n              // issue a HTTP get request to download the new fsimage \n              MD5Hash downloadImageDigest \u003d\n                TransferFsImage.downloadImageToStorage(\n                        parsedParams.getInfoServer(), txid,\n                        nnImage.getStorage(), true);\n              nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n              \n              // Now that we have a new checkpoint, we might be able to\n              // remove some old ones.\n              nnImage.purgeOldStorage();\n            } finally {\n              currentlyDownloadingCheckpoints.remove(txid);\n            }\n          }\n          return null;\n        }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
      "extendedDetails": {}
    },
    "5dbbe0e0a5d31689d3425e490865f95057dc051c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2617. Replaced Kerberized SSL for image transfer and fsck with SPNEGO-based solution. Contributed by Jakob Homan, Alejandro Abdelnur, and Aaron T. Myers\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1334216 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/05/12 2:58 PM",
      "commitName": "5dbbe0e0a5d31689d3425e490865f95057dc051c",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "02/05/12 6:44 PM",
      "commitNameOld": "cbc242429093ccabf76248f857de5e587a9682b0",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 1.84,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,71 +1,66 @@\n         public Void run() throws Exception {\n           if (parsedParams.isGetImage()) {\n             long txid \u003d parsedParams.getTxId();\n             File imageFile \u003d null;\n             String errorMessage \u003d \"Could not find image\";\n             if (parsedParams.shouldFetchLatest()) {\n               imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n             } else {\n               errorMessage +\u003d \" with txid \" + txid;\n               imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n             }\n             if (imageFile \u003d\u003d null) {\n               throw new IOException(errorMessage);\n             }\n             CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n             setFileNameHeaders(response, imageFile);\n             setVerificationHeaders(response, imageFile);\n             // send fsImage\n             TransferFsImage.getFileServer(response.getOutputStream(), imageFile,\n                 getThrottler(conf)); \n           } else if (parsedParams.isGetEdit()) {\n             long startTxId \u003d parsedParams.getStartTxId();\n             long endTxId \u003d parsedParams.getEndTxId();\n             \n             File editFile \u003d nnImage.getStorage()\n                 .findFinalizedEditsFile(startTxId, endTxId);\n             setVerificationHeaders(response, editFile);\n             \n             setFileNameHeaders(response, editFile);\n             // send edits\n             TransferFsImage.getFileServer(response.getOutputStream(), editFile,\n                 getThrottler(conf));\n           } else if (parsedParams.isPutImage()) {\n             final long txid \u003d parsedParams.getTxId();\n \n             if (! currentlyDownloadingCheckpoints.add(txid)) {\n               response.sendError(HttpServletResponse.SC_CONFLICT,\n                   \"Another checkpointer is already in the process of uploading a\" +\n                   \" checkpoint made at transaction ID \" + txid);\n               return null;\n             }\n \n             try {\n               if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Another checkpointer already uploaded an checkpoint \" +\n                     \"for txid \" + txid);\n                 return null;\n               }\n               \n               // issue a HTTP get request to download the new fsimage \n-              MD5Hash downloadImageDigest \u003d reloginIfNecessary().doAs(\n-                  new PrivilegedExceptionAction\u003cMD5Hash\u003e() {\n-                  @Override\n-                  public MD5Hash run() throws Exception {\n-                    return TransferFsImage.downloadImageToStorage(\n+              MD5Hash downloadImageDigest \u003d\n+                TransferFsImage.downloadImageToStorage(\n                         parsedParams.getInfoServer(), txid,\n                         nnImage.getStorage(), true);\n-                    }\n-              });\n               nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n               \n               // Now that we have a new checkpoint, we might be able to\n               // remove some old ones.\n               nnImage.purgeOldStorage();\n             } finally {\n               currentlyDownloadingCheckpoints.remove(txid);\n             }\n           }\n           return null;\n         }\n\\ No newline at end of file\n",
      "actualSource": "        public Void run() throws Exception {\n          if (parsedParams.isGetImage()) {\n            long txid \u003d parsedParams.getTxId();\n            File imageFile \u003d null;\n            String errorMessage \u003d \"Could not find image\";\n            if (parsedParams.shouldFetchLatest()) {\n              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n            } else {\n              errorMessage +\u003d \" with txid \" + txid;\n              imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n            }\n            if (imageFile \u003d\u003d null) {\n              throw new IOException(errorMessage);\n            }\n            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n            setFileNameHeaders(response, imageFile);\n            setVerificationHeaders(response, imageFile);\n            // send fsImage\n            TransferFsImage.getFileServer(response.getOutputStream(), imageFile,\n                getThrottler(conf)); \n          } else if (parsedParams.isGetEdit()) {\n            long startTxId \u003d parsedParams.getStartTxId();\n            long endTxId \u003d parsedParams.getEndTxId();\n            \n            File editFile \u003d nnImage.getStorage()\n                .findFinalizedEditsFile(startTxId, endTxId);\n            setVerificationHeaders(response, editFile);\n            \n            setFileNameHeaders(response, editFile);\n            // send edits\n            TransferFsImage.getFileServer(response.getOutputStream(), editFile,\n                getThrottler(conf));\n          } else if (parsedParams.isPutImage()) {\n            final long txid \u003d parsedParams.getTxId();\n\n            if (! currentlyDownloadingCheckpoints.add(txid)) {\n              response.sendError(HttpServletResponse.SC_CONFLICT,\n                  \"Another checkpointer is already in the process of uploading a\" +\n                  \" checkpoint made at transaction ID \" + txid);\n              return null;\n            }\n\n            try {\n              if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer already uploaded an checkpoint \" +\n                    \"for txid \" + txid);\n                return null;\n              }\n              \n              // issue a HTTP get request to download the new fsimage \n              MD5Hash downloadImageDigest \u003d\n                TransferFsImage.downloadImageToStorage(\n                        parsedParams.getInfoServer(), txid,\n                        nnImage.getStorage(), true);\n              nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n              \n              // Now that we have a new checkpoint, we might be able to\n              // remove some old ones.\n              nnImage.purgeOldStorage();\n            } finally {\n              currentlyDownloadingCheckpoints.remove(txid);\n            }\n          }\n          return null;\n        }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
      "extendedDetails": {}
    },
    "cbc242429093ccabf76248f857de5e587a9682b0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3330. If GetImageServlet throws an Error or RTE, response should not have HTTP \"OK\" status. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1333286 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/05/12 6:44 PM",
      "commitName": "cbc242429093ccabf76248f857de5e587a9682b0",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "19/04/12 1:43 PM",
      "commitNameOld": "49ed783a3a68726264c68cdc6c958ba9ad26c2c9",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 13.21,
      "commitsBetweenForRepo": 70,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,71 @@\n         public Void run() throws Exception {\n           if (parsedParams.isGetImage()) {\n             long txid \u003d parsedParams.getTxId();\n             File imageFile \u003d null;\n             String errorMessage \u003d \"Could not find image\";\n             if (parsedParams.shouldFetchLatest()) {\n               imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n             } else {\n               errorMessage +\u003d \" with txid \" + txid;\n               imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n             }\n             if (imageFile \u003d\u003d null) {\n               throw new IOException(errorMessage);\n             }\n+            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n             setFileNameHeaders(response, imageFile);\n             setVerificationHeaders(response, imageFile);\n             // send fsImage\n             TransferFsImage.getFileServer(response.getOutputStream(), imageFile,\n                 getThrottler(conf)); \n           } else if (parsedParams.isGetEdit()) {\n             long startTxId \u003d parsedParams.getStartTxId();\n             long endTxId \u003d parsedParams.getEndTxId();\n             \n             File editFile \u003d nnImage.getStorage()\n                 .findFinalizedEditsFile(startTxId, endTxId);\n             setVerificationHeaders(response, editFile);\n             \n             setFileNameHeaders(response, editFile);\n             // send edits\n             TransferFsImage.getFileServer(response.getOutputStream(), editFile,\n                 getThrottler(conf));\n           } else if (parsedParams.isPutImage()) {\n             final long txid \u003d parsedParams.getTxId();\n \n             if (! currentlyDownloadingCheckpoints.add(txid)) {\n               response.sendError(HttpServletResponse.SC_CONFLICT,\n                   \"Another checkpointer is already in the process of uploading a\" +\n                   \" checkpoint made at transaction ID \" + txid);\n               return null;\n             }\n \n             try {\n               if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Another checkpointer already uploaded an checkpoint \" +\n                     \"for txid \" + txid);\n                 return null;\n               }\n               \n               // issue a HTTP get request to download the new fsimage \n               MD5Hash downloadImageDigest \u003d reloginIfNecessary().doAs(\n                   new PrivilegedExceptionAction\u003cMD5Hash\u003e() {\n                   @Override\n                   public MD5Hash run() throws Exception {\n                     return TransferFsImage.downloadImageToStorage(\n                         parsedParams.getInfoServer(), txid,\n                         nnImage.getStorage(), true);\n                     }\n               });\n               nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n               \n               // Now that we have a new checkpoint, we might be able to\n               // remove some old ones.\n               nnImage.purgeOldStorage();\n             } finally {\n               currentlyDownloadingCheckpoints.remove(txid);\n             }\n           }\n           return null;\n         }\n\\ No newline at end of file\n",
      "actualSource": "        public Void run() throws Exception {\n          if (parsedParams.isGetImage()) {\n            long txid \u003d parsedParams.getTxId();\n            File imageFile \u003d null;\n            String errorMessage \u003d \"Could not find image\";\n            if (parsedParams.shouldFetchLatest()) {\n              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n            } else {\n              errorMessage +\u003d \" with txid \" + txid;\n              imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n            }\n            if (imageFile \u003d\u003d null) {\n              throw new IOException(errorMessage);\n            }\n            CheckpointFaultInjector.getInstance().beforeGetImageSetsHeaders();\n            setFileNameHeaders(response, imageFile);\n            setVerificationHeaders(response, imageFile);\n            // send fsImage\n            TransferFsImage.getFileServer(response.getOutputStream(), imageFile,\n                getThrottler(conf)); \n          } else if (parsedParams.isGetEdit()) {\n            long startTxId \u003d parsedParams.getStartTxId();\n            long endTxId \u003d parsedParams.getEndTxId();\n            \n            File editFile \u003d nnImage.getStorage()\n                .findFinalizedEditsFile(startTxId, endTxId);\n            setVerificationHeaders(response, editFile);\n            \n            setFileNameHeaders(response, editFile);\n            // send edits\n            TransferFsImage.getFileServer(response.getOutputStream(), editFile,\n                getThrottler(conf));\n          } else if (parsedParams.isPutImage()) {\n            final long txid \u003d parsedParams.getTxId();\n\n            if (! currentlyDownloadingCheckpoints.add(txid)) {\n              response.sendError(HttpServletResponse.SC_CONFLICT,\n                  \"Another checkpointer is already in the process of uploading a\" +\n                  \" checkpoint made at transaction ID \" + txid);\n              return null;\n            }\n\n            try {\n              if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer already uploaded an checkpoint \" +\n                    \"for txid \" + txid);\n                return null;\n              }\n              \n              // issue a HTTP get request to download the new fsimage \n              MD5Hash downloadImageDigest \u003d reloginIfNecessary().doAs(\n                  new PrivilegedExceptionAction\u003cMD5Hash\u003e() {\n                  @Override\n                  public MD5Hash run() throws Exception {\n                    return TransferFsImage.downloadImageToStorage(\n                        parsedParams.getInfoServer(), txid,\n                        nnImage.getStorage(), true);\n                    }\n              });\n              nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n              \n              // Now that we have a new checkpoint, we might be able to\n              // remove some old ones.\n              nnImage.purgeOldStorage();\n            } finally {\n              currentlyDownloadingCheckpoints.remove(txid);\n            }\n          }\n          return null;\n        }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
      "extendedDetails": {}
    },
    "ce1a7ec9755f17527c29b0db713d7e01750e10c9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2941. Add an administrative command to download a copy of the fsimage from the NN. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1305447 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/03/12 10:02 AM",
      "commitName": "ce1a7ec9755f17527c29b0db713d7e01750e10c9",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "04/01/12 4:22 PM",
      "commitNameOld": "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 81.69,
      "commitsBetweenForRepo": 606,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,61 +1,70 @@\n         public Void run() throws Exception {\n           if (parsedParams.isGetImage()) {\n             long txid \u003d parsedParams.getTxId();\n-            File imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n-            if (imageFile \u003d\u003d null) {\n-              throw new IOException(\"Could not find image with txid \" + txid);\n+            File imageFile \u003d null;\n+            String errorMessage \u003d \"Could not find image\";\n+            if (parsedParams.shouldFetchLatest()) {\n+              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n+            } else {\n+              errorMessage +\u003d \" with txid \" + txid;\n+              imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n             }\n+            if (imageFile \u003d\u003d null) {\n+              throw new IOException(errorMessage);\n+            }\n+            setFileNameHeaders(response, imageFile);\n             setVerificationHeaders(response, imageFile);\n             // send fsImage\n             TransferFsImage.getFileServer(response.getOutputStream(), imageFile,\n                 getThrottler(conf)); \n           } else if (parsedParams.isGetEdit()) {\n             long startTxId \u003d parsedParams.getStartTxId();\n             long endTxId \u003d parsedParams.getEndTxId();\n             \n             File editFile \u003d nnImage.getStorage()\n                 .findFinalizedEditsFile(startTxId, endTxId);\n             setVerificationHeaders(response, editFile);\n             \n+            setFileNameHeaders(response, editFile);\n             // send edits\n             TransferFsImage.getFileServer(response.getOutputStream(), editFile,\n                 getThrottler(conf));\n           } else if (parsedParams.isPutImage()) {\n             final long txid \u003d parsedParams.getTxId();\n \n             if (! currentlyDownloadingCheckpoints.add(txid)) {\n               response.sendError(HttpServletResponse.SC_CONFLICT,\n                   \"Another checkpointer is already in the process of uploading a\" +\n                   \" checkpoint made at transaction ID \" + txid);\n               return null;\n             }\n \n             try {\n               if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                 response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Another checkpointer already uploaded an checkpoint \" +\n                     \"for txid \" + txid);\n                 return null;\n               }\n               \n               // issue a HTTP get request to download the new fsimage \n               MD5Hash downloadImageDigest \u003d reloginIfNecessary().doAs(\n                   new PrivilegedExceptionAction\u003cMD5Hash\u003e() {\n                   @Override\n                   public MD5Hash run() throws Exception {\n                     return TransferFsImage.downloadImageToStorage(\n                         parsedParams.getInfoServer(), txid,\n                         nnImage.getStorage(), true);\n                     }\n               });\n               nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n               \n               // Now that we have a new checkpoint, we might be able to\n               // remove some old ones.\n               nnImage.purgeOldStorage();\n             } finally {\n               currentlyDownloadingCheckpoints.remove(txid);\n             }\n           }\n           return null;\n         }\n\\ No newline at end of file\n",
      "actualSource": "        public Void run() throws Exception {\n          if (parsedParams.isGetImage()) {\n            long txid \u003d parsedParams.getTxId();\n            File imageFile \u003d null;\n            String errorMessage \u003d \"Could not find image\";\n            if (parsedParams.shouldFetchLatest()) {\n              imageFile \u003d nnImage.getStorage().getHighestFsImageName();\n            } else {\n              errorMessage +\u003d \" with txid \" + txid;\n              imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n            }\n            if (imageFile \u003d\u003d null) {\n              throw new IOException(errorMessage);\n            }\n            setFileNameHeaders(response, imageFile);\n            setVerificationHeaders(response, imageFile);\n            // send fsImage\n            TransferFsImage.getFileServer(response.getOutputStream(), imageFile,\n                getThrottler(conf)); \n          } else if (parsedParams.isGetEdit()) {\n            long startTxId \u003d parsedParams.getStartTxId();\n            long endTxId \u003d parsedParams.getEndTxId();\n            \n            File editFile \u003d nnImage.getStorage()\n                .findFinalizedEditsFile(startTxId, endTxId);\n            setVerificationHeaders(response, editFile);\n            \n            setFileNameHeaders(response, editFile);\n            // send edits\n            TransferFsImage.getFileServer(response.getOutputStream(), editFile,\n                getThrottler(conf));\n          } else if (parsedParams.isPutImage()) {\n            final long txid \u003d parsedParams.getTxId();\n\n            if (! currentlyDownloadingCheckpoints.add(txid)) {\n              response.sendError(HttpServletResponse.SC_CONFLICT,\n                  \"Another checkpointer is already in the process of uploading a\" +\n                  \" checkpoint made at transaction ID \" + txid);\n              return null;\n            }\n\n            try {\n              if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer already uploaded an checkpoint \" +\n                    \"for txid \" + txid);\n                return null;\n              }\n              \n              // issue a HTTP get request to download the new fsimage \n              MD5Hash downloadImageDigest \u003d reloginIfNecessary().doAs(\n                  new PrivilegedExceptionAction\u003cMD5Hash\u003e() {\n                  @Override\n                  public MD5Hash run() throws Exception {\n                    return TransferFsImage.downloadImageToStorage(\n                        parsedParams.getInfoServer(), txid,\n                        nnImage.getStorage(), true);\n                    }\n              });\n              nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n              \n              // Now that we have a new checkpoint, we might be able to\n              // remove some old ones.\n              nnImage.purgeOldStorage();\n            } finally {\n              currentlyDownloadingCheckpoints.remove(txid);\n            }\n          }\n          return null;\n        }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
      "extendedDetails": {}
    },
    "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2291. Allow the StandbyNode to make checkpoints in an HA setup. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1227411 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/01/12 4:22 PM",
      "commitName": "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 133.01,
      "commitsBetweenForRepo": 897,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,59 +1,61 @@\n         public Void run() throws Exception {\n           if (parsedParams.isGetImage()) {\n             long txid \u003d parsedParams.getTxId();\n             File imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n             if (imageFile \u003d\u003d null) {\n               throw new IOException(\"Could not find image with txid \" + txid);\n             }\n             setVerificationHeaders(response, imageFile);\n             // send fsImage\n             TransferFsImage.getFileServer(response.getOutputStream(), imageFile,\n                 getThrottler(conf)); \n           } else if (parsedParams.isGetEdit()) {\n             long startTxId \u003d parsedParams.getStartTxId();\n             long endTxId \u003d parsedParams.getEndTxId();\n             \n             File editFile \u003d nnImage.getStorage()\n                 .findFinalizedEditsFile(startTxId, endTxId);\n             setVerificationHeaders(response, editFile);\n             \n             // send edits\n             TransferFsImage.getFileServer(response.getOutputStream(), editFile,\n                 getThrottler(conf));\n           } else if (parsedParams.isPutImage()) {\n             final long txid \u003d parsedParams.getTxId();\n \n             if (! currentlyDownloadingCheckpoints.add(txid)) {\n-              throw new IOException(\n+              response.sendError(HttpServletResponse.SC_CONFLICT,\n                   \"Another checkpointer is already in the process of uploading a\" +\n                   \" checkpoint made at transaction ID \" + txid);\n+              return null;\n             }\n \n             try {\n               if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n-                throw new IOException(\n+                response.sendError(HttpServletResponse.SC_CONFLICT,\n                     \"Another checkpointer already uploaded an checkpoint \" +\n                     \"for txid \" + txid);\n+                return null;\n               }\n               \n               // issue a HTTP get request to download the new fsimage \n               MD5Hash downloadImageDigest \u003d reloginIfNecessary().doAs(\n                   new PrivilegedExceptionAction\u003cMD5Hash\u003e() {\n                   @Override\n                   public MD5Hash run() throws Exception {\n                     return TransferFsImage.downloadImageToStorage(\n                         parsedParams.getInfoServer(), txid,\n                         nnImage.getStorage(), true);\n                     }\n               });\n               nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n               \n               // Now that we have a new checkpoint, we might be able to\n               // remove some old ones.\n               nnImage.purgeOldStorage();\n             } finally {\n               currentlyDownloadingCheckpoints.remove(txid);\n             }\n           }\n           return null;\n         }\n\\ No newline at end of file\n",
      "actualSource": "        public Void run() throws Exception {\n          if (parsedParams.isGetImage()) {\n            long txid \u003d parsedParams.getTxId();\n            File imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n            if (imageFile \u003d\u003d null) {\n              throw new IOException(\"Could not find image with txid \" + txid);\n            }\n            setVerificationHeaders(response, imageFile);\n            // send fsImage\n            TransferFsImage.getFileServer(response.getOutputStream(), imageFile,\n                getThrottler(conf)); \n          } else if (parsedParams.isGetEdit()) {\n            long startTxId \u003d parsedParams.getStartTxId();\n            long endTxId \u003d parsedParams.getEndTxId();\n            \n            File editFile \u003d nnImage.getStorage()\n                .findFinalizedEditsFile(startTxId, endTxId);\n            setVerificationHeaders(response, editFile);\n            \n            // send edits\n            TransferFsImage.getFileServer(response.getOutputStream(), editFile,\n                getThrottler(conf));\n          } else if (parsedParams.isPutImage()) {\n            final long txid \u003d parsedParams.getTxId();\n\n            if (! currentlyDownloadingCheckpoints.add(txid)) {\n              response.sendError(HttpServletResponse.SC_CONFLICT,\n                  \"Another checkpointer is already in the process of uploading a\" +\n                  \" checkpoint made at transaction ID \" + txid);\n              return null;\n            }\n\n            try {\n              if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                response.sendError(HttpServletResponse.SC_CONFLICT,\n                    \"Another checkpointer already uploaded an checkpoint \" +\n                    \"for txid \" + txid);\n                return null;\n              }\n              \n              // issue a HTTP get request to download the new fsimage \n              MD5Hash downloadImageDigest \u003d reloginIfNecessary().doAs(\n                  new PrivilegedExceptionAction\u003cMD5Hash\u003e() {\n                  @Override\n                  public MD5Hash run() throws Exception {\n                    return TransferFsImage.downloadImageToStorage(\n                        parsedParams.getInfoServer(), txid,\n                        nnImage.getStorage(), true);\n                    }\n              });\n              nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n              \n              // Now that we have a new checkpoint, we might be able to\n              // remove some old ones.\n              nnImage.purgeOldStorage();\n            } finally {\n              currentlyDownloadingCheckpoints.remove(txid);\n            }\n          }\n          return null;\n        }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "        public Void run() throws Exception {\n          if (parsedParams.isGetImage()) {\n            long txid \u003d parsedParams.getTxId();\n            File imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n            if (imageFile \u003d\u003d null) {\n              throw new IOException(\"Could not find image with txid \" + txid);\n            }\n            setVerificationHeaders(response, imageFile);\n            // send fsImage\n            TransferFsImage.getFileServer(response.getOutputStream(), imageFile,\n                getThrottler(conf)); \n          } else if (parsedParams.isGetEdit()) {\n            long startTxId \u003d parsedParams.getStartTxId();\n            long endTxId \u003d parsedParams.getEndTxId();\n            \n            File editFile \u003d nnImage.getStorage()\n                .findFinalizedEditsFile(startTxId, endTxId);\n            setVerificationHeaders(response, editFile);\n            \n            // send edits\n            TransferFsImage.getFileServer(response.getOutputStream(), editFile,\n                getThrottler(conf));\n          } else if (parsedParams.isPutImage()) {\n            final long txid \u003d parsedParams.getTxId();\n\n            if (! currentlyDownloadingCheckpoints.add(txid)) {\n              throw new IOException(\n                  \"Another checkpointer is already in the process of uploading a\" +\n                  \" checkpoint made at transaction ID \" + txid);\n            }\n\n            try {\n              if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                throw new IOException(\n                    \"Another checkpointer already uploaded an checkpoint \" +\n                    \"for txid \" + txid);\n              }\n              \n              // issue a HTTP get request to download the new fsimage \n              MD5Hash downloadImageDigest \u003d reloginIfNecessary().doAs(\n                  new PrivilegedExceptionAction\u003cMD5Hash\u003e() {\n                  @Override\n                  public MD5Hash run() throws Exception {\n                    return TransferFsImage.downloadImageToStorage(\n                        parsedParams.getInfoServer(), txid,\n                        nnImage.getStorage(), true);\n                    }\n              });\n              nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n              \n              // Now that we have a new checkpoint, we might be able to\n              // remove some old ones.\n              nnImage.purgeOldStorage();\n            } finally {\n              currentlyDownloadingCheckpoints.remove(txid);\n            }\n          }\n          return null;\n        }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "        public Void run() throws Exception {\n          if (parsedParams.isGetImage()) {\n            long txid \u003d parsedParams.getTxId();\n            File imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n            if (imageFile \u003d\u003d null) {\n              throw new IOException(\"Could not find image with txid \" + txid);\n            }\n            setVerificationHeaders(response, imageFile);\n            // send fsImage\n            TransferFsImage.getFileServer(response.getOutputStream(), imageFile,\n                getThrottler(conf)); \n          } else if (parsedParams.isGetEdit()) {\n            long startTxId \u003d parsedParams.getStartTxId();\n            long endTxId \u003d parsedParams.getEndTxId();\n            \n            File editFile \u003d nnImage.getStorage()\n                .findFinalizedEditsFile(startTxId, endTxId);\n            setVerificationHeaders(response, editFile);\n            \n            // send edits\n            TransferFsImage.getFileServer(response.getOutputStream(), editFile,\n                getThrottler(conf));\n          } else if (parsedParams.isPutImage()) {\n            final long txid \u003d parsedParams.getTxId();\n\n            if (! currentlyDownloadingCheckpoints.add(txid)) {\n              throw new IOException(\n                  \"Another checkpointer is already in the process of uploading a\" +\n                  \" checkpoint made at transaction ID \" + txid);\n            }\n\n            try {\n              if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                throw new IOException(\n                    \"Another checkpointer already uploaded an checkpoint \" +\n                    \"for txid \" + txid);\n              }\n              \n              // issue a HTTP get request to download the new fsimage \n              MD5Hash downloadImageDigest \u003d reloginIfNecessary().doAs(\n                  new PrivilegedExceptionAction\u003cMD5Hash\u003e() {\n                  @Override\n                  public MD5Hash run() throws Exception {\n                    return TransferFsImage.downloadImageToStorage(\n                        parsedParams.getInfoServer(), txid,\n                        nnImage.getStorage(), true);\n                    }\n              });\n              nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n              \n              // Now that we have a new checkpoint, we might be able to\n              // remove some old ones.\n              nnImage.purgeOldStorage();\n            } finally {\n              currentlyDownloadingCheckpoints.remove(txid);\n            }\n          }\n          return null;\n        }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java"
      }
    },
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/11 9:28 AM",
      "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "25/07/11 5:04 PM",
      "commitNameOld": "01cd616d170d5d26a539e51e731e8e73b789b360",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 3.68,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,59 @@\n         public Void run() throws Exception {\n-          if (ff.getImage()) {\n-            response.setHeader(TransferFsImage.CONTENT_LENGTH,\n-                               String.valueOf(nnImage.getStorage()\n-                                              .getFsImageName().length()));\n-            // send fsImage\n-            TransferFsImage.getFileServer(response.getOutputStream(),\n-                                          nnImage.getStorage().getFsImageName(),\n-                getThrottler(conf)); \n-          } else if (ff.getEdit()) {\n-            response.setHeader(TransferFsImage.CONTENT_LENGTH,\n-                               String.valueOf(nnImage.getStorage()\n-                                              .getFsEditName().length()));\n-            // send edits\n-            TransferFsImage.getFileServer(response.getOutputStream(),\n-                                          nnImage.getStorage().getFsEditName(),\n-                getThrottler(conf));\n-          } else if (ff.putImage()) {\n-            // issue a HTTP get request to download the new fsimage \n-            nnImage.validateCheckpointUpload(ff.getToken());\n-            nnImage.newImageDigest \u003d ff.getNewChecksum();\n-            MD5Hash downloadImageDigest \u003d reloginIfNecessary().doAs(\n-                new PrivilegedExceptionAction\u003cMD5Hash\u003e() {\n-                @Override\n-                public MD5Hash run() throws Exception {\n-                  return TransferFsImage.getFileClient(\n-                      ff.getInfoServer(), \"getimage\u003d1\", \n-                      nnImage.getStorage().getFsImageNameCheckpoint(), true);\n-                }\n-            });\n-            if (!nnImage.newImageDigest.equals(downloadImageDigest)) {\n-              throw new IOException(\"The downloaded image is corrupt,\" +\n-                  \" expecting a checksum \" + nnImage.newImageDigest +\n-                  \" but received a checksum \" + downloadImageDigest);\n+          if (parsedParams.isGetImage()) {\n+            long txid \u003d parsedParams.getTxId();\n+            File imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n+            if (imageFile \u003d\u003d null) {\n+              throw new IOException(\"Could not find image with txid \" + txid);\n             }\n-           nnImage.checkpointUploadDone();\n+            setVerificationHeaders(response, imageFile);\n+            // send fsImage\n+            TransferFsImage.getFileServer(response.getOutputStream(), imageFile,\n+                getThrottler(conf)); \n+          } else if (parsedParams.isGetEdit()) {\n+            long startTxId \u003d parsedParams.getStartTxId();\n+            long endTxId \u003d parsedParams.getEndTxId();\n+            \n+            File editFile \u003d nnImage.getStorage()\n+                .findFinalizedEditsFile(startTxId, endTxId);\n+            setVerificationHeaders(response, editFile);\n+            \n+            // send edits\n+            TransferFsImage.getFileServer(response.getOutputStream(), editFile,\n+                getThrottler(conf));\n+          } else if (parsedParams.isPutImage()) {\n+            final long txid \u003d parsedParams.getTxId();\n+\n+            if (! currentlyDownloadingCheckpoints.add(txid)) {\n+              throw new IOException(\n+                  \"Another checkpointer is already in the process of uploading a\" +\n+                  \" checkpoint made at transaction ID \" + txid);\n+            }\n+\n+            try {\n+              if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n+                throw new IOException(\n+                    \"Another checkpointer already uploaded an checkpoint \" +\n+                    \"for txid \" + txid);\n+              }\n+              \n+              // issue a HTTP get request to download the new fsimage \n+              MD5Hash downloadImageDigest \u003d reloginIfNecessary().doAs(\n+                  new PrivilegedExceptionAction\u003cMD5Hash\u003e() {\n+                  @Override\n+                  public MD5Hash run() throws Exception {\n+                    return TransferFsImage.downloadImageToStorage(\n+                        parsedParams.getInfoServer(), txid,\n+                        nnImage.getStorage(), true);\n+                    }\n+              });\n+              nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n+              \n+              // Now that we have a new checkpoint, we might be able to\n+              // remove some old ones.\n+              nnImage.purgeOldStorage();\n+            } finally {\n+              currentlyDownloadingCheckpoints.remove(txid);\n+            }\n           }\n           return null;\n         }\n\\ No newline at end of file\n",
      "actualSource": "        public Void run() throws Exception {\n          if (parsedParams.isGetImage()) {\n            long txid \u003d parsedParams.getTxId();\n            File imageFile \u003d nnImage.getStorage().getFsImageName(txid);\n            if (imageFile \u003d\u003d null) {\n              throw new IOException(\"Could not find image with txid \" + txid);\n            }\n            setVerificationHeaders(response, imageFile);\n            // send fsImage\n            TransferFsImage.getFileServer(response.getOutputStream(), imageFile,\n                getThrottler(conf)); \n          } else if (parsedParams.isGetEdit()) {\n            long startTxId \u003d parsedParams.getStartTxId();\n            long endTxId \u003d parsedParams.getEndTxId();\n            \n            File editFile \u003d nnImage.getStorage()\n                .findFinalizedEditsFile(startTxId, endTxId);\n            setVerificationHeaders(response, editFile);\n            \n            // send edits\n            TransferFsImage.getFileServer(response.getOutputStream(), editFile,\n                getThrottler(conf));\n          } else if (parsedParams.isPutImage()) {\n            final long txid \u003d parsedParams.getTxId();\n\n            if (! currentlyDownloadingCheckpoints.add(txid)) {\n              throw new IOException(\n                  \"Another checkpointer is already in the process of uploading a\" +\n                  \" checkpoint made at transaction ID \" + txid);\n            }\n\n            try {\n              if (nnImage.getStorage().findImageFile(txid) !\u003d null) {\n                throw new IOException(\n                    \"Another checkpointer already uploaded an checkpoint \" +\n                    \"for txid \" + txid);\n              }\n              \n              // issue a HTTP get request to download the new fsimage \n              MD5Hash downloadImageDigest \u003d reloginIfNecessary().doAs(\n                  new PrivilegedExceptionAction\u003cMD5Hash\u003e() {\n                  @Override\n                  public MD5Hash run() throws Exception {\n                    return TransferFsImage.downloadImageToStorage(\n                        parsedParams.getInfoServer(), txid,\n                        nnImage.getStorage(), true);\n                    }\n              });\n              nnImage.saveDigestAndRenameCheckpointImage(txid, downloadImageDigest);\n              \n              // Now that we have a new checkpoint, we might be able to\n              // remove some old ones.\n              nnImage.purgeOldStorage();\n            } finally {\n              currentlyDownloadingCheckpoints.remove(txid);\n            }\n          }\n          return null;\n        }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,39 @@\n+        public Void run() throws Exception {\n+          if (ff.getImage()) {\n+            response.setHeader(TransferFsImage.CONTENT_LENGTH,\n+                               String.valueOf(nnImage.getStorage()\n+                                              .getFsImageName().length()));\n+            // send fsImage\n+            TransferFsImage.getFileServer(response.getOutputStream(),\n+                                          nnImage.getStorage().getFsImageName(),\n+                getThrottler(conf)); \n+          } else if (ff.getEdit()) {\n+            response.setHeader(TransferFsImage.CONTENT_LENGTH,\n+                               String.valueOf(nnImage.getStorage()\n+                                              .getFsEditName().length()));\n+            // send edits\n+            TransferFsImage.getFileServer(response.getOutputStream(),\n+                                          nnImage.getStorage().getFsEditName(),\n+                getThrottler(conf));\n+          } else if (ff.putImage()) {\n+            // issue a HTTP get request to download the new fsimage \n+            nnImage.validateCheckpointUpload(ff.getToken());\n+            nnImage.newImageDigest \u003d ff.getNewChecksum();\n+            MD5Hash downloadImageDigest \u003d reloginIfNecessary().doAs(\n+                new PrivilegedExceptionAction\u003cMD5Hash\u003e() {\n+                @Override\n+                public MD5Hash run() throws Exception {\n+                  return TransferFsImage.getFileClient(\n+                      ff.getInfoServer(), \"getimage\u003d1\", \n+                      nnImage.getStorage().getFsImageNameCheckpoint(), true);\n+                }\n+            });\n+            if (!nnImage.newImageDigest.equals(downloadImageDigest)) {\n+              throw new IOException(\"The downloaded image is corrupt,\" +\n+                  \" expecting a checksum \" + nnImage.newImageDigest +\n+                  \" but received a checksum \" + downloadImageDigest);\n+            }\n+           nnImage.checkpointUploadDone();\n+          }\n+          return null;\n+        }\n\\ No newline at end of file\n",
      "actualSource": "        public Void run() throws Exception {\n          if (ff.getImage()) {\n            response.setHeader(TransferFsImage.CONTENT_LENGTH,\n                               String.valueOf(nnImage.getStorage()\n                                              .getFsImageName().length()));\n            // send fsImage\n            TransferFsImage.getFileServer(response.getOutputStream(),\n                                          nnImage.getStorage().getFsImageName(),\n                getThrottler(conf)); \n          } else if (ff.getEdit()) {\n            response.setHeader(TransferFsImage.CONTENT_LENGTH,\n                               String.valueOf(nnImage.getStorage()\n                                              .getFsEditName().length()));\n            // send edits\n            TransferFsImage.getFileServer(response.getOutputStream(),\n                                          nnImage.getStorage().getFsEditName(),\n                getThrottler(conf));\n          } else if (ff.putImage()) {\n            // issue a HTTP get request to download the new fsimage \n            nnImage.validateCheckpointUpload(ff.getToken());\n            nnImage.newImageDigest \u003d ff.getNewChecksum();\n            MD5Hash downloadImageDigest \u003d reloginIfNecessary().doAs(\n                new PrivilegedExceptionAction\u003cMD5Hash\u003e() {\n                @Override\n                public MD5Hash run() throws Exception {\n                  return TransferFsImage.getFileClient(\n                      ff.getInfoServer(), \"getimage\u003d1\", \n                      nnImage.getStorage().getFsImageNameCheckpoint(), true);\n                }\n            });\n            if (!nnImage.newImageDigest.equals(downloadImageDigest)) {\n              throw new IOException(\"The downloaded image is corrupt,\" +\n                  \" expecting a checksum \" + nnImage.newImageDigest +\n                  \" but received a checksum \" + downloadImageDigest);\n            }\n           nnImage.checkpointUploadDone();\n          }\n          return null;\n        }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java"
    }
  }
}