{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "TaskAttemptImpl.java",
  "functionName": "transition",
  "functionId": "transition___taskAttempt-TaskAttemptImpl(modifiers-final)__event-TaskAttemptEvent",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
  "functionStartLine": 1872,
  "functionEndLine": 1902,
  "numCommitsSeen": 109,
  "timeTaken": 9333,
  "changeHistory": [
    "0af1a2b5bc1469ba22edb63cd58f9b436b1dc4d3",
    "cb78a65a152a4f576a3255df3676c3b788c84eb5",
    "e4c55e17fea55e2fcbef182bb2b0c4b22686f38c",
    "6a1c41111edcdc58c846fc50e53554fbba230171",
    "c163dc2fce10c1f4f4def6f079069b1bae901fcd",
    "aac5c149c7ca500b8eb810b7d4b561ff1e38ea02",
    "f67c2d1bd0c8abc3d4ea76deffe45fdd92ef5e05",
    "03d46dc571bc5b0f1b3c0cb5daa52e7ee324dd54",
    "0870734787d7005d85697549eab5b6479d97d453",
    "9db078212f5a37154925cc8872f9adaeca0ed371",
    "47a381e306877750b5a3ce5d76e0a5ff652ec188",
    "1c8d64f38a86b92f3c5a56105cd0cd51d8b8529b",
    "df2991c0cbc3f35c2640b93680667507c4f810dd",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "0af1a2b5bc1469ba22edb63cd58f9b436b1dc4d3": "Ybodychange",
    "cb78a65a152a4f576a3255df3676c3b788c84eb5": "Ybodychange",
    "e4c55e17fea55e2fcbef182bb2b0c4b22686f38c": "Ybodychange",
    "6a1c41111edcdc58c846fc50e53554fbba230171": "Ybodychange",
    "c163dc2fce10c1f4f4def6f079069b1bae901fcd": "Ybodychange",
    "aac5c149c7ca500b8eb810b7d4b561ff1e38ea02": "Ybodychange",
    "f67c2d1bd0c8abc3d4ea76deffe45fdd92ef5e05": "Ybodychange",
    "03d46dc571bc5b0f1b3c0cb5daa52e7ee324dd54": "Ybodychange",
    "0870734787d7005d85697549eab5b6479d97d453": "Ybodychange",
    "9db078212f5a37154925cc8872f9adaeca0ed371": "Ybodychange",
    "47a381e306877750b5a3ce5d76e0a5ff652ec188": "Ybodychange",
    "1c8d64f38a86b92f3c5a56105cd0cd51d8b8529b": "Ybodychange",
    "df2991c0cbc3f35c2640b93680667507c4f810dd": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "0af1a2b5bc1469ba22edb63cd58f9b436b1dc4d3": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2312. Deprecated old ContainerId#getId API and updated MapReduce to use ContainerId#getContainerId instead. Contributed by Tsuyoshi OZAWA\n",
      "commitDate": "15/10/14 3:22 PM",
      "commitName": "0af1a2b5bc1469ba22edb63cd58f9b436b1dc4d3",
      "commitAuthor": "Jian He",
      "commitDateOld": "17/06/14 5:51 PM",
      "commitNameOld": "0abddac4767a36e2351ce6a8b59e98a0ea664096",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 119.9,
      "commitsBetweenForRepo": 1124,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n     public void transition(final TaskAttemptImpl taskAttempt, \n         TaskAttemptEvent event) {\n       final TaskAttemptContainerAssignedEvent cEvent \u003d \n         (TaskAttemptContainerAssignedEvent) event;\n       Container container \u003d cEvent.getContainer();\n       taskAttempt.container \u003d container;\n       // this is a _real_ Task (classic Hadoop mapred flavor):\n       taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n       taskAttempt.jvmID \u003d\n           new WrappedJvmID(taskAttempt.remoteTask.getTaskID().getJobID(),\n-            taskAttempt.remoteTask.isMapTask(), taskAttempt.container.getId()\n-              .getId());\n+              taskAttempt.remoteTask.isMapTask(),\n+              taskAttempt.container.getId().getContainerId());\n       taskAttempt.taskAttemptListener.registerPendingTask(\n           taskAttempt.remoteTask, taskAttempt.jvmID);\n \n       taskAttempt.computeRackAndLocality();\n       \n       //launch the container\n       //create the container object to be launched for a given Task attempt\n       ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n           cEvent.getApplicationACLs(), taskAttempt.conf, taskAttempt.jobToken,\n           taskAttempt.remoteTask, taskAttempt.oldJobId, taskAttempt.jvmID,\n           taskAttempt.taskAttemptListener, taskAttempt.credentials);\n       taskAttempt.eventHandler\n         .handle(new ContainerRemoteLaunchEvent(taskAttempt.attemptId,\n           launchContext, container, taskAttempt.remoteTask));\n \n       // send event to speculator that our container needs are satisfied\n       taskAttempt.eventHandler.handle\n           (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void transition(final TaskAttemptImpl taskAttempt, \n        TaskAttemptEvent event) {\n      final TaskAttemptContainerAssignedEvent cEvent \u003d \n        (TaskAttemptContainerAssignedEvent) event;\n      Container container \u003d cEvent.getContainer();\n      taskAttempt.container \u003d container;\n      // this is a _real_ Task (classic Hadoop mapred flavor):\n      taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n      taskAttempt.jvmID \u003d\n          new WrappedJvmID(taskAttempt.remoteTask.getTaskID().getJobID(),\n              taskAttempt.remoteTask.isMapTask(),\n              taskAttempt.container.getId().getContainerId());\n      taskAttempt.taskAttemptListener.registerPendingTask(\n          taskAttempt.remoteTask, taskAttempt.jvmID);\n\n      taskAttempt.computeRackAndLocality();\n      \n      //launch the container\n      //create the container object to be launched for a given Task attempt\n      ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n          cEvent.getApplicationACLs(), taskAttempt.conf, taskAttempt.jobToken,\n          taskAttempt.remoteTask, taskAttempt.oldJobId, taskAttempt.jvmID,\n          taskAttempt.taskAttemptListener, taskAttempt.credentials);\n      taskAttempt.eventHandler\n        .handle(new ContainerRemoteLaunchEvent(taskAttempt.attemptId,\n          launchContext, container, taskAttempt.remoteTask));\n\n      // send event to speculator that our container needs are satisfied\n      taskAttempt.eventHandler.handle\n          (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "cb78a65a152a4f576a3255df3676c3b788c84eb5": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5152. Make MR App to simply pass through the container from RM instead of extracting and populating information itself to start any container. Contributed by Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1469544 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/04/13 1:13 PM",
      "commitName": "cb78a65a152a4f576a3255df3676c3b788c84eb5",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "11/04/13 12:28 PM",
      "commitNameOld": "e4c55e17fea55e2fcbef182bb2b0c4b22686f38c",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 7.03,
      "commitsBetweenForRepo": 35,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,31 @@\n     public void transition(final TaskAttemptImpl taskAttempt, \n         TaskAttemptEvent event) {\n       final TaskAttemptContainerAssignedEvent cEvent \u003d \n         (TaskAttemptContainerAssignedEvent) event;\n-      taskAttempt.containerID \u003d cEvent.getContainer().getId();\n-      taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n-      taskAttempt.containerMgrAddress \u003d StringInterner.weakIntern(\n-          taskAttempt.containerNodeId.toString());\n-      taskAttempt.nodeHttpAddress \u003d StringInterner.weakIntern(\n-          cEvent.getContainer().getNodeHttpAddress());\n-      taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n-      taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n+      Container container \u003d cEvent.getContainer();\n+      taskAttempt.container \u003d container;\n       // this is a _real_ Task (classic Hadoop mapred flavor):\n       taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n-      taskAttempt.jvmID \u003d new WrappedJvmID(\n-          taskAttempt.remoteTask.getTaskID().getJobID(), \n-          taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n+      taskAttempt.jvmID \u003d\n+          new WrappedJvmID(taskAttempt.remoteTask.getTaskID().getJobID(),\n+            taskAttempt.remoteTask.isMapTask(), taskAttempt.container.getId()\n+              .getId());\n       taskAttempt.taskAttemptListener.registerPendingTask(\n           taskAttempt.remoteTask, taskAttempt.jvmID);\n \n       taskAttempt.computeRackAndLocality();\n       \n       //launch the container\n       //create the container object to be launched for a given Task attempt\n       ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n           cEvent.getApplicationACLs(), taskAttempt.conf, taskAttempt.jobToken,\n           taskAttempt.remoteTask, taskAttempt.oldJobId, taskAttempt.jvmID,\n           taskAttempt.taskAttemptListener, taskAttempt.credentials);\n-      taskAttempt.eventHandler.handle(new ContainerRemoteLaunchEvent(\n-          taskAttempt.attemptId, taskAttempt.containerID,\n-          taskAttempt.containerMgrAddress, taskAttempt.containerToken,\n-          launchContext, taskAttempt.assignedCapability, taskAttempt.remoteTask));\n+      taskAttempt.eventHandler\n+        .handle(new ContainerRemoteLaunchEvent(taskAttempt.attemptId,\n+          launchContext, container, taskAttempt.remoteTask));\n \n       // send event to speculator that our container needs are satisfied\n       taskAttempt.eventHandler.handle\n           (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void transition(final TaskAttemptImpl taskAttempt, \n        TaskAttemptEvent event) {\n      final TaskAttemptContainerAssignedEvent cEvent \u003d \n        (TaskAttemptContainerAssignedEvent) event;\n      Container container \u003d cEvent.getContainer();\n      taskAttempt.container \u003d container;\n      // this is a _real_ Task (classic Hadoop mapred flavor):\n      taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n      taskAttempt.jvmID \u003d\n          new WrappedJvmID(taskAttempt.remoteTask.getTaskID().getJobID(),\n            taskAttempt.remoteTask.isMapTask(), taskAttempt.container.getId()\n              .getId());\n      taskAttempt.taskAttemptListener.registerPendingTask(\n          taskAttempt.remoteTask, taskAttempt.jvmID);\n\n      taskAttempt.computeRackAndLocality();\n      \n      //launch the container\n      //create the container object to be launched for a given Task attempt\n      ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n          cEvent.getApplicationACLs(), taskAttempt.conf, taskAttempt.jobToken,\n          taskAttempt.remoteTask, taskAttempt.oldJobId, taskAttempt.jvmID,\n          taskAttempt.taskAttemptListener, taskAttempt.credentials);\n      taskAttempt.eventHandler\n        .handle(new ContainerRemoteLaunchEvent(taskAttempt.attemptId,\n          launchContext, container, taskAttempt.remoteTask));\n\n      // send event to speculator that our container needs are satisfied\n      taskAttempt.eventHandler.handle\n          (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "e4c55e17fea55e2fcbef182bb2b0c4b22686f38c": {
      "type": "Ybodychange",
      "commitMessage": "YARN-486. Changed NM\u0027s startContainer API to accept Container record given by RM as a direct parameter instead of as part of the ContainerLaunchContext record. Contributed by Xuan Gong.\nMAPREDUCE-5139. Update MR AM to use the modified startContainer API after YARN-486. Contributed by Xuan Gong.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1467063 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/04/13 12:28 PM",
      "commitName": "e4c55e17fea55e2fcbef182bb2b0c4b22686f38c",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "10/04/13 9:52 PM",
      "commitNameOld": "6a1c41111edcdc58c846fc50e53554fbba230171",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 0.61,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,37 @@\n     public void transition(final TaskAttemptImpl taskAttempt, \n         TaskAttemptEvent event) {\n       final TaskAttemptContainerAssignedEvent cEvent \u003d \n         (TaskAttemptContainerAssignedEvent) event;\n       taskAttempt.containerID \u003d cEvent.getContainer().getId();\n       taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n       taskAttempt.containerMgrAddress \u003d StringInterner.weakIntern(\n           taskAttempt.containerNodeId.toString());\n       taskAttempt.nodeHttpAddress \u003d StringInterner.weakIntern(\n           cEvent.getContainer().getNodeHttpAddress());\n       taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n       taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n       // this is a _real_ Task (classic Hadoop mapred flavor):\n       taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n       taskAttempt.jvmID \u003d new WrappedJvmID(\n           taskAttempt.remoteTask.getTaskID().getJobID(), \n           taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n       taskAttempt.taskAttemptListener.registerPendingTask(\n           taskAttempt.remoteTask, taskAttempt.jvmID);\n \n       taskAttempt.computeRackAndLocality();\n       \n       //launch the container\n       //create the container object to be launched for a given Task attempt\n       ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n-          cEvent.getApplicationACLs(), taskAttempt.containerID,\n-          taskAttempt.conf, taskAttempt.jobToken, taskAttempt.remoteTask,\n-          taskAttempt.oldJobId, taskAttempt.assignedCapability,\n-          taskAttempt.jvmID, taskAttempt.taskAttemptListener,\n-          taskAttempt.credentials);\n+          cEvent.getApplicationACLs(), taskAttempt.conf, taskAttempt.jobToken,\n+          taskAttempt.remoteTask, taskAttempt.oldJobId, taskAttempt.jvmID,\n+          taskAttempt.taskAttemptListener, taskAttempt.credentials);\n       taskAttempt.eventHandler.handle(new ContainerRemoteLaunchEvent(\n           taskAttempt.attemptId, taskAttempt.containerID,\n           taskAttempt.containerMgrAddress, taskAttempt.containerToken,\n-          launchContext, taskAttempt.remoteTask));\n+          launchContext, taskAttempt.assignedCapability, taskAttempt.remoteTask));\n \n       // send event to speculator that our container needs are satisfied\n       taskAttempt.eventHandler.handle\n           (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void transition(final TaskAttemptImpl taskAttempt, \n        TaskAttemptEvent event) {\n      final TaskAttemptContainerAssignedEvent cEvent \u003d \n        (TaskAttemptContainerAssignedEvent) event;\n      taskAttempt.containerID \u003d cEvent.getContainer().getId();\n      taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n      taskAttempt.containerMgrAddress \u003d StringInterner.weakIntern(\n          taskAttempt.containerNodeId.toString());\n      taskAttempt.nodeHttpAddress \u003d StringInterner.weakIntern(\n          cEvent.getContainer().getNodeHttpAddress());\n      taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n      taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n      // this is a _real_ Task (classic Hadoop mapred flavor):\n      taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n      taskAttempt.jvmID \u003d new WrappedJvmID(\n          taskAttempt.remoteTask.getTaskID().getJobID(), \n          taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n      taskAttempt.taskAttemptListener.registerPendingTask(\n          taskAttempt.remoteTask, taskAttempt.jvmID);\n\n      taskAttempt.computeRackAndLocality();\n      \n      //launch the container\n      //create the container object to be launched for a given Task attempt\n      ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n          cEvent.getApplicationACLs(), taskAttempt.conf, taskAttempt.jobToken,\n          taskAttempt.remoteTask, taskAttempt.oldJobId, taskAttempt.jvmID,\n          taskAttempt.taskAttemptListener, taskAttempt.credentials);\n      taskAttempt.eventHandler.handle(new ContainerRemoteLaunchEvent(\n          taskAttempt.attemptId, taskAttempt.containerID,\n          taskAttempt.containerMgrAddress, taskAttempt.containerToken,\n          launchContext, taskAttempt.assignedCapability, taskAttempt.remoteTask));\n\n      // send event to speculator that our container needs are satisfied\n      taskAttempt.eventHandler.handle\n          (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "6a1c41111edcdc58c846fc50e53554fbba230171": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5079. Changes job recovery to restore state directly from job history, instaed of simulating state machine events. Contributed by Jason Lowe and Robert Parker.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1466767 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/04/13 9:52 PM",
      "commitName": "6a1c41111edcdc58c846fc50e53554fbba230171",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "15/03/13 2:09 PM",
      "commitNameOld": "7d7553c4eb7d9a282410a3213d26a89fea9b7865",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 26.32,
      "commitsBetweenForRepo": 136,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,39 @@\n     public void transition(final TaskAttemptImpl taskAttempt, \n         TaskAttemptEvent event) {\n       final TaskAttemptContainerAssignedEvent cEvent \u003d \n         (TaskAttemptContainerAssignedEvent) event;\n       taskAttempt.containerID \u003d cEvent.getContainer().getId();\n       taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n       taskAttempt.containerMgrAddress \u003d StringInterner.weakIntern(\n           taskAttempt.containerNodeId.toString());\n       taskAttempt.nodeHttpAddress \u003d StringInterner.weakIntern(\n           cEvent.getContainer().getNodeHttpAddress());\n-      taskAttempt.nodeRackName \u003d RackResolver.resolve(\n-          taskAttempt.containerNodeId.getHost()).getNetworkLocation();\n       taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n       taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n       // this is a _real_ Task (classic Hadoop mapred flavor):\n       taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n       taskAttempt.jvmID \u003d new WrappedJvmID(\n           taskAttempt.remoteTask.getTaskID().getJobID(), \n           taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n       taskAttempt.taskAttemptListener.registerPendingTask(\n           taskAttempt.remoteTask, taskAttempt.jvmID);\n \n-      taskAttempt.locality \u003d Locality.OFF_SWITCH;\n-      if (taskAttempt.dataLocalHosts.size() \u003e 0) {\n-        String cHost \u003d taskAttempt.resolveHost(\n-            taskAttempt.containerNodeId.getHost());\n-        if (taskAttempt.dataLocalHosts.contains(cHost)) {\n-          taskAttempt.locality \u003d Locality.NODE_LOCAL;\n-        }\n-      }\n-      if (taskAttempt.locality \u003d\u003d Locality.OFF_SWITCH) {\n-        if (taskAttempt.dataLocalRacks.contains(taskAttempt.nodeRackName)) {\n-          taskAttempt.locality \u003d Locality.RACK_LOCAL;\n-        }\n-      }\n+      taskAttempt.computeRackAndLocality();\n       \n       //launch the container\n       //create the container object to be launched for a given Task attempt\n       ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n           cEvent.getApplicationACLs(), taskAttempt.containerID,\n           taskAttempt.conf, taskAttempt.jobToken, taskAttempt.remoteTask,\n           taskAttempt.oldJobId, taskAttempt.assignedCapability,\n           taskAttempt.jvmID, taskAttempt.taskAttemptListener,\n           taskAttempt.credentials);\n       taskAttempt.eventHandler.handle(new ContainerRemoteLaunchEvent(\n           taskAttempt.attemptId, taskAttempt.containerID,\n           taskAttempt.containerMgrAddress, taskAttempt.containerToken,\n           launchContext, taskAttempt.remoteTask));\n \n       // send event to speculator that our container needs are satisfied\n       taskAttempt.eventHandler.handle\n           (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void transition(final TaskAttemptImpl taskAttempt, \n        TaskAttemptEvent event) {\n      final TaskAttemptContainerAssignedEvent cEvent \u003d \n        (TaskAttemptContainerAssignedEvent) event;\n      taskAttempt.containerID \u003d cEvent.getContainer().getId();\n      taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n      taskAttempt.containerMgrAddress \u003d StringInterner.weakIntern(\n          taskAttempt.containerNodeId.toString());\n      taskAttempt.nodeHttpAddress \u003d StringInterner.weakIntern(\n          cEvent.getContainer().getNodeHttpAddress());\n      taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n      taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n      // this is a _real_ Task (classic Hadoop mapred flavor):\n      taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n      taskAttempt.jvmID \u003d new WrappedJvmID(\n          taskAttempt.remoteTask.getTaskID().getJobID(), \n          taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n      taskAttempt.taskAttemptListener.registerPendingTask(\n          taskAttempt.remoteTask, taskAttempt.jvmID);\n\n      taskAttempt.computeRackAndLocality();\n      \n      //launch the container\n      //create the container object to be launched for a given Task attempt\n      ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n          cEvent.getApplicationACLs(), taskAttempt.containerID,\n          taskAttempt.conf, taskAttempt.jobToken, taskAttempt.remoteTask,\n          taskAttempt.oldJobId, taskAttempt.assignedCapability,\n          taskAttempt.jvmID, taskAttempt.taskAttemptListener,\n          taskAttempt.credentials);\n      taskAttempt.eventHandler.handle(new ContainerRemoteLaunchEvent(\n          taskAttempt.attemptId, taskAttempt.containerID,\n          taskAttempt.containerMgrAddress, taskAttempt.containerToken,\n          launchContext, taskAttempt.remoteTask));\n\n      // send event to speculator that our container needs are satisfied\n      taskAttempt.eventHandler.handle\n          (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "c163dc2fce10c1f4f4def6f079069b1bae901fcd": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4838. Add additional fields like Locality, Avataar to the JobHistory logs. Contributed by Zhijie Shen\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1439714 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/01/13 4:21 PM",
      "commitName": "c163dc2fce10c1f4f4def6f079069b1bae901fcd",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "09/01/13 8:12 AM",
      "commitNameOld": "0ba7078ef4ee127a47c5042c82db0b113a967b23",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 19.34,
      "commitsBetweenForRepo": 104,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,53 @@\n     public void transition(final TaskAttemptImpl taskAttempt, \n         TaskAttemptEvent event) {\n       final TaskAttemptContainerAssignedEvent cEvent \u003d \n         (TaskAttemptContainerAssignedEvent) event;\n       taskAttempt.containerID \u003d cEvent.getContainer().getId();\n       taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n       taskAttempt.containerMgrAddress \u003d StringInterner.weakIntern(\n           taskAttempt.containerNodeId.toString());\n       taskAttempt.nodeHttpAddress \u003d StringInterner.weakIntern(\n           cEvent.getContainer().getNodeHttpAddress());\n       taskAttempt.nodeRackName \u003d RackResolver.resolve(\n           taskAttempt.containerNodeId.getHost()).getNetworkLocation();\n       taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n       taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n       // this is a _real_ Task (classic Hadoop mapred flavor):\n       taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n       taskAttempt.jvmID \u003d new WrappedJvmID(\n           taskAttempt.remoteTask.getTaskID().getJobID(), \n           taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n       taskAttempt.taskAttemptListener.registerPendingTask(\n           taskAttempt.remoteTask, taskAttempt.jvmID);\n+\n+      taskAttempt.locality \u003d Locality.OFF_SWITCH;\n+      if (taskAttempt.dataLocalHosts.size() \u003e 0) {\n+        String cHost \u003d taskAttempt.resolveHost(\n+            taskAttempt.containerNodeId.getHost());\n+        if (taskAttempt.dataLocalHosts.contains(cHost)) {\n+          taskAttempt.locality \u003d Locality.NODE_LOCAL;\n+        }\n+      }\n+      if (taskAttempt.locality \u003d\u003d Locality.OFF_SWITCH) {\n+        if (taskAttempt.dataLocalRacks.contains(taskAttempt.nodeRackName)) {\n+          taskAttempt.locality \u003d Locality.RACK_LOCAL;\n+        }\n+      }\n       \n       //launch the container\n       //create the container object to be launched for a given Task attempt\n       ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n           cEvent.getApplicationACLs(), taskAttempt.containerID,\n           taskAttempt.conf, taskAttempt.jobToken, taskAttempt.remoteTask,\n           taskAttempt.oldJobId, taskAttempt.assignedCapability,\n           taskAttempt.jvmID, taskAttempt.taskAttemptListener,\n           taskAttempt.credentials);\n       taskAttempt.eventHandler.handle(new ContainerRemoteLaunchEvent(\n           taskAttempt.attemptId, taskAttempt.containerID,\n           taskAttempt.containerMgrAddress, taskAttempt.containerToken,\n           launchContext, taskAttempt.remoteTask));\n \n       // send event to speculator that our container needs are satisfied\n       taskAttempt.eventHandler.handle\n           (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void transition(final TaskAttemptImpl taskAttempt, \n        TaskAttemptEvent event) {\n      final TaskAttemptContainerAssignedEvent cEvent \u003d \n        (TaskAttemptContainerAssignedEvent) event;\n      taskAttempt.containerID \u003d cEvent.getContainer().getId();\n      taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n      taskAttempt.containerMgrAddress \u003d StringInterner.weakIntern(\n          taskAttempt.containerNodeId.toString());\n      taskAttempt.nodeHttpAddress \u003d StringInterner.weakIntern(\n          cEvent.getContainer().getNodeHttpAddress());\n      taskAttempt.nodeRackName \u003d RackResolver.resolve(\n          taskAttempt.containerNodeId.getHost()).getNetworkLocation();\n      taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n      taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n      // this is a _real_ Task (classic Hadoop mapred flavor):\n      taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n      taskAttempt.jvmID \u003d new WrappedJvmID(\n          taskAttempt.remoteTask.getTaskID().getJobID(), \n          taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n      taskAttempt.taskAttemptListener.registerPendingTask(\n          taskAttempt.remoteTask, taskAttempt.jvmID);\n\n      taskAttempt.locality \u003d Locality.OFF_SWITCH;\n      if (taskAttempt.dataLocalHosts.size() \u003e 0) {\n        String cHost \u003d taskAttempt.resolveHost(\n            taskAttempt.containerNodeId.getHost());\n        if (taskAttempt.dataLocalHosts.contains(cHost)) {\n          taskAttempt.locality \u003d Locality.NODE_LOCAL;\n        }\n      }\n      if (taskAttempt.locality \u003d\u003d Locality.OFF_SWITCH) {\n        if (taskAttempt.dataLocalRacks.contains(taskAttempt.nodeRackName)) {\n          taskAttempt.locality \u003d Locality.RACK_LOCAL;\n        }\n      }\n      \n      //launch the container\n      //create the container object to be launched for a given Task attempt\n      ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n          cEvent.getApplicationACLs(), taskAttempt.containerID,\n          taskAttempt.conf, taskAttempt.jobToken, taskAttempt.remoteTask,\n          taskAttempt.oldJobId, taskAttempt.assignedCapability,\n          taskAttempt.jvmID, taskAttempt.taskAttemptListener,\n          taskAttempt.credentials);\n      taskAttempt.eventHandler.handle(new ContainerRemoteLaunchEvent(\n          taskAttempt.attemptId, taskAttempt.containerID,\n          taskAttempt.containerMgrAddress, taskAttempt.containerToken,\n          launchContext, taskAttempt.remoteTask));\n\n      // send event to speculator that our container needs are satisfied\n      taskAttempt.eventHandler.handle\n          (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "aac5c149c7ca500b8eb810b7d4b561ff1e38ea02": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4752. Reduce MR AM memory usage through String Interning (Robert Evans via tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1404177 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/10/12 7:57 AM",
      "commitName": "aac5c149c7ca500b8eb810b7d4b561ff1e38ea02",
      "commitAuthor": "Thomas Graves",
      "commitDateOld": "23/10/12 2:02 PM",
      "commitNameOld": "382b565e8c8f59bef07b8cd893e1be30370f582c",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 7.75,
      "commitsBetweenForRepo": 38,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,39 @@\n     public void transition(final TaskAttemptImpl taskAttempt, \n         TaskAttemptEvent event) {\n       final TaskAttemptContainerAssignedEvent cEvent \u003d \n         (TaskAttemptContainerAssignedEvent) event;\n       taskAttempt.containerID \u003d cEvent.getContainer().getId();\n       taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n-      taskAttempt.containerMgrAddress \u003d taskAttempt.containerNodeId\n-          .toString();\n-      taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n+      taskAttempt.containerMgrAddress \u003d StringInterner.weakIntern(\n+          taskAttempt.containerNodeId.toString());\n+      taskAttempt.nodeHttpAddress \u003d StringInterner.weakIntern(\n+          cEvent.getContainer().getNodeHttpAddress());\n       taskAttempt.nodeRackName \u003d RackResolver.resolve(\n           taskAttempt.containerNodeId.getHost()).getNetworkLocation();\n       taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n       taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n       // this is a _real_ Task (classic Hadoop mapred flavor):\n       taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n       taskAttempt.jvmID \u003d new WrappedJvmID(\n           taskAttempt.remoteTask.getTaskID().getJobID(), \n           taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n       taskAttempt.taskAttemptListener.registerPendingTask(\n           taskAttempt.remoteTask, taskAttempt.jvmID);\n       \n       //launch the container\n       //create the container object to be launched for a given Task attempt\n       ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n           cEvent.getApplicationACLs(), taskAttempt.containerID,\n           taskAttempt.conf, taskAttempt.jobToken, taskAttempt.remoteTask,\n           taskAttempt.oldJobId, taskAttempt.assignedCapability,\n           taskAttempt.jvmID, taskAttempt.taskAttemptListener,\n           taskAttempt.credentials);\n       taskAttempt.eventHandler.handle(new ContainerRemoteLaunchEvent(\n           taskAttempt.attemptId, taskAttempt.containerID,\n           taskAttempt.containerMgrAddress, taskAttempt.containerToken,\n           launchContext, taskAttempt.remoteTask));\n \n       // send event to speculator that our container needs are satisfied\n       taskAttempt.eventHandler.handle\n           (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void transition(final TaskAttemptImpl taskAttempt, \n        TaskAttemptEvent event) {\n      final TaskAttemptContainerAssignedEvent cEvent \u003d \n        (TaskAttemptContainerAssignedEvent) event;\n      taskAttempt.containerID \u003d cEvent.getContainer().getId();\n      taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n      taskAttempt.containerMgrAddress \u003d StringInterner.weakIntern(\n          taskAttempt.containerNodeId.toString());\n      taskAttempt.nodeHttpAddress \u003d StringInterner.weakIntern(\n          cEvent.getContainer().getNodeHttpAddress());\n      taskAttempt.nodeRackName \u003d RackResolver.resolve(\n          taskAttempt.containerNodeId.getHost()).getNetworkLocation();\n      taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n      taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n      // this is a _real_ Task (classic Hadoop mapred flavor):\n      taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n      taskAttempt.jvmID \u003d new WrappedJvmID(\n          taskAttempt.remoteTask.getTaskID().getJobID(), \n          taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n      taskAttempt.taskAttemptListener.registerPendingTask(\n          taskAttempt.remoteTask, taskAttempt.jvmID);\n      \n      //launch the container\n      //create the container object to be launched for a given Task attempt\n      ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n          cEvent.getApplicationACLs(), taskAttempt.containerID,\n          taskAttempt.conf, taskAttempt.jobToken, taskAttempt.remoteTask,\n          taskAttempt.oldJobId, taskAttempt.assignedCapability,\n          taskAttempt.jvmID, taskAttempt.taskAttemptListener,\n          taskAttempt.credentials);\n      taskAttempt.eventHandler.handle(new ContainerRemoteLaunchEvent(\n          taskAttempt.attemptId, taskAttempt.containerID,\n          taskAttempt.containerMgrAddress, taskAttempt.containerToken,\n          launchContext, taskAttempt.remoteTask));\n\n      // send event to speculator that our container needs are satisfied\n      taskAttempt.eventHandler.handle\n          (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "f67c2d1bd0c8abc3d4ea76deffe45fdd92ef5e05": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4043. Secret keys set in Credentials are not seen by tasks (Jason Lowe via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1304587 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/03/12 1:46 PM",
      "commitName": "f67c2d1bd0c8abc3d4ea76deffe45fdd92ef5e05",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "19/03/12 1:31 PM",
      "commitNameOld": "9d8d02b68b5ffc18e8f9f00db1750a80d3fc9061",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 4.01,
      "commitsBetweenForRepo": 25,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,38 @@\n     public void transition(final TaskAttemptImpl taskAttempt, \n         TaskAttemptEvent event) {\n       final TaskAttemptContainerAssignedEvent cEvent \u003d \n         (TaskAttemptContainerAssignedEvent) event;\n       taskAttempt.containerID \u003d cEvent.getContainer().getId();\n       taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n       taskAttempt.containerMgrAddress \u003d taskAttempt.containerNodeId\n           .toString();\n       taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n       taskAttempt.nodeRackName \u003d RackResolver.resolve(\n           taskAttempt.containerNodeId.getHost()).getNetworkLocation();\n       taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n       taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n       // this is a _real_ Task (classic Hadoop mapred flavor):\n       taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n       taskAttempt.jvmID \u003d new WrappedJvmID(\n           taskAttempt.remoteTask.getTaskID().getJobID(), \n           taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n       taskAttempt.taskAttemptListener.registerPendingTask(\n           taskAttempt.remoteTask, taskAttempt.jvmID);\n       \n       //launch the container\n       //create the container object to be launched for a given Task attempt\n       ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n           cEvent.getApplicationACLs(), taskAttempt.containerID,\n           taskAttempt.conf, taskAttempt.jobToken, taskAttempt.remoteTask,\n           taskAttempt.oldJobId, taskAttempt.assignedCapability,\n           taskAttempt.jvmID, taskAttempt.taskAttemptListener,\n-          taskAttempt.fsTokens);\n+          taskAttempt.credentials);\n       taskAttempt.eventHandler.handle(new ContainerRemoteLaunchEvent(\n           taskAttempt.attemptId, taskAttempt.containerID,\n           taskAttempt.containerMgrAddress, taskAttempt.containerToken,\n           launchContext, taskAttempt.remoteTask));\n \n       // send event to speculator that our container needs are satisfied\n       taskAttempt.eventHandler.handle\n           (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void transition(final TaskAttemptImpl taskAttempt, \n        TaskAttemptEvent event) {\n      final TaskAttemptContainerAssignedEvent cEvent \u003d \n        (TaskAttemptContainerAssignedEvent) event;\n      taskAttempt.containerID \u003d cEvent.getContainer().getId();\n      taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n      taskAttempt.containerMgrAddress \u003d taskAttempt.containerNodeId\n          .toString();\n      taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n      taskAttempt.nodeRackName \u003d RackResolver.resolve(\n          taskAttempt.containerNodeId.getHost()).getNetworkLocation();\n      taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n      taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n      // this is a _real_ Task (classic Hadoop mapred flavor):\n      taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n      taskAttempt.jvmID \u003d new WrappedJvmID(\n          taskAttempt.remoteTask.getTaskID().getJobID(), \n          taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n      taskAttempt.taskAttemptListener.registerPendingTask(\n          taskAttempt.remoteTask, taskAttempt.jvmID);\n      \n      //launch the container\n      //create the container object to be launched for a given Task attempt\n      ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n          cEvent.getApplicationACLs(), taskAttempt.containerID,\n          taskAttempt.conf, taskAttempt.jobToken, taskAttempt.remoteTask,\n          taskAttempt.oldJobId, taskAttempt.assignedCapability,\n          taskAttempt.jvmID, taskAttempt.taskAttemptListener,\n          taskAttempt.credentials);\n      taskAttempt.eventHandler.handle(new ContainerRemoteLaunchEvent(\n          taskAttempt.attemptId, taskAttempt.containerID,\n          taskAttempt.containerMgrAddress, taskAttempt.containerToken,\n          launchContext, taskAttempt.remoteTask));\n\n      // send event to speculator that our container needs are satisfied\n      taskAttempt.eventHandler.handle\n          (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "03d46dc571bc5b0f1b3c0cb5daa52e7ee324dd54": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3569. TaskAttemptListener holds a global lock for all task-updates. (Contributed by Vinod Kumar Vavilapalli)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1227485 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/01/12 9:19 PM",
      "commitName": "03d46dc571bc5b0f1b3c0cb5daa52e7ee324dd54",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "04/01/12 5:29 PM",
      "commitNameOld": "0870734787d7005d85697549eab5b6479d97d453",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.16,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,38 @@\n     public void transition(final TaskAttemptImpl taskAttempt, \n         TaskAttemptEvent event) {\n       final TaskAttemptContainerAssignedEvent cEvent \u003d \n         (TaskAttemptContainerAssignedEvent) event;\n       taskAttempt.containerID \u003d cEvent.getContainer().getId();\n       taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n       taskAttempt.containerMgrAddress \u003d taskAttempt.containerNodeId\n           .toString();\n       taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n       taskAttempt.nodeRackName \u003d RackResolver.resolve(\n           taskAttempt.containerNodeId.getHost()).getNetworkLocation();\n       taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n       taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n       // this is a _real_ Task (classic Hadoop mapred flavor):\n       taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n       taskAttempt.jvmID \u003d new WrappedJvmID(\n           taskAttempt.remoteTask.getTaskID().getJobID(), \n           taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n-      taskAttempt.taskAttemptListener.registerPendingTask(taskAttempt.jvmID);\n+      taskAttempt.taskAttemptListener.registerPendingTask(\n+          taskAttempt.remoteTask, taskAttempt.jvmID);\n       \n       //launch the container\n       //create the container object to be launched for a given Task attempt\n       ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n           cEvent.getApplicationACLs(), taskAttempt.containerID,\n           taskAttempt.conf, taskAttempt.jobToken, taskAttempt.remoteTask,\n           taskAttempt.oldJobId, taskAttempt.assignedCapability,\n           taskAttempt.jvmID, taskAttempt.taskAttemptListener,\n           taskAttempt.fsTokens);\n       taskAttempt.eventHandler.handle(new ContainerRemoteLaunchEvent(\n           taskAttempt.attemptId, taskAttempt.containerID,\n           taskAttempt.containerMgrAddress, taskAttempt.containerToken,\n           launchContext, taskAttempt.remoteTask));\n \n       // send event to speculator that our container needs are satisfied\n       taskAttempt.eventHandler.handle\n           (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void transition(final TaskAttemptImpl taskAttempt, \n        TaskAttemptEvent event) {\n      final TaskAttemptContainerAssignedEvent cEvent \u003d \n        (TaskAttemptContainerAssignedEvent) event;\n      taskAttempt.containerID \u003d cEvent.getContainer().getId();\n      taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n      taskAttempt.containerMgrAddress \u003d taskAttempt.containerNodeId\n          .toString();\n      taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n      taskAttempt.nodeRackName \u003d RackResolver.resolve(\n          taskAttempt.containerNodeId.getHost()).getNetworkLocation();\n      taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n      taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n      // this is a _real_ Task (classic Hadoop mapred flavor):\n      taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n      taskAttempt.jvmID \u003d new WrappedJvmID(\n          taskAttempt.remoteTask.getTaskID().getJobID(), \n          taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n      taskAttempt.taskAttemptListener.registerPendingTask(\n          taskAttempt.remoteTask, taskAttempt.jvmID);\n      \n      //launch the container\n      //create the container object to be launched for a given Task attempt\n      ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n          cEvent.getApplicationACLs(), taskAttempt.containerID,\n          taskAttempt.conf, taskAttempt.jobToken, taskAttempt.remoteTask,\n          taskAttempt.oldJobId, taskAttempt.assignedCapability,\n          taskAttempt.jvmID, taskAttempt.taskAttemptListener,\n          taskAttempt.fsTokens);\n      taskAttempt.eventHandler.handle(new ContainerRemoteLaunchEvent(\n          taskAttempt.attemptId, taskAttempt.containerID,\n          taskAttempt.containerMgrAddress, taskAttempt.containerToken,\n          launchContext, taskAttempt.remoteTask));\n\n      // send event to speculator that our container needs are satisfied\n      taskAttempt.eventHandler.handle\n          (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "0870734787d7005d85697549eab5b6479d97d453": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3566. Fixed MR AM to construct CLC only once across all tasks. Contributed by Vinod K V.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1227422 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/01/12 5:29 PM",
      "commitName": "0870734787d7005d85697549eab5b6479d97d453",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "22/12/11 2:34 PM",
      "commitNameOld": "8fa0a3c737f27ff9d12fb657a7b22865754a5fd8",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 13.12,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,37 @@\n     public void transition(final TaskAttemptImpl taskAttempt, \n         TaskAttemptEvent event) {\n       final TaskAttemptContainerAssignedEvent cEvent \u003d \n         (TaskAttemptContainerAssignedEvent) event;\n       taskAttempt.containerID \u003d cEvent.getContainer().getId();\n       taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n       taskAttempt.containerMgrAddress \u003d taskAttempt.containerNodeId\n           .toString();\n       taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n       taskAttempt.nodeRackName \u003d RackResolver.resolve(\n           taskAttempt.containerNodeId.getHost()).getNetworkLocation();\n       taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n       taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n       // this is a _real_ Task (classic Hadoop mapred flavor):\n       taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n       taskAttempt.jvmID \u003d new WrappedJvmID(\n           taskAttempt.remoteTask.getTaskID().getJobID(), \n           taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n       taskAttempt.taskAttemptListener.registerPendingTask(taskAttempt.jvmID);\n       \n       //launch the container\n       //create the container object to be launched for a given Task attempt\n-      taskAttempt.eventHandler.handle(\n-          new ContainerRemoteLaunchEvent(taskAttempt.attemptId, \n-              taskAttempt.containerID, \n-              taskAttempt.containerMgrAddress, taskAttempt.containerToken) {\n-        @Override\n-        public ContainerLaunchContext getContainer() {\n-          return taskAttempt.createContainerLaunchContext(cEvent\n-              .getApplicationACLs());\n-        }\n-        @Override\n-        public Task getRemoteTask() {  // classic mapred Task, not YARN version\n-          return taskAttempt.remoteTask;\n-        }\n-      });\n+      ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n+          cEvent.getApplicationACLs(), taskAttempt.containerID,\n+          taskAttempt.conf, taskAttempt.jobToken, taskAttempt.remoteTask,\n+          taskAttempt.oldJobId, taskAttempt.assignedCapability,\n+          taskAttempt.jvmID, taskAttempt.taskAttemptListener,\n+          taskAttempt.fsTokens);\n+      taskAttempt.eventHandler.handle(new ContainerRemoteLaunchEvent(\n+          taskAttempt.attemptId, taskAttempt.containerID,\n+          taskAttempt.containerMgrAddress, taskAttempt.containerToken,\n+          launchContext, taskAttempt.remoteTask));\n \n       // send event to speculator that our container needs are satisfied\n       taskAttempt.eventHandler.handle\n           (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void transition(final TaskAttemptImpl taskAttempt, \n        TaskAttemptEvent event) {\n      final TaskAttemptContainerAssignedEvent cEvent \u003d \n        (TaskAttemptContainerAssignedEvent) event;\n      taskAttempt.containerID \u003d cEvent.getContainer().getId();\n      taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n      taskAttempt.containerMgrAddress \u003d taskAttempt.containerNodeId\n          .toString();\n      taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n      taskAttempt.nodeRackName \u003d RackResolver.resolve(\n          taskAttempt.containerNodeId.getHost()).getNetworkLocation();\n      taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n      taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n      // this is a _real_ Task (classic Hadoop mapred flavor):\n      taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n      taskAttempt.jvmID \u003d new WrappedJvmID(\n          taskAttempt.remoteTask.getTaskID().getJobID(), \n          taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n      taskAttempt.taskAttemptListener.registerPendingTask(taskAttempt.jvmID);\n      \n      //launch the container\n      //create the container object to be launched for a given Task attempt\n      ContainerLaunchContext launchContext \u003d createContainerLaunchContext(\n          cEvent.getApplicationACLs(), taskAttempt.containerID,\n          taskAttempt.conf, taskAttempt.jobToken, taskAttempt.remoteTask,\n          taskAttempt.oldJobId, taskAttempt.assignedCapability,\n          taskAttempt.jvmID, taskAttempt.taskAttemptListener,\n          taskAttempt.fsTokens);\n      taskAttempt.eventHandler.handle(new ContainerRemoteLaunchEvent(\n          taskAttempt.attemptId, taskAttempt.containerID,\n          taskAttempt.containerMgrAddress, taskAttempt.containerToken,\n          launchContext, taskAttempt.remoteTask));\n\n      // send event to speculator that our container needs are satisfied\n      taskAttempt.eventHandler.handle\n          (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "9db078212f5a37154925cc8872f9adaeca0ed371": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3035. Fixed MR JobHistory to ensure rack information is present. Contributed by chakravarthy.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195575 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/10/11 10:27 AM",
      "commitName": "9db078212f5a37154925cc8872f9adaeca0ed371",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "30/10/11 11:42 PM",
      "commitNameOld": "47a381e306877750b5a3ce5d76e0a5ff652ec188",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.45,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,41 @@\n     public void transition(final TaskAttemptImpl taskAttempt, \n         TaskAttemptEvent event) {\n       final TaskAttemptContainerAssignedEvent cEvent \u003d \n         (TaskAttemptContainerAssignedEvent) event;\n       taskAttempt.containerID \u003d cEvent.getContainer().getId();\n       taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n       taskAttempt.containerMgrAddress \u003d taskAttempt.containerNodeId\n           .toString();\n       taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n+      taskAttempt.nodeRackName \u003d RackResolver.resolve(\n+          taskAttempt.containerNodeId.getHost()).getNetworkLocation();\n       taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n       taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n       // this is a _real_ Task (classic Hadoop mapred flavor):\n       taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n       taskAttempt.jvmID \u003d new WrappedJvmID(\n           taskAttempt.remoteTask.getTaskID().getJobID(), \n           taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n       taskAttempt.taskAttemptListener.registerPendingTask(taskAttempt.jvmID);\n       \n       //launch the container\n       //create the container object to be launched for a given Task attempt\n       taskAttempt.eventHandler.handle(\n           new ContainerRemoteLaunchEvent(taskAttempt.attemptId, \n               taskAttempt.containerID, \n               taskAttempt.containerMgrAddress, taskAttempt.containerToken) {\n         @Override\n         public ContainerLaunchContext getContainer() {\n           return taskAttempt.createContainerLaunchContext(cEvent\n               .getApplicationACLs());\n         }\n         @Override\n         public Task getRemoteTask() {  // classic mapred Task, not YARN version\n           return taskAttempt.remoteTask;\n         }\n       });\n \n       // send event to speculator that our container needs are satisfied\n       taskAttempt.eventHandler.handle\n           (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void transition(final TaskAttemptImpl taskAttempt, \n        TaskAttemptEvent event) {\n      final TaskAttemptContainerAssignedEvent cEvent \u003d \n        (TaskAttemptContainerAssignedEvent) event;\n      taskAttempt.containerID \u003d cEvent.getContainer().getId();\n      taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n      taskAttempt.containerMgrAddress \u003d taskAttempt.containerNodeId\n          .toString();\n      taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n      taskAttempt.nodeRackName \u003d RackResolver.resolve(\n          taskAttempt.containerNodeId.getHost()).getNetworkLocation();\n      taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n      taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n      // this is a _real_ Task (classic Hadoop mapred flavor):\n      taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n      taskAttempt.jvmID \u003d new WrappedJvmID(\n          taskAttempt.remoteTask.getTaskID().getJobID(), \n          taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n      taskAttempt.taskAttemptListener.registerPendingTask(taskAttempt.jvmID);\n      \n      //launch the container\n      //create the container object to be launched for a given Task attempt\n      taskAttempt.eventHandler.handle(\n          new ContainerRemoteLaunchEvent(taskAttempt.attemptId, \n              taskAttempt.containerID, \n              taskAttempt.containerMgrAddress, taskAttempt.containerToken) {\n        @Override\n        public ContainerLaunchContext getContainer() {\n          return taskAttempt.createContainerLaunchContext(cEvent\n              .getApplicationACLs());\n        }\n        @Override\n        public Task getRemoteTask() {  // classic mapred Task, not YARN version\n          return taskAttempt.remoteTask;\n        }\n      });\n\n      // send event to speculator that our container needs are satisfied\n      taskAttempt.eventHandler.handle\n          (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "47a381e306877750b5a3ce5d76e0a5ff652ec188": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3146. Added a MR specific command line to dump logs for a given TaskAttemptID. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195349 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/10/11 11:42 PM",
      "commitName": "47a381e306877750b5a3ce5d76e0a5ff652ec188",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "30/10/11 4:29 AM",
      "commitNameOld": "1c8d64f38a86b92f3c5a56105cd0cd51d8b8529b",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.8,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,39 @@\n     public void transition(final TaskAttemptImpl taskAttempt, \n         TaskAttemptEvent event) {\n       final TaskAttemptContainerAssignedEvent cEvent \u003d \n         (TaskAttemptContainerAssignedEvent) event;\n       taskAttempt.containerID \u003d cEvent.getContainer().getId();\n-      taskAttempt.nodeHostName \u003d cEvent.getContainer().getNodeId().getHost();\n-      taskAttempt.containerMgrAddress \u003d cEvent.getContainer().getNodeId()\n+      taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n+      taskAttempt.containerMgrAddress \u003d taskAttempt.containerNodeId\n           .toString();\n       taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n       taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n       taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n       // this is a _real_ Task (classic Hadoop mapred flavor):\n       taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n       taskAttempt.jvmID \u003d new WrappedJvmID(\n           taskAttempt.remoteTask.getTaskID().getJobID(), \n           taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n       taskAttempt.taskAttemptListener.registerPendingTask(taskAttempt.jvmID);\n       \n       //launch the container\n       //create the container object to be launched for a given Task attempt\n       taskAttempt.eventHandler.handle(\n           new ContainerRemoteLaunchEvent(taskAttempt.attemptId, \n               taskAttempt.containerID, \n               taskAttempt.containerMgrAddress, taskAttempt.containerToken) {\n         @Override\n         public ContainerLaunchContext getContainer() {\n           return taskAttempt.createContainerLaunchContext(cEvent\n               .getApplicationACLs());\n         }\n         @Override\n         public Task getRemoteTask() {  // classic mapred Task, not YARN version\n           return taskAttempt.remoteTask;\n         }\n       });\n \n       // send event to speculator that our container needs are satisfied\n       taskAttempt.eventHandler.handle\n           (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void transition(final TaskAttemptImpl taskAttempt, \n        TaskAttemptEvent event) {\n      final TaskAttemptContainerAssignedEvent cEvent \u003d \n        (TaskAttemptContainerAssignedEvent) event;\n      taskAttempt.containerID \u003d cEvent.getContainer().getId();\n      taskAttempt.containerNodeId \u003d cEvent.getContainer().getNodeId();\n      taskAttempt.containerMgrAddress \u003d taskAttempt.containerNodeId\n          .toString();\n      taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n      taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n      taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n      // this is a _real_ Task (classic Hadoop mapred flavor):\n      taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n      taskAttempt.jvmID \u003d new WrappedJvmID(\n          taskAttempt.remoteTask.getTaskID().getJobID(), \n          taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n      taskAttempt.taskAttemptListener.registerPendingTask(taskAttempt.jvmID);\n      \n      //launch the container\n      //create the container object to be launched for a given Task attempt\n      taskAttempt.eventHandler.handle(\n          new ContainerRemoteLaunchEvent(taskAttempt.attemptId, \n              taskAttempt.containerID, \n              taskAttempt.containerMgrAddress, taskAttempt.containerToken) {\n        @Override\n        public ContainerLaunchContext getContainer() {\n          return taskAttempt.createContainerLaunchContext(cEvent\n              .getApplicationACLs());\n        }\n        @Override\n        public Task getRemoteTask() {  // classic mapred Task, not YARN version\n          return taskAttempt.remoteTask;\n        }\n      });\n\n      // send event to speculator that our container needs are satisfied\n      taskAttempt.eventHandler.handle\n          (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "1c8d64f38a86b92f3c5a56105cd0cd51d8b8529b": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3274. Fixed a race condition in MRAppMaster that was causing a task-scheduling deadlock. Contributed by Robert Joseph Evans.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195145 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/10/11 4:29 AM",
      "commitName": "1c8d64f38a86b92f3c5a56105cd0cd51d8b8529b",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "24/10/11 11:26 PM",
      "commitNameOld": "fffdf661e30afd10331d2153ff052c141b7ebe4b",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 5.21,
      "commitsBetweenForRepo": 73,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,39 @@\n     public void transition(final TaskAttemptImpl taskAttempt, \n         TaskAttemptEvent event) {\n       final TaskAttemptContainerAssignedEvent cEvent \u003d \n         (TaskAttemptContainerAssignedEvent) event;\n       taskAttempt.containerID \u003d cEvent.getContainer().getId();\n       taskAttempt.nodeHostName \u003d cEvent.getContainer().getNodeId().getHost();\n       taskAttempt.containerMgrAddress \u003d cEvent.getContainer().getNodeId()\n           .toString();\n       taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n       taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n       taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n       // this is a _real_ Task (classic Hadoop mapred flavor):\n       taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n       taskAttempt.jvmID \u003d new WrappedJvmID(\n           taskAttempt.remoteTask.getTaskID().getJobID(), \n           taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n+      taskAttempt.taskAttemptListener.registerPendingTask(taskAttempt.jvmID);\n       \n       //launch the container\n       //create the container object to be launched for a given Task attempt\n       taskAttempt.eventHandler.handle(\n           new ContainerRemoteLaunchEvent(taskAttempt.attemptId, \n               taskAttempt.containerID, \n               taskAttempt.containerMgrAddress, taskAttempt.containerToken) {\n         @Override\n         public ContainerLaunchContext getContainer() {\n           return taskAttempt.createContainerLaunchContext(cEvent\n               .getApplicationACLs());\n         }\n         @Override\n         public Task getRemoteTask() {  // classic mapred Task, not YARN version\n           return taskAttempt.remoteTask;\n         }\n       });\n \n       // send event to speculator that our container needs are satisfied\n       taskAttempt.eventHandler.handle\n           (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void transition(final TaskAttemptImpl taskAttempt, \n        TaskAttemptEvent event) {\n      final TaskAttemptContainerAssignedEvent cEvent \u003d \n        (TaskAttemptContainerAssignedEvent) event;\n      taskAttempt.containerID \u003d cEvent.getContainer().getId();\n      taskAttempt.nodeHostName \u003d cEvent.getContainer().getNodeId().getHost();\n      taskAttempt.containerMgrAddress \u003d cEvent.getContainer().getNodeId()\n          .toString();\n      taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n      taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n      taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n      // this is a _real_ Task (classic Hadoop mapred flavor):\n      taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n      taskAttempt.jvmID \u003d new WrappedJvmID(\n          taskAttempt.remoteTask.getTaskID().getJobID(), \n          taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n      taskAttempt.taskAttemptListener.registerPendingTask(taskAttempt.jvmID);\n      \n      //launch the container\n      //create the container object to be launched for a given Task attempt\n      taskAttempt.eventHandler.handle(\n          new ContainerRemoteLaunchEvent(taskAttempt.attemptId, \n              taskAttempt.containerID, \n              taskAttempt.containerMgrAddress, taskAttempt.containerToken) {\n        @Override\n        public ContainerLaunchContext getContainer() {\n          return taskAttempt.createContainerLaunchContext(cEvent\n              .getApplicationACLs());\n        }\n        @Override\n        public Task getRemoteTask() {  // classic mapred Task, not YARN version\n          return taskAttempt.remoteTask;\n        }\n      });\n\n      // send event to speculator that our container needs are satisfied\n      taskAttempt.eventHandler.handle\n          (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "df2991c0cbc3f35c2640b93680667507c4f810dd": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3104. Implemented Application-acls. (vinodkv)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1186748 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/10/11 4:45 AM",
      "commitName": "df2991c0cbc3f35c2640b93680667507c4f810dd",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "18/10/11 10:21 PM",
      "commitNameOld": "13e4562924a6cb3d16c262e0f595b2ffbf9e0546",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 1.27,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,38 @@\n     public void transition(final TaskAttemptImpl taskAttempt, \n         TaskAttemptEvent event) {\n-      TaskAttemptContainerAssignedEvent cEvent \u003d \n+      final TaskAttemptContainerAssignedEvent cEvent \u003d \n         (TaskAttemptContainerAssignedEvent) event;\n       taskAttempt.containerID \u003d cEvent.getContainer().getId();\n       taskAttempt.nodeHostName \u003d cEvent.getContainer().getNodeId().getHost();\n       taskAttempt.containerMgrAddress \u003d cEvent.getContainer().getNodeId()\n           .toString();\n       taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n       taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n       taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n       // this is a _real_ Task (classic Hadoop mapred flavor):\n       taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n       taskAttempt.jvmID \u003d new WrappedJvmID(\n           taskAttempt.remoteTask.getTaskID().getJobID(), \n           taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n       \n       //launch the container\n       //create the container object to be launched for a given Task attempt\n       taskAttempt.eventHandler.handle(\n           new ContainerRemoteLaunchEvent(taskAttempt.attemptId, \n               taskAttempt.containerID, \n               taskAttempt.containerMgrAddress, taskAttempt.containerToken) {\n         @Override\n         public ContainerLaunchContext getContainer() {\n-          return taskAttempt.createContainerLaunchContext();\n+          return taskAttempt.createContainerLaunchContext(cEvent\n+              .getApplicationACLs());\n         }\n         @Override\n         public Task getRemoteTask() {  // classic mapred Task, not YARN version\n           return taskAttempt.remoteTask;\n         }\n       });\n \n       // send event to speculator that our container needs are satisfied\n       taskAttempt.eventHandler.handle\n           (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void transition(final TaskAttemptImpl taskAttempt, \n        TaskAttemptEvent event) {\n      final TaskAttemptContainerAssignedEvent cEvent \u003d \n        (TaskAttemptContainerAssignedEvent) event;\n      taskAttempt.containerID \u003d cEvent.getContainer().getId();\n      taskAttempt.nodeHostName \u003d cEvent.getContainer().getNodeId().getHost();\n      taskAttempt.containerMgrAddress \u003d cEvent.getContainer().getNodeId()\n          .toString();\n      taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n      taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n      taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n      // this is a _real_ Task (classic Hadoop mapred flavor):\n      taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n      taskAttempt.jvmID \u003d new WrappedJvmID(\n          taskAttempt.remoteTask.getTaskID().getJobID(), \n          taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n      \n      //launch the container\n      //create the container object to be launched for a given Task attempt\n      taskAttempt.eventHandler.handle(\n          new ContainerRemoteLaunchEvent(taskAttempt.attemptId, \n              taskAttempt.containerID, \n              taskAttempt.containerMgrAddress, taskAttempt.containerToken) {\n        @Override\n        public ContainerLaunchContext getContainer() {\n          return taskAttempt.createContainerLaunchContext(cEvent\n              .getApplicationACLs());\n        }\n        @Override\n        public Task getRemoteTask() {  // classic mapred Task, not YARN version\n          return taskAttempt.remoteTask;\n        }\n      });\n\n      // send event to speculator that our container needs are satisfied\n      taskAttempt.eventHandler.handle\n          (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public void transition(final TaskAttemptImpl taskAttempt, \n        TaskAttemptEvent event) {\n      TaskAttemptContainerAssignedEvent cEvent \u003d \n        (TaskAttemptContainerAssignedEvent) event;\n      taskAttempt.containerID \u003d cEvent.getContainer().getId();\n      taskAttempt.nodeHostName \u003d cEvent.getContainer().getNodeId().getHost();\n      taskAttempt.containerMgrAddress \u003d cEvent.getContainer().getNodeId()\n          .toString();\n      taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n      taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n      taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n      // this is a _real_ Task (classic Hadoop mapred flavor):\n      taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n      taskAttempt.jvmID \u003d new WrappedJvmID(\n          taskAttempt.remoteTask.getTaskID().getJobID(), \n          taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n      \n      //launch the container\n      //create the container object to be launched for a given Task attempt\n      taskAttempt.eventHandler.handle(\n          new ContainerRemoteLaunchEvent(taskAttempt.attemptId, \n              taskAttempt.containerID, \n              taskAttempt.containerMgrAddress, taskAttempt.containerToken) {\n        @Override\n        public ContainerLaunchContext getContainer() {\n          return taskAttempt.createContainerLaunchContext();\n        }\n        @Override\n        public Task getRemoteTask() {  // classic mapred Task, not YARN version\n          return taskAttempt.remoteTask;\n        }\n      });\n\n      // send event to speculator that our container needs are satisfied\n      taskAttempt.eventHandler.handle\n          (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,37 @@\n+    public void transition(final TaskAttemptImpl taskAttempt, \n+        TaskAttemptEvent event) {\n+      TaskAttemptContainerAssignedEvent cEvent \u003d \n+        (TaskAttemptContainerAssignedEvent) event;\n+      taskAttempt.containerID \u003d cEvent.getContainer().getId();\n+      taskAttempt.nodeHostName \u003d cEvent.getContainer().getNodeId().getHost();\n+      taskAttempt.containerMgrAddress \u003d cEvent.getContainer().getNodeId()\n+          .toString();\n+      taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n+      taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n+      taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n+      // this is a _real_ Task (classic Hadoop mapred flavor):\n+      taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n+      taskAttempt.jvmID \u003d new WrappedJvmID(\n+          taskAttempt.remoteTask.getTaskID().getJobID(), \n+          taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n+      \n+      //launch the container\n+      //create the container object to be launched for a given Task attempt\n+      taskAttempt.eventHandler.handle(\n+          new ContainerRemoteLaunchEvent(taskAttempt.attemptId, \n+              taskAttempt.containerID, \n+              taskAttempt.containerMgrAddress, taskAttempt.containerToken) {\n+        @Override\n+        public ContainerLaunchContext getContainer() {\n+          return taskAttempt.createContainerLaunchContext();\n+        }\n+        @Override\n+        public Task getRemoteTask() {  // classic mapred Task, not YARN version\n+          return taskAttempt.remoteTask;\n+        }\n+      });\n+\n+      // send event to speculator that our container needs are satisfied\n+      taskAttempt.eventHandler.handle\n+          (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public void transition(final TaskAttemptImpl taskAttempt, \n        TaskAttemptEvent event) {\n      TaskAttemptContainerAssignedEvent cEvent \u003d \n        (TaskAttemptContainerAssignedEvent) event;\n      taskAttempt.containerID \u003d cEvent.getContainer().getId();\n      taskAttempt.nodeHostName \u003d cEvent.getContainer().getNodeId().getHost();\n      taskAttempt.containerMgrAddress \u003d cEvent.getContainer().getNodeId()\n          .toString();\n      taskAttempt.nodeHttpAddress \u003d cEvent.getContainer().getNodeHttpAddress();\n      taskAttempt.containerToken \u003d cEvent.getContainer().getContainerToken();\n      taskAttempt.assignedCapability \u003d cEvent.getContainer().getResource();\n      // this is a _real_ Task (classic Hadoop mapred flavor):\n      taskAttempt.remoteTask \u003d taskAttempt.createRemoteTask();\n      taskAttempt.jvmID \u003d new WrappedJvmID(\n          taskAttempt.remoteTask.getTaskID().getJobID(), \n          taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());\n      \n      //launch the container\n      //create the container object to be launched for a given Task attempt\n      taskAttempt.eventHandler.handle(\n          new ContainerRemoteLaunchEvent(taskAttempt.attemptId, \n              taskAttempt.containerID, \n              taskAttempt.containerMgrAddress, taskAttempt.containerToken) {\n        @Override\n        public ContainerLaunchContext getContainer() {\n          return taskAttempt.createContainerLaunchContext();\n        }\n        @Override\n        public Task getRemoteTask() {  // classic mapred Task, not YARN version\n          return taskAttempt.remoteTask;\n        }\n      });\n\n      // send event to speculator that our container needs are satisfied\n      taskAttempt.eventHandler.handle\n          (new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));\n    }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java"
    }
  }
}