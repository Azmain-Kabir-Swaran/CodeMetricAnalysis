{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "TransferFsImage.java",
  "functionName": "getFileClient",
  "functionId": "getFileClient___infoServer-URL__queryString-String__localPaths-List__File____dstStorage-Storage__getChecksum-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
  "functionStartLine": 431,
  "functionEndLine": 437,
  "numCommitsSeen": 78,
  "timeTaken": 6417,
  "changeHistory": [
    "94a1632fcb677fda6f4d812614026417f1d0a360",
    "dbd22b23c2d68b97b4da47215897906f06f978e3",
    "0f595915a388305edbb3ce928415571811d304e8",
    "045dc880e13271737b3cf316296e92fb95806663",
    "4bca22005f48f426b9bc7cf36d435ead470a2590",
    "8dd3148e734fa9d1db761ce65410fdc49c0fe1d5",
    "8879653ab44efcca36e073a383b2e5bb56da88fd",
    "5dbbe0e0a5d31689d3425e490865f95057dc051c",
    "ce1a7ec9755f17527c29b0db713d7e01750e10c9",
    "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae",
    "8ae98a9d1ca4725e28783370517cb3a3ecda7324",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "ef223e8e8e1e18733fc18cd84e34dd0bb0f9a710",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "94a1632fcb677fda6f4d812614026417f1d0a360": "Ybodychange",
    "dbd22b23c2d68b97b4da47215897906f06f978e3": "Ybodychange",
    "0f595915a388305edbb3ce928415571811d304e8": "Ybodychange",
    "045dc880e13271737b3cf316296e92fb95806663": "Ymultichange(Yparameterchange,Ybodychange)",
    "4bca22005f48f426b9bc7cf36d435ead470a2590": "Ybodychange",
    "8dd3148e734fa9d1db761ce65410fdc49c0fe1d5": "Ymultichange(Yparameterchange,Ybodychange)",
    "8879653ab44efcca36e073a383b2e5bb56da88fd": "Ybodychange",
    "5dbbe0e0a5d31689d3425e490865f95057dc051c": "Ybodychange",
    "ce1a7ec9755f17527c29b0db713d7e01750e10c9": "Ybodychange",
    "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae": "Ybodychange",
    "8ae98a9d1ca4725e28783370517cb3a3ecda7324": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "ef223e8e8e1e18733fc18cd84e34dd0bb0f9a710": "Ybodychange",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": "Ymultichange(Yparameterchange,Ybodychange)",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "94a1632fcb677fda6f4d812614026417f1d0a360": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3405. Checkpointing should use HTTP POST or PUT instead of GET-GET to send merged fsimages. Contributed by Vinayakumar B.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1575611 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/03/14 1:25 PM",
      "commitName": "94a1632fcb677fda6f4d812614026417f1d0a360",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "08/03/14 1:15 PM",
      "commitNameOld": "dbd22b23c2d68b97b4da47215897906f06f978e3",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n   static MD5Hash getFileClient(URL infoServer,\n       String queryString, List\u003cFile\u003e localPaths,\n       Storage dstStorage, boolean getChecksum) throws IOException {\n-    URL url \u003d new URL(infoServer, \"/getimage?\" + queryString);\n+    URL url \u003d new URL(infoServer, ImageServlet.PATH_SPEC + \"?\" + queryString);\n     LOG.info(\"Opening connection to \" + url);\n     return doGetUrl(url, localPaths, dstStorage, getChecksum);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static MD5Hash getFileClient(URL infoServer,\n      String queryString, List\u003cFile\u003e localPaths,\n      Storage dstStorage, boolean getChecksum) throws IOException {\n    URL url \u003d new URL(infoServer, ImageServlet.PATH_SPEC + \"?\" + queryString);\n    LOG.info(\"Opening connection to \" + url);\n    return doGetUrl(url, localPaths, dstStorage, getChecksum);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
      "extendedDetails": {}
    },
    "dbd22b23c2d68b97b4da47215897906f06f978e3": {
      "type": "Ybodychange",
      "commitMessage": "Revert HDFS-3405 for recommit with correct renamed files\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1575610 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/03/14 1:15 PM",
      "commitName": "dbd22b23c2d68b97b4da47215897906f06f978e3",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "07/03/14 4:39 PM",
      "commitNameOld": "0f595915a388305edbb3ce928415571811d304e8",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 0.86,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n   static MD5Hash getFileClient(URL infoServer,\n       String queryString, List\u003cFile\u003e localPaths,\n       Storage dstStorage, boolean getChecksum) throws IOException {\n-    URL url \u003d new URL(infoServer, ImageServlet.PATH_SPEC + \"?\" + queryString);\n+    URL url \u003d new URL(infoServer, \"/getimage?\" + queryString);\n     LOG.info(\"Opening connection to \" + url);\n     return doGetUrl(url, localPaths, dstStorage, getChecksum);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static MD5Hash getFileClient(URL infoServer,\n      String queryString, List\u003cFile\u003e localPaths,\n      Storage dstStorage, boolean getChecksum) throws IOException {\n    URL url \u003d new URL(infoServer, \"/getimage?\" + queryString);\n    LOG.info(\"Opening connection to \" + url);\n    return doGetUrl(url, localPaths, dstStorage, getChecksum);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
      "extendedDetails": {}
    },
    "0f595915a388305edbb3ce928415571811d304e8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3405. Checkpointing should use HTTP POST or PUT instead of GET-GET to send merged fsimages. Contributed by Vinayakumar B.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1575457 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/03/14 4:39 PM",
      "commitName": "0f595915a388305edbb3ce928415571811d304e8",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "27/02/14 5:21 PM",
      "commitNameOld": "e9a17c8ce0656a4e5d47401ca22a575c5f5f66db",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 7.97,
      "commitsBetweenForRepo": 73,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n   static MD5Hash getFileClient(URL infoServer,\n       String queryString, List\u003cFile\u003e localPaths,\n       Storage dstStorage, boolean getChecksum) throws IOException {\n-    URL url \u003d new URL(infoServer, \"/getimage?\" + queryString);\n+    URL url \u003d new URL(infoServer, ImageServlet.PATH_SPEC + \"?\" + queryString);\n     LOG.info(\"Opening connection to \" + url);\n     return doGetUrl(url, localPaths, dstStorage, getChecksum);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static MD5Hash getFileClient(URL infoServer,\n      String queryString, List\u003cFile\u003e localPaths,\n      Storage dstStorage, boolean getChecksum) throws IOException {\n    URL url \u003d new URL(infoServer, ImageServlet.PATH_SPEC + \"?\" + queryString);\n    LOG.info(\"Opening connection to \" + url);\n    return doGetUrl(url, localPaths, dstStorage, getChecksum);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
      "extendedDetails": {}
    },
    "045dc880e13271737b3cf316296e92fb95806663": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5312. Generate HTTP/HTTPS URL in DFSUtil#getInfoServer() based on the configured http policy. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548629 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/12/13 10:01 AM",
      "commitName": "045dc880e13271737b3cf316296e92fb95806663",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5312. Generate HTTP/HTTPS URL in DFSUtil#getInfoServer() based on the configured http policy. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548629 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/13 10:01 AM",
          "commitName": "045dc880e13271737b3cf316296e92fb95806663",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "25/11/13 5:16 PM",
          "commitNameOld": "d8a23834614581a292aad214dddcbcc4bbe86d27",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 10.7,
          "commitsBetweenForRepo": 59,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,7 @@\n-  static MD5Hash getFileClient(String nnHostPort,\n+  static MD5Hash getFileClient(URL infoServer,\n       String queryString, List\u003cFile\u003e localPaths,\n       Storage dstStorage, boolean getChecksum) throws IOException {\n-\n-    String str \u003d HttpConfig.getSchemePrefix() + nnHostPort + \"/getimage?\" +\n-        queryString;\n-    LOG.info(\"Opening connection to \" + str);\n-    //\n-    // open connection to remote server\n-    //\n-    URL url \u003d new URL(str);\n+    URL url \u003d new URL(infoServer, \"/getimage?\" + queryString);\n+    LOG.info(\"Opening connection to \" + url);\n     return doGetUrl(url, localPaths, dstStorage, getChecksum);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static MD5Hash getFileClient(URL infoServer,\n      String queryString, List\u003cFile\u003e localPaths,\n      Storage dstStorage, boolean getChecksum) throws IOException {\n    URL url \u003d new URL(infoServer, \"/getimage?\" + queryString);\n    LOG.info(\"Opening connection to \" + url);\n    return doGetUrl(url, localPaths, dstStorage, getChecksum);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
          "extendedDetails": {
            "oldValue": "[nnHostPort-String, queryString-String, localPaths-List\u003cFile\u003e, dstStorage-Storage, getChecksum-boolean]",
            "newValue": "[infoServer-URL, queryString-String, localPaths-List\u003cFile\u003e, dstStorage-Storage, getChecksum-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5312. Generate HTTP/HTTPS URL in DFSUtil#getInfoServer() based on the configured http policy. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548629 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/13 10:01 AM",
          "commitName": "045dc880e13271737b3cf316296e92fb95806663",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "25/11/13 5:16 PM",
          "commitNameOld": "d8a23834614581a292aad214dddcbcc4bbe86d27",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 10.7,
          "commitsBetweenForRepo": 59,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,7 @@\n-  static MD5Hash getFileClient(String nnHostPort,\n+  static MD5Hash getFileClient(URL infoServer,\n       String queryString, List\u003cFile\u003e localPaths,\n       Storage dstStorage, boolean getChecksum) throws IOException {\n-\n-    String str \u003d HttpConfig.getSchemePrefix() + nnHostPort + \"/getimage?\" +\n-        queryString;\n-    LOG.info(\"Opening connection to \" + str);\n-    //\n-    // open connection to remote server\n-    //\n-    URL url \u003d new URL(str);\n+    URL url \u003d new URL(infoServer, \"/getimage?\" + queryString);\n+    LOG.info(\"Opening connection to \" + url);\n     return doGetUrl(url, localPaths, dstStorage, getChecksum);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static MD5Hash getFileClient(URL infoServer,\n      String queryString, List\u003cFile\u003e localPaths,\n      Storage dstStorage, boolean getChecksum) throws IOException {\n    URL url \u003d new URL(infoServer, \"/getimage?\" + queryString);\n    LOG.info(\"Opening connection to \" + url);\n    return doGetUrl(url, localPaths, dstStorage, getChecksum);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
          "extendedDetails": {}
        }
      ]
    },
    "4bca22005f48f426b9bc7cf36d435ead470a2590": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-8681. add support for HTTPS to the web UIs. (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1371525 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/08/12 3:52 PM",
      "commitName": "4bca22005f48f426b9bc7cf36d435ead470a2590",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "12/07/12 12:01 PM",
      "commitNameOld": "4a5ba3b7bd2360fd9605863630b477d362874e1e",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 28.16,
      "commitsBetweenForRepo": 151,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,13 @@\n   static MD5Hash getFileClient(String nnHostPort,\n       String queryString, List\u003cFile\u003e localPaths,\n       Storage dstStorage, boolean getChecksum) throws IOException {\n \n-    String str \u003d \"http://\" + nnHostPort + \"/getimage?\" + queryString;\n+    String str \u003d HttpConfig.getSchemePrefix() + nnHostPort + \"/getimage?\" +\n+        queryString;\n     LOG.info(\"Opening connection to \" + str);\n     //\n     // open connection to remote server\n     //\n     URL url \u003d new URL(str);\n     return doGetUrl(url, localPaths, dstStorage, getChecksum);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static MD5Hash getFileClient(String nnHostPort,\n      String queryString, List\u003cFile\u003e localPaths,\n      Storage dstStorage, boolean getChecksum) throws IOException {\n\n    String str \u003d HttpConfig.getSchemePrefix() + nnHostPort + \"/getimage?\" +\n        queryString;\n    LOG.info(\"Opening connection to \" + str);\n    //\n    // open connection to remote server\n    //\n    URL url \u003d new URL(str);\n    return doGetUrl(url, localPaths, dstStorage, getChecksum);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
      "extendedDetails": {}
    },
    "8dd3148e734fa9d1db761ce65410fdc49c0fe1d5": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-3190. Simple refactors in existing NN code to assist QuorumJournalManager extension. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1356525 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/07/12 4:59 PM",
      "commitName": "8dd3148e734fa9d1db761ce65410fdc49c0fe1d5",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-3190. Simple refactors in existing NN code to assist QuorumJournalManager extension. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1356525 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "02/07/12 4:59 PM",
          "commitName": "8dd3148e734fa9d1db761ce65410fdc49c0fe1d5",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "11/06/12 10:00 PM",
          "commitNameOld": "8879653ab44efcca36e073a383b2e5bb56da88fd",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 20.79,
          "commitsBetweenForRepo": 90,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,136 +1,12 @@\n   static MD5Hash getFileClient(String nnHostPort,\n       String queryString, List\u003cFile\u003e localPaths,\n-      NNStorage dstStorage, boolean getChecksum) throws IOException {\n-    byte[] buf \u003d new byte[HdfsConstants.IO_FILE_BUFFER_SIZE];\n+      Storage dstStorage, boolean getChecksum) throws IOException {\n \n     String str \u003d \"http://\" + nnHostPort + \"/getimage?\" + queryString;\n     LOG.info(\"Opening connection to \" + str);\n     //\n     // open connection to remote server\n     //\n-    long startTime \u003d Util.monotonicNow();\n     URL url \u003d new URL(str);\n-\n-    HttpURLConnection connection \u003d (HttpURLConnection)\n-      SecurityUtil.openSecureHttpConnection(url);\n-\n-    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n-      throw new HttpGetFailedException(\n-          \"Image transfer servlet at \" + url +\n-          \" failed with status code \" + connection.getResponseCode() +\n-          \"\\nResponse message:\\n\" + connection.getResponseMessage(),\n-          connection);\n-    }\n-    \n-    long advertisedSize;\n-    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n-    if (contentLength !\u003d null) {\n-      advertisedSize \u003d Long.parseLong(contentLength);\n-    } else {\n-      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n-                            \"by the namenode when trying to fetch \" + str);\n-    }\n-    \n-    if (localPaths !\u003d null) {\n-      String fsImageName \u003d connection.getHeaderField(\n-          GetImageServlet.HADOOP_IMAGE_EDITS_HEADER);\n-      // If the local paths refer to directories, use the server-provided header\n-      // as the filename within that directory\n-      List\u003cFile\u003e newLocalPaths \u003d new ArrayList\u003cFile\u003e();\n-      for (File localPath : localPaths) {\n-        if (localPath.isDirectory()) {\n-          if (fsImageName \u003d\u003d null) {\n-            throw new IOException(\"No filename header provided by server\");\n-          }\n-          newLocalPaths.add(new File(localPath, fsImageName));\n-        } else {\n-          newLocalPaths.add(localPath);\n-        }\n-      }\n-      localPaths \u003d newLocalPaths;\n-    }\n-    \n-    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n-\n-    long received \u003d 0;\n-    InputStream stream \u003d connection.getInputStream();\n-    MessageDigest digester \u003d null;\n-    if (getChecksum) {\n-      digester \u003d MD5Hash.getDigester();\n-      stream \u003d new DigestInputStream(stream, digester);\n-    }\n-    boolean finishedReceiving \u003d false;\n-\n-    List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n-\n-    try {\n-      if (localPaths !\u003d null) {\n-        for (File f : localPaths) {\n-          try {\n-            if (f.exists()) {\n-              LOG.warn(\"Overwriting existing file \" + f\n-                  + \" with file downloaded from \" + str);\n-            }\n-            outputStreams.add(new FileOutputStream(f));\n-          } catch (IOException ioe) {\n-            LOG.warn(\"Unable to download file \" + f, ioe);\n-            // This will be null if we\u0027re downloading the fsimage to a file\n-            // outside of an NNStorage directory.\n-            if (dstStorage !\u003d null) {\n-              dstStorage.reportErrorOnFile(f);\n-            }\n-          }\n-        }\n-        \n-        if (outputStreams.isEmpty()) {\n-          throw new IOException(\n-              \"Unable to download to any storage directory\");\n-        }\n-      }\n-      \n-      int num \u003d 1;\n-      while (num \u003e 0) {\n-        num \u003d stream.read(buf);\n-        if (num \u003e 0) {\n-          received +\u003d num;\n-          for (FileOutputStream fos : outputStreams) {\n-            fos.write(buf, 0, num);\n-          }\n-        }\n-      }\n-      finishedReceiving \u003d true;\n-    } finally {\n-      stream.close();\n-      for (FileOutputStream fos : outputStreams) {\n-        fos.getChannel().force(true);\n-        fos.close();\n-      }\n-      if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n-        // only throw this exception if we think we read all of it on our end\n-        // -- otherwise a client-side IOException would be masked by this\n-        // exception that makes it look like a server-side problem!\n-        throw new IOException(\"File \" + str + \" received length \" + received +\n-                              \" is not of the advertised size \" +\n-                              advertisedSize);\n-      }\n-    }\n-    double xferSec \u003d Math.max(\n-        ((float)(Util.monotonicNow() - startTime)) / 1000.0, 0.001);\n-    long xferKb \u003d received / 1024;\n-    LOG.info(String.format(\"Transfer took %.2fs at %.2f KB/s\",\n-        xferSec, xferKb / xferSec));\n-\n-    if (digester !\u003d null) {\n-      MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n-      \n-      if (advertisedDigest !\u003d null \u0026\u0026\n-          !computedDigest.equals(advertisedDigest)) {\n-        throw new IOException(\"File \" + str + \" computed digest \" +\n-            computedDigest + \" does not match advertised digest \" + \n-            advertisedDigest);\n-      }\n-      return computedDigest;\n-    } else {\n-      return null;\n-    }    \n+    return doGetUrl(url, localPaths, dstStorage, getChecksum);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static MD5Hash getFileClient(String nnHostPort,\n      String queryString, List\u003cFile\u003e localPaths,\n      Storage dstStorage, boolean getChecksum) throws IOException {\n\n    String str \u003d \"http://\" + nnHostPort + \"/getimage?\" + queryString;\n    LOG.info(\"Opening connection to \" + str);\n    //\n    // open connection to remote server\n    //\n    URL url \u003d new URL(str);\n    return doGetUrl(url, localPaths, dstStorage, getChecksum);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
          "extendedDetails": {
            "oldValue": "[nnHostPort-String, queryString-String, localPaths-List\u003cFile\u003e, dstStorage-NNStorage, getChecksum-boolean]",
            "newValue": "[nnHostPort-String, queryString-String, localPaths-List\u003cFile\u003e, dstStorage-Storage, getChecksum-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3190. Simple refactors in existing NN code to assist QuorumJournalManager extension. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1356525 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "02/07/12 4:59 PM",
          "commitName": "8dd3148e734fa9d1db761ce65410fdc49c0fe1d5",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "11/06/12 10:00 PM",
          "commitNameOld": "8879653ab44efcca36e073a383b2e5bb56da88fd",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 20.79,
          "commitsBetweenForRepo": 90,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,136 +1,12 @@\n   static MD5Hash getFileClient(String nnHostPort,\n       String queryString, List\u003cFile\u003e localPaths,\n-      NNStorage dstStorage, boolean getChecksum) throws IOException {\n-    byte[] buf \u003d new byte[HdfsConstants.IO_FILE_BUFFER_SIZE];\n+      Storage dstStorage, boolean getChecksum) throws IOException {\n \n     String str \u003d \"http://\" + nnHostPort + \"/getimage?\" + queryString;\n     LOG.info(\"Opening connection to \" + str);\n     //\n     // open connection to remote server\n     //\n-    long startTime \u003d Util.monotonicNow();\n     URL url \u003d new URL(str);\n-\n-    HttpURLConnection connection \u003d (HttpURLConnection)\n-      SecurityUtil.openSecureHttpConnection(url);\n-\n-    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n-      throw new HttpGetFailedException(\n-          \"Image transfer servlet at \" + url +\n-          \" failed with status code \" + connection.getResponseCode() +\n-          \"\\nResponse message:\\n\" + connection.getResponseMessage(),\n-          connection);\n-    }\n-    \n-    long advertisedSize;\n-    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n-    if (contentLength !\u003d null) {\n-      advertisedSize \u003d Long.parseLong(contentLength);\n-    } else {\n-      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n-                            \"by the namenode when trying to fetch \" + str);\n-    }\n-    \n-    if (localPaths !\u003d null) {\n-      String fsImageName \u003d connection.getHeaderField(\n-          GetImageServlet.HADOOP_IMAGE_EDITS_HEADER);\n-      // If the local paths refer to directories, use the server-provided header\n-      // as the filename within that directory\n-      List\u003cFile\u003e newLocalPaths \u003d new ArrayList\u003cFile\u003e();\n-      for (File localPath : localPaths) {\n-        if (localPath.isDirectory()) {\n-          if (fsImageName \u003d\u003d null) {\n-            throw new IOException(\"No filename header provided by server\");\n-          }\n-          newLocalPaths.add(new File(localPath, fsImageName));\n-        } else {\n-          newLocalPaths.add(localPath);\n-        }\n-      }\n-      localPaths \u003d newLocalPaths;\n-    }\n-    \n-    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n-\n-    long received \u003d 0;\n-    InputStream stream \u003d connection.getInputStream();\n-    MessageDigest digester \u003d null;\n-    if (getChecksum) {\n-      digester \u003d MD5Hash.getDigester();\n-      stream \u003d new DigestInputStream(stream, digester);\n-    }\n-    boolean finishedReceiving \u003d false;\n-\n-    List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n-\n-    try {\n-      if (localPaths !\u003d null) {\n-        for (File f : localPaths) {\n-          try {\n-            if (f.exists()) {\n-              LOG.warn(\"Overwriting existing file \" + f\n-                  + \" with file downloaded from \" + str);\n-            }\n-            outputStreams.add(new FileOutputStream(f));\n-          } catch (IOException ioe) {\n-            LOG.warn(\"Unable to download file \" + f, ioe);\n-            // This will be null if we\u0027re downloading the fsimage to a file\n-            // outside of an NNStorage directory.\n-            if (dstStorage !\u003d null) {\n-              dstStorage.reportErrorOnFile(f);\n-            }\n-          }\n-        }\n-        \n-        if (outputStreams.isEmpty()) {\n-          throw new IOException(\n-              \"Unable to download to any storage directory\");\n-        }\n-      }\n-      \n-      int num \u003d 1;\n-      while (num \u003e 0) {\n-        num \u003d stream.read(buf);\n-        if (num \u003e 0) {\n-          received +\u003d num;\n-          for (FileOutputStream fos : outputStreams) {\n-            fos.write(buf, 0, num);\n-          }\n-        }\n-      }\n-      finishedReceiving \u003d true;\n-    } finally {\n-      stream.close();\n-      for (FileOutputStream fos : outputStreams) {\n-        fos.getChannel().force(true);\n-        fos.close();\n-      }\n-      if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n-        // only throw this exception if we think we read all of it on our end\n-        // -- otherwise a client-side IOException would be masked by this\n-        // exception that makes it look like a server-side problem!\n-        throw new IOException(\"File \" + str + \" received length \" + received +\n-                              \" is not of the advertised size \" +\n-                              advertisedSize);\n-      }\n-    }\n-    double xferSec \u003d Math.max(\n-        ((float)(Util.monotonicNow() - startTime)) / 1000.0, 0.001);\n-    long xferKb \u003d received / 1024;\n-    LOG.info(String.format(\"Transfer took %.2fs at %.2f KB/s\",\n-        xferSec, xferKb / xferSec));\n-\n-    if (digester !\u003d null) {\n-      MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n-      \n-      if (advertisedDigest !\u003d null \u0026\u0026\n-          !computedDigest.equals(advertisedDigest)) {\n-        throw new IOException(\"File \" + str + \" computed digest \" +\n-            computedDigest + \" does not match advertised digest \" + \n-            advertisedDigest);\n-      }\n-      return computedDigest;\n-    } else {\n-      return null;\n-    }    \n+    return doGetUrl(url, localPaths, dstStorage, getChecksum);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static MD5Hash getFileClient(String nnHostPort,\n      String queryString, List\u003cFile\u003e localPaths,\n      Storage dstStorage, boolean getChecksum) throws IOException {\n\n    String str \u003d \"http://\" + nnHostPort + \"/getimage?\" + queryString;\n    LOG.info(\"Opening connection to \" + str);\n    //\n    // open connection to remote server\n    //\n    URL url \u003d new URL(str);\n    return doGetUrl(url, localPaths, dstStorage, getChecksum);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
          "extendedDetails": {}
        }
      ]
    },
    "8879653ab44efcca36e073a383b2e5bb56da88fd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3520. Add transfer rate logging to TransferFsImage. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1349117 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/06/12 10:00 PM",
      "commitName": "8879653ab44efcca36e073a383b2e5bb56da88fd",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "04/05/12 2:58 PM",
      "commitNameOld": "5dbbe0e0a5d31689d3425e490865f95057dc051c",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 38.29,
      "commitsBetweenForRepo": 194,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,130 +1,136 @@\n   static MD5Hash getFileClient(String nnHostPort,\n       String queryString, List\u003cFile\u003e localPaths,\n       NNStorage dstStorage, boolean getChecksum) throws IOException {\n     byte[] buf \u003d new byte[HdfsConstants.IO_FILE_BUFFER_SIZE];\n \n     String str \u003d \"http://\" + nnHostPort + \"/getimage?\" + queryString;\n     LOG.info(\"Opening connection to \" + str);\n     //\n     // open connection to remote server\n     //\n+    long startTime \u003d Util.monotonicNow();\n     URL url \u003d new URL(str);\n \n     HttpURLConnection connection \u003d (HttpURLConnection)\n       SecurityUtil.openSecureHttpConnection(url);\n \n     if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n       throw new HttpGetFailedException(\n           \"Image transfer servlet at \" + url +\n           \" failed with status code \" + connection.getResponseCode() +\n           \"\\nResponse message:\\n\" + connection.getResponseMessage(),\n           connection);\n     }\n     \n     long advertisedSize;\n     String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n     if (contentLength !\u003d null) {\n       advertisedSize \u003d Long.parseLong(contentLength);\n     } else {\n       throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                             \"by the namenode when trying to fetch \" + str);\n     }\n     \n     if (localPaths !\u003d null) {\n       String fsImageName \u003d connection.getHeaderField(\n           GetImageServlet.HADOOP_IMAGE_EDITS_HEADER);\n       // If the local paths refer to directories, use the server-provided header\n       // as the filename within that directory\n       List\u003cFile\u003e newLocalPaths \u003d new ArrayList\u003cFile\u003e();\n       for (File localPath : localPaths) {\n         if (localPath.isDirectory()) {\n           if (fsImageName \u003d\u003d null) {\n             throw new IOException(\"No filename header provided by server\");\n           }\n           newLocalPaths.add(new File(localPath, fsImageName));\n         } else {\n           newLocalPaths.add(localPath);\n         }\n       }\n       localPaths \u003d newLocalPaths;\n     }\n     \n     MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n \n     long received \u003d 0;\n     InputStream stream \u003d connection.getInputStream();\n     MessageDigest digester \u003d null;\n     if (getChecksum) {\n       digester \u003d MD5Hash.getDigester();\n       stream \u003d new DigestInputStream(stream, digester);\n     }\n     boolean finishedReceiving \u003d false;\n \n     List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n \n     try {\n       if (localPaths !\u003d null) {\n         for (File f : localPaths) {\n           try {\n             if (f.exists()) {\n               LOG.warn(\"Overwriting existing file \" + f\n                   + \" with file downloaded from \" + str);\n             }\n             outputStreams.add(new FileOutputStream(f));\n           } catch (IOException ioe) {\n             LOG.warn(\"Unable to download file \" + f, ioe);\n             // This will be null if we\u0027re downloading the fsimage to a file\n             // outside of an NNStorage directory.\n             if (dstStorage !\u003d null) {\n               dstStorage.reportErrorOnFile(f);\n             }\n           }\n         }\n         \n         if (outputStreams.isEmpty()) {\n           throw new IOException(\n               \"Unable to download to any storage directory\");\n         }\n       }\n       \n       int num \u003d 1;\n       while (num \u003e 0) {\n         num \u003d stream.read(buf);\n         if (num \u003e 0) {\n           received +\u003d num;\n           for (FileOutputStream fos : outputStreams) {\n             fos.write(buf, 0, num);\n           }\n         }\n       }\n       finishedReceiving \u003d true;\n     } finally {\n       stream.close();\n       for (FileOutputStream fos : outputStreams) {\n         fos.getChannel().force(true);\n         fos.close();\n       }\n       if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n         // only throw this exception if we think we read all of it on our end\n         // -- otherwise a client-side IOException would be masked by this\n         // exception that makes it look like a server-side problem!\n         throw new IOException(\"File \" + str + \" received length \" + received +\n                               \" is not of the advertised size \" +\n                               advertisedSize);\n       }\n     }\n+    double xferSec \u003d Math.max(\n+        ((float)(Util.monotonicNow() - startTime)) / 1000.0, 0.001);\n+    long xferKb \u003d received / 1024;\n+    LOG.info(String.format(\"Transfer took %.2fs at %.2f KB/s\",\n+        xferSec, xferKb / xferSec));\n \n     if (digester !\u003d null) {\n       MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n       \n       if (advertisedDigest !\u003d null \u0026\u0026\n           !computedDigest.equals(advertisedDigest)) {\n         throw new IOException(\"File \" + str + \" computed digest \" +\n             computedDigest + \" does not match advertised digest \" + \n             advertisedDigest);\n       }\n       return computedDigest;\n     } else {\n       return null;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  static MD5Hash getFileClient(String nnHostPort,\n      String queryString, List\u003cFile\u003e localPaths,\n      NNStorage dstStorage, boolean getChecksum) throws IOException {\n    byte[] buf \u003d new byte[HdfsConstants.IO_FILE_BUFFER_SIZE];\n\n    String str \u003d \"http://\" + nnHostPort + \"/getimage?\" + queryString;\n    LOG.info(\"Opening connection to \" + str);\n    //\n    // open connection to remote server\n    //\n    long startTime \u003d Util.monotonicNow();\n    URL url \u003d new URL(str);\n\n    HttpURLConnection connection \u003d (HttpURLConnection)\n      SecurityUtil.openSecureHttpConnection(url);\n\n    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n      throw new HttpGetFailedException(\n          \"Image transfer servlet at \" + url +\n          \" failed with status code \" + connection.getResponseCode() +\n          \"\\nResponse message:\\n\" + connection.getResponseMessage(),\n          connection);\n    }\n    \n    long advertisedSize;\n    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n    if (contentLength !\u003d null) {\n      advertisedSize \u003d Long.parseLong(contentLength);\n    } else {\n      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                            \"by the namenode when trying to fetch \" + str);\n    }\n    \n    if (localPaths !\u003d null) {\n      String fsImageName \u003d connection.getHeaderField(\n          GetImageServlet.HADOOP_IMAGE_EDITS_HEADER);\n      // If the local paths refer to directories, use the server-provided header\n      // as the filename within that directory\n      List\u003cFile\u003e newLocalPaths \u003d new ArrayList\u003cFile\u003e();\n      for (File localPath : localPaths) {\n        if (localPath.isDirectory()) {\n          if (fsImageName \u003d\u003d null) {\n            throw new IOException(\"No filename header provided by server\");\n          }\n          newLocalPaths.add(new File(localPath, fsImageName));\n        } else {\n          newLocalPaths.add(localPath);\n        }\n      }\n      localPaths \u003d newLocalPaths;\n    }\n    \n    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n\n    long received \u003d 0;\n    InputStream stream \u003d connection.getInputStream();\n    MessageDigest digester \u003d null;\n    if (getChecksum) {\n      digester \u003d MD5Hash.getDigester();\n      stream \u003d new DigestInputStream(stream, digester);\n    }\n    boolean finishedReceiving \u003d false;\n\n    List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n\n    try {\n      if (localPaths !\u003d null) {\n        for (File f : localPaths) {\n          try {\n            if (f.exists()) {\n              LOG.warn(\"Overwriting existing file \" + f\n                  + \" with file downloaded from \" + str);\n            }\n            outputStreams.add(new FileOutputStream(f));\n          } catch (IOException ioe) {\n            LOG.warn(\"Unable to download file \" + f, ioe);\n            // This will be null if we\u0027re downloading the fsimage to a file\n            // outside of an NNStorage directory.\n            if (dstStorage !\u003d null) {\n              dstStorage.reportErrorOnFile(f);\n            }\n          }\n        }\n        \n        if (outputStreams.isEmpty()) {\n          throw new IOException(\n              \"Unable to download to any storage directory\");\n        }\n      }\n      \n      int num \u003d 1;\n      while (num \u003e 0) {\n        num \u003d stream.read(buf);\n        if (num \u003e 0) {\n          received +\u003d num;\n          for (FileOutputStream fos : outputStreams) {\n            fos.write(buf, 0, num);\n          }\n        }\n      }\n      finishedReceiving \u003d true;\n    } finally {\n      stream.close();\n      for (FileOutputStream fos : outputStreams) {\n        fos.getChannel().force(true);\n        fos.close();\n      }\n      if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n        // only throw this exception if we think we read all of it on our end\n        // -- otherwise a client-side IOException would be masked by this\n        // exception that makes it look like a server-side problem!\n        throw new IOException(\"File \" + str + \" received length \" + received +\n                              \" is not of the advertised size \" +\n                              advertisedSize);\n      }\n    }\n    double xferSec \u003d Math.max(\n        ((float)(Util.monotonicNow() - startTime)) / 1000.0, 0.001);\n    long xferKb \u003d received / 1024;\n    LOG.info(String.format(\"Transfer took %.2fs at %.2f KB/s\",\n        xferSec, xferKb / xferSec));\n\n    if (digester !\u003d null) {\n      MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n      \n      if (advertisedDigest !\u003d null \u0026\u0026\n          !computedDigest.equals(advertisedDigest)) {\n        throw new IOException(\"File \" + str + \" computed digest \" +\n            computedDigest + \" does not match advertised digest \" + \n            advertisedDigest);\n      }\n      return computedDigest;\n    } else {\n      return null;\n    }    \n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
      "extendedDetails": {}
    },
    "5dbbe0e0a5d31689d3425e490865f95057dc051c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2617. Replaced Kerberized SSL for image transfer and fsck with SPNEGO-based solution. Contributed by Jakob Homan, Alejandro Abdelnur, and Aaron T. Myers\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1334216 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/05/12 2:58 PM",
      "commitName": "5dbbe0e0a5d31689d3425e490865f95057dc051c",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "02/05/12 6:44 PM",
      "commitNameOld": "cbc242429093ccabf76248f857de5e587a9682b0",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 1.84,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,132 +1,130 @@\n   static MD5Hash getFileClient(String nnHostPort,\n       String queryString, List\u003cFile\u003e localPaths,\n       NNStorage dstStorage, boolean getChecksum) throws IOException {\n     byte[] buf \u003d new byte[HdfsConstants.IO_FILE_BUFFER_SIZE];\n-    String proto \u003d UserGroupInformation.isSecurityEnabled() ? \"https://\" : \"http://\";\n-    StringBuilder str \u003d new StringBuilder(proto+nnHostPort+\"/getimage?\");\n-    str.append(queryString);\n \n+    String str \u003d \"http://\" + nnHostPort + \"/getimage?\" + queryString;\n+    LOG.info(\"Opening connection to \" + str);\n     //\n     // open connection to remote server\n     //\n-    URL url \u003d new URL(str.toString());\n-    \n-    // Avoid Krb bug with cross-realm hosts\n-    SecurityUtil.fetchServiceTicket(url);\n-    HttpURLConnection connection \u003d (HttpURLConnection) url.openConnection();\n-    \n+    URL url \u003d new URL(str);\n+\n+    HttpURLConnection connection \u003d (HttpURLConnection)\n+      SecurityUtil.openSecureHttpConnection(url);\n+\n     if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n       throw new HttpGetFailedException(\n           \"Image transfer servlet at \" + url +\n           \" failed with status code \" + connection.getResponseCode() +\n           \"\\nResponse message:\\n\" + connection.getResponseMessage(),\n           connection);\n     }\n     \n     long advertisedSize;\n     String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n     if (contentLength !\u003d null) {\n       advertisedSize \u003d Long.parseLong(contentLength);\n     } else {\n       throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                             \"by the namenode when trying to fetch \" + str);\n     }\n     \n     if (localPaths !\u003d null) {\n       String fsImageName \u003d connection.getHeaderField(\n           GetImageServlet.HADOOP_IMAGE_EDITS_HEADER);\n       // If the local paths refer to directories, use the server-provided header\n       // as the filename within that directory\n       List\u003cFile\u003e newLocalPaths \u003d new ArrayList\u003cFile\u003e();\n       for (File localPath : localPaths) {\n         if (localPath.isDirectory()) {\n           if (fsImageName \u003d\u003d null) {\n             throw new IOException(\"No filename header provided by server\");\n           }\n           newLocalPaths.add(new File(localPath, fsImageName));\n         } else {\n           newLocalPaths.add(localPath);\n         }\n       }\n       localPaths \u003d newLocalPaths;\n     }\n     \n     MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n \n     long received \u003d 0;\n     InputStream stream \u003d connection.getInputStream();\n     MessageDigest digester \u003d null;\n     if (getChecksum) {\n       digester \u003d MD5Hash.getDigester();\n       stream \u003d new DigestInputStream(stream, digester);\n     }\n     boolean finishedReceiving \u003d false;\n \n     List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n \n     try {\n       if (localPaths !\u003d null) {\n         for (File f : localPaths) {\n           try {\n             if (f.exists()) {\n               LOG.warn(\"Overwriting existing file \" + f\n                   + \" with file downloaded from \" + str);\n             }\n             outputStreams.add(new FileOutputStream(f));\n           } catch (IOException ioe) {\n             LOG.warn(\"Unable to download file \" + f, ioe);\n             // This will be null if we\u0027re downloading the fsimage to a file\n             // outside of an NNStorage directory.\n             if (dstStorage !\u003d null) {\n               dstStorage.reportErrorOnFile(f);\n             }\n           }\n         }\n         \n         if (outputStreams.isEmpty()) {\n           throw new IOException(\n               \"Unable to download to any storage directory\");\n         }\n       }\n       \n       int num \u003d 1;\n       while (num \u003e 0) {\n         num \u003d stream.read(buf);\n         if (num \u003e 0) {\n           received +\u003d num;\n           for (FileOutputStream fos : outputStreams) {\n             fos.write(buf, 0, num);\n           }\n         }\n       }\n       finishedReceiving \u003d true;\n     } finally {\n       stream.close();\n       for (FileOutputStream fos : outputStreams) {\n         fos.getChannel().force(true);\n         fos.close();\n       }\n       if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n         // only throw this exception if we think we read all of it on our end\n         // -- otherwise a client-side IOException would be masked by this\n         // exception that makes it look like a server-side problem!\n         throw new IOException(\"File \" + str + \" received length \" + received +\n                               \" is not of the advertised size \" +\n                               advertisedSize);\n       }\n     }\n \n     if (digester !\u003d null) {\n       MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n       \n       if (advertisedDigest !\u003d null \u0026\u0026\n           !computedDigest.equals(advertisedDigest)) {\n         throw new IOException(\"File \" + str + \" computed digest \" +\n             computedDigest + \" does not match advertised digest \" + \n             advertisedDigest);\n       }\n       return computedDigest;\n     } else {\n       return null;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  static MD5Hash getFileClient(String nnHostPort,\n      String queryString, List\u003cFile\u003e localPaths,\n      NNStorage dstStorage, boolean getChecksum) throws IOException {\n    byte[] buf \u003d new byte[HdfsConstants.IO_FILE_BUFFER_SIZE];\n\n    String str \u003d \"http://\" + nnHostPort + \"/getimage?\" + queryString;\n    LOG.info(\"Opening connection to \" + str);\n    //\n    // open connection to remote server\n    //\n    URL url \u003d new URL(str);\n\n    HttpURLConnection connection \u003d (HttpURLConnection)\n      SecurityUtil.openSecureHttpConnection(url);\n\n    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n      throw new HttpGetFailedException(\n          \"Image transfer servlet at \" + url +\n          \" failed with status code \" + connection.getResponseCode() +\n          \"\\nResponse message:\\n\" + connection.getResponseMessage(),\n          connection);\n    }\n    \n    long advertisedSize;\n    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n    if (contentLength !\u003d null) {\n      advertisedSize \u003d Long.parseLong(contentLength);\n    } else {\n      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                            \"by the namenode when trying to fetch \" + str);\n    }\n    \n    if (localPaths !\u003d null) {\n      String fsImageName \u003d connection.getHeaderField(\n          GetImageServlet.HADOOP_IMAGE_EDITS_HEADER);\n      // If the local paths refer to directories, use the server-provided header\n      // as the filename within that directory\n      List\u003cFile\u003e newLocalPaths \u003d new ArrayList\u003cFile\u003e();\n      for (File localPath : localPaths) {\n        if (localPath.isDirectory()) {\n          if (fsImageName \u003d\u003d null) {\n            throw new IOException(\"No filename header provided by server\");\n          }\n          newLocalPaths.add(new File(localPath, fsImageName));\n        } else {\n          newLocalPaths.add(localPath);\n        }\n      }\n      localPaths \u003d newLocalPaths;\n    }\n    \n    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n\n    long received \u003d 0;\n    InputStream stream \u003d connection.getInputStream();\n    MessageDigest digester \u003d null;\n    if (getChecksum) {\n      digester \u003d MD5Hash.getDigester();\n      stream \u003d new DigestInputStream(stream, digester);\n    }\n    boolean finishedReceiving \u003d false;\n\n    List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n\n    try {\n      if (localPaths !\u003d null) {\n        for (File f : localPaths) {\n          try {\n            if (f.exists()) {\n              LOG.warn(\"Overwriting existing file \" + f\n                  + \" with file downloaded from \" + str);\n            }\n            outputStreams.add(new FileOutputStream(f));\n          } catch (IOException ioe) {\n            LOG.warn(\"Unable to download file \" + f, ioe);\n            // This will be null if we\u0027re downloading the fsimage to a file\n            // outside of an NNStorage directory.\n            if (dstStorage !\u003d null) {\n              dstStorage.reportErrorOnFile(f);\n            }\n          }\n        }\n        \n        if (outputStreams.isEmpty()) {\n          throw new IOException(\n              \"Unable to download to any storage directory\");\n        }\n      }\n      \n      int num \u003d 1;\n      while (num \u003e 0) {\n        num \u003d stream.read(buf);\n        if (num \u003e 0) {\n          received +\u003d num;\n          for (FileOutputStream fos : outputStreams) {\n            fos.write(buf, 0, num);\n          }\n        }\n      }\n      finishedReceiving \u003d true;\n    } finally {\n      stream.close();\n      for (FileOutputStream fos : outputStreams) {\n        fos.getChannel().force(true);\n        fos.close();\n      }\n      if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n        // only throw this exception if we think we read all of it on our end\n        // -- otherwise a client-side IOException would be masked by this\n        // exception that makes it look like a server-side problem!\n        throw new IOException(\"File \" + str + \" received length \" + received +\n                              \" is not of the advertised size \" +\n                              advertisedSize);\n      }\n    }\n\n    if (digester !\u003d null) {\n      MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n      \n      if (advertisedDigest !\u003d null \u0026\u0026\n          !computedDigest.equals(advertisedDigest)) {\n        throw new IOException(\"File \" + str + \" computed digest \" +\n            computedDigest + \" does not match advertised digest \" + \n            advertisedDigest);\n      }\n      return computedDigest;\n    } else {\n      return null;\n    }    \n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
      "extendedDetails": {}
    },
    "ce1a7ec9755f17527c29b0db713d7e01750e10c9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2941. Add an administrative command to download a copy of the fsimage from the NN. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1305447 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/03/12 10:02 AM",
      "commitName": "ce1a7ec9755f17527c29b0db713d7e01750e10c9",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "12/03/12 12:41 PM",
      "commitNameOld": "1a75ec82885e45baf4d5cd56d6c738d8e68d8bc7",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 13.89,
      "commitsBetweenForRepo": 74,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,109 +1,132 @@\n   static MD5Hash getFileClient(String nnHostPort,\n       String queryString, List\u003cFile\u003e localPaths,\n       NNStorage dstStorage, boolean getChecksum) throws IOException {\n     byte[] buf \u003d new byte[HdfsConstants.IO_FILE_BUFFER_SIZE];\n     String proto \u003d UserGroupInformation.isSecurityEnabled() ? \"https://\" : \"http://\";\n     StringBuilder str \u003d new StringBuilder(proto+nnHostPort+\"/getimage?\");\n     str.append(queryString);\n \n     //\n     // open connection to remote server\n     //\n     URL url \u003d new URL(str.toString());\n     \n     // Avoid Krb bug with cross-realm hosts\n     SecurityUtil.fetchServiceTicket(url);\n     HttpURLConnection connection \u003d (HttpURLConnection) url.openConnection();\n     \n     if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n       throw new HttpGetFailedException(\n           \"Image transfer servlet at \" + url +\n           \" failed with status code \" + connection.getResponseCode() +\n           \"\\nResponse message:\\n\" + connection.getResponseMessage(),\n           connection);\n     }\n     \n     long advertisedSize;\n     String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n     if (contentLength !\u003d null) {\n       advertisedSize \u003d Long.parseLong(contentLength);\n     } else {\n       throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                             \"by the namenode when trying to fetch \" + str);\n     }\n     \n+    if (localPaths !\u003d null) {\n+      String fsImageName \u003d connection.getHeaderField(\n+          GetImageServlet.HADOOP_IMAGE_EDITS_HEADER);\n+      // If the local paths refer to directories, use the server-provided header\n+      // as the filename within that directory\n+      List\u003cFile\u003e newLocalPaths \u003d new ArrayList\u003cFile\u003e();\n+      for (File localPath : localPaths) {\n+        if (localPath.isDirectory()) {\n+          if (fsImageName \u003d\u003d null) {\n+            throw new IOException(\"No filename header provided by server\");\n+          }\n+          newLocalPaths.add(new File(localPath, fsImageName));\n+        } else {\n+          newLocalPaths.add(localPath);\n+        }\n+      }\n+      localPaths \u003d newLocalPaths;\n+    }\n+    \n     MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n \n     long received \u003d 0;\n     InputStream stream \u003d connection.getInputStream();\n     MessageDigest digester \u003d null;\n     if (getChecksum) {\n       digester \u003d MD5Hash.getDigester();\n       stream \u003d new DigestInputStream(stream, digester);\n     }\n     boolean finishedReceiving \u003d false;\n \n     List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n \n     try {\n       if (localPaths !\u003d null) {\n         for (File f : localPaths) {\n           try {\n             if (f.exists()) {\n               LOG.warn(\"Overwriting existing file \" + f\n                   + \" with file downloaded from \" + str);\n             }\n             outputStreams.add(new FileOutputStream(f));\n           } catch (IOException ioe) {\n             LOG.warn(\"Unable to download file \" + f, ioe);\n-            dstStorage.reportErrorOnFile(f);\n+            // This will be null if we\u0027re downloading the fsimage to a file\n+            // outside of an NNStorage directory.\n+            if (dstStorage !\u003d null) {\n+              dstStorage.reportErrorOnFile(f);\n+            }\n           }\n         }\n         \n         if (outputStreams.isEmpty()) {\n           throw new IOException(\n               \"Unable to download to any storage directory\");\n         }\n       }\n       \n       int num \u003d 1;\n       while (num \u003e 0) {\n         num \u003d stream.read(buf);\n         if (num \u003e 0) {\n           received +\u003d num;\n           for (FileOutputStream fos : outputStreams) {\n             fos.write(buf, 0, num);\n           }\n         }\n       }\n       finishedReceiving \u003d true;\n     } finally {\n       stream.close();\n       for (FileOutputStream fos : outputStreams) {\n         fos.getChannel().force(true);\n         fos.close();\n       }\n       if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n         // only throw this exception if we think we read all of it on our end\n         // -- otherwise a client-side IOException would be masked by this\n         // exception that makes it look like a server-side problem!\n         throw new IOException(\"File \" + str + \" received length \" + received +\n                               \" is not of the advertised size \" +\n                               advertisedSize);\n       }\n     }\n \n     if (digester !\u003d null) {\n       MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n       \n       if (advertisedDigest !\u003d null \u0026\u0026\n           !computedDigest.equals(advertisedDigest)) {\n         throw new IOException(\"File \" + str + \" computed digest \" +\n             computedDigest + \" does not match advertised digest \" + \n             advertisedDigest);\n       }\n       return computedDigest;\n     } else {\n       return null;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  static MD5Hash getFileClient(String nnHostPort,\n      String queryString, List\u003cFile\u003e localPaths,\n      NNStorage dstStorage, boolean getChecksum) throws IOException {\n    byte[] buf \u003d new byte[HdfsConstants.IO_FILE_BUFFER_SIZE];\n    String proto \u003d UserGroupInformation.isSecurityEnabled() ? \"https://\" : \"http://\";\n    StringBuilder str \u003d new StringBuilder(proto+nnHostPort+\"/getimage?\");\n    str.append(queryString);\n\n    //\n    // open connection to remote server\n    //\n    URL url \u003d new URL(str.toString());\n    \n    // Avoid Krb bug with cross-realm hosts\n    SecurityUtil.fetchServiceTicket(url);\n    HttpURLConnection connection \u003d (HttpURLConnection) url.openConnection();\n    \n    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n      throw new HttpGetFailedException(\n          \"Image transfer servlet at \" + url +\n          \" failed with status code \" + connection.getResponseCode() +\n          \"\\nResponse message:\\n\" + connection.getResponseMessage(),\n          connection);\n    }\n    \n    long advertisedSize;\n    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n    if (contentLength !\u003d null) {\n      advertisedSize \u003d Long.parseLong(contentLength);\n    } else {\n      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                            \"by the namenode when trying to fetch \" + str);\n    }\n    \n    if (localPaths !\u003d null) {\n      String fsImageName \u003d connection.getHeaderField(\n          GetImageServlet.HADOOP_IMAGE_EDITS_HEADER);\n      // If the local paths refer to directories, use the server-provided header\n      // as the filename within that directory\n      List\u003cFile\u003e newLocalPaths \u003d new ArrayList\u003cFile\u003e();\n      for (File localPath : localPaths) {\n        if (localPath.isDirectory()) {\n          if (fsImageName \u003d\u003d null) {\n            throw new IOException(\"No filename header provided by server\");\n          }\n          newLocalPaths.add(new File(localPath, fsImageName));\n        } else {\n          newLocalPaths.add(localPath);\n        }\n      }\n      localPaths \u003d newLocalPaths;\n    }\n    \n    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n\n    long received \u003d 0;\n    InputStream stream \u003d connection.getInputStream();\n    MessageDigest digester \u003d null;\n    if (getChecksum) {\n      digester \u003d MD5Hash.getDigester();\n      stream \u003d new DigestInputStream(stream, digester);\n    }\n    boolean finishedReceiving \u003d false;\n\n    List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n\n    try {\n      if (localPaths !\u003d null) {\n        for (File f : localPaths) {\n          try {\n            if (f.exists()) {\n              LOG.warn(\"Overwriting existing file \" + f\n                  + \" with file downloaded from \" + str);\n            }\n            outputStreams.add(new FileOutputStream(f));\n          } catch (IOException ioe) {\n            LOG.warn(\"Unable to download file \" + f, ioe);\n            // This will be null if we\u0027re downloading the fsimage to a file\n            // outside of an NNStorage directory.\n            if (dstStorage !\u003d null) {\n              dstStorage.reportErrorOnFile(f);\n            }\n          }\n        }\n        \n        if (outputStreams.isEmpty()) {\n          throw new IOException(\n              \"Unable to download to any storage directory\");\n        }\n      }\n      \n      int num \u003d 1;\n      while (num \u003e 0) {\n        num \u003d stream.read(buf);\n        if (num \u003e 0) {\n          received +\u003d num;\n          for (FileOutputStream fos : outputStreams) {\n            fos.write(buf, 0, num);\n          }\n        }\n      }\n      finishedReceiving \u003d true;\n    } finally {\n      stream.close();\n      for (FileOutputStream fos : outputStreams) {\n        fos.getChannel().force(true);\n        fos.close();\n      }\n      if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n        // only throw this exception if we think we read all of it on our end\n        // -- otherwise a client-side IOException would be masked by this\n        // exception that makes it look like a server-side problem!\n        throw new IOException(\"File \" + str + \" received length \" + received +\n                              \" is not of the advertised size \" +\n                              advertisedSize);\n      }\n    }\n\n    if (digester !\u003d null) {\n      MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n      \n      if (advertisedDigest !\u003d null \u0026\u0026\n          !computedDigest.equals(advertisedDigest)) {\n        throw new IOException(\"File \" + str + \" computed digest \" +\n            computedDigest + \" does not match advertised digest \" + \n            advertisedDigest);\n      }\n      return computedDigest;\n    } else {\n      return null;\n    }    \n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
      "extendedDetails": {}
    },
    "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2291. Allow the StandbyNode to make checkpoints in an HA setup. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1227411 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/01/12 4:22 PM",
      "commitName": "5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "04/09/11 12:30 PM",
      "commitNameOld": "8ae98a9d1ca4725e28783370517cb3a3ecda7324",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 122.2,
      "commitsBetweenForRepo": 844,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,108 +1,109 @@\n   static MD5Hash getFileClient(String nnHostPort,\n       String queryString, List\u003cFile\u003e localPaths,\n       NNStorage dstStorage, boolean getChecksum) throws IOException {\n     byte[] buf \u003d new byte[HdfsConstants.IO_FILE_BUFFER_SIZE];\n     String proto \u003d UserGroupInformation.isSecurityEnabled() ? \"https://\" : \"http://\";\n     StringBuilder str \u003d new StringBuilder(proto+nnHostPort+\"/getimage?\");\n     str.append(queryString);\n \n     //\n     // open connection to remote server\n     //\n     URL url \u003d new URL(str.toString());\n     \n     // Avoid Krb bug with cross-realm hosts\n     SecurityUtil.fetchServiceTicket(url);\n     HttpURLConnection connection \u003d (HttpURLConnection) url.openConnection();\n     \n     if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n-      throw new IOException(\n+      throw new HttpGetFailedException(\n           \"Image transfer servlet at \" + url +\n           \" failed with status code \" + connection.getResponseCode() +\n-          \"\\nResponse message:\\n\" + connection.getResponseMessage());\n+          \"\\nResponse message:\\n\" + connection.getResponseMessage(),\n+          connection);\n     }\n     \n     long advertisedSize;\n     String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n     if (contentLength !\u003d null) {\n       advertisedSize \u003d Long.parseLong(contentLength);\n     } else {\n       throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                             \"by the namenode when trying to fetch \" + str);\n     }\n     \n     MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n \n     long received \u003d 0;\n     InputStream stream \u003d connection.getInputStream();\n     MessageDigest digester \u003d null;\n     if (getChecksum) {\n       digester \u003d MD5Hash.getDigester();\n       stream \u003d new DigestInputStream(stream, digester);\n     }\n     boolean finishedReceiving \u003d false;\n \n     List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n \n     try {\n       if (localPaths !\u003d null) {\n         for (File f : localPaths) {\n           try {\n             if (f.exists()) {\n               LOG.warn(\"Overwriting existing file \" + f\n                   + \" with file downloaded from \" + str);\n             }\n             outputStreams.add(new FileOutputStream(f));\n           } catch (IOException ioe) {\n             LOG.warn(\"Unable to download file \" + f, ioe);\n             dstStorage.reportErrorOnFile(f);\n           }\n         }\n         \n         if (outputStreams.isEmpty()) {\n           throw new IOException(\n               \"Unable to download to any storage directory\");\n         }\n       }\n       \n       int num \u003d 1;\n       while (num \u003e 0) {\n         num \u003d stream.read(buf);\n         if (num \u003e 0) {\n           received +\u003d num;\n           for (FileOutputStream fos : outputStreams) {\n             fos.write(buf, 0, num);\n           }\n         }\n       }\n       finishedReceiving \u003d true;\n     } finally {\n       stream.close();\n       for (FileOutputStream fos : outputStreams) {\n         fos.getChannel().force(true);\n         fos.close();\n       }\n       if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n         // only throw this exception if we think we read all of it on our end\n         // -- otherwise a client-side IOException would be masked by this\n         // exception that makes it look like a server-side problem!\n         throw new IOException(\"File \" + str + \" received length \" + received +\n                               \" is not of the advertised size \" +\n                               advertisedSize);\n       }\n     }\n \n     if (digester !\u003d null) {\n       MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n       \n       if (advertisedDigest !\u003d null \u0026\u0026\n           !computedDigest.equals(advertisedDigest)) {\n         throw new IOException(\"File \" + str + \" computed digest \" +\n             computedDigest + \" does not match advertised digest \" + \n             advertisedDigest);\n       }\n       return computedDigest;\n     } else {\n       return null;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  static MD5Hash getFileClient(String nnHostPort,\n      String queryString, List\u003cFile\u003e localPaths,\n      NNStorage dstStorage, boolean getChecksum) throws IOException {\n    byte[] buf \u003d new byte[HdfsConstants.IO_FILE_BUFFER_SIZE];\n    String proto \u003d UserGroupInformation.isSecurityEnabled() ? \"https://\" : \"http://\";\n    StringBuilder str \u003d new StringBuilder(proto+nnHostPort+\"/getimage?\");\n    str.append(queryString);\n\n    //\n    // open connection to remote server\n    //\n    URL url \u003d new URL(str.toString());\n    \n    // Avoid Krb bug with cross-realm hosts\n    SecurityUtil.fetchServiceTicket(url);\n    HttpURLConnection connection \u003d (HttpURLConnection) url.openConnection();\n    \n    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n      throw new HttpGetFailedException(\n          \"Image transfer servlet at \" + url +\n          \" failed with status code \" + connection.getResponseCode() +\n          \"\\nResponse message:\\n\" + connection.getResponseMessage(),\n          connection);\n    }\n    \n    long advertisedSize;\n    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n    if (contentLength !\u003d null) {\n      advertisedSize \u003d Long.parseLong(contentLength);\n    } else {\n      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                            \"by the namenode when trying to fetch \" + str);\n    }\n    \n    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n\n    long received \u003d 0;\n    InputStream stream \u003d connection.getInputStream();\n    MessageDigest digester \u003d null;\n    if (getChecksum) {\n      digester \u003d MD5Hash.getDigester();\n      stream \u003d new DigestInputStream(stream, digester);\n    }\n    boolean finishedReceiving \u003d false;\n\n    List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n\n    try {\n      if (localPaths !\u003d null) {\n        for (File f : localPaths) {\n          try {\n            if (f.exists()) {\n              LOG.warn(\"Overwriting existing file \" + f\n                  + \" with file downloaded from \" + str);\n            }\n            outputStreams.add(new FileOutputStream(f));\n          } catch (IOException ioe) {\n            LOG.warn(\"Unable to download file \" + f, ioe);\n            dstStorage.reportErrorOnFile(f);\n          }\n        }\n        \n        if (outputStreams.isEmpty()) {\n          throw new IOException(\n              \"Unable to download to any storage directory\");\n        }\n      }\n      \n      int num \u003d 1;\n      while (num \u003e 0) {\n        num \u003d stream.read(buf);\n        if (num \u003e 0) {\n          received +\u003d num;\n          for (FileOutputStream fos : outputStreams) {\n            fos.write(buf, 0, num);\n          }\n        }\n      }\n      finishedReceiving \u003d true;\n    } finally {\n      stream.close();\n      for (FileOutputStream fos : outputStreams) {\n        fos.getChannel().force(true);\n        fos.close();\n      }\n      if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n        // only throw this exception if we think we read all of it on our end\n        // -- otherwise a client-side IOException would be masked by this\n        // exception that makes it look like a server-side problem!\n        throw new IOException(\"File \" + str + \" received length \" + received +\n                              \" is not of the advertised size \" +\n                              advertisedSize);\n      }\n    }\n\n    if (digester !\u003d null) {\n      MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n      \n      if (advertisedDigest !\u003d null \u0026\u0026\n          !computedDigest.equals(advertisedDigest)) {\n        throw new IOException(\"File \" + str + \" computed digest \" +\n            computedDigest + \" does not match advertised digest \" + \n            advertisedDigest);\n      }\n      return computedDigest;\n    } else {\n      return null;\n    }    \n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
      "extendedDetails": {}
    },
    "8ae98a9d1ca4725e28783370517cb3a3ecda7324": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1620. Rename HdfsConstants -\u003e HdfsServerConstants, FSConstants -\u003e HdfsConstants. (Harsh J Chouraria via atm)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1165096 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/09/11 12:30 PM",
      "commitName": "8ae98a9d1ca4725e28783370517cb3a3ecda7324",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 10.8,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,108 +1,108 @@\n   static MD5Hash getFileClient(String nnHostPort,\n       String queryString, List\u003cFile\u003e localPaths,\n       NNStorage dstStorage, boolean getChecksum) throws IOException {\n-    byte[] buf \u003d new byte[FSConstants.IO_FILE_BUFFER_SIZE];\n+    byte[] buf \u003d new byte[HdfsConstants.IO_FILE_BUFFER_SIZE];\n     String proto \u003d UserGroupInformation.isSecurityEnabled() ? \"https://\" : \"http://\";\n     StringBuilder str \u003d new StringBuilder(proto+nnHostPort+\"/getimage?\");\n     str.append(queryString);\n \n     //\n     // open connection to remote server\n     //\n     URL url \u003d new URL(str.toString());\n     \n     // Avoid Krb bug with cross-realm hosts\n     SecurityUtil.fetchServiceTicket(url);\n     HttpURLConnection connection \u003d (HttpURLConnection) url.openConnection();\n     \n     if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n       throw new IOException(\n           \"Image transfer servlet at \" + url +\n           \" failed with status code \" + connection.getResponseCode() +\n           \"\\nResponse message:\\n\" + connection.getResponseMessage());\n     }\n     \n     long advertisedSize;\n     String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n     if (contentLength !\u003d null) {\n       advertisedSize \u003d Long.parseLong(contentLength);\n     } else {\n       throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                             \"by the namenode when trying to fetch \" + str);\n     }\n     \n     MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n \n     long received \u003d 0;\n     InputStream stream \u003d connection.getInputStream();\n     MessageDigest digester \u003d null;\n     if (getChecksum) {\n       digester \u003d MD5Hash.getDigester();\n       stream \u003d new DigestInputStream(stream, digester);\n     }\n     boolean finishedReceiving \u003d false;\n \n     List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n \n     try {\n       if (localPaths !\u003d null) {\n         for (File f : localPaths) {\n           try {\n             if (f.exists()) {\n               LOG.warn(\"Overwriting existing file \" + f\n                   + \" with file downloaded from \" + str);\n             }\n             outputStreams.add(new FileOutputStream(f));\n           } catch (IOException ioe) {\n             LOG.warn(\"Unable to download file \" + f, ioe);\n             dstStorage.reportErrorOnFile(f);\n           }\n         }\n         \n         if (outputStreams.isEmpty()) {\n           throw new IOException(\n               \"Unable to download to any storage directory\");\n         }\n       }\n       \n       int num \u003d 1;\n       while (num \u003e 0) {\n         num \u003d stream.read(buf);\n         if (num \u003e 0) {\n           received +\u003d num;\n           for (FileOutputStream fos : outputStreams) {\n             fos.write(buf, 0, num);\n           }\n         }\n       }\n       finishedReceiving \u003d true;\n     } finally {\n       stream.close();\n       for (FileOutputStream fos : outputStreams) {\n         fos.getChannel().force(true);\n         fos.close();\n       }\n       if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n         // only throw this exception if we think we read all of it on our end\n         // -- otherwise a client-side IOException would be masked by this\n         // exception that makes it look like a server-side problem!\n         throw new IOException(\"File \" + str + \" received length \" + received +\n                               \" is not of the advertised size \" +\n                               advertisedSize);\n       }\n     }\n \n     if (digester !\u003d null) {\n       MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n       \n       if (advertisedDigest !\u003d null \u0026\u0026\n           !computedDigest.equals(advertisedDigest)) {\n         throw new IOException(\"File \" + str + \" computed digest \" +\n             computedDigest + \" does not match advertised digest \" + \n             advertisedDigest);\n       }\n       return computedDigest;\n     } else {\n       return null;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  static MD5Hash getFileClient(String nnHostPort,\n      String queryString, List\u003cFile\u003e localPaths,\n      NNStorage dstStorage, boolean getChecksum) throws IOException {\n    byte[] buf \u003d new byte[HdfsConstants.IO_FILE_BUFFER_SIZE];\n    String proto \u003d UserGroupInformation.isSecurityEnabled() ? \"https://\" : \"http://\";\n    StringBuilder str \u003d new StringBuilder(proto+nnHostPort+\"/getimage?\");\n    str.append(queryString);\n\n    //\n    // open connection to remote server\n    //\n    URL url \u003d new URL(str.toString());\n    \n    // Avoid Krb bug with cross-realm hosts\n    SecurityUtil.fetchServiceTicket(url);\n    HttpURLConnection connection \u003d (HttpURLConnection) url.openConnection();\n    \n    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n      throw new IOException(\n          \"Image transfer servlet at \" + url +\n          \" failed with status code \" + connection.getResponseCode() +\n          \"\\nResponse message:\\n\" + connection.getResponseMessage());\n    }\n    \n    long advertisedSize;\n    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n    if (contentLength !\u003d null) {\n      advertisedSize \u003d Long.parseLong(contentLength);\n    } else {\n      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                            \"by the namenode when trying to fetch \" + str);\n    }\n    \n    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n\n    long received \u003d 0;\n    InputStream stream \u003d connection.getInputStream();\n    MessageDigest digester \u003d null;\n    if (getChecksum) {\n      digester \u003d MD5Hash.getDigester();\n      stream \u003d new DigestInputStream(stream, digester);\n    }\n    boolean finishedReceiving \u003d false;\n\n    List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n\n    try {\n      if (localPaths !\u003d null) {\n        for (File f : localPaths) {\n          try {\n            if (f.exists()) {\n              LOG.warn(\"Overwriting existing file \" + f\n                  + \" with file downloaded from \" + str);\n            }\n            outputStreams.add(new FileOutputStream(f));\n          } catch (IOException ioe) {\n            LOG.warn(\"Unable to download file \" + f, ioe);\n            dstStorage.reportErrorOnFile(f);\n          }\n        }\n        \n        if (outputStreams.isEmpty()) {\n          throw new IOException(\n              \"Unable to download to any storage directory\");\n        }\n      }\n      \n      int num \u003d 1;\n      while (num \u003e 0) {\n        num \u003d stream.read(buf);\n        if (num \u003e 0) {\n          received +\u003d num;\n          for (FileOutputStream fos : outputStreams) {\n            fos.write(buf, 0, num);\n          }\n        }\n      }\n      finishedReceiving \u003d true;\n    } finally {\n      stream.close();\n      for (FileOutputStream fos : outputStreams) {\n        fos.getChannel().force(true);\n        fos.close();\n      }\n      if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n        // only throw this exception if we think we read all of it on our end\n        // -- otherwise a client-side IOException would be masked by this\n        // exception that makes it look like a server-side problem!\n        throw new IOException(\"File \" + str + \" received length \" + received +\n                              \" is not of the advertised size \" +\n                              advertisedSize);\n      }\n    }\n\n    if (digester !\u003d null) {\n      MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n      \n      if (advertisedDigest !\u003d null \u0026\u0026\n          !computedDigest.equals(advertisedDigest)) {\n        throw new IOException(\"File \" + str + \" computed digest \" +\n            computedDigest + \" does not match advertised digest \" + \n            advertisedDigest);\n      }\n      return computedDigest;\n    } else {\n      return null;\n    }    \n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  static MD5Hash getFileClient(String nnHostPort,\n      String queryString, List\u003cFile\u003e localPaths,\n      NNStorage dstStorage, boolean getChecksum) throws IOException {\n    byte[] buf \u003d new byte[FSConstants.IO_FILE_BUFFER_SIZE];\n    String proto \u003d UserGroupInformation.isSecurityEnabled() ? \"https://\" : \"http://\";\n    StringBuilder str \u003d new StringBuilder(proto+nnHostPort+\"/getimage?\");\n    str.append(queryString);\n\n    //\n    // open connection to remote server\n    //\n    URL url \u003d new URL(str.toString());\n    \n    // Avoid Krb bug with cross-realm hosts\n    SecurityUtil.fetchServiceTicket(url);\n    HttpURLConnection connection \u003d (HttpURLConnection) url.openConnection();\n    \n    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n      throw new IOException(\n          \"Image transfer servlet at \" + url +\n          \" failed with status code \" + connection.getResponseCode() +\n          \"\\nResponse message:\\n\" + connection.getResponseMessage());\n    }\n    \n    long advertisedSize;\n    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n    if (contentLength !\u003d null) {\n      advertisedSize \u003d Long.parseLong(contentLength);\n    } else {\n      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                            \"by the namenode when trying to fetch \" + str);\n    }\n    \n    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n\n    long received \u003d 0;\n    InputStream stream \u003d connection.getInputStream();\n    MessageDigest digester \u003d null;\n    if (getChecksum) {\n      digester \u003d MD5Hash.getDigester();\n      stream \u003d new DigestInputStream(stream, digester);\n    }\n    boolean finishedReceiving \u003d false;\n\n    List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n\n    try {\n      if (localPaths !\u003d null) {\n        for (File f : localPaths) {\n          try {\n            if (f.exists()) {\n              LOG.warn(\"Overwriting existing file \" + f\n                  + \" with file downloaded from \" + str);\n            }\n            outputStreams.add(new FileOutputStream(f));\n          } catch (IOException ioe) {\n            LOG.warn(\"Unable to download file \" + f, ioe);\n            dstStorage.reportErrorOnFile(f);\n          }\n        }\n        \n        if (outputStreams.isEmpty()) {\n          throw new IOException(\n              \"Unable to download to any storage directory\");\n        }\n      }\n      \n      int num \u003d 1;\n      while (num \u003e 0) {\n        num \u003d stream.read(buf);\n        if (num \u003e 0) {\n          received +\u003d num;\n          for (FileOutputStream fos : outputStreams) {\n            fos.write(buf, 0, num);\n          }\n        }\n      }\n      finishedReceiving \u003d true;\n    } finally {\n      stream.close();\n      for (FileOutputStream fos : outputStreams) {\n        fos.getChannel().force(true);\n        fos.close();\n      }\n      if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n        // only throw this exception if we think we read all of it on our end\n        // -- otherwise a client-side IOException would be masked by this\n        // exception that makes it look like a server-side problem!\n        throw new IOException(\"File \" + str + \" received length \" + received +\n                              \" is not of the advertised size \" +\n                              advertisedSize);\n      }\n    }\n\n    if (digester !\u003d null) {\n      MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n      \n      if (advertisedDigest !\u003d null \u0026\u0026\n          !computedDigest.equals(advertisedDigest)) {\n        throw new IOException(\"File \" + str + \" computed digest \" +\n            computedDigest + \" does not match advertised digest \" + \n            advertisedDigest);\n      }\n      return computedDigest;\n    } else {\n      return null;\n    }    \n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  static MD5Hash getFileClient(String nnHostPort,\n      String queryString, List\u003cFile\u003e localPaths,\n      NNStorage dstStorage, boolean getChecksum) throws IOException {\n    byte[] buf \u003d new byte[FSConstants.IO_FILE_BUFFER_SIZE];\n    String proto \u003d UserGroupInformation.isSecurityEnabled() ? \"https://\" : \"http://\";\n    StringBuilder str \u003d new StringBuilder(proto+nnHostPort+\"/getimage?\");\n    str.append(queryString);\n\n    //\n    // open connection to remote server\n    //\n    URL url \u003d new URL(str.toString());\n    \n    // Avoid Krb bug with cross-realm hosts\n    SecurityUtil.fetchServiceTicket(url);\n    HttpURLConnection connection \u003d (HttpURLConnection) url.openConnection();\n    \n    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n      throw new IOException(\n          \"Image transfer servlet at \" + url +\n          \" failed with status code \" + connection.getResponseCode() +\n          \"\\nResponse message:\\n\" + connection.getResponseMessage());\n    }\n    \n    long advertisedSize;\n    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n    if (contentLength !\u003d null) {\n      advertisedSize \u003d Long.parseLong(contentLength);\n    } else {\n      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                            \"by the namenode when trying to fetch \" + str);\n    }\n    \n    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n\n    long received \u003d 0;\n    InputStream stream \u003d connection.getInputStream();\n    MessageDigest digester \u003d null;\n    if (getChecksum) {\n      digester \u003d MD5Hash.getDigester();\n      stream \u003d new DigestInputStream(stream, digester);\n    }\n    boolean finishedReceiving \u003d false;\n\n    List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n\n    try {\n      if (localPaths !\u003d null) {\n        for (File f : localPaths) {\n          try {\n            if (f.exists()) {\n              LOG.warn(\"Overwriting existing file \" + f\n                  + \" with file downloaded from \" + str);\n            }\n            outputStreams.add(new FileOutputStream(f));\n          } catch (IOException ioe) {\n            LOG.warn(\"Unable to download file \" + f, ioe);\n            dstStorage.reportErrorOnFile(f);\n          }\n        }\n        \n        if (outputStreams.isEmpty()) {\n          throw new IOException(\n              \"Unable to download to any storage directory\");\n        }\n      }\n      \n      int num \u003d 1;\n      while (num \u003e 0) {\n        num \u003d stream.read(buf);\n        if (num \u003e 0) {\n          received +\u003d num;\n          for (FileOutputStream fos : outputStreams) {\n            fos.write(buf, 0, num);\n          }\n        }\n      }\n      finishedReceiving \u003d true;\n    } finally {\n      stream.close();\n      for (FileOutputStream fos : outputStreams) {\n        fos.getChannel().force(true);\n        fos.close();\n      }\n      if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n        // only throw this exception if we think we read all of it on our end\n        // -- otherwise a client-side IOException would be masked by this\n        // exception that makes it look like a server-side problem!\n        throw new IOException(\"File \" + str + \" received length \" + received +\n                              \" is not of the advertised size \" +\n                              advertisedSize);\n      }\n    }\n\n    if (digester !\u003d null) {\n      MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n      \n      if (advertisedDigest !\u003d null \u0026\u0026\n          !computedDigest.equals(advertisedDigest)) {\n        throw new IOException(\"File \" + str + \" computed digest \" +\n            computedDigest + \" does not match advertised digest \" + \n            advertisedDigest);\n      }\n      return computedDigest;\n    } else {\n      return null;\n    }    \n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java"
      }
    },
    "ef223e8e8e1e18733fc18cd84e34dd0bb0f9a710": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2241. Remove implementing FSConstants interface to just get the constants from the interface. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1156420 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/08/11 5:46 PM",
      "commitName": "ef223e8e8e1e18733fc18cd84e34dd0bb0f9a710",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "09/08/11 5:01 PM",
      "commitNameOld": "eb6e44b1ba58ed971360a39ea5d5ce02ae65aa0f",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 1.03,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,108 +1,108 @@\n   static MD5Hash getFileClient(String nnHostPort,\n       String queryString, List\u003cFile\u003e localPaths,\n       NNStorage dstStorage, boolean getChecksum) throws IOException {\n-    byte[] buf \u003d new byte[BUFFER_SIZE];\n+    byte[] buf \u003d new byte[FSConstants.IO_FILE_BUFFER_SIZE];\n     String proto \u003d UserGroupInformation.isSecurityEnabled() ? \"https://\" : \"http://\";\n     StringBuilder str \u003d new StringBuilder(proto+nnHostPort+\"/getimage?\");\n     str.append(queryString);\n \n     //\n     // open connection to remote server\n     //\n     URL url \u003d new URL(str.toString());\n     \n     // Avoid Krb bug with cross-realm hosts\n     SecurityUtil.fetchServiceTicket(url);\n     HttpURLConnection connection \u003d (HttpURLConnection) url.openConnection();\n     \n     if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n       throw new IOException(\n           \"Image transfer servlet at \" + url +\n           \" failed with status code \" + connection.getResponseCode() +\n           \"\\nResponse message:\\n\" + connection.getResponseMessage());\n     }\n     \n     long advertisedSize;\n     String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n     if (contentLength !\u003d null) {\n       advertisedSize \u003d Long.parseLong(contentLength);\n     } else {\n       throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                             \"by the namenode when trying to fetch \" + str);\n     }\n     \n     MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n \n     long received \u003d 0;\n     InputStream stream \u003d connection.getInputStream();\n     MessageDigest digester \u003d null;\n     if (getChecksum) {\n       digester \u003d MD5Hash.getDigester();\n       stream \u003d new DigestInputStream(stream, digester);\n     }\n     boolean finishedReceiving \u003d false;\n \n     List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n \n     try {\n       if (localPaths !\u003d null) {\n         for (File f : localPaths) {\n           try {\n             if (f.exists()) {\n               LOG.warn(\"Overwriting existing file \" + f\n                   + \" with file downloaded from \" + str);\n             }\n             outputStreams.add(new FileOutputStream(f));\n           } catch (IOException ioe) {\n             LOG.warn(\"Unable to download file \" + f, ioe);\n             dstStorage.reportErrorOnFile(f);\n           }\n         }\n         \n         if (outputStreams.isEmpty()) {\n           throw new IOException(\n               \"Unable to download to any storage directory\");\n         }\n       }\n       \n       int num \u003d 1;\n       while (num \u003e 0) {\n         num \u003d stream.read(buf);\n         if (num \u003e 0) {\n           received +\u003d num;\n           for (FileOutputStream fos : outputStreams) {\n             fos.write(buf, 0, num);\n           }\n         }\n       }\n       finishedReceiving \u003d true;\n     } finally {\n       stream.close();\n       for (FileOutputStream fos : outputStreams) {\n         fos.getChannel().force(true);\n         fos.close();\n       }\n       if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n         // only throw this exception if we think we read all of it on our end\n         // -- otherwise a client-side IOException would be masked by this\n         // exception that makes it look like a server-side problem!\n         throw new IOException(\"File \" + str + \" received length \" + received +\n                               \" is not of the advertised size \" +\n                               advertisedSize);\n       }\n     }\n \n     if (digester !\u003d null) {\n       MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n       \n       if (advertisedDigest !\u003d null \u0026\u0026\n           !computedDigest.equals(advertisedDigest)) {\n         throw new IOException(\"File \" + str + \" computed digest \" +\n             computedDigest + \" does not match advertised digest \" + \n             advertisedDigest);\n       }\n       return computedDigest;\n     } else {\n       return null;\n     }    \n   }\n\\ No newline at end of file\n",
      "actualSource": "  static MD5Hash getFileClient(String nnHostPort,\n      String queryString, List\u003cFile\u003e localPaths,\n      NNStorage dstStorage, boolean getChecksum) throws IOException {\n    byte[] buf \u003d new byte[FSConstants.IO_FILE_BUFFER_SIZE];\n    String proto \u003d UserGroupInformation.isSecurityEnabled() ? \"https://\" : \"http://\";\n    StringBuilder str \u003d new StringBuilder(proto+nnHostPort+\"/getimage?\");\n    str.append(queryString);\n\n    //\n    // open connection to remote server\n    //\n    URL url \u003d new URL(str.toString());\n    \n    // Avoid Krb bug with cross-realm hosts\n    SecurityUtil.fetchServiceTicket(url);\n    HttpURLConnection connection \u003d (HttpURLConnection) url.openConnection();\n    \n    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n      throw new IOException(\n          \"Image transfer servlet at \" + url +\n          \" failed with status code \" + connection.getResponseCode() +\n          \"\\nResponse message:\\n\" + connection.getResponseMessage());\n    }\n    \n    long advertisedSize;\n    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n    if (contentLength !\u003d null) {\n      advertisedSize \u003d Long.parseLong(contentLength);\n    } else {\n      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                            \"by the namenode when trying to fetch \" + str);\n    }\n    \n    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n\n    long received \u003d 0;\n    InputStream stream \u003d connection.getInputStream();\n    MessageDigest digester \u003d null;\n    if (getChecksum) {\n      digester \u003d MD5Hash.getDigester();\n      stream \u003d new DigestInputStream(stream, digester);\n    }\n    boolean finishedReceiving \u003d false;\n\n    List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n\n    try {\n      if (localPaths !\u003d null) {\n        for (File f : localPaths) {\n          try {\n            if (f.exists()) {\n              LOG.warn(\"Overwriting existing file \" + f\n                  + \" with file downloaded from \" + str);\n            }\n            outputStreams.add(new FileOutputStream(f));\n          } catch (IOException ioe) {\n            LOG.warn(\"Unable to download file \" + f, ioe);\n            dstStorage.reportErrorOnFile(f);\n          }\n        }\n        \n        if (outputStreams.isEmpty()) {\n          throw new IOException(\n              \"Unable to download to any storage directory\");\n        }\n      }\n      \n      int num \u003d 1;\n      while (num \u003e 0) {\n        num \u003d stream.read(buf);\n        if (num \u003e 0) {\n          received +\u003d num;\n          for (FileOutputStream fos : outputStreams) {\n            fos.write(buf, 0, num);\n          }\n        }\n      }\n      finishedReceiving \u003d true;\n    } finally {\n      stream.close();\n      for (FileOutputStream fos : outputStreams) {\n        fos.getChannel().force(true);\n        fos.close();\n      }\n      if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n        // only throw this exception if we think we read all of it on our end\n        // -- otherwise a client-side IOException would be masked by this\n        // exception that makes it look like a server-side problem!\n        throw new IOException(\"File \" + str + \" received length \" + received +\n                              \" is not of the advertised size \" +\n                              advertisedSize);\n      }\n    }\n\n    if (digester !\u003d null) {\n      MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n      \n      if (advertisedDigest !\u003d null \u0026\u0026\n          !computedDigest.equals(advertisedDigest)) {\n        throw new IOException(\"File \" + str + \" computed digest \" +\n            computedDigest + \" does not match advertised digest \" + \n            advertisedDigest);\n      }\n      return computedDigest;\n    } else {\n      return null;\n    }    \n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
      "extendedDetails": {}
    },
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/11 9:28 AM",
      "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/07/11 9:28 AM",
          "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "12/06/11 3:00 PM",
          "commitNameOld": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 46.77,
          "commitsBetweenForRepo": 164,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,73 +1,108 @@\n-  static MD5Hash getFileClient(String fsName, String id, File[] localPath,\n-      boolean getChecksum)\n-    throws IOException {\n+  static MD5Hash getFileClient(String nnHostPort,\n+      String queryString, List\u003cFile\u003e localPaths,\n+      NNStorage dstStorage, boolean getChecksum) throws IOException {\n     byte[] buf \u003d new byte[BUFFER_SIZE];\n     String proto \u003d UserGroupInformation.isSecurityEnabled() ? \"https://\" : \"http://\";\n-    StringBuilder str \u003d new StringBuilder(proto+fsName+\"/getimage?\");\n-    str.append(id);\n+    StringBuilder str \u003d new StringBuilder(proto+nnHostPort+\"/getimage?\");\n+    str.append(queryString);\n \n     //\n     // open connection to remote server\n     //\n     URL url \u003d new URL(str.toString());\n     \n     // Avoid Krb bug with cross-realm hosts\n     SecurityUtil.fetchServiceTicket(url);\n-    URLConnection connection \u003d url.openConnection();\n+    HttpURLConnection connection \u003d (HttpURLConnection) url.openConnection();\n+    \n+    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n+      throw new IOException(\n+          \"Image transfer servlet at \" + url +\n+          \" failed with status code \" + connection.getResponseCode() +\n+          \"\\nResponse message:\\n\" + connection.getResponseMessage());\n+    }\n+    \n     long advertisedSize;\n     String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n     if (contentLength !\u003d null) {\n       advertisedSize \u003d Long.parseLong(contentLength);\n     } else {\n       throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                             \"by the namenode when trying to fetch \" + str);\n     }\n+    \n+    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n+\n     long received \u003d 0;\n     InputStream stream \u003d connection.getInputStream();\n     MessageDigest digester \u003d null;\n     if (getChecksum) {\n       digester \u003d MD5Hash.getDigester();\n       stream \u003d new DigestInputStream(stream, digester);\n     }\n-    FileOutputStream[] output \u003d null;\n     boolean finishedReceiving \u003d false;\n \n+    List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n+\n     try {\n-      if (localPath !\u003d null) {\n-        output \u003d new FileOutputStream[localPath.length];\n-        for (int i \u003d 0; i \u003c output.length; i++) {\n-          output[i] \u003d new FileOutputStream(localPath[i]);\n+      if (localPaths !\u003d null) {\n+        for (File f : localPaths) {\n+          try {\n+            if (f.exists()) {\n+              LOG.warn(\"Overwriting existing file \" + f\n+                  + \" with file downloaded from \" + str);\n+            }\n+            outputStreams.add(new FileOutputStream(f));\n+          } catch (IOException ioe) {\n+            LOG.warn(\"Unable to download file \" + f, ioe);\n+            dstStorage.reportErrorOnFile(f);\n+          }\n+        }\n+        \n+        if (outputStreams.isEmpty()) {\n+          throw new IOException(\n+              \"Unable to download to any storage directory\");\n         }\n       }\n+      \n       int num \u003d 1;\n       while (num \u003e 0) {\n         num \u003d stream.read(buf);\n-        if (num \u003e 0 \u0026\u0026 localPath !\u003d null) {\n+        if (num \u003e 0) {\n           received +\u003d num;\n-          for (int i \u003d 0; i \u003c output.length; i++) {\n-            output[i].write(buf, 0, num);\n+          for (FileOutputStream fos : outputStreams) {\n+            fos.write(buf, 0, num);\n           }\n         }\n       }\n       finishedReceiving \u003d true;\n     } finally {\n       stream.close();\n-      if (output !\u003d null) {\n-        for (int i \u003d 0; i \u003c output.length; i++) {\n-          if (output[i] !\u003d null) {\n-            output[i].getChannel().force(true);\n-            output[i].close();\n-          }\n-        }\n+      for (FileOutputStream fos : outputStreams) {\n+        fos.getChannel().force(true);\n+        fos.close();\n       }\n       if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n         // only throw this exception if we think we read all of it on our end\n         // -- otherwise a client-side IOException would be masked by this\n         // exception that makes it look like a server-side problem!\n         throw new IOException(\"File \" + str + \" received length \" + received +\n                               \" is not of the advertised size \" +\n                               advertisedSize);\n       }\n     }\n-    return digester\u003d\u003dnull ? null : new MD5Hash(digester.digest());\n+\n+    if (digester !\u003d null) {\n+      MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n+      \n+      if (advertisedDigest !\u003d null \u0026\u0026\n+          !computedDigest.equals(advertisedDigest)) {\n+        throw new IOException(\"File \" + str + \" computed digest \" +\n+            computedDigest + \" does not match advertised digest \" + \n+            advertisedDigest);\n+      }\n+      return computedDigest;\n+    } else {\n+      return null;\n+    }    \n   }\n\\ No newline at end of file\n",
          "actualSource": "  static MD5Hash getFileClient(String nnHostPort,\n      String queryString, List\u003cFile\u003e localPaths,\n      NNStorage dstStorage, boolean getChecksum) throws IOException {\n    byte[] buf \u003d new byte[BUFFER_SIZE];\n    String proto \u003d UserGroupInformation.isSecurityEnabled() ? \"https://\" : \"http://\";\n    StringBuilder str \u003d new StringBuilder(proto+nnHostPort+\"/getimage?\");\n    str.append(queryString);\n\n    //\n    // open connection to remote server\n    //\n    URL url \u003d new URL(str.toString());\n    \n    // Avoid Krb bug with cross-realm hosts\n    SecurityUtil.fetchServiceTicket(url);\n    HttpURLConnection connection \u003d (HttpURLConnection) url.openConnection();\n    \n    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n      throw new IOException(\n          \"Image transfer servlet at \" + url +\n          \" failed with status code \" + connection.getResponseCode() +\n          \"\\nResponse message:\\n\" + connection.getResponseMessage());\n    }\n    \n    long advertisedSize;\n    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n    if (contentLength !\u003d null) {\n      advertisedSize \u003d Long.parseLong(contentLength);\n    } else {\n      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                            \"by the namenode when trying to fetch \" + str);\n    }\n    \n    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n\n    long received \u003d 0;\n    InputStream stream \u003d connection.getInputStream();\n    MessageDigest digester \u003d null;\n    if (getChecksum) {\n      digester \u003d MD5Hash.getDigester();\n      stream \u003d new DigestInputStream(stream, digester);\n    }\n    boolean finishedReceiving \u003d false;\n\n    List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n\n    try {\n      if (localPaths !\u003d null) {\n        for (File f : localPaths) {\n          try {\n            if (f.exists()) {\n              LOG.warn(\"Overwriting existing file \" + f\n                  + \" with file downloaded from \" + str);\n            }\n            outputStreams.add(new FileOutputStream(f));\n          } catch (IOException ioe) {\n            LOG.warn(\"Unable to download file \" + f, ioe);\n            dstStorage.reportErrorOnFile(f);\n          }\n        }\n        \n        if (outputStreams.isEmpty()) {\n          throw new IOException(\n              \"Unable to download to any storage directory\");\n        }\n      }\n      \n      int num \u003d 1;\n      while (num \u003e 0) {\n        num \u003d stream.read(buf);\n        if (num \u003e 0) {\n          received +\u003d num;\n          for (FileOutputStream fos : outputStreams) {\n            fos.write(buf, 0, num);\n          }\n        }\n      }\n      finishedReceiving \u003d true;\n    } finally {\n      stream.close();\n      for (FileOutputStream fos : outputStreams) {\n        fos.getChannel().force(true);\n        fos.close();\n      }\n      if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n        // only throw this exception if we think we read all of it on our end\n        // -- otherwise a client-side IOException would be masked by this\n        // exception that makes it look like a server-side problem!\n        throw new IOException(\"File \" + str + \" received length \" + received +\n                              \" is not of the advertised size \" +\n                              advertisedSize);\n      }\n    }\n\n    if (digester !\u003d null) {\n      MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n      \n      if (advertisedDigest !\u003d null \u0026\u0026\n          !computedDigest.equals(advertisedDigest)) {\n        throw new IOException(\"File \" + str + \" computed digest \" +\n            computedDigest + \" does not match advertised digest \" + \n            advertisedDigest);\n      }\n      return computedDigest;\n    } else {\n      return null;\n    }    \n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
          "extendedDetails": {
            "oldValue": "[fsName-String, id-String, localPath-File[], getChecksum-boolean]",
            "newValue": "[nnHostPort-String, queryString-String, localPaths-List\u003cFile\u003e, dstStorage-NNStorage, getChecksum-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/07/11 9:28 AM",
          "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "12/06/11 3:00 PM",
          "commitNameOld": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 46.77,
          "commitsBetweenForRepo": 164,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,73 +1,108 @@\n-  static MD5Hash getFileClient(String fsName, String id, File[] localPath,\n-      boolean getChecksum)\n-    throws IOException {\n+  static MD5Hash getFileClient(String nnHostPort,\n+      String queryString, List\u003cFile\u003e localPaths,\n+      NNStorage dstStorage, boolean getChecksum) throws IOException {\n     byte[] buf \u003d new byte[BUFFER_SIZE];\n     String proto \u003d UserGroupInformation.isSecurityEnabled() ? \"https://\" : \"http://\";\n-    StringBuilder str \u003d new StringBuilder(proto+fsName+\"/getimage?\");\n-    str.append(id);\n+    StringBuilder str \u003d new StringBuilder(proto+nnHostPort+\"/getimage?\");\n+    str.append(queryString);\n \n     //\n     // open connection to remote server\n     //\n     URL url \u003d new URL(str.toString());\n     \n     // Avoid Krb bug with cross-realm hosts\n     SecurityUtil.fetchServiceTicket(url);\n-    URLConnection connection \u003d url.openConnection();\n+    HttpURLConnection connection \u003d (HttpURLConnection) url.openConnection();\n+    \n+    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n+      throw new IOException(\n+          \"Image transfer servlet at \" + url +\n+          \" failed with status code \" + connection.getResponseCode() +\n+          \"\\nResponse message:\\n\" + connection.getResponseMessage());\n+    }\n+    \n     long advertisedSize;\n     String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n     if (contentLength !\u003d null) {\n       advertisedSize \u003d Long.parseLong(contentLength);\n     } else {\n       throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                             \"by the namenode when trying to fetch \" + str);\n     }\n+    \n+    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n+\n     long received \u003d 0;\n     InputStream stream \u003d connection.getInputStream();\n     MessageDigest digester \u003d null;\n     if (getChecksum) {\n       digester \u003d MD5Hash.getDigester();\n       stream \u003d new DigestInputStream(stream, digester);\n     }\n-    FileOutputStream[] output \u003d null;\n     boolean finishedReceiving \u003d false;\n \n+    List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n+\n     try {\n-      if (localPath !\u003d null) {\n-        output \u003d new FileOutputStream[localPath.length];\n-        for (int i \u003d 0; i \u003c output.length; i++) {\n-          output[i] \u003d new FileOutputStream(localPath[i]);\n+      if (localPaths !\u003d null) {\n+        for (File f : localPaths) {\n+          try {\n+            if (f.exists()) {\n+              LOG.warn(\"Overwriting existing file \" + f\n+                  + \" with file downloaded from \" + str);\n+            }\n+            outputStreams.add(new FileOutputStream(f));\n+          } catch (IOException ioe) {\n+            LOG.warn(\"Unable to download file \" + f, ioe);\n+            dstStorage.reportErrorOnFile(f);\n+          }\n+        }\n+        \n+        if (outputStreams.isEmpty()) {\n+          throw new IOException(\n+              \"Unable to download to any storage directory\");\n         }\n       }\n+      \n       int num \u003d 1;\n       while (num \u003e 0) {\n         num \u003d stream.read(buf);\n-        if (num \u003e 0 \u0026\u0026 localPath !\u003d null) {\n+        if (num \u003e 0) {\n           received +\u003d num;\n-          for (int i \u003d 0; i \u003c output.length; i++) {\n-            output[i].write(buf, 0, num);\n+          for (FileOutputStream fos : outputStreams) {\n+            fos.write(buf, 0, num);\n           }\n         }\n       }\n       finishedReceiving \u003d true;\n     } finally {\n       stream.close();\n-      if (output !\u003d null) {\n-        for (int i \u003d 0; i \u003c output.length; i++) {\n-          if (output[i] !\u003d null) {\n-            output[i].getChannel().force(true);\n-            output[i].close();\n-          }\n-        }\n+      for (FileOutputStream fos : outputStreams) {\n+        fos.getChannel().force(true);\n+        fos.close();\n       }\n       if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n         // only throw this exception if we think we read all of it on our end\n         // -- otherwise a client-side IOException would be masked by this\n         // exception that makes it look like a server-side problem!\n         throw new IOException(\"File \" + str + \" received length \" + received +\n                               \" is not of the advertised size \" +\n                               advertisedSize);\n       }\n     }\n-    return digester\u003d\u003dnull ? null : new MD5Hash(digester.digest());\n+\n+    if (digester !\u003d null) {\n+      MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n+      \n+      if (advertisedDigest !\u003d null \u0026\u0026\n+          !computedDigest.equals(advertisedDigest)) {\n+        throw new IOException(\"File \" + str + \" computed digest \" +\n+            computedDigest + \" does not match advertised digest \" + \n+            advertisedDigest);\n+      }\n+      return computedDigest;\n+    } else {\n+      return null;\n+    }    \n   }\n\\ No newline at end of file\n",
          "actualSource": "  static MD5Hash getFileClient(String nnHostPort,\n      String queryString, List\u003cFile\u003e localPaths,\n      NNStorage dstStorage, boolean getChecksum) throws IOException {\n    byte[] buf \u003d new byte[BUFFER_SIZE];\n    String proto \u003d UserGroupInformation.isSecurityEnabled() ? \"https://\" : \"http://\";\n    StringBuilder str \u003d new StringBuilder(proto+nnHostPort+\"/getimage?\");\n    str.append(queryString);\n\n    //\n    // open connection to remote server\n    //\n    URL url \u003d new URL(str.toString());\n    \n    // Avoid Krb bug with cross-realm hosts\n    SecurityUtil.fetchServiceTicket(url);\n    HttpURLConnection connection \u003d (HttpURLConnection) url.openConnection();\n    \n    if (connection.getResponseCode() !\u003d HttpURLConnection.HTTP_OK) {\n      throw new IOException(\n          \"Image transfer servlet at \" + url +\n          \" failed with status code \" + connection.getResponseCode() +\n          \"\\nResponse message:\\n\" + connection.getResponseMessage());\n    }\n    \n    long advertisedSize;\n    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n    if (contentLength !\u003d null) {\n      advertisedSize \u003d Long.parseLong(contentLength);\n    } else {\n      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                            \"by the namenode when trying to fetch \" + str);\n    }\n    \n    MD5Hash advertisedDigest \u003d parseMD5Header(connection);\n\n    long received \u003d 0;\n    InputStream stream \u003d connection.getInputStream();\n    MessageDigest digester \u003d null;\n    if (getChecksum) {\n      digester \u003d MD5Hash.getDigester();\n      stream \u003d new DigestInputStream(stream, digester);\n    }\n    boolean finishedReceiving \u003d false;\n\n    List\u003cFileOutputStream\u003e outputStreams \u003d Lists.newArrayList();\n\n    try {\n      if (localPaths !\u003d null) {\n        for (File f : localPaths) {\n          try {\n            if (f.exists()) {\n              LOG.warn(\"Overwriting existing file \" + f\n                  + \" with file downloaded from \" + str);\n            }\n            outputStreams.add(new FileOutputStream(f));\n          } catch (IOException ioe) {\n            LOG.warn(\"Unable to download file \" + f, ioe);\n            dstStorage.reportErrorOnFile(f);\n          }\n        }\n        \n        if (outputStreams.isEmpty()) {\n          throw new IOException(\n              \"Unable to download to any storage directory\");\n        }\n      }\n      \n      int num \u003d 1;\n      while (num \u003e 0) {\n        num \u003d stream.read(buf);\n        if (num \u003e 0) {\n          received +\u003d num;\n          for (FileOutputStream fos : outputStreams) {\n            fos.write(buf, 0, num);\n          }\n        }\n      }\n      finishedReceiving \u003d true;\n    } finally {\n      stream.close();\n      for (FileOutputStream fos : outputStreams) {\n        fos.getChannel().force(true);\n        fos.close();\n      }\n      if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n        // only throw this exception if we think we read all of it on our end\n        // -- otherwise a client-side IOException would be masked by this\n        // exception that makes it look like a server-side problem!\n        throw new IOException(\"File \" + str + \" received length \" + received +\n                              \" is not of the advertised size \" +\n                              advertisedSize);\n      }\n    }\n\n    if (digester !\u003d null) {\n      MD5Hash computedDigest \u003d new MD5Hash(digester.digest());\n      \n      if (advertisedDigest !\u003d null \u0026\u0026\n          !computedDigest.equals(advertisedDigest)) {\n        throw new IOException(\"File \" + str + \" computed digest \" +\n            computedDigest + \" does not match advertised digest \" + \n            advertisedDigest);\n      }\n      return computedDigest;\n    } else {\n      return null;\n    }    \n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java",
          "extendedDetails": {}
        }
      ]
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,73 @@\n+  static MD5Hash getFileClient(String fsName, String id, File[] localPath,\n+      boolean getChecksum)\n+    throws IOException {\n+    byte[] buf \u003d new byte[BUFFER_SIZE];\n+    String proto \u003d UserGroupInformation.isSecurityEnabled() ? \"https://\" : \"http://\";\n+    StringBuilder str \u003d new StringBuilder(proto+fsName+\"/getimage?\");\n+    str.append(id);\n+\n+    //\n+    // open connection to remote server\n+    //\n+    URL url \u003d new URL(str.toString());\n+    \n+    // Avoid Krb bug with cross-realm hosts\n+    SecurityUtil.fetchServiceTicket(url);\n+    URLConnection connection \u003d url.openConnection();\n+    long advertisedSize;\n+    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n+    if (contentLength !\u003d null) {\n+      advertisedSize \u003d Long.parseLong(contentLength);\n+    } else {\n+      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n+                            \"by the namenode when trying to fetch \" + str);\n+    }\n+    long received \u003d 0;\n+    InputStream stream \u003d connection.getInputStream();\n+    MessageDigest digester \u003d null;\n+    if (getChecksum) {\n+      digester \u003d MD5Hash.getDigester();\n+      stream \u003d new DigestInputStream(stream, digester);\n+    }\n+    FileOutputStream[] output \u003d null;\n+    boolean finishedReceiving \u003d false;\n+\n+    try {\n+      if (localPath !\u003d null) {\n+        output \u003d new FileOutputStream[localPath.length];\n+        for (int i \u003d 0; i \u003c output.length; i++) {\n+          output[i] \u003d new FileOutputStream(localPath[i]);\n+        }\n+      }\n+      int num \u003d 1;\n+      while (num \u003e 0) {\n+        num \u003d stream.read(buf);\n+        if (num \u003e 0 \u0026\u0026 localPath !\u003d null) {\n+          received +\u003d num;\n+          for (int i \u003d 0; i \u003c output.length; i++) {\n+            output[i].write(buf, 0, num);\n+          }\n+        }\n+      }\n+      finishedReceiving \u003d true;\n+    } finally {\n+      stream.close();\n+      if (output !\u003d null) {\n+        for (int i \u003d 0; i \u003c output.length; i++) {\n+          if (output[i] !\u003d null) {\n+            output[i].getChannel().force(true);\n+            output[i].close();\n+          }\n+        }\n+      }\n+      if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n+        // only throw this exception if we think we read all of it on our end\n+        // -- otherwise a client-side IOException would be masked by this\n+        // exception that makes it look like a server-side problem!\n+        throw new IOException(\"File \" + str + \" received length \" + received +\n+                              \" is not of the advertised size \" +\n+                              advertisedSize);\n+      }\n+    }\n+    return digester\u003d\u003dnull ? null : new MD5Hash(digester.digest());\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static MD5Hash getFileClient(String fsName, String id, File[] localPath,\n      boolean getChecksum)\n    throws IOException {\n    byte[] buf \u003d new byte[BUFFER_SIZE];\n    String proto \u003d UserGroupInformation.isSecurityEnabled() ? \"https://\" : \"http://\";\n    StringBuilder str \u003d new StringBuilder(proto+fsName+\"/getimage?\");\n    str.append(id);\n\n    //\n    // open connection to remote server\n    //\n    URL url \u003d new URL(str.toString());\n    \n    // Avoid Krb bug with cross-realm hosts\n    SecurityUtil.fetchServiceTicket(url);\n    URLConnection connection \u003d url.openConnection();\n    long advertisedSize;\n    String contentLength \u003d connection.getHeaderField(CONTENT_LENGTH);\n    if (contentLength !\u003d null) {\n      advertisedSize \u003d Long.parseLong(contentLength);\n    } else {\n      throw new IOException(CONTENT_LENGTH + \" header is not provided \" +\n                            \"by the namenode when trying to fetch \" + str);\n    }\n    long received \u003d 0;\n    InputStream stream \u003d connection.getInputStream();\n    MessageDigest digester \u003d null;\n    if (getChecksum) {\n      digester \u003d MD5Hash.getDigester();\n      stream \u003d new DigestInputStream(stream, digester);\n    }\n    FileOutputStream[] output \u003d null;\n    boolean finishedReceiving \u003d false;\n\n    try {\n      if (localPath !\u003d null) {\n        output \u003d new FileOutputStream[localPath.length];\n        for (int i \u003d 0; i \u003c output.length; i++) {\n          output[i] \u003d new FileOutputStream(localPath[i]);\n        }\n      }\n      int num \u003d 1;\n      while (num \u003e 0) {\n        num \u003d stream.read(buf);\n        if (num \u003e 0 \u0026\u0026 localPath !\u003d null) {\n          received +\u003d num;\n          for (int i \u003d 0; i \u003c output.length; i++) {\n            output[i].write(buf, 0, num);\n          }\n        }\n      }\n      finishedReceiving \u003d true;\n    } finally {\n      stream.close();\n      if (output !\u003d null) {\n        for (int i \u003d 0; i \u003c output.length; i++) {\n          if (output[i] !\u003d null) {\n            output[i].getChannel().force(true);\n            output[i].close();\n          }\n        }\n      }\n      if (finishedReceiving \u0026\u0026 received !\u003d advertisedSize) {\n        // only throw this exception if we think we read all of it on our end\n        // -- otherwise a client-side IOException would be masked by this\n        // exception that makes it look like a server-side problem!\n        throw new IOException(\"File \" + str + \" received length \" + received +\n                              \" is not of the advertised size \" +\n                              advertisedSize);\n      }\n    }\n    return digester\u003d\u003dnull ? null : new MD5Hash(digester.digest());\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.java"
    }
  }
}