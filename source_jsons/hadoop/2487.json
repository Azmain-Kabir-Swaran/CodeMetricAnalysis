{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PBHelperClient.java",
  "functionName": "convert",
  "functionId": "convert___fs-HdfsFileStatus",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
  "functionStartLine": 2298,
  "functionEndLine": 2347,
  "numCommitsSeen": 226,
  "timeTaken": 10374,
  "changeHistory": [
    "1d2640b6132e8308c07476badd2d1482be68a298",
    "0e560f3b8d194c10dce06443979df4074e14b0db",
    "675e9a8f57570771a0219d95940681b067d36b94",
    "b85603e3f85e85da406241b991f3a9974384c3aa",
    "107c177782a24a16c66113841f2fc5144f56207b",
    "645a8f2a4d09acb5a21820f52ee78784d9e4cc8a",
    "12e44e7bdaf53d3720a89d32f0cc2717241bd6b2",
    "c470c8953d4927043b6383fad8e792289c634c09",
    "06022b8fdc40e50eaac63758246353058e8cfa6d",
    "bb84f1fccb18c6c7373851e05d2451d55e908242",
    "a7bcc9535860214380e235641d1d5d2dd15aee58",
    "9b250d74f029f8ccf3a613f9fb74f59838a66ec1",
    "2efea952139b30dd1c881eed0b443ffa72be6dce",
    "bdee397e95e98ece071345822e2e4d3f690f09c3",
    "6ecf78a99b4b10d4c569cc2b335060ab988b8001",
    "4525c4a25ba90163c9543116e2bd54239e0dd097",
    "8134b1c8702d7d6b3994c73b34afc7f8ee33ac6e",
    "d8dfcdcbc2e2df3aa1d7b309f263434739475e7e",
    "3954a2fb1cbc7a8a0d1ad5859e7f5c9415530f4c",
    "6a609cb471d413b15e3659cc9d7cd6f5f3357256",
    "b5229fd19bfecc2e5249db652ad34ec08152334b",
    "3001a172c8868763f8e59e866e36f7f50dee62cc",
    "13345f3a85b6b66c71a38e7c187c8ebb7cb5c35e",
    "48da033901d3471ef176a94104158546152353e9"
  ],
  "changeHistoryShort": {
    "1d2640b6132e8308c07476badd2d1482be68a298": "Ybodychange",
    "0e560f3b8d194c10dce06443979df4074e14b0db": "Ybodychange",
    "675e9a8f57570771a0219d95940681b067d36b94": "Ybodychange",
    "b85603e3f85e85da406241b991f3a9974384c3aa": "Ybodychange",
    "107c177782a24a16c66113841f2fc5144f56207b": "Ybodychange",
    "645a8f2a4d09acb5a21820f52ee78784d9e4cc8a": "Ybodychange",
    "12e44e7bdaf53d3720a89d32f0cc2717241bd6b2": "Ybodychange",
    "c470c8953d4927043b6383fad8e792289c634c09": "Ybodychange",
    "06022b8fdc40e50eaac63758246353058e8cfa6d": "Ymultichange(Ymovefromfile,Ybodychange)",
    "bb84f1fccb18c6c7373851e05d2451d55e908242": "Ybodychange",
    "a7bcc9535860214380e235641d1d5d2dd15aee58": "Ybodychange",
    "9b250d74f029f8ccf3a613f9fb74f59838a66ec1": "Ybodychange",
    "2efea952139b30dd1c881eed0b443ffa72be6dce": "Ybodychange",
    "bdee397e95e98ece071345822e2e4d3f690f09c3": "Ybodychange",
    "6ecf78a99b4b10d4c569cc2b335060ab988b8001": "Ybodychange",
    "4525c4a25ba90163c9543116e2bd54239e0dd097": "Ybodychange",
    "8134b1c8702d7d6b3994c73b34afc7f8ee33ac6e": "Ybodychange",
    "d8dfcdcbc2e2df3aa1d7b309f263434739475e7e": "Ybodychange",
    "3954a2fb1cbc7a8a0d1ad5859e7f5c9415530f4c": "Ybodychange",
    "6a609cb471d413b15e3659cc9d7cd6f5f3357256": "Ybodychange",
    "b5229fd19bfecc2e5249db652ad34ec08152334b": "Ybodychange",
    "3001a172c8868763f8e59e866e36f7f50dee62cc": "Ybodychange",
    "13345f3a85b6b66c71a38e7c187c8ebb7cb5c35e": "Ybodychange",
    "48da033901d3471ef176a94104158546152353e9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1d2640b6132e8308c07476badd2d1482be68a298": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13601. Optimize ByteString conversions in PBHelper.\n",
      "commitDate": "22/05/18 11:55 PM",
      "commitName": "1d2640b6132e8308c07476badd2d1482be68a298",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "26/04/18 5:36 AM",
      "commitNameOld": "0ec88ea42be7178d5fbc832ac393ded6c2aca8c8",
      "commitAuthorOld": "Nanda kumar",
      "daysBetweenCommits": 26.76,
      "commitsBetweenForRepo": 232,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,50 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDirectory()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d\n         HdfsFileStatusProto.newBuilder().\n             setLength(fs.getLen()).\n             setFileType(fType).\n             setBlockReplication(fs.getReplication()).\n             setBlocksize(fs.getBlockSize()).\n             setModificationTime(fs.getModificationTime()).\n             setAccessTime(fs.getAccessTime()).\n             setPermission(convert(fs.getPermission())).\n-            setOwner(fs.getOwner()).\n-            setGroup(fs.getGroup()).\n+            setOwnerBytes(getFixedByteString(fs.getOwner())).\n+            setGroupBytes(getFixedByteString(fs.getGroup())).\n             setFileId(fs.getFileId()).\n             setChildrenNum(fs.getChildrenNum()).\n             setPath(getByteString(fs.getLocalNameInBytes())).\n             setStoragePolicy(fs.getStoragePolicy());\n     if (fs.isSymlink())  {\n       builder.setSymlink(getByteString(fs.getSymlinkInBytes()));\n     }\n     if (fs.getFileEncryptionInfo() !\u003d null) {\n       builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n     }\n     if (fs instanceof HdfsLocatedFileStatus) {\n       final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n       LocatedBlocks locations \u003d lfs.getLocatedBlocks();\n       if (locations !\u003d null) {\n         builder.setLocations(convert(locations));\n       }\n     }\n     if(fs.getErasureCodingPolicy() !\u003d null) {\n       builder.setEcPolicy(convertErasureCodingPolicy(\n           fs.getErasureCodingPolicy()));\n     }\n     int flags \u003d fs.hasAcl()   ? HdfsFileStatusProto.Flags.HAS_ACL_VALUE   : 0;\n     flags |\u003d fs.isEncrypted() ? HdfsFileStatusProto.Flags.HAS_CRYPT_VALUE : 0;\n     flags |\u003d fs.isErasureCoded() ? HdfsFileStatusProto.Flags.HAS_EC_VALUE : 0;\n     flags |\u003d fs.isSnapshotEnabled() ? HdfsFileStatusProto.Flags\n         .SNAPSHOT_ENABLED_VALUE : 0;\n     builder.setFlags(flags);\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDirectory()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d\n        HdfsFileStatusProto.newBuilder().\n            setLength(fs.getLen()).\n            setFileType(fType).\n            setBlockReplication(fs.getReplication()).\n            setBlocksize(fs.getBlockSize()).\n            setModificationTime(fs.getModificationTime()).\n            setAccessTime(fs.getAccessTime()).\n            setPermission(convert(fs.getPermission())).\n            setOwnerBytes(getFixedByteString(fs.getOwner())).\n            setGroupBytes(getFixedByteString(fs.getGroup())).\n            setFileId(fs.getFileId()).\n            setChildrenNum(fs.getChildrenNum()).\n            setPath(getByteString(fs.getLocalNameInBytes())).\n            setStoragePolicy(fs.getStoragePolicy());\n    if (fs.isSymlink())  {\n      builder.setSymlink(getByteString(fs.getSymlinkInBytes()));\n    }\n    if (fs.getFileEncryptionInfo() !\u003d null) {\n      builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n      LocatedBlocks locations \u003d lfs.getLocatedBlocks();\n      if (locations !\u003d null) {\n        builder.setLocations(convert(locations));\n      }\n    }\n    if(fs.getErasureCodingPolicy() !\u003d null) {\n      builder.setEcPolicy(convertErasureCodingPolicy(\n          fs.getErasureCodingPolicy()));\n    }\n    int flags \u003d fs.hasAcl()   ? HdfsFileStatusProto.Flags.HAS_ACL_VALUE   : 0;\n    flags |\u003d fs.isEncrypted() ? HdfsFileStatusProto.Flags.HAS_CRYPT_VALUE : 0;\n    flags |\u003d fs.isErasureCoded() ? HdfsFileStatusProto.Flags.HAS_EC_VALUE : 0;\n    flags |\u003d fs.isSnapshotEnabled() ? HdfsFileStatusProto.Flags\n        .SNAPSHOT_ENABLED_VALUE : 0;\n    builder.setFlags(flags);\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "0e560f3b8d194c10dce06443979df4074e14b0db": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12681. Make HdfsLocatedFileStatus a subtype of LocatedFileStatus\n",
      "commitDate": "29/11/17 8:28 PM",
      "commitName": "0e560f3b8d194c10dce06443979df4074e14b0db",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "15/11/17 7:20 PM",
      "commitNameOld": "675e9a8f57570771a0219d95940681b067d36b94",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 14.05,
      "commitsBetweenForRepo": 52,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,50 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDirectory()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d\n         HdfsFileStatusProto.newBuilder().\n             setLength(fs.getLen()).\n             setFileType(fType).\n             setBlockReplication(fs.getReplication()).\n             setBlocksize(fs.getBlockSize()).\n             setModificationTime(fs.getModificationTime()).\n             setAccessTime(fs.getAccessTime()).\n             setPermission(convert(fs.getPermission())).\n             setOwner(fs.getOwner()).\n             setGroup(fs.getGroup()).\n             setFileId(fs.getFileId()).\n             setChildrenNum(fs.getChildrenNum()).\n             setPath(getByteString(fs.getLocalNameInBytes())).\n             setStoragePolicy(fs.getStoragePolicy());\n     if (fs.isSymlink())  {\n       builder.setSymlink(getByteString(fs.getSymlinkInBytes()));\n     }\n     if (fs.getFileEncryptionInfo() !\u003d null) {\n       builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n     }\n     if (fs instanceof HdfsLocatedFileStatus) {\n       final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n-      LocatedBlocks locations \u003d lfs.getBlockLocations();\n+      LocatedBlocks locations \u003d lfs.getLocatedBlocks();\n       if (locations !\u003d null) {\n         builder.setLocations(convert(locations));\n       }\n     }\n     if(fs.getErasureCodingPolicy() !\u003d null) {\n       builder.setEcPolicy(convertErasureCodingPolicy(\n           fs.getErasureCodingPolicy()));\n     }\n     int flags \u003d fs.hasAcl()   ? HdfsFileStatusProto.Flags.HAS_ACL_VALUE   : 0;\n     flags |\u003d fs.isEncrypted() ? HdfsFileStatusProto.Flags.HAS_CRYPT_VALUE : 0;\n     flags |\u003d fs.isErasureCoded() ? HdfsFileStatusProto.Flags.HAS_EC_VALUE : 0;\n     flags |\u003d fs.isSnapshotEnabled() ? HdfsFileStatusProto.Flags\n         .SNAPSHOT_ENABLED_VALUE : 0;\n     builder.setFlags(flags);\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDirectory()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d\n        HdfsFileStatusProto.newBuilder().\n            setLength(fs.getLen()).\n            setFileType(fType).\n            setBlockReplication(fs.getReplication()).\n            setBlocksize(fs.getBlockSize()).\n            setModificationTime(fs.getModificationTime()).\n            setAccessTime(fs.getAccessTime()).\n            setPermission(convert(fs.getPermission())).\n            setOwner(fs.getOwner()).\n            setGroup(fs.getGroup()).\n            setFileId(fs.getFileId()).\n            setChildrenNum(fs.getChildrenNum()).\n            setPath(getByteString(fs.getLocalNameInBytes())).\n            setStoragePolicy(fs.getStoragePolicy());\n    if (fs.isSymlink())  {\n      builder.setSymlink(getByteString(fs.getSymlinkInBytes()));\n    }\n    if (fs.getFileEncryptionInfo() !\u003d null) {\n      builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n      LocatedBlocks locations \u003d lfs.getLocatedBlocks();\n      if (locations !\u003d null) {\n        builder.setLocations(convert(locations));\n      }\n    }\n    if(fs.getErasureCodingPolicy() !\u003d null) {\n      builder.setEcPolicy(convertErasureCodingPolicy(\n          fs.getErasureCodingPolicy()));\n    }\n    int flags \u003d fs.hasAcl()   ? HdfsFileStatusProto.Flags.HAS_ACL_VALUE   : 0;\n    flags |\u003d fs.isEncrypted() ? HdfsFileStatusProto.Flags.HAS_CRYPT_VALUE : 0;\n    flags |\u003d fs.isErasureCoded() ? HdfsFileStatusProto.Flags.HAS_EC_VALUE : 0;\n    flags |\u003d fs.isSnapshotEnabled() ? HdfsFileStatusProto.Flags\n        .SNAPSHOT_ENABLED_VALUE : 0;\n    builder.setFlags(flags);\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "675e9a8f57570771a0219d95940681b067d36b94": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-12681. Fold HdfsLocatedFileStatus into HdfsFileStatus.\"\n\nThis reverts commit b85603e3f85e85da406241b991f3a9974384c3aa.\n",
      "commitDate": "15/11/17 7:20 PM",
      "commitName": "675e9a8f57570771a0219d95940681b067d36b94",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "03/11/17 2:30 PM",
      "commitNameOld": "b85603e3f85e85da406241b991f3a9974384c3aa",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 12.24,
      "commitsBetweenForRepo": 169,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,50 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDirectory()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d\n         HdfsFileStatusProto.newBuilder().\n             setLength(fs.getLen()).\n             setFileType(fType).\n             setBlockReplication(fs.getReplication()).\n             setBlocksize(fs.getBlockSize()).\n             setModificationTime(fs.getModificationTime()).\n             setAccessTime(fs.getAccessTime()).\n             setPermission(convert(fs.getPermission())).\n             setOwner(fs.getOwner()).\n             setGroup(fs.getGroup()).\n             setFileId(fs.getFileId()).\n             setChildrenNum(fs.getChildrenNum()).\n             setPath(getByteString(fs.getLocalNameInBytes())).\n             setStoragePolicy(fs.getStoragePolicy());\n     if (fs.isSymlink())  {\n       builder.setSymlink(getByteString(fs.getSymlinkInBytes()));\n     }\n     if (fs.getFileEncryptionInfo() !\u003d null) {\n       builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n     }\n-    LocatedBlocks locations \u003d fs.getLocatedBlocks();\n-    if (locations !\u003d null) {\n-      builder.setLocations(convert(locations));\n+    if (fs instanceof HdfsLocatedFileStatus) {\n+      final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n+      LocatedBlocks locations \u003d lfs.getBlockLocations();\n+      if (locations !\u003d null) {\n+        builder.setLocations(convert(locations));\n+      }\n     }\n     if(fs.getErasureCodingPolicy() !\u003d null) {\n       builder.setEcPolicy(convertErasureCodingPolicy(\n           fs.getErasureCodingPolicy()));\n     }\n     int flags \u003d fs.hasAcl()   ? HdfsFileStatusProto.Flags.HAS_ACL_VALUE   : 0;\n     flags |\u003d fs.isEncrypted() ? HdfsFileStatusProto.Flags.HAS_CRYPT_VALUE : 0;\n     flags |\u003d fs.isErasureCoded() ? HdfsFileStatusProto.Flags.HAS_EC_VALUE : 0;\n     flags |\u003d fs.isSnapshotEnabled() ? HdfsFileStatusProto.Flags\n         .SNAPSHOT_ENABLED_VALUE : 0;\n     builder.setFlags(flags);\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDirectory()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d\n        HdfsFileStatusProto.newBuilder().\n            setLength(fs.getLen()).\n            setFileType(fType).\n            setBlockReplication(fs.getReplication()).\n            setBlocksize(fs.getBlockSize()).\n            setModificationTime(fs.getModificationTime()).\n            setAccessTime(fs.getAccessTime()).\n            setPermission(convert(fs.getPermission())).\n            setOwner(fs.getOwner()).\n            setGroup(fs.getGroup()).\n            setFileId(fs.getFileId()).\n            setChildrenNum(fs.getChildrenNum()).\n            setPath(getByteString(fs.getLocalNameInBytes())).\n            setStoragePolicy(fs.getStoragePolicy());\n    if (fs.isSymlink())  {\n      builder.setSymlink(getByteString(fs.getSymlinkInBytes()));\n    }\n    if (fs.getFileEncryptionInfo() !\u003d null) {\n      builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n      LocatedBlocks locations \u003d lfs.getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(convert(locations));\n      }\n    }\n    if(fs.getErasureCodingPolicy() !\u003d null) {\n      builder.setEcPolicy(convertErasureCodingPolicy(\n          fs.getErasureCodingPolicy()));\n    }\n    int flags \u003d fs.hasAcl()   ? HdfsFileStatusProto.Flags.HAS_ACL_VALUE   : 0;\n    flags |\u003d fs.isEncrypted() ? HdfsFileStatusProto.Flags.HAS_CRYPT_VALUE : 0;\n    flags |\u003d fs.isErasureCoded() ? HdfsFileStatusProto.Flags.HAS_EC_VALUE : 0;\n    flags |\u003d fs.isSnapshotEnabled() ? HdfsFileStatusProto.Flags\n        .SNAPSHOT_ENABLED_VALUE : 0;\n    builder.setFlags(flags);\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "b85603e3f85e85da406241b991f3a9974384c3aa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12681. Fold HdfsLocatedFileStatus into HdfsFileStatus.\n",
      "commitDate": "03/11/17 2:30 PM",
      "commitName": "b85603e3f85e85da406241b991f3a9974384c3aa",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "02/11/17 9:27 PM",
      "commitNameOld": "e565b5277d5b890dad107fe85e295a3907e4bfc1",
      "commitAuthorOld": "Xiao Chen",
      "daysBetweenCommits": 0.71,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,47 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDirectory()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d\n         HdfsFileStatusProto.newBuilder().\n             setLength(fs.getLen()).\n             setFileType(fType).\n             setBlockReplication(fs.getReplication()).\n             setBlocksize(fs.getBlockSize()).\n             setModificationTime(fs.getModificationTime()).\n             setAccessTime(fs.getAccessTime()).\n             setPermission(convert(fs.getPermission())).\n             setOwner(fs.getOwner()).\n             setGroup(fs.getGroup()).\n             setFileId(fs.getFileId()).\n             setChildrenNum(fs.getChildrenNum()).\n             setPath(getByteString(fs.getLocalNameInBytes())).\n             setStoragePolicy(fs.getStoragePolicy());\n     if (fs.isSymlink())  {\n       builder.setSymlink(getByteString(fs.getSymlinkInBytes()));\n     }\n     if (fs.getFileEncryptionInfo() !\u003d null) {\n       builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n     }\n-    if (fs instanceof HdfsLocatedFileStatus) {\n-      final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n-      LocatedBlocks locations \u003d lfs.getBlockLocations();\n-      if (locations !\u003d null) {\n-        builder.setLocations(convert(locations));\n-      }\n+    LocatedBlocks locations \u003d fs.getLocatedBlocks();\n+    if (locations !\u003d null) {\n+      builder.setLocations(convert(locations));\n     }\n     if(fs.getErasureCodingPolicy() !\u003d null) {\n       builder.setEcPolicy(convertErasureCodingPolicy(\n           fs.getErasureCodingPolicy()));\n     }\n     int flags \u003d fs.hasAcl()   ? HdfsFileStatusProto.Flags.HAS_ACL_VALUE   : 0;\n     flags |\u003d fs.isEncrypted() ? HdfsFileStatusProto.Flags.HAS_CRYPT_VALUE : 0;\n     flags |\u003d fs.isErasureCoded() ? HdfsFileStatusProto.Flags.HAS_EC_VALUE : 0;\n     flags |\u003d fs.isSnapshotEnabled() ? HdfsFileStatusProto.Flags\n         .SNAPSHOT_ENABLED_VALUE : 0;\n     builder.setFlags(flags);\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDirectory()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d\n        HdfsFileStatusProto.newBuilder().\n            setLength(fs.getLen()).\n            setFileType(fType).\n            setBlockReplication(fs.getReplication()).\n            setBlocksize(fs.getBlockSize()).\n            setModificationTime(fs.getModificationTime()).\n            setAccessTime(fs.getAccessTime()).\n            setPermission(convert(fs.getPermission())).\n            setOwner(fs.getOwner()).\n            setGroup(fs.getGroup()).\n            setFileId(fs.getFileId()).\n            setChildrenNum(fs.getChildrenNum()).\n            setPath(getByteString(fs.getLocalNameInBytes())).\n            setStoragePolicy(fs.getStoragePolicy());\n    if (fs.isSymlink())  {\n      builder.setSymlink(getByteString(fs.getSymlinkInBytes()));\n    }\n    if (fs.getFileEncryptionInfo() !\u003d null) {\n      builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n    }\n    LocatedBlocks locations \u003d fs.getLocatedBlocks();\n    if (locations !\u003d null) {\n      builder.setLocations(convert(locations));\n    }\n    if(fs.getErasureCodingPolicy() !\u003d null) {\n      builder.setEcPolicy(convertErasureCodingPolicy(\n          fs.getErasureCodingPolicy()));\n    }\n    int flags \u003d fs.hasAcl()   ? HdfsFileStatusProto.Flags.HAS_ACL_VALUE   : 0;\n    flags |\u003d fs.isEncrypted() ? HdfsFileStatusProto.Flags.HAS_CRYPT_VALUE : 0;\n    flags |\u003d fs.isErasureCoded() ? HdfsFileStatusProto.Flags.HAS_EC_VALUE : 0;\n    flags |\u003d fs.isSnapshotEnabled() ? HdfsFileStatusProto.Flags\n        .SNAPSHOT_ENABLED_VALUE : 0;\n    builder.setFlags(flags);\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "107c177782a24a16c66113841f2fc5144f56207b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12455. WebHDFS - Adding \"snapshot enabled\" status to ListStatus query result. Contributed by Ajay Kumar.\n",
      "commitDate": "03/10/17 1:02 PM",
      "commitName": "107c177782a24a16c66113841f2fc5144f56207b",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "20/09/17 11:51 AM",
      "commitNameOld": "a12f09ba3c4a3aa4c4558090c5e1b7bcaebe3b94",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 13.05,
      "commitsBetweenForRepo": 85,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,50 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDirectory()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d\n         HdfsFileStatusProto.newBuilder().\n             setLength(fs.getLen()).\n             setFileType(fType).\n             setBlockReplication(fs.getReplication()).\n             setBlocksize(fs.getBlockSize()).\n             setModificationTime(fs.getModificationTime()).\n             setAccessTime(fs.getAccessTime()).\n             setPermission(convert(fs.getPermission())).\n             setOwner(fs.getOwner()).\n             setGroup(fs.getGroup()).\n             setFileId(fs.getFileId()).\n             setChildrenNum(fs.getChildrenNum()).\n             setPath(getByteString(fs.getLocalNameInBytes())).\n             setStoragePolicy(fs.getStoragePolicy());\n     if (fs.isSymlink())  {\n       builder.setSymlink(getByteString(fs.getSymlinkInBytes()));\n     }\n     if (fs.getFileEncryptionInfo() !\u003d null) {\n       builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n     }\n     if (fs instanceof HdfsLocatedFileStatus) {\n       final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n       LocatedBlocks locations \u003d lfs.getBlockLocations();\n       if (locations !\u003d null) {\n         builder.setLocations(convert(locations));\n       }\n     }\n     if(fs.getErasureCodingPolicy() !\u003d null) {\n       builder.setEcPolicy(convertErasureCodingPolicy(\n           fs.getErasureCodingPolicy()));\n     }\n     int flags \u003d fs.hasAcl()   ? HdfsFileStatusProto.Flags.HAS_ACL_VALUE   : 0;\n     flags |\u003d fs.isEncrypted() ? HdfsFileStatusProto.Flags.HAS_CRYPT_VALUE : 0;\n     flags |\u003d fs.isErasureCoded() ? HdfsFileStatusProto.Flags.HAS_EC_VALUE : 0;\n+    flags |\u003d fs.isSnapshotEnabled() ? HdfsFileStatusProto.Flags\n+        .SNAPSHOT_ENABLED_VALUE : 0;\n     builder.setFlags(flags);\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDirectory()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d\n        HdfsFileStatusProto.newBuilder().\n            setLength(fs.getLen()).\n            setFileType(fType).\n            setBlockReplication(fs.getReplication()).\n            setBlocksize(fs.getBlockSize()).\n            setModificationTime(fs.getModificationTime()).\n            setAccessTime(fs.getAccessTime()).\n            setPermission(convert(fs.getPermission())).\n            setOwner(fs.getOwner()).\n            setGroup(fs.getGroup()).\n            setFileId(fs.getFileId()).\n            setChildrenNum(fs.getChildrenNum()).\n            setPath(getByteString(fs.getLocalNameInBytes())).\n            setStoragePolicy(fs.getStoragePolicy());\n    if (fs.isSymlink())  {\n      builder.setSymlink(getByteString(fs.getSymlinkInBytes()));\n    }\n    if (fs.getFileEncryptionInfo() !\u003d null) {\n      builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n      LocatedBlocks locations \u003d lfs.getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(convert(locations));\n      }\n    }\n    if(fs.getErasureCodingPolicy() !\u003d null) {\n      builder.setEcPolicy(convertErasureCodingPolicy(\n          fs.getErasureCodingPolicy()));\n    }\n    int flags \u003d fs.hasAcl()   ? HdfsFileStatusProto.Flags.HAS_ACL_VALUE   : 0;\n    flags |\u003d fs.isEncrypted() ? HdfsFileStatusProto.Flags.HAS_CRYPT_VALUE : 0;\n    flags |\u003d fs.isErasureCoded() ? HdfsFileStatusProto.Flags.HAS_EC_VALUE : 0;\n    flags |\u003d fs.isSnapshotEnabled() ? HdfsFileStatusProto.Flags\n        .SNAPSHOT_ENABLED_VALUE : 0;\n    builder.setFlags(flags);\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "645a8f2a4d09acb5a21820f52ee78784d9e4cc8a": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14726. Mark FileStatus::isDir as final\n",
      "commitDate": "14/08/17 9:57 PM",
      "commitName": "645a8f2a4d09acb5a21820f52ee78784d9e4cc8a",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "02/08/17 12:12 PM",
      "commitNameOld": "12e44e7bdaf53d3720a89d32f0cc2717241bd6b2",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 12.41,
      "commitsBetweenForRepo": 83,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,48 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_FILE;\n-    if (fs.isDir()) {\n+    if (fs.isDirectory()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d\n         HdfsFileStatusProto.newBuilder().\n             setLength(fs.getLen()).\n             setFileType(fType).\n             setBlockReplication(fs.getReplication()).\n             setBlocksize(fs.getBlockSize()).\n             setModificationTime(fs.getModificationTime()).\n             setAccessTime(fs.getAccessTime()).\n             setPermission(convert(fs.getPermission())).\n             setOwner(fs.getOwner()).\n             setGroup(fs.getGroup()).\n             setFileId(fs.getFileId()).\n             setChildrenNum(fs.getChildrenNum()).\n             setPath(getByteString(fs.getLocalNameInBytes())).\n             setStoragePolicy(fs.getStoragePolicy());\n     if (fs.isSymlink())  {\n       builder.setSymlink(getByteString(fs.getSymlinkInBytes()));\n     }\n     if (fs.getFileEncryptionInfo() !\u003d null) {\n       builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n     }\n     if (fs instanceof HdfsLocatedFileStatus) {\n       final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n       LocatedBlocks locations \u003d lfs.getBlockLocations();\n       if (locations !\u003d null) {\n         builder.setLocations(convert(locations));\n       }\n     }\n     if(fs.getErasureCodingPolicy() !\u003d null) {\n       builder.setEcPolicy(convertErasureCodingPolicy(\n           fs.getErasureCodingPolicy()));\n     }\n     int flags \u003d fs.hasAcl()   ? HdfsFileStatusProto.Flags.HAS_ACL_VALUE   : 0;\n     flags |\u003d fs.isEncrypted() ? HdfsFileStatusProto.Flags.HAS_CRYPT_VALUE : 0;\n     flags |\u003d fs.isErasureCoded() ? HdfsFileStatusProto.Flags.HAS_EC_VALUE : 0;\n     builder.setFlags(flags);\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDirectory()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d\n        HdfsFileStatusProto.newBuilder().\n            setLength(fs.getLen()).\n            setFileType(fType).\n            setBlockReplication(fs.getReplication()).\n            setBlocksize(fs.getBlockSize()).\n            setModificationTime(fs.getModificationTime()).\n            setAccessTime(fs.getAccessTime()).\n            setPermission(convert(fs.getPermission())).\n            setOwner(fs.getOwner()).\n            setGroup(fs.getGroup()).\n            setFileId(fs.getFileId()).\n            setChildrenNum(fs.getChildrenNum()).\n            setPath(getByteString(fs.getLocalNameInBytes())).\n            setStoragePolicy(fs.getStoragePolicy());\n    if (fs.isSymlink())  {\n      builder.setSymlink(getByteString(fs.getSymlinkInBytes()));\n    }\n    if (fs.getFileEncryptionInfo() !\u003d null) {\n      builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n      LocatedBlocks locations \u003d lfs.getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(convert(locations));\n      }\n    }\n    if(fs.getErasureCodingPolicy() !\u003d null) {\n      builder.setEcPolicy(convertErasureCodingPolicy(\n          fs.getErasureCodingPolicy()));\n    }\n    int flags \u003d fs.hasAcl()   ? HdfsFileStatusProto.Flags.HAS_ACL_VALUE   : 0;\n    flags |\u003d fs.isEncrypted() ? HdfsFileStatusProto.Flags.HAS_CRYPT_VALUE : 0;\n    flags |\u003d fs.isErasureCoded() ? HdfsFileStatusProto.Flags.HAS_EC_VALUE : 0;\n    builder.setFlags(flags);\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "12e44e7bdaf53d3720a89d32f0cc2717241bd6b2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6984. Serialize FileStatus via protobuf.\n",
      "commitDate": "02/08/17 12:12 PM",
      "commitName": "12e44e7bdaf53d3720a89d32f0cc2717241bd6b2",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "29/06/17 6:38 AM",
      "commitNameOld": "16c8dbde574f49827fde5ee9add1861ee65d4645",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 34.23,
      "commitsBetweenForRepo": 222,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,48 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d\n         HdfsFileStatusProto.newBuilder().\n             setLength(fs.getLen()).\n             setFileType(fType).\n             setBlockReplication(fs.getReplication()).\n             setBlocksize(fs.getBlockSize()).\n             setModificationTime(fs.getModificationTime()).\n             setAccessTime(fs.getAccessTime()).\n             setPermission(convert(fs.getPermission())).\n             setOwner(fs.getOwner()).\n             setGroup(fs.getGroup()).\n             setFileId(fs.getFileId()).\n             setChildrenNum(fs.getChildrenNum()).\n             setPath(getByteString(fs.getLocalNameInBytes())).\n             setStoragePolicy(fs.getStoragePolicy());\n     if (fs.isSymlink())  {\n       builder.setSymlink(getByteString(fs.getSymlinkInBytes()));\n     }\n     if (fs.getFileEncryptionInfo() !\u003d null) {\n       builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n     }\n     if (fs instanceof HdfsLocatedFileStatus) {\n       final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n       LocatedBlocks locations \u003d lfs.getBlockLocations();\n       if (locations !\u003d null) {\n         builder.setLocations(convert(locations));\n       }\n     }\n     if(fs.getErasureCodingPolicy() !\u003d null) {\n       builder.setEcPolicy(convertErasureCodingPolicy(\n           fs.getErasureCodingPolicy()));\n     }\n+    int flags \u003d fs.hasAcl()   ? HdfsFileStatusProto.Flags.HAS_ACL_VALUE   : 0;\n+    flags |\u003d fs.isEncrypted() ? HdfsFileStatusProto.Flags.HAS_CRYPT_VALUE : 0;\n+    flags |\u003d fs.isErasureCoded() ? HdfsFileStatusProto.Flags.HAS_EC_VALUE : 0;\n+    builder.setFlags(flags);\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d\n        HdfsFileStatusProto.newBuilder().\n            setLength(fs.getLen()).\n            setFileType(fType).\n            setBlockReplication(fs.getReplication()).\n            setBlocksize(fs.getBlockSize()).\n            setModificationTime(fs.getModificationTime()).\n            setAccessTime(fs.getAccessTime()).\n            setPermission(convert(fs.getPermission())).\n            setOwner(fs.getOwner()).\n            setGroup(fs.getGroup()).\n            setFileId(fs.getFileId()).\n            setChildrenNum(fs.getChildrenNum()).\n            setPath(getByteString(fs.getLocalNameInBytes())).\n            setStoragePolicy(fs.getStoragePolicy());\n    if (fs.isSymlink())  {\n      builder.setSymlink(getByteString(fs.getSymlinkInBytes()));\n    }\n    if (fs.getFileEncryptionInfo() !\u003d null) {\n      builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n      LocatedBlocks locations \u003d lfs.getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(convert(locations));\n      }\n    }\n    if(fs.getErasureCodingPolicy() !\u003d null) {\n      builder.setEcPolicy(convertErasureCodingPolicy(\n          fs.getErasureCodingPolicy()));\n    }\n    int flags \u003d fs.hasAcl()   ? HdfsFileStatusProto.Flags.HAS_ACL_VALUE   : 0;\n    flags |\u003d fs.isEncrypted() ? HdfsFileStatusProto.Flags.HAS_CRYPT_VALUE : 0;\n    flags |\u003d fs.isErasureCoded() ? HdfsFileStatusProto.Flags.HAS_EC_VALUE : 0;\n    builder.setFlags(flags);\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "c470c8953d4927043b6383fad8e792289c634c09": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9557. Reduce object allocation in PB conversion. Contributed by Daryn Sharp.\n",
      "commitDate": "16/12/15 11:10 AM",
      "commitName": "c470c8953d4927043b6383fad8e792289c634c09",
      "commitAuthor": "cnauroth",
      "commitDateOld": "23/11/15 10:50 AM",
      "commitNameOld": "298a8cb096906b5d688842f6520e90dc9779f0b3",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 23.01,
      "commitsBetweenForRepo": 138,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d\n         HdfsFileStatusProto.newBuilder().\n             setLength(fs.getLen()).\n             setFileType(fType).\n             setBlockReplication(fs.getReplication()).\n             setBlocksize(fs.getBlockSize()).\n             setModificationTime(fs.getModificationTime()).\n             setAccessTime(fs.getAccessTime()).\n             setPermission(convert(fs.getPermission())).\n             setOwner(fs.getOwner()).\n             setGroup(fs.getGroup()).\n             setFileId(fs.getFileId()).\n             setChildrenNum(fs.getChildrenNum()).\n-            setPath(ByteString.copyFrom(fs.getLocalNameInBytes())).\n+            setPath(getByteString(fs.getLocalNameInBytes())).\n             setStoragePolicy(fs.getStoragePolicy());\n     if (fs.isSymlink())  {\n-      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n+      builder.setSymlink(getByteString(fs.getSymlinkInBytes()));\n     }\n     if (fs.getFileEncryptionInfo() !\u003d null) {\n       builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n     }\n     if (fs instanceof HdfsLocatedFileStatus) {\n       final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n       LocatedBlocks locations \u003d lfs.getBlockLocations();\n       if (locations !\u003d null) {\n         builder.setLocations(convert(locations));\n       }\n     }\n     if(fs.getErasureCodingPolicy() !\u003d null) {\n       builder.setEcPolicy(convertErasureCodingPolicy(\n           fs.getErasureCodingPolicy()));\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d\n        HdfsFileStatusProto.newBuilder().\n            setLength(fs.getLen()).\n            setFileType(fType).\n            setBlockReplication(fs.getReplication()).\n            setBlocksize(fs.getBlockSize()).\n            setModificationTime(fs.getModificationTime()).\n            setAccessTime(fs.getAccessTime()).\n            setPermission(convert(fs.getPermission())).\n            setOwner(fs.getOwner()).\n            setGroup(fs.getGroup()).\n            setFileId(fs.getFileId()).\n            setChildrenNum(fs.getChildrenNum()).\n            setPath(getByteString(fs.getLocalNameInBytes())).\n            setStoragePolicy(fs.getStoragePolicy());\n    if (fs.isSymlink())  {\n      builder.setSymlink(getByteString(fs.getSymlinkInBytes()));\n    }\n    if (fs.getFileEncryptionInfo() !\u003d null) {\n      builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n      LocatedBlocks locations \u003d lfs.getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(convert(locations));\n      }\n    }\n    if(fs.getErasureCodingPolicy() !\u003d null) {\n      builder.setEcPolicy(convertErasureCodingPolicy(\n          fs.getErasureCodingPolicy()));\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "06022b8fdc40e50eaac63758246353058e8cfa6d": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-9111. Move hdfs-client protobuf convert methods from PBHelper to PBHelperClient. Contributed by Mingliang Liu.\n",
      "commitDate": "21/09/15 6:53 PM",
      "commitName": "06022b8fdc40e50eaac63758246353058e8cfa6d",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-9111. Move hdfs-client protobuf convert methods from PBHelper to PBHelperClient. Contributed by Mingliang Liu.\n",
          "commitDate": "21/09/15 6:53 PM",
          "commitName": "06022b8fdc40e50eaac63758246353058e8cfa6d",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "21/09/15 5:51 PM",
          "commitNameOld": "8e01b0d97ac3d74b049a801dfa1cc6e77d8f680a",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,40 +1,40 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n-    HdfsFileStatusProto.Builder builder \u003d \n+    HdfsFileStatusProto.Builder builder \u003d\n      HdfsFileStatusProto.newBuilder().\n       setLength(fs.getLen()).\n       setFileType(fType).\n       setBlockReplication(fs.getReplication()).\n       setBlocksize(fs.getBlockSize()).\n       setModificationTime(fs.getModificationTime()).\n       setAccessTime(fs.getAccessTime()).\n-      setPermission(PBHelper.convert(fs.getPermission())).\n+      setPermission(convert(fs.getPermission())).\n       setOwner(fs.getOwner()).\n       setGroup(fs.getGroup()).\n       setFileId(fs.getFileId()).\n       setChildrenNum(fs.getChildrenNum()).\n       setPath(ByteString.copyFrom(fs.getLocalNameInBytes())).\n       setStoragePolicy(fs.getStoragePolicy());\n     if (fs.isSymlink())  {\n       builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n     }\n     if (fs.getFileEncryptionInfo() !\u003d null) {\n       builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n     }\n     if (fs instanceof HdfsLocatedFileStatus) {\n       final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n       LocatedBlocks locations \u003d lfs.getBlockLocations();\n       if (locations !\u003d null) {\n-        builder.setLocations(PBHelper.convert(locations));\n+        builder.setLocations(convert(locations));\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d\n     HdfsFileStatusProto.newBuilder().\n      setLength(fs.getLen()).\n      setFileType(fType).\n      setBlockReplication(fs.getReplication()).\n      setBlocksize(fs.getBlockSize()).\n      setModificationTime(fs.getModificationTime()).\n      setAccessTime(fs.getAccessTime()).\n      setPermission(convert(fs.getPermission())).\n      setOwner(fs.getOwner()).\n      setGroup(fs.getGroup()).\n      setFileId(fs.getFileId()).\n      setChildrenNum(fs.getChildrenNum()).\n      setPath(ByteString.copyFrom(fs.getLocalNameInBytes())).\n      setStoragePolicy(fs.getStoragePolicy());\n    if (fs.isSymlink())  {\n      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n    }\n    if (fs.getFileEncryptionInfo() !\u003d null) {\n      builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n      LocatedBlocks locations \u003d lfs.getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(convert(locations));\n      }\n    }\n    return builder.build();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
            "oldMethodName": "convert",
            "newMethodName": "convert"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9111. Move hdfs-client protobuf convert methods from PBHelper to PBHelperClient. Contributed by Mingliang Liu.\n",
          "commitDate": "21/09/15 6:53 PM",
          "commitName": "06022b8fdc40e50eaac63758246353058e8cfa6d",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "21/09/15 5:51 PM",
          "commitNameOld": "8e01b0d97ac3d74b049a801dfa1cc6e77d8f680a",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,40 +1,40 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n-    HdfsFileStatusProto.Builder builder \u003d \n+    HdfsFileStatusProto.Builder builder \u003d\n      HdfsFileStatusProto.newBuilder().\n       setLength(fs.getLen()).\n       setFileType(fType).\n       setBlockReplication(fs.getReplication()).\n       setBlocksize(fs.getBlockSize()).\n       setModificationTime(fs.getModificationTime()).\n       setAccessTime(fs.getAccessTime()).\n-      setPermission(PBHelper.convert(fs.getPermission())).\n+      setPermission(convert(fs.getPermission())).\n       setOwner(fs.getOwner()).\n       setGroup(fs.getGroup()).\n       setFileId(fs.getFileId()).\n       setChildrenNum(fs.getChildrenNum()).\n       setPath(ByteString.copyFrom(fs.getLocalNameInBytes())).\n       setStoragePolicy(fs.getStoragePolicy());\n     if (fs.isSymlink())  {\n       builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n     }\n     if (fs.getFileEncryptionInfo() !\u003d null) {\n       builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n     }\n     if (fs instanceof HdfsLocatedFileStatus) {\n       final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n       LocatedBlocks locations \u003d lfs.getBlockLocations();\n       if (locations !\u003d null) {\n-        builder.setLocations(PBHelper.convert(locations));\n+        builder.setLocations(convert(locations));\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d\n     HdfsFileStatusProto.newBuilder().\n      setLength(fs.getLen()).\n      setFileType(fType).\n      setBlockReplication(fs.getReplication()).\n      setBlocksize(fs.getBlockSize()).\n      setModificationTime(fs.getModificationTime()).\n      setAccessTime(fs.getAccessTime()).\n      setPermission(convert(fs.getPermission())).\n      setOwner(fs.getOwner()).\n      setGroup(fs.getGroup()).\n      setFileId(fs.getFileId()).\n      setChildrenNum(fs.getChildrenNum()).\n      setPath(ByteString.copyFrom(fs.getLocalNameInBytes())).\n      setStoragePolicy(fs.getStoragePolicy());\n    if (fs.isSymlink())  {\n      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n    }\n    if (fs.getFileEncryptionInfo() !\u003d null) {\n      builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n      LocatedBlocks locations \u003d lfs.getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(convert(locations));\n      }\n    }\n    return builder.build();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
          "extendedDetails": {}
        }
      ]
    },
    "bb84f1fccb18c6c7373851e05d2451d55e908242": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7159. Use block storage policy to set lazy persist preference. (Arpit Agarwal)\n",
      "commitDate": "29/09/14 10:27 PM",
      "commitName": "bb84f1fccb18c6c7373851e05d2451d55e908242",
      "commitAuthor": "arp",
      "commitDateOld": "25/09/14 7:50 PM",
      "commitNameOld": "032e0eba6b5acda3e33f4b99b48845eedb5ed149",
      "commitAuthorOld": "",
      "daysBetweenCommits": 4.11,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,40 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d \n      HdfsFileStatusProto.newBuilder().\n       setLength(fs.getLen()).\n       setFileType(fType).\n       setBlockReplication(fs.getReplication()).\n       setBlocksize(fs.getBlockSize()).\n-      setIsLazyPersist(fs.isLazyPersist()).\n       setModificationTime(fs.getModificationTime()).\n       setAccessTime(fs.getAccessTime()).\n       setPermission(PBHelper.convert(fs.getPermission())).\n       setOwner(fs.getOwner()).\n       setGroup(fs.getGroup()).\n       setFileId(fs.getFileId()).\n       setChildrenNum(fs.getChildrenNum()).\n       setPath(ByteString.copyFrom(fs.getLocalNameInBytes())).\n       setStoragePolicy(fs.getStoragePolicy());\n     if (fs.isSymlink())  {\n       builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n     }\n     if (fs.getFileEncryptionInfo() !\u003d null) {\n       builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n     }\n     if (fs instanceof HdfsLocatedFileStatus) {\n       final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n       LocatedBlocks locations \u003d lfs.getBlockLocations();\n       if (locations !\u003d null) {\n         builder.setLocations(PBHelper.convert(locations));\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d \n     HdfsFileStatusProto.newBuilder().\n      setLength(fs.getLen()).\n      setFileType(fType).\n      setBlockReplication(fs.getReplication()).\n      setBlocksize(fs.getBlockSize()).\n      setModificationTime(fs.getModificationTime()).\n      setAccessTime(fs.getAccessTime()).\n      setPermission(PBHelper.convert(fs.getPermission())).\n      setOwner(fs.getOwner()).\n      setGroup(fs.getGroup()).\n      setFileId(fs.getFileId()).\n      setChildrenNum(fs.getChildrenNum()).\n      setPath(ByteString.copyFrom(fs.getLocalNameInBytes())).\n      setStoragePolicy(fs.getStoragePolicy());\n    if (fs.isSymlink())  {\n      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n    }\n    if (fs.getFileEncryptionInfo() !\u003d null) {\n      builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n      LocatedBlocks locations \u003d lfs.getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(PBHelper.convert(locations));\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "a7bcc9535860214380e235641d1d5d2dd15aee58": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6921. Add LazyPersist flag to FileStatus. (Arpit Agarwal)\n",
      "commitDate": "27/08/14 9:47 PM",
      "commitName": "a7bcc9535860214380e235641d1d5d2dd15aee58",
      "commitAuthor": "arp",
      "commitDateOld": "04/08/14 7:30 PM",
      "commitNameOld": "ac73d416f3cfbc9561286ce4bc7624113db4e751",
      "commitAuthorOld": "",
      "daysBetweenCommits": 23.09,
      "commitsBetweenForRepo": 190,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,39 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d \n      HdfsFileStatusProto.newBuilder().\n       setLength(fs.getLen()).\n       setFileType(fType).\n       setBlockReplication(fs.getReplication()).\n       setBlocksize(fs.getBlockSize()).\n+      setIsLazyPersist(fs.isLazyPersist()).\n       setModificationTime(fs.getModificationTime()).\n       setAccessTime(fs.getAccessTime()).\n       setPermission(PBHelper.convert(fs.getPermission())).\n       setOwner(fs.getOwner()).\n       setGroup(fs.getGroup()).\n       setFileId(fs.getFileId()).\n       setChildrenNum(fs.getChildrenNum()).\n       setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n     if (fs.isSymlink())  {\n       builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n     }\n     if (fs.getFileEncryptionInfo() !\u003d null) {\n       builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n     }\n     if (fs instanceof HdfsLocatedFileStatus) {\n       LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n       if (locations !\u003d null) {\n         builder.setLocations(PBHelper.convert(locations));\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d \n     HdfsFileStatusProto.newBuilder().\n      setLength(fs.getLen()).\n      setFileType(fType).\n      setBlockReplication(fs.getReplication()).\n      setBlocksize(fs.getBlockSize()).\n      setIsLazyPersist(fs.isLazyPersist()).\n      setModificationTime(fs.getModificationTime()).\n      setAccessTime(fs.getAccessTime()).\n      setPermission(PBHelper.convert(fs.getPermission())).\n      setOwner(fs.getOwner()).\n      setGroup(fs.getGroup()).\n      setFileId(fs.getFileId()).\n      setChildrenNum(fs.getChildrenNum()).\n      setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n    if (fs.isSymlink())  {\n      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n    }\n    if (fs.getFileEncryptionInfo() !\u003d null) {\n      builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(PBHelper.convert(locations));\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "9b250d74f029f8ccf3a613f9fb74f59838a66ec1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6847. Support storage policy on directories and include storage policy in HdfsFileStatus.  Contributed by Jing Zhao\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-6584@1618416 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/08/14 1:58 PM",
      "commitName": "9b250d74f029f8ccf3a613f9fb74f59838a66ec1",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "31/07/14 6:29 PM",
      "commitNameOld": "dc7744d2e50350fb9ac5f2a1f761cdc63b220899",
      "commitAuthorOld": "",
      "daysBetweenCommits": 15.81,
      "commitsBetweenForRepo": 87,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,37 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d \n      HdfsFileStatusProto.newBuilder().\n       setLength(fs.getLen()).\n       setFileType(fType).\n       setBlockReplication(fs.getReplication()).\n       setBlocksize(fs.getBlockSize()).\n       setModificationTime(fs.getModificationTime()).\n       setAccessTime(fs.getAccessTime()).\n       setPermission(PBHelper.convert(fs.getPermission())).\n       setOwner(fs.getOwner()).\n       setGroup(fs.getGroup()).\n       setFileId(fs.getFileId()).\n       setChildrenNum(fs.getChildrenNum()).\n-      setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n+      setPath(ByteString.copyFrom(fs.getLocalNameInBytes())).\n+      setStoragePolicy(fs.getStoragePolicy());\n     if (fs.isSymlink())  {\n       builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n     }\n     if (fs instanceof HdfsLocatedFileStatus) {\n-      LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n+      final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n+      LocatedBlocks locations \u003d lfs.getBlockLocations();\n       if (locations !\u003d null) {\n         builder.setLocations(PBHelper.convert(locations));\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d \n     HdfsFileStatusProto.newBuilder().\n      setLength(fs.getLen()).\n      setFileType(fType).\n      setBlockReplication(fs.getReplication()).\n      setBlocksize(fs.getBlockSize()).\n      setModificationTime(fs.getModificationTime()).\n      setAccessTime(fs.getAccessTime()).\n      setPermission(PBHelper.convert(fs.getPermission())).\n      setOwner(fs.getOwner()).\n      setGroup(fs.getGroup()).\n      setFileId(fs.getFileId()).\n      setChildrenNum(fs.getChildrenNum()).\n      setPath(ByteString.copyFrom(fs.getLocalNameInBytes())).\n      setStoragePolicy(fs.getStoragePolicy());\n    if (fs.isSymlink())  {\n      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      final HdfsLocatedFileStatus lfs \u003d (HdfsLocatedFileStatus) fs;\n      LocatedBlocks locations \u003d lfs.getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(PBHelper.convert(locations));\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "2efea952139b30dd1c881eed0b443ffa72be6dce": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6391. Get the Key/IV from the NameNode for encrypted files in DFSClient. Contributed by Charles Lamb and Andrew Wang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/fs-encryption@1606220 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/06/14 1:43 PM",
      "commitName": "2efea952139b30dd1c881eed0b443ffa72be6dce",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "19/06/14 11:32 AM",
      "commitNameOld": "97583dbb0a07ac054c06c1a317855110c8629ab3",
      "commitAuthorOld": "",
      "daysBetweenCommits": 8.09,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,38 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d \n      HdfsFileStatusProto.newBuilder().\n       setLength(fs.getLen()).\n       setFileType(fType).\n       setBlockReplication(fs.getReplication()).\n       setBlocksize(fs.getBlockSize()).\n       setModificationTime(fs.getModificationTime()).\n       setAccessTime(fs.getAccessTime()).\n       setPermission(PBHelper.convert(fs.getPermission())).\n       setOwner(fs.getOwner()).\n       setGroup(fs.getGroup()).\n       setFileId(fs.getFileId()).\n       setChildrenNum(fs.getChildrenNum()).\n       setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n     if (fs.isSymlink())  {\n       builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n     }\n-    if (fs.getKey() !\u003d null) {\n-      builder.setKey(ByteString.copyFrom(fs.getKey()));\n-    }\n-    if (fs.getIv() !\u003d null) {\n-      builder.setIv(ByteString.copyFrom(fs.getIv()));\n+    if (fs.getFileEncryptionInfo() !\u003d null) {\n+      builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n     }\n     if (fs instanceof HdfsLocatedFileStatus) {\n       LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n       if (locations !\u003d null) {\n         builder.setLocations(PBHelper.convert(locations));\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d \n     HdfsFileStatusProto.newBuilder().\n      setLength(fs.getLen()).\n      setFileType(fType).\n      setBlockReplication(fs.getReplication()).\n      setBlocksize(fs.getBlockSize()).\n      setModificationTime(fs.getModificationTime()).\n      setAccessTime(fs.getAccessTime()).\n      setPermission(PBHelper.convert(fs.getPermission())).\n      setOwner(fs.getOwner()).\n      setGroup(fs.getGroup()).\n      setFileId(fs.getFileId()).\n      setChildrenNum(fs.getChildrenNum()).\n      setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n    if (fs.isSymlink())  {\n      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n    }\n    if (fs.getFileEncryptionInfo() !\u003d null) {\n      builder.setFileEncryptionInfo(convert(fs.getFileEncryptionInfo()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(PBHelper.convert(locations));\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "bdee397e95e98ece071345822e2e4d3f690f09c3": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-6392. Wire crypto streams for encrypted files in DFSClient. (clamb and yliu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/fs-encryption@1600582 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/06/14 3:10 AM",
      "commitName": "bdee397e95e98ece071345822e2e4d3f690f09c3",
      "commitAuthor": "Charles Lamb",
      "commitDateOld": "21/05/14 6:57 AM",
      "commitNameOld": "ac23a55547716df29b3e25c98a113399e184d9d1",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 14.84,
      "commitsBetweenForRepo": 63,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,41 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d \n      HdfsFileStatusProto.newBuilder().\n       setLength(fs.getLen()).\n       setFileType(fType).\n       setBlockReplication(fs.getReplication()).\n       setBlocksize(fs.getBlockSize()).\n       setModificationTime(fs.getModificationTime()).\n       setAccessTime(fs.getAccessTime()).\n       setPermission(PBHelper.convert(fs.getPermission())).\n       setOwner(fs.getOwner()).\n       setGroup(fs.getGroup()).\n       setFileId(fs.getFileId()).\n       setChildrenNum(fs.getChildrenNum()).\n       setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n     if (fs.isSymlink())  {\n       builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n     }\n+    if (fs.getKey() !\u003d null) {\n+      builder.setKey(ByteString.copyFrom(fs.getKey()));\n+    }\n+    if (fs.getIv() !\u003d null) {\n+      builder.setIv(ByteString.copyFrom(fs.getIv()));\n+    }\n     if (fs instanceof HdfsLocatedFileStatus) {\n       LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n       if (locations !\u003d null) {\n         builder.setLocations(PBHelper.convert(locations));\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d \n     HdfsFileStatusProto.newBuilder().\n      setLength(fs.getLen()).\n      setFileType(fType).\n      setBlockReplication(fs.getReplication()).\n      setBlocksize(fs.getBlockSize()).\n      setModificationTime(fs.getModificationTime()).\n      setAccessTime(fs.getAccessTime()).\n      setPermission(PBHelper.convert(fs.getPermission())).\n      setOwner(fs.getOwner()).\n      setGroup(fs.getGroup()).\n      setFileId(fs.getFileId()).\n      setChildrenNum(fs.getChildrenNum()).\n      setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n    if (fs.isSymlink())  {\n      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n    }\n    if (fs.getKey() !\u003d null) {\n      builder.setKey(ByteString.copyFrom(fs.getKey()));\n    }\n    if (fs.getIv() !\u003d null) {\n      builder.setIv(ByteString.copyFrom(fs.getIv()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(PBHelper.convert(locations));\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "6ecf78a99b4b10d4c569cc2b335060ab988b8001": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4772. Add number of children in HdfsFileStatus. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1495253 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/06/13 5:32 PM",
      "commitName": "6ecf78a99b4b10d4c569cc2b335060ab988b8001",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "14/02/13 3:07 PM",
      "commitNameOld": "d9e2514d21c2ae356ee7fe8d4a857748b5defa4c",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 126.06,
      "commitsBetweenForRepo": 784,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,35 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d \n      HdfsFileStatusProto.newBuilder().\n       setLength(fs.getLen()).\n       setFileType(fType).\n       setBlockReplication(fs.getReplication()).\n       setBlocksize(fs.getBlockSize()).\n       setModificationTime(fs.getModificationTime()).\n       setAccessTime(fs.getAccessTime()).\n       setPermission(PBHelper.convert(fs.getPermission())).\n       setOwner(fs.getOwner()).\n       setGroup(fs.getGroup()).\n       setFileId(fs.getFileId()).\n+      setChildrenNum(fs.getChildrenNum()).\n       setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n     if (fs.isSymlink())  {\n       builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n     }\n     if (fs instanceof HdfsLocatedFileStatus) {\n       LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n       if (locations !\u003d null) {\n         builder.setLocations(PBHelper.convert(locations));\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d \n     HdfsFileStatusProto.newBuilder().\n      setLength(fs.getLen()).\n      setFileType(fType).\n      setBlockReplication(fs.getReplication()).\n      setBlocksize(fs.getBlockSize()).\n      setModificationTime(fs.getModificationTime()).\n      setAccessTime(fs.getAccessTime()).\n      setPermission(PBHelper.convert(fs.getPermission())).\n      setOwner(fs.getOwner()).\n      setGroup(fs.getGroup()).\n      setFileId(fs.getFileId()).\n      setChildrenNum(fs.getChildrenNum()).\n      setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n    if (fs.isSymlink())  {\n      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(PBHelper.convert(locations));\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "4525c4a25ba90163c9543116e2bd54239e0dd097": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4340. Update addBlock() to inculde inode id as additional argument. Contributed Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1443169 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/02/13 11:52 AM",
      "commitName": "4525c4a25ba90163c9543116e2bd54239e0dd097",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "09/01/13 2:29 PM",
      "commitNameOld": "3555e7c574de5a6d163c5375a31de290776b2ab0",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 27.89,
      "commitsBetweenForRepo": 147,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,34 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d \n      HdfsFileStatusProto.newBuilder().\n       setLength(fs.getLen()).\n       setFileType(fType).\n       setBlockReplication(fs.getReplication()).\n       setBlocksize(fs.getBlockSize()).\n       setModificationTime(fs.getModificationTime()).\n       setAccessTime(fs.getAccessTime()).\n       setPermission(PBHelper.convert(fs.getPermission())).\n       setOwner(fs.getOwner()).\n       setGroup(fs.getGroup()).\n+      setFileId(fs.getFileId()).\n       setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n     if (fs.isSymlink())  {\n       builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n     }\n     if (fs instanceof HdfsLocatedFileStatus) {\n       LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n       if (locations !\u003d null) {\n         builder.setLocations(PBHelper.convert(locations));\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d \n     HdfsFileStatusProto.newBuilder().\n      setLength(fs.getLen()).\n      setFileType(fType).\n      setBlockReplication(fs.getReplication()).\n      setBlocksize(fs.getBlockSize()).\n      setModificationTime(fs.getModificationTime()).\n      setAccessTime(fs.getAccessTime()).\n      setPermission(PBHelper.convert(fs.getPermission())).\n      setOwner(fs.getOwner()).\n      setGroup(fs.getGroup()).\n      setFileId(fs.getFileId()).\n      setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n    if (fs.isSymlink())  {\n      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(PBHelper.convert(locations));\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "8134b1c8702d7d6b3994c73b34afc7f8ee33ac6e": {
      "type": "Ybodychange",
      "commitMessage": "Merge trunk into HA branch.\n\nSeveral conflicts around introduction of protobuf translator for DatanodeProtocol - mostly trivial resolutions.\n\nNB: this does not successfully pass any tests since the HAStatus field needs\nto be integrated into the HeartbeatResponse Protobuf implementation.\nThat will be a separate commit for clearer history.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1214518 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/12/11 2:47 PM",
      "commitName": "8134b1c8702d7d6b3994c73b34afc7f8ee33ac6e",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "13/12/11 11:02 AM",
      "commitNameOld": "a0fe4f476ae907c9c070af48a250739a4fb33362",
      "commitAuthorOld": "",
      "daysBetweenCommits": 1.16,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,33 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n-    FileType fType \u003d FileType.IS_DIR;;\n+    FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d \n      HdfsFileStatusProto.newBuilder().\n       setLength(fs.getLen()).\n       setFileType(fType).\n       setBlockReplication(fs.getReplication()).\n       setBlocksize(fs.getBlockSize()).\n       setModificationTime(fs.getModificationTime()).\n       setAccessTime(fs.getAccessTime()).\n       setPermission(PBHelper.convert(fs.getPermission())).\n       setOwner(fs.getOwner()).\n       setGroup(fs.getGroup()).\n       setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n-    \n-    if (fs.getSymlink() !\u003d null) {\n+    if (fs.isSymlink())  {\n       builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n     }\n     if (fs instanceof HdfsLocatedFileStatus) {\n       LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n       if (locations !\u003d null) {\n         builder.setLocations(PBHelper.convert(locations));\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d \n     HdfsFileStatusProto.newBuilder().\n      setLength(fs.getLen()).\n      setFileType(fType).\n      setBlockReplication(fs.getReplication()).\n      setBlocksize(fs.getBlockSize()).\n      setModificationTime(fs.getModificationTime()).\n      setAccessTime(fs.getAccessTime()).\n      setPermission(PBHelper.convert(fs.getPermission())).\n      setOwner(fs.getOwner()).\n      setGroup(fs.getGroup()).\n      setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n    if (fs.isSymlink())  {\n      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(PBHelper.convert(locations));\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "d8dfcdcbc2e2df3aa1d7b309f263434739475e7e": {
      "type": "Ybodychange",
      "commitMessage": "    HDFS-2669 Enable protobuf rpc for ClientNamenodeProtocol\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1214128 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/12/11 1:27 AM",
      "commitName": "d8dfcdcbc2e2df3aa1d7b309f263434739475e7e",
      "commitAuthor": "Sanjay Radia",
      "commitDateOld": "13/12/11 6:15 PM",
      "commitNameOld": "3cffe34177c72ea67194c3b0aaf0ddbf67ff3a0c",
      "commitAuthorOld": "Jitendra Nath Pandey",
      "daysBetweenCommits": 0.3,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,33 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n-    FileType fType \u003d FileType.IS_DIR;;\n+    FileType fType \u003d FileType.IS_FILE;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d \n      HdfsFileStatusProto.newBuilder().\n       setLength(fs.getLen()).\n       setFileType(fType).\n       setBlockReplication(fs.getReplication()).\n       setBlocksize(fs.getBlockSize()).\n       setModificationTime(fs.getModificationTime()).\n       setAccessTime(fs.getAccessTime()).\n       setPermission(PBHelper.convert(fs.getPermission())).\n       setOwner(fs.getOwner()).\n       setGroup(fs.getGroup()).\n       setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n-    \n-    if (fs.getSymlink() !\u003d null) {\n+    if (fs.isSymlink())  {\n       builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n     }\n     if (fs instanceof HdfsLocatedFileStatus) {\n       LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n       if (locations !\u003d null) {\n         builder.setLocations(PBHelper.convert(locations));\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_FILE;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d \n     HdfsFileStatusProto.newBuilder().\n      setLength(fs.getLen()).\n      setFileType(fType).\n      setBlockReplication(fs.getReplication()).\n      setBlocksize(fs.getBlockSize()).\n      setModificationTime(fs.getModificationTime()).\n      setAccessTime(fs.getAccessTime()).\n      setPermission(PBHelper.convert(fs.getPermission())).\n      setOwner(fs.getOwner()).\n      setGroup(fs.getGroup()).\n      setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n    if (fs.isSymlink())  {\n      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(PBHelper.convert(locations));\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "3954a2fb1cbc7a8a0d1ad5859e7f5c9415530f4c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2663. Optional protobuf parameters are not handled correctly. Contributed by Suresh Srinivas.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213985 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/12/11 3:31 PM",
      "commitName": "3954a2fb1cbc7a8a0d1ad5859e7f5c9415530f4c",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "13/12/11 3:27 PM",
      "commitNameOld": "6a609cb471d413b15e3659cc9d7cd6f5f3357256",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,34 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_DIR;;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d \n      HdfsFileStatusProto.newBuilder().\n       setLength(fs.getLen()).\n       setFileType(fType).\n       setBlockReplication(fs.getReplication()).\n       setBlocksize(fs.getBlockSize()).\n       setModificationTime(fs.getModificationTime()).\n       setAccessTime(fs.getAccessTime()).\n       setPermission(PBHelper.convert(fs.getPermission())).\n       setOwner(fs.getOwner()).\n       setGroup(fs.getGroup()).\n-      setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes())).\n       setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n-    LocatedBlocks locations \u003d null;\n+    \n+    if (fs.getSymlink() !\u003d null) {\n+      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n+    }\n     if (fs instanceof HdfsLocatedFileStatus) {\n-      builder.setLocations(PBHelper.convert(locations));\n+      LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n+      if (locations !\u003d null) {\n+        builder.setLocations(PBHelper.convert(locations));\n+      }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_DIR;;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d \n     HdfsFileStatusProto.newBuilder().\n      setLength(fs.getLen()).\n      setFileType(fType).\n      setBlockReplication(fs.getReplication()).\n      setBlocksize(fs.getBlockSize()).\n      setModificationTime(fs.getModificationTime()).\n      setAccessTime(fs.getAccessTime()).\n      setPermission(PBHelper.convert(fs.getPermission())).\n      setOwner(fs.getOwner()).\n      setGroup(fs.getGroup()).\n      setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n    \n    if (fs.getSymlink() !\u003d null) {\n      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(PBHelper.convert(locations));\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "6a609cb471d413b15e3659cc9d7cd6f5f3357256": {
      "type": "Ybodychange",
      "commitMessage": "Reverting the patch r1213981\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213984 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/12/11 3:27 PM",
      "commitName": "6a609cb471d413b15e3659cc9d7cd6f5f3357256",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "13/12/11 3:22 PM",
      "commitNameOld": "b5229fd19bfecc2e5249db652ad34ec08152334b",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,29 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_DIR;;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d \n      HdfsFileStatusProto.newBuilder().\n       setLength(fs.getLen()).\n       setFileType(fType).\n       setBlockReplication(fs.getReplication()).\n       setBlocksize(fs.getBlockSize()).\n       setModificationTime(fs.getModificationTime()).\n       setAccessTime(fs.getAccessTime()).\n       setPermission(PBHelper.convert(fs.getPermission())).\n       setOwner(fs.getOwner()).\n       setGroup(fs.getGroup()).\n+      setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes())).\n       setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n-    \n-    if (fs.getSymlink() !\u003d null) {\n-      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n-    }\n+    LocatedBlocks locations \u003d null;\n     if (fs instanceof HdfsLocatedFileStatus) {\n-      LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n-      if (locations !\u003d null) {\n-        builder.setLocations(PBHelper.convert(locations));\n-      }\n+      builder.setLocations(PBHelper.convert(locations));\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_DIR;;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d \n     HdfsFileStatusProto.newBuilder().\n      setLength(fs.getLen()).\n      setFileType(fType).\n      setBlockReplication(fs.getReplication()).\n      setBlocksize(fs.getBlockSize()).\n      setModificationTime(fs.getModificationTime()).\n      setAccessTime(fs.getAccessTime()).\n      setPermission(PBHelper.convert(fs.getPermission())).\n      setOwner(fs.getOwner()).\n      setGroup(fs.getGroup()).\n      setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes())).\n      setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n    LocatedBlocks locations \u003d null;\n    if (fs instanceof HdfsLocatedFileStatus) {\n      builder.setLocations(PBHelper.convert(locations));\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "b5229fd19bfecc2e5249db652ad34ec08152334b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2663. Optional protobuf parameters are not handled correctly. Contributed by Suresh Srinivas.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213981 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/12/11 3:22 PM",
      "commitName": "b5229fd19bfecc2e5249db652ad34ec08152334b",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "13/12/11 3:17 PM",
      "commitNameOld": "3001a172c8868763f8e59e866e36f7f50dee62cc",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,34 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_DIR;;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d \n      HdfsFileStatusProto.newBuilder().\n       setLength(fs.getLen()).\n       setFileType(fType).\n       setBlockReplication(fs.getReplication()).\n       setBlocksize(fs.getBlockSize()).\n       setModificationTime(fs.getModificationTime()).\n       setAccessTime(fs.getAccessTime()).\n       setPermission(PBHelper.convert(fs.getPermission())).\n       setOwner(fs.getOwner()).\n       setGroup(fs.getGroup()).\n-      setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes())).\n       setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n-    LocatedBlocks locations \u003d null;\n+    \n+    if (fs.getSymlink() !\u003d null) {\n+      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n+    }\n     if (fs instanceof HdfsLocatedFileStatus) {\n-      builder.setLocations(PBHelper.convert(locations));\n+      LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n+      if (locations !\u003d null) {\n+        builder.setLocations(PBHelper.convert(locations));\n+      }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_DIR;;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d \n     HdfsFileStatusProto.newBuilder().\n      setLength(fs.getLen()).\n      setFileType(fType).\n      setBlockReplication(fs.getReplication()).\n      setBlocksize(fs.getBlockSize()).\n      setModificationTime(fs.getModificationTime()).\n      setAccessTime(fs.getAccessTime()).\n      setPermission(PBHelper.convert(fs.getPermission())).\n      setOwner(fs.getOwner()).\n      setGroup(fs.getGroup()).\n      setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n    \n    if (fs.getSymlink() !\u003d null) {\n      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(PBHelper.convert(locations));\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "3001a172c8868763f8e59e866e36f7f50dee62cc": {
      "type": "Ybodychange",
      "commitMessage": "Reverting r1213512 because it committed changes that were not part of the patch.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213980 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/12/11 3:17 PM",
      "commitName": "3001a172c8868763f8e59e866e36f7f50dee62cc",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "13/12/11 9:59 AM",
      "commitNameOld": "4ec8424e5d8c3f4d802aaacb05cd39d9633eddf8",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.22,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,29 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_DIR;;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d \n      HdfsFileStatusProto.newBuilder().\n       setLength(fs.getLen()).\n       setFileType(fType).\n       setBlockReplication(fs.getReplication()).\n       setBlocksize(fs.getBlockSize()).\n       setModificationTime(fs.getModificationTime()).\n       setAccessTime(fs.getAccessTime()).\n       setPermission(PBHelper.convert(fs.getPermission())).\n       setOwner(fs.getOwner()).\n       setGroup(fs.getGroup()).\n+      setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes())).\n       setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n-    \n-    if (fs.getSymlink() !\u003d null) {\n-      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n-    }\n+    LocatedBlocks locations \u003d null;\n     if (fs instanceof HdfsLocatedFileStatus) {\n-      LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n-      if (locations !\u003d null) {\n-        builder.setLocations(PBHelper.convert(locations));\n-      }\n+      builder.setLocations(PBHelper.convert(locations));\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_DIR;;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d \n     HdfsFileStatusProto.newBuilder().\n      setLength(fs.getLen()).\n      setFileType(fType).\n      setBlockReplication(fs.getReplication()).\n      setBlocksize(fs.getBlockSize()).\n      setModificationTime(fs.getModificationTime()).\n      setAccessTime(fs.getAccessTime()).\n      setPermission(PBHelper.convert(fs.getPermission())).\n      setOwner(fs.getOwner()).\n      setGroup(fs.getGroup()).\n      setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes())).\n      setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n    LocatedBlocks locations \u003d null;\n    if (fs instanceof HdfsLocatedFileStatus) {\n      builder.setLocations(PBHelper.convert(locations));\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "13345f3a85b6b66c71a38e7c187c8ebb7cb5c35e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2663. Handle protobuf optional parameters correctly. Contributed by Suresh Srinivas.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213512 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/12/11 4:21 PM",
      "commitName": "13345f3a85b6b66c71a38e7c187c8ebb7cb5c35e",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "11/12/11 9:36 PM",
      "commitNameOld": "48da033901d3471ef176a94104158546152353e9",
      "commitAuthorOld": "Sanjay Radia",
      "daysBetweenCommits": 0.78,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,34 @@\n   public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n     if (fs \u003d\u003d null)\n       return null;\n     FileType fType \u003d FileType.IS_DIR;;\n     if (fs.isDir()) {\n       fType \u003d FileType.IS_DIR;\n     } else if (fs.isSymlink()) {\n       fType \u003d FileType.IS_SYMLINK;\n     }\n \n     HdfsFileStatusProto.Builder builder \u003d \n      HdfsFileStatusProto.newBuilder().\n       setLength(fs.getLen()).\n       setFileType(fType).\n       setBlockReplication(fs.getReplication()).\n       setBlocksize(fs.getBlockSize()).\n       setModificationTime(fs.getModificationTime()).\n       setAccessTime(fs.getAccessTime()).\n       setPermission(PBHelper.convert(fs.getPermission())).\n       setOwner(fs.getOwner()).\n       setGroup(fs.getGroup()).\n-      setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes())).\n       setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n-    LocatedBlocks locations \u003d null;\n+    \n+    if (fs.getSymlink() !\u003d null) {\n+      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n+    }\n     if (fs instanceof HdfsLocatedFileStatus) {\n-      builder.setLocations(PBHelper.convert(locations));\n+      LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n+      if (locations !\u003d null) {\n+        builder.setLocations(PBHelper.convert(locations));\n+      }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_DIR;;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d \n     HdfsFileStatusProto.newBuilder().\n      setLength(fs.getLen()).\n      setFileType(fType).\n      setBlockReplication(fs.getReplication()).\n      setBlocksize(fs.getBlockSize()).\n      setModificationTime(fs.getModificationTime()).\n      setAccessTime(fs.getAccessTime()).\n      setPermission(PBHelper.convert(fs.getPermission())).\n      setOwner(fs.getOwner()).\n      setGroup(fs.getGroup()).\n      setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n    \n    if (fs.getSymlink() !\u003d null) {\n      builder.setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes()));\n    }\n    if (fs instanceof HdfsLocatedFileStatus) {\n      LocatedBlocks locations \u003d ((HdfsLocatedFileStatus)fs).getBlockLocations();\n      if (locations !\u003d null) {\n        builder.setLocations(PBHelper.convert(locations));\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "48da033901d3471ef176a94104158546152353e9": {
      "type": "Yintroduced",
      "commitMessage": "    HDFS-2651 ClientNameNodeProtocol Translators for Protocol Buffers (sanjay)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213143 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/12/11 9:36 PM",
      "commitName": "48da033901d3471ef176a94104158546152353e9",
      "commitAuthor": "Sanjay Radia",
      "diff": "@@ -0,0 +1,29 @@\n+  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n+    if (fs \u003d\u003d null)\n+      return null;\n+    FileType fType \u003d FileType.IS_DIR;;\n+    if (fs.isDir()) {\n+      fType \u003d FileType.IS_DIR;\n+    } else if (fs.isSymlink()) {\n+      fType \u003d FileType.IS_SYMLINK;\n+    }\n+\n+    HdfsFileStatusProto.Builder builder \u003d \n+     HdfsFileStatusProto.newBuilder().\n+      setLength(fs.getLen()).\n+      setFileType(fType).\n+      setBlockReplication(fs.getReplication()).\n+      setBlocksize(fs.getBlockSize()).\n+      setModificationTime(fs.getModificationTime()).\n+      setAccessTime(fs.getAccessTime()).\n+      setPermission(PBHelper.convert(fs.getPermission())).\n+      setOwner(fs.getOwner()).\n+      setGroup(fs.getGroup()).\n+      setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes())).\n+      setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n+    LocatedBlocks locations \u003d null;\n+    if (fs instanceof HdfsLocatedFileStatus) {\n+      builder.setLocations(PBHelper.convert(locations));\n+    }\n+    return builder.build();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatusProto convert(HdfsFileStatus fs) {\n    if (fs \u003d\u003d null)\n      return null;\n    FileType fType \u003d FileType.IS_DIR;;\n    if (fs.isDir()) {\n      fType \u003d FileType.IS_DIR;\n    } else if (fs.isSymlink()) {\n      fType \u003d FileType.IS_SYMLINK;\n    }\n\n    HdfsFileStatusProto.Builder builder \u003d \n     HdfsFileStatusProto.newBuilder().\n      setLength(fs.getLen()).\n      setFileType(fType).\n      setBlockReplication(fs.getReplication()).\n      setBlocksize(fs.getBlockSize()).\n      setModificationTime(fs.getModificationTime()).\n      setAccessTime(fs.getAccessTime()).\n      setPermission(PBHelper.convert(fs.getPermission())).\n      setOwner(fs.getOwner()).\n      setGroup(fs.getGroup()).\n      setSymlink(ByteString.copyFrom(fs.getSymlinkInBytes())).\n      setPath(ByteString.copyFrom(fs.getLocalNameInBytes()));\n    LocatedBlocks locations \u003d null;\n    if (fs instanceof HdfsLocatedFileStatus) {\n      builder.setLocations(PBHelper.convert(locations));\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java"
    }
  }
}