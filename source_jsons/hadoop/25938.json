{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ContainerLauncherImpl.java",
  "functionName": "serviceStart",
  "functionId": "serviceStart",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
  "functionStartLine": 278,
  "functionEndLine": 340,
  "numCommitsSeen": 75,
  "timeTaken": 8672,
  "changeHistory": [
    "2440671a117f165dcda5056404bc898df3c50803",
    "9d38520c8e42530a817a7f69c9aa73a9ad40639c",
    "0928502029ef141759008997335ea2cd836a7154",
    "cd2c5fab8b3542483337e6384e4de67b4a2e3507",
    "1e45b1f1fd38543b0b1233f57fdee1ac4a365332",
    "849c68c7b5f80064de3692d766444c2f8864f47a",
    "239a5549eadeccb0ab433abb38079dbe19f862ff",
    "7f4dc277572df6ba25fa961073b99a5bdb086c00",
    "724f21734316343873386a14059a347067d65a10",
    "db8ac0ec3cbec046f9cf32644c16fd2a51dd85a2",
    "68328ae92632afc9cdd6e75b7a8d832723ddbe3b",
    "d09ceac1f7a85fce688b20528a1b095a8042bebd",
    "fafe8cd28e726566509c679e19d7da622f29f90d",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "2440671a117f165dcda5056404bc898df3c50803": "Ybodychange",
    "9d38520c8e42530a817a7f69c9aa73a9ad40639c": "Ybodychange",
    "0928502029ef141759008997335ea2cd836a7154": "Ymultichange(Yrename,Ymodifierchange,Yexceptionschange,Ybodychange)",
    "cd2c5fab8b3542483337e6384e4de67b4a2e3507": "Ybodychange",
    "1e45b1f1fd38543b0b1233f57fdee1ac4a365332": "Ybodychange",
    "849c68c7b5f80064de3692d766444c2f8864f47a": "Ybodychange",
    "239a5549eadeccb0ab433abb38079dbe19f862ff": "Ybodychange",
    "7f4dc277572df6ba25fa961073b99a5bdb086c00": "Ybodychange",
    "724f21734316343873386a14059a347067d65a10": "Ybodychange",
    "db8ac0ec3cbec046f9cf32644c16fd2a51dd85a2": "Ybodychange",
    "68328ae92632afc9cdd6e75b7a8d832723ddbe3b": "Ybodychange",
    "d09ceac1f7a85fce688b20528a1b095a8042bebd": "Ybodychange",
    "fafe8cd28e726566509c679e19d7da622f29f90d": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2440671a117f165dcda5056404bc898df3c50803": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6634. Log uncaught exceptions/errors in various thread pools in mapreduce. Contributed by Sidharta Seethana.\n",
      "commitDate": "18/02/16 12:48 AM",
      "commitName": "2440671a117f165dcda5056404bc898df3c50803",
      "commitAuthor": "Varun Vasudev",
      "commitDateOld": "11/05/15 3:37 PM",
      "commitNameOld": "444836b3dcd3ee28238af7b5e753d644e8095788",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 282.42,
      "commitsBetweenForRepo": 2094,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,63 +1,63 @@\n   protected void serviceStart() throws Exception {\n \n     ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n         \"ContainerLauncher #%d\").setDaemon(true).build();\n \n     // Start with a default core-pool size of 10 and change it dynamically.\n-    launcherPool \u003d new ThreadPoolExecutor(initialPoolSize,\n+    launcherPool \u003d new HadoopThreadPoolExecutor(initialPoolSize,\n         Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n         new LinkedBlockingQueue\u003cRunnable\u003e(),\n         tf);\n     eventHandlingThread \u003d new Thread() {\n       @Override\n       public void run() {\n         ContainerLauncherEvent event \u003d null;\n         Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n \n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, interrupted : \" + e);\n             }\n             return;\n           }\n           allNodes.add(event.getContainerMgrAddress());\n \n           int poolSize \u003d launcherPool.getCorePoolSize();\n \n           // See if we need up the pool size only if haven\u0027t reached the\n           // maximum limit yet.\n           if (poolSize !\u003d limitOnPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n             int numNodes \u003d allNodes.size();\n             int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n \n             if (poolSize \u003c idealPoolSize) {\n               // Bump up the pool size to idealPoolSize+initialPoolSize, the\n               // later is just a buffer so we are not always increasing the\n               // pool-size\n               int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                   + initialPoolSize);\n               LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                   + \" as number-of-nodes to talk to is \" + numNodes);\n               launcherPool.setCorePoolSize(newPoolSize);\n             }\n           }\n \n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(createEventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     };\n     eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n     eventHandlingThread.start();\n     super.serviceStart();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStart() throws Exception {\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        \"ContainerLauncher #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size of 10 and change it dynamically.\n    launcherPool \u003d new HadoopThreadPoolExecutor(initialPoolSize,\n        Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n        new LinkedBlockingQueue\u003cRunnable\u003e(),\n        tf);\n    eventHandlingThread \u003d new Thread() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, interrupted : \" + e);\n            }\n            return;\n          }\n          allNodes.add(event.getContainerMgrAddress());\n\n          int poolSize \u003d launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven\u0027t reached the\n          // maximum limit yet.\n          if (poolSize !\u003d limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int numNodes \u003d allNodes.size();\n            int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize \u003c idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+initialPoolSize, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                  + initialPoolSize);\n              LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                  + \" as number-of-nodes to talk to is \" + numNodes);\n              launcherPool.setCorePoolSize(newPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(createEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    };\n    eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n    eventHandlingThread.start();\n    super.serviceStart();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
      "extendedDetails": {}
    },
    "9d38520c8e42530a817a7f69c9aa73a9ad40639c": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6265. Make ContainerLauncherImpl.INITIAL_POOL_SIZE configurable to better control to launch/kill containers. Contributed by Zhihai Xu\n",
      "commitDate": "14/03/15 12:44 AM",
      "commitName": "9d38520c8e42530a817a7f69c9aa73a9ad40639c",
      "commitAuthor": "Tsuyoshi Ozawa",
      "commitDateOld": "23/07/13 8:41 PM",
      "commitNameOld": "3ca3137179ef093e42cde06587c9ea785b10f32c",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 598.17,
      "commitsBetweenForRepo": 4500,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,63 +1,63 @@\n   protected void serviceStart() throws Exception {\n \n     ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n         \"ContainerLauncher #%d\").setDaemon(true).build();\n \n     // Start with a default core-pool size of 10 and change it dynamically.\n-    launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n+    launcherPool \u003d new ThreadPoolExecutor(initialPoolSize,\n         Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n         new LinkedBlockingQueue\u003cRunnable\u003e(),\n         tf);\n     eventHandlingThread \u003d new Thread() {\n       @Override\n       public void run() {\n         ContainerLauncherEvent event \u003d null;\n         Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n \n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, interrupted : \" + e);\n             }\n             return;\n           }\n           allNodes.add(event.getContainerMgrAddress());\n \n           int poolSize \u003d launcherPool.getCorePoolSize();\n \n           // See if we need up the pool size only if haven\u0027t reached the\n           // maximum limit yet.\n           if (poolSize !\u003d limitOnPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n             int numNodes \u003d allNodes.size();\n             int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n \n             if (poolSize \u003c idealPoolSize) {\n-              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n+              // Bump up the pool size to idealPoolSize+initialPoolSize, the\n               // later is just a buffer so we are not always increasing the\n               // pool-size\n               int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n-                  + INITIAL_POOL_SIZE);\n+                  + initialPoolSize);\n               LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                   + \" as number-of-nodes to talk to is \" + numNodes);\n               launcherPool.setCorePoolSize(newPoolSize);\n             }\n           }\n \n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(createEventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     };\n     eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n     eventHandlingThread.start();\n     super.serviceStart();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStart() throws Exception {\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        \"ContainerLauncher #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size of 10 and change it dynamically.\n    launcherPool \u003d new ThreadPoolExecutor(initialPoolSize,\n        Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n        new LinkedBlockingQueue\u003cRunnable\u003e(),\n        tf);\n    eventHandlingThread \u003d new Thread() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, interrupted : \" + e);\n            }\n            return;\n          }\n          allNodes.add(event.getContainerMgrAddress());\n\n          int poolSize \u003d launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven\u0027t reached the\n          // maximum limit yet.\n          if (poolSize !\u003d limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int numNodes \u003d allNodes.size();\n            int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize \u003c idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+initialPoolSize, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                  + initialPoolSize);\n              LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                  + \" as number-of-nodes to talk to is \" + numNodes);\n              launcherPool.setCorePoolSize(newPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(createEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    };\n    eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n    eventHandlingThread.start();\n    super.serviceStart();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
      "extendedDetails": {}
    },
    "0928502029ef141759008997335ea2cd836a7154": {
      "type": "Ymultichange(Yrename,Ymodifierchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/06/13 8:54 AM",
      "commitName": "0928502029ef141759008997335ea2cd836a7154",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,63 +1,63 @@\n-  public void start() {\n+  protected void serviceStart() throws Exception {\n \n     ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n         \"ContainerLauncher #%d\").setDaemon(true).build();\n \n     // Start with a default core-pool size of 10 and change it dynamically.\n     launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n         Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n         new LinkedBlockingQueue\u003cRunnable\u003e(),\n         tf);\n     eventHandlingThread \u003d new Thread() {\n       @Override\n       public void run() {\n         ContainerLauncherEvent event \u003d null;\n         Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n \n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, interrupted : \" + e);\n             }\n             return;\n           }\n           allNodes.add(event.getContainerMgrAddress());\n \n           int poolSize \u003d launcherPool.getCorePoolSize();\n \n           // See if we need up the pool size only if haven\u0027t reached the\n           // maximum limit yet.\n           if (poolSize !\u003d limitOnPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n             int numNodes \u003d allNodes.size();\n             int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n \n             if (poolSize \u003c idealPoolSize) {\n               // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n               // later is just a buffer so we are not always increasing the\n               // pool-size\n               int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                   + INITIAL_POOL_SIZE);\n               LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                   + \" as number-of-nodes to talk to is \" + numNodes);\n               launcherPool.setCorePoolSize(newPoolSize);\n             }\n           }\n \n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(createEventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     };\n     eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n     eventHandlingThread.start();\n-    super.start();\n+    super.serviceStart();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceStart() throws Exception {\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        \"ContainerLauncher #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size of 10 and change it dynamically.\n    launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n        Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n        new LinkedBlockingQueue\u003cRunnable\u003e(),\n        tf);\n    eventHandlingThread \u003d new Thread() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, interrupted : \" + e);\n            }\n            return;\n          }\n          allNodes.add(event.getContainerMgrAddress());\n\n          int poolSize \u003d launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven\u0027t reached the\n          // maximum limit yet.\n          if (poolSize !\u003d limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int numNodes \u003d allNodes.size();\n            int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize \u003c idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                  + INITIAL_POOL_SIZE);\n              LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                  + \" as number-of-nodes to talk to is \" + numNodes);\n              launcherPool.setCorePoolSize(newPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(createEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    };\n    eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n    eventHandlingThread.start();\n    super.serviceStart();\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
          "extendedDetails": {
            "oldValue": "start",
            "newValue": "serviceStart"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,63 +1,63 @@\n-  public void start() {\n+  protected void serviceStart() throws Exception {\n \n     ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n         \"ContainerLauncher #%d\").setDaemon(true).build();\n \n     // Start with a default core-pool size of 10 and change it dynamically.\n     launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n         Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n         new LinkedBlockingQueue\u003cRunnable\u003e(),\n         tf);\n     eventHandlingThread \u003d new Thread() {\n       @Override\n       public void run() {\n         ContainerLauncherEvent event \u003d null;\n         Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n \n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, interrupted : \" + e);\n             }\n             return;\n           }\n           allNodes.add(event.getContainerMgrAddress());\n \n           int poolSize \u003d launcherPool.getCorePoolSize();\n \n           // See if we need up the pool size only if haven\u0027t reached the\n           // maximum limit yet.\n           if (poolSize !\u003d limitOnPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n             int numNodes \u003d allNodes.size();\n             int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n \n             if (poolSize \u003c idealPoolSize) {\n               // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n               // later is just a buffer so we are not always increasing the\n               // pool-size\n               int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                   + INITIAL_POOL_SIZE);\n               LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                   + \" as number-of-nodes to talk to is \" + numNodes);\n               launcherPool.setCorePoolSize(newPoolSize);\n             }\n           }\n \n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(createEventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     };\n     eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n     eventHandlingThread.start();\n-    super.start();\n+    super.serviceStart();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceStart() throws Exception {\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        \"ContainerLauncher #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size of 10 and change it dynamically.\n    launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n        Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n        new LinkedBlockingQueue\u003cRunnable\u003e(),\n        tf);\n    eventHandlingThread \u003d new Thread() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, interrupted : \" + e);\n            }\n            return;\n          }\n          allNodes.add(event.getContainerMgrAddress());\n\n          int poolSize \u003d launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven\u0027t reached the\n          // maximum limit yet.\n          if (poolSize !\u003d limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int numNodes \u003d allNodes.size();\n            int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize \u003c idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                  + INITIAL_POOL_SIZE);\n              LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                  + \" as number-of-nodes to talk to is \" + numNodes);\n              launcherPool.setCorePoolSize(newPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(createEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    };\n    eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n    eventHandlingThread.start();\n    super.serviceStart();\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[protected]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,63 +1,63 @@\n-  public void start() {\n+  protected void serviceStart() throws Exception {\n \n     ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n         \"ContainerLauncher #%d\").setDaemon(true).build();\n \n     // Start with a default core-pool size of 10 and change it dynamically.\n     launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n         Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n         new LinkedBlockingQueue\u003cRunnable\u003e(),\n         tf);\n     eventHandlingThread \u003d new Thread() {\n       @Override\n       public void run() {\n         ContainerLauncherEvent event \u003d null;\n         Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n \n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, interrupted : \" + e);\n             }\n             return;\n           }\n           allNodes.add(event.getContainerMgrAddress());\n \n           int poolSize \u003d launcherPool.getCorePoolSize();\n \n           // See if we need up the pool size only if haven\u0027t reached the\n           // maximum limit yet.\n           if (poolSize !\u003d limitOnPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n             int numNodes \u003d allNodes.size();\n             int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n \n             if (poolSize \u003c idealPoolSize) {\n               // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n               // later is just a buffer so we are not always increasing the\n               // pool-size\n               int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                   + INITIAL_POOL_SIZE);\n               LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                   + \" as number-of-nodes to talk to is \" + numNodes);\n               launcherPool.setCorePoolSize(newPoolSize);\n             }\n           }\n \n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(createEventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     };\n     eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n     eventHandlingThread.start();\n-    super.start();\n+    super.serviceStart();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceStart() throws Exception {\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        \"ContainerLauncher #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size of 10 and change it dynamically.\n    launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n        Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n        new LinkedBlockingQueue\u003cRunnable\u003e(),\n        tf);\n    eventHandlingThread \u003d new Thread() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, interrupted : \" + e);\n            }\n            return;\n          }\n          allNodes.add(event.getContainerMgrAddress());\n\n          int poolSize \u003d launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven\u0027t reached the\n          // maximum limit yet.\n          if (poolSize !\u003d limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int numNodes \u003d allNodes.size();\n            int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize \u003c idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                  + INITIAL_POOL_SIZE);\n              LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                  + \" as number-of-nodes to talk to is \" + numNodes);\n              launcherPool.setCorePoolSize(newPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(createEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    };\n    eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n    eventHandlingThread.start();\n    super.serviceStart();\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[Exception]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,63 +1,63 @@\n-  public void start() {\n+  protected void serviceStart() throws Exception {\n \n     ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n         \"ContainerLauncher #%d\").setDaemon(true).build();\n \n     // Start with a default core-pool size of 10 and change it dynamically.\n     launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n         Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n         new LinkedBlockingQueue\u003cRunnable\u003e(),\n         tf);\n     eventHandlingThread \u003d new Thread() {\n       @Override\n       public void run() {\n         ContainerLauncherEvent event \u003d null;\n         Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n \n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, interrupted : \" + e);\n             }\n             return;\n           }\n           allNodes.add(event.getContainerMgrAddress());\n \n           int poolSize \u003d launcherPool.getCorePoolSize();\n \n           // See if we need up the pool size only if haven\u0027t reached the\n           // maximum limit yet.\n           if (poolSize !\u003d limitOnPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n             int numNodes \u003d allNodes.size();\n             int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n \n             if (poolSize \u003c idealPoolSize) {\n               // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n               // later is just a buffer so we are not always increasing the\n               // pool-size\n               int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                   + INITIAL_POOL_SIZE);\n               LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                   + \" as number-of-nodes to talk to is \" + numNodes);\n               launcherPool.setCorePoolSize(newPoolSize);\n             }\n           }\n \n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(createEventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     };\n     eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n     eventHandlingThread.start();\n-    super.start();\n+    super.serviceStart();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceStart() throws Exception {\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        \"ContainerLauncher #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size of 10 and change it dynamically.\n    launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n        Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n        new LinkedBlockingQueue\u003cRunnable\u003e(),\n        tf);\n    eventHandlingThread \u003d new Thread() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, interrupted : \" + e);\n            }\n            return;\n          }\n          allNodes.add(event.getContainerMgrAddress());\n\n          int poolSize \u003d launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven\u0027t reached the\n          // maximum limit yet.\n          if (poolSize !\u003d limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int numNodes \u003d allNodes.size();\n            int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize \u003c idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                  + INITIAL_POOL_SIZE);\n              LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                  + \" as number-of-nodes to talk to is \" + numNodes);\n              launcherPool.setCorePoolSize(newPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(createEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    };\n    eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n    eventHandlingThread.start();\n    super.serviceStart();\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd2c5fab8b3542483337e6384e4de67b4a2e3507": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3872. Fix an event handling races in ContainerLauncherImpl. (Contributed by Robert Kanter)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1459547 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/03/13 2:55 PM",
      "commitName": "cd2c5fab8b3542483337e6384e4de67b4a2e3507",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "21/12/12 2:27 PM",
      "commitNameOld": "92692c863cae56485de45e0aae3921018cf67b01",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 89.98,
      "commitsBetweenForRepo": 398,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,59 +1,63 @@\n   public void start() {\n \n     ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n         \"ContainerLauncher #%d\").setDaemon(true).build();\n \n     // Start with a default core-pool size of 10 and change it dynamically.\n     launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n         Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n         new LinkedBlockingQueue\u003cRunnable\u003e(),\n         tf);\n     eventHandlingThread \u003d new Thread() {\n       @Override\n       public void run() {\n         ContainerLauncherEvent event \u003d null;\n+        Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n+\n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, interrupted : \" + e);\n             }\n             return;\n           }\n+          allNodes.add(event.getContainerMgrAddress());\n+\n           int poolSize \u003d launcherPool.getCorePoolSize();\n \n           // See if we need up the pool size only if haven\u0027t reached the\n           // maximum limit yet.\n           if (poolSize !\u003d limitOnPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n             int numNodes \u003d allNodes.size();\n             int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n \n             if (poolSize \u003c idealPoolSize) {\n               // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n               // later is just a buffer so we are not always increasing the\n               // pool-size\n               int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                   + INITIAL_POOL_SIZE);\n               LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                   + \" as number-of-nodes to talk to is \" + numNodes);\n               launcherPool.setCorePoolSize(newPoolSize);\n             }\n           }\n \n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(createEventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     };\n     eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n     eventHandlingThread.start();\n     super.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        \"ContainerLauncher #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size of 10 and change it dynamically.\n    launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n        Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n        new LinkedBlockingQueue\u003cRunnable\u003e(),\n        tf);\n    eventHandlingThread \u003d new Thread() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, interrupted : \" + e);\n            }\n            return;\n          }\n          allNodes.add(event.getContainerMgrAddress());\n\n          int poolSize \u003d launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven\u0027t reached the\n          // maximum limit yet.\n          if (poolSize !\u003d limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int numNodes \u003d allNodes.size();\n            int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize \u003c idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                  + INITIAL_POOL_SIZE);\n              LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                  + \" as number-of-nodes to talk to is \" + numNodes);\n              launcherPool.setCorePoolSize(newPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(createEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    };\n    eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n    eventHandlingThread.start();\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
      "extendedDetails": {}
    },
    "1e45b1f1fd38543b0b1233f57fdee1ac4a365332": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4741. WARN and ERROR messages logged during normal AM shutdown. Contributed by Vinod Kumar Vavilapalli\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1401738 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/10/12 8:45 AM",
      "commitName": "1e45b1f1fd38543b0b1233f57fdee1ac4a365332",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "30/05/12 7:48 AM",
      "commitNameOld": "0a80f82a304fc8bb3d9cf5ec016e12e6415270fc",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 147.04,
      "commitsBetweenForRepo": 847,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,57 +1,59 @@\n   public void start() {\n \n     ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n         \"ContainerLauncher #%d\").setDaemon(true).build();\n \n     // Start with a default core-pool size of 10 and change it dynamically.\n     launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n         Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n         new LinkedBlockingQueue\u003cRunnable\u003e(),\n         tf);\n     eventHandlingThread \u003d new Thread() {\n       @Override\n       public void run() {\n         ContainerLauncherEvent event \u003d null;\n-        while (!Thread.currentThread().isInterrupted()) {\n+        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n-            LOG.error(\"Returning, interrupted : \" + e);\n+            if (!stopped.get()) {\n+              LOG.error(\"Returning, interrupted : \" + e);\n+            }\n             return;\n           }\n           int poolSize \u003d launcherPool.getCorePoolSize();\n \n           // See if we need up the pool size only if haven\u0027t reached the\n           // maximum limit yet.\n           if (poolSize !\u003d limitOnPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n             int numNodes \u003d allNodes.size();\n             int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n \n             if (poolSize \u003c idealPoolSize) {\n               // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n               // later is just a buffer so we are not always increasing the\n               // pool-size\n               int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                   + INITIAL_POOL_SIZE);\n               LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                   + \" as number-of-nodes to talk to is \" + numNodes);\n               launcherPool.setCorePoolSize(newPoolSize);\n             }\n           }\n \n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(createEventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     };\n     eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n     eventHandlingThread.start();\n     super.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        \"ContainerLauncher #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size of 10 and change it dynamically.\n    launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n        Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n        new LinkedBlockingQueue\u003cRunnable\u003e(),\n        tf);\n    eventHandlingThread \u003d new Thread() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, interrupted : \" + e);\n            }\n            return;\n          }\n          int poolSize \u003d launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven\u0027t reached the\n          // maximum limit yet.\n          if (poolSize !\u003d limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int numNodes \u003d allNodes.size();\n            int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize \u003c idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                  + INITIAL_POOL_SIZE);\n              LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                  + \" as number-of-nodes to talk to is \" + numNodes);\n              launcherPool.setCorePoolSize(newPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(createEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    };\n    eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n    eventHandlingThread.start();\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
      "extendedDetails": {}
    },
    "849c68c7b5f80064de3692d766444c2f8864f47a": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3312. Modified MR AM to not send a stop-container request for a container that isn\u0027t launched at all. Contributed by Robert Joseph Evans.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1229451 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/12 6:15 PM",
      "commitName": "849c68c7b5f80064de3692d766444c2f8864f47a",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "09/01/12 2:20 PM",
      "commitNameOld": "239a5549eadeccb0ab433abb38079dbe19f862ff",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 0.16,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,58 +1,58 @@\n   public void start() {\n \n     ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n         \"ContainerLauncher #%d\").setDaemon(true).build();\n \n     // Start with a default core-pool size of 10 and change it dynamically.\n     launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n         Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n         new LinkedBlockingQueue\u003cRunnable\u003e(),\n         tf);\n-    eventHandlingThread \u003d new Thread(new Runnable() {\n+    eventHandlingThread \u003d new Thread() {\n       @Override\n       public void run() {\n         ContainerLauncherEvent event \u003d null;\n         while (!Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             LOG.error(\"Returning, interrupted : \" + e);\n             return;\n           }\n \n           int poolSize \u003d launcherPool.getCorePoolSize();\n \n           // See if we need up the pool size only if haven\u0027t reached the\n           // maximum limit yet.\n           if (poolSize !\u003d limitOnPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n             int numNodes \u003d allNodes.size();\n             int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n \n             if (poolSize \u003c idealPoolSize) {\n               // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n               // later is just a buffer so we are not always increasing the\n               // pool-size\n               int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                   + INITIAL_POOL_SIZE);\n               LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                   + \" as number-of-nodes to talk to is \" + numNodes);\n               launcherPool.setCorePoolSize(newPoolSize);\n             }\n           }\n \n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(createEventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n-    });\n+    };\n     eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n     eventHandlingThread.start();\n     super.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        \"ContainerLauncher #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size of 10 and change it dynamically.\n    launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n        Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n        new LinkedBlockingQueue\u003cRunnable\u003e(),\n        tf);\n    eventHandlingThread \u003d new Thread() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n\n          int poolSize \u003d launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven\u0027t reached the\n          // maximum limit yet.\n          if (poolSize !\u003d limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int numNodes \u003d allNodes.size();\n            int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize \u003c idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                  + INITIAL_POOL_SIZE);\n              LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                  + \" as number-of-nodes to talk to is \" + numNodes);\n              launcherPool.setCorePoolSize(newPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(createEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    };\n    eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n    eventHandlingThread.start();\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
      "extendedDetails": {}
    },
    "239a5549eadeccb0ab433abb38079dbe19f862ff": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3616. Thread pool for launching containers in MR AM not expanding as expected. (Contributed by Vinod Kumar Vavilapalli) \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1229394 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/12 2:20 PM",
      "commitName": "239a5549eadeccb0ab433abb38079dbe19f862ff",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "16/11/11 7:37 AM",
      "commitNameOld": "00b50a5c94df63668b07ca1623c40fe7252f1322",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 54.28,
      "commitsBetweenForRepo": 276,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,57 +1,58 @@\n   public void start() {\n \n     ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n         \"ContainerLauncher #%d\").setDaemon(true).build();\n \n     // Start with a default core-pool size of 10 and change it dynamically.\n     launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n         Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n         new LinkedBlockingQueue\u003cRunnable\u003e(),\n         tf);\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n         ContainerLauncherEvent event \u003d null;\n         while (!Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             LOG.error(\"Returning, interrupted : \" + e);\n             return;\n           }\n \n           int poolSize \u003d launcherPool.getCorePoolSize();\n \n           // See if we need up the pool size only if haven\u0027t reached the\n           // maximum limit yet.\n           if (poolSize !\u003d limitOnPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n             int numNodes \u003d allNodes.size();\n             int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n \n-            if (poolSize \u003c\u003d idealPoolSize) {\n+            if (poolSize \u003c idealPoolSize) {\n               // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n               // later is just a buffer so we are not always increasing the\n               // pool-size\n-              int newPoolSize \u003d idealPoolSize + INITIAL_POOL_SIZE;\n-              LOG.info(\"Setting ContainerLauncher pool size to \"\n-                  + newPoolSize);\n+              int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n+                  + INITIAL_POOL_SIZE);\n+              LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n+                  + \" as number-of-nodes to talk to is \" + numNodes);\n               launcherPool.setCorePoolSize(newPoolSize);\n             }\n           }\n \n           // the events from the queue are handled in parallel\n           // using a thread pool\n-          launcherPool.execute(new EventProcessor(event));\n+          launcherPool.execute(createEventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     });\n     eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n     eventHandlingThread.start();\n     super.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        \"ContainerLauncher #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size of 10 and change it dynamically.\n    launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n        Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n        new LinkedBlockingQueue\u003cRunnable\u003e(),\n        tf);\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n\n          int poolSize \u003d launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven\u0027t reached the\n          // maximum limit yet.\n          if (poolSize !\u003d limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int numNodes \u003d allNodes.size();\n            int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize \u003c idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              int newPoolSize \u003d Math.min(limitOnPoolSize, idealPoolSize\n                  + INITIAL_POOL_SIZE);\n              LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                  + \" as number-of-nodes to talk to is \" + numNodes);\n              launcherPool.setCorePoolSize(newPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(createEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    });\n    eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n    eventHandlingThread.start();\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
      "extendedDetails": {}
    },
    "7f4dc277572df6ba25fa961073b99a5bdb086c00": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3256. Added authorization checks for the protocol between NodeManager and ApplicationMaster. Contributed by Vinod K V.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1194850 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/10/11 2:35 AM",
      "commitName": "7f4dc277572df6ba25fa961073b99a5bdb086c00",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "27/10/11 10:32 AM",
      "commitNameOld": "724f21734316343873386a14059a347067d65a10",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 1.67,
      "commitsBetweenForRepo": 42,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,56 +1,57 @@\n   public void start() {\n \n     ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n         \"ContainerLauncher #%d\").setDaemon(true).build();\n \n     // Start with a default core-pool size of 10 and change it dynamically.\n     launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n         Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n         new LinkedBlockingQueue\u003cRunnable\u003e(),\n         tf);\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n         ContainerLauncherEvent event \u003d null;\n         while (!Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             LOG.error(\"Returning, interrupted : \" + e);\n             return;\n           }\n \n           int poolSize \u003d launcherPool.getCorePoolSize();\n \n           // See if we need up the pool size only if haven\u0027t reached the\n           // maximum limit yet.\n           if (poolSize !\u003d limitOnPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n-            int numNodes \u003d ugiMap.size();\n+            int numNodes \u003d allNodes.size();\n             int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n \n             if (poolSize \u003c\u003d idealPoolSize) {\n               // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n               // later is just a buffer so we are not always increasing the\n               // pool-size\n               int newPoolSize \u003d idealPoolSize + INITIAL_POOL_SIZE;\n-              LOG.debug(\"Setting pool size to \" + newPoolSize);\n+              LOG.info(\"Setting ContainerLauncher pool size to \"\n+                  + newPoolSize);\n               launcherPool.setCorePoolSize(newPoolSize);\n             }\n           }\n \n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(new EventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     });\n     eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n     eventHandlingThread.start();\n     super.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        \"ContainerLauncher #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size of 10 and change it dynamically.\n    launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n        Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n        new LinkedBlockingQueue\u003cRunnable\u003e(),\n        tf);\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n\n          int poolSize \u003d launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven\u0027t reached the\n          // maximum limit yet.\n          if (poolSize !\u003d limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int numNodes \u003d allNodes.size();\n            int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize \u003c\u003d idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              int newPoolSize \u003d idealPoolSize + INITIAL_POOL_SIZE;\n              LOG.info(\"Setting ContainerLauncher pool size to \"\n                  + newPoolSize);\n              launcherPool.setCorePoolSize(newPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    });\n    eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n    eventHandlingThread.start();\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
      "extendedDetails": {}
    },
    "724f21734316343873386a14059a347067d65a10": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3228. Fixed MR AM to timeout RPCs to bad NodeManagers. Contributed by Vinod K V.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1189879 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/10/11 10:32 AM",
      "commitName": "724f21734316343873386a14059a347067d65a10",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "26/10/11 11:24 PM",
      "commitNameOld": "db8ac0ec3cbec046f9cf32644c16fd2a51dd85a2",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.46,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,55 +1,56 @@\n   public void start() {\n+\n+    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n+        \"ContainerLauncher #%d\").setDaemon(true).build();\n+\n     // Start with a default core-pool size of 10 and change it dynamically.\n-    ThreadFactory tf \u003d new ThreadFactoryBuilder()\n-      .setNameFormat(\"ContainerLauncher #%d\")\n-      .build();\n     launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n         Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n         new LinkedBlockingQueue\u003cRunnable\u003e(),\n         tf);\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n         ContainerLauncherEvent event \u003d null;\n         while (!Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             LOG.error(\"Returning, interrupted : \" + e);\n             return;\n           }\n \n           int poolSize \u003d launcherPool.getCorePoolSize();\n \n           // See if we need up the pool size only if haven\u0027t reached the\n           // maximum limit yet.\n           if (poolSize !\u003d limitOnPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n             int numNodes \u003d ugiMap.size();\n             int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n \n             if (poolSize \u003c\u003d idealPoolSize) {\n               // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n               // later is just a buffer so we are not always increasing the\n               // pool-size\n               int newPoolSize \u003d idealPoolSize + INITIAL_POOL_SIZE;\n               LOG.debug(\"Setting pool size to \" + newPoolSize);\n               launcherPool.setCorePoolSize(newPoolSize);\n             }\n           }\n \n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(new EventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     });\n     eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n     eventHandlingThread.start();\n     super.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        \"ContainerLauncher #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size of 10 and change it dynamically.\n    launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n        Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n        new LinkedBlockingQueue\u003cRunnable\u003e(),\n        tf);\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n\n          int poolSize \u003d launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven\u0027t reached the\n          // maximum limit yet.\n          if (poolSize !\u003d limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int numNodes \u003d ugiMap.size();\n            int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize \u003c\u003d idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              int newPoolSize \u003d idealPoolSize + INITIAL_POOL_SIZE;\n              LOG.debug(\"Setting pool size to \" + newPoolSize);\n              launcherPool.setCorePoolSize(newPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    });\n    eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n    eventHandlingThread.start();\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
      "extendedDetails": {}
    },
    "db8ac0ec3cbec046f9cf32644c16fd2a51dd85a2": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3257. Added authorization checks for the protocol between ResourceManager and ApplicatoinMaster. Contributed by Vinod K V. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1189630 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/10/11 11:24 PM",
      "commitName": "db8ac0ec3cbec046f9cf32644c16fd2a51dd85a2",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/10/11 11:07 PM",
      "commitNameOld": "d19cfe01642f9582e1fe5d567beb480399c37a01",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 2.01,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,55 @@\n   public void start() {\n     // Start with a default core-pool size of 10 and change it dynamically.\n     ThreadFactory tf \u003d new ThreadFactoryBuilder()\n       .setNameFormat(\"ContainerLauncher #%d\")\n       .build();\n     launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n         Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n         new LinkedBlockingQueue\u003cRunnable\u003e(),\n         tf);\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n         ContainerLauncherEvent event \u003d null;\n         while (!Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             LOG.error(\"Returning, interrupted : \" + e);\n             return;\n           }\n \n           int poolSize \u003d launcherPool.getCorePoolSize();\n \n           // See if we need up the pool size only if haven\u0027t reached the\n           // maximum limit yet.\n           if (poolSize !\u003d limitOnPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n             int numNodes \u003d ugiMap.size();\n             int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n \n             if (poolSize \u003c\u003d idealPoolSize) {\n               // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n               // later is just a buffer so we are not always increasing the\n               // pool-size\n-              launcherPool.setCorePoolSize(idealPoolSize + INITIAL_POOL_SIZE);\n+              int newPoolSize \u003d idealPoolSize + INITIAL_POOL_SIZE;\n+              LOG.debug(\"Setting pool size to \" + newPoolSize);\n+              launcherPool.setCorePoolSize(newPoolSize);\n             }\n           }\n \n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(new EventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     });\n     eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n     eventHandlingThread.start();\n     super.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n    // Start with a default core-pool size of 10 and change it dynamically.\n    ThreadFactory tf \u003d new ThreadFactoryBuilder()\n      .setNameFormat(\"ContainerLauncher #%d\")\n      .build();\n    launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n        Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n        new LinkedBlockingQueue\u003cRunnable\u003e(),\n        tf);\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n\n          int poolSize \u003d launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven\u0027t reached the\n          // maximum limit yet.\n          if (poolSize !\u003d limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int numNodes \u003d ugiMap.size();\n            int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize \u003c\u003d idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              int newPoolSize \u003d idealPoolSize + INITIAL_POOL_SIZE;\n              LOG.debug(\"Setting pool size to \" + newPoolSize);\n              launcherPool.setCorePoolSize(newPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    });\n    eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n    eventHandlingThread.start();\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
      "extendedDetails": {}
    },
    "68328ae92632afc9cdd6e75b7a8d832723ddbe3b": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3187. Add names for various unnamed threads in MR2. (Todd Lipcon and Siddharth Seth via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1184904 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/11 12:27 PM",
      "commitName": "68328ae92632afc9cdd6e75b7a8d832723ddbe3b",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "05/10/11 4:43 AM",
      "commitNameOld": "66137cf17cb4abccd6065819d97edc63c6510477",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 11.32,
      "commitsBetweenForRepo": 86,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,53 @@\n   public void start() {\n     // Start with a default core-pool size of 10 and change it dynamically.\n+    ThreadFactory tf \u003d new ThreadFactoryBuilder()\n+      .setNameFormat(\"ContainerLauncher #%d\")\n+      .build();\n     launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n         Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n-        new LinkedBlockingQueue\u003cRunnable\u003e());\n+        new LinkedBlockingQueue\u003cRunnable\u003e(),\n+        tf);\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n         ContainerLauncherEvent event \u003d null;\n         while (!Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             LOG.error(\"Returning, interrupted : \" + e);\n             return;\n           }\n \n           int poolSize \u003d launcherPool.getCorePoolSize();\n \n           // See if we need up the pool size only if haven\u0027t reached the\n           // maximum limit yet.\n           if (poolSize !\u003d limitOnPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n             int numNodes \u003d ugiMap.size();\n             int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n \n             if (poolSize \u003c\u003d idealPoolSize) {\n               // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n               // later is just a buffer so we are not always increasing the\n               // pool-size\n               launcherPool.setCorePoolSize(idealPoolSize + INITIAL_POOL_SIZE);\n             }\n           }\n \n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(new EventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     });\n+    eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n     eventHandlingThread.start();\n     super.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n    // Start with a default core-pool size of 10 and change it dynamically.\n    ThreadFactory tf \u003d new ThreadFactoryBuilder()\n      .setNameFormat(\"ContainerLauncher #%d\")\n      .build();\n    launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n        Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n        new LinkedBlockingQueue\u003cRunnable\u003e(),\n        tf);\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n\n          int poolSize \u003d launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven\u0027t reached the\n          // maximum limit yet.\n          if (poolSize !\u003d limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int numNodes \u003d ugiMap.size();\n            int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize \u003c\u003d idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              launcherPool.setCorePoolSize(idealPoolSize + INITIAL_POOL_SIZE);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    });\n    eventHandlingThread.setName(\"ContainerLauncher Event Handler\");\n    eventHandlingThread.start();\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
      "extendedDetails": {}
    },
    "d09ceac1f7a85fce688b20528a1b095a8042bebd": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2691. Increase threadpool size for launching containers in MapReduce ApplicationMaster. Contributed by Vinod K V.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1175294 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/09/11 9:43 PM",
      "commitName": "d09ceac1f7a85fce688b20528a1b095a8042bebd",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "13/09/11 11:15 AM",
      "commitNameOld": "88ff272cfd2544a8436b2e7bdbf783ed425725d4",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 11.44,
      "commitsBetweenForRepo": 72,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,48 @@\n   public void start() {\n-    launcherPool \u003d\n-        new ThreadPoolExecutor(getConfig().getInt(\n-            MRJobConfig.MR_AM_CONTAINERLAUNCHER_THREAD_COUNT, 10),\n-            Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n-            new LinkedBlockingQueue\u003cRunnable\u003e());\n-    launcherPool.prestartAllCoreThreads(); // Wait for work.\n+    // Start with a default core-pool size of 10 and change it dynamically.\n+    launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n+        Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n+        new LinkedBlockingQueue\u003cRunnable\u003e());\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n         ContainerLauncherEvent event \u003d null;\n         while (!Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             LOG.error(\"Returning, interrupted : \" + e);\n             return;\n           }\n+\n+          int poolSize \u003d launcherPool.getCorePoolSize();\n+\n+          // See if we need up the pool size only if haven\u0027t reached the\n+          // maximum limit yet.\n+          if (poolSize !\u003d limitOnPoolSize) {\n+\n+            // nodes where containers will run at *this* point of time. This is\n+            // *not* the cluster size and doesn\u0027t need to be.\n+            int numNodes \u003d ugiMap.size();\n+            int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n+\n+            if (poolSize \u003c\u003d idealPoolSize) {\n+              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n+              // later is just a buffer so we are not always increasing the\n+              // pool-size\n+              launcherPool.setCorePoolSize(idealPoolSize + INITIAL_POOL_SIZE);\n+            }\n+          }\n+\n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(new EventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     });\n     eventHandlingThread.start();\n     super.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n    // Start with a default core-pool size of 10 and change it dynamically.\n    launcherPool \u003d new ThreadPoolExecutor(INITIAL_POOL_SIZE,\n        Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n        new LinkedBlockingQueue\u003cRunnable\u003e());\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n\n          int poolSize \u003d launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven\u0027t reached the\n          // maximum limit yet.\n          if (poolSize !\u003d limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int numNodes \u003d ugiMap.size();\n            int idealPoolSize \u003d Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize \u003c\u003d idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              launcherPool.setCorePoolSize(idealPoolSize + INITIAL_POOL_SIZE);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    });\n    eventHandlingThread.start();\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
      "extendedDetails": {}
    },
    "fafe8cd28e726566509c679e19d7da622f29f90d": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2864. Normalize configuration variable names for YARN. Contributed by Robert Evans.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1166955 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/09/11 6:44 PM",
      "commitName": "fafe8cd28e726566509c679e19d7da622f29f90d",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "31/08/11 4:38 AM",
      "commitNameOld": "ade0f0560f729e50382c6992f713f29e2dd5b270",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 8.59,
      "commitsBetweenForRepo": 49,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,30 @@\n   public void start() {\n     launcherPool \u003d\n         new ThreadPoolExecutor(getConfig().getInt(\n-            AMConstants.CONTAINERLAUNCHER_THREADPOOL_SIZE, 10),\n+            MRJobConfig.MR_AM_CONTAINERLAUNCHER_THREAD_COUNT, 10),\n             Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n             new LinkedBlockingQueue\u003cRunnable\u003e());\n     launcherPool.prestartAllCoreThreads(); // Wait for work.\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n         ContainerLauncherEvent event \u003d null;\n         while (!Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             LOG.error(\"Returning, interrupted : \" + e);\n             return;\n           }\n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(new EventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     });\n     eventHandlingThread.start();\n     super.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n    launcherPool \u003d\n        new ThreadPoolExecutor(getConfig().getInt(\n            MRJobConfig.MR_AM_CONTAINERLAUNCHER_THREAD_COUNT, 10),\n            Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n            new LinkedBlockingQueue\u003cRunnable\u003e());\n    launcherPool.prestartAllCoreThreads(); // Wait for work.\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    });\n    eventHandlingThread.start();\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void start() {\n    launcherPool \u003d\n        new ThreadPoolExecutor(getConfig().getInt(\n            AMConstants.CONTAINERLAUNCHER_THREADPOOL_SIZE, 10),\n            Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n            new LinkedBlockingQueue\u003cRunnable\u003e());\n    launcherPool.prestartAllCoreThreads(); // Wait for work.\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    });\n    eventHandlingThread.start();\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,30 @@\n+  public void start() {\n+    launcherPool \u003d\n+        new ThreadPoolExecutor(getConfig().getInt(\n+            AMConstants.CONTAINERLAUNCHER_THREADPOOL_SIZE, 10),\n+            Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n+            new LinkedBlockingQueue\u003cRunnable\u003e());\n+    launcherPool.prestartAllCoreThreads(); // Wait for work.\n+    eventHandlingThread \u003d new Thread(new Runnable() {\n+      @Override\n+      public void run() {\n+        ContainerLauncherEvent event \u003d null;\n+        while (!Thread.currentThread().isInterrupted()) {\n+          try {\n+            event \u003d eventQueue.take();\n+          } catch (InterruptedException e) {\n+            LOG.error(\"Returning, interrupted : \" + e);\n+            return;\n+          }\n+          // the events from the queue are handled in parallel\n+          // using a thread pool\n+          launcherPool.execute(new EventProcessor(event));\n+\n+          // TODO: Group launching of multiple containers to a single\n+          // NodeManager into a single connection\n+        }\n+      }\n+    });\n+    eventHandlingThread.start();\n+    super.start();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n    launcherPool \u003d\n        new ThreadPoolExecutor(getConfig().getInt(\n            AMConstants.CONTAINERLAUNCHER_THREADPOOL_SIZE, 10),\n            Integer.MAX_VALUE, 1, TimeUnit.HOURS,\n            new LinkedBlockingQueue\u003cRunnable\u003e());\n    launcherPool.prestartAllCoreThreads(); // Wait for work.\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        ContainerLauncherEvent event \u003d null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    });\n    eventHandlingThread.start();\n    super.start();\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java"
    }
  }
}