{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RSLegacyRawEncoder.java",
  "functionName": "doEncode",
  "functionId": "doEncode___encodingState-ByteBufferEncodingState",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSLegacyRawEncoder.java",
  "functionStartLine": 56,
  "functionEndLine": 88,
  "numCommitsSeen": 10,
  "timeTaken": 3170,
  "changeHistory": [
    "a22fe02fba66280a8e994282e9ead23d9e20669a",
    "77202fa1035a54496d11d07472fbc399148ff630",
    "efdc0070d880c7e1b778e0029a1b827ca962ce70",
    "6e4f8a46c5ce983493cb0ac2234fceafdb3a5613",
    "343c0e76fcd95ac739ca7cd6742c9d617e19fc37",
    "17f7cdc04764524c091bb0e9eb43399f88ac0e6b",
    "dae27f6dd14ac3ed0b9821a3c5239569b13f6adf"
  ],
  "changeHistoryShort": {
    "a22fe02fba66280a8e994282e9ead23d9e20669a": "Yfilerename",
    "77202fa1035a54496d11d07472fbc399148ff630": "Ymultichange(Yparameterchange,Ybodychange)",
    "efdc0070d880c7e1b778e0029a1b827ca962ce70": "Yfilerename",
    "6e4f8a46c5ce983493cb0ac2234fceafdb3a5613": "Ybodychange",
    "343c0e76fcd95ac739ca7cd6742c9d617e19fc37": "Ybodychange",
    "17f7cdc04764524c091bb0e9eb43399f88ac0e6b": "Yfilerename",
    "dae27f6dd14ac3ed0b9821a3c5239569b13f6adf": "Yintroduced"
  },
  "changeHistoryDetails": {
    "a22fe02fba66280a8e994282e9ead23d9e20669a": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-14261. Some refactoring work for erasure coding raw coder. Contributed by Lin Zeng.\n",
      "commitDate": "21/04/17 11:35 AM",
      "commitName": "a22fe02fba66280a8e994282e9ead23d9e20669a",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "20/04/17 10:33 PM",
      "commitNameOld": "b0803388fc5ec03b774aa003f52232deb8db6f69",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 0.54,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected void doEncode(ByteBufferEncodingState encodingState) {\n    CoderUtil.resetOutputBuffers(encodingState.outputs,\n        encodingState.encodeLength);\n    // parity units + data units\n    ByteBuffer[] all \u003d new ByteBuffer[encodingState.outputs.length +\n        encodingState.inputs.length];\n\n    if (allowChangeInputs()) {\n      System.arraycopy(encodingState.outputs, 0, all, 0,\n          encodingState.outputs.length);\n      System.arraycopy(encodingState.inputs, 0, all,\n          encodingState.outputs.length, encodingState.inputs.length);\n    } else {\n      System.arraycopy(encodingState.outputs, 0, all, 0,\n          encodingState.outputs.length);\n\n      /**\n       * Note when this coder would be really (rarely) used in a production\n       * system, this can  be optimized to cache and reuse the new allocated\n       * buffers avoiding reallocating.\n       */\n      ByteBuffer tmp;\n      for (int i \u003d 0; i \u003c encodingState.inputs.length; i++) {\n        tmp \u003d ByteBuffer.allocate(encodingState.inputs[i].remaining());\n        tmp.put(encodingState.inputs[i]);\n        tmp.flip();\n        all[encodingState.outputs.length + i] \u003d tmp;\n      }\n    }\n\n    // Compute the remainder\n    RSUtil.GF.remainder(all, generatingPolynomial);\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSLegacyRawEncoder.java",
      "extendedDetails": {
        "oldPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawEncoderLegacy.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSLegacyRawEncoder.java"
      }
    },
    "77202fa1035a54496d11d07472fbc399148ff630": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HADOOP-13010. Refactor raw erasure coders. Contributed by Kai Zheng\n",
      "commitDate": "26/05/16 10:23 PM",
      "commitName": "77202fa1035a54496d11d07472fbc399148ff630",
      "commitAuthor": "Kai Zheng",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-13010. Refactor raw erasure coders. Contributed by Kai Zheng\n",
          "commitDate": "26/05/16 10:23 PM",
          "commitName": "77202fa1035a54496d11d07472fbc399148ff630",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "24/02/16 2:29 PM",
          "commitNameOld": "efdc0070d880c7e1b778e0029a1b827ca962ce70",
          "commitAuthorOld": "Zhe Zhang",
          "daysBetweenCommits": 92.29,
          "commitsBetweenForRepo": 576,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,27 +1,33 @@\n-  protected void doEncode(ByteBuffer[] inputs, ByteBuffer[] outputs) {\n+  protected void doEncode(ByteBufferEncodingState encodingState) {\n+    CoderUtil.resetOutputBuffers(encodingState.outputs,\n+        encodingState.encodeLength);\n     // parity units + data units\n-    ByteBuffer[] all \u003d new ByteBuffer[outputs.length + inputs.length];\n+    ByteBuffer[] all \u003d new ByteBuffer[encodingState.outputs.length +\n+        encodingState.inputs.length];\n \n-    if (isAllowingChangeInputs()) {\n-      System.arraycopy(outputs, 0, all, 0, outputs.length);\n-      System.arraycopy(inputs, 0, all, outputs.length, inputs.length);\n+    if (allowChangeInputs()) {\n+      System.arraycopy(encodingState.outputs, 0, all, 0,\n+          encodingState.outputs.length);\n+      System.arraycopy(encodingState.inputs, 0, all,\n+          encodingState.outputs.length, encodingState.inputs.length);\n     } else {\n-      System.arraycopy(outputs, 0, all, 0, outputs.length);\n+      System.arraycopy(encodingState.outputs, 0, all, 0,\n+          encodingState.outputs.length);\n \n       /**\n        * Note when this coder would be really (rarely) used in a production\n        * system, this can  be optimized to cache and reuse the new allocated\n        * buffers avoiding reallocating.\n        */\n       ByteBuffer tmp;\n-      for (int i \u003d 0; i \u003c inputs.length; i++) {\n-        tmp \u003d ByteBuffer.allocate(inputs[i].remaining());\n-        tmp.put(inputs[i]);\n+      for (int i \u003d 0; i \u003c encodingState.inputs.length; i++) {\n+        tmp \u003d ByteBuffer.allocate(encodingState.inputs[i].remaining());\n+        tmp.put(encodingState.inputs[i]);\n         tmp.flip();\n-        all[outputs.length + i] \u003d tmp;\n+        all[encodingState.outputs.length + i] \u003d tmp;\n       }\n     }\n \n     // Compute the remainder\n     RSUtil.GF.remainder(all, generatingPolynomial);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void doEncode(ByteBufferEncodingState encodingState) {\n    CoderUtil.resetOutputBuffers(encodingState.outputs,\n        encodingState.encodeLength);\n    // parity units + data units\n    ByteBuffer[] all \u003d new ByteBuffer[encodingState.outputs.length +\n        encodingState.inputs.length];\n\n    if (allowChangeInputs()) {\n      System.arraycopy(encodingState.outputs, 0, all, 0,\n          encodingState.outputs.length);\n      System.arraycopy(encodingState.inputs, 0, all,\n          encodingState.outputs.length, encodingState.inputs.length);\n    } else {\n      System.arraycopy(encodingState.outputs, 0, all, 0,\n          encodingState.outputs.length);\n\n      /**\n       * Note when this coder would be really (rarely) used in a production\n       * system, this can  be optimized to cache and reuse the new allocated\n       * buffers avoiding reallocating.\n       */\n      ByteBuffer tmp;\n      for (int i \u003d 0; i \u003c encodingState.inputs.length; i++) {\n        tmp \u003d ByteBuffer.allocate(encodingState.inputs[i].remaining());\n        tmp.put(encodingState.inputs[i]);\n        tmp.flip();\n        all[encodingState.outputs.length + i] \u003d tmp;\n      }\n    }\n\n    // Compute the remainder\n    RSUtil.GF.remainder(all, generatingPolynomial);\n  }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawEncoderLegacy.java",
          "extendedDetails": {
            "oldValue": "[inputs-ByteBuffer[], outputs-ByteBuffer[]]",
            "newValue": "[encodingState-ByteBufferEncodingState]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-13010. Refactor raw erasure coders. Contributed by Kai Zheng\n",
          "commitDate": "26/05/16 10:23 PM",
          "commitName": "77202fa1035a54496d11d07472fbc399148ff630",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "24/02/16 2:29 PM",
          "commitNameOld": "efdc0070d880c7e1b778e0029a1b827ca962ce70",
          "commitAuthorOld": "Zhe Zhang",
          "daysBetweenCommits": 92.29,
          "commitsBetweenForRepo": 576,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,27 +1,33 @@\n-  protected void doEncode(ByteBuffer[] inputs, ByteBuffer[] outputs) {\n+  protected void doEncode(ByteBufferEncodingState encodingState) {\n+    CoderUtil.resetOutputBuffers(encodingState.outputs,\n+        encodingState.encodeLength);\n     // parity units + data units\n-    ByteBuffer[] all \u003d new ByteBuffer[outputs.length + inputs.length];\n+    ByteBuffer[] all \u003d new ByteBuffer[encodingState.outputs.length +\n+        encodingState.inputs.length];\n \n-    if (isAllowingChangeInputs()) {\n-      System.arraycopy(outputs, 0, all, 0, outputs.length);\n-      System.arraycopy(inputs, 0, all, outputs.length, inputs.length);\n+    if (allowChangeInputs()) {\n+      System.arraycopy(encodingState.outputs, 0, all, 0,\n+          encodingState.outputs.length);\n+      System.arraycopy(encodingState.inputs, 0, all,\n+          encodingState.outputs.length, encodingState.inputs.length);\n     } else {\n-      System.arraycopy(outputs, 0, all, 0, outputs.length);\n+      System.arraycopy(encodingState.outputs, 0, all, 0,\n+          encodingState.outputs.length);\n \n       /**\n        * Note when this coder would be really (rarely) used in a production\n        * system, this can  be optimized to cache and reuse the new allocated\n        * buffers avoiding reallocating.\n        */\n       ByteBuffer tmp;\n-      for (int i \u003d 0; i \u003c inputs.length; i++) {\n-        tmp \u003d ByteBuffer.allocate(inputs[i].remaining());\n-        tmp.put(inputs[i]);\n+      for (int i \u003d 0; i \u003c encodingState.inputs.length; i++) {\n+        tmp \u003d ByteBuffer.allocate(encodingState.inputs[i].remaining());\n+        tmp.put(encodingState.inputs[i]);\n         tmp.flip();\n-        all[outputs.length + i] \u003d tmp;\n+        all[encodingState.outputs.length + i] \u003d tmp;\n       }\n     }\n \n     // Compute the remainder\n     RSUtil.GF.remainder(all, generatingPolynomial);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void doEncode(ByteBufferEncodingState encodingState) {\n    CoderUtil.resetOutputBuffers(encodingState.outputs,\n        encodingState.encodeLength);\n    // parity units + data units\n    ByteBuffer[] all \u003d new ByteBuffer[encodingState.outputs.length +\n        encodingState.inputs.length];\n\n    if (allowChangeInputs()) {\n      System.arraycopy(encodingState.outputs, 0, all, 0,\n          encodingState.outputs.length);\n      System.arraycopy(encodingState.inputs, 0, all,\n          encodingState.outputs.length, encodingState.inputs.length);\n    } else {\n      System.arraycopy(encodingState.outputs, 0, all, 0,\n          encodingState.outputs.length);\n\n      /**\n       * Note when this coder would be really (rarely) used in a production\n       * system, this can  be optimized to cache and reuse the new allocated\n       * buffers avoiding reallocating.\n       */\n      ByteBuffer tmp;\n      for (int i \u003d 0; i \u003c encodingState.inputs.length; i++) {\n        tmp \u003d ByteBuffer.allocate(encodingState.inputs[i].remaining());\n        tmp.put(encodingState.inputs[i]);\n        tmp.flip();\n        all[encodingState.outputs.length + i] \u003d tmp;\n      }\n    }\n\n    // Compute the remainder\n    RSUtil.GF.remainder(all, generatingPolynomial);\n  }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawEncoderLegacy.java",
          "extendedDetails": {}
        }
      ]
    },
    "efdc0070d880c7e1b778e0029a1b827ca962ce70": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-12808. Rename the RS coder from HDFS-RAID as legacy. Contributed by Rui Li.\n\nChange-Id: Icb64eb60833fe0139aadb6da9aa666f664defc0e\n",
      "commitDate": "24/02/16 2:29 PM",
      "commitName": "efdc0070d880c7e1b778e0029a1b827ca962ce70",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "24/02/16 1:55 PM",
      "commitNameOld": "d6b181c6faa56e43c9f05d2cc860a0aeb940fd90",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected void doEncode(ByteBuffer[] inputs, ByteBuffer[] outputs) {\n    // parity units + data units\n    ByteBuffer[] all \u003d new ByteBuffer[outputs.length + inputs.length];\n\n    if (isAllowingChangeInputs()) {\n      System.arraycopy(outputs, 0, all, 0, outputs.length);\n      System.arraycopy(inputs, 0, all, outputs.length, inputs.length);\n    } else {\n      System.arraycopy(outputs, 0, all, 0, outputs.length);\n\n      /**\n       * Note when this coder would be really (rarely) used in a production\n       * system, this can  be optimized to cache and reuse the new allocated\n       * buffers avoiding reallocating.\n       */\n      ByteBuffer tmp;\n      for (int i \u003d 0; i \u003c inputs.length; i++) {\n        tmp \u003d ByteBuffer.allocate(inputs[i].remaining());\n        tmp.put(inputs[i]);\n        tmp.flip();\n        all[outputs.length + i] \u003d tmp;\n      }\n    }\n\n    // Compute the remainder\n    RSUtil.GF.remainder(all, generatingPolynomial);\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawEncoderLegacy.java",
      "extendedDetails": {
        "oldPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawEncoder.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawEncoderLegacy.java"
      }
    },
    "6e4f8a46c5ce983493cb0ac2234fceafdb3a5613": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12047. Indicate preference not to affect input buffers during coding in erasure coder. (Contributed by Kai Zheng)\n",
      "commitDate": "01/11/15 6:40 PM",
      "commitName": "6e4f8a46c5ce983493cb0ac2234fceafdb3a5613",
      "commitAuthor": "Walter Su",
      "commitDateOld": "07/10/15 6:12 PM",
      "commitNameOld": "66e2cfa1a0285f2b4f62a4ffb4d5c1ee54f76156",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 25.06,
      "commitsBetweenForRepo": 227,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,27 @@\n   protected void doEncode(ByteBuffer[] inputs, ByteBuffer[] outputs) {\n     // parity units + data units\n     ByteBuffer[] all \u003d new ByteBuffer[outputs.length + inputs.length];\n-    System.arraycopy(outputs, 0, all, 0, outputs.length);\n-    System.arraycopy(inputs, 0, all, outputs.length, inputs.length);\n+\n+    if (isAllowingChangeInputs()) {\n+      System.arraycopy(outputs, 0, all, 0, outputs.length);\n+      System.arraycopy(inputs, 0, all, outputs.length, inputs.length);\n+    } else {\n+      System.arraycopy(outputs, 0, all, 0, outputs.length);\n+\n+      /**\n+       * Note when this coder would be really (rarely) used in a production\n+       * system, this can  be optimized to cache and reuse the new allocated\n+       * buffers avoiding reallocating.\n+       */\n+      ByteBuffer tmp;\n+      for (int i \u003d 0; i \u003c inputs.length; i++) {\n+        tmp \u003d ByteBuffer.allocate(inputs[i].remaining());\n+        tmp.put(inputs[i]);\n+        tmp.flip();\n+        all[outputs.length + i] \u003d tmp;\n+      }\n+    }\n \n     // Compute the remainder\n     RSUtil.GF.remainder(all, generatingPolynomial);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void doEncode(ByteBuffer[] inputs, ByteBuffer[] outputs) {\n    // parity units + data units\n    ByteBuffer[] all \u003d new ByteBuffer[outputs.length + inputs.length];\n\n    if (isAllowingChangeInputs()) {\n      System.arraycopy(outputs, 0, all, 0, outputs.length);\n      System.arraycopy(inputs, 0, all, outputs.length, inputs.length);\n    } else {\n      System.arraycopy(outputs, 0, all, 0, outputs.length);\n\n      /**\n       * Note when this coder would be really (rarely) used in a production\n       * system, this can  be optimized to cache and reuse the new allocated\n       * buffers avoiding reallocating.\n       */\n      ByteBuffer tmp;\n      for (int i \u003d 0; i \u003c inputs.length; i++) {\n        tmp \u003d ByteBuffer.allocate(inputs[i].remaining());\n        tmp.put(inputs[i]);\n        tmp.flip();\n        all[outputs.length + i] \u003d tmp;\n      }\n    }\n\n    // Compute the remainder\n    RSUtil.GF.remainder(all, generatingPolynomial);\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawEncoder.java",
      "extendedDetails": {}
    },
    "343c0e76fcd95ac739ca7cd6742c9d617e19fc37": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11938. Enhance ByteBuffer version encode/decode API of raw erasure coder. Contributed by Kai Zheng.\n",
      "commitDate": "26/05/15 12:02 PM",
      "commitName": "343c0e76fcd95ac739ca7cd6742c9d617e19fc37",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "26/05/15 11:55 AM",
      "commitNameOld": "17f7cdc04764524c091bb0e9eb43399f88ac0e6b",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 76,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,9 @@\n   protected void doEncode(ByteBuffer[] inputs, ByteBuffer[] outputs) {\n-    ByteBuffer[] data \u003d new ByteBuffer[getNumDataUnits() + getNumParityUnits()];\n-    for (int i \u003d 0; i \u003c getNumParityUnits(); i++) {\n-      data[i] \u003d outputs[i];\n-    }\n-    for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n-      data[i + getNumParityUnits()] \u003d inputs[i];\n-    }\n+    // parity units + data units\n+    ByteBuffer[] all \u003d new ByteBuffer[outputs.length + inputs.length];\n+    System.arraycopy(outputs, 0, all, 0, outputs.length);\n+    System.arraycopy(inputs, 0, all, outputs.length, inputs.length);\n \n     // Compute the remainder\n-    RSUtil.GF.remainder(data, generatingPolynomial);\n+    RSUtil.GF.remainder(all, generatingPolynomial);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void doEncode(ByteBuffer[] inputs, ByteBuffer[] outputs) {\n    // parity units + data units\n    ByteBuffer[] all \u003d new ByteBuffer[outputs.length + inputs.length];\n    System.arraycopy(outputs, 0, all, 0, outputs.length);\n    System.arraycopy(inputs, 0, all, outputs.length, inputs.length);\n\n    // Compute the remainder\n    RSUtil.GF.remainder(all, generatingPolynomial);\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawEncoder.java",
      "extendedDetails": {}
    },
    "17f7cdc04764524c091bb0e9eb43399f88ac0e6b": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-11805 Better to rename some raw erasure coders. Contributed by Kai Zheng\n",
      "commitDate": "26/05/15 11:55 AM",
      "commitName": "17f7cdc04764524c091bb0e9eb43399f88ac0e6b",
      "commitAuthor": "Kai Zheng",
      "commitDateOld": "26/05/15 11:55 AM",
      "commitNameOld": "146ce7a9784e52432b76164009336a4b2cf2860e",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected void doEncode(ByteBuffer[] inputs, ByteBuffer[] outputs) {\n    ByteBuffer[] data \u003d new ByteBuffer[getNumDataUnits() + getNumParityUnits()];\n    for (int i \u003d 0; i \u003c getNumParityUnits(); i++) {\n      data[i] \u003d outputs[i];\n    }\n    for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n      data[i + getNumParityUnits()] \u003d inputs[i];\n    }\n\n    // Compute the remainder\n    RSUtil.GF.remainder(data, generatingPolynomial);\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawEncoder.java",
      "extendedDetails": {
        "oldPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/JRSRawEncoder.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawEncoder.java"
      }
    },
    "dae27f6dd14ac3ed0b9821a3c5239569b13f6adf": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-11542. Raw Reed-Solomon coder in pure Java. Contributed by Kai Zheng\n",
      "commitDate": "26/05/15 11:07 AM",
      "commitName": "dae27f6dd14ac3ed0b9821a3c5239569b13f6adf",
      "commitAuthor": "drankye",
      "diff": "@@ -0,0 +1,12 @@\n+  protected void doEncode(ByteBuffer[] inputs, ByteBuffer[] outputs) {\n+    ByteBuffer[] data \u003d new ByteBuffer[getNumDataUnits() + getNumParityUnits()];\n+    for (int i \u003d 0; i \u003c getNumParityUnits(); i++) {\n+      data[i] \u003d outputs[i];\n+    }\n+    for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n+      data[i + getNumParityUnits()] \u003d inputs[i];\n+    }\n+\n+    // Compute the remainder\n+    RSUtil.GF.remainder(data, generatingPolynomial);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected void doEncode(ByteBuffer[] inputs, ByteBuffer[] outputs) {\n    ByteBuffer[] data \u003d new ByteBuffer[getNumDataUnits() + getNumParityUnits()];\n    for (int i \u003d 0; i \u003c getNumParityUnits(); i++) {\n      data[i] \u003d outputs[i];\n    }\n    for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n      data[i + getNumParityUnits()] \u003d inputs[i];\n    }\n\n    // Compute the remainder\n    RSUtil.GF.remainder(data, generatingPolynomial);\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/JRSRawEncoder.java"
    }
  }
}