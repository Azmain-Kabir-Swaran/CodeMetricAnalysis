{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPlacementPolicyRackFaultTolerant.java",
  "functionName": "chooseOnce",
  "functionId": "chooseOnce___numOfReplicas-int__writer-Node__excludedNodes-Set__Node__(modifiers-final)__blocksize-long(modifiers-final)__maxNodesPerRack-int(modifiers-final)__results-List__DatanodeStorageInfo__(modifiers-final)__avoidStaleNodes-boolean(modifiers-final)__storageTypes-EnumMap__StorageType,Integer__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyRackFaultTolerant.java",
  "functionStartLine": 208,
  "functionEndLine": 229,
  "numCommitsSeen": 8,
  "timeTaken": 1195,
  "changeHistory": [
    "c1d50a91f7c05e4aaf4655380c8dcd11703ff158",
    "9595cc003ca5ed3d59b6942056a4fcb9080f79c9"
  ],
  "changeHistoryShort": {
    "c1d50a91f7c05e4aaf4655380c8dcd11703ff158": "Yfilerename",
    "9595cc003ca5ed3d59b6942056a4fcb9080f79c9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c1d50a91f7c05e4aaf4655380c8dcd11703ff158": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8513. Rename BlockPlacementPolicyRackFaultTolarent to BlockPlacementPolicyRackFaultTolerant. (wang)\n",
      "commitDate": "02/06/15 3:48 PM",
      "commitName": "c1d50a91f7c05e4aaf4655380c8dcd11703ff158",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "02/06/15 3:39 PM",
      "commitNameOld": "efc510a570cf880e7df1b69932aa41932658ee51",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private Node chooseOnce(int numOfReplicas,\n                            Node writer,\n                            final Set\u003cNode\u003e excludedNodes,\n                            final long blocksize,\n                            final int maxNodesPerRack,\n                            final List\u003cDatanodeStorageInfo\u003e results,\n                            final boolean avoidStaleNodes,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                            throws NotEnoughReplicasException {\n    if (numOfReplicas \u003d\u003d 0) {\n      return writer;\n    }\n    writer \u003d chooseLocalStorage(writer, excludedNodes, blocksize,\n        maxNodesPerRack, results, avoidStaleNodes, storageTypes, true)\n        .getDatanodeDescriptor();\n    if (--numOfReplicas \u003d\u003d 0) {\n      return writer;\n    }\n    chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,\n        maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    return writer;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyRackFaultTolerant.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyRackFaultTolarent.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyRackFaultTolerant.java"
      }
    },
    "9595cc003ca5ed3d59b6942056a4fcb9080f79c9": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7891. A block placement policy with best rack failure tolerance.  Contributed by Walter Su\n",
      "commitDate": "16/04/15 6:25 PM",
      "commitName": "9595cc003ca5ed3d59b6942056a4fcb9080f79c9",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "diff": "@@ -0,0 +1,22 @@\n+  private Node chooseOnce(int numOfReplicas,\n+                            Node writer,\n+                            final Set\u003cNode\u003e excludedNodes,\n+                            final long blocksize,\n+                            final int maxNodesPerRack,\n+                            final List\u003cDatanodeStorageInfo\u003e results,\n+                            final boolean avoidStaleNodes,\n+                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n+                            throws NotEnoughReplicasException {\n+    if (numOfReplicas \u003d\u003d 0) {\n+      return writer;\n+    }\n+    writer \u003d chooseLocalStorage(writer, excludedNodes, blocksize,\n+        maxNodesPerRack, results, avoidStaleNodes, storageTypes, true)\n+        .getDatanodeDescriptor();\n+    if (--numOfReplicas \u003d\u003d 0) {\n+      return writer;\n+    }\n+    chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,\n+        maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n+    return writer;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private Node chooseOnce(int numOfReplicas,\n                            Node writer,\n                            final Set\u003cNode\u003e excludedNodes,\n                            final long blocksize,\n                            final int maxNodesPerRack,\n                            final List\u003cDatanodeStorageInfo\u003e results,\n                            final boolean avoidStaleNodes,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                            throws NotEnoughReplicasException {\n    if (numOfReplicas \u003d\u003d 0) {\n      return writer;\n    }\n    writer \u003d chooseLocalStorage(writer, excludedNodes, blocksize,\n        maxNodesPerRack, results, avoidStaleNodes, storageTypes, true)\n        .getDatanodeDescriptor();\n    if (--numOfReplicas \u003d\u003d 0) {\n      return writer;\n    }\n    chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,\n        maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    return writer;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyRackFaultTolarent.java"
    }
  }
}