{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ClientNamenodeProtocolTranslatorPB.java",
  "functionName": "updatePipeline",
  "functionId": "updatePipeline___clientName-String__oldBlock-ExtendedBlock__newBlock-ExtendedBlock__newNodes-DatanodeID[]__storageIDs-String[]",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java",
  "functionStartLine": 1110,
  "functionEndLine": 1125,
  "numCommitsSeen": 154,
  "timeTaken": 3350,
  "changeHistory": [
    "63d9f1596c92206cce3b72e3214d2fb5f6242b90",
    "06022b8fdc40e50eaac63758246353058e8cfa6d",
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42"
  ],
  "changeHistoryShort": {
    "63d9f1596c92206cce3b72e3214d2fb5f6242b90": "Yfilerename",
    "06022b8fdc40e50eaac63758246353058e8cfa6d": "Ybodychange",
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": "Ybodychange"
  },
  "changeHistoryDetails": {
    "63d9f1596c92206cce3b72e3214d2fb5f6242b90": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-9039. Separate client and server side methods of o.a.h.hdfs.NameNodeProxies. Contributed by Mingliang Liu.\n",
      "commitDate": "22/09/15 8:52 PM",
      "commitName": "63d9f1596c92206cce3b72e3214d2fb5f6242b90",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "22/09/15 9:08 AM",
      "commitNameOld": "cc2b4739902df60254dce2ddb23ef8f6ff2a3495",
      "commitAuthorOld": "Harsh J",
      "daysBetweenCommits": 0.49,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n      ExtendedBlock newBlock, DatanodeID[] newNodes, String[] storageIDs) throws IOException {\n    UpdatePipelineRequestProto req \u003d UpdatePipelineRequestProto.newBuilder()\n        .setClientName(clientName)\n        .setOldBlock(PBHelperClient.convert(oldBlock))\n        .setNewBlock(PBHelperClient.convert(newBlock))\n        .addAllNewNodes(Arrays.asList(PBHelperClient.convert(newNodes)))\n        .addAllStorageIDs(storageIDs \u003d\u003d null ? null : Arrays.asList(storageIDs))\n        .build();\n    try {\n      rpcProxy.updatePipeline(null, req);\n    } catch (ServiceException e) {\n      throw ProtobufHelper.getRemoteException(e);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java"
      }
    },
    "06022b8fdc40e50eaac63758246353058e8cfa6d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9111. Move hdfs-client protobuf convert methods from PBHelper to PBHelperClient. Contributed by Mingliang Liu.\n",
      "commitDate": "21/09/15 6:53 PM",
      "commitName": "06022b8fdc40e50eaac63758246353058e8cfa6d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "22/08/15 1:31 PM",
      "commitNameOld": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 30.22,
      "commitsBetweenForRepo": 176,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,15 @@\n   public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n       ExtendedBlock newBlock, DatanodeID[] newNodes, String[] storageIDs) throws IOException {\n     UpdatePipelineRequestProto req \u003d UpdatePipelineRequestProto.newBuilder()\n         .setClientName(clientName)\n         .setOldBlock(PBHelperClient.convert(oldBlock))\n         .setNewBlock(PBHelperClient.convert(newBlock))\n-        .addAllNewNodes(Arrays.asList(PBHelper.convert(newNodes)))\n+        .addAllNewNodes(Arrays.asList(PBHelperClient.convert(newNodes)))\n         .addAllStorageIDs(storageIDs \u003d\u003d null ? null : Arrays.asList(storageIDs))\n         .build();\n     try {\n       rpcProxy.updatePipeline(null, req);\n     } catch (ServiceException e) {\n       throw ProtobufHelper.getRemoteException(e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n      ExtendedBlock newBlock, DatanodeID[] newNodes, String[] storageIDs) throws IOException {\n    UpdatePipelineRequestProto req \u003d UpdatePipelineRequestProto.newBuilder()\n        .setClientName(clientName)\n        .setOldBlock(PBHelperClient.convert(oldBlock))\n        .setNewBlock(PBHelperClient.convert(newBlock))\n        .addAllNewNodes(Arrays.asList(PBHelperClient.convert(newNodes)))\n        .addAllStorageIDs(storageIDs \u003d\u003d null ? null : Arrays.asList(storageIDs))\n        .build();\n    try {\n      rpcProxy.updatePipeline(null, req);\n    } catch (ServiceException e) {\n      throw ProtobufHelper.getRemoteException(e);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java",
      "extendedDetails": {}
    },
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8934. Move ShortCircuitShm to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "22/08/15 1:31 PM",
      "commitName": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "05/08/15 10:40 PM",
      "commitNameOld": "cc71ad80e184fc6e5043729e8cfcf6a62ca3e71f",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 16.62,
      "commitsBetweenForRepo": 81,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,15 @@\n   public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n       ExtendedBlock newBlock, DatanodeID[] newNodes, String[] storageIDs) throws IOException {\n     UpdatePipelineRequestProto req \u003d UpdatePipelineRequestProto.newBuilder()\n         .setClientName(clientName)\n-        .setOldBlock(PBHelper.convert(oldBlock))\n-        .setNewBlock(PBHelper.convert(newBlock))\n+        .setOldBlock(PBHelperClient.convert(oldBlock))\n+        .setNewBlock(PBHelperClient.convert(newBlock))\n         .addAllNewNodes(Arrays.asList(PBHelper.convert(newNodes)))\n         .addAllStorageIDs(storageIDs \u003d\u003d null ? null : Arrays.asList(storageIDs))\n         .build();\n     try {\n       rpcProxy.updatePipeline(null, req);\n     } catch (ServiceException e) {\n       throw ProtobufHelper.getRemoteException(e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n      ExtendedBlock newBlock, DatanodeID[] newNodes, String[] storageIDs) throws IOException {\n    UpdatePipelineRequestProto req \u003d UpdatePipelineRequestProto.newBuilder()\n        .setClientName(clientName)\n        .setOldBlock(PBHelperClient.convert(oldBlock))\n        .setNewBlock(PBHelperClient.convert(newBlock))\n        .addAllNewNodes(Arrays.asList(PBHelper.convert(newNodes)))\n        .addAllStorageIDs(storageIDs \u003d\u003d null ? null : Arrays.asList(storageIDs))\n        .build();\n    try {\n      rpcProxy.updatePipeline(null, req);\n    } catch (ServiceException e) {\n      throw ProtobufHelper.getRemoteException(e);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java",
      "extendedDetails": {}
    }
  }
}