{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeAdminBackoffMonitor.java",
  "functionName": "processPendingReplication",
  "functionId": "processPendingReplication",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminBackoffMonitor.java",
  "functionStartLine": 668,
  "functionEndLine": 703,
  "numCommitsSeen": 1,
  "timeTaken": 876,
  "changeHistory": [
    "c93cb6790e0f1c64efd03d859f907a0522010894"
  ],
  "changeHistoryShort": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-14854. Create improved decommission monitor implementation. Contributed by Stephen O\u0027Donnell.\n\nReviewed-by: Inigo Goiri \u003cinigoiri@apache.org\u003e\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "10/12/19 5:16 PM",
      "commitName": "c93cb6790e0f1c64efd03d859f907a0522010894",
      "commitAuthor": "Stephen O\u0027Donnell",
      "diff": "@@ -0,0 +1,36 @@\n+  private void processPendingReplication() {\n+    namesystem.writeLock();\n+    try {\n+      for (Iterator\u003cMap.Entry\u003cDatanodeDescriptor, List\u003cBlockInfo\u003e\u003e\u003e\n+           entIt \u003d pendingRep.entrySet().iterator(); entIt.hasNext();) {\n+        Map.Entry\u003cDatanodeDescriptor, List\u003cBlockInfo\u003e\u003e entry \u003d entIt.next();\n+        DatanodeDescriptor dn \u003d entry.getKey();\n+        List\u003cBlockInfo\u003e blocks \u003d entry.getValue();\n+        if (blocks \u003d\u003d null) {\n+          // should not be able to happen\n+          entIt.remove();\n+          continue;\n+        }\n+        Iterator\u003cBlockInfo\u003e blockIt \u003d  blocks.iterator();\n+        BlockStats suspectBlocks \u003d new BlockStats();\n+        while(blockIt.hasNext()) {\n+          BlockInfo b \u003d blockIt.next();\n+          if (isBlockReplicatedOk(dn, b, true, suspectBlocks)) {\n+            blockIt.remove();\n+          }\n+          numBlocksChecked++;\n+        }\n+        if (blocks.size() \u003d\u003d 0) {\n+          entIt.remove();\n+        }\n+        // Update metrics for this datanode.\n+        dn.getLeavingServiceStatus().set(\n+            suspectBlocks.getOpenFileCount(),\n+            suspectBlocks.getOpenFiles(),\n+            getPendingCountForNode(dn),\n+            suspectBlocks.getOutOfServiceBlockCount());\n+      }\n+    } finally {\n+      namesystem.writeUnlock();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void processPendingReplication() {\n    namesystem.writeLock();\n    try {\n      for (Iterator\u003cMap.Entry\u003cDatanodeDescriptor, List\u003cBlockInfo\u003e\u003e\u003e\n           entIt \u003d pendingRep.entrySet().iterator(); entIt.hasNext();) {\n        Map.Entry\u003cDatanodeDescriptor, List\u003cBlockInfo\u003e\u003e entry \u003d entIt.next();\n        DatanodeDescriptor dn \u003d entry.getKey();\n        List\u003cBlockInfo\u003e blocks \u003d entry.getValue();\n        if (blocks \u003d\u003d null) {\n          // should not be able to happen\n          entIt.remove();\n          continue;\n        }\n        Iterator\u003cBlockInfo\u003e blockIt \u003d  blocks.iterator();\n        BlockStats suspectBlocks \u003d new BlockStats();\n        while(blockIt.hasNext()) {\n          BlockInfo b \u003d blockIt.next();\n          if (isBlockReplicatedOk(dn, b, true, suspectBlocks)) {\n            blockIt.remove();\n          }\n          numBlocksChecked++;\n        }\n        if (blocks.size() \u003d\u003d 0) {\n          entIt.remove();\n        }\n        // Update metrics for this datanode.\n        dn.getLeavingServiceStatus().set(\n            suspectBlocks.getOpenFileCount(),\n            suspectBlocks.getOpenFiles(),\n            getPendingCountForNode(dn),\n            suspectBlocks.getOutOfServiceBlockCount());\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminBackoffMonitor.java"
    }
  }
}