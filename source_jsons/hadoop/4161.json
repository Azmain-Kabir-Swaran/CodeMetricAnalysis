{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ECPolicyLoader.java",
  "functionName": "loadSchemas",
  "functionId": "loadSchemas___root-Element",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/util/ECPolicyLoader.java",
  "functionStartLine": 157,
  "functionEndLine": 182,
  "numCommitsSeen": 3,
  "timeTaken": 442,
  "changeHistory": [
    "b0803388fc5ec03b774aa003f52232deb8db6f69"
  ],
  "changeHistoryShort": {
    "b0803388fc5ec03b774aa003f52232deb8db6f69": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b0803388fc5ec03b774aa003f52232deb8db6f69": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11604. Define and parse erasure code policies. Contributed by Lin Zeng\n",
      "commitDate": "20/04/17 10:33 PM",
      "commitName": "b0803388fc5ec03b774aa003f52232deb8db6f69",
      "commitAuthor": "Kai Zheng",
      "diff": "@@ -0,0 +1,26 @@\n+  private Map\u003cString, ECSchema\u003e loadSchemas(Element root) {\n+    NodeList elements \u003d root.getElementsByTagName(\"schemas\")\n+        .item(0).getChildNodes();\n+    Map\u003cString, ECSchema\u003e schemas \u003d new HashMap\u003cString, ECSchema\u003e();\n+    for (int i \u003d 0; i \u003c elements.getLength(); i++) {\n+      Node node \u003d elements.item(i);\n+      if (node instanceof Element) {\n+        Element element \u003d (Element) node;\n+        if (\"schema\".equals(element.getTagName())) {\n+          String schemaId \u003d element.getAttribute(\"id\");\n+          ECSchema schema \u003d loadSchema(element);\n+          if (!schemas.containsValue(schema)) {\n+            schemas.put(schemaId, schema);\n+          } else {\n+            throw new RuntimeException(\"Repetitive schemas in EC policy\"\n+                + \" configuration file: \" + schemaId);\n+          }\n+        } else {\n+          throw new RuntimeException(\"Bad element in EC policy\"\n+              + \" configuration file: \" + element.getTagName());\n+        }\n+      }\n+    }\n+\n+    return schemas;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private Map\u003cString, ECSchema\u003e loadSchemas(Element root) {\n    NodeList elements \u003d root.getElementsByTagName(\"schemas\")\n        .item(0).getChildNodes();\n    Map\u003cString, ECSchema\u003e schemas \u003d new HashMap\u003cString, ECSchema\u003e();\n    for (int i \u003d 0; i \u003c elements.getLength(); i++) {\n      Node node \u003d elements.item(i);\n      if (node instanceof Element) {\n        Element element \u003d (Element) node;\n        if (\"schema\".equals(element.getTagName())) {\n          String schemaId \u003d element.getAttribute(\"id\");\n          ECSchema schema \u003d loadSchema(element);\n          if (!schemas.containsValue(schema)) {\n            schemas.put(schemaId, schema);\n          } else {\n            throw new RuntimeException(\"Repetitive schemas in EC policy\"\n                + \" configuration file: \" + schemaId);\n          }\n        } else {\n          throw new RuntimeException(\"Bad element in EC policy\"\n              + \" configuration file: \" + element.getTagName());\n        }\n      }\n    }\n\n    return schemas;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/util/ECPolicyLoader.java"
    }
  }
}