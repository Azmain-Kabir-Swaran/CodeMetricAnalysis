{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "INodeFile.java",
  "functionName": "toLong",
  "functionId": "toLong___preferredBlockSize-long__layoutRedundancy-long__storagePolicyID-byte",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
  "functionStartLine": 237,
  "functionEndLine": 247,
  "numCommitsSeen": 460,
  "timeTaken": 4505,
  "changeHistory": [
    "55c07bbed2f475f7b584a86112ee1b6fe0221e98",
    "a2a5d7b5bca715835d92816e7b267b59f7270708",
    "7600e3c48ff2043654dbe9f415a186a336b5ea6c"
  ],
  "changeHistoryShort": {
    "55c07bbed2f475f7b584a86112ee1b6fe0221e98": "Ymultichange(Yparameterchange,Ybodychange)",
    "a2a5d7b5bca715835d92816e7b267b59f7270708": "Ymultichange(Yparameterchange,Ybodychange)",
    "7600e3c48ff2043654dbe9f415a186a336b5ea6c": "Ybodychange"
  },
  "changeHistoryDetails": {
    "55c07bbed2f475f7b584a86112ee1b6fe0221e98": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-11382. Persist Erasure Coding Policy ID in a new optional field in INodeFile in FSImage. Contributed by Manoj Govindassamy.\n",
      "commitDate": "27/02/17 5:07 PM",
      "commitName": "55c07bbed2f475f7b584a86112ee1b6fe0221e98",
      "commitAuthor": "Andrew Wang",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-11382. Persist Erasure Coding Policy ID in a new optional field in INodeFile in FSImage. Contributed by Manoj Govindassamy.\n",
          "commitDate": "27/02/17 5:07 PM",
          "commitName": "55c07bbed2f475f7b584a86112ee1b6fe0221e98",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "18/01/17 1:31 PM",
          "commitNameOld": "a2a5d7b5bca715835d92816e7b267b59f7270708",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 40.15,
          "commitsBetweenForRepo": 201,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,11 @@\n-    static long toLong(long preferredBlockSize, short replication,\n-        BlockType blockType, byte storagePolicyID) {\n-      Preconditions.checkArgument(replication \u003e\u003d 0 \u0026\u0026\n-          replication \u003c\u003d MAX_REDUNDANCY);\n+    static long toLong(long preferredBlockSize, long layoutRedundancy,\n+        byte storagePolicyID) {\n       long h \u003d 0;\n       if (preferredBlockSize \u003d\u003d 0) {\n         preferredBlockSize \u003d PREFERRED_BLOCK_SIZE.BITS.getMin();\n       }\n       h \u003d PREFERRED_BLOCK_SIZE.BITS.combine(preferredBlockSize, h);\n-      // For erasure coded files, replication is used to store ec policy id\n-      // TODO: this is hacky. Add some utility to generate the layoutRedundancy\n-      long layoutRedundancy \u003d 0;\n-      if (blockType \u003d\u003d STRIPED) {\n-        layoutRedundancy |\u003d BLOCK_TYPE_MASK_STRIPED;\n-      }\n-      layoutRedundancy |\u003d replication;\n       h \u003d BLOCK_LAYOUT_AND_REDUNDANCY.BITS.combine(layoutRedundancy, h);\n       h \u003d STORAGE_POLICY_ID.BITS.combine(storagePolicyID, h);\n       return h;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    static long toLong(long preferredBlockSize, long layoutRedundancy,\n        byte storagePolicyID) {\n      long h \u003d 0;\n      if (preferredBlockSize \u003d\u003d 0) {\n        preferredBlockSize \u003d PREFERRED_BLOCK_SIZE.BITS.getMin();\n      }\n      h \u003d PREFERRED_BLOCK_SIZE.BITS.combine(preferredBlockSize, h);\n      h \u003d BLOCK_LAYOUT_AND_REDUNDANCY.BITS.combine(layoutRedundancy, h);\n      h \u003d STORAGE_POLICY_ID.BITS.combine(storagePolicyID, h);\n      return h;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldValue": "[preferredBlockSize-long, replication-short, blockType-BlockType, storagePolicyID-byte]",
            "newValue": "[preferredBlockSize-long, layoutRedundancy-long, storagePolicyID-byte]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-11382. Persist Erasure Coding Policy ID in a new optional field in INodeFile in FSImage. Contributed by Manoj Govindassamy.\n",
          "commitDate": "27/02/17 5:07 PM",
          "commitName": "55c07bbed2f475f7b584a86112ee1b6fe0221e98",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "18/01/17 1:31 PM",
          "commitNameOld": "a2a5d7b5bca715835d92816e7b267b59f7270708",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 40.15,
          "commitsBetweenForRepo": 201,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,11 @@\n-    static long toLong(long preferredBlockSize, short replication,\n-        BlockType blockType, byte storagePolicyID) {\n-      Preconditions.checkArgument(replication \u003e\u003d 0 \u0026\u0026\n-          replication \u003c\u003d MAX_REDUNDANCY);\n+    static long toLong(long preferredBlockSize, long layoutRedundancy,\n+        byte storagePolicyID) {\n       long h \u003d 0;\n       if (preferredBlockSize \u003d\u003d 0) {\n         preferredBlockSize \u003d PREFERRED_BLOCK_SIZE.BITS.getMin();\n       }\n       h \u003d PREFERRED_BLOCK_SIZE.BITS.combine(preferredBlockSize, h);\n-      // For erasure coded files, replication is used to store ec policy id\n-      // TODO: this is hacky. Add some utility to generate the layoutRedundancy\n-      long layoutRedundancy \u003d 0;\n-      if (blockType \u003d\u003d STRIPED) {\n-        layoutRedundancy |\u003d BLOCK_TYPE_MASK_STRIPED;\n-      }\n-      layoutRedundancy |\u003d replication;\n       h \u003d BLOCK_LAYOUT_AND_REDUNDANCY.BITS.combine(layoutRedundancy, h);\n       h \u003d STORAGE_POLICY_ID.BITS.combine(storagePolicyID, h);\n       return h;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    static long toLong(long preferredBlockSize, long layoutRedundancy,\n        byte storagePolicyID) {\n      long h \u003d 0;\n      if (preferredBlockSize \u003d\u003d 0) {\n        preferredBlockSize \u003d PREFERRED_BLOCK_SIZE.BITS.getMin();\n      }\n      h \u003d PREFERRED_BLOCK_SIZE.BITS.combine(preferredBlockSize, h);\n      h \u003d BLOCK_LAYOUT_AND_REDUNDANCY.BITS.combine(layoutRedundancy, h);\n      h \u003d STORAGE_POLICY_ID.BITS.combine(storagePolicyID, h);\n      return h;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {}
        }
      ]
    },
    "a2a5d7b5bca715835d92816e7b267b59f7270708": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-10759. Change fsimage bool isStriped from boolean to an enum. Contributed by Ewan Higgs.\n",
      "commitDate": "18/01/17 1:31 PM",
      "commitName": "a2a5d7b5bca715835d92816e7b267b59f7270708",
      "commitAuthor": "Andrew Wang",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-10759. Change fsimage bool isStriped from boolean to an enum. Contributed by Ewan Higgs.\n",
          "commitDate": "18/01/17 1:31 PM",
          "commitName": "a2a5d7b5bca715835d92816e7b267b59f7270708",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "29/11/16 11:52 PM",
          "commitNameOld": "51e6c1cc3f66f9908d2e816e7291ac34bee43f52",
          "commitAuthorOld": "Kai Zheng",
          "daysBetweenCommits": 49.57,
          "commitsBetweenForRepo": 244,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,20 @@\n     static long toLong(long preferredBlockSize, short replication,\n-        boolean isStriped, byte storagePolicyID) {\n+        BlockType blockType, byte storagePolicyID) {\n       Preconditions.checkArgument(replication \u003e\u003d 0 \u0026\u0026\n           replication \u003c\u003d MAX_REDUNDANCY);\n       long h \u003d 0;\n       if (preferredBlockSize \u003d\u003d 0) {\n         preferredBlockSize \u003d PREFERRED_BLOCK_SIZE.BITS.getMin();\n       }\n       h \u003d PREFERRED_BLOCK_SIZE.BITS.combine(preferredBlockSize, h);\n       // For erasure coded files, replication is used to store ec policy id\n       // TODO: this is hacky. Add some utility to generate the layoutRedundancy\n       long layoutRedundancy \u003d 0;\n-      if (isStriped) {\n-        layoutRedundancy |\u003d 1 \u003c\u003c 11;\n+      if (blockType \u003d\u003d STRIPED) {\n+        layoutRedundancy |\u003d BLOCK_TYPE_MASK_STRIPED;\n       }\n       layoutRedundancy |\u003d replication;\n       h \u003d BLOCK_LAYOUT_AND_REDUNDANCY.BITS.combine(layoutRedundancy, h);\n       h \u003d STORAGE_POLICY_ID.BITS.combine(storagePolicyID, h);\n       return h;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    static long toLong(long preferredBlockSize, short replication,\n        BlockType blockType, byte storagePolicyID) {\n      Preconditions.checkArgument(replication \u003e\u003d 0 \u0026\u0026\n          replication \u003c\u003d MAX_REDUNDANCY);\n      long h \u003d 0;\n      if (preferredBlockSize \u003d\u003d 0) {\n        preferredBlockSize \u003d PREFERRED_BLOCK_SIZE.BITS.getMin();\n      }\n      h \u003d PREFERRED_BLOCK_SIZE.BITS.combine(preferredBlockSize, h);\n      // For erasure coded files, replication is used to store ec policy id\n      // TODO: this is hacky. Add some utility to generate the layoutRedundancy\n      long layoutRedundancy \u003d 0;\n      if (blockType \u003d\u003d STRIPED) {\n        layoutRedundancy |\u003d BLOCK_TYPE_MASK_STRIPED;\n      }\n      layoutRedundancy |\u003d replication;\n      h \u003d BLOCK_LAYOUT_AND_REDUNDANCY.BITS.combine(layoutRedundancy, h);\n      h \u003d STORAGE_POLICY_ID.BITS.combine(storagePolicyID, h);\n      return h;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldValue": "[preferredBlockSize-long, replication-short, isStriped-boolean, storagePolicyID-byte]",
            "newValue": "[preferredBlockSize-long, replication-short, blockType-BlockType, storagePolicyID-byte]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10759. Change fsimage bool isStriped from boolean to an enum. Contributed by Ewan Higgs.\n",
          "commitDate": "18/01/17 1:31 PM",
          "commitName": "a2a5d7b5bca715835d92816e7b267b59f7270708",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "29/11/16 11:52 PM",
          "commitNameOld": "51e6c1cc3f66f9908d2e816e7291ac34bee43f52",
          "commitAuthorOld": "Kai Zheng",
          "daysBetweenCommits": 49.57,
          "commitsBetweenForRepo": 244,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,20 @@\n     static long toLong(long preferredBlockSize, short replication,\n-        boolean isStriped, byte storagePolicyID) {\n+        BlockType blockType, byte storagePolicyID) {\n       Preconditions.checkArgument(replication \u003e\u003d 0 \u0026\u0026\n           replication \u003c\u003d MAX_REDUNDANCY);\n       long h \u003d 0;\n       if (preferredBlockSize \u003d\u003d 0) {\n         preferredBlockSize \u003d PREFERRED_BLOCK_SIZE.BITS.getMin();\n       }\n       h \u003d PREFERRED_BLOCK_SIZE.BITS.combine(preferredBlockSize, h);\n       // For erasure coded files, replication is used to store ec policy id\n       // TODO: this is hacky. Add some utility to generate the layoutRedundancy\n       long layoutRedundancy \u003d 0;\n-      if (isStriped) {\n-        layoutRedundancy |\u003d 1 \u003c\u003c 11;\n+      if (blockType \u003d\u003d STRIPED) {\n+        layoutRedundancy |\u003d BLOCK_TYPE_MASK_STRIPED;\n       }\n       layoutRedundancy |\u003d replication;\n       h \u003d BLOCK_LAYOUT_AND_REDUNDANCY.BITS.combine(layoutRedundancy, h);\n       h \u003d STORAGE_POLICY_ID.BITS.combine(storagePolicyID, h);\n       return h;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    static long toLong(long preferredBlockSize, short replication,\n        BlockType blockType, byte storagePolicyID) {\n      Preconditions.checkArgument(replication \u003e\u003d 0 \u0026\u0026\n          replication \u003c\u003d MAX_REDUNDANCY);\n      long h \u003d 0;\n      if (preferredBlockSize \u003d\u003d 0) {\n        preferredBlockSize \u003d PREFERRED_BLOCK_SIZE.BITS.getMin();\n      }\n      h \u003d PREFERRED_BLOCK_SIZE.BITS.combine(preferredBlockSize, h);\n      // For erasure coded files, replication is used to store ec policy id\n      // TODO: this is hacky. Add some utility to generate the layoutRedundancy\n      long layoutRedundancy \u003d 0;\n      if (blockType \u003d\u003d STRIPED) {\n        layoutRedundancy |\u003d BLOCK_TYPE_MASK_STRIPED;\n      }\n      layoutRedundancy |\u003d replication;\n      h \u003d BLOCK_LAYOUT_AND_REDUNDANCY.BITS.combine(layoutRedundancy, h);\n      h \u003d STORAGE_POLICY_ID.BITS.combine(storagePolicyID, h);\n      return h;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {}
        }
      ]
    },
    "7600e3c48ff2043654dbe9f415a186a336b5ea6c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7866. Erasure coding: NameNode manages multiple erasure coding policies. Contributed by Rui Li.\n",
      "commitDate": "08/03/16 10:30 PM",
      "commitName": "7600e3c48ff2043654dbe9f415a186a336b5ea6c",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "12/02/16 11:07 AM",
      "commitNameOld": "972782d9568e0849484c027f27c1638ba50ec56e",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 25.47,
      "commitsBetweenForRepo": 166,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,20 @@\n     static long toLong(long preferredBlockSize, short replication,\n         boolean isStriped, byte storagePolicyID) {\n+      Preconditions.checkArgument(replication \u003e\u003d 0 \u0026\u0026\n+          replication \u003c\u003d MAX_REDUNDANCY);\n       long h \u003d 0;\n       if (preferredBlockSize \u003d\u003d 0) {\n         preferredBlockSize \u003d PREFERRED_BLOCK_SIZE.BITS.getMin();\n       }\n       h \u003d PREFERRED_BLOCK_SIZE.BITS.combine(preferredBlockSize, h);\n-      // Replication factor for striped files is zero\n+      // For erasure coded files, replication is used to store ec policy id\n+      // TODO: this is hacky. Add some utility to generate the layoutRedundancy\n+      long layoutRedundancy \u003d 0;\n       if (isStriped) {\n-        h \u003d REPLICATION.BITS.combine(0L, h);\n-        h \u003d IS_STRIPED.BITS.combine(1L, h);\n-      } else {\n-        h \u003d REPLICATION.BITS.combine(replication, h);\n-        h \u003d IS_STRIPED.BITS.combine(0L, h);\n+        layoutRedundancy |\u003d 1 \u003c\u003c 11;\n       }\n+      layoutRedundancy |\u003d replication;\n+      h \u003d BLOCK_LAYOUT_AND_REDUNDANCY.BITS.combine(layoutRedundancy, h);\n       h \u003d STORAGE_POLICY_ID.BITS.combine(storagePolicyID, h);\n       return h;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    static long toLong(long preferredBlockSize, short replication,\n        boolean isStriped, byte storagePolicyID) {\n      Preconditions.checkArgument(replication \u003e\u003d 0 \u0026\u0026\n          replication \u003c\u003d MAX_REDUNDANCY);\n      long h \u003d 0;\n      if (preferredBlockSize \u003d\u003d 0) {\n        preferredBlockSize \u003d PREFERRED_BLOCK_SIZE.BITS.getMin();\n      }\n      h \u003d PREFERRED_BLOCK_SIZE.BITS.combine(preferredBlockSize, h);\n      // For erasure coded files, replication is used to store ec policy id\n      // TODO: this is hacky. Add some utility to generate the layoutRedundancy\n      long layoutRedundancy \u003d 0;\n      if (isStriped) {\n        layoutRedundancy |\u003d 1 \u003c\u003c 11;\n      }\n      layoutRedundancy |\u003d replication;\n      h \u003d BLOCK_LAYOUT_AND_REDUNDANCY.BITS.combine(layoutRedundancy, h);\n      h \u003d STORAGE_POLICY_ID.BITS.combine(storagePolicyID, h);\n      return h;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    }
  }
}