{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Merger.java",
  "functionName": "computeBytesInMerges",
  "functionId": "computeBytesInMerges___factor-int__inMem-int",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Merger.java",
  "functionStartLine": 817,
  "functionEndLine": 860,
  "numCommitsSeen": 14,
  "timeTaken": 4624,
  "changeHistory": [
    "0f430e53fde884f24b473043f0a7e2bffa98ebd3",
    "da4cab10990b3a352fc2c699f3b41c994ac55e95",
    "539153a6798a667d39f20972c5ae0936060e2cc1",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "0f430e53fde884f24b473043f0a7e2bffa98ebd3": "Ybodychange",
    "da4cab10990b3a352fc2c699f3b41c994ac55e95": "Ybodychange",
    "539153a6798a667d39f20972c5ae0936060e2cc1": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "0f430e53fde884f24b473043f0a7e2bffa98ebd3": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2264. Job status exceeds 100% in some cases. (devaraj.k and sandyr via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1440076 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/01/13 11:38 AM",
      "commitName": "0f430e53fde884f24b473043f0a7e2bffa98ebd3",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "28/01/13 10:58 AM",
      "commitNameOld": "da4cab10990b3a352fc2c699f3b41c994ac55e95",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 1.03,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n     long computeBytesInMerges(int factor, int inMem) {\n       int numSegments \u003d segments.size();\n       List\u003cLong\u003e segmentSizes \u003d new ArrayList\u003cLong\u003e(numSegments);\n       long totalBytes \u003d 0;\n       int n \u003d numSegments - inMem;\n       // factor for 1st pass\n       int f \u003d getPassFactor(factor, 1, n) + inMem;\n       n \u003d numSegments;\n  \n       for (int i \u003d 0; i \u003c numSegments; i++) {\n         // Not handling empty segments here assuming that it would not affect\n         // much in calculation of mergeProgress.\n-        segmentSizes.add(segments.get(i).getLength());\n+        segmentSizes.add(segments.get(i).getRawDataLength());\n       }\n       \n       // If includeFinalMerge is true, allow the following while loop iterate\n       // for 1 more iteration. This is to include final merge as part of the\n       // computation of expected input bytes of merges\n       boolean considerFinalMerge \u003d includeFinalMerge;\n       \n       while (n \u003e f || considerFinalMerge) {\n         if (n \u003c\u003df ) {\n           considerFinalMerge \u003d false;\n         }\n         long mergedSize \u003d 0;\n         f \u003d Math.min(f, segmentSizes.size());\n         for (int j \u003d 0; j \u003c f; j++) {\n           mergedSize +\u003d segmentSizes.remove(0);\n         }\n         totalBytes +\u003d mergedSize;\n         \n         // insert new size into the sorted list\n         int pos \u003d Collections.binarySearch(segmentSizes, mergedSize);\n         if (pos \u003c 0) {\n           pos \u003d -pos-1;\n         }\n         segmentSizes.add(pos, mergedSize);\n         \n         n -\u003d (f-1);\n         f \u003d factor;\n       }\n \n       return totalBytes;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    long computeBytesInMerges(int factor, int inMem) {\n      int numSegments \u003d segments.size();\n      List\u003cLong\u003e segmentSizes \u003d new ArrayList\u003cLong\u003e(numSegments);\n      long totalBytes \u003d 0;\n      int n \u003d numSegments - inMem;\n      // factor for 1st pass\n      int f \u003d getPassFactor(factor, 1, n) + inMem;\n      n \u003d numSegments;\n \n      for (int i \u003d 0; i \u003c numSegments; i++) {\n        // Not handling empty segments here assuming that it would not affect\n        // much in calculation of mergeProgress.\n        segmentSizes.add(segments.get(i).getRawDataLength());\n      }\n      \n      // If includeFinalMerge is true, allow the following while loop iterate\n      // for 1 more iteration. This is to include final merge as part of the\n      // computation of expected input bytes of merges\n      boolean considerFinalMerge \u003d includeFinalMerge;\n      \n      while (n \u003e f || considerFinalMerge) {\n        if (n \u003c\u003df ) {\n          considerFinalMerge \u003d false;\n        }\n        long mergedSize \u003d 0;\n        f \u003d Math.min(f, segmentSizes.size());\n        for (int j \u003d 0; j \u003c f; j++) {\n          mergedSize +\u003d segmentSizes.remove(0);\n        }\n        totalBytes +\u003d mergedSize;\n        \n        // insert new size into the sorted list\n        int pos \u003d Collections.binarySearch(segmentSizes, mergedSize);\n        if (pos \u003c 0) {\n          pos \u003d -pos-1;\n        }\n        segmentSizes.add(pos, mergedSize);\n        \n        n -\u003d (f-1);\n        f \u003d factor;\n      }\n\n      return totalBytes;\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Merger.java",
      "extendedDetails": {}
    },
    "da4cab10990b3a352fc2c699f3b41c994ac55e95": {
      "type": "Ybodychange",
      "commitMessage": "Revering MAPREDUCE-2264\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1439561 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/01/13 10:58 AM",
      "commitName": "da4cab10990b3a352fc2c699f3b41c994ac55e95",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "24/01/13 4:25 PM",
      "commitNameOld": "539153a6798a667d39f20972c5ae0936060e2cc1",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 3.77,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n     long computeBytesInMerges(int factor, int inMem) {\n       int numSegments \u003d segments.size();\n       List\u003cLong\u003e segmentSizes \u003d new ArrayList\u003cLong\u003e(numSegments);\n       long totalBytes \u003d 0;\n       int n \u003d numSegments - inMem;\n       // factor for 1st pass\n       int f \u003d getPassFactor(factor, 1, n) + inMem;\n       n \u003d numSegments;\n  \n       for (int i \u003d 0; i \u003c numSegments; i++) {\n         // Not handling empty segments here assuming that it would not affect\n         // much in calculation of mergeProgress.\n-        segmentSizes.add(segments.get(i).getRawDataLength());\n+        segmentSizes.add(segments.get(i).getLength());\n       }\n       \n       // If includeFinalMerge is true, allow the following while loop iterate\n       // for 1 more iteration. This is to include final merge as part of the\n       // computation of expected input bytes of merges\n       boolean considerFinalMerge \u003d includeFinalMerge;\n       \n       while (n \u003e f || considerFinalMerge) {\n         if (n \u003c\u003df ) {\n           considerFinalMerge \u003d false;\n         }\n         long mergedSize \u003d 0;\n         f \u003d Math.min(f, segmentSizes.size());\n         for (int j \u003d 0; j \u003c f; j++) {\n           mergedSize +\u003d segmentSizes.remove(0);\n         }\n         totalBytes +\u003d mergedSize;\n         \n         // insert new size into the sorted list\n         int pos \u003d Collections.binarySearch(segmentSizes, mergedSize);\n         if (pos \u003c 0) {\n           pos \u003d -pos-1;\n         }\n         segmentSizes.add(pos, mergedSize);\n         \n         n -\u003d (f-1);\n         f \u003d factor;\n       }\n \n       return totalBytes;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    long computeBytesInMerges(int factor, int inMem) {\n      int numSegments \u003d segments.size();\n      List\u003cLong\u003e segmentSizes \u003d new ArrayList\u003cLong\u003e(numSegments);\n      long totalBytes \u003d 0;\n      int n \u003d numSegments - inMem;\n      // factor for 1st pass\n      int f \u003d getPassFactor(factor, 1, n) + inMem;\n      n \u003d numSegments;\n \n      for (int i \u003d 0; i \u003c numSegments; i++) {\n        // Not handling empty segments here assuming that it would not affect\n        // much in calculation of mergeProgress.\n        segmentSizes.add(segments.get(i).getLength());\n      }\n      \n      // If includeFinalMerge is true, allow the following while loop iterate\n      // for 1 more iteration. This is to include final merge as part of the\n      // computation of expected input bytes of merges\n      boolean considerFinalMerge \u003d includeFinalMerge;\n      \n      while (n \u003e f || considerFinalMerge) {\n        if (n \u003c\u003df ) {\n          considerFinalMerge \u003d false;\n        }\n        long mergedSize \u003d 0;\n        f \u003d Math.min(f, segmentSizes.size());\n        for (int j \u003d 0; j \u003c f; j++) {\n          mergedSize +\u003d segmentSizes.remove(0);\n        }\n        totalBytes +\u003d mergedSize;\n        \n        // insert new size into the sorted list\n        int pos \u003d Collections.binarySearch(segmentSizes, mergedSize);\n        if (pos \u003c 0) {\n          pos \u003d -pos-1;\n        }\n        segmentSizes.add(pos, mergedSize);\n        \n        n -\u003d (f-1);\n        f \u003d factor;\n      }\n\n      return totalBytes;\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Merger.java",
      "extendedDetails": {}
    },
    "539153a6798a667d39f20972c5ae0936060e2cc1": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2264. Job status exceeds 100% in some cases. (devaraj.k and sandyr via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1438277 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/01/13 4:25 PM",
      "commitName": "539153a6798a667d39f20972c5ae0936060e2cc1",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 519.01,
      "commitsBetweenForRepo": 3240,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n     long computeBytesInMerges(int factor, int inMem) {\n       int numSegments \u003d segments.size();\n       List\u003cLong\u003e segmentSizes \u003d new ArrayList\u003cLong\u003e(numSegments);\n       long totalBytes \u003d 0;\n       int n \u003d numSegments - inMem;\n       // factor for 1st pass\n       int f \u003d getPassFactor(factor, 1, n) + inMem;\n       n \u003d numSegments;\n  \n       for (int i \u003d 0; i \u003c numSegments; i++) {\n         // Not handling empty segments here assuming that it would not affect\n         // much in calculation of mergeProgress.\n-        segmentSizes.add(segments.get(i).getLength());\n+        segmentSizes.add(segments.get(i).getRawDataLength());\n       }\n       \n       // If includeFinalMerge is true, allow the following while loop iterate\n       // for 1 more iteration. This is to include final merge as part of the\n       // computation of expected input bytes of merges\n       boolean considerFinalMerge \u003d includeFinalMerge;\n       \n       while (n \u003e f || considerFinalMerge) {\n         if (n \u003c\u003df ) {\n           considerFinalMerge \u003d false;\n         }\n         long mergedSize \u003d 0;\n         f \u003d Math.min(f, segmentSizes.size());\n         for (int j \u003d 0; j \u003c f; j++) {\n           mergedSize +\u003d segmentSizes.remove(0);\n         }\n         totalBytes +\u003d mergedSize;\n         \n         // insert new size into the sorted list\n         int pos \u003d Collections.binarySearch(segmentSizes, mergedSize);\n         if (pos \u003c 0) {\n           pos \u003d -pos-1;\n         }\n         segmentSizes.add(pos, mergedSize);\n         \n         n -\u003d (f-1);\n         f \u003d factor;\n       }\n \n       return totalBytes;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    long computeBytesInMerges(int factor, int inMem) {\n      int numSegments \u003d segments.size();\n      List\u003cLong\u003e segmentSizes \u003d new ArrayList\u003cLong\u003e(numSegments);\n      long totalBytes \u003d 0;\n      int n \u003d numSegments - inMem;\n      // factor for 1st pass\n      int f \u003d getPassFactor(factor, 1, n) + inMem;\n      n \u003d numSegments;\n \n      for (int i \u003d 0; i \u003c numSegments; i++) {\n        // Not handling empty segments here assuming that it would not affect\n        // much in calculation of mergeProgress.\n        segmentSizes.add(segments.get(i).getRawDataLength());\n      }\n      \n      // If includeFinalMerge is true, allow the following while loop iterate\n      // for 1 more iteration. This is to include final merge as part of the\n      // computation of expected input bytes of merges\n      boolean considerFinalMerge \u003d includeFinalMerge;\n      \n      while (n \u003e f || considerFinalMerge) {\n        if (n \u003c\u003df ) {\n          considerFinalMerge \u003d false;\n        }\n        long mergedSize \u003d 0;\n        f \u003d Math.min(f, segmentSizes.size());\n        for (int j \u003d 0; j \u003c f; j++) {\n          mergedSize +\u003d segmentSizes.remove(0);\n        }\n        totalBytes +\u003d mergedSize;\n        \n        // insert new size into the sorted list\n        int pos \u003d Collections.binarySearch(segmentSizes, mergedSize);\n        if (pos \u003c 0) {\n          pos \u003d -pos-1;\n        }\n        segmentSizes.add(pos, mergedSize);\n        \n        n -\u003d (f-1);\n        f \u003d factor;\n      }\n\n      return totalBytes;\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Merger.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    long computeBytesInMerges(int factor, int inMem) {\n      int numSegments \u003d segments.size();\n      List\u003cLong\u003e segmentSizes \u003d new ArrayList\u003cLong\u003e(numSegments);\n      long totalBytes \u003d 0;\n      int n \u003d numSegments - inMem;\n      // factor for 1st pass\n      int f \u003d getPassFactor(factor, 1, n) + inMem;\n      n \u003d numSegments;\n \n      for (int i \u003d 0; i \u003c numSegments; i++) {\n        // Not handling empty segments here assuming that it would not affect\n        // much in calculation of mergeProgress.\n        segmentSizes.add(segments.get(i).getLength());\n      }\n      \n      // If includeFinalMerge is true, allow the following while loop iterate\n      // for 1 more iteration. This is to include final merge as part of the\n      // computation of expected input bytes of merges\n      boolean considerFinalMerge \u003d includeFinalMerge;\n      \n      while (n \u003e f || considerFinalMerge) {\n        if (n \u003c\u003df ) {\n          considerFinalMerge \u003d false;\n        }\n        long mergedSize \u003d 0;\n        f \u003d Math.min(f, segmentSizes.size());\n        for (int j \u003d 0; j \u003c f; j++) {\n          mergedSize +\u003d segmentSizes.remove(0);\n        }\n        totalBytes +\u003d mergedSize;\n        \n        // insert new size into the sorted list\n        int pos \u003d Collections.binarySearch(segmentSizes, mergedSize);\n        if (pos \u003c 0) {\n          pos \u003d -pos-1;\n        }\n        segmentSizes.add(pos, mergedSize);\n        \n        n -\u003d (f-1);\n        f \u003d factor;\n      }\n\n      return totalBytes;\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Merger.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Merger.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Merger.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    long computeBytesInMerges(int factor, int inMem) {\n      int numSegments \u003d segments.size();\n      List\u003cLong\u003e segmentSizes \u003d new ArrayList\u003cLong\u003e(numSegments);\n      long totalBytes \u003d 0;\n      int n \u003d numSegments - inMem;\n      // factor for 1st pass\n      int f \u003d getPassFactor(factor, 1, n) + inMem;\n      n \u003d numSegments;\n \n      for (int i \u003d 0; i \u003c numSegments; i++) {\n        // Not handling empty segments here assuming that it would not affect\n        // much in calculation of mergeProgress.\n        segmentSizes.add(segments.get(i).getLength());\n      }\n      \n      // If includeFinalMerge is true, allow the following while loop iterate\n      // for 1 more iteration. This is to include final merge as part of the\n      // computation of expected input bytes of merges\n      boolean considerFinalMerge \u003d includeFinalMerge;\n      \n      while (n \u003e f || considerFinalMerge) {\n        if (n \u003c\u003df ) {\n          considerFinalMerge \u003d false;\n        }\n        long mergedSize \u003d 0;\n        f \u003d Math.min(f, segmentSizes.size());\n        for (int j \u003d 0; j \u003c f; j++) {\n          mergedSize +\u003d segmentSizes.remove(0);\n        }\n        totalBytes +\u003d mergedSize;\n        \n        // insert new size into the sorted list\n        int pos \u003d Collections.binarySearch(segmentSizes, mergedSize);\n        if (pos \u003c 0) {\n          pos \u003d -pos-1;\n        }\n        segmentSizes.add(pos, mergedSize);\n        \n        n -\u003d (f-1);\n        f \u003d factor;\n      }\n\n      return totalBytes;\n    }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Merger.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/java/org/apache/hadoop/mapred/Merger.java",
        "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Merger.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,44 @@\n+    long computeBytesInMerges(int factor, int inMem) {\n+      int numSegments \u003d segments.size();\n+      List\u003cLong\u003e segmentSizes \u003d new ArrayList\u003cLong\u003e(numSegments);\n+      long totalBytes \u003d 0;\n+      int n \u003d numSegments - inMem;\n+      // factor for 1st pass\n+      int f \u003d getPassFactor(factor, 1, n) + inMem;\n+      n \u003d numSegments;\n+ \n+      for (int i \u003d 0; i \u003c numSegments; i++) {\n+        // Not handling empty segments here assuming that it would not affect\n+        // much in calculation of mergeProgress.\n+        segmentSizes.add(segments.get(i).getLength());\n+      }\n+      \n+      // If includeFinalMerge is true, allow the following while loop iterate\n+      // for 1 more iteration. This is to include final merge as part of the\n+      // computation of expected input bytes of merges\n+      boolean considerFinalMerge \u003d includeFinalMerge;\n+      \n+      while (n \u003e f || considerFinalMerge) {\n+        if (n \u003c\u003df ) {\n+          considerFinalMerge \u003d false;\n+        }\n+        long mergedSize \u003d 0;\n+        f \u003d Math.min(f, segmentSizes.size());\n+        for (int j \u003d 0; j \u003c f; j++) {\n+          mergedSize +\u003d segmentSizes.remove(0);\n+        }\n+        totalBytes +\u003d mergedSize;\n+        \n+        // insert new size into the sorted list\n+        int pos \u003d Collections.binarySearch(segmentSizes, mergedSize);\n+        if (pos \u003c 0) {\n+          pos \u003d -pos-1;\n+        }\n+        segmentSizes.add(pos, mergedSize);\n+        \n+        n -\u003d (f-1);\n+        f \u003d factor;\n+      }\n+\n+      return totalBytes;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    long computeBytesInMerges(int factor, int inMem) {\n      int numSegments \u003d segments.size();\n      List\u003cLong\u003e segmentSizes \u003d new ArrayList\u003cLong\u003e(numSegments);\n      long totalBytes \u003d 0;\n      int n \u003d numSegments - inMem;\n      // factor for 1st pass\n      int f \u003d getPassFactor(factor, 1, n) + inMem;\n      n \u003d numSegments;\n \n      for (int i \u003d 0; i \u003c numSegments; i++) {\n        // Not handling empty segments here assuming that it would not affect\n        // much in calculation of mergeProgress.\n        segmentSizes.add(segments.get(i).getLength());\n      }\n      \n      // If includeFinalMerge is true, allow the following while loop iterate\n      // for 1 more iteration. This is to include final merge as part of the\n      // computation of expected input bytes of merges\n      boolean considerFinalMerge \u003d includeFinalMerge;\n      \n      while (n \u003e f || considerFinalMerge) {\n        if (n \u003c\u003df ) {\n          considerFinalMerge \u003d false;\n        }\n        long mergedSize \u003d 0;\n        f \u003d Math.min(f, segmentSizes.size());\n        for (int j \u003d 0; j \u003c f; j++) {\n          mergedSize +\u003d segmentSizes.remove(0);\n        }\n        totalBytes +\u003d mergedSize;\n        \n        // insert new size into the sorted list\n        int pos \u003d Collections.binarySearch(segmentSizes, mergedSize);\n        if (pos \u003c 0) {\n          pos \u003d -pos-1;\n        }\n        segmentSizes.add(pos, mergedSize);\n        \n        n -\u003d (f-1);\n        f \u003d factor;\n      }\n\n      return totalBytes;\n    }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapred/Merger.java"
    }
  }
}