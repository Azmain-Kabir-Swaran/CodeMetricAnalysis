{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Display.java",
  "functionName": "processPath",
  "functionId": "processPath___item-PathData",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java",
  "functionStartLine": 198,
  "functionEndLine": 214,
  "numCommitsSeen": 25,
  "timeTaken": 1827,
  "changeHistory": [
    "cf268114c9af2e33f35d0c24b57e31ef4d5e8353",
    "84d50003f6e46f9f9ac2b9d7bb937de757be161b",
    "b427fe9de879f178a4adec2931b7d5f324ffc764",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
    "a5290c9eca69027cff2448d05fee6983cbb54cd7",
    "3337cdb3121d926301a3cca17abef029abdb2ff3"
  ],
  "changeHistoryShort": {
    "cf268114c9af2e33f35d0c24b57e31ef4d5e8353": "Ybodychange",
    "84d50003f6e46f9f9ac2b9d7bb937de757be161b": "Ybodychange",
    "b427fe9de879f178a4adec2931b7d5f324ffc764": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yfilerename",
    "a5290c9eca69027cff2448d05fee6983cbb54cd7": "Ybodychange",
    "3337cdb3121d926301a3cca17abef029abdb2ff3": "Yintroduced"
  },
  "changeHistoryDetails": {
    "cf268114c9af2e33f35d0c24b57e31ef4d5e8353": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13960. hdfs dfs -checksum command should optionally show block size in output. Contributed by Lokesh Jain.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "02/04/19 12:24 PM",
      "commitName": "cf268114c9af2e33f35d0c24b57e31ef4d5e8353",
      "commitAuthor": "Lokesh Jain",
      "commitDateOld": "28/11/16 9:07 PM",
      "commitNameOld": "67d9f2808efb34b9a7b0b824cb4033b95ad33474",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 854.6,
      "commitsBetweenForRepo": 6545,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,17 @@\n     protected void processPath(PathData item) throws IOException {\n       if (item.stat.isDirectory()) {\n         throw new PathIsDirectoryException(item.toString());\n       }\n \n       FileChecksum checksum \u003d item.fs.getFileChecksum(item.path);\n-      if (checksum \u003d\u003d null) {\n-        out.printf(\"%s\\tNONE\\t%n\", item.toString());\n+      String outputChecksum \u003d checksum \u003d\u003d null ? \"NONE\" :\n+          String.format(\"%s\\t%s\", checksum.getAlgorithmName(), StringUtils\n+              .byteToHexString(checksum.getBytes(), 0, checksum.getLength()));\n+      if (displayBlockSize) {\n+        FileStatus fileStatus \u003d item.fs.getFileStatus(item.path);\n+        out.printf(\"%s\\t%s\\tBlockSize\u003d%s%n\", item.toString(), outputChecksum,\n+            fileStatus !\u003d null ? fileStatus.getBlockSize() : \"NONE\");\n       } else {\n-        String checksumString \u003d StringUtils.byteToHexString(\n-            checksum.getBytes(), 0, checksum.getLength());\n-        out.printf(\"%s\\t%s\\t%s%n\",\n-            item.toString(), checksum.getAlgorithmName(),\n-            checksumString);\n+        out.printf(\"%s\\t%s%n\", item.toString(), outputChecksum);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected void processPath(PathData item) throws IOException {\n      if (item.stat.isDirectory()) {\n        throw new PathIsDirectoryException(item.toString());\n      }\n\n      FileChecksum checksum \u003d item.fs.getFileChecksum(item.path);\n      String outputChecksum \u003d checksum \u003d\u003d null ? \"NONE\" :\n          String.format(\"%s\\t%s\", checksum.getAlgorithmName(), StringUtils\n              .byteToHexString(checksum.getBytes(), 0, checksum.getLength()));\n      if (displayBlockSize) {\n        FileStatus fileStatus \u003d item.fs.getFileStatus(item.path);\n        out.printf(\"%s\\t%s\\tBlockSize\u003d%s%n\", item.toString(), outputChecksum,\n            fileStatus !\u003d null ? fileStatus.getBlockSize() : \"NONE\");\n      } else {\n        out.printf(\"%s\\t%s%n\", item.toString(), outputChecksum);\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java",
      "extendedDetails": {}
    },
    "84d50003f6e46f9f9ac2b9d7bb937de757be161b": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11386. Replace \\n by %n in format hadoop-common format strings. Contributed by Li Lu.\n",
      "commitDate": "10/12/14 2:37 PM",
      "commitName": "84d50003f6e46f9f9ac2b9d7bb937de757be161b",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "02/09/14 11:15 AM",
      "commitNameOld": "01e8f056d9b7245193e6050f9830ca058db02a6e",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 99.18,
      "commitsBetweenForRepo": 941,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n     protected void processPath(PathData item) throws IOException {\n       if (item.stat.isDirectory()) {\n         throw new PathIsDirectoryException(item.toString());\n       }\n \n       FileChecksum checksum \u003d item.fs.getFileChecksum(item.path);\n       if (checksum \u003d\u003d null) {\n-        out.printf(\"%s\\tNONE\\t\\n\", item.toString());\n+        out.printf(\"%s\\tNONE\\t%n\", item.toString());\n       } else {\n         String checksumString \u003d StringUtils.byteToHexString(\n             checksum.getBytes(), 0, checksum.getLength());\n-        out.printf(\"%s\\t%s\\t%s\\n\",\n+        out.printf(\"%s\\t%s\\t%s%n\",\n             item.toString(), checksum.getAlgorithmName(),\n             checksumString);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected void processPath(PathData item) throws IOException {\n      if (item.stat.isDirectory()) {\n        throw new PathIsDirectoryException(item.toString());\n      }\n\n      FileChecksum checksum \u003d item.fs.getFileChecksum(item.path);\n      if (checksum \u003d\u003d null) {\n        out.printf(\"%s\\tNONE\\t%n\", item.toString());\n      } else {\n        String checksumString \u003d StringUtils.byteToHexString(\n            checksum.getBytes(), 0, checksum.getLength());\n        out.printf(\"%s\\t%s\\t%s%n\",\n            item.toString(), checksum.getAlgorithmName(),\n            checksumString);\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java",
      "extendedDetails": {}
    },
    "b427fe9de879f178a4adec2931b7d5f324ffc764": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9209. Add shell command to dump file checksums (Todd Lipcon via jeagles)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1453613 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/03/13 3:17 PM",
      "commitName": "b427fe9de879f178a4adec2931b7d5f324ffc764",
      "commitAuthor": "Jonathan Turner Eagles",
      "commitDateOld": "26/11/12 4:40 PM",
      "commitNameOld": "3b3a72e622992122461fa72dee419fc162019e8f",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 99.94,
      "commitsBetweenForRepo": 418,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,16 @@\n     protected void processPath(PathData item) throws IOException {\n       if (item.stat.isDirectory()) {\n         throw new PathIsDirectoryException(item.toString());\n       }\n-      \n-      item.fs.setVerifyChecksum(verifyChecksum);\n-      printToStdout(getInputStream(item));\n+\n+      FileChecksum checksum \u003d item.fs.getFileChecksum(item.path);\n+      if (checksum \u003d\u003d null) {\n+        out.printf(\"%s\\tNONE\\t\\n\", item.toString());\n+      } else {\n+        String checksumString \u003d StringUtils.byteToHexString(\n+            checksum.getBytes(), 0, checksum.getLength());\n+        out.printf(\"%s\\t%s\\t%s\\n\",\n+            item.toString(), checksum.getAlgorithmName(),\n+            checksumString);\n+      }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected void processPath(PathData item) throws IOException {\n      if (item.stat.isDirectory()) {\n        throw new PathIsDirectoryException(item.toString());\n      }\n\n      FileChecksum checksum \u003d item.fs.getFileChecksum(item.path);\n      if (checksum \u003d\u003d null) {\n        out.printf(\"%s\\tNONE\\t\\n\", item.toString());\n      } else {\n        String checksumString \u003d StringUtils.byteToHexString(\n            checksum.getBytes(), 0, checksum.getLength());\n        out.printf(\"%s\\t%s\\t%s\\n\",\n            item.toString(), checksum.getAlgorithmName(),\n            checksumString);\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    protected void processPath(PathData item) throws IOException {\n      if (item.stat.isDirectory()) {\n        throw new PathIsDirectoryException(item.toString());\n      }\n      \n      item.fs.setVerifyChecksum(verifyChecksum);\n      printToStdout(getInputStream(item));\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java",
      "extendedDetails": {
        "oldPath": "hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java"
      }
    },
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-6671. Use maven for hadoop common builds. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1153184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/08/11 9:37 AM",
      "commitName": "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
      "commitAuthor": "Thomas White",
      "commitDateOld": "01/08/11 3:53 PM",
      "commitNameOld": "9bac807cedbcff34e1a144fb475eff267e5ed86d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    protected void processPath(PathData item) throws IOException {\n      if (item.stat.isDirectory()) {\n        throw new PathIsDirectoryException(item.toString());\n      }\n      \n      item.fs.setVerifyChecksum(verifyChecksum);\n      printToStdout(getInputStream(item));\n    }",
      "path": "hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java",
      "extendedDetails": {
        "oldPath": "common/src/java/org/apache/hadoop/fs/shell/Display.java",
        "newPath": "hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "11/06/11 9:13 PM",
      "commitNameOld": "a285fb5effe9ba3be4ec5f942afaf5ddd1186151",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    protected void processPath(PathData item) throws IOException {\n      if (item.stat.isDirectory()) {\n        throw new PathIsDirectoryException(item.toString());\n      }\n      \n      item.fs.setVerifyChecksum(verifyChecksum);\n      printToStdout(getInputStream(item));\n    }",
      "path": "common/src/java/org/apache/hadoop/fs/shell/Display.java",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/hadoop/fs/shell/Display.java",
        "newPath": "common/src/java/org/apache/hadoop/fs/shell/Display.java"
      }
    },
    "a5290c9eca69027cff2448d05fee6983cbb54cd7": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-7271. Standardize shell command error messages.  Contributed by Daryn Sharp\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1101653 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/05/11 2:29 PM",
      "commitName": "a5290c9eca69027cff2448d05fee6983cbb54cd7",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "09/05/11 1:08 PM",
      "commitNameOld": "3337cdb3121d926301a3cca17abef029abdb2ff3",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 1.06,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,8 @@\n     protected void processPath(PathData item) throws IOException {\n+      if (item.stat.isDirectory()) {\n+        throw new PathIsDirectoryException(item.toString());\n+      }\n+      \n       item.fs.setVerifyChecksum(verifyChecksum);\n       printToStdout(getInputStream(item));\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected void processPath(PathData item) throws IOException {\n      if (item.stat.isDirectory()) {\n        throw new PathIsDirectoryException(item.toString());\n      }\n      \n      item.fs.setVerifyChecksum(verifyChecksum);\n      printToStdout(getInputStream(item));\n    }",
      "path": "src/java/org/apache/hadoop/fs/shell/Display.java",
      "extendedDetails": {}
    },
    "3337cdb3121d926301a3cca17abef029abdb2ff3": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7238. Refactor the cat and text commands to conform to new FsCommand class.  Contributed by Daryn Sharp\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1101199 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/05/11 1:08 PM",
      "commitName": "3337cdb3121d926301a3cca17abef029abdb2ff3",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,4 @@\n+    protected void processPath(PathData item) throws IOException {\n+      item.fs.setVerifyChecksum(verifyChecksum);\n+      printToStdout(getInputStream(item));\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    protected void processPath(PathData item) throws IOException {\n      item.fs.setVerifyChecksum(verifyChecksum);\n      printToStdout(getInputStream(item));\n    }",
      "path": "src/java/org/apache/hadoop/fs/shell/Display.java"
    }
  }
}