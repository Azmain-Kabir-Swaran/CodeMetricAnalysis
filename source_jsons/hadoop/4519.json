{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PBHelper.java",
  "functionName": "convert",
  "functionId": "convert___b-RecoveringBlockProto",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
  "functionStartLine": 386,
  "functionEndLine": 404,
  "numCommitsSeen": 197,
  "timeTaken": 7877,
  "changeHistory": [
    "70d6f201260086a3f12beaa317fede2a99639fef",
    "61ab0440f7eaff0f631cbae0378403912f88d7ad",
    "e287e7d14b838a866ba03d895fa35819999d7c09",
    "06022b8fdc40e50eaac63758246353058e8cfa6d",
    "e2c9b288b223b9fd82dc12018936e13128413492",
    "08ac06283a3e9bf0d49d873823aabd419b08e41f",
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
    "7a59150bff64fc81f838de586eacd6d062172605",
    "0a713035f2fb1a222291cfdb2cbde906814c2fd9"
  ],
  "changeHistoryShort": {
    "70d6f201260086a3f12beaa317fede2a99639fef": "Ybodychange",
    "61ab0440f7eaff0f631cbae0378403912f88d7ad": "Ybodychange",
    "e287e7d14b838a866ba03d895fa35819999d7c09": "Ybodychange",
    "06022b8fdc40e50eaac63758246353058e8cfa6d": "Ybodychange",
    "e2c9b288b223b9fd82dc12018936e13128413492": "Ybodychange",
    "08ac06283a3e9bf0d49d873823aabd419b08e41f": "Ybodychange",
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2": "Ybodychange",
    "7a59150bff64fc81f838de586eacd6d062172605": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
    "0a713035f2fb1a222291cfdb2cbde906814c2fd9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "70d6f201260086a3f12beaa317fede2a99639fef": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9575. Use byte array for internal block indices in a striped block.  Contributed by jing9\n",
      "commitDate": "21/12/15 10:47 PM",
      "commitName": "70d6f201260086a3f12beaa317fede2a99639fef",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "18/12/15 3:57 PM",
      "commitNameOld": "61ab0440f7eaff0f631cbae0378403912f88d7ad",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 3.28,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,19 @@\n   public static RecoveringBlock convert(RecoveringBlockProto b) {\n     LocatedBlock lb \u003d PBHelperClient.convertLocatedBlockProto(b.getBlock());\n     RecoveringBlock rBlock;\n     if (b.hasTruncateBlock()) {\n       rBlock \u003d new RecoveringBlock(lb.getBlock(), lb.getLocations(),\n           PBHelperClient.convert(b.getTruncateBlock()));\n     } else {\n       rBlock \u003d new RecoveringBlock(lb.getBlock(), lb.getLocations(),\n           b.getNewGenStamp());\n     }\n \n     if (b.hasEcPolicy()) {\n-      List\u003cInteger\u003e BlockIndicesList \u003d b.getBlockIndicesList();\n-      int[] indices \u003d new int[BlockIndicesList.size()];\n-      for (int i \u003d 0; i \u003c BlockIndicesList.size(); i++) {\n-        indices[i] \u003d BlockIndicesList.get(i).shortValue();\n-      }\n+      assert b.hasBlockIndices();\n+      byte[] indices \u003d b.getBlockIndices().toByteArray();\n       rBlock \u003d new RecoveringStripedBlock(rBlock, indices,\n           PBHelperClient.convertErasureCodingPolicy(b.getEcPolicy()));\n     }\n     return rBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static RecoveringBlock convert(RecoveringBlockProto b) {\n    LocatedBlock lb \u003d PBHelperClient.convertLocatedBlockProto(b.getBlock());\n    RecoveringBlock rBlock;\n    if (b.hasTruncateBlock()) {\n      rBlock \u003d new RecoveringBlock(lb.getBlock(), lb.getLocations(),\n          PBHelperClient.convert(b.getTruncateBlock()));\n    } else {\n      rBlock \u003d new RecoveringBlock(lb.getBlock(), lb.getLocations(),\n          b.getNewGenStamp());\n    }\n\n    if (b.hasEcPolicy()) {\n      assert b.hasBlockIndices();\n      byte[] indices \u003d b.getBlockIndices().toByteArray();\n      rBlock \u003d new RecoveringStripedBlock(rBlock, indices,\n          PBHelperClient.convertErasureCodingPolicy(b.getEcPolicy()));\n    }\n    return rBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "61ab0440f7eaff0f631cbae0378403912f88d7ad": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9173. Erasure Coding: Lease recovery for striped file. Contributed by Walter Su and Jing Zhao.\n\nChange-Id: I51703a61c9d8454f883028f3f6acb5729fde1b15\n",
      "commitDate": "18/12/15 3:57 PM",
      "commitName": "61ab0440f7eaff0f631cbae0378403912f88d7ad",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "16/12/15 11:10 AM",
      "commitNameOld": "c470c8953d4927043b6383fad8e792289c634c09",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 2.2,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,22 @@\n   public static RecoveringBlock convert(RecoveringBlockProto b) {\n     LocatedBlock lb \u003d PBHelperClient.convertLocatedBlockProto(b.getBlock());\n     RecoveringBlock rBlock;\n     if (b.hasTruncateBlock()) {\n       rBlock \u003d new RecoveringBlock(lb.getBlock(), lb.getLocations(),\n           PBHelperClient.convert(b.getTruncateBlock()));\n     } else {\n       rBlock \u003d new RecoveringBlock(lb.getBlock(), lb.getLocations(),\n           b.getNewGenStamp());\n     }\n+\n+    if (b.hasEcPolicy()) {\n+      List\u003cInteger\u003e BlockIndicesList \u003d b.getBlockIndicesList();\n+      int[] indices \u003d new int[BlockIndicesList.size()];\n+      for (int i \u003d 0; i \u003c BlockIndicesList.size(); i++) {\n+        indices[i] \u003d BlockIndicesList.get(i).shortValue();\n+      }\n+      rBlock \u003d new RecoveringStripedBlock(rBlock, indices,\n+          PBHelperClient.convertErasureCodingPolicy(b.getEcPolicy()));\n+    }\n     return rBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static RecoveringBlock convert(RecoveringBlockProto b) {\n    LocatedBlock lb \u003d PBHelperClient.convertLocatedBlockProto(b.getBlock());\n    RecoveringBlock rBlock;\n    if (b.hasTruncateBlock()) {\n      rBlock \u003d new RecoveringBlock(lb.getBlock(), lb.getLocations(),\n          PBHelperClient.convert(b.getTruncateBlock()));\n    } else {\n      rBlock \u003d new RecoveringBlock(lb.getBlock(), lb.getLocations(),\n          b.getNewGenStamp());\n    }\n\n    if (b.hasEcPolicy()) {\n      List\u003cInteger\u003e BlockIndicesList \u003d b.getBlockIndicesList();\n      int[] indices \u003d new int[BlockIndicesList.size()];\n      for (int i \u003d 0; i \u003c BlockIndicesList.size(); i++) {\n        indices[i] \u003d BlockIndicesList.get(i).shortValue();\n      }\n      rBlock \u003d new RecoveringStripedBlock(rBlock, indices,\n          PBHelperClient.convertErasureCodingPolicy(b.getEcPolicy()));\n    }\n    return rBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "e287e7d14b838a866ba03d895fa35819999d7c09": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9255. Consolidate block recovery related implementation into a single class. Contributed by Walter Su.\n\nChange-Id: I7a1c03f50123d79ac0a78c981d9721617e3229d1\n",
      "commitDate": "28/10/15 7:34 AM",
      "commitName": "e287e7d14b838a866ba03d895fa35819999d7c09",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "29/09/15 1:39 AM",
      "commitNameOld": "8fd55202468b28422b0df888641c9b08906fe4a7",
      "commitAuthorOld": "",
      "daysBetweenCommits": 29.25,
      "commitsBetweenForRepo": 244,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,12 @@\n   public static RecoveringBlock convert(RecoveringBlockProto b) {\n-    ExtendedBlock block \u003d PBHelperClient.convert(b.getBlock().getB());\n-    DatanodeInfo[] locs \u003d PBHelperClient.convert(b.getBlock().getLocsList());\n-    return (b.hasTruncateBlock()) ?\n-        new RecoveringBlock(block, locs, PBHelperClient.convert(b.getTruncateBlock())) :\n-        new RecoveringBlock(block, locs, b.getNewGenStamp());\n+    LocatedBlock lb \u003d PBHelperClient.convertLocatedBlockProto(b.getBlock());\n+    RecoveringBlock rBlock;\n+    if (b.hasTruncateBlock()) {\n+      rBlock \u003d new RecoveringBlock(lb.getBlock(), lb.getLocations(),\n+          PBHelperClient.convert(b.getTruncateBlock()));\n+    } else {\n+      rBlock \u003d new RecoveringBlock(lb.getBlock(), lb.getLocations(),\n+          b.getNewGenStamp());\n+    }\n+    return rBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static RecoveringBlock convert(RecoveringBlockProto b) {\n    LocatedBlock lb \u003d PBHelperClient.convertLocatedBlockProto(b.getBlock());\n    RecoveringBlock rBlock;\n    if (b.hasTruncateBlock()) {\n      rBlock \u003d new RecoveringBlock(lb.getBlock(), lb.getLocations(),\n          PBHelperClient.convert(b.getTruncateBlock()));\n    } else {\n      rBlock \u003d new RecoveringBlock(lb.getBlock(), lb.getLocations(),\n          b.getNewGenStamp());\n    }\n    return rBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "06022b8fdc40e50eaac63758246353058e8cfa6d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9111. Move hdfs-client protobuf convert methods from PBHelper to PBHelperClient. Contributed by Mingliang Liu.\n",
      "commitDate": "21/09/15 6:53 PM",
      "commitName": "06022b8fdc40e50eaac63758246353058e8cfa6d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "19/09/15 6:08 PM",
      "commitNameOld": "3a9c7076e81c1cc47c0ecf30c60abd9a65d8a501",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 2.03,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n   public static RecoveringBlock convert(RecoveringBlockProto b) {\n     ExtendedBlock block \u003d PBHelperClient.convert(b.getBlock().getB());\n-    DatanodeInfo[] locs \u003d convert(b.getBlock().getLocsList());\n+    DatanodeInfo[] locs \u003d PBHelperClient.convert(b.getBlock().getLocsList());\n     return (b.hasTruncateBlock()) ?\n-        new RecoveringBlock(block, locs, PBHelper.convert(b.getTruncateBlock())) :\n+        new RecoveringBlock(block, locs, PBHelperClient.convert(b.getTruncateBlock())) :\n         new RecoveringBlock(block, locs, b.getNewGenStamp());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static RecoveringBlock convert(RecoveringBlockProto b) {\n    ExtendedBlock block \u003d PBHelperClient.convert(b.getBlock().getB());\n    DatanodeInfo[] locs \u003d PBHelperClient.convert(b.getBlock().getLocsList());\n    return (b.hasTruncateBlock()) ?\n        new RecoveringBlock(block, locs, PBHelperClient.convert(b.getTruncateBlock())) :\n        new RecoveringBlock(block, locs, b.getNewGenStamp());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "e2c9b288b223b9fd82dc12018936e13128413492": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8925. Move BlockReaderLocal to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "28/08/15 2:38 PM",
      "commitName": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "22/08/15 1:31 PM",
      "commitNameOld": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 6.05,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n   public static RecoveringBlock convert(RecoveringBlockProto b) {\n-    ExtendedBlock block \u003d convert(b.getBlock().getB());\n+    ExtendedBlock block \u003d PBHelperClient.convert(b.getBlock().getB());\n     DatanodeInfo[] locs \u003d convert(b.getBlock().getLocsList());\n     return (b.hasTruncateBlock()) ?\n         new RecoveringBlock(block, locs, PBHelper.convert(b.getTruncateBlock())) :\n         new RecoveringBlock(block, locs, b.getNewGenStamp());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static RecoveringBlock convert(RecoveringBlockProto b) {\n    ExtendedBlock block \u003d PBHelperClient.convert(b.getBlock().getB());\n    DatanodeInfo[] locs \u003d convert(b.getBlock().getLocsList());\n    return (b.hasTruncateBlock()) ?\n        new RecoveringBlock(block, locs, PBHelper.convert(b.getTruncateBlock())) :\n        new RecoveringBlock(block, locs, b.getNewGenStamp());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "08ac06283a3e9bf0d49d873823aabd419b08e41f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7056. Snapshot support for truncate. Contributed by Konstantin Shvachko and Plamen Jeliazkov.",
      "commitDate": "13/01/15 12:24 AM",
      "commitName": "08ac06283a3e9bf0d49d873823aabd419b08e41f",
      "commitAuthor": "Konstantin V Shvachko",
      "commitDateOld": "12/01/15 10:50 PM",
      "commitNameOld": "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
      "commitAuthorOld": "Plamen Jeliazkov",
      "daysBetweenCommits": 0.07,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,7 @@\n   public static RecoveringBlock convert(RecoveringBlockProto b) {\n     ExtendedBlock block \u003d convert(b.getBlock().getB());\n     DatanodeInfo[] locs \u003d convert(b.getBlock().getLocsList());\n-    return new RecoveringBlock(block, locs, b.getNewGenStamp(),\n-        b.getTruncateFlag());\n+    return (b.hasTruncateBlock()) ?\n+        new RecoveringBlock(block, locs, PBHelper.convert(b.getTruncateBlock())) :\n+        new RecoveringBlock(block, locs, b.getNewGenStamp());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static RecoveringBlock convert(RecoveringBlockProto b) {\n    ExtendedBlock block \u003d convert(b.getBlock().getB());\n    DatanodeInfo[] locs \u003d convert(b.getBlock().getLocsList());\n    return (b.hasTruncateBlock()) ?\n        new RecoveringBlock(block, locs, PBHelper.convert(b.getTruncateBlock())) :\n        new RecoveringBlock(block, locs, b.getNewGenStamp());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3107. Introduce truncate. Contributed by Plamen Jeliazkov.",
      "commitDate": "12/01/15 10:50 PM",
      "commitName": "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
      "commitAuthor": "Plamen Jeliazkov",
      "commitDateOld": "15/12/14 10:30 AM",
      "commitNameOld": "6e13fc62e1f284f22fd0089f06ce281198bc7c2a",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 28.51,
      "commitsBetweenForRepo": 143,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,6 @@\n   public static RecoveringBlock convert(RecoveringBlockProto b) {\n     ExtendedBlock block \u003d convert(b.getBlock().getB());\n     DatanodeInfo[] locs \u003d convert(b.getBlock().getLocsList());\n-    return new RecoveringBlock(block, locs, b.getNewGenStamp());\n+    return new RecoveringBlock(block, locs, b.getNewGenStamp(),\n+        b.getTruncateFlag());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static RecoveringBlock convert(RecoveringBlockProto b) {\n    ExtendedBlock block \u003d convert(b.getBlock().getB());\n    DatanodeInfo[] locs \u003d convert(b.getBlock().getLocsList());\n    return new RecoveringBlock(block, locs, b.getNewGenStamp(),\n        b.getTruncateFlag());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "7a59150bff64fc81f838de586eacd6d062172605": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-2629. Implement protobuf service for InterDatanodeProtocol. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1211206 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/12/11 2:19 PM",
      "commitName": "7a59150bff64fc81f838de586eacd6d062172605",
      "commitAuthor": "Suresh Srinivas",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2629. Implement protobuf service for InterDatanodeProtocol. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1211206 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/11 2:19 PM",
          "commitName": "7a59150bff64fc81f838de586eacd6d062172605",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "05/12/11 4:25 PM",
          "commitNameOld": "0a713035f2fb1a222291cfdb2cbde906814c2fd9",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 0.91,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,5 @@\n-  public static BlockWithLocations[] convert(List\u003cBlockWithLocationsProto\u003e b) {\n-    BlockWithLocations[] ret \u003d new BlockWithLocations[b.size()];\n-    int i \u003d 0;\n-    for (BlockWithLocationsProto entry : b) {\n-      ret[i++] \u003d convert(entry);\n-    }\n-    return ret;\n+  public static RecoveringBlock convert(RecoveringBlockProto b) {\n+    ExtendedBlock block \u003d convert(b.getBlock().getB());\n+    DatanodeInfo[] locs \u003d convert(b.getBlock().getLocsList());\n+    return new RecoveringBlock(block, locs, b.getNewGenStamp());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static RecoveringBlock convert(RecoveringBlockProto b) {\n    ExtendedBlock block \u003d convert(b.getBlock().getB());\n    DatanodeInfo[] locs \u003d convert(b.getBlock().getLocsList());\n    return new RecoveringBlock(block, locs, b.getNewGenStamp());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
          "extendedDetails": {
            "oldValue": "[b-List\u003cBlockWithLocationsProto\u003e]",
            "newValue": "[b-RecoveringBlockProto]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-2629. Implement protobuf service for InterDatanodeProtocol. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1211206 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/11 2:19 PM",
          "commitName": "7a59150bff64fc81f838de586eacd6d062172605",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "05/12/11 4:25 PM",
          "commitNameOld": "0a713035f2fb1a222291cfdb2cbde906814c2fd9",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 0.91,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,5 @@\n-  public static BlockWithLocations[] convert(List\u003cBlockWithLocationsProto\u003e b) {\n-    BlockWithLocations[] ret \u003d new BlockWithLocations[b.size()];\n-    int i \u003d 0;\n-    for (BlockWithLocationsProto entry : b) {\n-      ret[i++] \u003d convert(entry);\n-    }\n-    return ret;\n+  public static RecoveringBlock convert(RecoveringBlockProto b) {\n+    ExtendedBlock block \u003d convert(b.getBlock().getB());\n+    DatanodeInfo[] locs \u003d convert(b.getBlock().getLocsList());\n+    return new RecoveringBlock(block, locs, b.getNewGenStamp());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static RecoveringBlock convert(RecoveringBlockProto b) {\n    ExtendedBlock block \u003d convert(b.getBlock().getB());\n    DatanodeInfo[] locs \u003d convert(b.getBlock().getLocsList());\n    return new RecoveringBlock(block, locs, b.getNewGenStamp());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
          "extendedDetails": {
            "oldValue": "BlockWithLocations[]",
            "newValue": "RecoveringBlock"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2629. Implement protobuf service for InterDatanodeProtocol. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1211206 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/11 2:19 PM",
          "commitName": "7a59150bff64fc81f838de586eacd6d062172605",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "05/12/11 4:25 PM",
          "commitNameOld": "0a713035f2fb1a222291cfdb2cbde906814c2fd9",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 0.91,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,5 @@\n-  public static BlockWithLocations[] convert(List\u003cBlockWithLocationsProto\u003e b) {\n-    BlockWithLocations[] ret \u003d new BlockWithLocations[b.size()];\n-    int i \u003d 0;\n-    for (BlockWithLocationsProto entry : b) {\n-      ret[i++] \u003d convert(entry);\n-    }\n-    return ret;\n+  public static RecoveringBlock convert(RecoveringBlockProto b) {\n+    ExtendedBlock block \u003d convert(b.getBlock().getB());\n+    DatanodeInfo[] locs \u003d convert(b.getBlock().getLocsList());\n+    return new RecoveringBlock(block, locs, b.getNewGenStamp());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static RecoveringBlock convert(RecoveringBlockProto b) {\n    ExtendedBlock block \u003d convert(b.getBlock().getB());\n    DatanodeInfo[] locs \u003d convert(b.getBlock().getLocsList());\n    return new RecoveringBlock(block, locs, b.getNewGenStamp());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
          "extendedDetails": {}
        }
      ]
    },
    "0a713035f2fb1a222291cfdb2cbde906814c2fd9": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2618. Implement protobuf service for NamenodeProtocol. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1210719 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/12/11 4:25 PM",
      "commitName": "0a713035f2fb1a222291cfdb2cbde906814c2fd9",
      "commitAuthor": "Suresh Srinivas",
      "diff": "@@ -0,0 +1,8 @@\n+  public static BlockWithLocations[] convert(List\u003cBlockWithLocationsProto\u003e b) {\n+    BlockWithLocations[] ret \u003d new BlockWithLocations[b.size()];\n+    int i \u003d 0;\n+    for (BlockWithLocationsProto entry : b) {\n+      ret[i++] \u003d convert(entry);\n+    }\n+    return ret;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockWithLocations[] convert(List\u003cBlockWithLocationsProto\u003e b) {\n    BlockWithLocations[] ret \u003d new BlockWithLocations[b.size()];\n    int i \u003d 0;\n    for (BlockWithLocationsProto entry : b) {\n      ret[i++] \u003d convert(entry);\n    }\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java"
    }
  }
}