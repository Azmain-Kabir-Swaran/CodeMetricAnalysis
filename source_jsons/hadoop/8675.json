{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSDirTruncateOp.java",
  "functionName": "unprotectedTruncate",
  "functionId": "unprotectedTruncate___fsn-FSNamesystem__iip-INodesInPath__newLength-long__collectedBlocks-BlocksMapUpdateInfo__mtime-long__delta-QuotaCounts",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
  "functionStartLine": 294,
  "functionEndLine": 311,
  "numCommitsSeen": 498,
  "timeTaken": 6175,
  "changeHistory": [
    "972782d9568e0849484c027f27c1638ba50ec56e",
    "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
    "d368d3647a858644b9fcd3be33d9fea2a6962f69",
    "f2231cebcddc80f0b753c4a7cb45ee4040846951",
    "5dae97a584d30cef3e34141edfaca49c4ec57913",
    "08ac06283a3e9bf0d49d873823aabd419b08e41f",
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2"
  ],
  "changeHistoryShort": {
    "972782d9568e0849484c027f27c1638ba50ec56e": "Ybodychange",
    "d3797f9f3cf502b7bfee3b64c641807b276c6faf": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yparameterchange)",
    "d368d3647a858644b9fcd3be33d9fea2a6962f69": "Ymultichange(Yparameterchange,Ybodychange)",
    "f2231cebcddc80f0b753c4a7cb45ee4040846951": "Ybodychange",
    "5dae97a584d30cef3e34141edfaca49c4ec57913": "Ybodychange",
    "08ac06283a3e9bf0d49d873823aabd419b08e41f": "Ybodychange",
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2": "Yintroduced"
  },
  "changeHistoryDetails": {
    "972782d9568e0849484c027f27c1638ba50ec56e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9754. Avoid unnecessary getBlockCollection calls in BlockManager. Contributed by Jing Zhao.\n",
      "commitDate": "12/02/16 11:07 AM",
      "commitName": "972782d9568e0849484c027f27c1638ba50ec56e",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "21/01/16 11:13 AM",
      "commitNameOld": "c304890c8c7782d835896859f5b7f60b96c306c0",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 22.0,
      "commitsBetweenForRepo": 168,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   private static boolean unprotectedTruncate(FSNamesystem fsn,\n       INodesInPath iip, long newLength, BlocksMapUpdateInfo collectedBlocks,\n       long mtime, QuotaCounts delta) throws IOException {\n     assert fsn.hasWriteLock();\n \n     INodeFile file \u003d iip.getLastINode().asFile();\n     int latestSnapshot \u003d iip.getLatestSnapshotId();\n     file.recordModification(latestSnapshot, true);\n \n     verifyQuotaForTruncate(fsn, iip, file, newLength, delta);\n \n-    long remainingLength \u003d\n-        file.collectBlocksBeyondMax(newLength, collectedBlocks);\n-    file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n+    Set\u003cBlockInfo\u003e toRetain \u003d file.getSnapshotBlocksToRetain(latestSnapshot);\n+    long remainingLength \u003d file.collectBlocksBeyondMax(newLength,\n+        collectedBlocks, toRetain);\n     file.setModificationTime(mtime);\n     // return whether on a block boundary\n     return (remainingLength - newLength) \u003d\u003d 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static boolean unprotectedTruncate(FSNamesystem fsn,\n      INodesInPath iip, long newLength, BlocksMapUpdateInfo collectedBlocks,\n      long mtime, QuotaCounts delta) throws IOException {\n    assert fsn.hasWriteLock();\n\n    INodeFile file \u003d iip.getLastINode().asFile();\n    int latestSnapshot \u003d iip.getLatestSnapshotId();\n    file.recordModification(latestSnapshot, true);\n\n    verifyQuotaForTruncate(fsn, iip, file, newLength, delta);\n\n    Set\u003cBlockInfo\u003e toRetain \u003d file.getSnapshotBlocksToRetain(latestSnapshot);\n    long remainingLength \u003d file.collectBlocksBeyondMax(newLength,\n        collectedBlocks, toRetain);\n    file.setModificationTime(mtime);\n    // return whether on a block boundary\n    return (remainingLength - newLength) \u003d\u003d 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
      "extendedDetails": {}
    },
    "d3797f9f3cf502b7bfee3b64c641807b276c6faf": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yparameterchange)",
      "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
      "commitDate": "29/06/15 4:45 PM",
      "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
          "commitDate": "29/06/15 4:45 PM",
          "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "29/06/15 2:56 PM",
          "commitNameOld": "8e333720e13428a4d0d0f65692102f8f2e5da98d",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,18 @@\n-  boolean unprotectedTruncate(INodesInPath iip, long newLength,\n-                              BlocksMapUpdateInfo collectedBlocks,\n-                              long mtime, QuotaCounts delta) throws IOException {\n-    assert hasWriteLock();\n+  private static boolean unprotectedTruncate(FSNamesystem fsn,\n+      INodesInPath iip, long newLength, BlocksMapUpdateInfo collectedBlocks,\n+      long mtime, QuotaCounts delta) throws IOException {\n+    assert fsn.hasWriteLock();\n+\n     INodeFile file \u003d iip.getLastINode().asFile();\n     int latestSnapshot \u003d iip.getLatestSnapshotId();\n     file.recordModification(latestSnapshot, true);\n \n-    verifyQuotaForTruncate(iip, file, newLength, delta);\n+    verifyQuotaForTruncate(fsn, iip, file, newLength, delta);\n \n     long remainingLength \u003d\n         file.collectBlocksBeyondMax(newLength, collectedBlocks);\n     file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n     file.setModificationTime(mtime);\n     // return whether on a block boundary\n     return (remainingLength - newLength) \u003d\u003d 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static boolean unprotectedTruncate(FSNamesystem fsn,\n      INodesInPath iip, long newLength, BlocksMapUpdateInfo collectedBlocks,\n      long mtime, QuotaCounts delta) throws IOException {\n    assert fsn.hasWriteLock();\n\n    INodeFile file \u003d iip.getLastINode().asFile();\n    int latestSnapshot \u003d iip.getLatestSnapshotId();\n    file.recordModification(latestSnapshot, true);\n\n    verifyQuotaForTruncate(fsn, iip, file, newLength, delta);\n\n    long remainingLength \u003d\n        file.collectBlocksBeyondMax(newLength, collectedBlocks);\n    file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n    file.setModificationTime(mtime);\n    // return whether on a block boundary\n    return (remainingLength - newLength) \u003d\u003d 0;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
            "oldMethodName": "unprotectedTruncate",
            "newMethodName": "unprotectedTruncate"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
          "commitDate": "29/06/15 4:45 PM",
          "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "29/06/15 2:56 PM",
          "commitNameOld": "8e333720e13428a4d0d0f65692102f8f2e5da98d",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,18 @@\n-  boolean unprotectedTruncate(INodesInPath iip, long newLength,\n-                              BlocksMapUpdateInfo collectedBlocks,\n-                              long mtime, QuotaCounts delta) throws IOException {\n-    assert hasWriteLock();\n+  private static boolean unprotectedTruncate(FSNamesystem fsn,\n+      INodesInPath iip, long newLength, BlocksMapUpdateInfo collectedBlocks,\n+      long mtime, QuotaCounts delta) throws IOException {\n+    assert fsn.hasWriteLock();\n+\n     INodeFile file \u003d iip.getLastINode().asFile();\n     int latestSnapshot \u003d iip.getLatestSnapshotId();\n     file.recordModification(latestSnapshot, true);\n \n-    verifyQuotaForTruncate(iip, file, newLength, delta);\n+    verifyQuotaForTruncate(fsn, iip, file, newLength, delta);\n \n     long remainingLength \u003d\n         file.collectBlocksBeyondMax(newLength, collectedBlocks);\n     file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n     file.setModificationTime(mtime);\n     // return whether on a block boundary\n     return (remainingLength - newLength) \u003d\u003d 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static boolean unprotectedTruncate(FSNamesystem fsn,\n      INodesInPath iip, long newLength, BlocksMapUpdateInfo collectedBlocks,\n      long mtime, QuotaCounts delta) throws IOException {\n    assert fsn.hasWriteLock();\n\n    INodeFile file \u003d iip.getLastINode().asFile();\n    int latestSnapshot \u003d iip.getLatestSnapshotId();\n    file.recordModification(latestSnapshot, true);\n\n    verifyQuotaForTruncate(fsn, iip, file, newLength, delta);\n\n    long remainingLength \u003d\n        file.collectBlocksBeyondMax(newLength, collectedBlocks);\n    file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n    file.setModificationTime(mtime);\n    // return whether on a block boundary\n    return (remainingLength - newLength) \u003d\u003d 0;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[private, static]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
          "commitDate": "29/06/15 4:45 PM",
          "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "29/06/15 2:56 PM",
          "commitNameOld": "8e333720e13428a4d0d0f65692102f8f2e5da98d",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,18 @@\n-  boolean unprotectedTruncate(INodesInPath iip, long newLength,\n-                              BlocksMapUpdateInfo collectedBlocks,\n-                              long mtime, QuotaCounts delta) throws IOException {\n-    assert hasWriteLock();\n+  private static boolean unprotectedTruncate(FSNamesystem fsn,\n+      INodesInPath iip, long newLength, BlocksMapUpdateInfo collectedBlocks,\n+      long mtime, QuotaCounts delta) throws IOException {\n+    assert fsn.hasWriteLock();\n+\n     INodeFile file \u003d iip.getLastINode().asFile();\n     int latestSnapshot \u003d iip.getLatestSnapshotId();\n     file.recordModification(latestSnapshot, true);\n \n-    verifyQuotaForTruncate(iip, file, newLength, delta);\n+    verifyQuotaForTruncate(fsn, iip, file, newLength, delta);\n \n     long remainingLength \u003d\n         file.collectBlocksBeyondMax(newLength, collectedBlocks);\n     file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n     file.setModificationTime(mtime);\n     // return whether on a block boundary\n     return (remainingLength - newLength) \u003d\u003d 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static boolean unprotectedTruncate(FSNamesystem fsn,\n      INodesInPath iip, long newLength, BlocksMapUpdateInfo collectedBlocks,\n      long mtime, QuotaCounts delta) throws IOException {\n    assert fsn.hasWriteLock();\n\n    INodeFile file \u003d iip.getLastINode().asFile();\n    int latestSnapshot \u003d iip.getLatestSnapshotId();\n    file.recordModification(latestSnapshot, true);\n\n    verifyQuotaForTruncate(fsn, iip, file, newLength, delta);\n\n    long remainingLength \u003d\n        file.collectBlocksBeyondMax(newLength, collectedBlocks);\n    file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n    file.setModificationTime(mtime);\n    // return whether on a block boundary\n    return (remainingLength - newLength) \u003d\u003d 0;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
          "commitDate": "29/06/15 4:45 PM",
          "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "29/06/15 2:56 PM",
          "commitNameOld": "8e333720e13428a4d0d0f65692102f8f2e5da98d",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,18 @@\n-  boolean unprotectedTruncate(INodesInPath iip, long newLength,\n-                              BlocksMapUpdateInfo collectedBlocks,\n-                              long mtime, QuotaCounts delta) throws IOException {\n-    assert hasWriteLock();\n+  private static boolean unprotectedTruncate(FSNamesystem fsn,\n+      INodesInPath iip, long newLength, BlocksMapUpdateInfo collectedBlocks,\n+      long mtime, QuotaCounts delta) throws IOException {\n+    assert fsn.hasWriteLock();\n+\n     INodeFile file \u003d iip.getLastINode().asFile();\n     int latestSnapshot \u003d iip.getLatestSnapshotId();\n     file.recordModification(latestSnapshot, true);\n \n-    verifyQuotaForTruncate(iip, file, newLength, delta);\n+    verifyQuotaForTruncate(fsn, iip, file, newLength, delta);\n \n     long remainingLength \u003d\n         file.collectBlocksBeyondMax(newLength, collectedBlocks);\n     file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n     file.setModificationTime(mtime);\n     // return whether on a block boundary\n     return (remainingLength - newLength) \u003d\u003d 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static boolean unprotectedTruncate(FSNamesystem fsn,\n      INodesInPath iip, long newLength, BlocksMapUpdateInfo collectedBlocks,\n      long mtime, QuotaCounts delta) throws IOException {\n    assert fsn.hasWriteLock();\n\n    INodeFile file \u003d iip.getLastINode().asFile();\n    int latestSnapshot \u003d iip.getLatestSnapshotId();\n    file.recordModification(latestSnapshot, true);\n\n    verifyQuotaForTruncate(fsn, iip, file, newLength, delta);\n\n    long remainingLength \u003d\n        file.collectBlocksBeyondMax(newLength, collectedBlocks);\n    file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n    file.setModificationTime(mtime);\n    // return whether on a block boundary\n    return (remainingLength - newLength) \u003d\u003d 0;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {
            "oldValue": "[iip-INodesInPath, newLength-long, collectedBlocks-BlocksMapUpdateInfo, mtime-long, delta-QuotaCounts]",
            "newValue": "[fsn-FSNamesystem, iip-INodesInPath, newLength-long, collectedBlocks-BlocksMapUpdateInfo, mtime-long, delta-QuotaCounts]"
          }
        }
      ]
    },
    "d368d3647a858644b9fcd3be33d9fea2a6962f69": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7957. Truncate should verify quota before making changes. Contributed by Jing Zhao.\n",
      "commitDate": "20/03/15 11:50 AM",
      "commitName": "d368d3647a858644b9fcd3be33d9fea2a6962f69",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7957. Truncate should verify quota before making changes. Contributed by Jing Zhao.\n",
          "commitDate": "20/03/15 11:50 AM",
          "commitName": "d368d3647a858644b9fcd3be33d9fea2a6962f69",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "21/02/15 3:38 PM",
          "commitNameOld": "8b465b4b8caed31ca9daeaae108f9a868a30a455",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 26.8,
          "commitsBetweenForRepo": 228,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,17 @@\n   boolean unprotectedTruncate(INodesInPath iip, long newLength,\n                               BlocksMapUpdateInfo collectedBlocks,\n-                              long mtime) throws IOException {\n+                              long mtime, QuotaCounts delta) throws IOException {\n     assert hasWriteLock();\n     INodeFile file \u003d iip.getLastINode().asFile();\n     int latestSnapshot \u003d iip.getLatestSnapshotId();\n     file.recordModification(latestSnapshot, true);\n-    long oldDiskspaceNoRep \u003d file.storagespaceConsumedNoReplication();\n+\n+    verifyQuotaForTruncate(iip, file, newLength, delta);\n+\n     long remainingLength \u003d\n         file.collectBlocksBeyondMax(newLength, collectedBlocks);\n     file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n     file.setModificationTime(mtime);\n-    updateCount(iip, 0, file.storagespaceConsumedNoReplication() - oldDiskspaceNoRep,\n-      file.getBlockReplication(), true);\n     // return whether on a block boundary\n     return (remainingLength - newLength) \u003d\u003d 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean unprotectedTruncate(INodesInPath iip, long newLength,\n                              BlocksMapUpdateInfo collectedBlocks,\n                              long mtime, QuotaCounts delta) throws IOException {\n    assert hasWriteLock();\n    INodeFile file \u003d iip.getLastINode().asFile();\n    int latestSnapshot \u003d iip.getLatestSnapshotId();\n    file.recordModification(latestSnapshot, true);\n\n    verifyQuotaForTruncate(iip, file, newLength, delta);\n\n    long remainingLength \u003d\n        file.collectBlocksBeyondMax(newLength, collectedBlocks);\n    file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n    file.setModificationTime(mtime);\n    // return whether on a block boundary\n    return (remainingLength - newLength) \u003d\u003d 0;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[iip-INodesInPath, newLength-long, collectedBlocks-BlocksMapUpdateInfo, mtime-long]",
            "newValue": "[iip-INodesInPath, newLength-long, collectedBlocks-BlocksMapUpdateInfo, mtime-long, delta-QuotaCounts]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7957. Truncate should verify quota before making changes. Contributed by Jing Zhao.\n",
          "commitDate": "20/03/15 11:50 AM",
          "commitName": "d368d3647a858644b9fcd3be33d9fea2a6962f69",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "21/02/15 3:38 PM",
          "commitNameOld": "8b465b4b8caed31ca9daeaae108f9a868a30a455",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 26.8,
          "commitsBetweenForRepo": 228,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,17 @@\n   boolean unprotectedTruncate(INodesInPath iip, long newLength,\n                               BlocksMapUpdateInfo collectedBlocks,\n-                              long mtime) throws IOException {\n+                              long mtime, QuotaCounts delta) throws IOException {\n     assert hasWriteLock();\n     INodeFile file \u003d iip.getLastINode().asFile();\n     int latestSnapshot \u003d iip.getLatestSnapshotId();\n     file.recordModification(latestSnapshot, true);\n-    long oldDiskspaceNoRep \u003d file.storagespaceConsumedNoReplication();\n+\n+    verifyQuotaForTruncate(iip, file, newLength, delta);\n+\n     long remainingLength \u003d\n         file.collectBlocksBeyondMax(newLength, collectedBlocks);\n     file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n     file.setModificationTime(mtime);\n-    updateCount(iip, 0, file.storagespaceConsumedNoReplication() - oldDiskspaceNoRep,\n-      file.getBlockReplication(), true);\n     // return whether on a block boundary\n     return (remainingLength - newLength) \u003d\u003d 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean unprotectedTruncate(INodesInPath iip, long newLength,\n                              BlocksMapUpdateInfo collectedBlocks,\n                              long mtime, QuotaCounts delta) throws IOException {\n    assert hasWriteLock();\n    INodeFile file \u003d iip.getLastINode().asFile();\n    int latestSnapshot \u003d iip.getLatestSnapshotId();\n    file.recordModification(latestSnapshot, true);\n\n    verifyQuotaForTruncate(iip, file, newLength, delta);\n\n    long remainingLength \u003d\n        file.collectBlocksBeyondMax(newLength, collectedBlocks);\n    file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n    file.setModificationTime(mtime);\n    // return whether on a block boundary\n    return (remainingLength - newLength) \u003d\u003d 0;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {}
        }
      ]
    },
    "f2231cebcddc80f0b753c4a7cb45ee4040846951": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7775. Use consistent naming for NN-internal quota related types and functions. (Contributed bu Xiaoyu Yao)\n",
      "commitDate": "13/02/15 9:01 PM",
      "commitName": "f2231cebcddc80f0b753c4a7cb45ee4040846951",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "11/02/15 10:41 AM",
      "commitNameOld": "5dae97a584d30cef3e34141edfaca49c4ec57913",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 2.43,
      "commitsBetweenForRepo": 58,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   boolean unprotectedTruncate(INodesInPath iip, long newLength,\n                               BlocksMapUpdateInfo collectedBlocks,\n                               long mtime) throws IOException {\n     assert hasWriteLock();\n     INodeFile file \u003d iip.getLastINode().asFile();\n     int latestSnapshot \u003d iip.getLatestSnapshotId();\n     file.recordModification(latestSnapshot, true);\n-    long oldDiskspaceNoRep \u003d file.diskspaceConsumedNoReplication();\n+    long oldDiskspaceNoRep \u003d file.storagespaceConsumedNoReplication();\n     long remainingLength \u003d\n         file.collectBlocksBeyondMax(newLength, collectedBlocks);\n     file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n     file.setModificationTime(mtime);\n-    updateCount(iip, 0, file.diskspaceConsumedNoReplication() - oldDiskspaceNoRep,\n+    updateCount(iip, 0, file.storagespaceConsumedNoReplication() - oldDiskspaceNoRep,\n       file.getBlockReplication(), true);\n     // return whether on a block boundary\n     return (remainingLength - newLength) \u003d\u003d 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean unprotectedTruncate(INodesInPath iip, long newLength,\n                              BlocksMapUpdateInfo collectedBlocks,\n                              long mtime) throws IOException {\n    assert hasWriteLock();\n    INodeFile file \u003d iip.getLastINode().asFile();\n    int latestSnapshot \u003d iip.getLatestSnapshotId();\n    file.recordModification(latestSnapshot, true);\n    long oldDiskspaceNoRep \u003d file.storagespaceConsumedNoReplication();\n    long remainingLength \u003d\n        file.collectBlocksBeyondMax(newLength, collectedBlocks);\n    file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n    file.setModificationTime(mtime);\n    updateCount(iip, 0, file.storagespaceConsumedNoReplication() - oldDiskspaceNoRep,\n      file.getBlockReplication(), true);\n    // return whether on a block boundary\n    return (remainingLength - newLength) \u003d\u003d 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "5dae97a584d30cef3e34141edfaca49c4ec57913": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7723. Quota By Storage Type namenode implemenation. (Contributed by Xiaoyu Yao)\n",
      "commitDate": "11/02/15 10:41 AM",
      "commitName": "5dae97a584d30cef3e34141edfaca49c4ec57913",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "08/02/15 11:51 AM",
      "commitNameOld": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 2.95,
      "commitsBetweenForRepo": 40,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,17 @@\n   boolean unprotectedTruncate(INodesInPath iip, long newLength,\n                               BlocksMapUpdateInfo collectedBlocks,\n                               long mtime) throws IOException {\n     assert hasWriteLock();\n     INodeFile file \u003d iip.getLastINode().asFile();\n     int latestSnapshot \u003d iip.getLatestSnapshotId();\n     file.recordModification(latestSnapshot, true);\n-    long oldDiskspace \u003d file.diskspaceConsumed();\n+    long oldDiskspaceNoRep \u003d file.diskspaceConsumedNoReplication();\n     long remainingLength \u003d\n         file.collectBlocksBeyondMax(newLength, collectedBlocks);\n     file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n     file.setModificationTime(mtime);\n-    updateCount(iip, 0, file.diskspaceConsumed() - oldDiskspace, true);\n+    updateCount(iip, 0, file.diskspaceConsumedNoReplication() - oldDiskspaceNoRep,\n+      file.getBlockReplication(), true);\n     // return whether on a block boundary\n     return (remainingLength - newLength) \u003d\u003d 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean unprotectedTruncate(INodesInPath iip, long newLength,\n                              BlocksMapUpdateInfo collectedBlocks,\n                              long mtime) throws IOException {\n    assert hasWriteLock();\n    INodeFile file \u003d iip.getLastINode().asFile();\n    int latestSnapshot \u003d iip.getLatestSnapshotId();\n    file.recordModification(latestSnapshot, true);\n    long oldDiskspaceNoRep \u003d file.diskspaceConsumedNoReplication();\n    long remainingLength \u003d\n        file.collectBlocksBeyondMax(newLength, collectedBlocks);\n    file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n    file.setModificationTime(mtime);\n    updateCount(iip, 0, file.diskspaceConsumedNoReplication() - oldDiskspaceNoRep,\n      file.getBlockReplication(), true);\n    // return whether on a block boundary\n    return (remainingLength - newLength) \u003d\u003d 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "08ac06283a3e9bf0d49d873823aabd419b08e41f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7056. Snapshot support for truncate. Contributed by Konstantin Shvachko and Plamen Jeliazkov.",
      "commitDate": "13/01/15 12:24 AM",
      "commitName": "08ac06283a3e9bf0d49d873823aabd419b08e41f",
      "commitAuthor": "Konstantin V Shvachko",
      "commitDateOld": "12/01/15 10:50 PM",
      "commitNameOld": "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
      "commitAuthorOld": "Plamen Jeliazkov",
      "daysBetweenCommits": 0.07,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,16 @@\n   boolean unprotectedTruncate(INodesInPath iip, long newLength,\n                               BlocksMapUpdateInfo collectedBlocks,\n                               long mtime) throws IOException {\n     assert hasWriteLock();\n     INodeFile file \u003d iip.getLastINode().asFile();\n+    int latestSnapshot \u003d iip.getLatestSnapshotId();\n+    file.recordModification(latestSnapshot, true);\n     long oldDiskspace \u003d file.diskspaceConsumed();\n     long remainingLength \u003d\n         file.collectBlocksBeyondMax(newLength, collectedBlocks);\n+    file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n     file.setModificationTime(mtime);\n     updateCount(iip, 0, file.diskspaceConsumed() - oldDiskspace, true);\n-    // If on block boundary, then return\n-    long lastBlockDelta \u003d remainingLength - newLength;\n-    if(lastBlockDelta \u003d\u003d 0)\n-      return true;\n-    // Set new last block length\n-    BlockInfo lastBlock \u003d file.getLastBlock();\n-    assert lastBlock.getNumBytes() - lastBlockDelta \u003e 0 : \"wrong block size\";\n-    lastBlock.setNumBytes(lastBlock.getNumBytes() - lastBlockDelta);\n-    return false;\n+    // return whether on a block boundary\n+    return (remainingLength - newLength) \u003d\u003d 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean unprotectedTruncate(INodesInPath iip, long newLength,\n                              BlocksMapUpdateInfo collectedBlocks,\n                              long mtime) throws IOException {\n    assert hasWriteLock();\n    INodeFile file \u003d iip.getLastINode().asFile();\n    int latestSnapshot \u003d iip.getLatestSnapshotId();\n    file.recordModification(latestSnapshot, true);\n    long oldDiskspace \u003d file.diskspaceConsumed();\n    long remainingLength \u003d\n        file.collectBlocksBeyondMax(newLength, collectedBlocks);\n    file.excludeSnapshotBlocks(latestSnapshot, collectedBlocks);\n    file.setModificationTime(mtime);\n    updateCount(iip, 0, file.diskspaceConsumed() - oldDiskspace, true);\n    // return whether on a block boundary\n    return (remainingLength - newLength) \u003d\u003d 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3107. Introduce truncate. Contributed by Plamen Jeliazkov.",
      "commitDate": "12/01/15 10:50 PM",
      "commitName": "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
      "commitAuthor": "Plamen Jeliazkov",
      "diff": "@@ -0,0 +1,20 @@\n+  boolean unprotectedTruncate(INodesInPath iip, long newLength,\n+                              BlocksMapUpdateInfo collectedBlocks,\n+                              long mtime) throws IOException {\n+    assert hasWriteLock();\n+    INodeFile file \u003d iip.getLastINode().asFile();\n+    long oldDiskspace \u003d file.diskspaceConsumed();\n+    long remainingLength \u003d\n+        file.collectBlocksBeyondMax(newLength, collectedBlocks);\n+    file.setModificationTime(mtime);\n+    updateCount(iip, 0, file.diskspaceConsumed() - oldDiskspace, true);\n+    // If on block boundary, then return\n+    long lastBlockDelta \u003d remainingLength - newLength;\n+    if(lastBlockDelta \u003d\u003d 0)\n+      return true;\n+    // Set new last block length\n+    BlockInfo lastBlock \u003d file.getLastBlock();\n+    assert lastBlock.getNumBytes() - lastBlockDelta \u003e 0 : \"wrong block size\";\n+    lastBlock.setNumBytes(lastBlock.getNumBytes() - lastBlockDelta);\n+    return false;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  boolean unprotectedTruncate(INodesInPath iip, long newLength,\n                              BlocksMapUpdateInfo collectedBlocks,\n                              long mtime) throws IOException {\n    assert hasWriteLock();\n    INodeFile file \u003d iip.getLastINode().asFile();\n    long oldDiskspace \u003d file.diskspaceConsumed();\n    long remainingLength \u003d\n        file.collectBlocksBeyondMax(newLength, collectedBlocks);\n    file.setModificationTime(mtime);\n    updateCount(iip, 0, file.diskspaceConsumed() - oldDiskspace, true);\n    // If on block boundary, then return\n    long lastBlockDelta \u003d remainingLength - newLength;\n    if(lastBlockDelta \u003d\u003d 0)\n      return true;\n    // Set new last block length\n    BlockInfo lastBlock \u003d file.getLastBlock();\n    assert lastBlock.getNumBytes() - lastBlockDelta \u003e 0 : \"wrong block size\";\n    lastBlock.setNumBytes(lastBlock.getNumBytes() - lastBlockDelta);\n    return false;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java"
    }
  }
}