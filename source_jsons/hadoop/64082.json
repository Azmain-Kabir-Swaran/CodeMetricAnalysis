{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3ADataBlocks.java",
  "functionName": "read",
  "functionId": "read___b-byte[]__offset-int__length-int",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java",
  "functionStartLine": 747,
  "functionEndLine": 766,
  "numCommitsSeen": 7,
  "timeTaken": 1701,
  "changeHistory": [
    "dab00da19f25619ccc71c7f803a235b21766bf1e",
    "6c348c56918973fd988b110e79231324a8befe12"
  ],
  "changeHistoryShort": {
    "dab00da19f25619ccc71c7f803a235b21766bf1e": "Ymultichange(Yparameterchange,Ybodychange)",
    "6c348c56918973fd988b110e79231324a8befe12": "Yintroduced"
  },
  "changeHistoryDetails": {
    "dab00da19f25619ccc71c7f803a235b21766bf1e": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HADOOP-14028. S3A BlockOutputStreams doesn\u0027t delete temporary files in multipart uploads or handle part upload failures.\nContributed by Steve Loughran.\n\n(cherry picked from commit 29fe5af017b945d8750c074ca39031b5b777eddd)\n",
      "commitDate": "25/02/17 7:35 AM",
      "commitName": "dab00da19f25619ccc71c7f803a235b21766bf1e",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-14028. S3A BlockOutputStreams doesn\u0027t delete temporary files in multipart uploads or handle part upload failures.\nContributed by Steve Loughran.\n\n(cherry picked from commit 29fe5af017b945d8750c074ca39031b5b777eddd)\n",
          "commitDate": "25/02/17 7:35 AM",
          "commitName": "dab00da19f25619ccc71c7f803a235b21766bf1e",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "20/02/17 8:21 AM",
          "commitNameOld": "8035749c26947dc641ef87dac041050d439a16d1",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 4.97,
          "commitsBetweenForRepo": 37,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,20 @@\n-      public synchronized int read(byte[] buffer, int offset, int length)\n-          throws IOException {\n-        Preconditions.checkArgument(length \u003e\u003d 0, \"length is negative\");\n-        Preconditions.checkArgument(buffer !\u003d null, \"Null buffer\");\n-        if (buffer.length - offset \u003c length) {\n-          throw new IndexOutOfBoundsException(\n-              FSExceptionMessages.TOO_MANY_BYTES_FOR_DEST_BUFFER\n-                  + \": request length \u003d\" + length\n-                  + \", with offset \u003d\" + offset\n-                  + \"; buffer capacity \u003d\" + (buffer.length - offset));\n-        }\n-        verifyOpen();\n-        if (!hasRemaining()) {\n-          return -1;\n-        }\n+        public synchronized int read(byte[] b, int offset, int length)\n+            throws IOException {\n+          Preconditions.checkArgument(length \u003e\u003d 0, \"length is negative\");\n+          Preconditions.checkArgument(b !\u003d null, \"Null buffer\");\n+          if (b.length - offset \u003c length) {\n+            throw new IndexOutOfBoundsException(\n+                FSExceptionMessages.TOO_MANY_BYTES_FOR_DEST_BUFFER\n+                    + \": request length \u003d\" + length\n+                    + \", with offset \u003d\" + offset\n+                    + \"; buffer capacity \u003d\" + (b.length - offset));\n+          }\n+          verifyOpen();\n+          if (!hasRemaining()) {\n+            return -1;\n+          }\n \n-        int toRead \u003d Math.min(length, available());\n-        byteBuffer.get(buffer, offset, toRead);\n-        return toRead;\n-      }\n\\ No newline at end of file\n+          int toRead \u003d Math.min(length, available());\n+          byteBuffer.get(b, offset, toRead);\n+          return toRead;\n+        }\n\\ No newline at end of file\n",
          "actualSource": "        public synchronized int read(byte[] b, int offset, int length)\n            throws IOException {\n          Preconditions.checkArgument(length \u003e\u003d 0, \"length is negative\");\n          Preconditions.checkArgument(b !\u003d null, \"Null buffer\");\n          if (b.length - offset \u003c length) {\n            throw new IndexOutOfBoundsException(\n                FSExceptionMessages.TOO_MANY_BYTES_FOR_DEST_BUFFER\n                    + \": request length \u003d\" + length\n                    + \", with offset \u003d\" + offset\n                    + \"; buffer capacity \u003d\" + (b.length - offset));\n          }\n          verifyOpen();\n          if (!hasRemaining()) {\n            return -1;\n          }\n\n          int toRead \u003d Math.min(length, available());\n          byteBuffer.get(b, offset, toRead);\n          return toRead;\n        }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java",
          "extendedDetails": {
            "oldValue": "[buffer-byte[], offset-int, length-int]",
            "newValue": "[b-byte[], offset-int, length-int]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-14028. S3A BlockOutputStreams doesn\u0027t delete temporary files in multipart uploads or handle part upload failures.\nContributed by Steve Loughran.\n\n(cherry picked from commit 29fe5af017b945d8750c074ca39031b5b777eddd)\n",
          "commitDate": "25/02/17 7:35 AM",
          "commitName": "dab00da19f25619ccc71c7f803a235b21766bf1e",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "20/02/17 8:21 AM",
          "commitNameOld": "8035749c26947dc641ef87dac041050d439a16d1",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 4.97,
          "commitsBetweenForRepo": 37,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,20 @@\n-      public synchronized int read(byte[] buffer, int offset, int length)\n-          throws IOException {\n-        Preconditions.checkArgument(length \u003e\u003d 0, \"length is negative\");\n-        Preconditions.checkArgument(buffer !\u003d null, \"Null buffer\");\n-        if (buffer.length - offset \u003c length) {\n-          throw new IndexOutOfBoundsException(\n-              FSExceptionMessages.TOO_MANY_BYTES_FOR_DEST_BUFFER\n-                  + \": request length \u003d\" + length\n-                  + \", with offset \u003d\" + offset\n-                  + \"; buffer capacity \u003d\" + (buffer.length - offset));\n-        }\n-        verifyOpen();\n-        if (!hasRemaining()) {\n-          return -1;\n-        }\n+        public synchronized int read(byte[] b, int offset, int length)\n+            throws IOException {\n+          Preconditions.checkArgument(length \u003e\u003d 0, \"length is negative\");\n+          Preconditions.checkArgument(b !\u003d null, \"Null buffer\");\n+          if (b.length - offset \u003c length) {\n+            throw new IndexOutOfBoundsException(\n+                FSExceptionMessages.TOO_MANY_BYTES_FOR_DEST_BUFFER\n+                    + \": request length \u003d\" + length\n+                    + \", with offset \u003d\" + offset\n+                    + \"; buffer capacity \u003d\" + (b.length - offset));\n+          }\n+          verifyOpen();\n+          if (!hasRemaining()) {\n+            return -1;\n+          }\n \n-        int toRead \u003d Math.min(length, available());\n-        byteBuffer.get(buffer, offset, toRead);\n-        return toRead;\n-      }\n\\ No newline at end of file\n+          int toRead \u003d Math.min(length, available());\n+          byteBuffer.get(b, offset, toRead);\n+          return toRead;\n+        }\n\\ No newline at end of file\n",
          "actualSource": "        public synchronized int read(byte[] b, int offset, int length)\n            throws IOException {\n          Preconditions.checkArgument(length \u003e\u003d 0, \"length is negative\");\n          Preconditions.checkArgument(b !\u003d null, \"Null buffer\");\n          if (b.length - offset \u003c length) {\n            throw new IndexOutOfBoundsException(\n                FSExceptionMessages.TOO_MANY_BYTES_FOR_DEST_BUFFER\n                    + \": request length \u003d\" + length\n                    + \", with offset \u003d\" + offset\n                    + \"; buffer capacity \u003d\" + (b.length - offset));\n          }\n          verifyOpen();\n          if (!hasRemaining()) {\n            return -1;\n          }\n\n          int toRead \u003d Math.min(length, available());\n          byteBuffer.get(b, offset, toRead);\n          return toRead;\n        }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java",
          "extendedDetails": {}
        }
      ]
    },
    "6c348c56918973fd988b110e79231324a8befe12": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13560. S3ABlockOutputStream to support huge (many GB) file writes. Contributed by Steve Loughran\n",
      "commitDate": "18/10/16 1:16 PM",
      "commitName": "6c348c56918973fd988b110e79231324a8befe12",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,20 @@\n+      public synchronized int read(byte[] buffer, int offset, int length)\n+          throws IOException {\n+        Preconditions.checkArgument(length \u003e\u003d 0, \"length is negative\");\n+        Preconditions.checkArgument(buffer !\u003d null, \"Null buffer\");\n+        if (buffer.length - offset \u003c length) {\n+          throw new IndexOutOfBoundsException(\n+              FSExceptionMessages.TOO_MANY_BYTES_FOR_DEST_BUFFER\n+                  + \": request length \u003d\" + length\n+                  + \", with offset \u003d\" + offset\n+                  + \"; buffer capacity \u003d\" + (buffer.length - offset));\n+        }\n+        verifyOpen();\n+        if (!hasRemaining()) {\n+          return -1;\n+        }\n+\n+        int toRead \u003d Math.min(length, available());\n+        byteBuffer.get(buffer, offset, toRead);\n+        return toRead;\n+      }\n\\ No newline at end of file\n",
      "actualSource": "      public synchronized int read(byte[] buffer, int offset, int length)\n          throws IOException {\n        Preconditions.checkArgument(length \u003e\u003d 0, \"length is negative\");\n        Preconditions.checkArgument(buffer !\u003d null, \"Null buffer\");\n        if (buffer.length - offset \u003c length) {\n          throw new IndexOutOfBoundsException(\n              FSExceptionMessages.TOO_MANY_BYTES_FOR_DEST_BUFFER\n                  + \": request length \u003d\" + length\n                  + \", with offset \u003d\" + offset\n                  + \"; buffer capacity \u003d\" + (buffer.length - offset));\n        }\n        verifyOpen();\n        if (!hasRemaining()) {\n          return -1;\n        }\n\n        int toRead \u003d Math.min(length, available());\n        byteBuffer.get(buffer, offset, toRead);\n        return toRead;\n      }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java"
    }
  }
}