{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CacheManager.java",
  "functionName": "setCachedLocations",
  "functionId": "setCachedLocations___locations-LocatedBlocks",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
  "functionStartLine": 930,
  "functionEndLine": 937,
  "numCommitsSeen": 107,
  "timeTaken": 4196,
  "changeHistory": [
    "744208431f7365bf054e6b773b86af2583001e1d",
    "afe9ea3c12e1f5a71922400eadb642960bc87ca1",
    "d85c017d0488930d806f267141057fc73e68c728",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
    "3fc8792b5c75fca9fc4f6cf4b95fb2927c62e624"
  ],
  "changeHistoryShort": {
    "744208431f7365bf054e6b773b86af2583001e1d": "Ymultichange(Yparameterchange,Ybodychange)",
    "afe9ea3c12e1f5a71922400eadb642960bc87ca1": "Ybodychange",
    "d85c017d0488930d806f267141057fc73e68c728": "Ybodychange",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": "Ymultichange(Ymovefromfile,Ybodychange)",
    "3fc8792b5c75fca9fc4f6cf4b95fb2927c62e624": "Yintroduced"
  },
  "changeHistoryDetails": {
    "744208431f7365bf054e6b773b86af2583001e1d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-10940. Reduce performance penalty of block caching when not used. Contributed by Daryn Sharp.\n",
      "commitDate": "03/10/16 9:27 AM",
      "commitName": "744208431f7365bf054e6b773b86af2583001e1d",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-10940. Reduce performance penalty of block caching when not used. Contributed by Daryn Sharp.\n",
          "commitDate": "03/10/16 9:27 AM",
          "commitName": "744208431f7365bf054e6b773b86af2583001e1d",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "20/06/16 6:25 PM",
          "commitNameOld": "46f1602e896273b308fbd5df6c75f6c142828227",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 104.63,
          "commitsBetweenForRepo": 799,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,30 +1,8 @@\n-  public void setCachedLocations(LocatedBlock block) {\n-    CachedBlock cachedBlock \u003d\n-        new CachedBlock(block.getBlock().getBlockId(),\n-            (short)0, false);\n-    cachedBlock \u003d cachedBlocks.get(cachedBlock);\n-    if (cachedBlock \u003d\u003d null) {\n-      return;\n-    }\n-    List\u003cDatanodeDescriptor\u003e cachedDNs \u003d cachedBlock.getDatanodes(Type.CACHED);\n-    for (DatanodeDescriptor datanode : cachedDNs) {\n-      // Filter out cached blocks that do not have a backing replica.\n-      //\n-      // This should not happen since it means the CacheManager thinks\n-      // something is cached that does not exist, but it\u0027s a safety\n-      // measure.\n-      boolean found \u003d false;\n-      for (DatanodeInfo loc : block.getLocations()) {\n-        if (loc.equals(datanode)) {\n-          block.addCachedLoc(loc);\n-          found \u003d true;\n-          break;\n-        }\n-      }\n-      if (!found) {\n-        LOG.warn(\"Datanode {} is not a valid cache location for block {} \"\n-            + \"because that node does not have a backing replica!\",\n-            datanode, block.getBlock().getBlockName());\n+  public void setCachedLocations(LocatedBlocks locations) {\n+    // don\u0027t attempt lookups if there are no cached blocks\n+    if (cachedBlocks.size() \u003e 0) {\n+      for (LocatedBlock lb : locations.getLocatedBlocks()) {\n+        setCachedLocations(lb);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void setCachedLocations(LocatedBlocks locations) {\n    // don\u0027t attempt lookups if there are no cached blocks\n    if (cachedBlocks.size() \u003e 0) {\n      for (LocatedBlock lb : locations.getLocatedBlocks()) {\n        setCachedLocations(lb);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "[block-LocatedBlock]",
            "newValue": "[locations-LocatedBlocks]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10940. Reduce performance penalty of block caching when not used. Contributed by Daryn Sharp.\n",
          "commitDate": "03/10/16 9:27 AM",
          "commitName": "744208431f7365bf054e6b773b86af2583001e1d",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "20/06/16 6:25 PM",
          "commitNameOld": "46f1602e896273b308fbd5df6c75f6c142828227",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 104.63,
          "commitsBetweenForRepo": 799,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,30 +1,8 @@\n-  public void setCachedLocations(LocatedBlock block) {\n-    CachedBlock cachedBlock \u003d\n-        new CachedBlock(block.getBlock().getBlockId(),\n-            (short)0, false);\n-    cachedBlock \u003d cachedBlocks.get(cachedBlock);\n-    if (cachedBlock \u003d\u003d null) {\n-      return;\n-    }\n-    List\u003cDatanodeDescriptor\u003e cachedDNs \u003d cachedBlock.getDatanodes(Type.CACHED);\n-    for (DatanodeDescriptor datanode : cachedDNs) {\n-      // Filter out cached blocks that do not have a backing replica.\n-      //\n-      // This should not happen since it means the CacheManager thinks\n-      // something is cached that does not exist, but it\u0027s a safety\n-      // measure.\n-      boolean found \u003d false;\n-      for (DatanodeInfo loc : block.getLocations()) {\n-        if (loc.equals(datanode)) {\n-          block.addCachedLoc(loc);\n-          found \u003d true;\n-          break;\n-        }\n-      }\n-      if (!found) {\n-        LOG.warn(\"Datanode {} is not a valid cache location for block {} \"\n-            + \"because that node does not have a backing replica!\",\n-            datanode, block.getBlock().getBlockName());\n+  public void setCachedLocations(LocatedBlocks locations) {\n+    // don\u0027t attempt lookups if there are no cached blocks\n+    if (cachedBlocks.size() \u003e 0) {\n+      for (LocatedBlock lb : locations.getLocatedBlocks()) {\n+        setCachedLocations(lb);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void setCachedLocations(LocatedBlocks locations) {\n    // don\u0027t attempt lookups if there are no cached blocks\n    if (cachedBlocks.size() \u003e 0) {\n      for (LocatedBlock lb : locations.getLocatedBlocks()) {\n        setCachedLocations(lb);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "afe9ea3c12e1f5a71922400eadb642960bc87ca1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8646. Prune cached replicas from DatanodeDescriptor state on replica invalidation.\n",
      "commitDate": "24/06/15 2:42 PM",
      "commitName": "afe9ea3c12e1f5a71922400eadb642960bc87ca1",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "03/07/14 10:13 AM",
      "commitNameOld": "93e23a99157c30b51752fc49748c3c210745a187",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 356.19,
      "commitsBetweenForRepo": 3097,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,30 @@\n   public void setCachedLocations(LocatedBlock block) {\n     CachedBlock cachedBlock \u003d\n         new CachedBlock(block.getBlock().getBlockId(),\n             (short)0, false);\n     cachedBlock \u003d cachedBlocks.get(cachedBlock);\n     if (cachedBlock \u003d\u003d null) {\n       return;\n     }\n-    List\u003cDatanodeDescriptor\u003e datanodes \u003d cachedBlock.getDatanodes(Type.CACHED);\n-    for (DatanodeDescriptor datanode : datanodes) {\n-      block.addCachedLoc(datanode);\n+    List\u003cDatanodeDescriptor\u003e cachedDNs \u003d cachedBlock.getDatanodes(Type.CACHED);\n+    for (DatanodeDescriptor datanode : cachedDNs) {\n+      // Filter out cached blocks that do not have a backing replica.\n+      //\n+      // This should not happen since it means the CacheManager thinks\n+      // something is cached that does not exist, but it\u0027s a safety\n+      // measure.\n+      boolean found \u003d false;\n+      for (DatanodeInfo loc : block.getLocations()) {\n+        if (loc.equals(datanode)) {\n+          block.addCachedLoc(loc);\n+          found \u003d true;\n+          break;\n+        }\n+      }\n+      if (!found) {\n+        LOG.warn(\"Datanode {} is not a valid cache location for block {} \"\n+            + \"because that node does not have a backing replica!\",\n+            datanode, block.getBlock().getBlockName());\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void setCachedLocations(LocatedBlock block) {\n    CachedBlock cachedBlock \u003d\n        new CachedBlock(block.getBlock().getBlockId(),\n            (short)0, false);\n    cachedBlock \u003d cachedBlocks.get(cachedBlock);\n    if (cachedBlock \u003d\u003d null) {\n      return;\n    }\n    List\u003cDatanodeDescriptor\u003e cachedDNs \u003d cachedBlock.getDatanodes(Type.CACHED);\n    for (DatanodeDescriptor datanode : cachedDNs) {\n      // Filter out cached blocks that do not have a backing replica.\n      //\n      // This should not happen since it means the CacheManager thinks\n      // something is cached that does not exist, but it\u0027s a safety\n      // measure.\n      boolean found \u003d false;\n      for (DatanodeInfo loc : block.getLocations()) {\n        if (loc.equals(datanode)) {\n          block.addCachedLoc(loc);\n          found \u003d true;\n          break;\n        }\n      }\n      if (!found) {\n        LOG.warn(\"Datanode {} is not a valid cache location for block {} \"\n            + \"because that node does not have a backing replica!\",\n            datanode, block.getBlock().getBlockName());\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "d85c017d0488930d806f267141057fc73e68c728": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5651. Remove dfs.namenode.caching.enabled and improve CRM locking. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1555002 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/01/14 6:45 PM",
      "commitName": "d85c017d0488930d806f267141057fc73e68c728",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "31/12/13 4:01 PM",
      "commitNameOld": "07e4fb1455abc33584fc666ef745abe256ebd7d1",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 2.11,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,13 @@\n   public void setCachedLocations(LocatedBlock block) {\n-    if (!enabled) {\n-      return;\n-    }\n     CachedBlock cachedBlock \u003d\n         new CachedBlock(block.getBlock().getBlockId(),\n             (short)0, false);\n     cachedBlock \u003d cachedBlocks.get(cachedBlock);\n     if (cachedBlock \u003d\u003d null) {\n       return;\n     }\n     List\u003cDatanodeDescriptor\u003e datanodes \u003d cachedBlock.getDatanodes(Type.CACHED);\n     for (DatanodeDescriptor datanode : datanodes) {\n       block.addCachedLoc(datanode);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void setCachedLocations(LocatedBlock block) {\n    CachedBlock cachedBlock \u003d\n        new CachedBlock(block.getBlock().getBlockId(),\n            (short)0, false);\n    cachedBlock \u003d cachedBlocks.get(cachedBlock);\n    if (cachedBlock \u003d\u003d null) {\n      return;\n    }\n    List\u003cDatanodeDescriptor\u003e datanodes \u003d cachedBlock.getDatanodes(Type.CACHED);\n    for (DatanodeDescriptor datanode : datanodes) {\n      block.addCachedLoc(datanode);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 3:15 PM",
      "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "16/10/13 3:15 PM",
          "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "16/10/13 1:23 PM",
          "commitNameOld": "8da82eba1c84f828617a13a6f785a9b6cfc057a5",
          "commitAuthorOld": "Chris Nauroth",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,16 @@\n   public void setCachedLocations(LocatedBlock block) {\n-    BlockInfo blockInfo \u003d cachedBlocksMap.getStoredBlock(\n-        block.getBlock().getLocalBlock());\n-    for (int i\u003d0; i\u003cblockInfo.numNodes(); i++) {\n-      block.addCachedLoc(blockInfo.getDatanode(i));\n+    if (!enabled) {\n+      return;\n+    }\n+    CachedBlock cachedBlock \u003d\n+        new CachedBlock(block.getBlock().getBlockId(),\n+            (short)0, false);\n+    cachedBlock \u003d cachedBlocks.get(cachedBlock);\n+    if (cachedBlock \u003d\u003d null) {\n+      return;\n+    }\n+    List\u003cDatanodeDescriptor\u003e datanodes \u003d cachedBlock.getDatanodes(Type.CACHED);\n+    for (DatanodeDescriptor datanode : datanodes) {\n+      block.addCachedLoc(datanode);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void setCachedLocations(LocatedBlock block) {\n    if (!enabled) {\n      return;\n    }\n    CachedBlock cachedBlock \u003d\n        new CachedBlock(block.getBlock().getBlockId(),\n            (short)0, false);\n    cachedBlock \u003d cachedBlocks.get(cachedBlock);\n    if (cachedBlock \u003d\u003d null) {\n      return;\n    }\n    List\u003cDatanodeDescriptor\u003e datanodes \u003d cachedBlock.getDatanodes(Type.CACHED);\n    for (DatanodeDescriptor datanode : datanodes) {\n      block.addCachedLoc(datanode);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationManager.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
            "oldMethodName": "setCachedLocations",
            "newMethodName": "setCachedLocations"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "16/10/13 3:15 PM",
          "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "16/10/13 1:23 PM",
          "commitNameOld": "8da82eba1c84f828617a13a6f785a9b6cfc057a5",
          "commitAuthorOld": "Chris Nauroth",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,16 @@\n   public void setCachedLocations(LocatedBlock block) {\n-    BlockInfo blockInfo \u003d cachedBlocksMap.getStoredBlock(\n-        block.getBlock().getLocalBlock());\n-    for (int i\u003d0; i\u003cblockInfo.numNodes(); i++) {\n-      block.addCachedLoc(blockInfo.getDatanode(i));\n+    if (!enabled) {\n+      return;\n+    }\n+    CachedBlock cachedBlock \u003d\n+        new CachedBlock(block.getBlock().getBlockId(),\n+            (short)0, false);\n+    cachedBlock \u003d cachedBlocks.get(cachedBlock);\n+    if (cachedBlock \u003d\u003d null) {\n+      return;\n+    }\n+    List\u003cDatanodeDescriptor\u003e datanodes \u003d cachedBlock.getDatanodes(Type.CACHED);\n+    for (DatanodeDescriptor datanode : datanodes) {\n+      block.addCachedLoc(datanode);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void setCachedLocations(LocatedBlock block) {\n    if (!enabled) {\n      return;\n    }\n    CachedBlock cachedBlock \u003d\n        new CachedBlock(block.getBlock().getBlockId(),\n            (short)0, false);\n    cachedBlock \u003d cachedBlocks.get(cachedBlock);\n    if (cachedBlock \u003d\u003d null) {\n      return;\n    }\n    List\u003cDatanodeDescriptor\u003e datanodes \u003d cachedBlock.getDatanodes(Type.CACHED);\n    for (DatanodeDescriptor datanode : datanodes) {\n      block.addCachedLoc(datanode);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "3fc8792b5c75fca9fc4f6cf4b95fb2927c62e624": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5304. Expose if a block replica is cached in getFileBlockLocations. (Contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1530802 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/10/13 2:30 PM",
      "commitName": "3fc8792b5c75fca9fc4f6cf4b95fb2927c62e624",
      "commitAuthor": "Andrew Wang",
      "diff": "@@ -0,0 +1,7 @@\n+  public void setCachedLocations(LocatedBlock block) {\n+    BlockInfo blockInfo \u003d cachedBlocksMap.getStoredBlock(\n+        block.getBlock().getLocalBlock());\n+    for (int i\u003d0; i\u003cblockInfo.numNodes(); i++) {\n+      block.addCachedLoc(blockInfo.getDatanode(i));\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void setCachedLocations(LocatedBlock block) {\n    BlockInfo blockInfo \u003d cachedBlocksMap.getStoredBlock(\n        block.getBlock().getLocalBlock());\n    for (int i\u003d0; i\u003cblockInfo.numNodes(); i++) {\n      block.addCachedLoc(blockInfo.getDatanode(i));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationManager.java"
    }
  }
}