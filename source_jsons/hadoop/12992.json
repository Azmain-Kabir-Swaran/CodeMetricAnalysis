{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeDescriptor.java",
  "functionName": "addBlockToBeReplicated",
  "functionId": "addBlockToBeReplicated___block-Block__targets-DatanodeStorageInfo[]",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
  "functionStartLine": 651,
  "functionEndLine": 655,
  "numCommitsSeen": 118,
  "timeTaken": 2439,
  "changeHistory": [
    "447f46d9628db54e77f88e2d109587cc7dfd6154"
  ],
  "changeHistoryShort": {
    "447f46d9628db54e77f88e2d109587cc7dfd6154": "Ymodifierchange"
  },
  "changeHistoryDetails": {
    "447f46d9628db54e77f88e2d109587cc7dfd6154": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-14847. Erasure Coding: Blocks are over-replicated while EC decommissioning. Contributed by Fei Hui.\n",
      "commitDate": "19/10/19 5:40 PM",
      "commitName": "447f46d9628db54e77f88e2d109587cc7dfd6154",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "12/09/19 7:13 AM",
      "commitNameOld": "2ff2a7f6120079b6a88afff987a551fa3d1f47e2",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 37.44,
      "commitsBetweenForRepo": 286,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,5 @@\n-  void addBlockToBeReplicated(Block block, DatanodeStorageInfo[] targets) {\n+  public void addBlockToBeReplicated(Block block,\n+      DatanodeStorageInfo[] targets) {\n     assert(block !\u003d null \u0026\u0026 targets !\u003d null \u0026\u0026 targets.length \u003e 0);\n     replicateBlocks.offer(new BlockTargetPair(block, targets));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void addBlockToBeReplicated(Block block,\n      DatanodeStorageInfo[] targets) {\n    assert(block !\u003d null \u0026\u0026 targets !\u003d null \u0026\u0026 targets.length \u003e 0);\n    replicateBlocks.offer(new BlockTargetPair(block, targets));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[public]"
      }
    }
  }
}