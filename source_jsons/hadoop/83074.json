{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "GraphiteSink.java",
  "functionName": "putMetrics",
  "functionId": "putMetrics___record-MetricsRecord",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java",
  "functionStartLine": 69,
  "functionEndLine": 108,
  "numCommitsSeen": 10,
  "timeTaken": 1579,
  "changeHistory": [
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd",
    "4d2914210053f28c95094aa59e48f8e84c55a2c7",
    "466f08792f11c2f95bf293ac9b6facd7018a5bb8",
    "1adec79c7bcdb53128cffc6a3c289fa6e86a53b1",
    "ad5d0d716771955a5663adbffa5c3f38cc53c84e"
  ],
  "changeHistoryShort": {
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd": "Ybodychange",
    "4d2914210053f28c95094aa59e48f8e84c55a2c7": "Ybodychange",
    "466f08792f11c2f95bf293ac9b6facd7018a5bb8": "Ybodychange",
    "1adec79c7bcdb53128cffc6a3c289fa6e86a53b1": "Ybodychange",
    "ad5d0d716771955a5663adbffa5c3f38cc53c84e": "Yintroduced"
  },
  "changeHistoryDetails": {
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16029. Consecutive StringBuilder.append can be reused. Contributed by Ayush Saxena.\n",
      "commitDate": "11/01/19 10:54 AM",
      "commitName": "fb8932a727f757b2e9c1c61a18145878d0eb77bd",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "17/07/17 9:32 PM",
      "commitNameOld": "ccaf036662e22da14583942054898c99fa51dae5",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 542.6,
      "commitsBetweenForRepo": 4698,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,40 @@\n     public void putMetrics(MetricsRecord record) {\n         StringBuilder lines \u003d new StringBuilder();\n         StringBuilder metricsPathPrefix \u003d new StringBuilder();\n \n         // Configure the hierarchical place to display the graph.\n         metricsPathPrefix.append(metricsPrefix).append(\".\")\n                 .append(record.context()).append(\".\").append(record.name());\n \n         for (MetricsTag tag : record.tags()) {\n             if (tag.value() !\u003d null) {\n-                metricsPathPrefix.append(\".\");\n-                metricsPathPrefix.append(tag.name());\n-                metricsPathPrefix.append(\"\u003d\");\n-                metricsPathPrefix.append(tag.value());\n+                metricsPathPrefix.append(\".\")\n+                    .append(tag.name())\n+                    .append(\"\u003d\")\n+                    .append(tag.value());\n             }\n         }\n \n         // The record timestamp is in milliseconds while Graphite expects an epoc time in seconds.\n         long timestamp \u003d record.timestamp() / 1000L;\n \n         // Collect datapoints.\n         for (AbstractMetric metric : record.metrics()) {\n             lines.append(\n                     metricsPathPrefix.toString() + \".\"\n                             + metric.name().replace(\u0027 \u0027, \u0027.\u0027)).append(\" \")\n                     .append(metric.value()).append(\" \").append(timestamp)\n                     .append(\"\\n\");\n         }\n \n         try {\n           graphite.write(lines.toString());\n         } catch (Exception e) {\n           LOG.warn(\"Error sending metrics to Graphite\", e);\n           try {\n             graphite.close();\n           } catch (Exception e1) {\n             throw new MetricsException(\"Error closing connection to Graphite\", e1);\n           }\n         }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void putMetrics(MetricsRecord record) {\n        StringBuilder lines \u003d new StringBuilder();\n        StringBuilder metricsPathPrefix \u003d new StringBuilder();\n\n        // Configure the hierarchical place to display the graph.\n        metricsPathPrefix.append(metricsPrefix).append(\".\")\n                .append(record.context()).append(\".\").append(record.name());\n\n        for (MetricsTag tag : record.tags()) {\n            if (tag.value() !\u003d null) {\n                metricsPathPrefix.append(\".\")\n                    .append(tag.name())\n                    .append(\"\u003d\")\n                    .append(tag.value());\n            }\n        }\n\n        // The record timestamp is in milliseconds while Graphite expects an epoc time in seconds.\n        long timestamp \u003d record.timestamp() / 1000L;\n\n        // Collect datapoints.\n        for (AbstractMetric metric : record.metrics()) {\n            lines.append(\n                    metricsPathPrefix.toString() + \".\"\n                            + metric.name().replace(\u0027 \u0027, \u0027.\u0027)).append(\" \")\n                    .append(metric.value()).append(\" \").append(timestamp)\n                    .append(\"\\n\");\n        }\n\n        try {\n          graphite.write(lines.toString());\n        } catch (Exception e) {\n          LOG.warn(\"Error sending metrics to Graphite\", e);\n          try {\n            graphite.close();\n          } catch (Exception e1) {\n            throw new MetricsException(\"Error closing connection to Graphite\", e1);\n          }\n        }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java",
      "extendedDetails": {}
    },
    "4d2914210053f28c95094aa59e48f8e84c55a2c7": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11400. GraphiteSink does not reconnect to Graphite after \u0027broken pipe\u0027\n(Kamil Gorlo via raviprak)\n",
      "commitDate": "10/01/15 8:35 AM",
      "commitName": "4d2914210053f28c95094aa59e48f8e84c55a2c7",
      "commitAuthor": "Ravi Prakash",
      "commitDateOld": "11/12/14 4:42 PM",
      "commitNameOld": "5b9fcedb4d116d91d70aaad6cbf59093eeee36df",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 29.66,
      "commitsBetweenForRepo": 146,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,40 @@\n     public void putMetrics(MetricsRecord record) {\n         StringBuilder lines \u003d new StringBuilder();\n         StringBuilder metricsPathPrefix \u003d new StringBuilder();\n \n         // Configure the hierarchical place to display the graph.\n         metricsPathPrefix.append(metricsPrefix).append(\".\")\n                 .append(record.context()).append(\".\").append(record.name());\n \n         for (MetricsTag tag : record.tags()) {\n             if (tag.value() !\u003d null) {\n                 metricsPathPrefix.append(\".\");\n                 metricsPathPrefix.append(tag.name());\n                 metricsPathPrefix.append(\"\u003d\");\n                 metricsPathPrefix.append(tag.value());\n             }\n         }\n \n         // The record timestamp is in milliseconds while Graphite expects an epoc time in seconds.\n         long timestamp \u003d record.timestamp() / 1000L;\n \n         // Collect datapoints.\n         for (AbstractMetric metric : record.metrics()) {\n             lines.append(\n                     metricsPathPrefix.toString() + \".\"\n                             + metric.name().replace(\u0027 \u0027, \u0027.\u0027)).append(\" \")\n                     .append(metric.value()).append(\" \").append(timestamp)\n                     .append(\"\\n\");\n         }\n \n         try {\n-            if(writer !\u003d null){\n-              writer.write(lines.toString());\n-            } else {\n-              throw new MetricsException(\"Writer in GraphiteSink is null!\");\n-            }\n+          graphite.write(lines.toString());\n         } catch (Exception e) {\n-            throw new MetricsException(\"Error sending metrics\", e);\n+          LOG.warn(\"Error sending metrics to Graphite\", e);\n+          try {\n+            graphite.close();\n+          } catch (Exception e1) {\n+            throw new MetricsException(\"Error closing connection to Graphite\", e1);\n+          }\n         }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void putMetrics(MetricsRecord record) {\n        StringBuilder lines \u003d new StringBuilder();\n        StringBuilder metricsPathPrefix \u003d new StringBuilder();\n\n        // Configure the hierarchical place to display the graph.\n        metricsPathPrefix.append(metricsPrefix).append(\".\")\n                .append(record.context()).append(\".\").append(record.name());\n\n        for (MetricsTag tag : record.tags()) {\n            if (tag.value() !\u003d null) {\n                metricsPathPrefix.append(\".\");\n                metricsPathPrefix.append(tag.name());\n                metricsPathPrefix.append(\"\u003d\");\n                metricsPathPrefix.append(tag.value());\n            }\n        }\n\n        // The record timestamp is in milliseconds while Graphite expects an epoc time in seconds.\n        long timestamp \u003d record.timestamp() / 1000L;\n\n        // Collect datapoints.\n        for (AbstractMetric metric : record.metrics()) {\n            lines.append(\n                    metricsPathPrefix.toString() + \".\"\n                            + metric.name().replace(\u0027 \u0027, \u0027.\u0027)).append(\" \")\n                    .append(metric.value()).append(\" \").append(timestamp)\n                    .append(\"\\n\");\n        }\n\n        try {\n          graphite.write(lines.toString());\n        } catch (Exception e) {\n          LOG.warn(\"Error sending metrics to Graphite\", e);\n          try {\n            graphite.close();\n          } catch (Exception e1) {\n            throw new MetricsException(\"Error closing connection to Graphite\", e1);\n          }\n        }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java",
      "extendedDetails": {}
    },
    "466f08792f11c2f95bf293ac9b6facd7018a5bb8": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11181. GraphiteSink emits wrong timestamps (Sascha Coenen via raviprak)\n",
      "commitDate": "15/10/14 3:49 PM",
      "commitName": "466f08792f11c2f95bf293ac9b6facd7018a5bb8",
      "commitAuthor": "Ravi Prakash",
      "commitDateOld": "25/06/14 6:50 PM",
      "commitNameOld": "7fcaab2350405dc3bfb1ca941482416711b52cb4",
      "commitAuthorOld": "Ravi Prakash",
      "daysBetweenCommits": 111.87,
      "commitsBetweenForRepo": 1052,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,39 @@\n     public void putMetrics(MetricsRecord record) {\n         StringBuilder lines \u003d new StringBuilder();\n         StringBuilder metricsPathPrefix \u003d new StringBuilder();\n \n         // Configure the hierarchical place to display the graph.\n         metricsPathPrefix.append(metricsPrefix).append(\".\")\n                 .append(record.context()).append(\".\").append(record.name());\n \n         for (MetricsTag tag : record.tags()) {\n             if (tag.value() !\u003d null) {\n                 metricsPathPrefix.append(\".\");\n                 metricsPathPrefix.append(tag.name());\n                 metricsPathPrefix.append(\"\u003d\");\n                 metricsPathPrefix.append(tag.value());\n             }\n         }\n \n-        // Round the timestamp to second as Graphite accepts it in such format.\n-        int timestamp \u003d Math.round(record.timestamp() / 1000.0f);\n+        // The record timestamp is in milliseconds while Graphite expects an epoc time in seconds.\n+        long timestamp \u003d record.timestamp() / 1000L;\n \n         // Collect datapoints.\n         for (AbstractMetric metric : record.metrics()) {\n             lines.append(\n                     metricsPathPrefix.toString() + \".\"\n                             + metric.name().replace(\u0027 \u0027, \u0027.\u0027)).append(\" \")\n                     .append(metric.value()).append(\" \").append(timestamp)\n                     .append(\"\\n\");\n         }\n \n         try {\n             if(writer !\u003d null){\n               writer.write(lines.toString());\n             } else {\n               throw new MetricsException(\"Writer in GraphiteSink is null!\");\n             }\n         } catch (Exception e) {\n             throw new MetricsException(\"Error sending metrics\", e);\n         }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void putMetrics(MetricsRecord record) {\n        StringBuilder lines \u003d new StringBuilder();\n        StringBuilder metricsPathPrefix \u003d new StringBuilder();\n\n        // Configure the hierarchical place to display the graph.\n        metricsPathPrefix.append(metricsPrefix).append(\".\")\n                .append(record.context()).append(\".\").append(record.name());\n\n        for (MetricsTag tag : record.tags()) {\n            if (tag.value() !\u003d null) {\n                metricsPathPrefix.append(\".\");\n                metricsPathPrefix.append(tag.name());\n                metricsPathPrefix.append(\"\u003d\");\n                metricsPathPrefix.append(tag.value());\n            }\n        }\n\n        // The record timestamp is in milliseconds while Graphite expects an epoc time in seconds.\n        long timestamp \u003d record.timestamp() / 1000L;\n\n        // Collect datapoints.\n        for (AbstractMetric metric : record.metrics()) {\n            lines.append(\n                    metricsPathPrefix.toString() + \".\"\n                            + metric.name().replace(\u0027 \u0027, \u0027.\u0027)).append(\" \")\n                    .append(metric.value()).append(\" \").append(timestamp)\n                    .append(\"\\n\");\n        }\n\n        try {\n            if(writer !\u003d null){\n              writer.write(lines.toString());\n            } else {\n              throw new MetricsException(\"Writer in GraphiteSink is null!\");\n            }\n        } catch (Exception e) {\n            throw new MetricsException(\"Error sending metrics\", e);\n        }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java",
      "extendedDetails": {}
    },
    "1adec79c7bcdb53128cffc6a3c289fa6e86a53b1": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10660. GraphiteSink should implement Closeable (Chen He and Ted Yu via raviprak)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603379 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/06/14 2:27 AM",
      "commitName": "1adec79c7bcdb53128cffc6a3c289fa6e86a53b1",
      "commitAuthor": "Ravi Prakash",
      "commitDateOld": "02/06/14 10:42 PM",
      "commitNameOld": "ad5d0d716771955a5663adbffa5c3f38cc53c84e",
      "commitAuthorOld": "Ravi Prakash",
      "daysBetweenCommits": 15.16,
      "commitsBetweenForRepo": 86,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,39 @@\n     public void putMetrics(MetricsRecord record) {\n         StringBuilder lines \u003d new StringBuilder();\n         StringBuilder metricsPathPrefix \u003d new StringBuilder();\n \n         // Configure the hierarchical place to display the graph.\n         metricsPathPrefix.append(metricsPrefix).append(\".\")\n                 .append(record.context()).append(\".\").append(record.name());\n \n         for (MetricsTag tag : record.tags()) {\n             if (tag.value() !\u003d null) {\n                 metricsPathPrefix.append(\".\");\n                 metricsPathPrefix.append(tag.name());\n                 metricsPathPrefix.append(\"\u003d\");\n                 metricsPathPrefix.append(tag.value());\n             }\n         }\n \n         // Round the timestamp to second as Graphite accepts it in such format.\n         int timestamp \u003d Math.round(record.timestamp() / 1000.0f);\n \n         // Collect datapoints.\n         for (AbstractMetric metric : record.metrics()) {\n             lines.append(\n                     metricsPathPrefix.toString() + \".\"\n                             + metric.name().replace(\u0027 \u0027, \u0027.\u0027)).append(\" \")\n                     .append(metric.value()).append(\" \").append(timestamp)\n                     .append(\"\\n\");\n         }\n \n         try {\n-            writer.write(lines.toString());\n+            if(writer !\u003d null){\n+              writer.write(lines.toString());\n+            } else {\n+              throw new MetricsException(\"Writer in GraphiteSink is null!\");\n+            }\n         } catch (Exception e) {\n             throw new MetricsException(\"Error sending metrics\", e);\n         }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void putMetrics(MetricsRecord record) {\n        StringBuilder lines \u003d new StringBuilder();\n        StringBuilder metricsPathPrefix \u003d new StringBuilder();\n\n        // Configure the hierarchical place to display the graph.\n        metricsPathPrefix.append(metricsPrefix).append(\".\")\n                .append(record.context()).append(\".\").append(record.name());\n\n        for (MetricsTag tag : record.tags()) {\n            if (tag.value() !\u003d null) {\n                metricsPathPrefix.append(\".\");\n                metricsPathPrefix.append(tag.name());\n                metricsPathPrefix.append(\"\u003d\");\n                metricsPathPrefix.append(tag.value());\n            }\n        }\n\n        // Round the timestamp to second as Graphite accepts it in such format.\n        int timestamp \u003d Math.round(record.timestamp() / 1000.0f);\n\n        // Collect datapoints.\n        for (AbstractMetric metric : record.metrics()) {\n            lines.append(\n                    metricsPathPrefix.toString() + \".\"\n                            + metric.name().replace(\u0027 \u0027, \u0027.\u0027)).append(\" \")\n                    .append(metric.value()).append(\" \").append(timestamp)\n                    .append(\"\\n\");\n        }\n\n        try {\n            if(writer !\u003d null){\n              writer.write(lines.toString());\n            } else {\n              throw new MetricsException(\"Writer in GraphiteSink is null!\");\n            }\n        } catch (Exception e) {\n            throw new MetricsException(\"Error sending metrics\", e);\n        }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java",
      "extendedDetails": {}
    },
    "ad5d0d716771955a5663adbffa5c3f38cc53c84e": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP 9704. Write metrics sink plugin for Hadoop/Graphite (Chu Tong, Alex Newman and Babak Behzad via raviprak)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1599413 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/06/14 10:42 PM",
      "commitName": "ad5d0d716771955a5663adbffa5c3f38cc53c84e",
      "commitAuthor": "Ravi Prakash",
      "diff": "@@ -0,0 +1,35 @@\n+    public void putMetrics(MetricsRecord record) {\n+        StringBuilder lines \u003d new StringBuilder();\n+        StringBuilder metricsPathPrefix \u003d new StringBuilder();\n+\n+        // Configure the hierarchical place to display the graph.\n+        metricsPathPrefix.append(metricsPrefix).append(\".\")\n+                .append(record.context()).append(\".\").append(record.name());\n+\n+        for (MetricsTag tag : record.tags()) {\n+            if (tag.value() !\u003d null) {\n+                metricsPathPrefix.append(\".\");\n+                metricsPathPrefix.append(tag.name());\n+                metricsPathPrefix.append(\"\u003d\");\n+                metricsPathPrefix.append(tag.value());\n+            }\n+        }\n+\n+        // Round the timestamp to second as Graphite accepts it in such format.\n+        int timestamp \u003d Math.round(record.timestamp() / 1000.0f);\n+\n+        // Collect datapoints.\n+        for (AbstractMetric metric : record.metrics()) {\n+            lines.append(\n+                    metricsPathPrefix.toString() + \".\"\n+                            + metric.name().replace(\u0027 \u0027, \u0027.\u0027)).append(\" \")\n+                    .append(metric.value()).append(\" \").append(timestamp)\n+                    .append(\"\\n\");\n+        }\n+\n+        try {\n+            writer.write(lines.toString());\n+        } catch (Exception e) {\n+            throw new MetricsException(\"Error sending metrics\", e);\n+        }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public void putMetrics(MetricsRecord record) {\n        StringBuilder lines \u003d new StringBuilder();\n        StringBuilder metricsPathPrefix \u003d new StringBuilder();\n\n        // Configure the hierarchical place to display the graph.\n        metricsPathPrefix.append(metricsPrefix).append(\".\")\n                .append(record.context()).append(\".\").append(record.name());\n\n        for (MetricsTag tag : record.tags()) {\n            if (tag.value() !\u003d null) {\n                metricsPathPrefix.append(\".\");\n                metricsPathPrefix.append(tag.name());\n                metricsPathPrefix.append(\"\u003d\");\n                metricsPathPrefix.append(tag.value());\n            }\n        }\n\n        // Round the timestamp to second as Graphite accepts it in such format.\n        int timestamp \u003d Math.round(record.timestamp() / 1000.0f);\n\n        // Collect datapoints.\n        for (AbstractMetric metric : record.metrics()) {\n            lines.append(\n                    metricsPathPrefix.toString() + \".\"\n                            + metric.name().replace(\u0027 \u0027, \u0027.\u0027)).append(\" \")\n                    .append(metric.value()).append(\" \").append(timestamp)\n                    .append(\"\\n\");\n        }\n\n        try {\n            writer.write(lines.toString());\n        } catch (Exception e) {\n            throw new MetricsException(\"Error sending metrics\", e);\n        }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/GraphiteSink.java"
    }
  }
}