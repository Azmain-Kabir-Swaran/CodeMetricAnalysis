{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSInputStream.java",
  "functionName": "closeCurrentBlockReaders",
  "functionId": "closeCurrentBlockReaders",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
  "functionStartLine": 1767,
  "functionEndLine": 1778,
  "numCommitsSeen": 221,
  "timeTaken": 5042,
  "changeHistory": [
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "bff5999d07e9416a22846c849487e509ede55040",
    "a9dc5cd7069f721e8c55794b877026ba02537167",
    "7caa3bc98e6880f98c5c32c486a0c539f9fd3f5f",
    "c1314eb2a382bd9ce045a2fcc4a9e5c1fc368a24"
  ],
  "changeHistoryShort": {
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "bff5999d07e9416a22846c849487e509ede55040": "Ymultichange(Yrename,Ymodifierchange)",
    "a9dc5cd7069f721e8c55794b877026ba02537167": "Ybodychange",
    "7caa3bc98e6880f98c5c32c486a0c539f9fd3f5f": "Ymodifierchange",
    "c1314eb2a382bd9ce045a2fcc4a9e5c1fc368a24": "Yintroduced"
  },
  "changeHistoryDetails": {
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected void closeCurrentBlockReaders() {\n    if (blockReader \u003d\u003d null) return;\n    // Close the current block reader so that the new caching settings can \n    // take effect immediately.\n    try {\n      blockReader.close();\n    } catch (IOException e) {\n      DFSClient.LOG.error(\"error closing blockReader\", e);\n    }\n    blockReader \u003d null;\n    blockEnd \u003d -1;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
      }
    },
    "bff5999d07e9416a22846c849487e509ede55040": {
      "type": "Ymultichange(Yrename,Ymodifierchange)",
      "commitMessage": "HDFS-8703. Merge refactor of DFSInputStream from ErasureCoding branch (Contributed by Vinayakumar B)\n",
      "commitDate": "02/07/15 3:41 AM",
      "commitName": "bff5999d07e9416a22846c849487e509ede55040",
      "commitAuthor": "Vinayakumar B",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-8703. Merge refactor of DFSInputStream from ErasureCoding branch (Contributed by Vinayakumar B)\n",
          "commitDate": "02/07/15 3:41 AM",
          "commitName": "bff5999d07e9416a22846c849487e509ede55040",
          "commitAuthor": "Vinayakumar B",
          "commitDateOld": "04/06/15 10:51 AM",
          "commitNameOld": "ade6d9a61eb2e57a975f0efcdf8828d51ffec5fd",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 27.7,
          "commitsBetweenForRepo": 196,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,12 @@\n-  private void closeCurrentBlockReader() {\n+  protected void closeCurrentBlockReaders() {\n     if (blockReader \u003d\u003d null) return;\n     // Close the current block reader so that the new caching settings can \n     // take effect immediately.\n     try {\n       blockReader.close();\n     } catch (IOException e) {\n       DFSClient.LOG.error(\"error closing blockReader\", e);\n     }\n     blockReader \u003d null;\n     blockEnd \u003d -1;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void closeCurrentBlockReaders() {\n    if (blockReader \u003d\u003d null) return;\n    // Close the current block reader so that the new caching settings can \n    // take effect immediately.\n    try {\n      blockReader.close();\n    } catch (IOException e) {\n      DFSClient.LOG.error(\"error closing blockReader\", e);\n    }\n    blockReader \u003d null;\n    blockEnd \u003d -1;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
          "extendedDetails": {
            "oldValue": "closeCurrentBlockReader",
            "newValue": "closeCurrentBlockReaders"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-8703. Merge refactor of DFSInputStream from ErasureCoding branch (Contributed by Vinayakumar B)\n",
          "commitDate": "02/07/15 3:41 AM",
          "commitName": "bff5999d07e9416a22846c849487e509ede55040",
          "commitAuthor": "Vinayakumar B",
          "commitDateOld": "04/06/15 10:51 AM",
          "commitNameOld": "ade6d9a61eb2e57a975f0efcdf8828d51ffec5fd",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 27.7,
          "commitsBetweenForRepo": 196,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,12 @@\n-  private void closeCurrentBlockReader() {\n+  protected void closeCurrentBlockReaders() {\n     if (blockReader \u003d\u003d null) return;\n     // Close the current block reader so that the new caching settings can \n     // take effect immediately.\n     try {\n       blockReader.close();\n     } catch (IOException e) {\n       DFSClient.LOG.error(\"error closing blockReader\", e);\n     }\n     blockReader \u003d null;\n     blockEnd \u003d -1;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void closeCurrentBlockReaders() {\n    if (blockReader \u003d\u003d null) return;\n    // Close the current block reader so that the new caching settings can \n    // take effect immediately.\n    try {\n      blockReader.close();\n    } catch (IOException e) {\n      DFSClient.LOG.error(\"error closing blockReader\", e);\n    }\n    blockReader \u003d null;\n    blockEnd \u003d -1;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[protected]"
          }
        }
      ]
    },
    "a9dc5cd7069f721e8c55794b877026ba02537167": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7744. Fix potential NPE in DFSInputStream after setDropBehind or setReadahead is called (cmccabe)\n",
      "commitDate": "09/02/15 8:16 PM",
      "commitName": "a9dc5cd7069f721e8c55794b877026ba02537167",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "05/02/15 7:56 AM",
      "commitNameOld": "45ea53f9388e6bff1ac0aa3989a1dad56a611fd3",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 4.51,
      "commitsBetweenForRepo": 37,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,12 @@\n   private void closeCurrentBlockReader() {\n     if (blockReader \u003d\u003d null) return;\n     // Close the current block reader so that the new caching settings can \n     // take effect immediately.\n     try {\n       blockReader.close();\n     } catch (IOException e) {\n       DFSClient.LOG.error(\"error closing blockReader\", e);\n     }\n     blockReader \u003d null;\n+    blockEnd \u003d -1;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void closeCurrentBlockReader() {\n    if (blockReader \u003d\u003d null) return;\n    // Close the current block reader so that the new caching settings can \n    // take effect immediately.\n    try {\n      blockReader.close();\n    } catch (IOException e) {\n      DFSClient.LOG.error(\"error closing blockReader\", e);\n    }\n    blockReader \u003d null;\n    blockEnd \u003d -1;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "7caa3bc98e6880f98c5c32c486a0c539f9fd3f5f": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-6735. A minor optimization to avoid pread() be blocked by read() inside the same DFSInputStream (Lars Hofhansl via stack)\n",
      "commitDate": "02/12/14 8:57 PM",
      "commitName": "7caa3bc98e6880f98c5c32c486a0c539f9fd3f5f",
      "commitAuthor": "stack",
      "commitDateOld": "05/11/14 9:00 PM",
      "commitNameOld": "80d7d183cd4052d6e6d412ff6588d26471c85d6d",
      "commitAuthorOld": "Milan Desai",
      "daysBetweenCommits": 27.0,
      "commitsBetweenForRepo": 189,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n-  private synchronized void closeCurrentBlockReader() {\n+  private void closeCurrentBlockReader() {\n     if (blockReader \u003d\u003d null) return;\n     // Close the current block reader so that the new caching settings can \n     // take effect immediately.\n     try {\n       blockReader.close();\n     } catch (IOException e) {\n       DFSClient.LOG.error(\"error closing blockReader\", e);\n     }\n     blockReader \u003d null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void closeCurrentBlockReader() {\n    if (blockReader \u003d\u003d null) return;\n    // Close the current block reader so that the new caching settings can \n    // take effect immediately.\n    try {\n      blockReader.close();\n    } catch (IOException e) {\n      DFSClient.LOG.error(\"error closing blockReader\", e);\n    }\n    blockReader \u003d null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {
        "oldValue": "[private, synchronized]",
        "newValue": "[private]"
      }
    },
    "c1314eb2a382bd9ce045a2fcc4a9e5c1fc368a24": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4817.  Make HDFS advisory caching configurable on a per-file basis.  (Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1505753 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/07/13 11:15 AM",
      "commitName": "c1314eb2a382bd9ce045a2fcc4a9e5c1fc368a24",
      "commitAuthor": "Colin McCabe",
      "diff": "@@ -0,0 +1,11 @@\n+  private synchronized void closeCurrentBlockReader() {\n+    if (blockReader \u003d\u003d null) return;\n+    // Close the current block reader so that the new caching settings can \n+    // take effect immediately.\n+    try {\n+      blockReader.close();\n+    } catch (IOException e) {\n+      DFSClient.LOG.error(\"error closing blockReader\", e);\n+    }\n+    blockReader \u003d null;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void closeCurrentBlockReader() {\n    if (blockReader \u003d\u003d null) return;\n    // Close the current block reader so that the new caching settings can \n    // take effect immediately.\n    try {\n      blockReader.close();\n    } catch (IOException e) {\n      DFSClient.LOG.error(\"error closing blockReader\", e);\n    }\n    blockReader \u003d null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
    }
  }
}