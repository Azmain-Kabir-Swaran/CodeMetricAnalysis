{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "QJournalProtocolTranslatorPB.java",
  "functionName": "doPreUpgrade",
  "functionId": "doPreUpgrade___jid-String",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/protocolPB/QJournalProtocolTranslatorPB.java",
  "functionStartLine": 342,
  "functionEndLine": 351,
  "numCommitsSeen": 18,
  "timeTaken": 2286,
  "changeHistory": [
    "8dd1eeb94fef59feaf19182dd8f1fcf1389c7f34",
    "edb6dc5f303093c2604cd07b0c0dacf12dbce5de"
  ],
  "changeHistoryShort": {
    "8dd1eeb94fef59feaf19182dd8f1fcf1389c7f34": "Ybodychange",
    "edb6dc5f303093c2604cd07b0c0dacf12dbce5de": "Yintroduced"
  },
  "changeHistoryDetails": {
    "8dd1eeb94fef59feaf19182dd8f1fcf1389c7f34": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12553. Add nameServiceId to QJournalProtocol. Contributed by Bharat Viswanadham\n",
      "commitDate": "13/10/17 2:22 PM",
      "commitName": "8dd1eeb94fef59feaf19182dd8f1fcf1389c7f34",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "21/09/15 6:53 PM",
      "commitNameOld": "06022b8fdc40e50eaac63758246353058e8cfa6d",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 752.81,
      "commitsBetweenForRepo": 5072,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,10 @@\n   public void doPreUpgrade(String jid) throws IOException {\n     try {\n-      rpcProxy.doPreUpgrade(NULL_CONTROLLER,\n-          DoPreUpgradeRequestProto.newBuilder()\n-            .setJid(convertJournalId(jid))\n-            .build());\n+      DoPreUpgradeRequestProto.Builder req;\n+      req \u003d DoPreUpgradeRequestProto.newBuilder()\n+          .setJid(convertJournalId(jid));\n+      rpcProxy.doPreUpgrade(NULL_CONTROLLER, req.build());\n     } catch (ServiceException e) {\n       throw ProtobufHelper.getRemoteException(e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void doPreUpgrade(String jid) throws IOException {\n    try {\n      DoPreUpgradeRequestProto.Builder req;\n      req \u003d DoPreUpgradeRequestProto.newBuilder()\n          .setJid(convertJournalId(jid));\n      rpcProxy.doPreUpgrade(NULL_CONTROLLER, req.build());\n    } catch (ServiceException e) {\n      throw ProtobufHelper.getRemoteException(e);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/protocolPB/QJournalProtocolTranslatorPB.java",
      "extendedDetails": {}
    },
    "edb6dc5f303093c2604cd07b0c0dacf12dbce5de": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5138. Support HDFS upgrade in HA. Contributed by Aaron T. Myers.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1561381 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/01/14 12:01 PM",
      "commitName": "edb6dc5f303093c2604cd07b0c0dacf12dbce5de",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,10 @@\n+  public void doPreUpgrade(String jid) throws IOException {\n+    try {\n+      rpcProxy.doPreUpgrade(NULL_CONTROLLER,\n+          DoPreUpgradeRequestProto.newBuilder()\n+            .setJid(convertJournalId(jid))\n+            .build());\n+    } catch (ServiceException e) {\n+      throw ProtobufHelper.getRemoteException(e);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void doPreUpgrade(String jid) throws IOException {\n    try {\n      rpcProxy.doPreUpgrade(NULL_CONTROLLER,\n          DoPreUpgradeRequestProto.newBuilder()\n            .setJid(convertJournalId(jid))\n            .build());\n    } catch (ServiceException e) {\n      throw ProtobufHelper.getRemoteException(e);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/protocolPB/QJournalProtocolTranslatorPB.java"
    }
  }
}