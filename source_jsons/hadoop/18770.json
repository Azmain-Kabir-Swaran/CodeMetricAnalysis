{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FrameworkUploader.java",
  "functionName": "collectPackages",
  "functionId": "collectPackages",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-uploader/src/main/java/org/apache/hadoop/mapred/uploader/FrameworkUploader.java",
  "functionStartLine": 141,
  "functionEndLine": 173,
  "numCommitsSeen": 12,
  "timeTaken": 820,
  "changeHistory": [
    "3b78607a02f3a81ad730975ecdfa35967413271d"
  ],
  "changeHistoryShort": {
    "3b78607a02f3a81ad730975ecdfa35967413271d": "Yintroduced"
  },
  "changeHistoryDetails": {
    "3b78607a02f3a81ad730975ecdfa35967413271d": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-6994. Uploader tool for Distributed Cache Deploy code changes  (miklos.szegedi@cloudera.com via rkanter)\n",
      "commitDate": "01/12/17 12:12 PM",
      "commitName": "3b78607a02f3a81ad730975ecdfa35967413271d",
      "commitAuthor": "Robert Kanter",
      "diff": "@@ -0,0 +1,33 @@\n+  void collectPackages() throws UploaderException {\n+    parseLists();\n+    String[] list \u003d StringUtils.split(input, File.pathSeparatorChar);\n+    for (String item : list) {\n+      LOG.info(\"Original source \" + item);\n+      String expanded \u003d expandEnvironmentVariables(item, System.getenv());\n+      LOG.info(\"Expanded source \" + expanded);\n+      if (expanded.endsWith(\"*\")) {\n+        File path \u003d new File(expanded.substring(0, expanded.length() - 1));\n+        if (path.isDirectory()) {\n+          File[] files \u003d path.listFiles();\n+          if (files !\u003d null) {\n+            for (File jar : files) {\n+              if (!jar.isDirectory()) {\n+                addJar(jar);\n+              } else {\n+                LOG.info(\"Ignored \" + jar + \" because it is a directory\");\n+              }\n+            }\n+          } else {\n+            LOG.warn(\"Could not list directory \" + path);\n+          }\n+        } else {\n+          LOG.warn(\"Ignored \" + expanded + \". It is not a directory\");\n+        }\n+      } else if (expanded.endsWith(\".jar\")) {\n+        File jarFile \u003d new File(expanded);\n+        addJar(jarFile);\n+      } else if (!expanded.isEmpty()) {\n+        LOG.warn(\"Ignored \" + expanded + \" only jars are supported\");\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void collectPackages() throws UploaderException {\n    parseLists();\n    String[] list \u003d StringUtils.split(input, File.pathSeparatorChar);\n    for (String item : list) {\n      LOG.info(\"Original source \" + item);\n      String expanded \u003d expandEnvironmentVariables(item, System.getenv());\n      LOG.info(\"Expanded source \" + expanded);\n      if (expanded.endsWith(\"*\")) {\n        File path \u003d new File(expanded.substring(0, expanded.length() - 1));\n        if (path.isDirectory()) {\n          File[] files \u003d path.listFiles();\n          if (files !\u003d null) {\n            for (File jar : files) {\n              if (!jar.isDirectory()) {\n                addJar(jar);\n              } else {\n                LOG.info(\"Ignored \" + jar + \" because it is a directory\");\n              }\n            }\n          } else {\n            LOG.warn(\"Could not list directory \" + path);\n          }\n        } else {\n          LOG.warn(\"Ignored \" + expanded + \". It is not a directory\");\n        }\n      } else if (expanded.endsWith(\".jar\")) {\n        File jarFile \u003d new File(expanded);\n        addJar(jarFile);\n      } else if (!expanded.isEmpty()) {\n        LOG.warn(\"Ignored \" + expanded + \" only jars are supported\");\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-uploader/src/main/java/org/apache/hadoop/mapred/uploader/FrameworkUploader.java"
    }
  }
}