{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Storage.java",
  "functionName": "writeProperties",
  "functionId": "writeProperties___to-File__props-Properties",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/Storage.java",
  "functionStartLine": 1246,
  "functionEndLine": 1266,
  "numCommitsSeen": 89,
  "timeTaken": 3166,
  "changeHistory": [
    "1403b84b122fb76ef2b085a728b5402c32499c1f",
    "edb6dc5f303093c2604cd07b0c0dacf12dbce5de"
  ],
  "changeHistoryShort": {
    "1403b84b122fb76ef2b085a728b5402c32499c1f": "Ymultichange(Yparameterchange,Ybodychange)",
    "edb6dc5f303093c2604cd07b0c0dacf12dbce5de": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1403b84b122fb76ef2b085a728b5402c32499c1f": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-8546. Use try with resources in DataStorage and Storage.\n",
      "commitDate": "25/06/15 5:50 PM",
      "commitName": "1403b84b122fb76ef2b085a728b5402c32499c1f",
      "commitAuthor": "Andrew Wang",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-8546. Use try with resources in DataStorage and Storage.\n",
          "commitDate": "25/06/15 5:50 PM",
          "commitName": "1403b84b122fb76ef2b085a728b5402c32499c1f",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "10/03/15 6:20 PM",
          "commitNameOld": "5c1036d598051cf6af595740f1ab82092b0b6554",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 106.98,
          "commitsBetweenForRepo": 951,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,21 @@\n-  public static void writeProperties(File to, StorageDirectory sd,\n-      Properties props) throws IOException {\n-    RandomAccessFile file \u003d new RandomAccessFile(to, \"rws\");\n-    FileOutputStream out \u003d null;\n-    try {\n+  public static void writeProperties(File to, Properties props)\n+      throws IOException {\n+    try (RandomAccessFile file \u003d new RandomAccessFile(to, \"rws\");\n+        FileOutputStream out \u003d new FileOutputStream(file.getFD())) {\n       file.seek(0);\n-      out \u003d new FileOutputStream(file.getFD());\n       /*\n-       * If server is interrupted before this line, \n+       * If server is interrupted before this line,\n        * the version file will remain unchanged.\n        */\n       props.store(out, null);\n       /*\n-       * Now the new fields are flushed to the head of the file, but file \n-       * length can still be larger then required and therefore the file can \n+       * Now the new fields are flushed to the head of the file, but file\n+       * length can still be larger then required and therefore the file can\n        * contain whole or corrupted fields from its old contents in the end.\n        * If server is interrupted here and restarted later these extra fields\n        * either should not effect server behavior or should be handled\n        * by the server correctly.\n        */\n       file.setLength(out.getChannel().position());\n-    } finally {\n-      if (out !\u003d null) {\n-        out.close();\n-      }\n-      file.close();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static void writeProperties(File to, Properties props)\n      throws IOException {\n    try (RandomAccessFile file \u003d new RandomAccessFile(to, \"rws\");\n        FileOutputStream out \u003d new FileOutputStream(file.getFD())) {\n      file.seek(0);\n      /*\n       * If server is interrupted before this line,\n       * the version file will remain unchanged.\n       */\n      props.store(out, null);\n      /*\n       * Now the new fields are flushed to the head of the file, but file\n       * length can still be larger then required and therefore the file can\n       * contain whole or corrupted fields from its old contents in the end.\n       * If server is interrupted here and restarted later these extra fields\n       * either should not effect server behavior or should be handled\n       * by the server correctly.\n       */\n      file.setLength(out.getChannel().position());\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/Storage.java",
          "extendedDetails": {
            "oldValue": "[to-File, sd-StorageDirectory, props-Properties]",
            "newValue": "[to-File, props-Properties]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8546. Use try with resources in DataStorage and Storage.\n",
          "commitDate": "25/06/15 5:50 PM",
          "commitName": "1403b84b122fb76ef2b085a728b5402c32499c1f",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "10/03/15 6:20 PM",
          "commitNameOld": "5c1036d598051cf6af595740f1ab82092b0b6554",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 106.98,
          "commitsBetweenForRepo": 951,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,21 @@\n-  public static void writeProperties(File to, StorageDirectory sd,\n-      Properties props) throws IOException {\n-    RandomAccessFile file \u003d new RandomAccessFile(to, \"rws\");\n-    FileOutputStream out \u003d null;\n-    try {\n+  public static void writeProperties(File to, Properties props)\n+      throws IOException {\n+    try (RandomAccessFile file \u003d new RandomAccessFile(to, \"rws\");\n+        FileOutputStream out \u003d new FileOutputStream(file.getFD())) {\n       file.seek(0);\n-      out \u003d new FileOutputStream(file.getFD());\n       /*\n-       * If server is interrupted before this line, \n+       * If server is interrupted before this line,\n        * the version file will remain unchanged.\n        */\n       props.store(out, null);\n       /*\n-       * Now the new fields are flushed to the head of the file, but file \n-       * length can still be larger then required and therefore the file can \n+       * Now the new fields are flushed to the head of the file, but file\n+       * length can still be larger then required and therefore the file can\n        * contain whole or corrupted fields from its old contents in the end.\n        * If server is interrupted here and restarted later these extra fields\n        * either should not effect server behavior or should be handled\n        * by the server correctly.\n        */\n       file.setLength(out.getChannel().position());\n-    } finally {\n-      if (out !\u003d null) {\n-        out.close();\n-      }\n-      file.close();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static void writeProperties(File to, Properties props)\n      throws IOException {\n    try (RandomAccessFile file \u003d new RandomAccessFile(to, \"rws\");\n        FileOutputStream out \u003d new FileOutputStream(file.getFD())) {\n      file.seek(0);\n      /*\n       * If server is interrupted before this line,\n       * the version file will remain unchanged.\n       */\n      props.store(out, null);\n      /*\n       * Now the new fields are flushed to the head of the file, but file\n       * length can still be larger then required and therefore the file can\n       * contain whole or corrupted fields from its old contents in the end.\n       * If server is interrupted here and restarted later these extra fields\n       * either should not effect server behavior or should be handled\n       * by the server correctly.\n       */\n      file.setLength(out.getChannel().position());\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/Storage.java",
          "extendedDetails": {}
        }
      ]
    },
    "edb6dc5f303093c2604cd07b0c0dacf12dbce5de": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5138. Support HDFS upgrade in HA. Contributed by Aaron T. Myers.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1561381 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/01/14 12:01 PM",
      "commitName": "edb6dc5f303093c2604cd07b0c0dacf12dbce5de",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,28 @@\n+  public static void writeProperties(File to, StorageDirectory sd,\n+      Properties props) throws IOException {\n+    RandomAccessFile file \u003d new RandomAccessFile(to, \"rws\");\n+    FileOutputStream out \u003d null;\n+    try {\n+      file.seek(0);\n+      out \u003d new FileOutputStream(file.getFD());\n+      /*\n+       * If server is interrupted before this line, \n+       * the version file will remain unchanged.\n+       */\n+      props.store(out, null);\n+      /*\n+       * Now the new fields are flushed to the head of the file, but file \n+       * length can still be larger then required and therefore the file can \n+       * contain whole or corrupted fields from its old contents in the end.\n+       * If server is interrupted here and restarted later these extra fields\n+       * either should not effect server behavior or should be handled\n+       * by the server correctly.\n+       */\n+      file.setLength(out.getChannel().position());\n+    } finally {\n+      if (out !\u003d null) {\n+        out.close();\n+      }\n+      file.close();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static void writeProperties(File to, StorageDirectory sd,\n      Properties props) throws IOException {\n    RandomAccessFile file \u003d new RandomAccessFile(to, \"rws\");\n    FileOutputStream out \u003d null;\n    try {\n      file.seek(0);\n      out \u003d new FileOutputStream(file.getFD());\n      /*\n       * If server is interrupted before this line, \n       * the version file will remain unchanged.\n       */\n      props.store(out, null);\n      /*\n       * Now the new fields are flushed to the head of the file, but file \n       * length can still be larger then required and therefore the file can \n       * contain whole or corrupted fields from its old contents in the end.\n       * If server is interrupted here and restarted later these extra fields\n       * either should not effect server behavior or should be handled\n       * by the server correctly.\n       */\n      file.setLength(out.getChannel().position());\n    } finally {\n      if (out !\u003d null) {\n        out.close();\n      }\n      file.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/Storage.java"
    }
  }
}