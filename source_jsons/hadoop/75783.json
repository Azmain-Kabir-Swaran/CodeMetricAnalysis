{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "SnappyDecompressor.java",
  "functionName": "decompressDirect",
  "functionId": "decompressDirect___src-ByteBuffer__dst-ByteBuffer",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/snappy/SnappyDecompressor.java",
  "functionStartLine": 283,
  "functionEndLine": 313,
  "numCommitsSeen": 8,
  "timeTaken": 1282,
  "changeHistory": [
    "d9ba056bdb851138d0d25185d45c9f894080de24"
  ],
  "changeHistoryShort": {
    "d9ba056bdb851138d0d25185d45c9f894080de24": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d9ba056bdb851138d0d25185d45c9f894080de24": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-10047. Add a direct-buffer based apis for compression. Contributed by Gopal V.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1543542 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/11/13 11:29 AM",
      "commitName": "d9ba056bdb851138d0d25185d45c9f894080de24",
      "commitAuthor": "Arun Murthy",
      "diff": "@@ -0,0 +1,31 @@\n+  int decompressDirect(ByteBuffer src, ByteBuffer dst) throws IOException {\n+    assert (this instanceof SnappyDirectDecompressor);\n+    \n+    ByteBuffer presliced \u003d dst;\n+    if (dst.position() \u003e 0) {\n+      presliced \u003d dst;\n+      dst \u003d dst.slice();\n+    }\n+\n+    Buffer originalCompressed \u003d compressedDirectBuf;\n+    Buffer originalUncompressed \u003d uncompressedDirectBuf;\n+    int originalBufferSize \u003d directBufferSize;\n+    compressedDirectBuf \u003d src.slice();\n+    compressedDirectBufLen \u003d src.remaining();\n+    uncompressedDirectBuf \u003d dst;\n+    directBufferSize \u003d dst.remaining();\n+    int n \u003d 0;\n+    try {\n+      n \u003d decompressBytesDirect();\n+      presliced.position(presliced.position() + n);\n+      // SNAPPY always consumes the whole buffer or throws an exception\n+      src.position(src.limit());\n+      finished \u003d true;\n+    } finally {\n+      compressedDirectBuf \u003d originalCompressed;\n+      uncompressedDirectBuf \u003d originalUncompressed;\n+      compressedDirectBufLen \u003d 0;\n+      directBufferSize \u003d originalBufferSize;\n+    }\n+    return n;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  int decompressDirect(ByteBuffer src, ByteBuffer dst) throws IOException {\n    assert (this instanceof SnappyDirectDecompressor);\n    \n    ByteBuffer presliced \u003d dst;\n    if (dst.position() \u003e 0) {\n      presliced \u003d dst;\n      dst \u003d dst.slice();\n    }\n\n    Buffer originalCompressed \u003d compressedDirectBuf;\n    Buffer originalUncompressed \u003d uncompressedDirectBuf;\n    int originalBufferSize \u003d directBufferSize;\n    compressedDirectBuf \u003d src.slice();\n    compressedDirectBufLen \u003d src.remaining();\n    uncompressedDirectBuf \u003d dst;\n    directBufferSize \u003d dst.remaining();\n    int n \u003d 0;\n    try {\n      n \u003d decompressBytesDirect();\n      presliced.position(presliced.position() + n);\n      // SNAPPY always consumes the whole buffer or throws an exception\n      src.position(src.limit());\n      finished \u003d true;\n    } finally {\n      compressedDirectBuf \u003d originalCompressed;\n      uncompressedDirectBuf \u003d originalUncompressed;\n      compressedDirectBufLen \u003d 0;\n      directBufferSize \u003d originalBufferSize;\n    }\n    return n;\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/snappy/SnappyDecompressor.java"
    }
  }
}