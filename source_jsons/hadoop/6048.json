{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSEditLog.java",
  "functionName": "logOpenFile",
  "functionId": "logOpenFile___path-String__newNode-INodeFile__overwrite-boolean__toLogRpcIds-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
  "functionStartLine": 805,
  "functionEndLine": 837,
  "numCommitsSeen": 373,
  "timeTaken": 10273,
  "changeHistory": [
    "67662e2ac9e68f32b725c8118cf2be79a662fca5",
    "0100b155019496d077f958904de7d385697d65d9",
    "9e81be01144d5cf520313608e85cdc1d8063aa15",
    "b0a41de68c5b08f534ca231293de053c0b0cbd5d",
    "bb84f1fccb18c6c7373851e05d2451d55e908242",
    "d45e7c7e856c7103752888c0395fa94985cd7670",
    "6104520369045dfaa4b543cbad21236ed322249b",
    "d417e49ce4db119cdeb01be526cdb07f24baf388",
    "fc14360b0340a33c0e1eb34967d4dcd772533418",
    "c89c516b95f45e04af55d9030043a42e2d07b02b",
    "ce68f410b05a58ad05965f32ad7f5b246b363a75",
    "8c7a7e619699386f9e6991842558d78aa0c8053d",
    "19201622be1db8e166d1cc0dd7e62af4702d2784",
    "9a0651b4b86727910ae29d055aac6a23490b5ed3",
    "ad06a087131d69d173d8e03dce5c97650a530f2e",
    "706394d03992b394e9f907aff2155df493e4ea4e",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "67662e2ac9e68f32b725c8118cf2be79a662fca5": "Ybodychange",
    "0100b155019496d077f958904de7d385697d65d9": "Ybodychange",
    "9e81be01144d5cf520313608e85cdc1d8063aa15": "Ybodychange",
    "b0a41de68c5b08f534ca231293de053c0b0cbd5d": "Ybodychange",
    "bb84f1fccb18c6c7373851e05d2451d55e908242": "Ybodychange",
    "d45e7c7e856c7103752888c0395fa94985cd7670": "Ybodychange",
    "6104520369045dfaa4b543cbad21236ed322249b": "Ymultichange(Yparameterchange,Ybodychange)",
    "d417e49ce4db119cdeb01be526cdb07f24baf388": "Ybodychange",
    "fc14360b0340a33c0e1eb34967d4dcd772533418": "Ybodychange",
    "c89c516b95f45e04af55d9030043a42e2d07b02b": "Ybodychange",
    "ce68f410b05a58ad05965f32ad7f5b246b363a75": "Ymultichange(Yparameterchange,Ybodychange)",
    "8c7a7e619699386f9e6991842558d78aa0c8053d": "Ymultichange(Yparameterchange,Ybodychange)",
    "19201622be1db8e166d1cc0dd7e62af4702d2784": "Ybodychange",
    "9a0651b4b86727910ae29d055aac6a23490b5ed3": "Ybodychange",
    "ad06a087131d69d173d8e03dce5c97650a530f2e": "Ybodychange",
    "706394d03992b394e9f907aff2155df493e4ea4e": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "67662e2ac9e68f32b725c8118cf2be79a662fca5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12840. Creating a file with non-default EC policy in a EC zone is not correctly serialized in the editlog. Contributed by Lei (Eddy) Xu.\n",
      "commitDate": "07/12/17 11:15 AM",
      "commitName": "67662e2ac9e68f32b725c8118cf2be79a662fca5",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "20/11/17 12:49 PM",
      "commitNameOld": "60fc2a138827c2c29fa7e9d6844e3b8d43809726",
      "commitAuthorOld": "Chen Liang",
      "daysBetweenCommits": 16.93,
      "commitsBetweenForRepo": 79,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,33 @@\n   public void logOpenFile(String path, INodeFile newNode, boolean overwrite,\n       boolean toLogRpcIds) {\n     Preconditions.checkArgument(newNode.isUnderConstruction());\n     PermissionStatus permissions \u003d newNode.getPermissionStatus();\n     AddOp op \u003d AddOp.getInstance(cache.get())\n       .setInodeId(newNode.getId())\n       .setPath(path)\n       .setReplication(newNode.getFileReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(permissions)\n       .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n       .setClientMachine(\n           newNode.getFileUnderConstructionFeature().getClientMachine())\n       .setOverwrite(overwrite)\n-      .setStoragePolicyId(newNode.getLocalStoragePolicyID());\n+      .setStoragePolicyId(newNode.getLocalStoragePolicyID())\n+      .setErasureCodingPolicyId(newNode.getErasureCodingPolicyID());\n \n     AclFeature f \u003d newNode.getAclFeature();\n     if (f !\u003d null) {\n       op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n     }\n \n     XAttrFeature x \u003d newNode.getXAttrFeature();\n     if (x !\u003d null) {\n       op.setXAttrs(x.getXAttrs());\n     }\n \n     logRpcIds(op, toLogRpcIds);\n     logEdit(op);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logOpenFile(String path, INodeFile newNode, boolean overwrite,\n      boolean toLogRpcIds) {\n    Preconditions.checkArgument(newNode.isUnderConstruction());\n    PermissionStatus permissions \u003d newNode.getPermissionStatus();\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setInodeId(newNode.getId())\n      .setPath(path)\n      .setReplication(newNode.getFileReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(permissions)\n      .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n      .setClientMachine(\n          newNode.getFileUnderConstructionFeature().getClientMachine())\n      .setOverwrite(overwrite)\n      .setStoragePolicyId(newNode.getLocalStoragePolicyID())\n      .setErasureCodingPolicyId(newNode.getErasureCodingPolicyID());\n\n    AclFeature f \u003d newNode.getAclFeature();\n    if (f !\u003d null) {\n      op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n    }\n\n    XAttrFeature x \u003d newNode.getXAttrFeature();\n    if (x !\u003d null) {\n      op.setXAttrs(x.getXAttrs());\n    }\n\n    logRpcIds(op, toLogRpcIds);\n    logEdit(op);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "0100b155019496d077f958904de7d385697d65d9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8219. setStoragePolicy with folder behavior is different after cluster restart. (surendra singh lilhore via Xiaoyu Yao)\n",
      "commitDate": "05/05/15 1:41 PM",
      "commitName": "0100b155019496d077f958904de7d385697d65d9",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "05/05/15 10:50 AM",
      "commitNameOld": "fcd4cb751665adb241081e42b3403c3856b6c6fe",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.12,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,32 @@\n   public void logOpenFile(String path, INodeFile newNode, boolean overwrite,\n       boolean toLogRpcIds) {\n     Preconditions.checkArgument(newNode.isUnderConstruction());\n     PermissionStatus permissions \u003d newNode.getPermissionStatus();\n     AddOp op \u003d AddOp.getInstance(cache.get())\n       .setInodeId(newNode.getId())\n       .setPath(path)\n       .setReplication(newNode.getFileReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(permissions)\n       .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n       .setClientMachine(\n           newNode.getFileUnderConstructionFeature().getClientMachine())\n       .setOverwrite(overwrite)\n-      .setStoragePolicyId(newNode.getStoragePolicyID());\n+      .setStoragePolicyId(newNode.getLocalStoragePolicyID());\n \n     AclFeature f \u003d newNode.getAclFeature();\n     if (f !\u003d null) {\n       op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n     }\n \n     XAttrFeature x \u003d newNode.getXAttrFeature();\n     if (x !\u003d null) {\n       op.setXAttrs(x.getXAttrs());\n     }\n \n     logRpcIds(op, toLogRpcIds);\n     logEdit(op);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logOpenFile(String path, INodeFile newNode, boolean overwrite,\n      boolean toLogRpcIds) {\n    Preconditions.checkArgument(newNode.isUnderConstruction());\n    PermissionStatus permissions \u003d newNode.getPermissionStatus();\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setInodeId(newNode.getId())\n      .setPath(path)\n      .setReplication(newNode.getFileReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(permissions)\n      .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n      .setClientMachine(\n          newNode.getFileUnderConstructionFeature().getClientMachine())\n      .setOverwrite(overwrite)\n      .setStoragePolicyId(newNode.getLocalStoragePolicyID());\n\n    AclFeature f \u003d newNode.getAclFeature();\n    if (f !\u003d null) {\n      op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n    }\n\n    XAttrFeature x \u003d newNode.getXAttrFeature();\n    if (x !\u003d null) {\n      op.setXAttrs(x.getXAttrs());\n    }\n\n    logRpcIds(op, toLogRpcIds);\n    logEdit(op);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "9e81be01144d5cf520313608e85cdc1d8063aa15": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7398. Reset cached thread-local FSEditLogOp\u0027s on every FSEditLog#logEdit. Contributed by Gera Shegalov.\n",
      "commitDate": "18/11/14 4:56 PM",
      "commitName": "9e81be01144d5cf520313608e85cdc1d8063aa15",
      "commitAuthor": "cnauroth",
      "commitDateOld": "13/11/14 12:34 PM",
      "commitNameOld": "b0a41de68c5b08f534ca231293de053c0b0cbd5d",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 5.18,
      "commitsBetweenForRepo": 34,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,32 @@\n   public void logOpenFile(String path, INodeFile newNode, boolean overwrite,\n       boolean toLogRpcIds) {\n     Preconditions.checkArgument(newNode.isUnderConstruction());\n     PermissionStatus permissions \u003d newNode.getPermissionStatus();\n     AddOp op \u003d AddOp.getInstance(cache.get())\n-      .reset()\n       .setInodeId(newNode.getId())\n       .setPath(path)\n       .setReplication(newNode.getFileReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(permissions)\n       .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n       .setClientMachine(\n           newNode.getFileUnderConstructionFeature().getClientMachine())\n       .setOverwrite(overwrite)\n       .setStoragePolicyId(newNode.getStoragePolicyID());\n \n     AclFeature f \u003d newNode.getAclFeature();\n     if (f !\u003d null) {\n       op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n     }\n \n     XAttrFeature x \u003d newNode.getXAttrFeature();\n     if (x !\u003d null) {\n       op.setXAttrs(x.getXAttrs());\n     }\n \n     logRpcIds(op, toLogRpcIds);\n     logEdit(op);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logOpenFile(String path, INodeFile newNode, boolean overwrite,\n      boolean toLogRpcIds) {\n    Preconditions.checkArgument(newNode.isUnderConstruction());\n    PermissionStatus permissions \u003d newNode.getPermissionStatus();\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setInodeId(newNode.getId())\n      .setPath(path)\n      .setReplication(newNode.getFileReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(permissions)\n      .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n      .setClientMachine(\n          newNode.getFileUnderConstructionFeature().getClientMachine())\n      .setOverwrite(overwrite)\n      .setStoragePolicyId(newNode.getStoragePolicyID());\n\n    AclFeature f \u003d newNode.getAclFeature();\n    if (f !\u003d null) {\n      op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n    }\n\n    XAttrFeature x \u003d newNode.getXAttrFeature();\n    if (x !\u003d null) {\n      op.setXAttrs(x.getXAttrs());\n    }\n\n    logRpcIds(op, toLogRpcIds);\n    logEdit(op);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "b0a41de68c5b08f534ca231293de053c0b0cbd5d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7385. ThreadLocal used in FSEditLog class causes FSImage permission mess up. Contributed by jiangyu.\n",
      "commitDate": "13/11/14 12:34 PM",
      "commitName": "b0a41de68c5b08f534ca231293de053c0b0cbd5d",
      "commitAuthor": "cnauroth",
      "commitDateOld": "29/09/14 10:27 PM",
      "commitNameOld": "bb84f1fccb18c6c7373851e05d2451d55e908242",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 44.63,
      "commitsBetweenForRepo": 438,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,33 @@\n   public void logOpenFile(String path, INodeFile newNode, boolean overwrite,\n       boolean toLogRpcIds) {\n     Preconditions.checkArgument(newNode.isUnderConstruction());\n     PermissionStatus permissions \u003d newNode.getPermissionStatus();\n     AddOp op \u003d AddOp.getInstance(cache.get())\n+      .reset()\n       .setInodeId(newNode.getId())\n       .setPath(path)\n       .setReplication(newNode.getFileReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(permissions)\n       .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n       .setClientMachine(\n           newNode.getFileUnderConstructionFeature().getClientMachine())\n       .setOverwrite(overwrite)\n       .setStoragePolicyId(newNode.getStoragePolicyID());\n \n     AclFeature f \u003d newNode.getAclFeature();\n     if (f !\u003d null) {\n       op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n     }\n \n     XAttrFeature x \u003d newNode.getXAttrFeature();\n     if (x !\u003d null) {\n       op.setXAttrs(x.getXAttrs());\n     }\n \n     logRpcIds(op, toLogRpcIds);\n     logEdit(op);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logOpenFile(String path, INodeFile newNode, boolean overwrite,\n      boolean toLogRpcIds) {\n    Preconditions.checkArgument(newNode.isUnderConstruction());\n    PermissionStatus permissions \u003d newNode.getPermissionStatus();\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .reset()\n      .setInodeId(newNode.getId())\n      .setPath(path)\n      .setReplication(newNode.getFileReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(permissions)\n      .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n      .setClientMachine(\n          newNode.getFileUnderConstructionFeature().getClientMachine())\n      .setOverwrite(overwrite)\n      .setStoragePolicyId(newNode.getStoragePolicyID());\n\n    AclFeature f \u003d newNode.getAclFeature();\n    if (f !\u003d null) {\n      op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n    }\n\n    XAttrFeature x \u003d newNode.getXAttrFeature();\n    if (x !\u003d null) {\n      op.setXAttrs(x.getXAttrs());\n    }\n\n    logRpcIds(op, toLogRpcIds);\n    logEdit(op);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "bb84f1fccb18c6c7373851e05d2451d55e908242": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7159. Use block storage policy to set lazy persist preference. (Arpit Agarwal)\n",
      "commitDate": "29/09/14 10:27 PM",
      "commitName": "bb84f1fccb18c6c7373851e05d2451d55e908242",
      "commitAuthor": "arp",
      "commitDateOld": "29/09/14 12:36 PM",
      "commitNameOld": "d45e7c7e856c7103752888c0395fa94985cd7670",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 0.41,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,32 @@\n   public void logOpenFile(String path, INodeFile newNode, boolean overwrite,\n       boolean toLogRpcIds) {\n     Preconditions.checkArgument(newNode.isUnderConstruction());\n     PermissionStatus permissions \u003d newNode.getPermissionStatus();\n     AddOp op \u003d AddOp.getInstance(cache.get())\n       .setInodeId(newNode.getId())\n       .setPath(path)\n       .setReplication(newNode.getFileReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n-      .setLazyPersistFlag(newNode.getLazyPersistFlag())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(permissions)\n       .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n       .setClientMachine(\n           newNode.getFileUnderConstructionFeature().getClientMachine())\n       .setOverwrite(overwrite)\n       .setStoragePolicyId(newNode.getStoragePolicyID());\n \n     AclFeature f \u003d newNode.getAclFeature();\n     if (f !\u003d null) {\n       op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n     }\n \n     XAttrFeature x \u003d newNode.getXAttrFeature();\n     if (x !\u003d null) {\n       op.setXAttrs(x.getXAttrs());\n     }\n \n     logRpcIds(op, toLogRpcIds);\n     logEdit(op);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logOpenFile(String path, INodeFile newNode, boolean overwrite,\n      boolean toLogRpcIds) {\n    Preconditions.checkArgument(newNode.isUnderConstruction());\n    PermissionStatus permissions \u003d newNode.getPermissionStatus();\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setInodeId(newNode.getId())\n      .setPath(path)\n      .setReplication(newNode.getFileReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(permissions)\n      .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n      .setClientMachine(\n          newNode.getFileUnderConstructionFeature().getClientMachine())\n      .setOverwrite(overwrite)\n      .setStoragePolicyId(newNode.getStoragePolicyID());\n\n    AclFeature f \u003d newNode.getAclFeature();\n    if (f !\u003d null) {\n      op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n    }\n\n    XAttrFeature x \u003d newNode.getXAttrFeature();\n    if (x !\u003d null) {\n      op.setXAttrs(x.getXAttrs());\n    }\n\n    logRpcIds(op, toLogRpcIds);\n    logEdit(op);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "d45e7c7e856c7103752888c0395fa94985cd7670": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7153. Add storagePolicy to NN edit log during file creation. (Arpit Agarwal)\n",
      "commitDate": "29/09/14 12:36 PM",
      "commitName": "d45e7c7e856c7103752888c0395fa94985cd7670",
      "commitAuthor": "arp",
      "commitDateOld": "18/09/14 10:26 PM",
      "commitNameOld": "f8bbf80067ac03400acae4655615c9808c538ca8",
      "commitAuthorOld": "",
      "daysBetweenCommits": 10.59,
      "commitsBetweenForRepo": 99,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,33 @@\n   public void logOpenFile(String path, INodeFile newNode, boolean overwrite,\n       boolean toLogRpcIds) {\n     Preconditions.checkArgument(newNode.isUnderConstruction());\n     PermissionStatus permissions \u003d newNode.getPermissionStatus();\n     AddOp op \u003d AddOp.getInstance(cache.get())\n       .setInodeId(newNode.getId())\n       .setPath(path)\n       .setReplication(newNode.getFileReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setLazyPersistFlag(newNode.getLazyPersistFlag())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(permissions)\n       .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n       .setClientMachine(\n           newNode.getFileUnderConstructionFeature().getClientMachine())\n-      .setOverwrite(overwrite);\n+      .setOverwrite(overwrite)\n+      .setStoragePolicyId(newNode.getStoragePolicyID());\n \n     AclFeature f \u003d newNode.getAclFeature();\n     if (f !\u003d null) {\n       op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n     }\n \n     XAttrFeature x \u003d newNode.getXAttrFeature();\n     if (x !\u003d null) {\n       op.setXAttrs(x.getXAttrs());\n     }\n \n     logRpcIds(op, toLogRpcIds);\n     logEdit(op);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logOpenFile(String path, INodeFile newNode, boolean overwrite,\n      boolean toLogRpcIds) {\n    Preconditions.checkArgument(newNode.isUnderConstruction());\n    PermissionStatus permissions \u003d newNode.getPermissionStatus();\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setInodeId(newNode.getId())\n      .setPath(path)\n      .setReplication(newNode.getFileReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setLazyPersistFlag(newNode.getLazyPersistFlag())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(permissions)\n      .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n      .setClientMachine(\n          newNode.getFileUnderConstructionFeature().getClientMachine())\n      .setOverwrite(overwrite)\n      .setStoragePolicyId(newNode.getStoragePolicyID());\n\n    AclFeature f \u003d newNode.getAclFeature();\n    if (f !\u003d null) {\n      op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n    }\n\n    XAttrFeature x \u003d newNode.getXAttrFeature();\n    if (x !\u003d null) {\n      op.setXAttrs(x.getXAttrs());\n    }\n\n    logRpcIds(op, toLogRpcIds);\n    logEdit(op);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "6104520369045dfaa4b543cbad21236ed322249b": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6886. Use single editlog record for creating file + overwrite. Contributed by Yi Liu.\n",
      "commitDate": "04/09/14 6:54 PM",
      "commitName": "6104520369045dfaa4b543cbad21236ed322249b",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6886. Use single editlog record for creating file + overwrite. Contributed by Yi Liu.\n",
          "commitDate": "04/09/14 6:54 PM",
          "commitName": "6104520369045dfaa4b543cbad21236ed322249b",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "02/09/14 2:02 PM",
          "commitNameOld": "faa4455be512e070fa420084be8d1be5c72f3b08",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 2.2,
          "commitsBetweenForRepo": 22,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,31 @@\n-  public void logOpenFile(String path, INodeFile newNode, boolean toLogRpcIds) {\n+  public void logOpenFile(String path, INodeFile newNode, boolean overwrite,\n+      boolean toLogRpcIds) {\n     Preconditions.checkArgument(newNode.isUnderConstruction());\n     PermissionStatus permissions \u003d newNode.getPermissionStatus();\n     AddOp op \u003d AddOp.getInstance(cache.get())\n       .setInodeId(newNode.getId())\n       .setPath(path)\n       .setReplication(newNode.getFileReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(permissions)\n       .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n       .setClientMachine(\n-          newNode.getFileUnderConstructionFeature().getClientMachine());\n+          newNode.getFileUnderConstructionFeature().getClientMachine())\n+      .setOverwrite(overwrite);\n \n     AclFeature f \u003d newNode.getAclFeature();\n     if (f !\u003d null) {\n       op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n     }\n \n     XAttrFeature x \u003d newNode.getXAttrFeature();\n     if (x !\u003d null) {\n       op.setXAttrs(x.getXAttrs());\n     }\n \n     logRpcIds(op, toLogRpcIds);\n     logEdit(op);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void logOpenFile(String path, INodeFile newNode, boolean overwrite,\n      boolean toLogRpcIds) {\n    Preconditions.checkArgument(newNode.isUnderConstruction());\n    PermissionStatus permissions \u003d newNode.getPermissionStatus();\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setInodeId(newNode.getId())\n      .setPath(path)\n      .setReplication(newNode.getFileReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(permissions)\n      .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n      .setClientMachine(\n          newNode.getFileUnderConstructionFeature().getClientMachine())\n      .setOverwrite(overwrite);\n\n    AclFeature f \u003d newNode.getAclFeature();\n    if (f !\u003d null) {\n      op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n    }\n\n    XAttrFeature x \u003d newNode.getXAttrFeature();\n    if (x !\u003d null) {\n      op.setXAttrs(x.getXAttrs());\n    }\n\n    logRpcIds(op, toLogRpcIds);\n    logEdit(op);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
          "extendedDetails": {
            "oldValue": "[path-String, newNode-INodeFile, toLogRpcIds-boolean]",
            "newValue": "[path-String, newNode-INodeFile, overwrite-boolean, toLogRpcIds-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6886. Use single editlog record for creating file + overwrite. Contributed by Yi Liu.\n",
          "commitDate": "04/09/14 6:54 PM",
          "commitName": "6104520369045dfaa4b543cbad21236ed322249b",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "02/09/14 2:02 PM",
          "commitNameOld": "faa4455be512e070fa420084be8d1be5c72f3b08",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 2.2,
          "commitsBetweenForRepo": 22,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,31 @@\n-  public void logOpenFile(String path, INodeFile newNode, boolean toLogRpcIds) {\n+  public void logOpenFile(String path, INodeFile newNode, boolean overwrite,\n+      boolean toLogRpcIds) {\n     Preconditions.checkArgument(newNode.isUnderConstruction());\n     PermissionStatus permissions \u003d newNode.getPermissionStatus();\n     AddOp op \u003d AddOp.getInstance(cache.get())\n       .setInodeId(newNode.getId())\n       .setPath(path)\n       .setReplication(newNode.getFileReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(permissions)\n       .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n       .setClientMachine(\n-          newNode.getFileUnderConstructionFeature().getClientMachine());\n+          newNode.getFileUnderConstructionFeature().getClientMachine())\n+      .setOverwrite(overwrite);\n \n     AclFeature f \u003d newNode.getAclFeature();\n     if (f !\u003d null) {\n       op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n     }\n \n     XAttrFeature x \u003d newNode.getXAttrFeature();\n     if (x !\u003d null) {\n       op.setXAttrs(x.getXAttrs());\n     }\n \n     logRpcIds(op, toLogRpcIds);\n     logEdit(op);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void logOpenFile(String path, INodeFile newNode, boolean overwrite,\n      boolean toLogRpcIds) {\n    Preconditions.checkArgument(newNode.isUnderConstruction());\n    PermissionStatus permissions \u003d newNode.getPermissionStatus();\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setInodeId(newNode.getId())\n      .setPath(path)\n      .setReplication(newNode.getFileReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(permissions)\n      .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n      .setClientMachine(\n          newNode.getFileUnderConstructionFeature().getClientMachine())\n      .setOverwrite(overwrite);\n\n    AclFeature f \u003d newNode.getAclFeature();\n    if (f !\u003d null) {\n      op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n    }\n\n    XAttrFeature x \u003d newNode.getXAttrFeature();\n    if (x !\u003d null) {\n      op.setXAttrs(x.getXAttrs());\n    }\n\n    logRpcIds(op, toLogRpcIds);\n    logEdit(op);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
          "extendedDetails": {}
        }
      ]
    },
    "d417e49ce4db119cdeb01be526cdb07f24baf388": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6492. Support create-time xattrs and atomically setting multiple xattrs. (wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603971 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/06/14 10:37 AM",
      "commitName": "d417e49ce4db119cdeb01be526cdb07f24baf388",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "21/05/14 6:57 AM",
      "commitNameOld": "ac23a55547716df29b3e25c98a113399e184d9d1",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 29.15,
      "commitsBetweenForRepo": 170,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,29 @@\n   public void logOpenFile(String path, INodeFile newNode, boolean toLogRpcIds) {\n     Preconditions.checkArgument(newNode.isUnderConstruction());\n     PermissionStatus permissions \u003d newNode.getPermissionStatus();\n     AddOp op \u003d AddOp.getInstance(cache.get())\n       .setInodeId(newNode.getId())\n       .setPath(path)\n       .setReplication(newNode.getFileReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(permissions)\n       .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n-      .setClientMachine(newNode.getFileUnderConstructionFeature().getClientMachine());\n+      .setClientMachine(\n+          newNode.getFileUnderConstructionFeature().getClientMachine());\n \n     AclFeature f \u003d newNode.getAclFeature();\n     if (f !\u003d null) {\n       op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n     }\n+\n+    XAttrFeature x \u003d newNode.getXAttrFeature();\n+    if (x !\u003d null) {\n+      op.setXAttrs(x.getXAttrs());\n+    }\n+\n     logRpcIds(op, toLogRpcIds);\n     logEdit(op);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logOpenFile(String path, INodeFile newNode, boolean toLogRpcIds) {\n    Preconditions.checkArgument(newNode.isUnderConstruction());\n    PermissionStatus permissions \u003d newNode.getPermissionStatus();\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setInodeId(newNode.getId())\n      .setPath(path)\n      .setReplication(newNode.getFileReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(permissions)\n      .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n      .setClientMachine(\n          newNode.getFileUnderConstructionFeature().getClientMachine());\n\n    AclFeature f \u003d newNode.getAclFeature();\n    if (f !\u003d null) {\n      op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n    }\n\n    XAttrFeature x \u003d newNode.getXAttrFeature();\n    if (x !\u003d null) {\n      op.setXAttrs(x.getXAttrs());\n    }\n\n    logRpcIds(op, toLogRpcIds);\n    logEdit(op);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "fc14360b0340a33c0e1eb34967d4dcd772533418": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5923. Do not persist the ACL bit in the FsPermission. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4685@1567784 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/02/14 2:54 PM",
      "commitName": "fc14360b0340a33c0e1eb34967d4dcd772533418",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "07/02/14 3:11 PM",
      "commitNameOld": "c89c516b95f45e04af55d9030043a42e2d07b02b",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 4.99,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,22 @@\n   public void logOpenFile(String path, INodeFile newNode, boolean toLogRpcIds) {\n     Preconditions.checkArgument(newNode.isUnderConstruction());\n     PermissionStatus permissions \u003d newNode.getPermissionStatus();\n     AddOp op \u003d AddOp.getInstance(cache.get())\n       .setInodeId(newNode.getId())\n       .setPath(path)\n       .setReplication(newNode.getFileReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(permissions)\n-      .setAclEntries(permissions.getPermission().getAclBit() ?\n-        AclStorage.readINodeLogicalAcl(newNode) : null)\n       .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n       .setClientMachine(newNode.getFileUnderConstructionFeature().getClientMachine());\n+\n+    AclFeature f \u003d newNode.getAclFeature();\n+    if (f !\u003d null) {\n+      op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n+    }\n     logRpcIds(op, toLogRpcIds);\n     logEdit(op);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logOpenFile(String path, INodeFile newNode, boolean toLogRpcIds) {\n    Preconditions.checkArgument(newNode.isUnderConstruction());\n    PermissionStatus permissions \u003d newNode.getPermissionStatus();\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setInodeId(newNode.getId())\n      .setPath(path)\n      .setReplication(newNode.getFileReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(permissions)\n      .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n      .setClientMachine(newNode.getFileUnderConstructionFeature().getClientMachine());\n\n    AclFeature f \u003d newNode.getAclFeature();\n    if (f !\u003d null) {\n      op.setAclEntries(AclStorage.readINodeLogicalAcl(newNode));\n    }\n    logRpcIds(op, toLogRpcIds);\n    logEdit(op);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "c89c516b95f45e04af55d9030043a42e2d07b02b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5616. NameNode: implement default ACL handling. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4685@1565845 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/02/14 3:11 PM",
      "commitName": "c89c516b95f45e04af55d9030043a42e2d07b02b",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "27/01/14 10:09 AM",
      "commitNameOld": "ad240d6b3a9c9efb17c6bf73a51295dedf5c34de",
      "commitAuthorOld": "",
      "daysBetweenCommits": 11.21,
      "commitsBetweenForRepo": 64,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,19 @@\n   public void logOpenFile(String path, INodeFile newNode, boolean toLogRpcIds) {\n     Preconditions.checkArgument(newNode.isUnderConstruction());\n+    PermissionStatus permissions \u003d newNode.getPermissionStatus();\n     AddOp op \u003d AddOp.getInstance(cache.get())\n       .setInodeId(newNode.getId())\n       .setPath(path)\n       .setReplication(newNode.getFileReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setBlocks(newNode.getBlocks())\n-      .setPermissionStatus(newNode.getPermissionStatus())\n+      .setPermissionStatus(permissions)\n+      .setAclEntries(permissions.getPermission().getAclBit() ?\n+        AclStorage.readINodeLogicalAcl(newNode) : null)\n       .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n       .setClientMachine(newNode.getFileUnderConstructionFeature().getClientMachine());\n     logRpcIds(op, toLogRpcIds);\n     logEdit(op);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logOpenFile(String path, INodeFile newNode, boolean toLogRpcIds) {\n    Preconditions.checkArgument(newNode.isUnderConstruction());\n    PermissionStatus permissions \u003d newNode.getPermissionStatus();\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setInodeId(newNode.getId())\n      .setPath(path)\n      .setReplication(newNode.getFileReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(permissions)\n      .setAclEntries(permissions.getPermission().getAclBit() ?\n        AclStorage.readINodeLogicalAcl(newNode) : null)\n      .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n      .setClientMachine(newNode.getFileUnderConstructionFeature().getClientMachine());\n    logRpcIds(op, toLogRpcIds);\n    logEdit(op);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "ce68f410b05a58ad05965f32ad7f5b246b363a75": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5285. Flatten INodeFile hierarchy: Replace INodeFileUnderConstruction and INodeFileUnderConstructionWithSnapshot with FileUnderContructionFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544389 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/11/13 5:39 PM",
      "commitName": "ce68f410b05a58ad05965f32ad7f5b246b363a75",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5285. Flatten INodeFile hierarchy: Replace INodeFileUnderConstruction and INodeFileUnderConstructionWithSnapshot with FileUnderContructionFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544389 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/11/13 5:39 PM",
          "commitName": "ce68f410b05a58ad05965f32ad7f5b246b363a75",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/11/13 9:12 AM",
          "commitNameOld": "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 0.35,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,16 @@\n-  public void logOpenFile(String path, INodeFileUnderConstruction newNode,\n-      boolean toLogRpcIds) {\n+  public void logOpenFile(String path, INodeFile newNode, boolean toLogRpcIds) {\n+    Preconditions.checkArgument(newNode.isUnderConstruction());\n     AddOp op \u003d AddOp.getInstance(cache.get())\n       .setInodeId(newNode.getId())\n       .setPath(path)\n       .setReplication(newNode.getFileReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(newNode.getPermissionStatus())\n-      .setClientName(newNode.getClientName())\n-      .setClientMachine(newNode.getClientMachine());\n+      .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n+      .setClientMachine(newNode.getFileUnderConstructionFeature().getClientMachine());\n     logRpcIds(op, toLogRpcIds);\n     logEdit(op);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void logOpenFile(String path, INodeFile newNode, boolean toLogRpcIds) {\n    Preconditions.checkArgument(newNode.isUnderConstruction());\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setInodeId(newNode.getId())\n      .setPath(path)\n      .setReplication(newNode.getFileReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(newNode.getPermissionStatus())\n      .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n      .setClientMachine(newNode.getFileUnderConstructionFeature().getClientMachine());\n    logRpcIds(op, toLogRpcIds);\n    logEdit(op);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
          "extendedDetails": {
            "oldValue": "[path-String, newNode-INodeFileUnderConstruction, toLogRpcIds-boolean]",
            "newValue": "[path-String, newNode-INodeFile, toLogRpcIds-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5285. Flatten INodeFile hierarchy: Replace INodeFileUnderConstruction and INodeFileUnderConstructionWithSnapshot with FileUnderContructionFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544389 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/11/13 5:39 PM",
          "commitName": "ce68f410b05a58ad05965f32ad7f5b246b363a75",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/11/13 9:12 AM",
          "commitNameOld": "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 0.35,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,16 @@\n-  public void logOpenFile(String path, INodeFileUnderConstruction newNode,\n-      boolean toLogRpcIds) {\n+  public void logOpenFile(String path, INodeFile newNode, boolean toLogRpcIds) {\n+    Preconditions.checkArgument(newNode.isUnderConstruction());\n     AddOp op \u003d AddOp.getInstance(cache.get())\n       .setInodeId(newNode.getId())\n       .setPath(path)\n       .setReplication(newNode.getFileReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(newNode.getPermissionStatus())\n-      .setClientName(newNode.getClientName())\n-      .setClientMachine(newNode.getClientMachine());\n+      .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n+      .setClientMachine(newNode.getFileUnderConstructionFeature().getClientMachine());\n     logRpcIds(op, toLogRpcIds);\n     logEdit(op);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void logOpenFile(String path, INodeFile newNode, boolean toLogRpcIds) {\n    Preconditions.checkArgument(newNode.isUnderConstruction());\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setInodeId(newNode.getId())\n      .setPath(path)\n      .setReplication(newNode.getFileReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(newNode.getPermissionStatus())\n      .setClientName(newNode.getFileUnderConstructionFeature().getClientName())\n      .setClientMachine(newNode.getFileUnderConstructionFeature().getClientMachine());\n    logRpcIds(op, toLogRpcIds);\n    logEdit(op);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
          "extendedDetails": {}
        }
      ]
    },
    "8c7a7e619699386f9e6991842558d78aa0c8053d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5025. Record ClientId and CallId in EditLog to enable rebuilding retry cache in case of HA failover. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1508332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/07/13 12:51 AM",
      "commitName": "8c7a7e619699386f9e6991842558d78aa0c8053d",
      "commitAuthor": "Suresh Srinivas",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5025. Record ClientId and CallId in EditLog to enable rebuilding retry cache in case of HA failover. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1508332 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/07/13 12:51 AM",
          "commitName": "8c7a7e619699386f9e6991842558d78aa0c8053d",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "07/07/13 10:29 PM",
          "commitNameOld": "6770de7ec4f73e16740f1723f4e35d2fef2c22c8",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 22.1,
          "commitsBetweenForRepo": 149,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,16 @@\n-  public void logOpenFile(String path, INodeFileUnderConstruction newNode) {\n+  public void logOpenFile(String path, INodeFileUnderConstruction newNode,\n+      boolean toLogRpcIds) {\n     AddOp op \u003d AddOp.getInstance(cache.get())\n       .setInodeId(newNode.getId())\n       .setPath(path)\n       .setReplication(newNode.getFileReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(newNode.getPermissionStatus())\n       .setClientName(newNode.getClientName())\n       .setClientMachine(newNode.getClientMachine());\n-    \n-      logEdit(op);\n+    logRpcIds(op, toLogRpcIds);\n+    logEdit(op);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void logOpenFile(String path, INodeFileUnderConstruction newNode,\n      boolean toLogRpcIds) {\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setInodeId(newNode.getId())\n      .setPath(path)\n      .setReplication(newNode.getFileReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(newNode.getPermissionStatus())\n      .setClientName(newNode.getClientName())\n      .setClientMachine(newNode.getClientMachine());\n    logRpcIds(op, toLogRpcIds);\n    logEdit(op);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
          "extendedDetails": {
            "oldValue": "[path-String, newNode-INodeFileUnderConstruction]",
            "newValue": "[path-String, newNode-INodeFileUnderConstruction, toLogRpcIds-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5025. Record ClientId and CallId in EditLog to enable rebuilding retry cache in case of HA failover. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1508332 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/07/13 12:51 AM",
          "commitName": "8c7a7e619699386f9e6991842558d78aa0c8053d",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "07/07/13 10:29 PM",
          "commitNameOld": "6770de7ec4f73e16740f1723f4e35d2fef2c22c8",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 22.1,
          "commitsBetweenForRepo": 149,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,16 @@\n-  public void logOpenFile(String path, INodeFileUnderConstruction newNode) {\n+  public void logOpenFile(String path, INodeFileUnderConstruction newNode,\n+      boolean toLogRpcIds) {\n     AddOp op \u003d AddOp.getInstance(cache.get())\n       .setInodeId(newNode.getId())\n       .setPath(path)\n       .setReplication(newNode.getFileReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(newNode.getPermissionStatus())\n       .setClientName(newNode.getClientName())\n       .setClientMachine(newNode.getClientMachine());\n-    \n-      logEdit(op);\n+    logRpcIds(op, toLogRpcIds);\n+    logEdit(op);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void logOpenFile(String path, INodeFileUnderConstruction newNode,\n      boolean toLogRpcIds) {\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setInodeId(newNode.getId())\n      .setPath(path)\n      .setReplication(newNode.getFileReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(newNode.getPermissionStatus())\n      .setClientName(newNode.getClientName())\n      .setClientMachine(newNode.getClientMachine());\n    logRpcIds(op, toLogRpcIds);\n    logEdit(op);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
          "extendedDetails": {}
        }
      ]
    },
    "19201622be1db8e166d1cc0dd7e62af4702d2784": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4339. Persist inode id in fsimage and editlog. Contributed by Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1465835 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/04/13 4:57 PM",
      "commitName": "19201622be1db8e166d1cc0dd7e62af4702d2784",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "28/01/13 10:56 AM",
      "commitNameOld": "58c0c6f069db15c8bf9024b7b1fe5a78a8d736cf",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 70.21,
      "commitsBetweenForRepo": 331,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,15 @@\n   public void logOpenFile(String path, INodeFileUnderConstruction newNode) {\n     AddOp op \u003d AddOp.getInstance(cache.get())\n+      .setInodeId(newNode.getId())\n       .setPath(path)\n       .setReplication(newNode.getBlockReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(newNode.getPermissionStatus())\n       .setClientName(newNode.getClientName())\n       .setClientMachine(newNode.getClientMachine());\n     \n       logEdit(op);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logOpenFile(String path, INodeFileUnderConstruction newNode) {\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setInodeId(newNode.getId())\n      .setPath(path)\n      .setReplication(newNode.getBlockReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(newNode.getPermissionStatus())\n      .setClientName(newNode.getClientName())\n      .setClientMachine(newNode.getClientMachine());\n    \n      logEdit(op);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "9a0651b4b86727910ae29d055aac6a23490b5ed3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4078. Handle replication in snapshots.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1400743 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/10/12 5:11 PM",
      "commitName": "9a0651b4b86727910ae29d055aac6a23490b5ed3",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "19/10/12 2:15 PM",
      "commitNameOld": "ecffab63af630dac6e51fd2ccf225bf40d31b157",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 2.12,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   public void logOpenFile(String path, INodeFileUnderConstruction newNode) {\n     AddOp op \u003d AddOp.getInstance(cache.get())\n       .setPath(path)\n-      .setReplication(newNode.getBlockReplication())\n+      .setReplication(newNode.getFileReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(newNode.getPermissionStatus())\n       .setClientName(newNode.getClientName())\n       .setClientMachine(newNode.getClientMachine());\n     \n       logEdit(op);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logOpenFile(String path, INodeFileUnderConstruction newNode) {\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setPath(path)\n      .setReplication(newNode.getFileReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(newNode.getPermissionStatus())\n      .setClientName(newNode.getClientName())\n      .setClientMachine(newNode.getClientMachine());\n    \n      logEdit(op);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "ad06a087131d69d173d8e03dce5c97650a530f2e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4037. Rename the getReplication() method in BlockCollection to getBlockReplication(). \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1398288 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/10/12 6:48 AM",
      "commitName": "ad06a087131d69d173d8e03dce5c97650a530f2e",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "24/08/12 1:38 PM",
      "commitNameOld": "a8ff29266934d6d1455cc2f0af16856dbbf1796d",
      "commitAuthorOld": "",
      "daysBetweenCommits": 51.72,
      "commitsBetweenForRepo": 299,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   public void logOpenFile(String path, INodeFileUnderConstruction newNode) {\n     AddOp op \u003d AddOp.getInstance(cache.get())\n       .setPath(path)\n-      .setReplication(newNode.getReplication())\n+      .setReplication(newNode.getBlockReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(newNode.getPermissionStatus())\n       .setClientName(newNode.getClientName())\n       .setClientMachine(newNode.getClientMachine());\n     \n       logEdit(op);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logOpenFile(String path, INodeFileUnderConstruction newNode) {\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setPath(path)\n      .setReplication(newNode.getBlockReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(newNode.getPermissionStatus())\n      .setClientName(newNode.getClientName())\n      .setClientMachine(newNode.getClientMachine());\n    \n      logEdit(op);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "706394d03992b394e9f907aff2155df493e4ea4e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3004. Implement Recovery Mode. Contributed by Colin Patrick McCabe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311394 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/04/12 12:39 PM",
      "commitName": "706394d03992b394e9f907aff2155df493e4ea4e",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "02/04/12 5:55 PM",
      "commitNameOld": "e449de0526ce0aa58bdd0f513b0e2a744a4bbda1",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 6.78,
      "commitsBetweenForRepo": 66,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   public void logOpenFile(String path, INodeFileUnderConstruction newNode) {\n-    AddOp op \u003d AddOp.getInstance()\n+    AddOp op \u003d AddOp.getInstance(cache.get())\n       .setPath(path)\n       .setReplication(newNode.getReplication())\n       .setModificationTime(newNode.getModificationTime())\n       .setAccessTime(newNode.getAccessTime())\n       .setBlockSize(newNode.getPreferredBlockSize())\n       .setBlocks(newNode.getBlocks())\n       .setPermissionStatus(newNode.getPermissionStatus())\n       .setClientName(newNode.getClientName())\n       .setClientMachine(newNode.getClientMachine());\n     \n       logEdit(op);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logOpenFile(String path, INodeFileUnderConstruction newNode) {\n    AddOp op \u003d AddOp.getInstance(cache.get())\n      .setPath(path)\n      .setReplication(newNode.getReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(newNode.getPermissionStatus())\n      .setClientName(newNode.getClientName())\n      .setClientMachine(newNode.getClientMachine());\n    \n      logEdit(op);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void logOpenFile(String path, INodeFileUnderConstruction newNode) {\n    AddOp op \u003d AddOp.getInstance()\n      .setPath(path)\n      .setReplication(newNode.getReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(newNode.getPermissionStatus())\n      .setClientName(newNode.getClientName())\n      .setClientMachine(newNode.getClientMachine());\n    \n      logEdit(op);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void logOpenFile(String path, INodeFileUnderConstruction newNode) {\n    AddOp op \u003d AddOp.getInstance()\n      .setPath(path)\n      .setReplication(newNode.getReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(newNode.getPermissionStatus())\n      .setClientName(newNode.getClientName())\n      .setClientMachine(newNode.getClientMachine());\n    \n      logEdit(op);\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java"
      }
    },
    "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2149. Move EditLogOp serialization formats into FsEditLogOp implementations. Contributed by Ivan Kelly.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1151238 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/07/11 1:46 PM",
      "commitName": "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "30/06/11 11:38 AM",
      "commitNameOld": "5147e283ad9757ac2cabaf282ae5cbba76826ede",
      "commitAuthorOld": "Matthew Foley",
      "daysBetweenCommits": 26.09,
      "commitsBetweenForRepo": 87,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,14 @@\n   public void logOpenFile(String path, INodeFileUnderConstruction newNode) {\n-\n-    DeprecatedUTF8 nameReplicationPair[] \u003d new DeprecatedUTF8[] { \n-      new DeprecatedUTF8(path), \n-      FSEditLog.toLogReplication(newNode.getReplication()),\n-      FSEditLog.toLogLong(newNode.getModificationTime()),\n-      FSEditLog.toLogLong(newNode.getAccessTime()),\n-      FSEditLog.toLogLong(newNode.getPreferredBlockSize())};\n-    logEdit(OP_ADD,\n-            new ArrayWritable(DeprecatedUTF8.class, nameReplicationPair), \n-            new ArrayWritable(Block.class, newNode.getBlocks()),\n-            newNode.getPermissionStatus(),\n-            new DeprecatedUTF8(newNode.getClientName()),\n-            new DeprecatedUTF8(newNode.getClientMachine()));\n+    AddOp op \u003d AddOp.getInstance()\n+      .setPath(path)\n+      .setReplication(newNode.getReplication())\n+      .setModificationTime(newNode.getModificationTime())\n+      .setAccessTime(newNode.getAccessTime())\n+      .setBlockSize(newNode.getPreferredBlockSize())\n+      .setBlocks(newNode.getBlocks())\n+      .setPermissionStatus(newNode.getPermissionStatus())\n+      .setClientName(newNode.getClientName())\n+      .setClientMachine(newNode.getClientMachine());\n+    \n+      logEdit(op);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void logOpenFile(String path, INodeFileUnderConstruction newNode) {\n    AddOp op \u003d AddOp.getInstance()\n      .setPath(path)\n      .setReplication(newNode.getReplication())\n      .setModificationTime(newNode.getModificationTime())\n      .setAccessTime(newNode.getAccessTime())\n      .setBlockSize(newNode.getPreferredBlockSize())\n      .setBlocks(newNode.getBlocks())\n      .setPermissionStatus(newNode.getPermissionStatus())\n      .setClientName(newNode.getClientName())\n      .setClientMachine(newNode.getClientMachine());\n    \n      logEdit(op);\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,15 @@\n+  public void logOpenFile(String path, INodeFileUnderConstruction newNode) {\n+\n+    DeprecatedUTF8 nameReplicationPair[] \u003d new DeprecatedUTF8[] { \n+      new DeprecatedUTF8(path), \n+      FSEditLog.toLogReplication(newNode.getReplication()),\n+      FSEditLog.toLogLong(newNode.getModificationTime()),\n+      FSEditLog.toLogLong(newNode.getAccessTime()),\n+      FSEditLog.toLogLong(newNode.getPreferredBlockSize())};\n+    logEdit(OP_ADD,\n+            new ArrayWritable(DeprecatedUTF8.class, nameReplicationPair), \n+            new ArrayWritable(Block.class, newNode.getBlocks()),\n+            newNode.getPermissionStatus(),\n+            new DeprecatedUTF8(newNode.getClientName()),\n+            new DeprecatedUTF8(newNode.getClientMachine()));\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void logOpenFile(String path, INodeFileUnderConstruction newNode) {\n\n    DeprecatedUTF8 nameReplicationPair[] \u003d new DeprecatedUTF8[] { \n      new DeprecatedUTF8(path), \n      FSEditLog.toLogReplication(newNode.getReplication()),\n      FSEditLog.toLogLong(newNode.getModificationTime()),\n      FSEditLog.toLogLong(newNode.getAccessTime()),\n      FSEditLog.toLogLong(newNode.getPreferredBlockSize())};\n    logEdit(OP_ADD,\n            new ArrayWritable(DeprecatedUTF8.class, nameReplicationPair), \n            new ArrayWritable(Block.class, newNode.getBlocks()),\n            newNode.getPermissionStatus(),\n            new DeprecatedUTF8(newNode.getClientName()),\n            new DeprecatedUTF8(newNode.getClientMachine()));\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java"
    }
  }
}