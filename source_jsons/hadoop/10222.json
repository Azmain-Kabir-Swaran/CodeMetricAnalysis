{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPoolManager.java",
  "functionName": "startAll",
  "functionId": "startAll",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolManager.java",
  "functionStartLine": 122,
  "functionEndLine": 139,
  "numCommitsSeen": 57,
  "timeTaken": 6073,
  "changeHistory": [
    "0e8e499ff482c165d21c8e4f5ff9c33f306ca0d9",
    "f4fa76719e622a4ef883c51ec0abc6e6e6ddf09e",
    "1e346aa829519f8a2aa830e76d9856f914861805",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "0e8e499ff482c165d21c8e4f5ff9c33f306ca0d9": "Ybodychange",
    "f4fa76719e622a4ef883c51ec0abc6e6e6ddf09e": "Ymovefromfile",
    "1e346aa829519f8a2aa830e76d9856f914861805": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "0e8e499ff482c165d21c8e4f5ff9c33f306ca0d9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3659. Add missing @Override to methods across the hadoop-hdfs project. Contributed by Brandon Li. (harsh)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1361894 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/07/12 7:58 PM",
      "commitName": "0e8e499ff482c165d21c8e4f5ff9c33f306ca0d9",
      "commitAuthor": "Harsh J",
      "commitDateOld": "20/05/12 2:13 PM",
      "commitNameOld": "260dfa367e3c161edcc9d2b2217661710199c95e",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 56.24,
      "commitsBetweenForRepo": 276,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,18 @@\n   synchronized void startAll() throws IOException {\n     try {\n       UserGroupInformation.getLoginUser().doAs(\n           new PrivilegedExceptionAction\u003cObject\u003e() {\n+            @Override\n             public Object run() throws Exception {\n               for (BPOfferService bpos : offerServices) {\n                 bpos.start();\n               }\n               return null;\n             }\n           });\n     } catch (InterruptedException ex) {\n       IOException ioe \u003d new IOException();\n       ioe.initCause(ex.getCause());\n       throw ioe;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void startAll() throws IOException {\n    try {\n      UserGroupInformation.getLoginUser().doAs(\n          new PrivilegedExceptionAction\u003cObject\u003e() {\n            @Override\n            public Object run() throws Exception {\n              for (BPOfferService bpos : offerServices) {\n                bpos.start();\n              }\n              return null;\n            }\n          });\n    } catch (InterruptedException ex) {\n      IOException ioe \u003d new IOException();\n      ioe.initCause(ex.getCause());\n      throw ioe;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolManager.java",
      "extendedDetails": {}
    },
    "f4fa76719e622a4ef883c51ec0abc6e6e6ddf09e": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-2612. Handle refreshNameNodes in federated HA clusters. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1209249 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/12/11 1:26 PM",
      "commitName": "f4fa76719e622a4ef883c51ec0abc6e6e6ddf09e",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "01/12/11 12:38 PM",
      "commitNameOld": "4cbead84846f4f65c843fd5101ecc0bd7595c9c5",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.03,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n-    synchronized void startAll() throws IOException {\n-      try {\n-        UserGroupInformation.getLoginUser().doAs(\n-            new PrivilegedExceptionAction\u003cObject\u003e() {\n-              public Object run() throws Exception {\n-                for (BPOfferService bpos : offerServices) {\n-                  bpos.start();\n-                }\n-                return null;\n+  synchronized void startAll() throws IOException {\n+    try {\n+      UserGroupInformation.getLoginUser().doAs(\n+          new PrivilegedExceptionAction\u003cObject\u003e() {\n+            public Object run() throws Exception {\n+              for (BPOfferService bpos : offerServices) {\n+                bpos.start();\n               }\n-            });\n-      } catch (InterruptedException ex) {\n-        IOException ioe \u003d new IOException();\n-        ioe.initCause(ex.getCause());\n-        throw ioe;\n-      }\n-    }\n\\ No newline at end of file\n+              return null;\n+            }\n+          });\n+    } catch (InterruptedException ex) {\n+      IOException ioe \u003d new IOException();\n+      ioe.initCause(ex.getCause());\n+      throw ioe;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void startAll() throws IOException {\n    try {\n      UserGroupInformation.getLoginUser().doAs(\n          new PrivilegedExceptionAction\u003cObject\u003e() {\n            public Object run() throws Exception {\n              for (BPOfferService bpos : offerServices) {\n                bpos.start();\n              }\n              return null;\n            }\n          });\n    } catch (InterruptedException ex) {\n      IOException ioe \u003d new IOException();\n      ioe.initCause(ex.getCause());\n      throw ioe;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolManager.java",
        "oldMethodName": "startAll",
        "newMethodName": "startAll"
      }
    },
    "1e346aa829519f8a2aa830e76d9856f914861805": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1971. Send block report from datanode to both active and standby namenodes. (sanjay, todd via suresh)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1208925 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/11/11 5:10 PM",
      "commitName": "1e346aa829519f8a2aa830e76d9856f914861805",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "30/11/11 10:27 AM",
      "commitNameOld": "0eec2218a16be6092e2d7ea49a97e7807e408499",
      "commitAuthorOld": "",
      "daysBetweenCommits": 0.28,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n     synchronized void startAll() throws IOException {\n       try {\n         UserGroupInformation.getLoginUser().doAs(\n             new PrivilegedExceptionAction\u003cObject\u003e() {\n               public Object run() throws Exception {\n-                for (BPOfferService bpos : nameNodeThreads.values()) {\n+                for (BPOfferService bpos : offerServices) {\n                   bpos.start();\n                 }\n                 return null;\n               }\n             });\n       } catch (InterruptedException ex) {\n         IOException ioe \u003d new IOException();\n         ioe.initCause(ex.getCause());\n         throw ioe;\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    synchronized void startAll() throws IOException {\n      try {\n        UserGroupInformation.getLoginUser().doAs(\n            new PrivilegedExceptionAction\u003cObject\u003e() {\n              public Object run() throws Exception {\n                for (BPOfferService bpos : offerServices) {\n                  bpos.start();\n                }\n                return null;\n              }\n            });\n      } catch (InterruptedException ex) {\n        IOException ioe \u003d new IOException();\n        ioe.initCause(ex.getCause());\n        throw ioe;\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    synchronized void startAll() throws IOException {\n      try {\n        UserGroupInformation.getLoginUser().doAs(\n            new PrivilegedExceptionAction\u003cObject\u003e() {\n              public Object run() throws Exception {\n                for (BPOfferService bpos : nameNodeThreads.values()) {\n                  bpos.start();\n                }\n                return null;\n              }\n            });\n      } catch (InterruptedException ex) {\n        IOException ioe \u003d new IOException();\n        ioe.initCause(ex.getCause());\n        throw ioe;\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    synchronized void startAll() throws IOException {\n      try {\n        UserGroupInformation.getLoginUser().doAs(\n            new PrivilegedExceptionAction\u003cObject\u003e() {\n              public Object run() throws Exception {\n                for (BPOfferService bpos : nameNodeThreads.values()) {\n                  bpos.start();\n                }\n                return null;\n              }\n            });\n      } catch (InterruptedException ex) {\n        IOException ioe \u003d new IOException();\n        ioe.initCause(ex.getCause());\n        throw ioe;\n      }\n    }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,17 @@\n+    synchronized void startAll() throws IOException {\n+      try {\n+        UserGroupInformation.getLoginUser().doAs(\n+            new PrivilegedExceptionAction\u003cObject\u003e() {\n+              public Object run() throws Exception {\n+                for (BPOfferService bpos : nameNodeThreads.values()) {\n+                  bpos.start();\n+                }\n+                return null;\n+              }\n+            });\n+      } catch (InterruptedException ex) {\n+        IOException ioe \u003d new IOException();\n+        ioe.initCause(ex.getCause());\n+        throw ioe;\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    synchronized void startAll() throws IOException {\n      try {\n        UserGroupInformation.getLoginUser().doAs(\n            new PrivilegedExceptionAction\u003cObject\u003e() {\n              public Object run() throws Exception {\n                for (BPOfferService bpos : nameNodeThreads.values()) {\n                  bpos.start();\n                }\n                return null;\n              }\n            });\n      } catch (InterruptedException ex) {\n        IOException ioe \u003d new IOException();\n        ioe.initCause(ex.getCause());\n        throw ioe;\n      }\n    }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java"
    }
  }
}