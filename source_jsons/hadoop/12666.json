{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Mover.java",
  "functionName": "processRecursively",
  "functionId": "processRecursively___parent-String__status-HdfsFileStatus__result-Result",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java",
  "functionStartLine": 348,
  "functionEndLine": 374,
  "numCommitsSeen": 54,
  "timeTaken": 2441,
  "changeHistory": [
    "675e9a8f57570771a0219d95940681b067d36b94",
    "b85603e3f85e85da406241b991f3a9974384c3aa",
    "645a8f2a4d09acb5a21820f52ee78784d9e4cc8a"
  ],
  "changeHistoryShort": {
    "675e9a8f57570771a0219d95940681b067d36b94": "Ybodychange",
    "b85603e3f85e85da406241b991f3a9974384c3aa": "Ybodychange",
    "645a8f2a4d09acb5a21820f52ee78784d9e4cc8a": "Ybodychange"
  },
  "changeHistoryDetails": {
    "675e9a8f57570771a0219d95940681b067d36b94": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-12681. Fold HdfsLocatedFileStatus into HdfsFileStatus.\"\n\nThis reverts commit b85603e3f85e85da406241b991f3a9974384c3aa.\n",
      "commitDate": "15/11/17 7:20 PM",
      "commitName": "675e9a8f57570771a0219d95940681b067d36b94",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "03/11/17 2:30 PM",
      "commitNameOld": "b85603e3f85e85da406241b991f3a9974384c3aa",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 12.24,
      "commitsBetweenForRepo": 169,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,27 @@\n     private void processRecursively(String parent, HdfsFileStatus status,\n         Result result) {\n       String fullPath \u003d status.getFullName(parent);\n       if (status.isDirectory()) {\n         if (!fullPath.endsWith(Path.SEPARATOR)) {\n           fullPath \u003d fullPath + Path.SEPARATOR;\n         }\n \n         processPath(fullPath, result);\n         // process snapshots if this is a snapshottable directory\n         if (snapshottableDirs.contains(fullPath)) {\n           final String dirSnapshot \u003d fullPath + HdfsConstants.DOT_SNAPSHOT_DIR;\n           processPath(dirSnapshot, result);\n         }\n       } else if (!status.isSymlink()) { // file\n         try {\n           if (!isSnapshotPathInCurrent(fullPath)) {\n             // the full path is a snapshot path but it is also included in the\n             // current directory tree, thus ignore it.\n-            processFile(fullPath, status, result);\n+            processFile(fullPath, (HdfsLocatedFileStatus) status, result);\n           }\n         } catch (IOException e) {\n           LOG.warn(\"Failed to check the status of \" + parent\n               + \". Ignore it and continue.\", e);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processRecursively(String parent, HdfsFileStatus status,\n        Result result) {\n      String fullPath \u003d status.getFullName(parent);\n      if (status.isDirectory()) {\n        if (!fullPath.endsWith(Path.SEPARATOR)) {\n          fullPath \u003d fullPath + Path.SEPARATOR;\n        }\n\n        processPath(fullPath, result);\n        // process snapshots if this is a snapshottable directory\n        if (snapshottableDirs.contains(fullPath)) {\n          final String dirSnapshot \u003d fullPath + HdfsConstants.DOT_SNAPSHOT_DIR;\n          processPath(dirSnapshot, result);\n        }\n      } else if (!status.isSymlink()) { // file\n        try {\n          if (!isSnapshotPathInCurrent(fullPath)) {\n            // the full path is a snapshot path but it is also included in the\n            // current directory tree, thus ignore it.\n            processFile(fullPath, (HdfsLocatedFileStatus) status, result);\n          }\n        } catch (IOException e) {\n          LOG.warn(\"Failed to check the status of \" + parent\n              + \". Ignore it and continue.\", e);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java",
      "extendedDetails": {}
    },
    "b85603e3f85e85da406241b991f3a9974384c3aa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12681. Fold HdfsLocatedFileStatus into HdfsFileStatus.\n",
      "commitDate": "03/11/17 2:30 PM",
      "commitName": "b85603e3f85e85da406241b991f3a9974384c3aa",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "14/08/17 9:57 PM",
      "commitNameOld": "645a8f2a4d09acb5a21820f52ee78784d9e4cc8a",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 80.69,
      "commitsBetweenForRepo": 678,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,27 @@\n     private void processRecursively(String parent, HdfsFileStatus status,\n         Result result) {\n       String fullPath \u003d status.getFullName(parent);\n       if (status.isDirectory()) {\n         if (!fullPath.endsWith(Path.SEPARATOR)) {\n           fullPath \u003d fullPath + Path.SEPARATOR;\n         }\n \n         processPath(fullPath, result);\n         // process snapshots if this is a snapshottable directory\n         if (snapshottableDirs.contains(fullPath)) {\n           final String dirSnapshot \u003d fullPath + HdfsConstants.DOT_SNAPSHOT_DIR;\n           processPath(dirSnapshot, result);\n         }\n       } else if (!status.isSymlink()) { // file\n         try {\n           if (!isSnapshotPathInCurrent(fullPath)) {\n             // the full path is a snapshot path but it is also included in the\n             // current directory tree, thus ignore it.\n-            processFile(fullPath, (HdfsLocatedFileStatus) status, result);\n+            processFile(fullPath, status, result);\n           }\n         } catch (IOException e) {\n           LOG.warn(\"Failed to check the status of \" + parent\n               + \". Ignore it and continue.\", e);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processRecursively(String parent, HdfsFileStatus status,\n        Result result) {\n      String fullPath \u003d status.getFullName(parent);\n      if (status.isDirectory()) {\n        if (!fullPath.endsWith(Path.SEPARATOR)) {\n          fullPath \u003d fullPath + Path.SEPARATOR;\n        }\n\n        processPath(fullPath, result);\n        // process snapshots if this is a snapshottable directory\n        if (snapshottableDirs.contains(fullPath)) {\n          final String dirSnapshot \u003d fullPath + HdfsConstants.DOT_SNAPSHOT_DIR;\n          processPath(dirSnapshot, result);\n        }\n      } else if (!status.isSymlink()) { // file\n        try {\n          if (!isSnapshotPathInCurrent(fullPath)) {\n            // the full path is a snapshot path but it is also included in the\n            // current directory tree, thus ignore it.\n            processFile(fullPath, status, result);\n          }\n        } catch (IOException e) {\n          LOG.warn(\"Failed to check the status of \" + parent\n              + \". Ignore it and continue.\", e);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java",
      "extendedDetails": {}
    },
    "645a8f2a4d09acb5a21820f52ee78784d9e4cc8a": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14726. Mark FileStatus::isDir as final\n",
      "commitDate": "14/08/17 9:57 PM",
      "commitName": "645a8f2a4d09acb5a21820f52ee78784d9e4cc8a",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "06/06/17 2:57 PM",
      "commitNameOld": "c31cb879a3595f76d01408e6d066a0bde20be043",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 69.29,
      "commitsBetweenForRepo": 416,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,27 @@\n     private void processRecursively(String parent, HdfsFileStatus status,\n         Result result) {\n       String fullPath \u003d status.getFullName(parent);\n-      if (status.isDir()) {\n+      if (status.isDirectory()) {\n         if (!fullPath.endsWith(Path.SEPARATOR)) {\n           fullPath \u003d fullPath + Path.SEPARATOR;\n         }\n \n         processPath(fullPath, result);\n         // process snapshots if this is a snapshottable directory\n         if (snapshottableDirs.contains(fullPath)) {\n           final String dirSnapshot \u003d fullPath + HdfsConstants.DOT_SNAPSHOT_DIR;\n           processPath(dirSnapshot, result);\n         }\n       } else if (!status.isSymlink()) { // file\n         try {\n           if (!isSnapshotPathInCurrent(fullPath)) {\n             // the full path is a snapshot path but it is also included in the\n             // current directory tree, thus ignore it.\n             processFile(fullPath, (HdfsLocatedFileStatus) status, result);\n           }\n         } catch (IOException e) {\n           LOG.warn(\"Failed to check the status of \" + parent\n               + \". Ignore it and continue.\", e);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processRecursively(String parent, HdfsFileStatus status,\n        Result result) {\n      String fullPath \u003d status.getFullName(parent);\n      if (status.isDirectory()) {\n        if (!fullPath.endsWith(Path.SEPARATOR)) {\n          fullPath \u003d fullPath + Path.SEPARATOR;\n        }\n\n        processPath(fullPath, result);\n        // process snapshots if this is a snapshottable directory\n        if (snapshottableDirs.contains(fullPath)) {\n          final String dirSnapshot \u003d fullPath + HdfsConstants.DOT_SNAPSHOT_DIR;\n          processPath(dirSnapshot, result);\n        }\n      } else if (!status.isSymlink()) { // file\n        try {\n          if (!isSnapshotPathInCurrent(fullPath)) {\n            // the full path is a snapshot path but it is also included in the\n            // current directory tree, thus ignore it.\n            processFile(fullPath, (HdfsLocatedFileStatus) status, result);\n          }\n        } catch (IOException e) {\n          LOG.warn(\"Failed to check the status of \" + parent\n              + \". Ignore it and continue.\", e);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java",
      "extendedDetails": {}
    }
  }
}