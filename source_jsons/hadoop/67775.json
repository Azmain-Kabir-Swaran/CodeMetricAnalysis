{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DynamicInputFormat.java",
  "functionName": "getSplitRatio",
  "functionId": "getSplitRatio___nMaps-int__nRecords-int",
  "sourceFilePath": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/lib/DynamicInputFormat.java",
  "functionStartLine": 312,
  "functionEndLine": 314,
  "numCommitsSeen": 6,
  "timeTaken": 774,
  "changeHistory": [
    "03db13206f131d93347651513496e1b3fcff3dba",
    "d06948002fb0cabf72cc0d46bf2fa67d45370f67"
  ],
  "changeHistoryShort": {
    "03db13206f131d93347651513496e1b3fcff3dba": "Ybodychange",
    "d06948002fb0cabf72cc0d46bf2fa67d45370f67": "Yintroduced"
  },
  "changeHistoryDetails": {
    "03db13206f131d93347651513496e1b3fcff3dba": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5402. In DynamicInputFormat, change MAX_CHUNKS_TOLERABLE, MAX_CHUNKS_IDEAL, MIN_RECORDS_PER_CHUNK and SPLIT_RATIO to be configurable.  Contributed by Tsuyoshi OZAWA\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1592703 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/05/14 3:24 AM",
      "commitName": "03db13206f131d93347651513496e1b3fcff3dba",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "25/01/12 10:36 PM",
      "commitNameOld": "d06948002fb0cabf72cc0d46bf2fa67d45370f67",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 831.16,
      "commitsBetweenForRepo": 5265,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,3 @@\n   static int getSplitRatio(int nMaps, int nRecords) {\n-    if (nMaps \u003d\u003d 1) {\n-      LOG.warn(\"nMaps \u003d\u003d 1. Why use DynamicInputFormat?\");\n-      return 1;\n-    }\n-\n-    if (nMaps \u003e MAX_CHUNKS_IDEAL)\n-      return SPLIT_RATIO_DEFAULT;\n-\n-    int nPickups \u003d (int)Math.ceil((float)MAX_CHUNKS_IDEAL/nMaps);\n-    int nRecordsPerChunk \u003d (int)Math.ceil((float)nRecords/(nMaps*nPickups));\n-\n-    return nRecordsPerChunk \u003c MIN_RECORDS_PER_CHUNK ?\n-              SPLIT_RATIO_DEFAULT : nPickups;\n+    return getSplitRatio(nMaps, nRecords,new Configuration());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static int getSplitRatio(int nMaps, int nRecords) {\n    return getSplitRatio(nMaps, nRecords,new Configuration());\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/lib/DynamicInputFormat.java",
      "extendedDetails": {}
    },
    "d06948002fb0cabf72cc0d46bf2fa67d45370f67": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-2765. DistCp Rewrite. (Mithun Radhakrishnan via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1236045 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/01/12 10:36 PM",
      "commitName": "d06948002fb0cabf72cc0d46bf2fa67d45370f67",
      "commitAuthor": "Mahadev Konar",
      "diff": "@@ -0,0 +1,15 @@\n+  static int getSplitRatio(int nMaps, int nRecords) {\n+    if (nMaps \u003d\u003d 1) {\n+      LOG.warn(\"nMaps \u003d\u003d 1. Why use DynamicInputFormat?\");\n+      return 1;\n+    }\n+\n+    if (nMaps \u003e MAX_CHUNKS_IDEAL)\n+      return SPLIT_RATIO_DEFAULT;\n+\n+    int nPickups \u003d (int)Math.ceil((float)MAX_CHUNKS_IDEAL/nMaps);\n+    int nRecordsPerChunk \u003d (int)Math.ceil((float)nRecords/(nMaps*nPickups));\n+\n+    return nRecordsPerChunk \u003c MIN_RECORDS_PER_CHUNK ?\n+              SPLIT_RATIO_DEFAULT : nPickups;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static int getSplitRatio(int nMaps, int nRecords) {\n    if (nMaps \u003d\u003d 1) {\n      LOG.warn(\"nMaps \u003d\u003d 1. Why use DynamicInputFormat?\");\n      return 1;\n    }\n\n    if (nMaps \u003e MAX_CHUNKS_IDEAL)\n      return SPLIT_RATIO_DEFAULT;\n\n    int nPickups \u003d (int)Math.ceil((float)MAX_CHUNKS_IDEAL/nMaps);\n    int nRecordsPerChunk \u003d (int)Math.ceil((float)nRecords/(nMaps*nPickups));\n\n    return nRecordsPerChunk \u003c MIN_RECORDS_PER_CHUNK ?\n              SPLIT_RATIO_DEFAULT : nPickups;\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/lib/DynamicInputFormat.java"
    }
  }
}