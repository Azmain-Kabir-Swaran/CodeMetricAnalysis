{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "MD5FileUtils.java",
  "functionName": "saveMD5File",
  "functionId": "saveMD5File___dataFile-File__digest-MD5Hash",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/MD5FileUtils.java",
  "functionStartLine": 146,
  "functionEndLine": 150,
  "numCommitsSeen": 10,
  "timeTaken": 2193,
  "changeHistory": [
    "377424e36a25ab34bba9aaed5feaae9d293eb57f",
    "6449f524552f8c24d20b314ad21f6c579fa08e85",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63"
  ],
  "changeHistoryShort": {
    "377424e36a25ab34bba9aaed5feaae9d293eb57f": "Ybodychange",
    "6449f524552f8c24d20b314ad21f6c579fa08e85": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": "Yintroduced"
  },
  "changeHistoryDetails": {
    "377424e36a25ab34bba9aaed5feaae9d293eb57f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5966. Fix rollback of rolling upgrade in NameNode HA setup.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1569885 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/02/14 11:41 AM",
      "commitName": "377424e36a25ab34bba9aaed5feaae9d293eb57f",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "09/01/13 6:30 PM",
      "commitNameOld": "6449f524552f8c24d20b314ad21f6c579fa08e85",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 405.72,
      "commitsBetweenForRepo": 2485,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,5 @@\n   public static void saveMD5File(File dataFile, MD5Hash digest)\n       throws IOException {\n-    File md5File \u003d getDigestFileForFile(dataFile);\n-    String digestString \u003d StringUtils.byteToHexString(\n-        digest.getDigest());\n-    String md5Line \u003d digestString + \" *\" + dataFile.getName() + \"\\n\";\n-    \n-    AtomicFileOutputStream afos \u003d new AtomicFileOutputStream(md5File);\n-    afos.write(md5Line.getBytes(Charsets.UTF_8));\n-    afos.close();\n-    LOG.debug(\"Saved MD5 \" + digest + \" to \" + md5File);\n+    final String digestString \u003d StringUtils.byteToHexString(digest.getDigest());\n+    saveMD5File(dataFile, digestString);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void saveMD5File(File dataFile, MD5Hash digest)\n      throws IOException {\n    final String digestString \u003d StringUtils.byteToHexString(digest.getDigest());\n    saveMD5File(dataFile, digestString);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/MD5FileUtils.java",
      "extendedDetails": {}
    },
    "6449f524552f8c24d20b314ad21f6c579fa08e85": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4032. Specify the charset explicitly rather than rely on the default. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1431179 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/13 6:30 PM",
      "commitName": "6449f524552f8c24d20b314ad21f6c579fa08e85",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "27/10/11 3:11 PM",
      "commitNameOld": "646e855f6ef058b636a5fc85637a3f8e17fddaba",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 440.18,
      "commitsBetweenForRepo": 2689,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   public static void saveMD5File(File dataFile, MD5Hash digest)\n       throws IOException {\n     File md5File \u003d getDigestFileForFile(dataFile);\n     String digestString \u003d StringUtils.byteToHexString(\n         digest.getDigest());\n     String md5Line \u003d digestString + \" *\" + dataFile.getName() + \"\\n\";\n     \n     AtomicFileOutputStream afos \u003d new AtomicFileOutputStream(md5File);\n-    afos.write(md5Line.getBytes());\n+    afos.write(md5Line.getBytes(Charsets.UTF_8));\n     afos.close();\n     LOG.debug(\"Saved MD5 \" + digest + \" to \" + md5File);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void saveMD5File(File dataFile, MD5Hash digest)\n      throws IOException {\n    File md5File \u003d getDigestFileForFile(dataFile);\n    String digestString \u003d StringUtils.byteToHexString(\n        digest.getDigest());\n    String md5Line \u003d digestString + \" *\" + dataFile.getName() + \"\\n\";\n    \n    AtomicFileOutputStream afos \u003d new AtomicFileOutputStream(md5File);\n    afos.write(md5Line.getBytes(Charsets.UTF_8));\n    afos.close();\n    LOG.debug(\"Saved MD5 \" + digest + \" to \" + md5File);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/MD5FileUtils.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public static void saveMD5File(File dataFile, MD5Hash digest)\n      throws IOException {\n    File md5File \u003d getDigestFileForFile(dataFile);\n    String digestString \u003d StringUtils.byteToHexString(\n        digest.getDigest());\n    String md5Line \u003d digestString + \" *\" + dataFile.getName() + \"\\n\";\n    \n    AtomicFileOutputStream afos \u003d new AtomicFileOutputStream(md5File);\n    afos.write(md5Line.getBytes());\n    afos.close();\n    LOG.debug(\"Saved MD5 \" + digest + \" to \" + md5File);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/MD5FileUtils.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/MD5FileUtils.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/MD5FileUtils.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public static void saveMD5File(File dataFile, MD5Hash digest)\n      throws IOException {\n    File md5File \u003d getDigestFileForFile(dataFile);\n    String digestString \u003d StringUtils.byteToHexString(\n        digest.getDigest());\n    String md5Line \u003d digestString + \" *\" + dataFile.getName() + \"\\n\";\n    \n    AtomicFileOutputStream afos \u003d new AtomicFileOutputStream(md5File);\n    afos.write(md5Line.getBytes());\n    afos.close();\n    LOG.debug(\"Saved MD5 \" + digest + \" to \" + md5File);\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/MD5FileUtils.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/util/MD5FileUtils.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/MD5FileUtils.java"
      }
    },
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/11 9:28 AM",
      "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,12 @@\n+  public static void saveMD5File(File dataFile, MD5Hash digest)\n+      throws IOException {\n+    File md5File \u003d getDigestFileForFile(dataFile);\n+    String digestString \u003d StringUtils.byteToHexString(\n+        digest.getDigest());\n+    String md5Line \u003d digestString + \" *\" + dataFile.getName() + \"\\n\";\n+    \n+    AtomicFileOutputStream afos \u003d new AtomicFileOutputStream(md5File);\n+    afos.write(md5Line.getBytes());\n+    afos.close();\n+    LOG.debug(\"Saved MD5 \" + digest + \" to \" + md5File);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static void saveMD5File(File dataFile, MD5Hash digest)\n      throws IOException {\n    File md5File \u003d getDigestFileForFile(dataFile);\n    String digestString \u003d StringUtils.byteToHexString(\n        digest.getDigest());\n    String md5Line \u003d digestString + \" *\" + dataFile.getName() + \"\\n\";\n    \n    AtomicFileOutputStream afos \u003d new AtomicFileOutputStream(md5File);\n    afos.write(md5Line.getBytes());\n    afos.close();\n    LOG.debug(\"Saved MD5 \" + digest + \" to \" + md5File);\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/util/MD5FileUtils.java"
    }
  }
}