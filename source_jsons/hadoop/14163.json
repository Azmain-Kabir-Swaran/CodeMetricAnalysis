{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "QuorumJournalManager.java",
  "functionName": "startLogSegment",
  "functionId": "startLogSegment___txId-long__layoutVersion-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
  "functionStartLine": 430,
  "functionEndLine": 440,
  "numCommitsSeen": 62,
  "timeTaken": 3676,
  "changeHistory": [
    "abc8fde4caea0e197568ee28392c46f1ce0d42e1",
    "1e22f2bfbb1d9a29f5d4fa641b7a0dabd5b1dbf5",
    "098ec2b11ff3f677eb823f75b147a1ac8dbf959e",
    "9dab514b22f49322738935cfd915c2b4eba50b88",
    "663e7484c04c197eed53f10a7808140f1c955277",
    "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38",
    "42cdc1b0835abb4a331d40f30f2c210143b747bc",
    "74d4573a23db5586c6e47ff2277aa7c35237da34"
  ],
  "changeHistoryShort": {
    "abc8fde4caea0e197568ee28392c46f1ce0d42e1": "Ybodychange",
    "1e22f2bfbb1d9a29f5d4fa641b7a0dabd5b1dbf5": "Ybodychange",
    "098ec2b11ff3f677eb823f75b147a1ac8dbf959e": "Ybodychange",
    "9dab514b22f49322738935cfd915c2b4eba50b88": "Ymultichange(Yparameterchange,Ybodychange)",
    "663e7484c04c197eed53f10a7808140f1c955277": "Ybodychange",
    "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38": "Ybodychange",
    "42cdc1b0835abb4a331d40f30f2c210143b747bc": "Ybodychange",
    "74d4573a23db5586c6e47ff2277aa7c35237da34": "Yintroduced"
  },
  "changeHistoryDetails": {
    "abc8fde4caea0e197568ee28392c46f1ce0d42e1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13596. NN restart fails after RollingUpgrade from 2.x to 3.x. Contributed by Fei Hui.\n",
      "commitDate": "22/08/19 10:44 PM",
      "commitName": "abc8fde4caea0e197568ee28392c46f1ce0d42e1",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "26/03/19 11:27 AM",
      "commitNameOld": "55fb3c32fb48ca26a629d4d5f3f07e2858d09594",
      "commitAuthorOld": "Takanobu Asanuma",
      "daysBetweenCommits": 149.47,
      "commitsBetweenForRepo": 1133,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n   public EditLogOutputStream startLogSegment(long txId, int layoutVersion)\n       throws IOException {\n     Preconditions.checkState(isActiveWriter,\n         \"must recover segments before starting a new one\");\n     QuorumCall\u003cAsyncLogger, Void\u003e q \u003d loggers.startLogSegment(txId,\n         layoutVersion);\n     loggers.waitForWriteQuorum(q, startSegmentTimeoutMs,\n         \"startLogSegment(\" + txId + \")\");\n     return new QuorumOutputStream(loggers, txId, outputBufferCapacity,\n-        writeTxnsTimeoutMs);\n+        writeTxnsTimeoutMs, layoutVersion);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public EditLogOutputStream startLogSegment(long txId, int layoutVersion)\n      throws IOException {\n    Preconditions.checkState(isActiveWriter,\n        \"must recover segments before starting a new one\");\n    QuorumCall\u003cAsyncLogger, Void\u003e q \u003d loggers.startLogSegment(txId,\n        layoutVersion);\n    loggers.waitForWriteQuorum(q, startSegmentTimeoutMs,\n        \"startLogSegment(\" + txId + \")\");\n    return new QuorumOutputStream(loggers, txId, outputBufferCapacity,\n        writeTxnsTimeoutMs, layoutVersion);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
      "extendedDetails": {}
    },
    "1e22f2bfbb1d9a29f5d4fa641b7a0dabd5b1dbf5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13610. [SBN read] Edit Tail Fast Path Part 4: Cleanup. Integration test, documentation, remove unnecessary dummy sync, minors fixups. Contributed by Erik Krogen.\n",
      "commitDate": "24/12/18 9:34 AM",
      "commitName": "1e22f2bfbb1d9a29f5d4fa641b7a0dabd5b1dbf5",
      "commitAuthor": "Erik Krogen",
      "commitDateOld": "24/12/18 9:33 AM",
      "commitNameOld": "00e99c65943e64fd696ec715cf21e851b93115f1",
      "commitAuthorOld": "Erik Krogen",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,11 @@\n   public EditLogOutputStream startLogSegment(long txId, int layoutVersion)\n       throws IOException {\n     Preconditions.checkState(isActiveWriter,\n         \"must recover segments before starting a new one\");\n     QuorumCall\u003cAsyncLogger, Void\u003e q \u003d loggers.startLogSegment(txId,\n         layoutVersion);\n     loggers.waitForWriteQuorum(q, startSegmentTimeoutMs,\n         \"startLogSegment(\" + txId + \")\");\n-    boolean updateCommittedTxId \u003d conf.getBoolean(\n-        DFSConfigKeys.DFS_HA_TAILEDITS_INPROGRESS_KEY,\n-        DFSConfigKeys.DFS_HA_TAILEDITS_INPROGRESS_DEFAULT);\n     return new QuorumOutputStream(loggers, txId, outputBufferCapacity,\n-        writeTxnsTimeoutMs, updateCommittedTxId);\n+        writeTxnsTimeoutMs);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public EditLogOutputStream startLogSegment(long txId, int layoutVersion)\n      throws IOException {\n    Preconditions.checkState(isActiveWriter,\n        \"must recover segments before starting a new one\");\n    QuorumCall\u003cAsyncLogger, Void\u003e q \u003d loggers.startLogSegment(txId,\n        layoutVersion);\n    loggers.waitForWriteQuorum(q, startSegmentTimeoutMs,\n        \"startLogSegment(\" + txId + \")\");\n    return new QuorumOutputStream(loggers, txId, outputBufferCapacity,\n        writeTxnsTimeoutMs);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
      "extendedDetails": {}
    },
    "098ec2b11ff3f677eb823f75b147a1ac8dbf959e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10519. Add a configuration option to enable in-progress edit log tailing. Contributed by Jiayi Zhou.\n",
      "commitDate": "27/07/16 5:55 PM",
      "commitName": "098ec2b11ff3f677eb823f75b147a1ac8dbf959e",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "24/03/14 11:48 PM",
      "commitNameOld": "56205ca7d7f3b2a7e55f48b9cf444326e1d2b1a7",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 855.76,
      "commitsBetweenForRepo": 6651,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,14 @@\n   public EditLogOutputStream startLogSegment(long txId, int layoutVersion)\n       throws IOException {\n     Preconditions.checkState(isActiveWriter,\n         \"must recover segments before starting a new one\");\n     QuorumCall\u003cAsyncLogger, Void\u003e q \u003d loggers.startLogSegment(txId,\n         layoutVersion);\n     loggers.waitForWriteQuorum(q, startSegmentTimeoutMs,\n         \"startLogSegment(\" + txId + \")\");\n-    return new QuorumOutputStream(loggers, txId,\n-        outputBufferCapacity, writeTxnsTimeoutMs);\n+    boolean updateCommittedTxId \u003d conf.getBoolean(\n+        DFSConfigKeys.DFS_HA_TAILEDITS_INPROGRESS_KEY,\n+        DFSConfigKeys.DFS_HA_TAILEDITS_INPROGRESS_DEFAULT);\n+    return new QuorumOutputStream(loggers, txId, outputBufferCapacity,\n+        writeTxnsTimeoutMs, updateCommittedTxId);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public EditLogOutputStream startLogSegment(long txId, int layoutVersion)\n      throws IOException {\n    Preconditions.checkState(isActiveWriter,\n        \"must recover segments before starting a new one\");\n    QuorumCall\u003cAsyncLogger, Void\u003e q \u003d loggers.startLogSegment(txId,\n        layoutVersion);\n    loggers.waitForWriteQuorum(q, startSegmentTimeoutMs,\n        \"startLogSegment(\" + txId + \")\");\n    boolean updateCommittedTxId \u003d conf.getBoolean(\n        DFSConfigKeys.DFS_HA_TAILEDITS_INPROGRESS_KEY,\n        DFSConfigKeys.DFS_HA_TAILEDITS_INPROGRESS_DEFAULT);\n    return new QuorumOutputStream(loggers, txId, outputBufferCapacity,\n        writeTxnsTimeoutMs, updateCommittedTxId);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
      "extendedDetails": {}
    },
    "9dab514b22f49322738935cfd915c2b4eba50b88": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6038. Allow JournalNode to handle editlog produced by new release with future layoutversion. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1579813 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/03/14 4:06 PM",
      "commitName": "9dab514b22f49322738935cfd915c2b4eba50b88",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6038. Allow JournalNode to handle editlog produced by new release with future layoutversion. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1579813 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/03/14 4:06 PM",
          "commitName": "9dab514b22f49322738935cfd915c2b4eba50b88",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "14/02/14 4:28 PM",
          "commitNameOld": "470d4253b246670f220eec81dd617ba0ee979623",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 33.94,
          "commitsBetweenForRepo": 299,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,11 @@\n-  public EditLogOutputStream startLogSegment(long txId) throws IOException {\n+  public EditLogOutputStream startLogSegment(long txId, int layoutVersion)\n+      throws IOException {\n     Preconditions.checkState(isActiveWriter,\n         \"must recover segments before starting a new one\");\n-    QuorumCall\u003cAsyncLogger,Void\u003e q \u003d loggers.startLogSegment(txId);\n+    QuorumCall\u003cAsyncLogger, Void\u003e q \u003d loggers.startLogSegment(txId,\n+        layoutVersion);\n     loggers.waitForWriteQuorum(q, startSegmentTimeoutMs,\n         \"startLogSegment(\" + txId + \")\");\n     return new QuorumOutputStream(loggers, txId,\n         outputBufferCapacity, writeTxnsTimeoutMs);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public EditLogOutputStream startLogSegment(long txId, int layoutVersion)\n      throws IOException {\n    Preconditions.checkState(isActiveWriter,\n        \"must recover segments before starting a new one\");\n    QuorumCall\u003cAsyncLogger, Void\u003e q \u003d loggers.startLogSegment(txId,\n        layoutVersion);\n    loggers.waitForWriteQuorum(q, startSegmentTimeoutMs,\n        \"startLogSegment(\" + txId + \")\");\n    return new QuorumOutputStream(loggers, txId,\n        outputBufferCapacity, writeTxnsTimeoutMs);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
          "extendedDetails": {
            "oldValue": "[txId-long]",
            "newValue": "[txId-long, layoutVersion-int]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6038. Allow JournalNode to handle editlog produced by new release with future layoutversion. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1579813 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/03/14 4:06 PM",
          "commitName": "9dab514b22f49322738935cfd915c2b4eba50b88",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "14/02/14 4:28 PM",
          "commitNameOld": "470d4253b246670f220eec81dd617ba0ee979623",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 33.94,
          "commitsBetweenForRepo": 299,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,11 @@\n-  public EditLogOutputStream startLogSegment(long txId) throws IOException {\n+  public EditLogOutputStream startLogSegment(long txId, int layoutVersion)\n+      throws IOException {\n     Preconditions.checkState(isActiveWriter,\n         \"must recover segments before starting a new one\");\n-    QuorumCall\u003cAsyncLogger,Void\u003e q \u003d loggers.startLogSegment(txId);\n+    QuorumCall\u003cAsyncLogger, Void\u003e q \u003d loggers.startLogSegment(txId,\n+        layoutVersion);\n     loggers.waitForWriteQuorum(q, startSegmentTimeoutMs,\n         \"startLogSegment(\" + txId + \")\");\n     return new QuorumOutputStream(loggers, txId,\n         outputBufferCapacity, writeTxnsTimeoutMs);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public EditLogOutputStream startLogSegment(long txId, int layoutVersion)\n      throws IOException {\n    Preconditions.checkState(isActiveWriter,\n        \"must recover segments before starting a new one\");\n    QuorumCall\u003cAsyncLogger, Void\u003e q \u003d loggers.startLogSegment(txId,\n        layoutVersion);\n    loggers.waitForWriteQuorum(q, startSegmentTimeoutMs,\n        \"startLogSegment(\" + txId + \")\");\n    return new QuorumOutputStream(loggers, txId,\n        outputBufferCapacity, writeTxnsTimeoutMs);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "663e7484c04c197eed53f10a7808140f1c955277": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3950. QJM: misc TODO cleanup, improved log messages, etc. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1387704 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/09/12 11:52 AM",
      "commitName": "663e7484c04c197eed53f10a7808140f1c955277",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "10/09/12 11:31 PM",
      "commitNameOld": "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 8.51,
      "commitsBetweenForRepo": 40,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,9 @@\n   public EditLogOutputStream startLogSegment(long txId) throws IOException {\n     Preconditions.checkState(isActiveWriter,\n         \"must recover segments before starting a new one\");\n     QuorumCall\u003cAsyncLogger,Void\u003e q \u003d loggers.startLogSegment(txId);\n     loggers.waitForWriteQuorum(q, startSegmentTimeoutMs,\n         \"startLogSegment(\" + txId + \")\");\n-    return new QuorumOutputStream(loggers, txId);\n+    return new QuorumOutputStream(loggers, txId,\n+        outputBufferCapacity, writeTxnsTimeoutMs);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public EditLogOutputStream startLogSegment(long txId) throws IOException {\n    Preconditions.checkState(isActiveWriter,\n        \"must recover segments before starting a new one\");\n    QuorumCall\u003cAsyncLogger,Void\u003e q \u003d loggers.startLogSegment(txId);\n    loggers.waitForWriteQuorum(q, startSegmentTimeoutMs,\n        \"startLogSegment(\" + txId + \")\");\n    return new QuorumOutputStream(loggers, txId,\n        outputBufferCapacity, writeTxnsTimeoutMs);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
      "extendedDetails": {}
    },
    "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3906. QJM: quorum timeout on failover with large log segment. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1383251 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/09/12 11:31 PM",
      "commitName": "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "05/09/12 11:57 PM",
      "commitNameOld": "437948ea1c0c9c61c2b5049b82ffd9525f33be97",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 4.98,
      "commitsBetweenForRepo": 37,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,8 @@\n   public EditLogOutputStream startLogSegment(long txId) throws IOException {\n     Preconditions.checkState(isActiveWriter,\n         \"must recover segments before starting a new one\");\n     QuorumCall\u003cAsyncLogger,Void\u003e q \u003d loggers.startLogSegment(txId);\n-    loggers.waitForWriteQuorum(q, startSegmentTimeoutMs);\n+    loggers.waitForWriteQuorum(q, startSegmentTimeoutMs,\n+        \"startLogSegment(\" + txId + \")\");\n     return new QuorumOutputStream(loggers, txId);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public EditLogOutputStream startLogSegment(long txId) throws IOException {\n    Preconditions.checkState(isActiveWriter,\n        \"must recover segments before starting a new one\");\n    QuorumCall\u003cAsyncLogger,Void\u003e q \u003d loggers.startLogSegment(txId);\n    loggers.waitForWriteQuorum(q, startSegmentTimeoutMs,\n        \"startLogSegment(\" + txId + \")\");\n    return new QuorumOutputStream(loggers, txId);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
      "extendedDetails": {}
    },
    "42cdc1b0835abb4a331d40f30f2c210143b747bc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3797. QJM: add segment txid as a parameter to journal() RPC. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1373571 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/08/12 11:58 AM",
      "commitName": "42cdc1b0835abb4a331d40f30f2c210143b747bc",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "14/08/12 5:57 PM",
      "commitNameOld": "c95a1674b61ef2a6963dc64604986ef90a8c636d",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.75,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n   public EditLogOutputStream startLogSegment(long txId) throws IOException {\n     Preconditions.checkState(isActiveWriter,\n         \"must recover segments before starting a new one\");\n     QuorumCall\u003cAsyncLogger,Void\u003e q \u003d loggers.startLogSegment(txId);\n     loggers.waitForWriteQuorum(q, startSegmentTimeoutMs);\n-    return new QuorumOutputStream(loggers);\n+    return new QuorumOutputStream(loggers, txId);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public EditLogOutputStream startLogSegment(long txId) throws IOException {\n    Preconditions.checkState(isActiveWriter,\n        \"must recover segments before starting a new one\");\n    QuorumCall\u003cAsyncLogger,Void\u003e q \u003d loggers.startLogSegment(txId);\n    loggers.waitForWriteQuorum(q, startSegmentTimeoutMs);\n    return new QuorumOutputStream(loggers, txId);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
      "extendedDetails": {}
    },
    "74d4573a23db5586c6e47ff2277aa7c35237da34": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1363596 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/07/12 5:25 PM",
      "commitName": "74d4573a23db5586c6e47ff2277aa7c35237da34",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,7 @@\n+  public EditLogOutputStream startLogSegment(long txId) throws IOException {\n+    Preconditions.checkState(isActiveWriter,\n+        \"must recover segments before starting a new one\");\n+    QuorumCall\u003cAsyncLogger,Void\u003e q \u003d loggers.startLogSegment(txId);\n+    loggers.waitForWriteQuorum(q, startSegmentTimeoutMs);\n+    return new QuorumOutputStream(loggers);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public EditLogOutputStream startLogSegment(long txId) throws IOException {\n    Preconditions.checkState(isActiveWriter,\n        \"must recover segments before starting a new one\");\n    QuorumCall\u003cAsyncLogger,Void\u003e q \u003d loggers.startLogSegment(txId);\n    loggers.waitForWriteQuorum(q, startSegmentTimeoutMs);\n    return new QuorumOutputStream(loggers);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java"
    }
  }
}