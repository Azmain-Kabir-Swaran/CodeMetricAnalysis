{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FsDatasetImpl.java",
  "functionName": "getFailedStorageLocations",
  "functionId": "getFailedStorageLocations",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
  "functionStartLine": 685,
  "functionEndLine": 695,
  "numCommitsSeen": 197,
  "timeTaken": 6036,
  "changeHistory": [
    "f209e93566b159c22054dcb276e45f23a2b7b7d1",
    "96b12662ea76e3ded4ef13944fc8df206cfb4613",
    "9729b244de50322c2cc889c97c2ffb2b4675cf77"
  ],
  "changeHistoryShort": {
    "f209e93566b159c22054dcb276e45f23a2b7b7d1": "Ybodychange",
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": "Ybodychange",
    "9729b244de50322c2cc889c97c2ffb2b4675cf77": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f209e93566b159c22054dcb276e45f23a2b7b7d1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10638. Modifications to remove the assumption that StorageLocation is associated with java.io.File in Datanode. (Virajith Jalaparti via lei)\n",
      "commitDate": "26/10/16 10:32 AM",
      "commitName": "f209e93566b159c22054dcb276e45f23a2b7b7d1",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "21/10/16 12:59 PM",
      "commitNameOld": "ae8bccd5090d8b42dae9a8e0c13a9766a7c42ecb",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 4.9,
      "commitsBetweenForRepo": 41,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n   public String[] getFailedStorageLocations() {\n     VolumeFailureInfo[] infos \u003d volumes.getVolumeFailureInfos();\n     List\u003cString\u003e failedStorageLocations \u003d Lists.newArrayListWithCapacity(\n         infos.length);\n     for (VolumeFailureInfo info: infos) {\n       failedStorageLocations.add(\n-          info.getFailedStorageLocation().getFile().getAbsolutePath());\n+          info.getFailedStorageLocation().getNormalizedUri().toString());\n     }\n     return failedStorageLocations.toArray(\n         new String[failedStorageLocations.size()]);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String[] getFailedStorageLocations() {\n    VolumeFailureInfo[] infos \u003d volumes.getVolumeFailureInfos();\n    List\u003cString\u003e failedStorageLocations \u003d Lists.newArrayListWithCapacity(\n        infos.length);\n    for (VolumeFailureInfo info: infos) {\n      failedStorageLocations.add(\n          info.getFailedStorageLocation().getNormalizedUri().toString());\n    }\n    return failedStorageLocations.toArray(\n        new String[failedStorageLocations.size()]);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10637. Modifications to remove the assumption that FsVolumes are backed by java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "10/10/16 3:30 PM",
      "commitName": "96b12662ea76e3ded4ef13944fc8df206cfb4613",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "30/09/16 11:11 PM",
      "commitNameOld": "fe9ebe20ab113567f0777c11cb48ce0d3ce587a8",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 9.68,
      "commitsBetweenForRepo": 64,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,11 @@\n   public String[] getFailedStorageLocations() {\n     VolumeFailureInfo[] infos \u003d volumes.getVolumeFailureInfos();\n     List\u003cString\u003e failedStorageLocations \u003d Lists.newArrayListWithCapacity(\n         infos.length);\n     for (VolumeFailureInfo info: infos) {\n-      failedStorageLocations.add(info.getFailedStorageLocation());\n+      failedStorageLocations.add(\n+          info.getFailedStorageLocation().getFile().getAbsolutePath());\n     }\n     return failedStorageLocations.toArray(\n         new String[failedStorageLocations.size()]);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String[] getFailedStorageLocations() {\n    VolumeFailureInfo[] infos \u003d volumes.getVolumeFailureInfos();\n    List\u003cString\u003e failedStorageLocations \u003d Lists.newArrayListWithCapacity(\n        infos.length);\n    for (VolumeFailureInfo info: infos) {\n      failedStorageLocations.add(\n          info.getFailedStorageLocation().getFile().getAbsolutePath());\n    }\n    return failedStorageLocations.toArray(\n        new String[failedStorageLocations.size()]);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "9729b244de50322c2cc889c97c2ffb2b4675cf77": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7604. Track and display failed DataNode storage locations in NameNode. Contributed by Chris Nauroth.\n",
      "commitDate": "16/02/15 2:43 PM",
      "commitName": "9729b244de50322c2cc889c97c2ffb2b4675cf77",
      "commitAuthor": "cnauroth",
      "diff": "@@ -0,0 +1,10 @@\n+  public String[] getFailedStorageLocations() {\n+    VolumeFailureInfo[] infos \u003d volumes.getVolumeFailureInfos();\n+    List\u003cString\u003e failedStorageLocations \u003d Lists.newArrayListWithCapacity(\n+        infos.length);\n+    for (VolumeFailureInfo info: infos) {\n+      failedStorageLocations.add(info.getFailedStorageLocation());\n+    }\n+    return failedStorageLocations.toArray(\n+        new String[failedStorageLocations.size()]);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public String[] getFailedStorageLocations() {\n    VolumeFailureInfo[] infos \u003d volumes.getVolumeFailureInfos();\n    List\u003cString\u003e failedStorageLocations \u003d Lists.newArrayListWithCapacity(\n        infos.length);\n    for (VolumeFailureInfo info: infos) {\n      failedStorageLocations.add(info.getFailedStorageLocation());\n    }\n    return failedStorageLocations.toArray(\n        new String[failedStorageLocations.size()]);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java"
    }
  }
}