{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSDirRenameOp.java",
  "functionName": "cleanDst",
  "functionId": "cleanDst___bsps-BlockStoragePolicySuite__collectedBlocks-BlocksMapUpdateInfo",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirRenameOp.java",
  "functionStartLine": 784,
  "functionEndLine": 806,
  "numCommitsSeen": 48,
  "timeTaken": 4396,
  "changeHistory": [
    "4c57fb0cd9344290a9f4f6422c1457d69465eec7",
    "745d04be59accf80feda0ad38efcc74ba362f2ca",
    "b2c85db86c9a62b0a03ee87547265077f664970a",
    "4536399d47f6c061e149e2504600804a0f1e093d",
    "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
    "5dae97a584d30cef3e34141edfaca49c4ec57913",
    "8cb473124c1cf1c6f68ead7bde06558ebf7ce47e",
    "24315e7d374a1ddd4329b64350cf96fc9ab6f59c",
    "5caebbae8c2fc9ba2e32384657aee21641a1a6d0"
  ],
  "changeHistoryShort": {
    "4c57fb0cd9344290a9f4f6422c1457d69465eec7": "Yexceptionschange",
    "745d04be59accf80feda0ad38efcc74ba362f2ca": "Ybodychange",
    "b2c85db86c9a62b0a03ee87547265077f664970a": "Ybodychange",
    "4536399d47f6c061e149e2504600804a0f1e093d": "Ybodychange",
    "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63": "Ybodychange",
    "5dae97a584d30cef3e34141edfaca49c4ec57913": "Ymultichange(Yparameterchange,Ybodychange)",
    "8cb473124c1cf1c6f68ead7bde06558ebf7ce47e": "Ybodychange",
    "24315e7d374a1ddd4329b64350cf96fc9ab6f59c": "Ybodychange",
    "5caebbae8c2fc9ba2e32384657aee21641a1a6d0": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4c57fb0cd9344290a9f4f6422c1457d69465eec7": {
      "type": "Yexceptionschange",
      "commitMessage": "HDFS-13257. Code cleanup: INode never throws QuotaExceededException. Contributed by Tsz Wo Nicholas Sze.\n",
      "commitDate": "14/03/18 9:42 AM",
      "commitName": "4c57fb0cd9344290a9f4f6422c1457d69465eec7",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "09/03/18 3:50 PM",
      "commitNameOld": "ba0da2785d251745969f88a50d33ce61876d91aa",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 4.7,
      "commitsBetweenForRepo": 41,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,23 @@\n-    boolean cleanDst(BlockStoragePolicySuite bsps, BlocksMapUpdateInfo collectedBlocks)\n-        throws QuotaExceededException {\n+    boolean cleanDst(\n+        BlockStoragePolicySuite bsps, BlocksMapUpdateInfo collectedBlocks) {\n       Preconditions.checkState(oldDstChild !\u003d null);\n       List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n       List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n       INode.ReclaimContext context \u003d new INode.ReclaimContext(\n           bsps, collectedBlocks, removedINodes, removedUCFiles);\n       final boolean filesDeleted;\n       if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n         oldDstChild.destroyAndCollectBlocks(context);\n         filesDeleted \u003d true;\n       } else {\n         oldDstChild.cleanSubtree(context, Snapshot.CURRENT_STATE_ID,\n             dstIIP.getLatestSnapshotId());\n         filesDeleted \u003d context.quotaDelta().getNsDelta() \u003e\u003d 0;\n       }\n       fsd.updateReplicationFactor(context.collectedBlocks()\n                                       .toUpdateReplicationInfo());\n \n       fsd.getFSNamesystem().removeLeasesAndINodes(\n           removedUCFiles, removedINodes, false);\n       return filesDeleted;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    boolean cleanDst(\n        BlockStoragePolicySuite bsps, BlocksMapUpdateInfo collectedBlocks) {\n      Preconditions.checkState(oldDstChild !\u003d null);\n      List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n      List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n      INode.ReclaimContext context \u003d new INode.ReclaimContext(\n          bsps, collectedBlocks, removedINodes, removedUCFiles);\n      final boolean filesDeleted;\n      if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n        oldDstChild.destroyAndCollectBlocks(context);\n        filesDeleted \u003d true;\n      } else {\n        oldDstChild.cleanSubtree(context, Snapshot.CURRENT_STATE_ID,\n            dstIIP.getLatestSnapshotId());\n        filesDeleted \u003d context.quotaDelta().getNsDelta() \u003e\u003d 0;\n      }\n      fsd.updateReplicationFactor(context.collectedBlocks()\n                                      .toUpdateReplicationInfo());\n\n      fsd.getFSNamesystem().removeLeasesAndINodes(\n          removedUCFiles, removedINodes, false);\n      return filesDeleted;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirRenameOp.java",
      "extendedDetails": {
        "oldValue": "[QuotaExceededException]",
        "newValue": "[]"
      }
    },
    "745d04be59accf80feda0ad38efcc74ba362f2ca": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8823. Move replication factor into individual blocks. Contributed by Haohui Mai.\n",
      "commitDate": "22/08/15 12:09 AM",
      "commitName": "745d04be59accf80feda0ad38efcc74ba362f2ca",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "13/05/15 9:50 PM",
      "commitNameOld": "b2c85db86c9a62b0a03ee87547265077f664970a",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 100.1,
      "commitsBetweenForRepo": 639,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,23 @@\n     boolean cleanDst(BlockStoragePolicySuite bsps, BlocksMapUpdateInfo collectedBlocks)\n         throws QuotaExceededException {\n       Preconditions.checkState(oldDstChild !\u003d null);\n       List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n       List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n-      INode.ReclaimContext context \u003d new INode.ReclaimContext(bsps,\n-          collectedBlocks, removedINodes, removedUCFiles);\n+      INode.ReclaimContext context \u003d new INode.ReclaimContext(\n+          bsps, collectedBlocks, removedINodes, removedUCFiles);\n       final boolean filesDeleted;\n       if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n         oldDstChild.destroyAndCollectBlocks(context);\n         filesDeleted \u003d true;\n       } else {\n         oldDstChild.cleanSubtree(context, Snapshot.CURRENT_STATE_ID,\n             dstIIP.getLatestSnapshotId());\n         filesDeleted \u003d context.quotaDelta().getNsDelta() \u003e\u003d 0;\n       }\n+      fsd.updateReplicationFactor(context.collectedBlocks()\n+                                      .toUpdateReplicationInfo());\n+\n       fsd.getFSNamesystem().removeLeasesAndINodes(\n           removedUCFiles, removedINodes, false);\n       return filesDeleted;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    boolean cleanDst(BlockStoragePolicySuite bsps, BlocksMapUpdateInfo collectedBlocks)\n        throws QuotaExceededException {\n      Preconditions.checkState(oldDstChild !\u003d null);\n      List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n      List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n      INode.ReclaimContext context \u003d new INode.ReclaimContext(\n          bsps, collectedBlocks, removedINodes, removedUCFiles);\n      final boolean filesDeleted;\n      if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n        oldDstChild.destroyAndCollectBlocks(context);\n        filesDeleted \u003d true;\n      } else {\n        oldDstChild.cleanSubtree(context, Snapshot.CURRENT_STATE_ID,\n            dstIIP.getLatestSnapshotId());\n        filesDeleted \u003d context.quotaDelta().getNsDelta() \u003e\u003d 0;\n      }\n      fsd.updateReplicationFactor(context.collectedBlocks()\n                                      .toUpdateReplicationInfo());\n\n      fsd.getFSNamesystem().removeLeasesAndINodes(\n          removedUCFiles, removedINodes, false);\n      return filesDeleted;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirRenameOp.java",
      "extendedDetails": {}
    },
    "b2c85db86c9a62b0a03ee87547265077f664970a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7728. Avoid updating quota usage while loading edits. Contributed by Jing Zhao.\n",
      "commitDate": "13/05/15 9:50 PM",
      "commitName": "b2c85db86c9a62b0a03ee87547265077f664970a",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "09/05/15 10:51 PM",
      "commitNameOld": "4536399d47f6c061e149e2504600804a0f1e093d",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 3.96,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,20 @@\n     boolean cleanDst(BlockStoragePolicySuite bsps, BlocksMapUpdateInfo collectedBlocks)\n         throws QuotaExceededException {\n       Preconditions.checkState(oldDstChild !\u003d null);\n       List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n       List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n+      INode.ReclaimContext context \u003d new INode.ReclaimContext(bsps,\n+          collectedBlocks, removedINodes, removedUCFiles);\n       final boolean filesDeleted;\n       if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n-        oldDstChild.destroyAndCollectBlocks(\n-            new INode.ReclaimContext(bsps, collectedBlocks, removedINodes, removedUCFiles));\n+        oldDstChild.destroyAndCollectBlocks(context);\n         filesDeleted \u003d true;\n       } else {\n-        filesDeleted \u003d oldDstChild.cleanSubtree(\n-            new INode.ReclaimContext(bsps, collectedBlocks, removedINodes,\n-                                     removedUCFiles),\n-            Snapshot.CURRENT_STATE_ID,\n-            dstIIP.getLatestSnapshotId())\n-            .getNameSpace() \u003e\u003d 0;\n+        oldDstChild.cleanSubtree(context, Snapshot.CURRENT_STATE_ID,\n+            dstIIP.getLatestSnapshotId());\n+        filesDeleted \u003d context.quotaDelta().getNsDelta() \u003e\u003d 0;\n       }\n       fsd.getFSNamesystem().removeLeasesAndINodes(\n           removedUCFiles, removedINodes, false);\n       return filesDeleted;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    boolean cleanDst(BlockStoragePolicySuite bsps, BlocksMapUpdateInfo collectedBlocks)\n        throws QuotaExceededException {\n      Preconditions.checkState(oldDstChild !\u003d null);\n      List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n      List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n      INode.ReclaimContext context \u003d new INode.ReclaimContext(bsps,\n          collectedBlocks, removedINodes, removedUCFiles);\n      final boolean filesDeleted;\n      if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n        oldDstChild.destroyAndCollectBlocks(context);\n        filesDeleted \u003d true;\n      } else {\n        oldDstChild.cleanSubtree(context, Snapshot.CURRENT_STATE_ID,\n            dstIIP.getLatestSnapshotId());\n        filesDeleted \u003d context.quotaDelta().getNsDelta() \u003e\u003d 0;\n      }\n      fsd.getFSNamesystem().removeLeasesAndINodes(\n          removedUCFiles, removedINodes, false);\n      return filesDeleted;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirRenameOp.java",
      "extendedDetails": {}
    },
    "4536399d47f6c061e149e2504600804a0f1e093d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8357. Consolidate parameters of INode.CleanSubtree() into a parameter objects. Contributed by Li Lu.\n",
      "commitDate": "09/05/15 10:51 PM",
      "commitName": "4536399d47f6c061e149e2504600804a0f1e093d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "08/05/15 11:04 PM",
      "commitNameOld": "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.99,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,22 @@\n     boolean cleanDst(BlockStoragePolicySuite bsps, BlocksMapUpdateInfo collectedBlocks)\n         throws QuotaExceededException {\n       Preconditions.checkState(oldDstChild !\u003d null);\n       List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n       List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n       final boolean filesDeleted;\n       if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n-        oldDstChild.destroyAndCollectBlocks(bsps, collectedBlocks, removedINodes,\n-                                            removedUCFiles);\n+        oldDstChild.destroyAndCollectBlocks(\n+            new INode.ReclaimContext(bsps, collectedBlocks, removedINodes, removedUCFiles));\n         filesDeleted \u003d true;\n       } else {\n         filesDeleted \u003d oldDstChild.cleanSubtree(\n-            bsps, Snapshot.CURRENT_STATE_ID,\n-            dstIIP.getLatestSnapshotId(), collectedBlocks,\n-            removedINodes, removedUCFiles).getNameSpace() \u003e\u003d 0;\n+            new INode.ReclaimContext(bsps, collectedBlocks, removedINodes,\n+                                     removedUCFiles),\n+            Snapshot.CURRENT_STATE_ID,\n+            dstIIP.getLatestSnapshotId())\n+            .getNameSpace() \u003e\u003d 0;\n       }\n       fsd.getFSNamesystem().removeLeasesAndINodes(\n           removedUCFiles, removedINodes, false);\n       return filesDeleted;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    boolean cleanDst(BlockStoragePolicySuite bsps, BlocksMapUpdateInfo collectedBlocks)\n        throws QuotaExceededException {\n      Preconditions.checkState(oldDstChild !\u003d null);\n      List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n      List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n      final boolean filesDeleted;\n      if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n        oldDstChild.destroyAndCollectBlocks(\n            new INode.ReclaimContext(bsps, collectedBlocks, removedINodes, removedUCFiles));\n        filesDeleted \u003d true;\n      } else {\n        filesDeleted \u003d oldDstChild.cleanSubtree(\n            new INode.ReclaimContext(bsps, collectedBlocks, removedINodes,\n                                     removedUCFiles),\n            Snapshot.CURRENT_STATE_ID,\n            dstIIP.getLatestSnapshotId())\n            .getNameSpace() \u003e\u003d 0;\n      }\n      fsd.getFSNamesystem().removeLeasesAndINodes(\n          removedUCFiles, removedINodes, false);\n      return filesDeleted;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirRenameOp.java",
      "extendedDetails": {}
    },
    "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6757. Simplify lease manager with INodeID. Contributed by Haohui Mai.\n",
      "commitDate": "08/05/15 11:04 PM",
      "commitName": "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "05/05/15 10:50 AM",
      "commitNameOld": "fcd4cb751665adb241081e42b3403c3856b6c6fe",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 3.51,
      "commitsBetweenForRepo": 106,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,20 @@\n     boolean cleanDst(BlockStoragePolicySuite bsps, BlocksMapUpdateInfo collectedBlocks)\n         throws QuotaExceededException {\n       Preconditions.checkState(oldDstChild !\u003d null);\n       List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n+      List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n       final boolean filesDeleted;\n       if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n-        oldDstChild.destroyAndCollectBlocks(bsps, collectedBlocks, removedINodes);\n+        oldDstChild.destroyAndCollectBlocks(bsps, collectedBlocks, removedINodes,\n+                                            removedUCFiles);\n         filesDeleted \u003d true;\n       } else {\n-        filesDeleted \u003d oldDstChild.cleanSubtree(bsps, Snapshot.CURRENT_STATE_ID,\n-            dstIIP.getLatestSnapshotId(), collectedBlocks, removedINodes)\n-            .getNameSpace() \u003e\u003d 0;\n+        filesDeleted \u003d oldDstChild.cleanSubtree(\n+            bsps, Snapshot.CURRENT_STATE_ID,\n+            dstIIP.getLatestSnapshotId(), collectedBlocks,\n+            removedINodes, removedUCFiles).getNameSpace() \u003e\u003d 0;\n       }\n-      fsd.getFSNamesystem().removeLeasesAndINodes(src, removedINodes, false);\n+      fsd.getFSNamesystem().removeLeasesAndINodes(\n+          removedUCFiles, removedINodes, false);\n       return filesDeleted;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    boolean cleanDst(BlockStoragePolicySuite bsps, BlocksMapUpdateInfo collectedBlocks)\n        throws QuotaExceededException {\n      Preconditions.checkState(oldDstChild !\u003d null);\n      List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n      List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n      final boolean filesDeleted;\n      if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n        oldDstChild.destroyAndCollectBlocks(bsps, collectedBlocks, removedINodes,\n                                            removedUCFiles);\n        filesDeleted \u003d true;\n      } else {\n        filesDeleted \u003d oldDstChild.cleanSubtree(\n            bsps, Snapshot.CURRENT_STATE_ID,\n            dstIIP.getLatestSnapshotId(), collectedBlocks,\n            removedINodes, removedUCFiles).getNameSpace() \u003e\u003d 0;\n      }\n      fsd.getFSNamesystem().removeLeasesAndINodes(\n          removedUCFiles, removedINodes, false);\n      return filesDeleted;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirRenameOp.java",
      "extendedDetails": {}
    },
    "5dae97a584d30cef3e34141edfaca49c4ec57913": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7723. Quota By Storage Type namenode implemenation. (Contributed by Xiaoyu Yao)\n",
      "commitDate": "11/02/15 10:41 AM",
      "commitName": "5dae97a584d30cef3e34141edfaca49c4ec57913",
      "commitAuthor": "Arpit Agarwal",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7723. Quota By Storage Type namenode implemenation. (Contributed by Xiaoyu Yao)\n",
          "commitDate": "11/02/15 10:41 AM",
          "commitName": "5dae97a584d30cef3e34141edfaca49c4ec57913",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "02/02/15 4:32 PM",
          "commitNameOld": "8cb473124c1cf1c6f68ead7bde06558ebf7ce47e",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 8.76,
          "commitsBetweenForRepo": 109,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,16 @@\n-    boolean cleanDst(BlocksMapUpdateInfo collectedBlocks)\n+    boolean cleanDst(BlockStoragePolicySuite bsps, BlocksMapUpdateInfo collectedBlocks)\n         throws QuotaExceededException {\n       Preconditions.checkState(oldDstChild !\u003d null);\n       List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n       final boolean filesDeleted;\n       if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n-        oldDstChild.destroyAndCollectBlocks(collectedBlocks, removedINodes);\n+        oldDstChild.destroyAndCollectBlocks(bsps, collectedBlocks, removedINodes);\n         filesDeleted \u003d true;\n       } else {\n-        filesDeleted \u003d oldDstChild.cleanSubtree(Snapshot.CURRENT_STATE_ID,\n+        filesDeleted \u003d oldDstChild.cleanSubtree(bsps, Snapshot.CURRENT_STATE_ID,\n             dstIIP.getLatestSnapshotId(), collectedBlocks, removedINodes)\n-            .get(Quota.NAMESPACE) \u003e\u003d 0;\n+            .getNameSpace() \u003e\u003d 0;\n       }\n       fsd.getFSNamesystem().removeLeasesAndINodes(src, removedINodes, false);\n       return filesDeleted;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    boolean cleanDst(BlockStoragePolicySuite bsps, BlocksMapUpdateInfo collectedBlocks)\n        throws QuotaExceededException {\n      Preconditions.checkState(oldDstChild !\u003d null);\n      List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n      final boolean filesDeleted;\n      if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n        oldDstChild.destroyAndCollectBlocks(bsps, collectedBlocks, removedINodes);\n        filesDeleted \u003d true;\n      } else {\n        filesDeleted \u003d oldDstChild.cleanSubtree(bsps, Snapshot.CURRENT_STATE_ID,\n            dstIIP.getLatestSnapshotId(), collectedBlocks, removedINodes)\n            .getNameSpace() \u003e\u003d 0;\n      }\n      fsd.getFSNamesystem().removeLeasesAndINodes(src, removedINodes, false);\n      return filesDeleted;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirRenameOp.java",
          "extendedDetails": {
            "oldValue": "[collectedBlocks-BlocksMapUpdateInfo]",
            "newValue": "[bsps-BlockStoragePolicySuite, collectedBlocks-BlocksMapUpdateInfo]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7723. Quota By Storage Type namenode implemenation. (Contributed by Xiaoyu Yao)\n",
          "commitDate": "11/02/15 10:41 AM",
          "commitName": "5dae97a584d30cef3e34141edfaca49c4ec57913",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "02/02/15 4:32 PM",
          "commitNameOld": "8cb473124c1cf1c6f68ead7bde06558ebf7ce47e",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 8.76,
          "commitsBetweenForRepo": 109,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,16 @@\n-    boolean cleanDst(BlocksMapUpdateInfo collectedBlocks)\n+    boolean cleanDst(BlockStoragePolicySuite bsps, BlocksMapUpdateInfo collectedBlocks)\n         throws QuotaExceededException {\n       Preconditions.checkState(oldDstChild !\u003d null);\n       List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n       final boolean filesDeleted;\n       if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n-        oldDstChild.destroyAndCollectBlocks(collectedBlocks, removedINodes);\n+        oldDstChild.destroyAndCollectBlocks(bsps, collectedBlocks, removedINodes);\n         filesDeleted \u003d true;\n       } else {\n-        filesDeleted \u003d oldDstChild.cleanSubtree(Snapshot.CURRENT_STATE_ID,\n+        filesDeleted \u003d oldDstChild.cleanSubtree(bsps, Snapshot.CURRENT_STATE_ID,\n             dstIIP.getLatestSnapshotId(), collectedBlocks, removedINodes)\n-            .get(Quota.NAMESPACE) \u003e\u003d 0;\n+            .getNameSpace() \u003e\u003d 0;\n       }\n       fsd.getFSNamesystem().removeLeasesAndINodes(src, removedINodes, false);\n       return filesDeleted;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    boolean cleanDst(BlockStoragePolicySuite bsps, BlocksMapUpdateInfo collectedBlocks)\n        throws QuotaExceededException {\n      Preconditions.checkState(oldDstChild !\u003d null);\n      List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n      final boolean filesDeleted;\n      if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n        oldDstChild.destroyAndCollectBlocks(bsps, collectedBlocks, removedINodes);\n        filesDeleted \u003d true;\n      } else {\n        filesDeleted \u003d oldDstChild.cleanSubtree(bsps, Snapshot.CURRENT_STATE_ID,\n            dstIIP.getLatestSnapshotId(), collectedBlocks, removedINodes)\n            .getNameSpace() \u003e\u003d 0;\n      }\n      fsd.getFSNamesystem().removeLeasesAndINodes(src, removedINodes, false);\n      return filesDeleted;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirRenameOp.java",
          "extendedDetails": {}
        }
      ]
    },
    "8cb473124c1cf1c6f68ead7bde06558ebf7ce47e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6651. Deletion failure can leak inodes permanently. Contributed by Jing Zhao.\n",
      "commitDate": "02/02/15 4:32 PM",
      "commitName": "8cb473124c1cf1c6f68ead7bde06558ebf7ce47e",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/01/15 3:25 PM",
      "commitNameOld": "d244574d03903b0514b0308da85d2f06c2384524",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 5.05,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n     boolean cleanDst(BlocksMapUpdateInfo collectedBlocks)\n         throws QuotaExceededException {\n       Preconditions.checkState(oldDstChild !\u003d null);\n       List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n       final boolean filesDeleted;\n       if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n         oldDstChild.destroyAndCollectBlocks(collectedBlocks, removedINodes);\n         filesDeleted \u003d true;\n       } else {\n         filesDeleted \u003d oldDstChild.cleanSubtree(Snapshot.CURRENT_STATE_ID,\n-            dstIIP.getLatestSnapshotId(), collectedBlocks, removedINodes,\n-            true).get(Quota.NAMESPACE) \u003e\u003d 0;\n+            dstIIP.getLatestSnapshotId(), collectedBlocks, removedINodes)\n+            .get(Quota.NAMESPACE) \u003e\u003d 0;\n       }\n       fsd.getFSNamesystem().removeLeasesAndINodes(src, removedINodes, false);\n       return filesDeleted;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    boolean cleanDst(BlocksMapUpdateInfo collectedBlocks)\n        throws QuotaExceededException {\n      Preconditions.checkState(oldDstChild !\u003d null);\n      List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n      final boolean filesDeleted;\n      if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n        oldDstChild.destroyAndCollectBlocks(collectedBlocks, removedINodes);\n        filesDeleted \u003d true;\n      } else {\n        filesDeleted \u003d oldDstChild.cleanSubtree(Snapshot.CURRENT_STATE_ID,\n            dstIIP.getLatestSnapshotId(), collectedBlocks, removedINodes)\n            .get(Quota.NAMESPACE) \u003e\u003d 0;\n      }\n      fsd.getFSNamesystem().removeLeasesAndINodes(src, removedINodes, false);\n      return filesDeleted;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirRenameOp.java",
      "extendedDetails": {}
    },
    "24315e7d374a1ddd4329b64350cf96fc9ab6f59c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7573. Consolidate the implementation of delete() into a single class. Contributed by Haohui Mai.\n",
      "commitDate": "17/01/15 12:56 PM",
      "commitName": "24315e7d374a1ddd4329b64350cf96fc9ab6f59c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "22/12/14 11:19 PM",
      "commitNameOld": "5caebbae8c2fc9ba2e32384657aee21641a1a6d0",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 25.57,
      "commitsBetweenForRepo": 112,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,16 @@\n     boolean cleanDst(BlocksMapUpdateInfo collectedBlocks)\n         throws QuotaExceededException {\n       Preconditions.checkState(oldDstChild !\u003d null);\n       List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n       final boolean filesDeleted;\n       if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n         oldDstChild.destroyAndCollectBlocks(collectedBlocks, removedINodes);\n         filesDeleted \u003d true;\n       } else {\n         filesDeleted \u003d oldDstChild.cleanSubtree(Snapshot.CURRENT_STATE_ID,\n             dstIIP.getLatestSnapshotId(), collectedBlocks, removedINodes,\n             true).get(Quota.NAMESPACE) \u003e\u003d 0;\n       }\n-      fsd.getFSNamesystem().removePathAndBlocks(src, null, removedINodes,\n-          false);\n+      fsd.getFSNamesystem().removeLeasesAndINodes(src, removedINodes, false);\n       return filesDeleted;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    boolean cleanDst(BlocksMapUpdateInfo collectedBlocks)\n        throws QuotaExceededException {\n      Preconditions.checkState(oldDstChild !\u003d null);\n      List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n      final boolean filesDeleted;\n      if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n        oldDstChild.destroyAndCollectBlocks(collectedBlocks, removedINodes);\n        filesDeleted \u003d true;\n      } else {\n        filesDeleted \u003d oldDstChild.cleanSubtree(Snapshot.CURRENT_STATE_ID,\n            dstIIP.getLatestSnapshotId(), collectedBlocks, removedINodes,\n            true).get(Quota.NAMESPACE) \u003e\u003d 0;\n      }\n      fsd.getFSNamesystem().removeLeasesAndINodes(src, removedINodes, false);\n      return filesDeleted;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirRenameOp.java",
      "extendedDetails": {}
    },
    "5caebbae8c2fc9ba2e32384657aee21641a1a6d0": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7484. Make FSDirectory#addINode take existing INodes as its parameter. Contributed by Jing Zhao.\n",
      "commitDate": "22/12/14 11:19 PM",
      "commitName": "5caebbae8c2fc9ba2e32384657aee21641a1a6d0",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,17 @@\n+    boolean cleanDst(BlocksMapUpdateInfo collectedBlocks)\n+        throws QuotaExceededException {\n+      Preconditions.checkState(oldDstChild !\u003d null);\n+      List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n+      final boolean filesDeleted;\n+      if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n+        oldDstChild.destroyAndCollectBlocks(collectedBlocks, removedINodes);\n+        filesDeleted \u003d true;\n+      } else {\n+        filesDeleted \u003d oldDstChild.cleanSubtree(Snapshot.CURRENT_STATE_ID,\n+            dstIIP.getLatestSnapshotId(), collectedBlocks, removedINodes,\n+            true).get(Quota.NAMESPACE) \u003e\u003d 0;\n+      }\n+      fsd.getFSNamesystem().removePathAndBlocks(src, null, removedINodes,\n+          false);\n+      return filesDeleted;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    boolean cleanDst(BlocksMapUpdateInfo collectedBlocks)\n        throws QuotaExceededException {\n      Preconditions.checkState(oldDstChild !\u003d null);\n      List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n      final boolean filesDeleted;\n      if (!oldDstChild.isInLatestSnapshot(dstIIP.getLatestSnapshotId())) {\n        oldDstChild.destroyAndCollectBlocks(collectedBlocks, removedINodes);\n        filesDeleted \u003d true;\n      } else {\n        filesDeleted \u003d oldDstChild.cleanSubtree(Snapshot.CURRENT_STATE_ID,\n            dstIIP.getLatestSnapshotId(), collectedBlocks, removedINodes,\n            true).get(Quota.NAMESPACE) \u003e\u003d 0;\n      }\n      fsd.getFSNamesystem().removePathAndBlocks(src, null, removedINodes,\n          false);\n      return filesDeleted;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirRenameOp.java"
    }
  }
}