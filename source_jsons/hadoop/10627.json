{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockChecksumHelper.java",
  "functionName": "readHeader",
  "functionId": "readHeader",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockChecksumHelper.java",
  "functionStartLine": 240,
  "functionEndLine": 251,
  "numCommitsSeen": 8,
  "timeTaken": 2994,
  "changeHistory": [
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
    "a337ceb74e984991dbf976236d2e785cf5921b16",
    "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
    "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6"
  ],
  "changeHistoryShort": {
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720": "Ymultichange(Ymodifierchange,Ybodychange)",
    "a337ceb74e984991dbf976236d2e785cf5921b16": "Ymultichange(Ymodifierchange,Ybodychange)",
    "e5ff0ea7ba087984262f1f27200ae5bb40d9b838": "Ymultichange(Ymodifierchange,Ybodychange)",
    "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6": "Yintroduced"
  },
  "changeHistoryDetails": {
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\n",
      "commitDate": "26/03/16 7:58 PM",
      "commitName": "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\n",
          "commitDate": "26/03/16 7:58 PM",
          "commitName": "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "26/03/16 9:20 AM",
          "commitNameOld": "a337ceb74e984991dbf976236d2e785cf5921b16",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.44,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,12 @@\n-    protected void readHeader() throws IOException {\n+    void readHeader() throws IOException {\n       //read metadata file\n       header \u003d BlockMetadataHeader.readHeader(checksumIn);\n       checksum \u003d header.getChecksum();\n-      checksumSize \u003d checksum.getChecksumSize();\n-      bytesPerCRC \u003d checksum.getBytesPerChecksum();\n-      crcPerBlock \u003d checksumSize \u003c\u003d 0 ? 0 :\n+      setChecksumSize(checksum.getChecksumSize());\n+      setBytesPerCRC(checksum.getBytesPerChecksum());\n+      long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0 :\n           (metadataIn.getLength() -\n-              BlockMetadataHeader.getHeaderSize()) / checksumSize;\n-      crcType \u003d checksum.getChecksumType();\n+              BlockMetadataHeader.getHeaderSize()) / checksum.getChecksumSize();\n+      setCrcPerBlock(crcPerBlock);\n+      setCrcType(checksum.getChecksumType());\n     }\n\\ No newline at end of file\n",
          "actualSource": "    void readHeader() throws IOException {\n      //read metadata file\n      header \u003d BlockMetadataHeader.readHeader(checksumIn);\n      checksum \u003d header.getChecksum();\n      setChecksumSize(checksum.getChecksumSize());\n      setBytesPerCRC(checksum.getBytesPerChecksum());\n      long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0 :\n          (metadataIn.getLength() -\n              BlockMetadataHeader.getHeaderSize()) / checksum.getChecksumSize();\n      setCrcPerBlock(crcPerBlock);\n      setCrcType(checksum.getChecksumType());\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockChecksumHelper.java",
          "extendedDetails": {
            "oldValue": "[protected]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\n",
          "commitDate": "26/03/16 7:58 PM",
          "commitName": "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "26/03/16 9:20 AM",
          "commitNameOld": "a337ceb74e984991dbf976236d2e785cf5921b16",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.44,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,12 @@\n-    protected void readHeader() throws IOException {\n+    void readHeader() throws IOException {\n       //read metadata file\n       header \u003d BlockMetadataHeader.readHeader(checksumIn);\n       checksum \u003d header.getChecksum();\n-      checksumSize \u003d checksum.getChecksumSize();\n-      bytesPerCRC \u003d checksum.getBytesPerChecksum();\n-      crcPerBlock \u003d checksumSize \u003c\u003d 0 ? 0 :\n+      setChecksumSize(checksum.getChecksumSize());\n+      setBytesPerCRC(checksum.getBytesPerChecksum());\n+      long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0 :\n           (metadataIn.getLength() -\n-              BlockMetadataHeader.getHeaderSize()) / checksumSize;\n-      crcType \u003d checksum.getChecksumType();\n+              BlockMetadataHeader.getHeaderSize()) / checksum.getChecksumSize();\n+      setCrcPerBlock(crcPerBlock);\n+      setCrcType(checksum.getChecksumType());\n     }\n\\ No newline at end of file\n",
          "actualSource": "    void readHeader() throws IOException {\n      //read metadata file\n      header \u003d BlockMetadataHeader.readHeader(checksumIn);\n      checksum \u003d header.getChecksum();\n      setChecksumSize(checksum.getChecksumSize());\n      setBytesPerCRC(checksum.getBytesPerChecksum());\n      long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0 :\n          (metadataIn.getLength() -\n              BlockMetadataHeader.getHeaderSize()) / checksum.getChecksumSize();\n      setCrcPerBlock(crcPerBlock);\n      setCrcType(checksum.getChecksumType());\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockChecksumHelper.java",
          "extendedDetails": {}
        }
      ]
    },
    "a337ceb74e984991dbf976236d2e785cf5921b16": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "Revert \"HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\"\n\nThis reverts commit e5ff0ea7ba087984262f1f27200ae5bb40d9b838.\n",
      "commitDate": "26/03/16 9:20 AM",
      "commitName": "a337ceb74e984991dbf976236d2e785cf5921b16",
      "commitAuthor": "Arpit Agarwal",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "Revert \"HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\"\n\nThis reverts commit e5ff0ea7ba087984262f1f27200ae5bb40d9b838.\n",
          "commitDate": "26/03/16 9:20 AM",
          "commitName": "a337ceb74e984991dbf976236d2e785cf5921b16",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "26/03/16 12:52 AM",
          "commitNameOld": "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.35,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,11 @@\n-    void readHeader() throws IOException {\n+    protected void readHeader() throws IOException {\n       //read metadata file\n       header \u003d BlockMetadataHeader.readHeader(checksumIn);\n       checksum \u003d header.getChecksum();\n-      setChecksumSize(checksum.getChecksumSize());\n-      setBytesPerCRC(checksum.getBytesPerChecksum());\n-      long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0 :\n+      checksumSize \u003d checksum.getChecksumSize();\n+      bytesPerCRC \u003d checksum.getBytesPerChecksum();\n+      crcPerBlock \u003d checksumSize \u003c\u003d 0 ? 0 :\n           (metadataIn.getLength() -\n-              BlockMetadataHeader.getHeaderSize()) / checksum.getChecksumSize();\n-      setCrcPerBlock(crcPerBlock);\n-      setCrcType(checksum.getChecksumType());\n+              BlockMetadataHeader.getHeaderSize()) / checksumSize;\n+      crcType \u003d checksum.getChecksumType();\n     }\n\\ No newline at end of file\n",
          "actualSource": "    protected void readHeader() throws IOException {\n      //read metadata file\n      header \u003d BlockMetadataHeader.readHeader(checksumIn);\n      checksum \u003d header.getChecksum();\n      checksumSize \u003d checksum.getChecksumSize();\n      bytesPerCRC \u003d checksum.getBytesPerChecksum();\n      crcPerBlock \u003d checksumSize \u003c\u003d 0 ? 0 :\n          (metadataIn.getLength() -\n              BlockMetadataHeader.getHeaderSize()) / checksumSize;\n      crcType \u003d checksum.getChecksumType();\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockChecksumHelper.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[protected]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "Revert \"HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\"\n\nThis reverts commit e5ff0ea7ba087984262f1f27200ae5bb40d9b838.\n",
          "commitDate": "26/03/16 9:20 AM",
          "commitName": "a337ceb74e984991dbf976236d2e785cf5921b16",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "26/03/16 12:52 AM",
          "commitNameOld": "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.35,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,11 @@\n-    void readHeader() throws IOException {\n+    protected void readHeader() throws IOException {\n       //read metadata file\n       header \u003d BlockMetadataHeader.readHeader(checksumIn);\n       checksum \u003d header.getChecksum();\n-      setChecksumSize(checksum.getChecksumSize());\n-      setBytesPerCRC(checksum.getBytesPerChecksum());\n-      long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0 :\n+      checksumSize \u003d checksum.getChecksumSize();\n+      bytesPerCRC \u003d checksum.getBytesPerChecksum();\n+      crcPerBlock \u003d checksumSize \u003c\u003d 0 ? 0 :\n           (metadataIn.getLength() -\n-              BlockMetadataHeader.getHeaderSize()) / checksum.getChecksumSize();\n-      setCrcPerBlock(crcPerBlock);\n-      setCrcType(checksum.getChecksumType());\n+              BlockMetadataHeader.getHeaderSize()) / checksumSize;\n+      crcType \u003d checksum.getChecksumType();\n     }\n\\ No newline at end of file\n",
          "actualSource": "    protected void readHeader() throws IOException {\n      //read metadata file\n      header \u003d BlockMetadataHeader.readHeader(checksumIn);\n      checksum \u003d header.getChecksum();\n      checksumSize \u003d checksum.getChecksumSize();\n      bytesPerCRC \u003d checksum.getBytesPerChecksum();\n      crcPerBlock \u003d checksumSize \u003c\u003d 0 ? 0 :\n          (metadataIn.getLength() -\n              BlockMetadataHeader.getHeaderSize()) / checksumSize;\n      crcType \u003d checksum.getChecksumType();\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockChecksumHelper.java",
          "extendedDetails": {}
        }
      ]
    },
    "e5ff0ea7ba087984262f1f27200ae5bb40d9b838": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\n",
      "commitDate": "26/03/16 12:52 AM",
      "commitName": "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\n",
          "commitDate": "26/03/16 12:52 AM",
          "commitName": "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "29/02/16 9:52 PM",
          "commitNameOld": "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 25.08,
          "commitsBetweenForRepo": 134,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,12 @@\n-    protected void readHeader() throws IOException {\n+    void readHeader() throws IOException {\n       //read metadata file\n       header \u003d BlockMetadataHeader.readHeader(checksumIn);\n       checksum \u003d header.getChecksum();\n-      checksumSize \u003d checksum.getChecksumSize();\n-      bytesPerCRC \u003d checksum.getBytesPerChecksum();\n-      crcPerBlock \u003d checksumSize \u003c\u003d 0 ? 0 :\n+      setChecksumSize(checksum.getChecksumSize());\n+      setBytesPerCRC(checksum.getBytesPerChecksum());\n+      long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0 :\n           (metadataIn.getLength() -\n-              BlockMetadataHeader.getHeaderSize()) / checksumSize;\n-      crcType \u003d checksum.getChecksumType();\n+              BlockMetadataHeader.getHeaderSize()) / checksum.getChecksumSize();\n+      setCrcPerBlock(crcPerBlock);\n+      setCrcType(checksum.getChecksumType());\n     }\n\\ No newline at end of file\n",
          "actualSource": "    void readHeader() throws IOException {\n      //read metadata file\n      header \u003d BlockMetadataHeader.readHeader(checksumIn);\n      checksum \u003d header.getChecksum();\n      setChecksumSize(checksum.getChecksumSize());\n      setBytesPerCRC(checksum.getBytesPerChecksum());\n      long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0 :\n          (metadataIn.getLength() -\n              BlockMetadataHeader.getHeaderSize()) / checksum.getChecksumSize();\n      setCrcPerBlock(crcPerBlock);\n      setCrcType(checksum.getChecksumType());\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockChecksumHelper.java",
          "extendedDetails": {
            "oldValue": "[protected]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\n",
          "commitDate": "26/03/16 12:52 AM",
          "commitName": "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "29/02/16 9:52 PM",
          "commitNameOld": "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 25.08,
          "commitsBetweenForRepo": 134,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,12 @@\n-    protected void readHeader() throws IOException {\n+    void readHeader() throws IOException {\n       //read metadata file\n       header \u003d BlockMetadataHeader.readHeader(checksumIn);\n       checksum \u003d header.getChecksum();\n-      checksumSize \u003d checksum.getChecksumSize();\n-      bytesPerCRC \u003d checksum.getBytesPerChecksum();\n-      crcPerBlock \u003d checksumSize \u003c\u003d 0 ? 0 :\n+      setChecksumSize(checksum.getChecksumSize());\n+      setBytesPerCRC(checksum.getBytesPerChecksum());\n+      long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0 :\n           (metadataIn.getLength() -\n-              BlockMetadataHeader.getHeaderSize()) / checksumSize;\n-      crcType \u003d checksum.getChecksumType();\n+              BlockMetadataHeader.getHeaderSize()) / checksum.getChecksumSize();\n+      setCrcPerBlock(crcPerBlock);\n+      setCrcType(checksum.getChecksumType());\n     }\n\\ No newline at end of file\n",
          "actualSource": "    void readHeader() throws IOException {\n      //read metadata file\n      header \u003d BlockMetadataHeader.readHeader(checksumIn);\n      checksum \u003d header.getChecksum();\n      setChecksumSize(checksum.getChecksumSize());\n      setBytesPerCRC(checksum.getBytesPerChecksum());\n      long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0 :\n          (metadataIn.getLength() -\n              BlockMetadataHeader.getHeaderSize()) / checksum.getChecksumSize();\n      setCrcPerBlock(crcPerBlock);\n      setCrcType(checksum.getChecksumType());\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockChecksumHelper.java",
          "extendedDetails": {}
        }
      ]
    },
    "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9733. Refactor DFSClient#getFileChecksum and DataXceiver#blockChecksum. Contributed by Kai Zheng\n",
      "commitDate": "29/02/16 9:52 PM",
      "commitName": "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6",
      "commitAuthor": "Uma Maheswara Rao G",
      "diff": "@@ -0,0 +1,11 @@\n+    protected void readHeader() throws IOException {\n+      //read metadata file\n+      header \u003d BlockMetadataHeader.readHeader(checksumIn);\n+      checksum \u003d header.getChecksum();\n+      checksumSize \u003d checksum.getChecksumSize();\n+      bytesPerCRC \u003d checksum.getBytesPerChecksum();\n+      crcPerBlock \u003d checksumSize \u003c\u003d 0 ? 0 :\n+          (metadataIn.getLength() -\n+              BlockMetadataHeader.getHeaderSize()) / checksumSize;\n+      crcType \u003d checksum.getChecksumType();\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    protected void readHeader() throws IOException {\n      //read metadata file\n      header \u003d BlockMetadataHeader.readHeader(checksumIn);\n      checksum \u003d header.getChecksum();\n      checksumSize \u003d checksum.getChecksumSize();\n      bytesPerCRC \u003d checksum.getBytesPerChecksum();\n      crcPerBlock \u003d checksumSize \u003c\u003d 0 ? 0 :\n          (metadataIn.getLength() -\n              BlockMetadataHeader.getHeaderSize()) / checksumSize;\n      crcType \u003d checksum.getChecksumType();\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockChecksumHelper.java"
    }
  }
}