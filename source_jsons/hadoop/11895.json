{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RamDiskReplicaLruTracker.java",
  "functionName": "addReplica",
  "functionId": "addReplica___bpid-String(modifiers-final)__blockId-long(modifiers-final)__transientVolume-FsVolumeImpl(modifiers-final)__lockedBytesReserved-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaLruTracker.java",
  "functionStartLine": 81,
  "functionEndLine": 94,
  "numCommitsSeen": 15,
  "timeTaken": 4322,
  "changeHistory": [
    "e453989a5722e653bd97e3e54f9bbdffc9454fba",
    "b2d5ed36bcb80e2581191dcdc3976e825c959142",
    "4cf9afacbe3d0814fb616d238aa9b16b1ae68386",
    "eb448e14399e17f11b9e523e4050de245b9b0408"
  ],
  "changeHistoryShort": {
    "e453989a5722e653bd97e3e54f9bbdffc9454fba": "Ymultichange(Yparameterchange,Ybodychange)",
    "b2d5ed36bcb80e2581191dcdc3976e825c959142": "Ymultichange(Ymovefromfile,Ybodychange,Yparametermetachange,Yparameterchange)",
    "4cf9afacbe3d0814fb616d238aa9b16b1ae68386": "Ymultichange(Yparameterchange,Ybodychange)",
    "eb448e14399e17f11b9e523e4050de245b9b0408": "Yintroduced"
  },
  "changeHistoryDetails": {
    "e453989a5722e653bd97e3e54f9bbdffc9454fba": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-8157. Writes to RAM DISK reserve locked memory for block files. (Arpit Agarwal)\n",
      "commitDate": "16/05/15 9:05 AM",
      "commitName": "e453989a5722e653bd97e3e54f9bbdffc9454fba",
      "commitAuthor": "Arpit Agarwal",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-8157. Writes to RAM DISK reserve locked memory for block files. (Arpit Agarwal)\n",
          "commitDate": "16/05/15 9:05 AM",
          "commitName": "e453989a5722e653bd97e3e54f9bbdffc9454fba",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "27/10/14 9:38 AM",
          "commitNameOld": "463aec11718e47d4aabb86a7a539cb973460aae6",
          "commitAuthorOld": "cnauroth",
          "daysBetweenCommits": 200.98,
          "commitsBetweenForRepo": 1734,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,14 @@\n   synchronized void addReplica(final String bpid, final long blockId,\n-                               final FsVolumeImpl transientVolume) {\n+                               final FsVolumeImpl transientVolume,\n+                               long lockedBytesReserved) {\n     Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n     if (map \u003d\u003d null) {\n-      map \u003d new HashMap\u003cLong, RamDiskReplicaLru\u003e();\n+      map \u003d new HashMap\u003c\u003e();\n       replicaMaps.put(bpid, map);\n     }\n-    RamDiskReplicaLru ramDiskReplicaLru \u003d new RamDiskReplicaLru(bpid, blockId, transientVolume);\n+    RamDiskReplicaLru ramDiskReplicaLru \u003d\n+        new RamDiskReplicaLru(bpid, blockId, transientVolume,\n+                              lockedBytesReserved);\n     map.put(blockId, ramDiskReplicaLru);\n     replicasNotPersisted.add(ramDiskReplicaLru);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void addReplica(final String bpid, final long blockId,\n                               final FsVolumeImpl transientVolume,\n                               long lockedBytesReserved) {\n    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n    if (map \u003d\u003d null) {\n      map \u003d new HashMap\u003c\u003e();\n      replicaMaps.put(bpid, map);\n    }\n    RamDiskReplicaLru ramDiskReplicaLru \u003d\n        new RamDiskReplicaLru(bpid, blockId, transientVolume,\n                              lockedBytesReserved);\n    map.put(blockId, ramDiskReplicaLru);\n    replicasNotPersisted.add(ramDiskReplicaLru);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaLruTracker.java",
          "extendedDetails": {
            "oldValue": "[bpid-String(modifiers-final), blockId-long(modifiers-final), transientVolume-FsVolumeImpl(modifiers-final)]",
            "newValue": "[bpid-String(modifiers-final), blockId-long(modifiers-final), transientVolume-FsVolumeImpl(modifiers-final), lockedBytesReserved-long]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8157. Writes to RAM DISK reserve locked memory for block files. (Arpit Agarwal)\n",
          "commitDate": "16/05/15 9:05 AM",
          "commitName": "e453989a5722e653bd97e3e54f9bbdffc9454fba",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "27/10/14 9:38 AM",
          "commitNameOld": "463aec11718e47d4aabb86a7a539cb973460aae6",
          "commitAuthorOld": "cnauroth",
          "daysBetweenCommits": 200.98,
          "commitsBetweenForRepo": 1734,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,14 @@\n   synchronized void addReplica(final String bpid, final long blockId,\n-                               final FsVolumeImpl transientVolume) {\n+                               final FsVolumeImpl transientVolume,\n+                               long lockedBytesReserved) {\n     Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n     if (map \u003d\u003d null) {\n-      map \u003d new HashMap\u003cLong, RamDiskReplicaLru\u003e();\n+      map \u003d new HashMap\u003c\u003e();\n       replicaMaps.put(bpid, map);\n     }\n-    RamDiskReplicaLru ramDiskReplicaLru \u003d new RamDiskReplicaLru(bpid, blockId, transientVolume);\n+    RamDiskReplicaLru ramDiskReplicaLru \u003d\n+        new RamDiskReplicaLru(bpid, blockId, transientVolume,\n+                              lockedBytesReserved);\n     map.put(blockId, ramDiskReplicaLru);\n     replicasNotPersisted.add(ramDiskReplicaLru);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void addReplica(final String bpid, final long blockId,\n                               final FsVolumeImpl transientVolume,\n                               long lockedBytesReserved) {\n    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n    if (map \u003d\u003d null) {\n      map \u003d new HashMap\u003c\u003e();\n      replicaMaps.put(bpid, map);\n    }\n    RamDiskReplicaLru ramDiskReplicaLru \u003d\n        new RamDiskReplicaLru(bpid, blockId, transientVolume,\n                              lockedBytesReserved);\n    map.put(blockId, ramDiskReplicaLru);\n    replicasNotPersisted.add(ramDiskReplicaLru);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaLruTracker.java",
          "extendedDetails": {}
        }
      ]
    },
    "b2d5ed36bcb80e2581191dcdc3976e825c959142": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange,Yparametermetachange,Yparameterchange)",
      "commitMessage": "HDFS-7100. Make eviction scheme pluggable. (Arpit Agarwal)\n",
      "commitDate": "20/09/14 1:25 PM",
      "commitName": "b2d5ed36bcb80e2581191dcdc3976e825c959142",
      "commitAuthor": "arp",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-7100. Make eviction scheme pluggable. (Arpit Agarwal)\n",
          "commitDate": "20/09/14 1:25 PM",
          "commitName": "b2d5ed36bcb80e2581191dcdc3976e825c959142",
          "commitAuthor": "arp",
          "commitDateOld": "20/09/14 10:34 AM",
          "commitNameOld": "09dab88d3eeb9947211b075d8103f9b836a61e8a",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,11 @@\n-  synchronized void addReplica(String bpid, long blockId,\n-                               final FsVolumeSpi transientVolume) {\n-    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n+  synchronized void addReplica(final String bpid, final long blockId,\n+                               final FsVolumeImpl transientVolume) {\n+    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n     if (map \u003d\u003d null) {\n-      map \u003d new HashMap\u003cLong, ReplicaState\u003e();\n+      map \u003d new HashMap\u003cLong, RamDiskReplicaLru\u003e();\n       replicaMaps.put(bpid, map);\n     }\n-    ReplicaState replicaState \u003d new ReplicaState(bpid, blockId, transientVolume);\n-    map.put(blockId, replicaState);\n-    replicasNotPersisted.add(replicaState);\n+    RamDiskReplicaLru ramDiskReplicaLru \u003d new RamDiskReplicaLru(bpid, blockId, transientVolume);\n+    map.put(blockId, ramDiskReplicaLru);\n+    replicasNotPersisted.add(ramDiskReplicaLru);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void addReplica(final String bpid, final long blockId,\n                               final FsVolumeImpl transientVolume) {\n    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n    if (map \u003d\u003d null) {\n      map \u003d new HashMap\u003cLong, RamDiskReplicaLru\u003e();\n      replicaMaps.put(bpid, map);\n    }\n    RamDiskReplicaLru ramDiskReplicaLru \u003d new RamDiskReplicaLru(bpid, blockId, transientVolume);\n    map.put(blockId, ramDiskReplicaLru);\n    replicasNotPersisted.add(ramDiskReplicaLru);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaLruTracker.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaLruTracker.java",
            "oldMethodName": "addReplica",
            "newMethodName": "addReplica"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7100. Make eviction scheme pluggable. (Arpit Agarwal)\n",
          "commitDate": "20/09/14 1:25 PM",
          "commitName": "b2d5ed36bcb80e2581191dcdc3976e825c959142",
          "commitAuthor": "arp",
          "commitDateOld": "20/09/14 10:34 AM",
          "commitNameOld": "09dab88d3eeb9947211b075d8103f9b836a61e8a",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,11 @@\n-  synchronized void addReplica(String bpid, long blockId,\n-                               final FsVolumeSpi transientVolume) {\n-    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n+  synchronized void addReplica(final String bpid, final long blockId,\n+                               final FsVolumeImpl transientVolume) {\n+    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n     if (map \u003d\u003d null) {\n-      map \u003d new HashMap\u003cLong, ReplicaState\u003e();\n+      map \u003d new HashMap\u003cLong, RamDiskReplicaLru\u003e();\n       replicaMaps.put(bpid, map);\n     }\n-    ReplicaState replicaState \u003d new ReplicaState(bpid, blockId, transientVolume);\n-    map.put(blockId, replicaState);\n-    replicasNotPersisted.add(replicaState);\n+    RamDiskReplicaLru ramDiskReplicaLru \u003d new RamDiskReplicaLru(bpid, blockId, transientVolume);\n+    map.put(blockId, ramDiskReplicaLru);\n+    replicasNotPersisted.add(ramDiskReplicaLru);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void addReplica(final String bpid, final long blockId,\n                               final FsVolumeImpl transientVolume) {\n    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n    if (map \u003d\u003d null) {\n      map \u003d new HashMap\u003cLong, RamDiskReplicaLru\u003e();\n      replicaMaps.put(bpid, map);\n    }\n    RamDiskReplicaLru ramDiskReplicaLru \u003d new RamDiskReplicaLru(bpid, blockId, transientVolume);\n    map.put(blockId, ramDiskReplicaLru);\n    replicasNotPersisted.add(ramDiskReplicaLru);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaLruTracker.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparametermetachange",
          "commitMessage": "HDFS-7100. Make eviction scheme pluggable. (Arpit Agarwal)\n",
          "commitDate": "20/09/14 1:25 PM",
          "commitName": "b2d5ed36bcb80e2581191dcdc3976e825c959142",
          "commitAuthor": "arp",
          "commitDateOld": "20/09/14 10:34 AM",
          "commitNameOld": "09dab88d3eeb9947211b075d8103f9b836a61e8a",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,11 @@\n-  synchronized void addReplica(String bpid, long blockId,\n-                               final FsVolumeSpi transientVolume) {\n-    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n+  synchronized void addReplica(final String bpid, final long blockId,\n+                               final FsVolumeImpl transientVolume) {\n+    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n     if (map \u003d\u003d null) {\n-      map \u003d new HashMap\u003cLong, ReplicaState\u003e();\n+      map \u003d new HashMap\u003cLong, RamDiskReplicaLru\u003e();\n       replicaMaps.put(bpid, map);\n     }\n-    ReplicaState replicaState \u003d new ReplicaState(bpid, blockId, transientVolume);\n-    map.put(blockId, replicaState);\n-    replicasNotPersisted.add(replicaState);\n+    RamDiskReplicaLru ramDiskReplicaLru \u003d new RamDiskReplicaLru(bpid, blockId, transientVolume);\n+    map.put(blockId, ramDiskReplicaLru);\n+    replicasNotPersisted.add(ramDiskReplicaLru);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void addReplica(final String bpid, final long blockId,\n                               final FsVolumeImpl transientVolume) {\n    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n    if (map \u003d\u003d null) {\n      map \u003d new HashMap\u003cLong, RamDiskReplicaLru\u003e();\n      replicaMaps.put(bpid, map);\n    }\n    RamDiskReplicaLru ramDiskReplicaLru \u003d new RamDiskReplicaLru(bpid, blockId, transientVolume);\n    map.put(blockId, ramDiskReplicaLru);\n    replicasNotPersisted.add(ramDiskReplicaLru);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaLruTracker.java",
          "extendedDetails": {
            "oldValue": "[bpid-String, blockId-long, transientVolume-FsVolumeSpi(modifiers-final)]",
            "newValue": "[bpid-String(modifiers-final), blockId-long(modifiers-final), transientVolume-FsVolumeImpl(modifiers-final)]"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7100. Make eviction scheme pluggable. (Arpit Agarwal)\n",
          "commitDate": "20/09/14 1:25 PM",
          "commitName": "b2d5ed36bcb80e2581191dcdc3976e825c959142",
          "commitAuthor": "arp",
          "commitDateOld": "20/09/14 10:34 AM",
          "commitNameOld": "09dab88d3eeb9947211b075d8103f9b836a61e8a",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,11 @@\n-  synchronized void addReplica(String bpid, long blockId,\n-                               final FsVolumeSpi transientVolume) {\n-    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n+  synchronized void addReplica(final String bpid, final long blockId,\n+                               final FsVolumeImpl transientVolume) {\n+    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n     if (map \u003d\u003d null) {\n-      map \u003d new HashMap\u003cLong, ReplicaState\u003e();\n+      map \u003d new HashMap\u003cLong, RamDiskReplicaLru\u003e();\n       replicaMaps.put(bpid, map);\n     }\n-    ReplicaState replicaState \u003d new ReplicaState(bpid, blockId, transientVolume);\n-    map.put(blockId, replicaState);\n-    replicasNotPersisted.add(replicaState);\n+    RamDiskReplicaLru ramDiskReplicaLru \u003d new RamDiskReplicaLru(bpid, blockId, transientVolume);\n+    map.put(blockId, ramDiskReplicaLru);\n+    replicasNotPersisted.add(ramDiskReplicaLru);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void addReplica(final String bpid, final long blockId,\n                               final FsVolumeImpl transientVolume) {\n    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n    if (map \u003d\u003d null) {\n      map \u003d new HashMap\u003cLong, RamDiskReplicaLru\u003e();\n      replicaMaps.put(bpid, map);\n    }\n    RamDiskReplicaLru ramDiskReplicaLru \u003d new RamDiskReplicaLru(bpid, blockId, transientVolume);\n    map.put(blockId, ramDiskReplicaLru);\n    replicasNotPersisted.add(ramDiskReplicaLru);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaLruTracker.java",
          "extendedDetails": {
            "oldValue": "[bpid-String, blockId-long, transientVolume-FsVolumeSpi(modifiers-final)]",
            "newValue": "[bpid-String(modifiers-final), blockId-long(modifiers-final), transientVolume-FsVolumeImpl(modifiers-final)]"
          }
        }
      ]
    },
    "4cf9afacbe3d0814fb616d238aa9b16b1ae68386": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6960. Bugfix in LazyWriter, fix test case and some refactoring. (Arpit Agarwal)\n",
      "commitDate": "28/08/14 11:05 PM",
      "commitName": "4cf9afacbe3d0814fb616d238aa9b16b1ae68386",
      "commitAuthor": "arp",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6960. Bugfix in LazyWriter, fix test case and some refactoring. (Arpit Agarwal)\n",
          "commitDate": "28/08/14 11:05 PM",
          "commitName": "4cf9afacbe3d0814fb616d238aa9b16b1ae68386",
          "commitAuthor": "arp",
          "commitDateOld": "27/08/14 9:47 PM",
          "commitNameOld": "eb448e14399e17f11b9e523e4050de245b9b0408",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 1.05,
          "commitsBetweenForRepo": 16,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,11 @@\n   synchronized void addReplica(String bpid, long blockId,\n-                               final FsVolumeImpl transientVolume) {\n+                               final FsVolumeSpi transientVolume) {\n     Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n     if (map \u003d\u003d null) {\n       map \u003d new HashMap\u003cLong, ReplicaState\u003e();\n       replicaMaps.put(bpid, map);\n     }\n-    map.put(blockId, new ReplicaState(bpid, blockId, transientVolume));\n+    ReplicaState replicaState \u003d new ReplicaState(bpid, blockId, transientVolume);\n+    map.put(blockId, replicaState);\n+    replicasNotPersisted.add(replicaState);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void addReplica(String bpid, long blockId,\n                               final FsVolumeSpi transientVolume) {\n    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n    if (map \u003d\u003d null) {\n      map \u003d new HashMap\u003cLong, ReplicaState\u003e();\n      replicaMaps.put(bpid, map);\n    }\n    ReplicaState replicaState \u003d new ReplicaState(bpid, blockId, transientVolume);\n    map.put(blockId, replicaState);\n    replicasNotPersisted.add(replicaState);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java",
          "extendedDetails": {
            "oldValue": "[bpid-String, blockId-long, transientVolume-FsVolumeImpl(modifiers-final)]",
            "newValue": "[bpid-String, blockId-long, transientVolume-FsVolumeSpi(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6960. Bugfix in LazyWriter, fix test case and some refactoring. (Arpit Agarwal)\n",
          "commitDate": "28/08/14 11:05 PM",
          "commitName": "4cf9afacbe3d0814fb616d238aa9b16b1ae68386",
          "commitAuthor": "arp",
          "commitDateOld": "27/08/14 9:47 PM",
          "commitNameOld": "eb448e14399e17f11b9e523e4050de245b9b0408",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 1.05,
          "commitsBetweenForRepo": 16,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,11 @@\n   synchronized void addReplica(String bpid, long blockId,\n-                               final FsVolumeImpl transientVolume) {\n+                               final FsVolumeSpi transientVolume) {\n     Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n     if (map \u003d\u003d null) {\n       map \u003d new HashMap\u003cLong, ReplicaState\u003e();\n       replicaMaps.put(bpid, map);\n     }\n-    map.put(blockId, new ReplicaState(bpid, blockId, transientVolume));\n+    ReplicaState replicaState \u003d new ReplicaState(bpid, blockId, transientVolume);\n+    map.put(blockId, replicaState);\n+    replicasNotPersisted.add(replicaState);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void addReplica(String bpid, long blockId,\n                               final FsVolumeSpi transientVolume) {\n    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n    if (map \u003d\u003d null) {\n      map \u003d new HashMap\u003cLong, ReplicaState\u003e();\n      replicaMaps.put(bpid, map);\n    }\n    ReplicaState replicaState \u003d new ReplicaState(bpid, blockId, transientVolume);\n    map.put(blockId, replicaState);\n    replicasNotPersisted.add(replicaState);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java",
          "extendedDetails": {}
        }
      ]
    },
    "eb448e14399e17f11b9e523e4050de245b9b0408": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6926. DN support for saving replicas to persistent storage and evicting in-memory replicas. (Arpit Agarwal)\n",
      "commitDate": "27/08/14 9:47 PM",
      "commitName": "eb448e14399e17f11b9e523e4050de245b9b0408",
      "commitAuthor": "arp",
      "diff": "@@ -0,0 +1,9 @@\n+  synchronized void addReplica(String bpid, long blockId,\n+                               final FsVolumeImpl transientVolume) {\n+    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n+    if (map \u003d\u003d null) {\n+      map \u003d new HashMap\u003cLong, ReplicaState\u003e();\n+      replicaMaps.put(bpid, map);\n+    }\n+    map.put(blockId, new ReplicaState(bpid, blockId, transientVolume));\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void addReplica(String bpid, long blockId,\n                               final FsVolumeImpl transientVolume) {\n    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n    if (map \u003d\u003d null) {\n      map \u003d new HashMap\u003cLong, ReplicaState\u003e();\n      replicaMaps.put(bpid, map);\n    }\n    map.put(blockId, new ReplicaState(bpid, blockId, transientVolume));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java"
    }
  }
}