{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CancelCommand.java",
  "functionName": "execute",
  "functionId": "execute___cmd-CommandLine",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/CancelCommand.java",
  "functionStartLine": 59,
  "functionEndLine": 83,
  "numCommitsSeen": 6,
  "timeTaken": 870,
  "changeHistory": [
    "35c5943b8ba394191405555cdfc5e6127053ee97",
    "78a1032b71af7672840da98808e2bebac3cc11d1",
    "43eee50966191e9cfdb7ab19383edb3a44f93481"
  ],
  "changeHistoryShort": {
    "35c5943b8ba394191405555cdfc5e6127053ee97": "Ybodychange",
    "78a1032b71af7672840da98808e2bebac3cc11d1": "Ybodychange",
    "43eee50966191e9cfdb7ab19383edb3a44f93481": "Yintroduced"
  },
  "changeHistoryDetails": {
    "35c5943b8ba394191405555cdfc5e6127053ee97": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10553. DiskBalancer: Rename Tools/DiskBalancer class to Tools/DiskBalancerCLI. Contributed by Manoj Govindassamy.\n",
      "commitDate": "08/09/16 7:26 PM",
      "commitName": "35c5943b8ba394191405555cdfc5e6127053ee97",
      "commitAuthor": "Anu Engineer",
      "commitDateOld": "15/08/16 8:10 PM",
      "commitNameOld": "5628b36c0872d58c9b25f23da3dab4eafad9bca3",
      "commitAuthorOld": "Anu Engineer",
      "daysBetweenCommits": 23.97,
      "commitsBetweenForRepo": 154,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,25 @@\n   public void execute(CommandLine cmd) throws Exception {\n     LOG.info(\"Executing \\\"Cancel plan\\\" command.\");\n-    Preconditions.checkState(cmd.hasOption(DiskBalancer.CANCEL));\n-    verifyCommandOptions(DiskBalancer.CANCEL, cmd);\n+    Preconditions.checkState(cmd.hasOption(DiskBalancerCLI.CANCEL));\n+    verifyCommandOptions(DiskBalancerCLI.CANCEL, cmd);\n \n     // We can cancel a plan using datanode address and plan ID\n     // that you can read from a datanode using queryStatus\n-    if(cmd.hasOption(DiskBalancer.NODE)) {\n-      String nodeAddress \u003d cmd.getOptionValue(DiskBalancer.NODE);\n-      String planHash \u003d cmd.getOptionValue(DiskBalancer.CANCEL);\n+    if(cmd.hasOption(DiskBalancerCLI.NODE)) {\n+      String nodeAddress \u003d cmd.getOptionValue(DiskBalancerCLI.NODE);\n+      String planHash \u003d cmd.getOptionValue(DiskBalancerCLI.CANCEL);\n       cancelPlanUsingHash(nodeAddress, planHash);\n     } else {\n       // Or you can cancel a plan using the plan file. If the user\n       // points us to the plan file, we can compute the hash as well as read\n       // the address of the datanode from the plan file.\n-      String planFile \u003d cmd.getOptionValue(DiskBalancer.CANCEL);\n+      String planFile \u003d cmd.getOptionValue(DiskBalancerCLI.CANCEL);\n       Preconditions.checkArgument(planFile !\u003d null \u0026\u0026 !planFile.isEmpty(),\n           \"Invalid plan file specified.\");\n       String planData \u003d null;\n       try (FSDataInputStream plan \u003d open(planFile)) {\n         planData \u003d IOUtils.toString(plan);\n       }\n       cancelPlan(planData);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void execute(CommandLine cmd) throws Exception {\n    LOG.info(\"Executing \\\"Cancel plan\\\" command.\");\n    Preconditions.checkState(cmd.hasOption(DiskBalancerCLI.CANCEL));\n    verifyCommandOptions(DiskBalancerCLI.CANCEL, cmd);\n\n    // We can cancel a plan using datanode address and plan ID\n    // that you can read from a datanode using queryStatus\n    if(cmd.hasOption(DiskBalancerCLI.NODE)) {\n      String nodeAddress \u003d cmd.getOptionValue(DiskBalancerCLI.NODE);\n      String planHash \u003d cmd.getOptionValue(DiskBalancerCLI.CANCEL);\n      cancelPlanUsingHash(nodeAddress, planHash);\n    } else {\n      // Or you can cancel a plan using the plan file. If the user\n      // points us to the plan file, we can compute the hash as well as read\n      // the address of the datanode from the plan file.\n      String planFile \u003d cmd.getOptionValue(DiskBalancerCLI.CANCEL);\n      Preconditions.checkArgument(planFile !\u003d null \u0026\u0026 !planFile.isEmpty(),\n          \"Invalid plan file specified.\");\n      String planData \u003d null;\n      try (FSDataInputStream plan \u003d open(planFile)) {\n        planData \u003d IOUtils.toString(plan);\n      }\n      cancelPlan(planData);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/CancelCommand.java",
      "extendedDetails": {}
    },
    "78a1032b71af7672840da98808e2bebac3cc11d1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10500. Diskbalancer: Print out information when a plan is not generated. Contributed by Anu Engineer.\n",
      "commitDate": "23/06/16 6:21 PM",
      "commitName": "78a1032b71af7672840da98808e2bebac3cc11d1",
      "commitAuthor": "Anu Engineer",
      "commitDateOld": "23/06/16 6:21 PM",
      "commitNameOld": "43eee50966191e9cfdb7ab19383edb3a44f93481",
      "commitAuthorOld": "Anu Engineer",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,25 @@\n   public void execute(CommandLine cmd) throws Exception {\n     LOG.info(\"Executing \\\"Cancel plan\\\" command.\");\n     Preconditions.checkState(cmd.hasOption(DiskBalancer.CANCEL));\n     verifyCommandOptions(DiskBalancer.CANCEL, cmd);\n \n     // We can cancel a plan using datanode address and plan ID\n     // that you can read from a datanode using queryStatus\n     if(cmd.hasOption(DiskBalancer.NODE)) {\n       String nodeAddress \u003d cmd.getOptionValue(DiskBalancer.NODE);\n       String planHash \u003d cmd.getOptionValue(DiskBalancer.CANCEL);\n       cancelPlanUsingHash(nodeAddress, planHash);\n     } else {\n       // Or you can cancel a plan using the plan file. If the user\n       // points us to the plan file, we can compute the hash as well as read\n       // the address of the datanode from the plan file.\n       String planFile \u003d cmd.getOptionValue(DiskBalancer.CANCEL);\n-      Preconditions.checkArgument(planFile \u003d\u003d null || planFile.isEmpty(),\n+      Preconditions.checkArgument(planFile !\u003d null \u0026\u0026 !planFile.isEmpty(),\n           \"Invalid plan file specified.\");\n       String planData \u003d null;\n       try (FSDataInputStream plan \u003d open(planFile)) {\n         planData \u003d IOUtils.toString(plan);\n       }\n       cancelPlan(planData);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void execute(CommandLine cmd) throws Exception {\n    LOG.info(\"Executing \\\"Cancel plan\\\" command.\");\n    Preconditions.checkState(cmd.hasOption(DiskBalancer.CANCEL));\n    verifyCommandOptions(DiskBalancer.CANCEL, cmd);\n\n    // We can cancel a plan using datanode address and plan ID\n    // that you can read from a datanode using queryStatus\n    if(cmd.hasOption(DiskBalancer.NODE)) {\n      String nodeAddress \u003d cmd.getOptionValue(DiskBalancer.NODE);\n      String planHash \u003d cmd.getOptionValue(DiskBalancer.CANCEL);\n      cancelPlanUsingHash(nodeAddress, planHash);\n    } else {\n      // Or you can cancel a plan using the plan file. If the user\n      // points us to the plan file, we can compute the hash as well as read\n      // the address of the datanode from the plan file.\n      String planFile \u003d cmd.getOptionValue(DiskBalancer.CANCEL);\n      Preconditions.checkArgument(planFile !\u003d null \u0026\u0026 !planFile.isEmpty(),\n          \"Invalid plan file specified.\");\n      String planData \u003d null;\n      try (FSDataInputStream plan \u003d open(planFile)) {\n        planData \u003d IOUtils.toString(plan);\n      }\n      cancelPlan(planData);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/CancelCommand.java",
      "extendedDetails": {}
    },
    "43eee50966191e9cfdb7ab19383edb3a44f93481": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-10403. DiskBalancer: Add cancel command. Contributed by Anu Engineer.\n",
      "commitDate": "23/06/16 6:21 PM",
      "commitName": "43eee50966191e9cfdb7ab19383edb3a44f93481",
      "commitAuthor": "Anu Engineer",
      "diff": "@@ -0,0 +1,25 @@\n+  public void execute(CommandLine cmd) throws Exception {\n+    LOG.info(\"Executing \\\"Cancel plan\\\" command.\");\n+    Preconditions.checkState(cmd.hasOption(DiskBalancer.CANCEL));\n+    verifyCommandOptions(DiskBalancer.CANCEL, cmd);\n+\n+    // We can cancel a plan using datanode address and plan ID\n+    // that you can read from a datanode using queryStatus\n+    if(cmd.hasOption(DiskBalancer.NODE)) {\n+      String nodeAddress \u003d cmd.getOptionValue(DiskBalancer.NODE);\n+      String planHash \u003d cmd.getOptionValue(DiskBalancer.CANCEL);\n+      cancelPlanUsingHash(nodeAddress, planHash);\n+    } else {\n+      // Or you can cancel a plan using the plan file. If the user\n+      // points us to the plan file, we can compute the hash as well as read\n+      // the address of the datanode from the plan file.\n+      String planFile \u003d cmd.getOptionValue(DiskBalancer.CANCEL);\n+      Preconditions.checkArgument(planFile \u003d\u003d null || planFile.isEmpty(),\n+          \"Invalid plan file specified.\");\n+      String planData \u003d null;\n+      try (FSDataInputStream plan \u003d open(planFile)) {\n+        planData \u003d IOUtils.toString(plan);\n+      }\n+      cancelPlan(planData);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void execute(CommandLine cmd) throws Exception {\n    LOG.info(\"Executing \\\"Cancel plan\\\" command.\");\n    Preconditions.checkState(cmd.hasOption(DiskBalancer.CANCEL));\n    verifyCommandOptions(DiskBalancer.CANCEL, cmd);\n\n    // We can cancel a plan using datanode address and plan ID\n    // that you can read from a datanode using queryStatus\n    if(cmd.hasOption(DiskBalancer.NODE)) {\n      String nodeAddress \u003d cmd.getOptionValue(DiskBalancer.NODE);\n      String planHash \u003d cmd.getOptionValue(DiskBalancer.CANCEL);\n      cancelPlanUsingHash(nodeAddress, planHash);\n    } else {\n      // Or you can cancel a plan using the plan file. If the user\n      // points us to the plan file, we can compute the hash as well as read\n      // the address of the datanode from the plan file.\n      String planFile \u003d cmd.getOptionValue(DiskBalancer.CANCEL);\n      Preconditions.checkArgument(planFile \u003d\u003d null || planFile.isEmpty(),\n          \"Invalid plan file specified.\");\n      String planData \u003d null;\n      try (FSDataInputStream plan \u003d open(planFile)) {\n        planData \u003d IOUtils.toString(plan);\n      }\n      cancelPlan(planData);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/CancelCommand.java"
    }
  }
}