{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSDirectory.java",
  "functionName": "addLastINode",
  "functionId": "addLastINode___existing-INodesInPath__inode-INode__modes-FsPermission__checkQuota-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
  "functionStartLine": 1314,
  "functionEndLine": 1364,
  "numCommitsSeen": 873,
  "timeTaken": 15028,
  "changeHistory": [
    "3c117163a343d7da7ac958e22789b461c24efa5f",
    "4c57fb0cd9344290a9f4f6422c1457d69465eec7",
    "f0d5382ff3e31a47d13e4cb6c3a244cca82b17ce",
    "369ddc67bdaf61cca3f2f766ab504e2932f6fb72",
    "5dae97a584d30cef3e34141edfaca49c4ec57913",
    "8cb473124c1cf1c6f68ead7bde06558ebf7ce47e",
    "5caebbae8c2fc9ba2e32384657aee21641a1a6d0",
    "5776a41da08af653206bb94d7c76c9c4dcce059a",
    "9047eb516261b8c9c380d140a43dfdd5d701dee5",
    "7ee5ce3176a74d217551b5981f809a56c719424b",
    "1b3b09d94794622e8336220d897a1f10c4654677",
    "10dc6b09272dbf2022907681e134104e7d418021",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "3c117163a343d7da7ac958e22789b461c24efa5f": "Ybodychange",
    "4c57fb0cd9344290a9f4f6422c1457d69465eec7": "Ybodychange",
    "f0d5382ff3e31a47d13e4cb6c3a244cca82b17ce": "Ymultichange(Yparameterchange,Ybodychange)",
    "369ddc67bdaf61cca3f2f766ab504e2932f6fb72": "Ybodychange",
    "5dae97a584d30cef3e34141edfaca49c4ec57913": "Ybodychange",
    "8cb473124c1cf1c6f68ead7bde06558ebf7ce47e": "Ymodifierchange",
    "5caebbae8c2fc9ba2e32384657aee21641a1a6d0": "Ymultichange(Yparameterchange,Yreturntypechange,Ymodifierchange,Ybodychange)",
    "5776a41da08af653206bb94d7c76c9c4dcce059a": "Ybodychange",
    "9047eb516261b8c9c380d140a43dfdd5d701dee5": "Ymultichange(Yrename,Yparameterchange,Yreturntypechange,Yexceptionschange,Ybodychange)",
    "7ee5ce3176a74d217551b5981f809a56c719424b": "Ybodychange",
    "1b3b09d94794622e8336220d897a1f10c4654677": "Ybodychange",
    "10dc6b09272dbf2022907681e134104e7d418021": "Ymultichange(Yparameterchange,Ybodychange)",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "3c117163a343d7da7ac958e22789b461c24efa5f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14633. The StorageType quota and consume in QuotaFeature is not handled for rename. Contributed by Jinglun.\n",
      "commitDate": "03/09/19 9:29 AM",
      "commitName": "3c117163a343d7da7ac958e22789b461c24efa5f",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "29/11/18 1:55 PM",
      "commitNameOld": "0081b02e35306cb757c63d0f11a536941d73a139",
      "commitAuthorOld": "Tsz Wo Nicholas Sze",
      "daysBetweenCommits": 277.77,
      "commitsBetweenForRepo": 2073,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,51 @@\n   public INodesInPath addLastINode(INodesInPath existing, INode inode,\n       FsPermission modes, boolean checkQuota) throws QuotaExceededException {\n     assert existing.getLastINode() !\u003d null \u0026\u0026\n         existing.getLastINode().isDirectory();\n \n     final int pos \u003d existing.length();\n     // Disallow creation of /.reserved. This may be created when loading\n     // editlog/fsimage during upgrade since /.reserved was a valid name in older\n     // release. This may also be called when a user tries to create a file\n     // or directory /.reserved.\n     if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n       throw new HadoopIllegalArgumentException(\n           \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n               + \"be created. If this is during upgrade change the name of the \"\n               + \"existing file or directory to another name before upgrading \"\n               + \"to the new release.\");\n     }\n     final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n     // The filesystem limits are not really quotas, so this check may appear\n     // odd. It\u0027s because a rename operation deletes the src, tries to add\n     // to the dest, if that fails, re-adds the src from whence it came.\n     // The rename code disables the quota when it\u0027s restoring to the\n     // original location because a quota violation would cause the the item\n     // to go \"poof\".  The fs limits must be bypassed for the same reason.\n     if (checkQuota) {\n       final String parentPath \u003d existing.getPath();\n       verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n       verifyMaxDirItems(parent, parentPath);\n     }\n     // always verify inode name\n     verifyINodeName(inode.getLocalNameBytes());\n \n-    final QuotaCounts counts \u003d inode.computeQuotaUsage(getBlockStoragePolicySuite());\n+    final QuotaCounts counts \u003d inode\n+        .computeQuotaUsage(getBlockStoragePolicySuite(),\n+            parent.getStoragePolicyID(), false, Snapshot.CURRENT_STATE_ID);\n     updateCount(existing, pos, counts, checkQuota);\n \n     boolean isRename \u003d (inode.getParent() !\u003d null);\n     final boolean added \u003d parent.addChild(inode, true,\n         existing.getLatestSnapshotId());\n     if (!added) {\n       updateCountNoQuotaCheck(existing, pos, counts.negation());\n       return null;\n     } else {\n       if (!isRename) {\n         copyINodeDefaultAcl(inode, modes);\n       }\n       addToInodeMap(inode);\n     }\n     return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public INodesInPath addLastINode(INodesInPath existing, INode inode,\n      FsPermission modes, boolean checkQuota) throws QuotaExceededException {\n    assert existing.getLastINode() !\u003d null \u0026\u0026\n        existing.getLastINode().isDirectory();\n\n    final int pos \u003d existing.length();\n    // Disallow creation of /.reserved. This may be created when loading\n    // editlog/fsimage during upgrade since /.reserved was a valid name in older\n    // release. This may also be called when a user tries to create a file\n    // or directory /.reserved.\n    if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n      throw new HadoopIllegalArgumentException(\n          \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n              + \"be created. If this is during upgrade change the name of the \"\n              + \"existing file or directory to another name before upgrading \"\n              + \"to the new release.\");\n    }\n    final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n    // The filesystem limits are not really quotas, so this check may appear\n    // odd. It\u0027s because a rename operation deletes the src, tries to add\n    // to the dest, if that fails, re-adds the src from whence it came.\n    // The rename code disables the quota when it\u0027s restoring to the\n    // original location because a quota violation would cause the the item\n    // to go \"poof\".  The fs limits must be bypassed for the same reason.\n    if (checkQuota) {\n      final String parentPath \u003d existing.getPath();\n      verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n      verifyMaxDirItems(parent, parentPath);\n    }\n    // always verify inode name\n    verifyINodeName(inode.getLocalNameBytes());\n\n    final QuotaCounts counts \u003d inode\n        .computeQuotaUsage(getBlockStoragePolicySuite(),\n            parent.getStoragePolicyID(), false, Snapshot.CURRENT_STATE_ID);\n    updateCount(existing, pos, counts, checkQuota);\n\n    boolean isRename \u003d (inode.getParent() !\u003d null);\n    final boolean added \u003d parent.addChild(inode, true,\n        existing.getLatestSnapshotId());\n    if (!added) {\n      updateCountNoQuotaCheck(existing, pos, counts.negation());\n      return null;\n    } else {\n      if (!isRename) {\n        copyINodeDefaultAcl(inode, modes);\n      }\n      addToInodeMap(inode);\n    }\n    return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "4c57fb0cd9344290a9f4f6422c1457d69465eec7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13257. Code cleanup: INode never throws QuotaExceededException. Contributed by Tsz Wo Nicholas Sze.\n",
      "commitDate": "14/03/18 9:42 AM",
      "commitName": "4c57fb0cd9344290a9f4f6422c1457d69465eec7",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "14/12/17 12:58 PM",
      "commitNameOld": "f5a72424c0009c454aab6759c30f74b397a7e935",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 89.82,
      "commitsBetweenForRepo": 556,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,49 @@\n   public INodesInPath addLastINode(INodesInPath existing, INode inode,\n       FsPermission modes, boolean checkQuota) throws QuotaExceededException {\n     assert existing.getLastINode() !\u003d null \u0026\u0026\n         existing.getLastINode().isDirectory();\n \n     final int pos \u003d existing.length();\n     // Disallow creation of /.reserved. This may be created when loading\n     // editlog/fsimage during upgrade since /.reserved was a valid name in older\n     // release. This may also be called when a user tries to create a file\n     // or directory /.reserved.\n     if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n       throw new HadoopIllegalArgumentException(\n           \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n               + \"be created. If this is during upgrade change the name of the \"\n               + \"existing file or directory to another name before upgrading \"\n               + \"to the new release.\");\n     }\n     final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n     // The filesystem limits are not really quotas, so this check may appear\n     // odd. It\u0027s because a rename operation deletes the src, tries to add\n     // to the dest, if that fails, re-adds the src from whence it came.\n     // The rename code disables the quota when it\u0027s restoring to the\n     // original location because a quota violation would cause the the item\n     // to go \"poof\".  The fs limits must be bypassed for the same reason.\n     if (checkQuota) {\n       final String parentPath \u003d existing.getPath();\n       verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n       verifyMaxDirItems(parent, parentPath);\n     }\n     // always verify inode name\n     verifyINodeName(inode.getLocalNameBytes());\n \n     final QuotaCounts counts \u003d inode.computeQuotaUsage(getBlockStoragePolicySuite());\n     updateCount(existing, pos, counts, checkQuota);\n \n     boolean isRename \u003d (inode.getParent() !\u003d null);\n-    boolean added;\n-    try {\n-      added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n-    } catch (QuotaExceededException e) {\n-      updateCountNoQuotaCheck(existing, pos, counts.negation());\n-      throw e;\n-    }\n+    final boolean added \u003d parent.addChild(inode, true,\n+        existing.getLatestSnapshotId());\n     if (!added) {\n       updateCountNoQuotaCheck(existing, pos, counts.negation());\n       return null;\n     } else {\n       if (!isRename) {\n         copyINodeDefaultAcl(inode, modes);\n       }\n       addToInodeMap(inode);\n     }\n     return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public INodesInPath addLastINode(INodesInPath existing, INode inode,\n      FsPermission modes, boolean checkQuota) throws QuotaExceededException {\n    assert existing.getLastINode() !\u003d null \u0026\u0026\n        existing.getLastINode().isDirectory();\n\n    final int pos \u003d existing.length();\n    // Disallow creation of /.reserved. This may be created when loading\n    // editlog/fsimage during upgrade since /.reserved was a valid name in older\n    // release. This may also be called when a user tries to create a file\n    // or directory /.reserved.\n    if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n      throw new HadoopIllegalArgumentException(\n          \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n              + \"be created. If this is during upgrade change the name of the \"\n              + \"existing file or directory to another name before upgrading \"\n              + \"to the new release.\");\n    }\n    final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n    // The filesystem limits are not really quotas, so this check may appear\n    // odd. It\u0027s because a rename operation deletes the src, tries to add\n    // to the dest, if that fails, re-adds the src from whence it came.\n    // The rename code disables the quota when it\u0027s restoring to the\n    // original location because a quota violation would cause the the item\n    // to go \"poof\".  The fs limits must be bypassed for the same reason.\n    if (checkQuota) {\n      final String parentPath \u003d existing.getPath();\n      verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n      verifyMaxDirItems(parent, parentPath);\n    }\n    // always verify inode name\n    verifyINodeName(inode.getLocalNameBytes());\n\n    final QuotaCounts counts \u003d inode.computeQuotaUsage(getBlockStoragePolicySuite());\n    updateCount(existing, pos, counts, checkQuota);\n\n    boolean isRename \u003d (inode.getParent() !\u003d null);\n    final boolean added \u003d parent.addChild(inode, true,\n        existing.getLatestSnapshotId());\n    if (!added) {\n      updateCountNoQuotaCheck(existing, pos, counts.negation());\n      return null;\n    } else {\n      if (!isRename) {\n        copyINodeDefaultAcl(inode, modes);\n      }\n      addToInodeMap(inode);\n    }\n    return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "f0d5382ff3e31a47d13e4cb6c3a244cca82b17ce": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6962. ACL inheritance conflicts with umaskmode. Contributed by Chris Nauroth.\n",
      "commitDate": "06/09/16 11:02 AM",
      "commitName": "f0d5382ff3e31a47d13e4cb6c3a244cca82b17ce",
      "commitAuthor": "Chris Nauroth",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6962. ACL inheritance conflicts with umaskmode. Contributed by Chris Nauroth.\n",
          "commitDate": "06/09/16 11:02 AM",
          "commitName": "f0d5382ff3e31a47d13e4cb6c3a244cca82b17ce",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "24/08/16 6:46 AM",
          "commitNameOld": "ec252ce0fc0998ce13f31af3440c08a236328e5a",
          "commitAuthorOld": "Daryn Sharp",
          "daysBetweenCommits": 13.18,
          "commitsBetweenForRepo": 72,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,54 +1,54 @@\n   public INodesInPath addLastINode(INodesInPath existing, INode inode,\n-      boolean checkQuota) throws QuotaExceededException {\n+      FsPermission modes, boolean checkQuota) throws QuotaExceededException {\n     assert existing.getLastINode() !\u003d null \u0026\u0026\n         existing.getLastINode().isDirectory();\n \n     final int pos \u003d existing.length();\n     // Disallow creation of /.reserved. This may be created when loading\n     // editlog/fsimage during upgrade since /.reserved was a valid name in older\n     // release. This may also be called when a user tries to create a file\n     // or directory /.reserved.\n     if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n       throw new HadoopIllegalArgumentException(\n           \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n               + \"be created. If this is during upgrade change the name of the \"\n               + \"existing file or directory to another name before upgrading \"\n               + \"to the new release.\");\n     }\n     final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n     // The filesystem limits are not really quotas, so this check may appear\n     // odd. It\u0027s because a rename operation deletes the src, tries to add\n     // to the dest, if that fails, re-adds the src from whence it came.\n     // The rename code disables the quota when it\u0027s restoring to the\n     // original location because a quota violation would cause the the item\n     // to go \"poof\".  The fs limits must be bypassed for the same reason.\n     if (checkQuota) {\n       final String parentPath \u003d existing.getPath();\n       verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n       verifyMaxDirItems(parent, parentPath);\n     }\n     // always verify inode name\n     verifyINodeName(inode.getLocalNameBytes());\n \n     final QuotaCounts counts \u003d inode.computeQuotaUsage(getBlockStoragePolicySuite());\n     updateCount(existing, pos, counts, checkQuota);\n \n     boolean isRename \u003d (inode.getParent() !\u003d null);\n     boolean added;\n     try {\n       added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n     } catch (QuotaExceededException e) {\n       updateCountNoQuotaCheck(existing, pos, counts.negation());\n       throw e;\n     }\n     if (!added) {\n       updateCountNoQuotaCheck(existing, pos, counts.negation());\n       return null;\n     } else {\n       if (!isRename) {\n-        AclStorage.copyINodeDefaultAcl(inode);\n+        copyINodeDefaultAcl(inode, modes);\n       }\n       addToInodeMap(inode);\n     }\n     return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public INodesInPath addLastINode(INodesInPath existing, INode inode,\n      FsPermission modes, boolean checkQuota) throws QuotaExceededException {\n    assert existing.getLastINode() !\u003d null \u0026\u0026\n        existing.getLastINode().isDirectory();\n\n    final int pos \u003d existing.length();\n    // Disallow creation of /.reserved. This may be created when loading\n    // editlog/fsimage during upgrade since /.reserved was a valid name in older\n    // release. This may also be called when a user tries to create a file\n    // or directory /.reserved.\n    if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n      throw new HadoopIllegalArgumentException(\n          \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n              + \"be created. If this is during upgrade change the name of the \"\n              + \"existing file or directory to another name before upgrading \"\n              + \"to the new release.\");\n    }\n    final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n    // The filesystem limits are not really quotas, so this check may appear\n    // odd. It\u0027s because a rename operation deletes the src, tries to add\n    // to the dest, if that fails, re-adds the src from whence it came.\n    // The rename code disables the quota when it\u0027s restoring to the\n    // original location because a quota violation would cause the the item\n    // to go \"poof\".  The fs limits must be bypassed for the same reason.\n    if (checkQuota) {\n      final String parentPath \u003d existing.getPath();\n      verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n      verifyMaxDirItems(parent, parentPath);\n    }\n    // always verify inode name\n    verifyINodeName(inode.getLocalNameBytes());\n\n    final QuotaCounts counts \u003d inode.computeQuotaUsage(getBlockStoragePolicySuite());\n    updateCount(existing, pos, counts, checkQuota);\n\n    boolean isRename \u003d (inode.getParent() !\u003d null);\n    boolean added;\n    try {\n      added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n    } catch (QuotaExceededException e) {\n      updateCountNoQuotaCheck(existing, pos, counts.negation());\n      throw e;\n    }\n    if (!added) {\n      updateCountNoQuotaCheck(existing, pos, counts.negation());\n      return null;\n    } else {\n      if (!isRename) {\n        copyINodeDefaultAcl(inode, modes);\n      }\n      addToInodeMap(inode);\n    }\n    return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[existing-INodesInPath, inode-INode, checkQuota-boolean]",
            "newValue": "[existing-INodesInPath, inode-INode, modes-FsPermission, checkQuota-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6962. ACL inheritance conflicts with umaskmode. Contributed by Chris Nauroth.\n",
          "commitDate": "06/09/16 11:02 AM",
          "commitName": "f0d5382ff3e31a47d13e4cb6c3a244cca82b17ce",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "24/08/16 6:46 AM",
          "commitNameOld": "ec252ce0fc0998ce13f31af3440c08a236328e5a",
          "commitAuthorOld": "Daryn Sharp",
          "daysBetweenCommits": 13.18,
          "commitsBetweenForRepo": 72,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,54 +1,54 @@\n   public INodesInPath addLastINode(INodesInPath existing, INode inode,\n-      boolean checkQuota) throws QuotaExceededException {\n+      FsPermission modes, boolean checkQuota) throws QuotaExceededException {\n     assert existing.getLastINode() !\u003d null \u0026\u0026\n         existing.getLastINode().isDirectory();\n \n     final int pos \u003d existing.length();\n     // Disallow creation of /.reserved. This may be created when loading\n     // editlog/fsimage during upgrade since /.reserved was a valid name in older\n     // release. This may also be called when a user tries to create a file\n     // or directory /.reserved.\n     if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n       throw new HadoopIllegalArgumentException(\n           \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n               + \"be created. If this is during upgrade change the name of the \"\n               + \"existing file or directory to another name before upgrading \"\n               + \"to the new release.\");\n     }\n     final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n     // The filesystem limits are not really quotas, so this check may appear\n     // odd. It\u0027s because a rename operation deletes the src, tries to add\n     // to the dest, if that fails, re-adds the src from whence it came.\n     // The rename code disables the quota when it\u0027s restoring to the\n     // original location because a quota violation would cause the the item\n     // to go \"poof\".  The fs limits must be bypassed for the same reason.\n     if (checkQuota) {\n       final String parentPath \u003d existing.getPath();\n       verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n       verifyMaxDirItems(parent, parentPath);\n     }\n     // always verify inode name\n     verifyINodeName(inode.getLocalNameBytes());\n \n     final QuotaCounts counts \u003d inode.computeQuotaUsage(getBlockStoragePolicySuite());\n     updateCount(existing, pos, counts, checkQuota);\n \n     boolean isRename \u003d (inode.getParent() !\u003d null);\n     boolean added;\n     try {\n       added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n     } catch (QuotaExceededException e) {\n       updateCountNoQuotaCheck(existing, pos, counts.negation());\n       throw e;\n     }\n     if (!added) {\n       updateCountNoQuotaCheck(existing, pos, counts.negation());\n       return null;\n     } else {\n       if (!isRename) {\n-        AclStorage.copyINodeDefaultAcl(inode);\n+        copyINodeDefaultAcl(inode, modes);\n       }\n       addToInodeMap(inode);\n     }\n     return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public INodesInPath addLastINode(INodesInPath existing, INode inode,\n      FsPermission modes, boolean checkQuota) throws QuotaExceededException {\n    assert existing.getLastINode() !\u003d null \u0026\u0026\n        existing.getLastINode().isDirectory();\n\n    final int pos \u003d existing.length();\n    // Disallow creation of /.reserved. This may be created when loading\n    // editlog/fsimage during upgrade since /.reserved was a valid name in older\n    // release. This may also be called when a user tries to create a file\n    // or directory /.reserved.\n    if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n      throw new HadoopIllegalArgumentException(\n          \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n              + \"be created. If this is during upgrade change the name of the \"\n              + \"existing file or directory to another name before upgrading \"\n              + \"to the new release.\");\n    }\n    final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n    // The filesystem limits are not really quotas, so this check may appear\n    // odd. It\u0027s because a rename operation deletes the src, tries to add\n    // to the dest, if that fails, re-adds the src from whence it came.\n    // The rename code disables the quota when it\u0027s restoring to the\n    // original location because a quota violation would cause the the item\n    // to go \"poof\".  The fs limits must be bypassed for the same reason.\n    if (checkQuota) {\n      final String parentPath \u003d existing.getPath();\n      verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n      verifyMaxDirItems(parent, parentPath);\n    }\n    // always verify inode name\n    verifyINodeName(inode.getLocalNameBytes());\n\n    final QuotaCounts counts \u003d inode.computeQuotaUsage(getBlockStoragePolicySuite());\n    updateCount(existing, pos, counts, checkQuota);\n\n    boolean isRename \u003d (inode.getParent() !\u003d null);\n    boolean added;\n    try {\n      added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n    } catch (QuotaExceededException e) {\n      updateCountNoQuotaCheck(existing, pos, counts.negation());\n      throw e;\n    }\n    if (!added) {\n      updateCountNoQuotaCheck(existing, pos, counts.negation());\n      return null;\n    } else {\n      if (!isRename) {\n        copyINodeDefaultAcl(inode, modes);\n      }\n      addToInodeMap(inode);\n    }\n    return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {}
        }
      ]
    },
    "369ddc67bdaf61cca3f2f766ab504e2932f6fb72": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8153. Error Message points to wrong parent directory in case of path component name length error. Contributed by Anu Engineer.\n",
      "commitDate": "16/04/15 10:13 PM",
      "commitName": "369ddc67bdaf61cca3f2f766ab504e2932f6fb72",
      "commitAuthor": "Jitendra Pandey",
      "commitDateOld": "08/04/15 1:38 PM",
      "commitNameOld": "285b31e75e51ec8e3a796c2cb0208739368ca9b8",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 8.36,
      "commitsBetweenForRepo": 73,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,54 @@\n   public INodesInPath addLastINode(INodesInPath existing, INode inode,\n       boolean checkQuota) throws QuotaExceededException {\n     assert existing.getLastINode() !\u003d null \u0026\u0026\n         existing.getLastINode().isDirectory();\n \n     final int pos \u003d existing.length();\n     // Disallow creation of /.reserved. This may be created when loading\n     // editlog/fsimage during upgrade since /.reserved was a valid name in older\n     // release. This may also be called when a user tries to create a file\n     // or directory /.reserved.\n     if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n       throw new HadoopIllegalArgumentException(\n           \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n               + \"be created. If this is during upgrade change the name of the \"\n               + \"existing file or directory to another name before upgrading \"\n               + \"to the new release.\");\n     }\n     final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n     // The filesystem limits are not really quotas, so this check may appear\n     // odd. It\u0027s because a rename operation deletes the src, tries to add\n     // to the dest, if that fails, re-adds the src from whence it came.\n     // The rename code disables the quota when it\u0027s restoring to the\n     // original location because a quota violation would cause the the item\n     // to go \"poof\".  The fs limits must be bypassed for the same reason.\n     if (checkQuota) {\n-      final String parentPath \u003d existing.getPath(pos - 1);\n+      final String parentPath \u003d existing.getPath();\n       verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n       verifyMaxDirItems(parent, parentPath);\n     }\n     // always verify inode name\n     verifyINodeName(inode.getLocalNameBytes());\n \n     final QuotaCounts counts \u003d inode.computeQuotaUsage(getBlockStoragePolicySuite());\n     updateCount(existing, pos, counts, checkQuota);\n \n     boolean isRename \u003d (inode.getParent() !\u003d null);\n     boolean added;\n     try {\n       added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n     } catch (QuotaExceededException e) {\n       updateCountNoQuotaCheck(existing, pos, counts.negation());\n       throw e;\n     }\n     if (!added) {\n       updateCountNoQuotaCheck(existing, pos, counts.negation());\n       return null;\n     } else {\n       if (!isRename) {\n         AclStorage.copyINodeDefaultAcl(inode);\n       }\n       addToInodeMap(inode);\n     }\n     return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public INodesInPath addLastINode(INodesInPath existing, INode inode,\n      boolean checkQuota) throws QuotaExceededException {\n    assert existing.getLastINode() !\u003d null \u0026\u0026\n        existing.getLastINode().isDirectory();\n\n    final int pos \u003d existing.length();\n    // Disallow creation of /.reserved. This may be created when loading\n    // editlog/fsimage during upgrade since /.reserved was a valid name in older\n    // release. This may also be called when a user tries to create a file\n    // or directory /.reserved.\n    if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n      throw new HadoopIllegalArgumentException(\n          \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n              + \"be created. If this is during upgrade change the name of the \"\n              + \"existing file or directory to another name before upgrading \"\n              + \"to the new release.\");\n    }\n    final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n    // The filesystem limits are not really quotas, so this check may appear\n    // odd. It\u0027s because a rename operation deletes the src, tries to add\n    // to the dest, if that fails, re-adds the src from whence it came.\n    // The rename code disables the quota when it\u0027s restoring to the\n    // original location because a quota violation would cause the the item\n    // to go \"poof\".  The fs limits must be bypassed for the same reason.\n    if (checkQuota) {\n      final String parentPath \u003d existing.getPath();\n      verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n      verifyMaxDirItems(parent, parentPath);\n    }\n    // always verify inode name\n    verifyINodeName(inode.getLocalNameBytes());\n\n    final QuotaCounts counts \u003d inode.computeQuotaUsage(getBlockStoragePolicySuite());\n    updateCount(existing, pos, counts, checkQuota);\n\n    boolean isRename \u003d (inode.getParent() !\u003d null);\n    boolean added;\n    try {\n      added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n    } catch (QuotaExceededException e) {\n      updateCountNoQuotaCheck(existing, pos, counts.negation());\n      throw e;\n    }\n    if (!added) {\n      updateCountNoQuotaCheck(existing, pos, counts.negation());\n      return null;\n    } else {\n      if (!isRename) {\n        AclStorage.copyINodeDefaultAcl(inode);\n      }\n      addToInodeMap(inode);\n    }\n    return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "5dae97a584d30cef3e34141edfaca49c4ec57913": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7723. Quota By Storage Type namenode implemenation. (Contributed by Xiaoyu Yao)\n",
      "commitDate": "11/02/15 10:41 AM",
      "commitName": "5dae97a584d30cef3e34141edfaca49c4ec57913",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "08/02/15 11:51 AM",
      "commitNameOld": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 2.95,
      "commitsBetweenForRepo": 40,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,56 +1,54 @@\n   public INodesInPath addLastINode(INodesInPath existing, INode inode,\n       boolean checkQuota) throws QuotaExceededException {\n     assert existing.getLastINode() !\u003d null \u0026\u0026\n         existing.getLastINode().isDirectory();\n \n     final int pos \u003d existing.length();\n     // Disallow creation of /.reserved. This may be created when loading\n     // editlog/fsimage during upgrade since /.reserved was a valid name in older\n     // release. This may also be called when a user tries to create a file\n     // or directory /.reserved.\n     if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n       throw new HadoopIllegalArgumentException(\n           \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n               + \"be created. If this is during upgrade change the name of the \"\n               + \"existing file or directory to another name before upgrading \"\n               + \"to the new release.\");\n     }\n     final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n     // The filesystem limits are not really quotas, so this check may appear\n     // odd. It\u0027s because a rename operation deletes the src, tries to add\n     // to the dest, if that fails, re-adds the src from whence it came.\n     // The rename code disables the quota when it\u0027s restoring to the\n-    // original location becase a quota violation would cause the the item\n+    // original location because a quota violation would cause the the item\n     // to go \"poof\".  The fs limits must be bypassed for the same reason.\n     if (checkQuota) {\n       final String parentPath \u003d existing.getPath(pos - 1);\n       verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n       verifyMaxDirItems(parent, parentPath);\n     }\n     // always verify inode name\n     verifyINodeName(inode.getLocalNameBytes());\n \n-    final Quota.Counts counts \u003d inode.computeQuotaUsage();\n-    updateCount(existing, pos,\n-        counts.get(Quota.NAMESPACE), counts.get(Quota.DISKSPACE), checkQuota);\n+    final QuotaCounts counts \u003d inode.computeQuotaUsage(getBlockStoragePolicySuite());\n+    updateCount(existing, pos, counts, checkQuota);\n+\n     boolean isRename \u003d (inode.getParent() !\u003d null);\n     boolean added;\n     try {\n       added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n     } catch (QuotaExceededException e) {\n-      updateCountNoQuotaCheck(existing, pos,\n-          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n+      updateCountNoQuotaCheck(existing, pos, counts.negation());\n       throw e;\n     }\n     if (!added) {\n-      updateCountNoQuotaCheck(existing, pos,\n-          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n+      updateCountNoQuotaCheck(existing, pos, counts.negation());\n       return null;\n     } else {\n       if (!isRename) {\n         AclStorage.copyINodeDefaultAcl(inode);\n       }\n       addToInodeMap(inode);\n     }\n     return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public INodesInPath addLastINode(INodesInPath existing, INode inode,\n      boolean checkQuota) throws QuotaExceededException {\n    assert existing.getLastINode() !\u003d null \u0026\u0026\n        existing.getLastINode().isDirectory();\n\n    final int pos \u003d existing.length();\n    // Disallow creation of /.reserved. This may be created when loading\n    // editlog/fsimage during upgrade since /.reserved was a valid name in older\n    // release. This may also be called when a user tries to create a file\n    // or directory /.reserved.\n    if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n      throw new HadoopIllegalArgumentException(\n          \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n              + \"be created. If this is during upgrade change the name of the \"\n              + \"existing file or directory to another name before upgrading \"\n              + \"to the new release.\");\n    }\n    final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n    // The filesystem limits are not really quotas, so this check may appear\n    // odd. It\u0027s because a rename operation deletes the src, tries to add\n    // to the dest, if that fails, re-adds the src from whence it came.\n    // The rename code disables the quota when it\u0027s restoring to the\n    // original location because a quota violation would cause the the item\n    // to go \"poof\".  The fs limits must be bypassed for the same reason.\n    if (checkQuota) {\n      final String parentPath \u003d existing.getPath(pos - 1);\n      verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n      verifyMaxDirItems(parent, parentPath);\n    }\n    // always verify inode name\n    verifyINodeName(inode.getLocalNameBytes());\n\n    final QuotaCounts counts \u003d inode.computeQuotaUsage(getBlockStoragePolicySuite());\n    updateCount(existing, pos, counts, checkQuota);\n\n    boolean isRename \u003d (inode.getParent() !\u003d null);\n    boolean added;\n    try {\n      added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n    } catch (QuotaExceededException e) {\n      updateCountNoQuotaCheck(existing, pos, counts.negation());\n      throw e;\n    }\n    if (!added) {\n      updateCountNoQuotaCheck(existing, pos, counts.negation());\n      return null;\n    } else {\n      if (!isRename) {\n        AclStorage.copyINodeDefaultAcl(inode);\n      }\n      addToInodeMap(inode);\n    }\n    return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "8cb473124c1cf1c6f68ead7bde06558ebf7ce47e": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-6651. Deletion failure can leak inodes permanently. Contributed by Jing Zhao.\n",
      "commitDate": "02/02/15 4:32 PM",
      "commitName": "8cb473124c1cf1c6f68ead7bde06558ebf7ce47e",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/01/15 3:25 PM",
      "commitNameOld": "d244574d03903b0514b0308da85d2f06c2384524",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 5.05,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,56 +1,56 @@\n-  INodesInPath addLastINode(INodesInPath existing, INode inode,\n+  public INodesInPath addLastINode(INodesInPath existing, INode inode,\n       boolean checkQuota) throws QuotaExceededException {\n     assert existing.getLastINode() !\u003d null \u0026\u0026\n         existing.getLastINode().isDirectory();\n \n     final int pos \u003d existing.length();\n     // Disallow creation of /.reserved. This may be created when loading\n     // editlog/fsimage during upgrade since /.reserved was a valid name in older\n     // release. This may also be called when a user tries to create a file\n     // or directory /.reserved.\n     if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n       throw new HadoopIllegalArgumentException(\n           \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n               + \"be created. If this is during upgrade change the name of the \"\n               + \"existing file or directory to another name before upgrading \"\n               + \"to the new release.\");\n     }\n     final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n     // The filesystem limits are not really quotas, so this check may appear\n     // odd. It\u0027s because a rename operation deletes the src, tries to add\n     // to the dest, if that fails, re-adds the src from whence it came.\n     // The rename code disables the quota when it\u0027s restoring to the\n     // original location becase a quota violation would cause the the item\n     // to go \"poof\".  The fs limits must be bypassed for the same reason.\n     if (checkQuota) {\n       final String parentPath \u003d existing.getPath(pos - 1);\n       verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n       verifyMaxDirItems(parent, parentPath);\n     }\n     // always verify inode name\n     verifyINodeName(inode.getLocalNameBytes());\n \n     final Quota.Counts counts \u003d inode.computeQuotaUsage();\n     updateCount(existing, pos,\n         counts.get(Quota.NAMESPACE), counts.get(Quota.DISKSPACE), checkQuota);\n     boolean isRename \u003d (inode.getParent() !\u003d null);\n     boolean added;\n     try {\n       added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n     } catch (QuotaExceededException e) {\n       updateCountNoQuotaCheck(existing, pos,\n           -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n       throw e;\n     }\n     if (!added) {\n       updateCountNoQuotaCheck(existing, pos,\n           -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n       return null;\n     } else {\n       if (!isRename) {\n         AclStorage.copyINodeDefaultAcl(inode);\n       }\n       addToInodeMap(inode);\n     }\n     return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public INodesInPath addLastINode(INodesInPath existing, INode inode,\n      boolean checkQuota) throws QuotaExceededException {\n    assert existing.getLastINode() !\u003d null \u0026\u0026\n        existing.getLastINode().isDirectory();\n\n    final int pos \u003d existing.length();\n    // Disallow creation of /.reserved. This may be created when loading\n    // editlog/fsimage during upgrade since /.reserved was a valid name in older\n    // release. This may also be called when a user tries to create a file\n    // or directory /.reserved.\n    if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n      throw new HadoopIllegalArgumentException(\n          \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n              + \"be created. If this is during upgrade change the name of the \"\n              + \"existing file or directory to another name before upgrading \"\n              + \"to the new release.\");\n    }\n    final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n    // The filesystem limits are not really quotas, so this check may appear\n    // odd. It\u0027s because a rename operation deletes the src, tries to add\n    // to the dest, if that fails, re-adds the src from whence it came.\n    // The rename code disables the quota when it\u0027s restoring to the\n    // original location becase a quota violation would cause the the item\n    // to go \"poof\".  The fs limits must be bypassed for the same reason.\n    if (checkQuota) {\n      final String parentPath \u003d existing.getPath(pos - 1);\n      verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n      verifyMaxDirItems(parent, parentPath);\n    }\n    // always verify inode name\n    verifyINodeName(inode.getLocalNameBytes());\n\n    final Quota.Counts counts \u003d inode.computeQuotaUsage();\n    updateCount(existing, pos,\n        counts.get(Quota.NAMESPACE), counts.get(Quota.DISKSPACE), checkQuota);\n    boolean isRename \u003d (inode.getParent() !\u003d null);\n    boolean added;\n    try {\n      added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n    } catch (QuotaExceededException e) {\n      updateCountNoQuotaCheck(existing, pos,\n          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n      throw e;\n    }\n    if (!added) {\n      updateCountNoQuotaCheck(existing, pos,\n          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n      return null;\n    } else {\n      if (!isRename) {\n        AclStorage.copyINodeDefaultAcl(inode);\n      }\n      addToInodeMap(inode);\n    }\n    return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[public]"
      }
    },
    "5caebbae8c2fc9ba2e32384657aee21641a1a6d0": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-7484. Make FSDirectory#addINode take existing INodes as its parameter. Contributed by Jing Zhao.\n",
      "commitDate": "22/12/14 11:19 PM",
      "commitName": "5caebbae8c2fc9ba2e32384657aee21641a1a6d0",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7484. Make FSDirectory#addINode take existing INodes as its parameter. Contributed by Jing Zhao.\n",
          "commitDate": "22/12/14 11:19 PM",
          "commitName": "5caebbae8c2fc9ba2e32384657aee21641a1a6d0",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "18/12/14 11:25 AM",
          "commitNameOld": "65f2a4ee600dfffa5203450261da3c1989de25a9",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 4.5,
          "commitsBetweenForRepo": 32,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,56 @@\n-  private boolean addLastINode(INodesInPath inodesInPath, INode inode,\n+  INodesInPath addLastINode(INodesInPath existing, INode inode,\n       boolean checkQuota) throws QuotaExceededException {\n-    final int pos \u003d inodesInPath.length() - 1;\n-    return addChild(inodesInPath, pos, inode, checkQuota);\n+    assert existing.getLastINode() !\u003d null \u0026\u0026\n+        existing.getLastINode().isDirectory();\n+\n+    final int pos \u003d existing.length();\n+    // Disallow creation of /.reserved. This may be created when loading\n+    // editlog/fsimage during upgrade since /.reserved was a valid name in older\n+    // release. This may also be called when a user tries to create a file\n+    // or directory /.reserved.\n+    if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n+      throw new HadoopIllegalArgumentException(\n+          \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n+              + \"be created. If this is during upgrade change the name of the \"\n+              + \"existing file or directory to another name before upgrading \"\n+              + \"to the new release.\");\n+    }\n+    final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n+    // The filesystem limits are not really quotas, so this check may appear\n+    // odd. It\u0027s because a rename operation deletes the src, tries to add\n+    // to the dest, if that fails, re-adds the src from whence it came.\n+    // The rename code disables the quota when it\u0027s restoring to the\n+    // original location becase a quota violation would cause the the item\n+    // to go \"poof\".  The fs limits must be bypassed for the same reason.\n+    if (checkQuota) {\n+      final String parentPath \u003d existing.getPath(pos - 1);\n+      verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n+      verifyMaxDirItems(parent, parentPath);\n+    }\n+    // always verify inode name\n+    verifyINodeName(inode.getLocalNameBytes());\n+\n+    final Quota.Counts counts \u003d inode.computeQuotaUsage();\n+    updateCount(existing, pos,\n+        counts.get(Quota.NAMESPACE), counts.get(Quota.DISKSPACE), checkQuota);\n+    boolean isRename \u003d (inode.getParent() !\u003d null);\n+    boolean added;\n+    try {\n+      added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n+    } catch (QuotaExceededException e) {\n+      updateCountNoQuotaCheck(existing, pos,\n+          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n+      throw e;\n+    }\n+    if (!added) {\n+      updateCountNoQuotaCheck(existing, pos,\n+          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n+      return null;\n+    } else {\n+      if (!isRename) {\n+        AclStorage.copyINodeDefaultAcl(inode);\n+      }\n+      addToInodeMap(inode);\n+    }\n+    return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  INodesInPath addLastINode(INodesInPath existing, INode inode,\n      boolean checkQuota) throws QuotaExceededException {\n    assert existing.getLastINode() !\u003d null \u0026\u0026\n        existing.getLastINode().isDirectory();\n\n    final int pos \u003d existing.length();\n    // Disallow creation of /.reserved. This may be created when loading\n    // editlog/fsimage during upgrade since /.reserved was a valid name in older\n    // release. This may also be called when a user tries to create a file\n    // or directory /.reserved.\n    if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n      throw new HadoopIllegalArgumentException(\n          \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n              + \"be created. If this is during upgrade change the name of the \"\n              + \"existing file or directory to another name before upgrading \"\n              + \"to the new release.\");\n    }\n    final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n    // The filesystem limits are not really quotas, so this check may appear\n    // odd. It\u0027s because a rename operation deletes the src, tries to add\n    // to the dest, if that fails, re-adds the src from whence it came.\n    // The rename code disables the quota when it\u0027s restoring to the\n    // original location becase a quota violation would cause the the item\n    // to go \"poof\".  The fs limits must be bypassed for the same reason.\n    if (checkQuota) {\n      final String parentPath \u003d existing.getPath(pos - 1);\n      verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n      verifyMaxDirItems(parent, parentPath);\n    }\n    // always verify inode name\n    verifyINodeName(inode.getLocalNameBytes());\n\n    final Quota.Counts counts \u003d inode.computeQuotaUsage();\n    updateCount(existing, pos,\n        counts.get(Quota.NAMESPACE), counts.get(Quota.DISKSPACE), checkQuota);\n    boolean isRename \u003d (inode.getParent() !\u003d null);\n    boolean added;\n    try {\n      added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n    } catch (QuotaExceededException e) {\n      updateCountNoQuotaCheck(existing, pos,\n          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n      throw e;\n    }\n    if (!added) {\n      updateCountNoQuotaCheck(existing, pos,\n          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n      return null;\n    } else {\n      if (!isRename) {\n        AclStorage.copyINodeDefaultAcl(inode);\n      }\n      addToInodeMap(inode);\n    }\n    return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[inodesInPath-INodesInPath, inode-INode, checkQuota-boolean]",
            "newValue": "[existing-INodesInPath, inode-INode, checkQuota-boolean]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-7484. Make FSDirectory#addINode take existing INodes as its parameter. Contributed by Jing Zhao.\n",
          "commitDate": "22/12/14 11:19 PM",
          "commitName": "5caebbae8c2fc9ba2e32384657aee21641a1a6d0",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "18/12/14 11:25 AM",
          "commitNameOld": "65f2a4ee600dfffa5203450261da3c1989de25a9",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 4.5,
          "commitsBetweenForRepo": 32,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,56 @@\n-  private boolean addLastINode(INodesInPath inodesInPath, INode inode,\n+  INodesInPath addLastINode(INodesInPath existing, INode inode,\n       boolean checkQuota) throws QuotaExceededException {\n-    final int pos \u003d inodesInPath.length() - 1;\n-    return addChild(inodesInPath, pos, inode, checkQuota);\n+    assert existing.getLastINode() !\u003d null \u0026\u0026\n+        existing.getLastINode().isDirectory();\n+\n+    final int pos \u003d existing.length();\n+    // Disallow creation of /.reserved. This may be created when loading\n+    // editlog/fsimage during upgrade since /.reserved was a valid name in older\n+    // release. This may also be called when a user tries to create a file\n+    // or directory /.reserved.\n+    if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n+      throw new HadoopIllegalArgumentException(\n+          \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n+              + \"be created. If this is during upgrade change the name of the \"\n+              + \"existing file or directory to another name before upgrading \"\n+              + \"to the new release.\");\n+    }\n+    final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n+    // The filesystem limits are not really quotas, so this check may appear\n+    // odd. It\u0027s because a rename operation deletes the src, tries to add\n+    // to the dest, if that fails, re-adds the src from whence it came.\n+    // The rename code disables the quota when it\u0027s restoring to the\n+    // original location becase a quota violation would cause the the item\n+    // to go \"poof\".  The fs limits must be bypassed for the same reason.\n+    if (checkQuota) {\n+      final String parentPath \u003d existing.getPath(pos - 1);\n+      verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n+      verifyMaxDirItems(parent, parentPath);\n+    }\n+    // always verify inode name\n+    verifyINodeName(inode.getLocalNameBytes());\n+\n+    final Quota.Counts counts \u003d inode.computeQuotaUsage();\n+    updateCount(existing, pos,\n+        counts.get(Quota.NAMESPACE), counts.get(Quota.DISKSPACE), checkQuota);\n+    boolean isRename \u003d (inode.getParent() !\u003d null);\n+    boolean added;\n+    try {\n+      added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n+    } catch (QuotaExceededException e) {\n+      updateCountNoQuotaCheck(existing, pos,\n+          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n+      throw e;\n+    }\n+    if (!added) {\n+      updateCountNoQuotaCheck(existing, pos,\n+          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n+      return null;\n+    } else {\n+      if (!isRename) {\n+        AclStorage.copyINodeDefaultAcl(inode);\n+      }\n+      addToInodeMap(inode);\n+    }\n+    return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  INodesInPath addLastINode(INodesInPath existing, INode inode,\n      boolean checkQuota) throws QuotaExceededException {\n    assert existing.getLastINode() !\u003d null \u0026\u0026\n        existing.getLastINode().isDirectory();\n\n    final int pos \u003d existing.length();\n    // Disallow creation of /.reserved. This may be created when loading\n    // editlog/fsimage during upgrade since /.reserved was a valid name in older\n    // release. This may also be called when a user tries to create a file\n    // or directory /.reserved.\n    if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n      throw new HadoopIllegalArgumentException(\n          \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n              + \"be created. If this is during upgrade change the name of the \"\n              + \"existing file or directory to another name before upgrading \"\n              + \"to the new release.\");\n    }\n    final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n    // The filesystem limits are not really quotas, so this check may appear\n    // odd. It\u0027s because a rename operation deletes the src, tries to add\n    // to the dest, if that fails, re-adds the src from whence it came.\n    // The rename code disables the quota when it\u0027s restoring to the\n    // original location becase a quota violation would cause the the item\n    // to go \"poof\".  The fs limits must be bypassed for the same reason.\n    if (checkQuota) {\n      final String parentPath \u003d existing.getPath(pos - 1);\n      verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n      verifyMaxDirItems(parent, parentPath);\n    }\n    // always verify inode name\n    verifyINodeName(inode.getLocalNameBytes());\n\n    final Quota.Counts counts \u003d inode.computeQuotaUsage();\n    updateCount(existing, pos,\n        counts.get(Quota.NAMESPACE), counts.get(Quota.DISKSPACE), checkQuota);\n    boolean isRename \u003d (inode.getParent() !\u003d null);\n    boolean added;\n    try {\n      added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n    } catch (QuotaExceededException e) {\n      updateCountNoQuotaCheck(existing, pos,\n          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n      throw e;\n    }\n    if (!added) {\n      updateCountNoQuotaCheck(existing, pos,\n          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n      return null;\n    } else {\n      if (!isRename) {\n        AclStorage.copyINodeDefaultAcl(inode);\n      }\n      addToInodeMap(inode);\n    }\n    return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "boolean",
            "newValue": "INodesInPath"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-7484. Make FSDirectory#addINode take existing INodes as its parameter. Contributed by Jing Zhao.\n",
          "commitDate": "22/12/14 11:19 PM",
          "commitName": "5caebbae8c2fc9ba2e32384657aee21641a1a6d0",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "18/12/14 11:25 AM",
          "commitNameOld": "65f2a4ee600dfffa5203450261da3c1989de25a9",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 4.5,
          "commitsBetweenForRepo": 32,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,56 @@\n-  private boolean addLastINode(INodesInPath inodesInPath, INode inode,\n+  INodesInPath addLastINode(INodesInPath existing, INode inode,\n       boolean checkQuota) throws QuotaExceededException {\n-    final int pos \u003d inodesInPath.length() - 1;\n-    return addChild(inodesInPath, pos, inode, checkQuota);\n+    assert existing.getLastINode() !\u003d null \u0026\u0026\n+        existing.getLastINode().isDirectory();\n+\n+    final int pos \u003d existing.length();\n+    // Disallow creation of /.reserved. This may be created when loading\n+    // editlog/fsimage during upgrade since /.reserved was a valid name in older\n+    // release. This may also be called when a user tries to create a file\n+    // or directory /.reserved.\n+    if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n+      throw new HadoopIllegalArgumentException(\n+          \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n+              + \"be created. If this is during upgrade change the name of the \"\n+              + \"existing file or directory to another name before upgrading \"\n+              + \"to the new release.\");\n+    }\n+    final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n+    // The filesystem limits are not really quotas, so this check may appear\n+    // odd. It\u0027s because a rename operation deletes the src, tries to add\n+    // to the dest, if that fails, re-adds the src from whence it came.\n+    // The rename code disables the quota when it\u0027s restoring to the\n+    // original location becase a quota violation would cause the the item\n+    // to go \"poof\".  The fs limits must be bypassed for the same reason.\n+    if (checkQuota) {\n+      final String parentPath \u003d existing.getPath(pos - 1);\n+      verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n+      verifyMaxDirItems(parent, parentPath);\n+    }\n+    // always verify inode name\n+    verifyINodeName(inode.getLocalNameBytes());\n+\n+    final Quota.Counts counts \u003d inode.computeQuotaUsage();\n+    updateCount(existing, pos,\n+        counts.get(Quota.NAMESPACE), counts.get(Quota.DISKSPACE), checkQuota);\n+    boolean isRename \u003d (inode.getParent() !\u003d null);\n+    boolean added;\n+    try {\n+      added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n+    } catch (QuotaExceededException e) {\n+      updateCountNoQuotaCheck(existing, pos,\n+          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n+      throw e;\n+    }\n+    if (!added) {\n+      updateCountNoQuotaCheck(existing, pos,\n+          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n+      return null;\n+    } else {\n+      if (!isRename) {\n+        AclStorage.copyINodeDefaultAcl(inode);\n+      }\n+      addToInodeMap(inode);\n+    }\n+    return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  INodesInPath addLastINode(INodesInPath existing, INode inode,\n      boolean checkQuota) throws QuotaExceededException {\n    assert existing.getLastINode() !\u003d null \u0026\u0026\n        existing.getLastINode().isDirectory();\n\n    final int pos \u003d existing.length();\n    // Disallow creation of /.reserved. This may be created when loading\n    // editlog/fsimage during upgrade since /.reserved was a valid name in older\n    // release. This may also be called when a user tries to create a file\n    // or directory /.reserved.\n    if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n      throw new HadoopIllegalArgumentException(\n          \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n              + \"be created. If this is during upgrade change the name of the \"\n              + \"existing file or directory to another name before upgrading \"\n              + \"to the new release.\");\n    }\n    final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n    // The filesystem limits are not really quotas, so this check may appear\n    // odd. It\u0027s because a rename operation deletes the src, tries to add\n    // to the dest, if that fails, re-adds the src from whence it came.\n    // The rename code disables the quota when it\u0027s restoring to the\n    // original location becase a quota violation would cause the the item\n    // to go \"poof\".  The fs limits must be bypassed for the same reason.\n    if (checkQuota) {\n      final String parentPath \u003d existing.getPath(pos - 1);\n      verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n      verifyMaxDirItems(parent, parentPath);\n    }\n    // always verify inode name\n    verifyINodeName(inode.getLocalNameBytes());\n\n    final Quota.Counts counts \u003d inode.computeQuotaUsage();\n    updateCount(existing, pos,\n        counts.get(Quota.NAMESPACE), counts.get(Quota.DISKSPACE), checkQuota);\n    boolean isRename \u003d (inode.getParent() !\u003d null);\n    boolean added;\n    try {\n      added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n    } catch (QuotaExceededException e) {\n      updateCountNoQuotaCheck(existing, pos,\n          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n      throw e;\n    }\n    if (!added) {\n      updateCountNoQuotaCheck(existing, pos,\n          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n      return null;\n    } else {\n      if (!isRename) {\n        AclStorage.copyINodeDefaultAcl(inode);\n      }\n      addToInodeMap(inode);\n    }\n    return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7484. Make FSDirectory#addINode take existing INodes as its parameter. Contributed by Jing Zhao.\n",
          "commitDate": "22/12/14 11:19 PM",
          "commitName": "5caebbae8c2fc9ba2e32384657aee21641a1a6d0",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "18/12/14 11:25 AM",
          "commitNameOld": "65f2a4ee600dfffa5203450261da3c1989de25a9",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 4.5,
          "commitsBetweenForRepo": 32,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,56 @@\n-  private boolean addLastINode(INodesInPath inodesInPath, INode inode,\n+  INodesInPath addLastINode(INodesInPath existing, INode inode,\n       boolean checkQuota) throws QuotaExceededException {\n-    final int pos \u003d inodesInPath.length() - 1;\n-    return addChild(inodesInPath, pos, inode, checkQuota);\n+    assert existing.getLastINode() !\u003d null \u0026\u0026\n+        existing.getLastINode().isDirectory();\n+\n+    final int pos \u003d existing.length();\n+    // Disallow creation of /.reserved. This may be created when loading\n+    // editlog/fsimage during upgrade since /.reserved was a valid name in older\n+    // release. This may also be called when a user tries to create a file\n+    // or directory /.reserved.\n+    if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n+      throw new HadoopIllegalArgumentException(\n+          \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n+              + \"be created. If this is during upgrade change the name of the \"\n+              + \"existing file or directory to another name before upgrading \"\n+              + \"to the new release.\");\n+    }\n+    final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n+    // The filesystem limits are not really quotas, so this check may appear\n+    // odd. It\u0027s because a rename operation deletes the src, tries to add\n+    // to the dest, if that fails, re-adds the src from whence it came.\n+    // The rename code disables the quota when it\u0027s restoring to the\n+    // original location becase a quota violation would cause the the item\n+    // to go \"poof\".  The fs limits must be bypassed for the same reason.\n+    if (checkQuota) {\n+      final String parentPath \u003d existing.getPath(pos - 1);\n+      verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n+      verifyMaxDirItems(parent, parentPath);\n+    }\n+    // always verify inode name\n+    verifyINodeName(inode.getLocalNameBytes());\n+\n+    final Quota.Counts counts \u003d inode.computeQuotaUsage();\n+    updateCount(existing, pos,\n+        counts.get(Quota.NAMESPACE), counts.get(Quota.DISKSPACE), checkQuota);\n+    boolean isRename \u003d (inode.getParent() !\u003d null);\n+    boolean added;\n+    try {\n+      added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n+    } catch (QuotaExceededException e) {\n+      updateCountNoQuotaCheck(existing, pos,\n+          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n+      throw e;\n+    }\n+    if (!added) {\n+      updateCountNoQuotaCheck(existing, pos,\n+          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n+      return null;\n+    } else {\n+      if (!isRename) {\n+        AclStorage.copyINodeDefaultAcl(inode);\n+      }\n+      addToInodeMap(inode);\n+    }\n+    return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  INodesInPath addLastINode(INodesInPath existing, INode inode,\n      boolean checkQuota) throws QuotaExceededException {\n    assert existing.getLastINode() !\u003d null \u0026\u0026\n        existing.getLastINode().isDirectory();\n\n    final int pos \u003d existing.length();\n    // Disallow creation of /.reserved. This may be created when loading\n    // editlog/fsimage during upgrade since /.reserved was a valid name in older\n    // release. This may also be called when a user tries to create a file\n    // or directory /.reserved.\n    if (pos \u003d\u003d 1 \u0026\u0026 existing.getINode(0) \u003d\u003d rootDir \u0026\u0026 isReservedName(inode)) {\n      throw new HadoopIllegalArgumentException(\n          \"File name \\\"\" + inode.getLocalName() + \"\\\" is reserved and cannot \"\n              + \"be created. If this is during upgrade change the name of the \"\n              + \"existing file or directory to another name before upgrading \"\n              + \"to the new release.\");\n    }\n    final INodeDirectory parent \u003d existing.getINode(pos - 1).asDirectory();\n    // The filesystem limits are not really quotas, so this check may appear\n    // odd. It\u0027s because a rename operation deletes the src, tries to add\n    // to the dest, if that fails, re-adds the src from whence it came.\n    // The rename code disables the quota when it\u0027s restoring to the\n    // original location becase a quota violation would cause the the item\n    // to go \"poof\".  The fs limits must be bypassed for the same reason.\n    if (checkQuota) {\n      final String parentPath \u003d existing.getPath(pos - 1);\n      verifyMaxComponentLength(inode.getLocalNameBytes(), parentPath);\n      verifyMaxDirItems(parent, parentPath);\n    }\n    // always verify inode name\n    verifyINodeName(inode.getLocalNameBytes());\n\n    final Quota.Counts counts \u003d inode.computeQuotaUsage();\n    updateCount(existing, pos,\n        counts.get(Quota.NAMESPACE), counts.get(Quota.DISKSPACE), checkQuota);\n    boolean isRename \u003d (inode.getParent() !\u003d null);\n    boolean added;\n    try {\n      added \u003d parent.addChild(inode, true, existing.getLatestSnapshotId());\n    } catch (QuotaExceededException e) {\n      updateCountNoQuotaCheck(existing, pos,\n          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n      throw e;\n    }\n    if (!added) {\n      updateCountNoQuotaCheck(existing, pos,\n          -counts.get(Quota.NAMESPACE), -counts.get(Quota.DISKSPACE));\n      return null;\n    } else {\n      if (!isRename) {\n        AclStorage.copyINodeDefaultAcl(inode);\n      }\n      addToInodeMap(inode);\n    }\n    return INodesInPath.append(existing, inode, inode.getLocalNameBytes());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {}
        }
      ]
    },
    "5776a41da08af653206bb94d7c76c9c4dcce059a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7498. Simplify the logic in INodesInPath. Contributed by Jing Zhao.\n",
      "commitDate": "09/12/14 11:37 AM",
      "commitName": "5776a41da08af653206bb94d7c76c9c4dcce059a",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "08/12/14 11:52 AM",
      "commitNameOld": "6c5bbd7a42d1e8b4416fd8870fd60c67867b35c9",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.99,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,5 @@\n-  private boolean addLastINode(INodesInPath inodesInPath,\n-      INode inode, boolean checkQuota) throws QuotaExceededException {\n-    final int pos \u003d inodesInPath.getINodes().length - 1;\n+  private boolean addLastINode(INodesInPath inodesInPath, INode inode,\n+      boolean checkQuota) throws QuotaExceededException {\n+    final int pos \u003d inodesInPath.length() - 1;\n     return addChild(inodesInPath, pos, inode, checkQuota);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean addLastINode(INodesInPath inodesInPath, INode inode,\n      boolean checkQuota) throws QuotaExceededException {\n    final int pos \u003d inodesInPath.length() - 1;\n    return addChild(inodesInPath, pos, inode, checkQuota);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "9047eb516261b8c9c380d140a43dfdd5d701dee5": {
      "type": "Ymultichange(Yrename,Yparameterchange,Yreturntypechange,Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-4209. Clean up the addNode/addChild/addChildNoQuotaCheck methods in FSDirectory and INodeDirectory.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1414447 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/11/12 2:36 PM",
      "commitName": "9047eb516261b8c9c380d140a43dfdd5d701dee5",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-4209. Clean up the addNode/addChild/addChildNoQuotaCheck methods in FSDirectory and INodeDirectory.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1414447 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/11/12 2:36 PM",
          "commitName": "9047eb516261b8c9c380d140a43dfdd5d701dee5",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/11/12 11:27 AM",
          "commitNameOld": "0f1899ee19ab13d5128801063b0ce17612c0e96f",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 6.13,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,5 @@\n-  private \u003cT extends INode\u003e T addNode(String src, T child, long childDiskspace\n-      ) throws QuotaExceededException, UnresolvedLinkException {\n-    byte[][] components \u003d INode.getPathComponents(src);\n-    byte[] path \u003d components[components.length-1];\n-    child.setLocalName(path);\n-    cacheName(child);\n-    writeLock();\n-    try {\n-      INodesInPath inodesInPath \u003d rootDir.getExistingPathINodes(components,\n-          components.length, false);\n-      return addChild(inodesInPath, inodesInPath.getINodes().length-1, child,\n-          childDiskspace, true);\n-    } finally {\n-      writeUnlock();\n-    }\n+  private boolean addLastINode(INodesInPath inodesInPath,\n+      INode inode, boolean checkQuota) throws QuotaExceededException {\n+    final int pos \u003d inodesInPath.getINodes().length - 1;\n+    return addChild(inodesInPath, pos, inode, checkQuota);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private boolean addLastINode(INodesInPath inodesInPath,\n      INode inode, boolean checkQuota) throws QuotaExceededException {\n    final int pos \u003d inodesInPath.getINodes().length - 1;\n    return addChild(inodesInPath, pos, inode, checkQuota);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "addNode",
            "newValue": "addLastINode"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4209. Clean up the addNode/addChild/addChildNoQuotaCheck methods in FSDirectory and INodeDirectory.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1414447 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/11/12 2:36 PM",
          "commitName": "9047eb516261b8c9c380d140a43dfdd5d701dee5",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/11/12 11:27 AM",
          "commitNameOld": "0f1899ee19ab13d5128801063b0ce17612c0e96f",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 6.13,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,5 @@\n-  private \u003cT extends INode\u003e T addNode(String src, T child, long childDiskspace\n-      ) throws QuotaExceededException, UnresolvedLinkException {\n-    byte[][] components \u003d INode.getPathComponents(src);\n-    byte[] path \u003d components[components.length-1];\n-    child.setLocalName(path);\n-    cacheName(child);\n-    writeLock();\n-    try {\n-      INodesInPath inodesInPath \u003d rootDir.getExistingPathINodes(components,\n-          components.length, false);\n-      return addChild(inodesInPath, inodesInPath.getINodes().length-1, child,\n-          childDiskspace, true);\n-    } finally {\n-      writeUnlock();\n-    }\n+  private boolean addLastINode(INodesInPath inodesInPath,\n+      INode inode, boolean checkQuota) throws QuotaExceededException {\n+    final int pos \u003d inodesInPath.getINodes().length - 1;\n+    return addChild(inodesInPath, pos, inode, checkQuota);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private boolean addLastINode(INodesInPath inodesInPath,\n      INode inode, boolean checkQuota) throws QuotaExceededException {\n    final int pos \u003d inodesInPath.getINodes().length - 1;\n    return addChild(inodesInPath, pos, inode, checkQuota);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[src-String, child-T, childDiskspace-long]",
            "newValue": "[inodesInPath-INodesInPath, inode-INode, checkQuota-boolean]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-4209. Clean up the addNode/addChild/addChildNoQuotaCheck methods in FSDirectory and INodeDirectory.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1414447 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/11/12 2:36 PM",
          "commitName": "9047eb516261b8c9c380d140a43dfdd5d701dee5",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/11/12 11:27 AM",
          "commitNameOld": "0f1899ee19ab13d5128801063b0ce17612c0e96f",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 6.13,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,5 @@\n-  private \u003cT extends INode\u003e T addNode(String src, T child, long childDiskspace\n-      ) throws QuotaExceededException, UnresolvedLinkException {\n-    byte[][] components \u003d INode.getPathComponents(src);\n-    byte[] path \u003d components[components.length-1];\n-    child.setLocalName(path);\n-    cacheName(child);\n-    writeLock();\n-    try {\n-      INodesInPath inodesInPath \u003d rootDir.getExistingPathINodes(components,\n-          components.length, false);\n-      return addChild(inodesInPath, inodesInPath.getINodes().length-1, child,\n-          childDiskspace, true);\n-    } finally {\n-      writeUnlock();\n-    }\n+  private boolean addLastINode(INodesInPath inodesInPath,\n+      INode inode, boolean checkQuota) throws QuotaExceededException {\n+    final int pos \u003d inodesInPath.getINodes().length - 1;\n+    return addChild(inodesInPath, pos, inode, checkQuota);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private boolean addLastINode(INodesInPath inodesInPath,\n      INode inode, boolean checkQuota) throws QuotaExceededException {\n    final int pos \u003d inodesInPath.getINodes().length - 1;\n    return addChild(inodesInPath, pos, inode, checkQuota);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "T",
            "newValue": "boolean"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-4209. Clean up the addNode/addChild/addChildNoQuotaCheck methods in FSDirectory and INodeDirectory.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1414447 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/11/12 2:36 PM",
          "commitName": "9047eb516261b8c9c380d140a43dfdd5d701dee5",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/11/12 11:27 AM",
          "commitNameOld": "0f1899ee19ab13d5128801063b0ce17612c0e96f",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 6.13,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,5 @@\n-  private \u003cT extends INode\u003e T addNode(String src, T child, long childDiskspace\n-      ) throws QuotaExceededException, UnresolvedLinkException {\n-    byte[][] components \u003d INode.getPathComponents(src);\n-    byte[] path \u003d components[components.length-1];\n-    child.setLocalName(path);\n-    cacheName(child);\n-    writeLock();\n-    try {\n-      INodesInPath inodesInPath \u003d rootDir.getExistingPathINodes(components,\n-          components.length, false);\n-      return addChild(inodesInPath, inodesInPath.getINodes().length-1, child,\n-          childDiskspace, true);\n-    } finally {\n-      writeUnlock();\n-    }\n+  private boolean addLastINode(INodesInPath inodesInPath,\n+      INode inode, boolean checkQuota) throws QuotaExceededException {\n+    final int pos \u003d inodesInPath.getINodes().length - 1;\n+    return addChild(inodesInPath, pos, inode, checkQuota);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private boolean addLastINode(INodesInPath inodesInPath,\n      INode inode, boolean checkQuota) throws QuotaExceededException {\n    final int pos \u003d inodesInPath.getINodes().length - 1;\n    return addChild(inodesInPath, pos, inode, checkQuota);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[QuotaExceededException, UnresolvedLinkException]",
            "newValue": "[QuotaExceededException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4209. Clean up the addNode/addChild/addChildNoQuotaCheck methods in FSDirectory and INodeDirectory.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1414447 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/11/12 2:36 PM",
          "commitName": "9047eb516261b8c9c380d140a43dfdd5d701dee5",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/11/12 11:27 AM",
          "commitNameOld": "0f1899ee19ab13d5128801063b0ce17612c0e96f",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 6.13,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,5 @@\n-  private \u003cT extends INode\u003e T addNode(String src, T child, long childDiskspace\n-      ) throws QuotaExceededException, UnresolvedLinkException {\n-    byte[][] components \u003d INode.getPathComponents(src);\n-    byte[] path \u003d components[components.length-1];\n-    child.setLocalName(path);\n-    cacheName(child);\n-    writeLock();\n-    try {\n-      INodesInPath inodesInPath \u003d rootDir.getExistingPathINodes(components,\n-          components.length, false);\n-      return addChild(inodesInPath, inodesInPath.getINodes().length-1, child,\n-          childDiskspace, true);\n-    } finally {\n-      writeUnlock();\n-    }\n+  private boolean addLastINode(INodesInPath inodesInPath,\n+      INode inode, boolean checkQuota) throws QuotaExceededException {\n+    final int pos \u003d inodesInPath.getINodes().length - 1;\n+    return addChild(inodesInPath, pos, inode, checkQuota);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private boolean addLastINode(INodesInPath inodesInPath,\n      INode inode, boolean checkQuota) throws QuotaExceededException {\n    final int pos \u003d inodesInPath.getINodes().length - 1;\n    return addChild(inodesInPath, pos, inode, checkQuota);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {}
        }
      ]
    },
    "7ee5ce3176a74d217551b5981f809a56c719424b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4151. Change the methods in FSDirectory to pass INodesInPath instead of INode[] as a parameter.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1406006 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/11/12 3:26 PM",
      "commitName": "7ee5ce3176a74d217551b5981f809a56c719424b",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "02/11/12 5:20 PM",
      "commitNameOld": "d174f574bafcfefc635c64a47f258b1ce5d5c84e",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 2.96,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,16 @@\n-  private \u003cT extends INode\u003e T addNode(String src, T child, \n-        long childDiskspace) \n-  throws QuotaExceededException, UnresolvedLinkException {\n+  private \u003cT extends INode\u003e T addNode(String src, T child, long childDiskspace\n+      ) throws QuotaExceededException, UnresolvedLinkException {\n     byte[][] components \u003d INode.getPathComponents(src);\n     byte[] path \u003d components[components.length-1];\n     child.setLocalName(path);\n     cacheName(child);\n     writeLock();\n     try {\n       INodesInPath inodesInPath \u003d rootDir.getExistingPathINodes(components,\n           components.length, false);\n-      INode[] inodes \u003d inodesInPath.getINodes();\n-      return addChild(inodes, inodes.length-1, child, childDiskspace);\n+      return addChild(inodesInPath, inodesInPath.getINodes().length-1, child,\n+          childDiskspace, true);\n     } finally {\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private \u003cT extends INode\u003e T addNode(String src, T child, long childDiskspace\n      ) throws QuotaExceededException, UnresolvedLinkException {\n    byte[][] components \u003d INode.getPathComponents(src);\n    byte[] path \u003d components[components.length-1];\n    child.setLocalName(path);\n    cacheName(child);\n    writeLock();\n    try {\n      INodesInPath inodesInPath \u003d rootDir.getExistingPathINodes(components,\n          components.length, false);\n      return addChild(inodesInPath, inodesInPath.getINodes().length-1, child,\n          childDiskspace, true);\n    } finally {\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "1b3b09d94794622e8336220d897a1f10c4654677": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4124. Refactor INodeDirectory#getExistingPathINodes() to enable returningmore than INode array. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1403304 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/10/12 7:11 AM",
      "commitName": "1b3b09d94794622e8336220d897a1f10c4654677",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "28/10/12 4:10 PM",
      "commitNameOld": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.63,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,17 @@\n   private \u003cT extends INode\u003e T addNode(String src, T child, \n         long childDiskspace) \n   throws QuotaExceededException, UnresolvedLinkException {\n     byte[][] components \u003d INode.getPathComponents(src);\n     byte[] path \u003d components[components.length-1];\n     child.setLocalName(path);\n     cacheName(child);\n-    INode[] inodes \u003d new INode[components.length];\n     writeLock();\n     try {\n-      rootDir.getExistingPathINodes(components, inodes, false);\n+      INodesInPath inodesInPath \u003d rootDir.getExistingPathINodes(components,\n+          components.length, false);\n+      INode[] inodes \u003d inodesInPath.getINodes();\n       return addChild(inodes, inodes.length-1, child, childDiskspace);\n     } finally {\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private \u003cT extends INode\u003e T addNode(String src, T child, \n        long childDiskspace) \n  throws QuotaExceededException, UnresolvedLinkException {\n    byte[][] components \u003d INode.getPathComponents(src);\n    byte[] path \u003d components[components.length-1];\n    child.setLocalName(path);\n    cacheName(child);\n    writeLock();\n    try {\n      INodesInPath inodesInPath \u003d rootDir.getExistingPathINodes(components,\n          components.length, false);\n      INode[] inodes \u003d inodesInPath.getINodes();\n      return addChild(inodes, inodes.length-1, child, childDiskspace);\n    } finally {\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "10dc6b09272dbf2022907681e134104e7d418021": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-1869. mkdirs should use the supplied permission for all of the created directories.  Contributed by Daryn Sharp\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1189546 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/10/11 5:02 PM",
      "commitName": "10dc6b09272dbf2022907681e134104e7d418021",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-1869. mkdirs should use the supplied permission for all of the created directories.  Contributed by Daryn Sharp\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1189546 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "26/10/11 5:02 PM",
          "commitName": "10dc6b09272dbf2022907681e134104e7d418021",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "22/09/11 1:25 AM",
          "commitNameOld": "d773bf0fb57bf6fb77dbdd52e1c186833c17361c",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 34.65,
          "commitsBetweenForRepo": 266,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,16 @@\n   private \u003cT extends INode\u003e T addNode(String src, T child, \n-        long childDiskspace, boolean inheritPermission) \n+        long childDiskspace) \n   throws QuotaExceededException, UnresolvedLinkException {\n     byte[][] components \u003d INode.getPathComponents(src);\n     byte[] path \u003d components[components.length-1];\n     child.setLocalName(path);\n     cacheName(child);\n     INode[] inodes \u003d new INode[components.length];\n     writeLock();\n     try {\n       rootDir.getExistingPathINodes(components, inodes, false);\n-      return addChild(inodes, inodes.length-1, child, childDiskspace,\n-                      inheritPermission);\n+      return addChild(inodes, inodes.length-1, child, childDiskspace);\n     } finally {\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private \u003cT extends INode\u003e T addNode(String src, T child, \n        long childDiskspace) \n  throws QuotaExceededException, UnresolvedLinkException {\n    byte[][] components \u003d INode.getPathComponents(src);\n    byte[] path \u003d components[components.length-1];\n    child.setLocalName(path);\n    cacheName(child);\n    INode[] inodes \u003d new INode[components.length];\n    writeLock();\n    try {\n      rootDir.getExistingPathINodes(components, inodes, false);\n      return addChild(inodes, inodes.length-1, child, childDiskspace);\n    } finally {\n      writeUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[src-String, child-T, childDiskspace-long, inheritPermission-boolean]",
            "newValue": "[src-String, child-T, childDiskspace-long]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-1869. mkdirs should use the supplied permission for all of the created directories.  Contributed by Daryn Sharp\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1189546 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "26/10/11 5:02 PM",
          "commitName": "10dc6b09272dbf2022907681e134104e7d418021",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "22/09/11 1:25 AM",
          "commitNameOld": "d773bf0fb57bf6fb77dbdd52e1c186833c17361c",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 34.65,
          "commitsBetweenForRepo": 266,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,16 @@\n   private \u003cT extends INode\u003e T addNode(String src, T child, \n-        long childDiskspace, boolean inheritPermission) \n+        long childDiskspace) \n   throws QuotaExceededException, UnresolvedLinkException {\n     byte[][] components \u003d INode.getPathComponents(src);\n     byte[] path \u003d components[components.length-1];\n     child.setLocalName(path);\n     cacheName(child);\n     INode[] inodes \u003d new INode[components.length];\n     writeLock();\n     try {\n       rootDir.getExistingPathINodes(components, inodes, false);\n-      return addChild(inodes, inodes.length-1, child, childDiskspace,\n-                      inheritPermission);\n+      return addChild(inodes, inodes.length-1, child, childDiskspace);\n     } finally {\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private \u003cT extends INode\u003e T addNode(String src, T child, \n        long childDiskspace) \n  throws QuotaExceededException, UnresolvedLinkException {\n    byte[][] components \u003d INode.getPathComponents(src);\n    byte[] path \u003d components[components.length-1];\n    child.setLocalName(path);\n    cacheName(child);\n    INode[] inodes \u003d new INode[components.length];\n    writeLock();\n    try {\n      rootDir.getExistingPathINodes(components, inodes, false);\n      return addChild(inodes, inodes.length-1, child, childDiskspace);\n    } finally {\n      writeUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private \u003cT extends INode\u003e T addNode(String src, T child, \n        long childDiskspace, boolean inheritPermission) \n  throws QuotaExceededException, UnresolvedLinkException {\n    byte[][] components \u003d INode.getPathComponents(src);\n    byte[] path \u003d components[components.length-1];\n    child.setLocalName(path);\n    cacheName(child);\n    INode[] inodes \u003d new INode[components.length];\n    writeLock();\n    try {\n      rootDir.getExistingPathINodes(components, inodes, false);\n      return addChild(inodes, inodes.length-1, child, childDiskspace,\n                      inheritPermission);\n    } finally {\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private \u003cT extends INode\u003e T addNode(String src, T child, \n        long childDiskspace, boolean inheritPermission) \n  throws QuotaExceededException, UnresolvedLinkException {\n    byte[][] components \u003d INode.getPathComponents(src);\n    byte[] path \u003d components[components.length-1];\n    child.setLocalName(path);\n    cacheName(child);\n    INode[] inodes \u003d new INode[components.length];\n    writeLock();\n    try {\n      rootDir.getExistingPathINodes(components, inodes, false);\n      return addChild(inodes, inodes.length-1, child, childDiskspace,\n                      inheritPermission);\n    } finally {\n      writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,17 @@\n+  private \u003cT extends INode\u003e T addNode(String src, T child, \n+        long childDiskspace, boolean inheritPermission) \n+  throws QuotaExceededException, UnresolvedLinkException {\n+    byte[][] components \u003d INode.getPathComponents(src);\n+    byte[] path \u003d components[components.length-1];\n+    child.setLocalName(path);\n+    cacheName(child);\n+    INode[] inodes \u003d new INode[components.length];\n+    writeLock();\n+    try {\n+      rootDir.getExistingPathINodes(components, inodes, false);\n+      return addChild(inodes, inodes.length-1, child, childDiskspace,\n+                      inheritPermission);\n+    } finally {\n+      writeUnlock();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private \u003cT extends INode\u003e T addNode(String src, T child, \n        long childDiskspace, boolean inheritPermission) \n  throws QuotaExceededException, UnresolvedLinkException {\n    byte[][] components \u003d INode.getPathComponents(src);\n    byte[] path \u003d components[components.length-1];\n    child.setLocalName(path);\n    cacheName(child);\n    INode[] inodes \u003d new INode[components.length];\n    writeLock();\n    try {\n      rootDir.getExistingPathINodes(components, inodes, false);\n      return addChild(inodes, inodes.length-1, child, childDiskspace,\n                      inheritPermission);\n    } finally {\n      writeUnlock();\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java"
    }
  }
}