{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeDescriptor.java",
  "functionName": "updateStorageStats",
  "functionId": "updateStorageStats___reports-StorageReport[]__cacheCapacity-long__cacheUsed-long__xceiverCount-int__volFailures-int__volumeFailureSummary-VolumeFailureSummary",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
  "functionStartLine": 399,
  "functionEndLine": 494,
  "numCommitsSeen": 118,
  "timeTaken": 3528,
  "changeHistory": [
    "d8bac50e12d243ef8fd2c7e0ce5c9997131dee74",
    "3b1d30301bcd35bbe525a7e122d3e5acfab92c88",
    "71d0a825711387fe06396323a9ca6a5af0ade415",
    "d65df0f27395792c6e25f5e03b6ba1765e2ba925",
    "c4a85c694fae3f814ab4e7f3c172da1df0e0e353"
  ],
  "changeHistoryShort": {
    "d8bac50e12d243ef8fd2c7e0ce5c9997131dee74": "Ybodychange",
    "3b1d30301bcd35bbe525a7e122d3e5acfab92c88": "Ybodychange",
    "71d0a825711387fe06396323a9ca6a5af0ade415": "Ybodychange",
    "d65df0f27395792c6e25f5e03b6ba1765e2ba925": "Ybodychange",
    "c4a85c694fae3f814ab4e7f3c172da1df0e0e353": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d8bac50e12d243ef8fd2c7e0ce5c9997131dee74": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14610. HashMap is not thread safe. Field storageMap is typically synchronized by storageMap. However, in one place, field storageMap is not protected with synchronized. (#1015)\n\n",
      "commitDate": "01/07/19 1:54 PM",
      "commitName": "d8bac50e12d243ef8fd2c7e0ce5c9997131dee74",
      "commitAuthor": "paulward24",
      "commitDateOld": "05/11/18 11:02 AM",
      "commitNameOld": "f3f5e7ad005a88afad6fa09602073eaa450e21ed",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 238.08,
      "commitsBetweenForRepo": 1707,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,93 +1,96 @@\n   private void updateStorageStats(StorageReport[] reports, long cacheCapacity,\n       long cacheUsed, int xceiverCount, int volFailures,\n       VolumeFailureSummary volumeFailureSummary) {\n     long totalCapacity \u003d 0;\n     long totalRemaining \u003d 0;\n     long totalBlockPoolUsed \u003d 0;\n     long totalDfsUsed \u003d 0;\n     long totalNonDfsUsed \u003d 0;\n     Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n \n     // Decide if we should check for any missing StorageReport and mark it as\n     // failed. There are different scenarios.\n     // 1. When DN is running, a storage failed. Given the current DN\n     //    implementation doesn\u0027t add recovered storage back to its storage list\n     //    until DN restart, we can assume volFailures won\u0027t decrease\n     //    during the current DN registration session.\n     //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n     //    state change. No need to check for failed storage. This is an\n     //    optimization.  Recent versions of the DataNode report a\n     //    VolumeFailureSummary containing the date/time of the last volume\n     //    failure.  If that\u0027s available, then we check that instead for greater\n     //    accuracy.\n     // 2. After DN restarts, volFailures might not increase and it is possible\n     //    we still have new failed storage. For example, admins reduce\n     //    available storages in configuration. Another corner case\n     //    is the failed volumes might change after restart; a) there\n     //    is one good storage A, one restored good storage B, so there is\n     //    one element in storageReports and that is A. b) A failed. c) Before\n     //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n     //    restarts, storageReports has one element which is B.\n     final boolean checkFailedStorages;\n     if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n       checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n           this.volumeFailureSummary.getLastVolumeFailureDate();\n     } else {\n       checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n           !heartbeatedSinceRegistration;\n     }\n \n     if (checkFailedStorages) {\n       if (this.volumeFailures !\u003d volFailures) {\n         LOG.info(\"Number of failed storages changes from {} to {}\",\n             this.volumeFailures, volFailures);\n       }\n       synchronized (storageMap) {\n         failedStorageInfos \u003d\n             new HashSet\u003c\u003e(storageMap.values());\n       }\n     }\n \n     setCacheCapacity(cacheCapacity);\n     setCacheUsed(cacheUsed);\n     setXceiverCount(xceiverCount);\n     this.volumeFailures \u003d volFailures;\n     this.volumeFailureSummary \u003d volumeFailureSummary;\n     for (StorageReport report : reports) {\n \n-      DatanodeStorageInfo storage \u003d\n-          storageMap.get(report.getStorage().getStorageID());\n+      DatanodeStorageInfo storage \u003d null;\n+      synchronized (storageMap) {\n+        storage \u003d\n+            storageMap.get(report.getStorage().getStorageID());\n+      }\n       if (checkFailedStorages) {\n         failedStorageInfos.remove(storage);\n       }\n \n       storage.receivedHeartbeat(report);\n       // skip accounting for capacity of PROVIDED storages!\n       if (StorageType.PROVIDED.equals(storage.getStorageType())) {\n         continue;\n       }\n \n       totalCapacity +\u003d report.getCapacity();\n       totalRemaining +\u003d report.getRemaining();\n       totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n       totalDfsUsed +\u003d report.getDfsUsed();\n       totalNonDfsUsed +\u003d report.getNonDfsUsed();\n     }\n \n     // Update total metrics for the node.\n     setCapacity(totalCapacity);\n     setRemaining(totalRemaining);\n     setBlockPoolUsed(totalBlockPoolUsed);\n     setDfsUsed(totalDfsUsed);\n     setNonDfsUsed(totalNonDfsUsed);\n     if (checkFailedStorages) {\n       updateFailedStorage(failedStorageInfos);\n     }\n     long storageMapSize;\n     synchronized (storageMap) {\n       storageMapSize \u003d storageMap.size();\n     }\n     if (storageMapSize !\u003d reports.length) {\n       pruneStorageMap(reports);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void updateStorageStats(StorageReport[] reports, long cacheCapacity,\n      long cacheUsed, int xceiverCount, int volFailures,\n      VolumeFailureSummary volumeFailureSummary) {\n    long totalCapacity \u003d 0;\n    long totalRemaining \u003d 0;\n    long totalBlockPoolUsed \u003d 0;\n    long totalDfsUsed \u003d 0;\n    long totalNonDfsUsed \u003d 0;\n    Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n\n    // Decide if we should check for any missing StorageReport and mark it as\n    // failed. There are different scenarios.\n    // 1. When DN is running, a storage failed. Given the current DN\n    //    implementation doesn\u0027t add recovered storage back to its storage list\n    //    until DN restart, we can assume volFailures won\u0027t decrease\n    //    during the current DN registration session.\n    //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n    //    state change. No need to check for failed storage. This is an\n    //    optimization.  Recent versions of the DataNode report a\n    //    VolumeFailureSummary containing the date/time of the last volume\n    //    failure.  If that\u0027s available, then we check that instead for greater\n    //    accuracy.\n    // 2. After DN restarts, volFailures might not increase and it is possible\n    //    we still have new failed storage. For example, admins reduce\n    //    available storages in configuration. Another corner case\n    //    is the failed volumes might change after restart; a) there\n    //    is one good storage A, one restored good storage B, so there is\n    //    one element in storageReports and that is A. b) A failed. c) Before\n    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n    //    restarts, storageReports has one element which is B.\n    final boolean checkFailedStorages;\n    if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n      checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n          this.volumeFailureSummary.getLastVolumeFailureDate();\n    } else {\n      checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n          !heartbeatedSinceRegistration;\n    }\n\n    if (checkFailedStorages) {\n      if (this.volumeFailures !\u003d volFailures) {\n        LOG.info(\"Number of failed storages changes from {} to {}\",\n            this.volumeFailures, volFailures);\n      }\n      synchronized (storageMap) {\n        failedStorageInfos \u003d\n            new HashSet\u003c\u003e(storageMap.values());\n      }\n    }\n\n    setCacheCapacity(cacheCapacity);\n    setCacheUsed(cacheUsed);\n    setXceiverCount(xceiverCount);\n    this.volumeFailures \u003d volFailures;\n    this.volumeFailureSummary \u003d volumeFailureSummary;\n    for (StorageReport report : reports) {\n\n      DatanodeStorageInfo storage \u003d null;\n      synchronized (storageMap) {\n        storage \u003d\n            storageMap.get(report.getStorage().getStorageID());\n      }\n      if (checkFailedStorages) {\n        failedStorageInfos.remove(storage);\n      }\n\n      storage.receivedHeartbeat(report);\n      // skip accounting for capacity of PROVIDED storages!\n      if (StorageType.PROVIDED.equals(storage.getStorageType())) {\n        continue;\n      }\n\n      totalCapacity +\u003d report.getCapacity();\n      totalRemaining +\u003d report.getRemaining();\n      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n      totalDfsUsed +\u003d report.getDfsUsed();\n      totalNonDfsUsed +\u003d report.getNonDfsUsed();\n    }\n\n    // Update total metrics for the node.\n    setCapacity(totalCapacity);\n    setRemaining(totalRemaining);\n    setBlockPoolUsed(totalBlockPoolUsed);\n    setDfsUsed(totalDfsUsed);\n    setNonDfsUsed(totalNonDfsUsed);\n    if (checkFailedStorages) {\n      updateFailedStorage(failedStorageInfos);\n    }\n    long storageMapSize;\n    synchronized (storageMap) {\n      storageMapSize \u003d storageMap.size();\n    }\n    if (storageMapSize !\u003d reports.length) {\n      pruneStorageMap(reports);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "3b1d30301bcd35bbe525a7e122d3e5acfab92c88": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12775. [READ] Fix reporting of Provided volumes\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "3b1d30301bcd35bbe525a7e122d3e5acfab92c88",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "71d0a825711387fe06396323a9ca6a5af0ade415",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,93 +1,93 @@\n   private void updateStorageStats(StorageReport[] reports, long cacheCapacity,\n       long cacheUsed, int xceiverCount, int volFailures,\n       VolumeFailureSummary volumeFailureSummary) {\n     long totalCapacity \u003d 0;\n     long totalRemaining \u003d 0;\n     long totalBlockPoolUsed \u003d 0;\n     long totalDfsUsed \u003d 0;\n     long totalNonDfsUsed \u003d 0;\n     Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n \n     // Decide if we should check for any missing StorageReport and mark it as\n     // failed. There are different scenarios.\n     // 1. When DN is running, a storage failed. Given the current DN\n     //    implementation doesn\u0027t add recovered storage back to its storage list\n     //    until DN restart, we can assume volFailures won\u0027t decrease\n     //    during the current DN registration session.\n     //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n     //    state change. No need to check for failed storage. This is an\n     //    optimization.  Recent versions of the DataNode report a\n     //    VolumeFailureSummary containing the date/time of the last volume\n     //    failure.  If that\u0027s available, then we check that instead for greater\n     //    accuracy.\n     // 2. After DN restarts, volFailures might not increase and it is possible\n     //    we still have new failed storage. For example, admins reduce\n     //    available storages in configuration. Another corner case\n     //    is the failed volumes might change after restart; a) there\n     //    is one good storage A, one restored good storage B, so there is\n     //    one element in storageReports and that is A. b) A failed. c) Before\n     //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n     //    restarts, storageReports has one element which is B.\n     final boolean checkFailedStorages;\n     if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n       checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n           this.volumeFailureSummary.getLastVolumeFailureDate();\n     } else {\n       checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n           !heartbeatedSinceRegistration;\n     }\n \n     if (checkFailedStorages) {\n       if (this.volumeFailures !\u003d volFailures) {\n         LOG.info(\"Number of failed storages changes from {} to {}\",\n             this.volumeFailures, volFailures);\n       }\n       synchronized (storageMap) {\n         failedStorageInfos \u003d\n             new HashSet\u003c\u003e(storageMap.values());\n       }\n     }\n \n     setCacheCapacity(cacheCapacity);\n     setCacheUsed(cacheUsed);\n     setXceiverCount(xceiverCount);\n     this.volumeFailures \u003d volFailures;\n     this.volumeFailureSummary \u003d volumeFailureSummary;\n     for (StorageReport report : reports) {\n-      totalCapacity +\u003d report.getCapacity();\n-      totalRemaining +\u003d report.getRemaining();\n-      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n-      totalDfsUsed +\u003d report.getDfsUsed();\n-      totalNonDfsUsed +\u003d report.getNonDfsUsed();\n \n-      // for PROVIDED storages, do not call updateStorage() unless\n-      // DatanodeStorageInfo already exists!\n-      if (StorageType.PROVIDED.equals(report.getStorage().getStorageType())\n-          \u0026\u0026 storageMap.get(report.getStorage().getStorageID()) \u003d\u003d null) {\n-        continue;\n-      }\n-      DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n+      DatanodeStorageInfo storage \u003d\n+          storageMap.get(report.getStorage().getStorageID());\n       if (checkFailedStorages) {\n         failedStorageInfos.remove(storage);\n       }\n \n       storage.receivedHeartbeat(report);\n+      // skip accounting for capacity of PROVIDED storages!\n+      if (StorageType.PROVIDED.equals(storage.getStorageType())) {\n+        continue;\n+      }\n+\n+      totalCapacity +\u003d report.getCapacity();\n+      totalRemaining +\u003d report.getRemaining();\n+      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n+      totalDfsUsed +\u003d report.getDfsUsed();\n+      totalNonDfsUsed +\u003d report.getNonDfsUsed();\n     }\n \n     // Update total metrics for the node.\n     setCapacity(totalCapacity);\n     setRemaining(totalRemaining);\n     setBlockPoolUsed(totalBlockPoolUsed);\n     setDfsUsed(totalDfsUsed);\n     setNonDfsUsed(totalNonDfsUsed);\n     if (checkFailedStorages) {\n       updateFailedStorage(failedStorageInfos);\n     }\n     long storageMapSize;\n     synchronized (storageMap) {\n       storageMapSize \u003d storageMap.size();\n     }\n     if (storageMapSize !\u003d reports.length) {\n       pruneStorageMap(reports);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void updateStorageStats(StorageReport[] reports, long cacheCapacity,\n      long cacheUsed, int xceiverCount, int volFailures,\n      VolumeFailureSummary volumeFailureSummary) {\n    long totalCapacity \u003d 0;\n    long totalRemaining \u003d 0;\n    long totalBlockPoolUsed \u003d 0;\n    long totalDfsUsed \u003d 0;\n    long totalNonDfsUsed \u003d 0;\n    Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n\n    // Decide if we should check for any missing StorageReport and mark it as\n    // failed. There are different scenarios.\n    // 1. When DN is running, a storage failed. Given the current DN\n    //    implementation doesn\u0027t add recovered storage back to its storage list\n    //    until DN restart, we can assume volFailures won\u0027t decrease\n    //    during the current DN registration session.\n    //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n    //    state change. No need to check for failed storage. This is an\n    //    optimization.  Recent versions of the DataNode report a\n    //    VolumeFailureSummary containing the date/time of the last volume\n    //    failure.  If that\u0027s available, then we check that instead for greater\n    //    accuracy.\n    // 2. After DN restarts, volFailures might not increase and it is possible\n    //    we still have new failed storage. For example, admins reduce\n    //    available storages in configuration. Another corner case\n    //    is the failed volumes might change after restart; a) there\n    //    is one good storage A, one restored good storage B, so there is\n    //    one element in storageReports and that is A. b) A failed. c) Before\n    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n    //    restarts, storageReports has one element which is B.\n    final boolean checkFailedStorages;\n    if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n      checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n          this.volumeFailureSummary.getLastVolumeFailureDate();\n    } else {\n      checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n          !heartbeatedSinceRegistration;\n    }\n\n    if (checkFailedStorages) {\n      if (this.volumeFailures !\u003d volFailures) {\n        LOG.info(\"Number of failed storages changes from {} to {}\",\n            this.volumeFailures, volFailures);\n      }\n      synchronized (storageMap) {\n        failedStorageInfos \u003d\n            new HashSet\u003c\u003e(storageMap.values());\n      }\n    }\n\n    setCacheCapacity(cacheCapacity);\n    setCacheUsed(cacheUsed);\n    setXceiverCount(xceiverCount);\n    this.volumeFailures \u003d volFailures;\n    this.volumeFailureSummary \u003d volumeFailureSummary;\n    for (StorageReport report : reports) {\n\n      DatanodeStorageInfo storage \u003d\n          storageMap.get(report.getStorage().getStorageID());\n      if (checkFailedStorages) {\n        failedStorageInfos.remove(storage);\n      }\n\n      storage.receivedHeartbeat(report);\n      // skip accounting for capacity of PROVIDED storages!\n      if (StorageType.PROVIDED.equals(storage.getStorageType())) {\n        continue;\n      }\n\n      totalCapacity +\u003d report.getCapacity();\n      totalRemaining +\u003d report.getRemaining();\n      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n      totalDfsUsed +\u003d report.getDfsUsed();\n      totalNonDfsUsed +\u003d report.getNonDfsUsed();\n    }\n\n    // Update total metrics for the node.\n    setCapacity(totalCapacity);\n    setRemaining(totalRemaining);\n    setBlockPoolUsed(totalBlockPoolUsed);\n    setDfsUsed(totalDfsUsed);\n    setNonDfsUsed(totalNonDfsUsed);\n    if (checkFailedStorages) {\n      updateFailedStorage(failedStorageInfos);\n    }\n    long storageMapSize;\n    synchronized (storageMap) {\n      storageMapSize \u003d storageMap.size();\n    }\n    if (storageMapSize !\u003d reports.length) {\n      pruneStorageMap(reports);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "71d0a825711387fe06396323a9ca6a5af0ade415": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12607. [READ] Even one dead datanode with PROVIDED storage results in ProvidedStorageInfo being marked as FAILED\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "71d0a825711387fe06396323a9ca6a5af0ade415",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "d6a9a8997339939b59ce36246225f7cc45b21da5",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,91 +1,93 @@\n   private void updateStorageStats(StorageReport[] reports, long cacheCapacity,\n       long cacheUsed, int xceiverCount, int volFailures,\n       VolumeFailureSummary volumeFailureSummary) {\n     long totalCapacity \u003d 0;\n     long totalRemaining \u003d 0;\n     long totalBlockPoolUsed \u003d 0;\n     long totalDfsUsed \u003d 0;\n     long totalNonDfsUsed \u003d 0;\n     Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n \n     // Decide if we should check for any missing StorageReport and mark it as\n     // failed. There are different scenarios.\n     // 1. When DN is running, a storage failed. Given the current DN\n     //    implementation doesn\u0027t add recovered storage back to its storage list\n     //    until DN restart, we can assume volFailures won\u0027t decrease\n     //    during the current DN registration session.\n     //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n     //    state change. No need to check for failed storage. This is an\n     //    optimization.  Recent versions of the DataNode report a\n     //    VolumeFailureSummary containing the date/time of the last volume\n     //    failure.  If that\u0027s available, then we check that instead for greater\n     //    accuracy.\n     // 2. After DN restarts, volFailures might not increase and it is possible\n     //    we still have new failed storage. For example, admins reduce\n     //    available storages in configuration. Another corner case\n     //    is the failed volumes might change after restart; a) there\n     //    is one good storage A, one restored good storage B, so there is\n     //    one element in storageReports and that is A. b) A failed. c) Before\n     //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n     //    restarts, storageReports has one element which is B.\n     final boolean checkFailedStorages;\n     if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n       checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n           this.volumeFailureSummary.getLastVolumeFailureDate();\n     } else {\n       checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n           !heartbeatedSinceRegistration;\n     }\n \n     if (checkFailedStorages) {\n       if (this.volumeFailures !\u003d volFailures) {\n         LOG.info(\"Number of failed storages changes from {} to {}\",\n             this.volumeFailures, volFailures);\n       }\n       synchronized (storageMap) {\n         failedStorageInfos \u003d\n             new HashSet\u003c\u003e(storageMap.values());\n       }\n     }\n \n     setCacheCapacity(cacheCapacity);\n     setCacheUsed(cacheUsed);\n     setXceiverCount(xceiverCount);\n     this.volumeFailures \u003d volFailures;\n     this.volumeFailureSummary \u003d volumeFailureSummary;\n     for (StorageReport report : reports) {\n       totalCapacity +\u003d report.getCapacity();\n       totalRemaining +\u003d report.getRemaining();\n       totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n       totalDfsUsed +\u003d report.getDfsUsed();\n       totalNonDfsUsed +\u003d report.getNonDfsUsed();\n \n-      if (StorageType.PROVIDED.equals(\n-          report.getStorage().getStorageType())) {\n+      // for PROVIDED storages, do not call updateStorage() unless\n+      // DatanodeStorageInfo already exists!\n+      if (StorageType.PROVIDED.equals(report.getStorage().getStorageType())\n+          \u0026\u0026 storageMap.get(report.getStorage().getStorageID()) \u003d\u003d null) {\n         continue;\n       }\n       DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n       if (checkFailedStorages) {\n         failedStorageInfos.remove(storage);\n       }\n \n       storage.receivedHeartbeat(report);\n     }\n \n     // Update total metrics for the node.\n     setCapacity(totalCapacity);\n     setRemaining(totalRemaining);\n     setBlockPoolUsed(totalBlockPoolUsed);\n     setDfsUsed(totalDfsUsed);\n     setNonDfsUsed(totalNonDfsUsed);\n     if (checkFailedStorages) {\n       updateFailedStorage(failedStorageInfos);\n     }\n     long storageMapSize;\n     synchronized (storageMap) {\n       storageMapSize \u003d storageMap.size();\n     }\n     if (storageMapSize !\u003d reports.length) {\n       pruneStorageMap(reports);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void updateStorageStats(StorageReport[] reports, long cacheCapacity,\n      long cacheUsed, int xceiverCount, int volFailures,\n      VolumeFailureSummary volumeFailureSummary) {\n    long totalCapacity \u003d 0;\n    long totalRemaining \u003d 0;\n    long totalBlockPoolUsed \u003d 0;\n    long totalDfsUsed \u003d 0;\n    long totalNonDfsUsed \u003d 0;\n    Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n\n    // Decide if we should check for any missing StorageReport and mark it as\n    // failed. There are different scenarios.\n    // 1. When DN is running, a storage failed. Given the current DN\n    //    implementation doesn\u0027t add recovered storage back to its storage list\n    //    until DN restart, we can assume volFailures won\u0027t decrease\n    //    during the current DN registration session.\n    //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n    //    state change. No need to check for failed storage. This is an\n    //    optimization.  Recent versions of the DataNode report a\n    //    VolumeFailureSummary containing the date/time of the last volume\n    //    failure.  If that\u0027s available, then we check that instead for greater\n    //    accuracy.\n    // 2. After DN restarts, volFailures might not increase and it is possible\n    //    we still have new failed storage. For example, admins reduce\n    //    available storages in configuration. Another corner case\n    //    is the failed volumes might change after restart; a) there\n    //    is one good storage A, one restored good storage B, so there is\n    //    one element in storageReports and that is A. b) A failed. c) Before\n    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n    //    restarts, storageReports has one element which is B.\n    final boolean checkFailedStorages;\n    if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n      checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n          this.volumeFailureSummary.getLastVolumeFailureDate();\n    } else {\n      checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n          !heartbeatedSinceRegistration;\n    }\n\n    if (checkFailedStorages) {\n      if (this.volumeFailures !\u003d volFailures) {\n        LOG.info(\"Number of failed storages changes from {} to {}\",\n            this.volumeFailures, volFailures);\n      }\n      synchronized (storageMap) {\n        failedStorageInfos \u003d\n            new HashSet\u003c\u003e(storageMap.values());\n      }\n    }\n\n    setCacheCapacity(cacheCapacity);\n    setCacheUsed(cacheUsed);\n    setXceiverCount(xceiverCount);\n    this.volumeFailures \u003d volFailures;\n    this.volumeFailureSummary \u003d volumeFailureSummary;\n    for (StorageReport report : reports) {\n      totalCapacity +\u003d report.getCapacity();\n      totalRemaining +\u003d report.getRemaining();\n      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n      totalDfsUsed +\u003d report.getDfsUsed();\n      totalNonDfsUsed +\u003d report.getNonDfsUsed();\n\n      // for PROVIDED storages, do not call updateStorage() unless\n      // DatanodeStorageInfo already exists!\n      if (StorageType.PROVIDED.equals(report.getStorage().getStorageType())\n          \u0026\u0026 storageMap.get(report.getStorage().getStorageID()) \u003d\u003d null) {\n        continue;\n      }\n      DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n      if (checkFailedStorages) {\n        failedStorageInfos.remove(storage);\n      }\n\n      storage.receivedHeartbeat(report);\n    }\n\n    // Update total metrics for the node.\n    setCapacity(totalCapacity);\n    setRemaining(totalRemaining);\n    setBlockPoolUsed(totalBlockPoolUsed);\n    setDfsUsed(totalDfsUsed);\n    setNonDfsUsed(totalNonDfsUsed);\n    if (checkFailedStorages) {\n      updateFailedStorage(failedStorageInfos);\n    }\n    long storageMapSize;\n    synchronized (storageMap) {\n      storageMapSize \u003d storageMap.size();\n    }\n    if (storageMapSize !\u003d reports.length) {\n      pruneStorageMap(reports);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "d65df0f27395792c6e25f5e03b6ba1765e2ba925": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11190. [READ] Namenode support for data stored in external stores.\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "d65df0f27395792c6e25f5e03b6ba1765e2ba925",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "17/08/17 3:26 PM",
      "commitNameOld": "b29894889742dda654cd88a7ce72a4e51fccb328",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 120.14,
      "commitsBetweenForRepo": 995,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,91 @@\n   private void updateStorageStats(StorageReport[] reports, long cacheCapacity,\n       long cacheUsed, int xceiverCount, int volFailures,\n       VolumeFailureSummary volumeFailureSummary) {\n     long totalCapacity \u003d 0;\n     long totalRemaining \u003d 0;\n     long totalBlockPoolUsed \u003d 0;\n     long totalDfsUsed \u003d 0;\n     long totalNonDfsUsed \u003d 0;\n     Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n \n     // Decide if we should check for any missing StorageReport and mark it as\n     // failed. There are different scenarios.\n     // 1. When DN is running, a storage failed. Given the current DN\n     //    implementation doesn\u0027t add recovered storage back to its storage list\n     //    until DN restart, we can assume volFailures won\u0027t decrease\n     //    during the current DN registration session.\n     //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n     //    state change. No need to check for failed storage. This is an\n     //    optimization.  Recent versions of the DataNode report a\n     //    VolumeFailureSummary containing the date/time of the last volume\n     //    failure.  If that\u0027s available, then we check that instead for greater\n     //    accuracy.\n     // 2. After DN restarts, volFailures might not increase and it is possible\n     //    we still have new failed storage. For example, admins reduce\n     //    available storages in configuration. Another corner case\n     //    is the failed volumes might change after restart; a) there\n     //    is one good storage A, one restored good storage B, so there is\n     //    one element in storageReports and that is A. b) A failed. c) Before\n     //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n     //    restarts, storageReports has one element which is B.\n     final boolean checkFailedStorages;\n     if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n       checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n           this.volumeFailureSummary.getLastVolumeFailureDate();\n     } else {\n       checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n           !heartbeatedSinceRegistration;\n     }\n \n     if (checkFailedStorages) {\n       if (this.volumeFailures !\u003d volFailures) {\n         LOG.info(\"Number of failed storages changes from {} to {}\",\n             this.volumeFailures, volFailures);\n       }\n       synchronized (storageMap) {\n         failedStorageInfos \u003d\n             new HashSet\u003c\u003e(storageMap.values());\n       }\n     }\n \n     setCacheCapacity(cacheCapacity);\n     setCacheUsed(cacheUsed);\n     setXceiverCount(xceiverCount);\n     this.volumeFailures \u003d volFailures;\n     this.volumeFailureSummary \u003d volumeFailureSummary;\n     for (StorageReport report : reports) {\n+      totalCapacity +\u003d report.getCapacity();\n+      totalRemaining +\u003d report.getRemaining();\n+      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n+      totalDfsUsed +\u003d report.getDfsUsed();\n+      totalNonDfsUsed +\u003d report.getNonDfsUsed();\n+\n+      if (StorageType.PROVIDED.equals(\n+          report.getStorage().getStorageType())) {\n+        continue;\n+      }\n       DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n       if (checkFailedStorages) {\n         failedStorageInfos.remove(storage);\n       }\n \n       storage.receivedHeartbeat(report);\n-      totalCapacity +\u003d report.getCapacity();\n-      totalRemaining +\u003d report.getRemaining();\n-      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n-      totalDfsUsed +\u003d report.getDfsUsed();\n-      totalNonDfsUsed +\u003d report.getNonDfsUsed();\n     }\n \n     // Update total metrics for the node.\n     setCapacity(totalCapacity);\n     setRemaining(totalRemaining);\n     setBlockPoolUsed(totalBlockPoolUsed);\n     setDfsUsed(totalDfsUsed);\n     setNonDfsUsed(totalNonDfsUsed);\n     if (checkFailedStorages) {\n       updateFailedStorage(failedStorageInfos);\n     }\n     long storageMapSize;\n     synchronized (storageMap) {\n       storageMapSize \u003d storageMap.size();\n     }\n     if (storageMapSize !\u003d reports.length) {\n       pruneStorageMap(reports);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void updateStorageStats(StorageReport[] reports, long cacheCapacity,\n      long cacheUsed, int xceiverCount, int volFailures,\n      VolumeFailureSummary volumeFailureSummary) {\n    long totalCapacity \u003d 0;\n    long totalRemaining \u003d 0;\n    long totalBlockPoolUsed \u003d 0;\n    long totalDfsUsed \u003d 0;\n    long totalNonDfsUsed \u003d 0;\n    Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n\n    // Decide if we should check for any missing StorageReport and mark it as\n    // failed. There are different scenarios.\n    // 1. When DN is running, a storage failed. Given the current DN\n    //    implementation doesn\u0027t add recovered storage back to its storage list\n    //    until DN restart, we can assume volFailures won\u0027t decrease\n    //    during the current DN registration session.\n    //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n    //    state change. No need to check for failed storage. This is an\n    //    optimization.  Recent versions of the DataNode report a\n    //    VolumeFailureSummary containing the date/time of the last volume\n    //    failure.  If that\u0027s available, then we check that instead for greater\n    //    accuracy.\n    // 2. After DN restarts, volFailures might not increase and it is possible\n    //    we still have new failed storage. For example, admins reduce\n    //    available storages in configuration. Another corner case\n    //    is the failed volumes might change after restart; a) there\n    //    is one good storage A, one restored good storage B, so there is\n    //    one element in storageReports and that is A. b) A failed. c) Before\n    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n    //    restarts, storageReports has one element which is B.\n    final boolean checkFailedStorages;\n    if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n      checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n          this.volumeFailureSummary.getLastVolumeFailureDate();\n    } else {\n      checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n          !heartbeatedSinceRegistration;\n    }\n\n    if (checkFailedStorages) {\n      if (this.volumeFailures !\u003d volFailures) {\n        LOG.info(\"Number of failed storages changes from {} to {}\",\n            this.volumeFailures, volFailures);\n      }\n      synchronized (storageMap) {\n        failedStorageInfos \u003d\n            new HashSet\u003c\u003e(storageMap.values());\n      }\n    }\n\n    setCacheCapacity(cacheCapacity);\n    setCacheUsed(cacheUsed);\n    setXceiverCount(xceiverCount);\n    this.volumeFailures \u003d volFailures;\n    this.volumeFailureSummary \u003d volumeFailureSummary;\n    for (StorageReport report : reports) {\n      totalCapacity +\u003d report.getCapacity();\n      totalRemaining +\u003d report.getRemaining();\n      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n      totalDfsUsed +\u003d report.getDfsUsed();\n      totalNonDfsUsed +\u003d report.getNonDfsUsed();\n\n      if (StorageType.PROVIDED.equals(\n          report.getStorage().getStorageType())) {\n        continue;\n      }\n      DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n      if (checkFailedStorages) {\n        failedStorageInfos.remove(storage);\n      }\n\n      storage.receivedHeartbeat(report);\n    }\n\n    // Update total metrics for the node.\n    setCapacity(totalCapacity);\n    setRemaining(totalRemaining);\n    setBlockPoolUsed(totalBlockPoolUsed);\n    setDfsUsed(totalDfsUsed);\n    setNonDfsUsed(totalNonDfsUsed);\n    if (checkFailedStorages) {\n      updateFailedStorage(failedStorageInfos);\n    }\n    long storageMapSize;\n    synchronized (storageMap) {\n      storageMapSize \u003d storageMap.size();\n    }\n    if (storageMapSize !\u003d reports.length) {\n      pruneStorageMap(reports);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "c4a85c694fae3f814ab4e7f3c172da1df0e0e353": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11896. Non-dfsUsed will be doubled on dead node re-registration. Contributed by Brahma Reddy Battula.",
      "commitDate": "27/07/17 12:02 PM",
      "commitName": "c4a85c694fae3f814ab4e7f3c172da1df0e0e353",
      "commitAuthor": "Brahma Reddy Battula",
      "diff": "@@ -0,0 +1,86 @@\n+  private void updateStorageStats(StorageReport[] reports, long cacheCapacity,\n+      long cacheUsed, int xceiverCount, int volFailures,\n+      VolumeFailureSummary volumeFailureSummary) {\n+    long totalCapacity \u003d 0;\n+    long totalRemaining \u003d 0;\n+    long totalBlockPoolUsed \u003d 0;\n+    long totalDfsUsed \u003d 0;\n+    long totalNonDfsUsed \u003d 0;\n+    Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n+\n+    // Decide if we should check for any missing StorageReport and mark it as\n+    // failed. There are different scenarios.\n+    // 1. When DN is running, a storage failed. Given the current DN\n+    //    implementation doesn\u0027t add recovered storage back to its storage list\n+    //    until DN restart, we can assume volFailures won\u0027t decrease\n+    //    during the current DN registration session.\n+    //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n+    //    state change. No need to check for failed storage. This is an\n+    //    optimization.  Recent versions of the DataNode report a\n+    //    VolumeFailureSummary containing the date/time of the last volume\n+    //    failure.  If that\u0027s available, then we check that instead for greater\n+    //    accuracy.\n+    // 2. After DN restarts, volFailures might not increase and it is possible\n+    //    we still have new failed storage. For example, admins reduce\n+    //    available storages in configuration. Another corner case\n+    //    is the failed volumes might change after restart; a) there\n+    //    is one good storage A, one restored good storage B, so there is\n+    //    one element in storageReports and that is A. b) A failed. c) Before\n+    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n+    //    restarts, storageReports has one element which is B.\n+    final boolean checkFailedStorages;\n+    if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n+      checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n+          this.volumeFailureSummary.getLastVolumeFailureDate();\n+    } else {\n+      checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n+          !heartbeatedSinceRegistration;\n+    }\n+\n+    if (checkFailedStorages) {\n+      if (this.volumeFailures !\u003d volFailures) {\n+        LOG.info(\"Number of failed storages changes from {} to {}\",\n+            this.volumeFailures, volFailures);\n+      }\n+      synchronized (storageMap) {\n+        failedStorageInfos \u003d\n+            new HashSet\u003c\u003e(storageMap.values());\n+      }\n+    }\n+\n+    setCacheCapacity(cacheCapacity);\n+    setCacheUsed(cacheUsed);\n+    setXceiverCount(xceiverCount);\n+    this.volumeFailures \u003d volFailures;\n+    this.volumeFailureSummary \u003d volumeFailureSummary;\n+    for (StorageReport report : reports) {\n+      DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n+      if (checkFailedStorages) {\n+        failedStorageInfos.remove(storage);\n+      }\n+\n+      storage.receivedHeartbeat(report);\n+      totalCapacity +\u003d report.getCapacity();\n+      totalRemaining +\u003d report.getRemaining();\n+      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n+      totalDfsUsed +\u003d report.getDfsUsed();\n+      totalNonDfsUsed +\u003d report.getNonDfsUsed();\n+    }\n+\n+    // Update total metrics for the node.\n+    setCapacity(totalCapacity);\n+    setRemaining(totalRemaining);\n+    setBlockPoolUsed(totalBlockPoolUsed);\n+    setDfsUsed(totalDfsUsed);\n+    setNonDfsUsed(totalNonDfsUsed);\n+    if (checkFailedStorages) {\n+      updateFailedStorage(failedStorageInfos);\n+    }\n+    long storageMapSize;\n+    synchronized (storageMap) {\n+      storageMapSize \u003d storageMap.size();\n+    }\n+    if (storageMapSize !\u003d reports.length) {\n+      pruneStorageMap(reports);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void updateStorageStats(StorageReport[] reports, long cacheCapacity,\n      long cacheUsed, int xceiverCount, int volFailures,\n      VolumeFailureSummary volumeFailureSummary) {\n    long totalCapacity \u003d 0;\n    long totalRemaining \u003d 0;\n    long totalBlockPoolUsed \u003d 0;\n    long totalDfsUsed \u003d 0;\n    long totalNonDfsUsed \u003d 0;\n    Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n\n    // Decide if we should check for any missing StorageReport and mark it as\n    // failed. There are different scenarios.\n    // 1. When DN is running, a storage failed. Given the current DN\n    //    implementation doesn\u0027t add recovered storage back to its storage list\n    //    until DN restart, we can assume volFailures won\u0027t decrease\n    //    during the current DN registration session.\n    //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n    //    state change. No need to check for failed storage. This is an\n    //    optimization.  Recent versions of the DataNode report a\n    //    VolumeFailureSummary containing the date/time of the last volume\n    //    failure.  If that\u0027s available, then we check that instead for greater\n    //    accuracy.\n    // 2. After DN restarts, volFailures might not increase and it is possible\n    //    we still have new failed storage. For example, admins reduce\n    //    available storages in configuration. Another corner case\n    //    is the failed volumes might change after restart; a) there\n    //    is one good storage A, one restored good storage B, so there is\n    //    one element in storageReports and that is A. b) A failed. c) Before\n    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n    //    restarts, storageReports has one element which is B.\n    final boolean checkFailedStorages;\n    if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n      checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n          this.volumeFailureSummary.getLastVolumeFailureDate();\n    } else {\n      checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n          !heartbeatedSinceRegistration;\n    }\n\n    if (checkFailedStorages) {\n      if (this.volumeFailures !\u003d volFailures) {\n        LOG.info(\"Number of failed storages changes from {} to {}\",\n            this.volumeFailures, volFailures);\n      }\n      synchronized (storageMap) {\n        failedStorageInfos \u003d\n            new HashSet\u003c\u003e(storageMap.values());\n      }\n    }\n\n    setCacheCapacity(cacheCapacity);\n    setCacheUsed(cacheUsed);\n    setXceiverCount(xceiverCount);\n    this.volumeFailures \u003d volFailures;\n    this.volumeFailureSummary \u003d volumeFailureSummary;\n    for (StorageReport report : reports) {\n      DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n      if (checkFailedStorages) {\n        failedStorageInfos.remove(storage);\n      }\n\n      storage.receivedHeartbeat(report);\n      totalCapacity +\u003d report.getCapacity();\n      totalRemaining +\u003d report.getRemaining();\n      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n      totalDfsUsed +\u003d report.getDfsUsed();\n      totalNonDfsUsed +\u003d report.getNonDfsUsed();\n    }\n\n    // Update total metrics for the node.\n    setCapacity(totalCapacity);\n    setRemaining(totalRemaining);\n    setBlockPoolUsed(totalBlockPoolUsed);\n    setDfsUsed(totalDfsUsed);\n    setNonDfsUsed(totalNonDfsUsed);\n    if (checkFailedStorages) {\n      updateFailedStorage(failedStorageInfos);\n    }\n    long storageMapSize;\n    synchronized (storageMap) {\n      storageMapSize \u003d storageMap.size();\n    }\n    if (storageMapSize !\u003d reports.length) {\n      pruneStorageMap(reports);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java"
    }
  }
}