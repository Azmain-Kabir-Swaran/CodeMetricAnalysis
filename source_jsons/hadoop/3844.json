{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DistributedFileSystem.java",
  "functionName": "primitiveCreate",
  "functionId": "primitiveCreate___f-Path__absolutePermission-FsPermission__flag-EnumSet__CreateFlag____bufferSize-int__replication-short__blockSize-long__progress-Progressable__checksumOpt-ChecksumOpt",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
  "functionStartLine": 619,
  "functionEndLine": 630,
  "numCommitsSeen": 242,
  "timeTaken": 9306,
  "changeHistory": [
    "0dd8956f2e4bd7cd2315ef23703e4b2da1a0d073",
    "687233f20d24c29041929dd0a99d963cec54b6df",
    "1c030c6e58dc83152f933323bb7743ad47f5af27",
    "2efea952139b30dd1c881eed0b443ffa72be6dce",
    "8767e4cde172b6e6070e3fd45325ede617b99343",
    "b0ea77303ba62a400376ca32c63c5b138f32cbe7",
    "34554d1e11ee1d5b564d7d9ed3e6d55931d72749",
    "ea32198db4e783f0c0b93a3f74120fe41ded98e8",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "0dd8956f2e4bd7cd2315ef23703e4b2da1a0d073": "Ybodychange",
    "687233f20d24c29041929dd0a99d963cec54b6df": "Ybodychange",
    "1c030c6e58dc83152f933323bb7743ad47f5af27": "Yfilerename",
    "2efea952139b30dd1c881eed0b443ffa72be6dce": "Ybodychange",
    "8767e4cde172b6e6070e3fd45325ede617b99343": "Ybodychange",
    "b0ea77303ba62a400376ca32c63c5b138f32cbe7": "Ymultichange(Yparameterchange,Ybodychange)",
    "34554d1e11ee1d5b564d7d9ed3e6d55931d72749": "Ybodychange",
    "ea32198db4e783f0c0b93a3f74120fe41ded98e8": "Ymultichange(Yreturntypechange,Ybodychange)",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "0dd8956f2e4bd7cd2315ef23703e4b2da1a0d073": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16885. Encryption zone file copy failure leaks a temp file\n\n\r\nContributed by Xiaoyu Yao.\r\n\r\nContains HDFS-14892. Close the output stream if createWrappedOutputStream() fails\r\n\r\nCopying file through the FsShell command into an HDFS encryption zone where\r\nthe caller lacks permissions is leaks a temp ._COPYING file\r\nand potentially a wrapped stream unclosed.\r\n\r\nThis is a convergence of a fix for S3 meeting an issue in HDFS.\r\n\r\nS3: a HEAD against a file can cache a 404, \r\n -you must not do any existence checks, including deleteOnExit(),\r\n  until the file is written. \r\n\r\nHence: HADOOP-16490, only register files for deletion the create worked\r\nand the upload is not direct. \r\n\r\nHDFS-14892. HDFS doesn\u0027t close wrapped streams when IOEs are raised on\r\ncreate() failures. Which means that an entry is retained on the NN.\r\n-you need to register a file with deleteOnExit() even if the file wasn\u0027t\r\ncreated.\r\n\r\nThis patch:\r\n\r\n* Moves the deleteOnExit to ensure the created file get deleted cleanly.\r\n* Fixes HDFS to close the wrapped stream on failures.\r\n\r\n\r\n",
      "commitDate": "02/03/20 5:22 AM",
      "commitName": "0dd8956f2e4bd7cd2315ef23703e4b2da1a0d073",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "20/02/20 6:56 PM",
      "commitNameOld": "2338d25dc7150d75fbda84cc95422380b5622224",
      "commitAuthorOld": "Masatake Iwasaki",
      "daysBetweenCommits": 10.43,
      "commitsBetweenForRepo": 42,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   protected HdfsDataOutputStream primitiveCreate(Path f,\n       FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n       short replication, long blockSize, Progressable progress,\n       ChecksumOpt checksumOpt) throws IOException {\n     statistics.incrementWriteOps(1);\n     storageStatistics.incrementOpCounter(OpType.PRIMITIVE_CREATE);\n     final DFSOutputStream dfsos \u003d dfs.primitiveCreate(\n         getPathName(fixRelativePart(f)),\n         absolutePermission, flag, true, replication, blockSize,\n         progress, bufferSize, checksumOpt);\n-    return dfs.createWrappedOutputStream(dfsos, statistics);\n+    return safelyCreateWrappedOutputStream(dfsos);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected HdfsDataOutputStream primitiveCreate(Path f,\n      FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n      short replication, long blockSize, Progressable progress,\n      ChecksumOpt checksumOpt) throws IOException {\n    statistics.incrementWriteOps(1);\n    storageStatistics.incrementOpCounter(OpType.PRIMITIVE_CREATE);\n    final DFSOutputStream dfsos \u003d dfs.primitiveCreate(\n        getPathName(fixRelativePart(f)),\n        absolutePermission, flag, true, replication, blockSize,\n        progress, bufferSize, checksumOpt);\n    return safelyCreateWrappedOutputStream(dfsos);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {}
    },
    "687233f20d24c29041929dd0a99d963cec54b6df": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13065. Add a new interface for retrieving FS and FC Statistics (Mingliang Liu via cmccabe)\n",
      "commitDate": "11/05/16 1:45 PM",
      "commitName": "687233f20d24c29041929dd0a99d963cec54b6df",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "02/05/16 7:30 PM",
      "commitNameOld": "45a753ccf79d334513c7bc8f2b81c89a4697075d",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 8.76,
      "commitsBetweenForRepo": 55,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,12 @@\n   protected HdfsDataOutputStream primitiveCreate(Path f,\n       FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n       short replication, long blockSize, Progressable progress,\n       ChecksumOpt checksumOpt) throws IOException {\n     statistics.incrementWriteOps(1);\n+    storageStatistics.incrementOpCounter(OpType.PRIMITIVE_CREATE);\n     final DFSOutputStream dfsos \u003d dfs.primitiveCreate(\n         getPathName(fixRelativePart(f)),\n         absolutePermission, flag, true, replication, blockSize,\n         progress, bufferSize, checksumOpt);\n     return dfs.createWrappedOutputStream(dfsos, statistics);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected HdfsDataOutputStream primitiveCreate(Path f,\n      FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n      short replication, long blockSize, Progressable progress,\n      ChecksumOpt checksumOpt) throws IOException {\n    statistics.incrementWriteOps(1);\n    storageStatistics.incrementOpCounter(OpType.PRIMITIVE_CREATE);\n    final DFSOutputStream dfsos \u003d dfs.primitiveCreate(\n        getPathName(fixRelativePart(f)),\n        absolutePermission, flag, true, replication, blockSize,\n        progress, bufferSize, checksumOpt);\n    return dfs.createWrappedOutputStream(dfsos, statistics);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {}
    },
    "1c030c6e58dc83152f933323bb7743ad47f5af27": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8740. Move DistributedFileSystem to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "27/09/15 10:54 AM",
      "commitName": "1c030c6e58dc83152f933323bb7743ad47f5af27",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "27/09/15 1:42 AM",
      "commitNameOld": "f0f984e4e63d0dbafe93062a122ee051330db301",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.38,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected HdfsDataOutputStream primitiveCreate(Path f,\n    FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n    short replication, long blockSize, Progressable progress,\n    ChecksumOpt checksumOpt) throws IOException {\n    statistics.incrementWriteOps(1);\n    final DFSOutputStream dfsos \u003d dfs.primitiveCreate(\n      getPathName(fixRelativePart(f)),\n      absolutePermission, flag, true, replication, blockSize,\n      progress, bufferSize, checksumOpt);\n    return dfs.createWrappedOutputStream(dfsos, statistics);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java"
      }
    },
    "2efea952139b30dd1c881eed0b443ffa72be6dce": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6391. Get the Key/IV from the NameNode for encrypted files in DFSClient. Contributed by Charles Lamb and Andrew Wang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/fs-encryption@1606220 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/06/14 1:43 PM",
      "commitName": "2efea952139b30dd1c881eed0b443ffa72be6dce",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "16/06/14 11:13 AM",
      "commitNameOld": "c5b7236d9c3240f6cefc1782bc7926a678d104f4",
      "commitAuthorOld": "",
      "daysBetweenCommits": 11.1,
      "commitsBetweenForRepo": 39,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,11 @@\n   protected HdfsDataOutputStream primitiveCreate(Path f,\n     FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n     short replication, long blockSize, Progressable progress,\n     ChecksumOpt checksumOpt) throws IOException {\n     statistics.incrementWriteOps(1);\n-    return new HdfsDataOutputStream(dfs.primitiveCreate(\n-        getPathName(fixRelativePart(f)),\n-        absolutePermission, flag, true, replication, blockSize,\n-        progress, bufferSize, checksumOpt),statistics);\n-   }\n\\ No newline at end of file\n+    final DFSOutputStream dfsos \u003d dfs.primitiveCreate(\n+      getPathName(fixRelativePart(f)),\n+      absolutePermission, flag, true, replication, blockSize,\n+      progress, bufferSize, checksumOpt);\n+    return dfs.createWrappedOutputStream(dfsos, statistics);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected HdfsDataOutputStream primitiveCreate(Path f,\n    FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n    short replication, long blockSize, Progressable progress,\n    ChecksumOpt checksumOpt) throws IOException {\n    statistics.incrementWriteOps(1);\n    final DFSOutputStream dfsos \u003d dfs.primitiveCreate(\n      getPathName(fixRelativePart(f)),\n      absolutePermission, flag, true, replication, blockSize,\n      progress, bufferSize, checksumOpt);\n    return dfs.createWrappedOutputStream(dfsos, statistics);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {}
    },
    "8767e4cde172b6e6070e3fd45325ede617b99343": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9418.  Add symlink support to DistributedFileSystem (Andrew Wang via Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1502373 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/07/13 2:31 PM",
      "commitName": "8767e4cde172b6e6070e3fd45325ede617b99343",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "13/06/13 11:11 AM",
      "commitNameOld": "7e1744ccf9a9b5b035afbb182aad123a1d1d357f",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 28.14,
      "commitsBetweenForRepo": 172,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,10 @@\n   protected HdfsDataOutputStream primitiveCreate(Path f,\n     FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n     short replication, long blockSize, Progressable progress,\n     ChecksumOpt checksumOpt) throws IOException {\n     statistics.incrementWriteOps(1);\n-    return new HdfsDataOutputStream(dfs.primitiveCreate(getPathName(f),\n+    return new HdfsDataOutputStream(dfs.primitiveCreate(\n+        getPathName(fixRelativePart(f)),\n         absolutePermission, flag, true, replication, blockSize,\n         progress, bufferSize, checksumOpt),statistics);\n-   } \n\\ No newline at end of file\n+   }\n\\ No newline at end of file\n",
      "actualSource": "  protected HdfsDataOutputStream primitiveCreate(Path f,\n    FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n    short replication, long blockSize, Progressable progress,\n    ChecksumOpt checksumOpt) throws IOException {\n    statistics.incrementWriteOps(1);\n    return new HdfsDataOutputStream(dfs.primitiveCreate(\n        getPathName(fixRelativePart(f)),\n        absolutePermission, flag, true, replication, blockSize,\n        progress, bufferSize, checksumOpt),statistics);\n   }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {}
    },
    "b0ea77303ba62a400376ca32c63c5b138f32cbe7": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HADOOP-8240. Add a new API to allow users to specify a checksum type on FileSystem.create(..).  Contributed by Kihwal Lee\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1374696 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/12 10:46 PM",
      "commitName": "b0ea77303ba62a400376ca32c63c5b138f32cbe7",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-8240. Add a new API to allow users to specify a checksum type on FileSystem.create(..).  Contributed by Kihwal Lee\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1374696 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/12 10:46 PM",
          "commitName": "b0ea77303ba62a400376ca32c63c5b138f32cbe7",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "17/08/12 9:52 AM",
          "commitNameOld": "fccace6116713c85cd59a808c565ea39fb5d6944",
          "commitAuthorOld": "Aaron Myers",
          "daysBetweenCommits": 1.54,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,9 @@\n   protected HdfsDataOutputStream primitiveCreate(Path f,\n     FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n     short replication, long blockSize, Progressable progress,\n-    int bytesPerChecksum) throws IOException {\n+    ChecksumOpt checksumOpt) throws IOException {\n     statistics.incrementWriteOps(1);\n     return new HdfsDataOutputStream(dfs.primitiveCreate(getPathName(f),\n         absolutePermission, flag, true, replication, blockSize,\n-        progress, bufferSize, bytesPerChecksum),statistics);\n+        progress, bufferSize, checksumOpt),statistics);\n    } \n\\ No newline at end of file\n",
          "actualSource": "  protected HdfsDataOutputStream primitiveCreate(Path f,\n    FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n    short replication, long blockSize, Progressable progress,\n    ChecksumOpt checksumOpt) throws IOException {\n    statistics.incrementWriteOps(1);\n    return new HdfsDataOutputStream(dfs.primitiveCreate(getPathName(f),\n        absolutePermission, flag, true, replication, blockSize,\n        progress, bufferSize, checksumOpt),statistics);\n   } ",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
          "extendedDetails": {
            "oldValue": "[f-Path, absolutePermission-FsPermission, flag-EnumSet\u003cCreateFlag\u003e, bufferSize-int, replication-short, blockSize-long, progress-Progressable, bytesPerChecksum-int]",
            "newValue": "[f-Path, absolutePermission-FsPermission, flag-EnumSet\u003cCreateFlag\u003e, bufferSize-int, replication-short, blockSize-long, progress-Progressable, checksumOpt-ChecksumOpt]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-8240. Add a new API to allow users to specify a checksum type on FileSystem.create(..).  Contributed by Kihwal Lee\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1374696 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/12 10:46 PM",
          "commitName": "b0ea77303ba62a400376ca32c63c5b138f32cbe7",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "17/08/12 9:52 AM",
          "commitNameOld": "fccace6116713c85cd59a808c565ea39fb5d6944",
          "commitAuthorOld": "Aaron Myers",
          "daysBetweenCommits": 1.54,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,9 @@\n   protected HdfsDataOutputStream primitiveCreate(Path f,\n     FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n     short replication, long blockSize, Progressable progress,\n-    int bytesPerChecksum) throws IOException {\n+    ChecksumOpt checksumOpt) throws IOException {\n     statistics.incrementWriteOps(1);\n     return new HdfsDataOutputStream(dfs.primitiveCreate(getPathName(f),\n         absolutePermission, flag, true, replication, blockSize,\n-        progress, bufferSize, bytesPerChecksum),statistics);\n+        progress, bufferSize, checksumOpt),statistics);\n    } \n\\ No newline at end of file\n",
          "actualSource": "  protected HdfsDataOutputStream primitiveCreate(Path f,\n    FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n    short replication, long blockSize, Progressable progress,\n    ChecksumOpt checksumOpt) throws IOException {\n    statistics.incrementWriteOps(1);\n    return new HdfsDataOutputStream(dfs.primitiveCreate(getPathName(f),\n        absolutePermission, flag, true, replication, blockSize,\n        progress, bufferSize, checksumOpt),statistics);\n   } ",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "34554d1e11ee1d5b564d7d9ed3e6d55931d72749": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3760. primitiveCreate is a write, not a read. Contributed by Andy Isaacson.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370649 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/12 7:53 PM",
      "commitName": "34554d1e11ee1d5b564d7d9ed3e6d55931d72749",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "27/06/12 6:25 PM",
      "commitNameOld": "f105784d6a28d2a0cedb619f0951de93d995e9da",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 41.06,
      "commitsBetweenForRepo": 226,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,9 @@\n   protected HdfsDataOutputStream primitiveCreate(Path f,\n     FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n     short replication, long blockSize, Progressable progress,\n     int bytesPerChecksum) throws IOException {\n-    statistics.incrementReadOps(1);\n+    statistics.incrementWriteOps(1);\n     return new HdfsDataOutputStream(dfs.primitiveCreate(getPathName(f),\n         absolutePermission, flag, true, replication, blockSize,\n         progress, bufferSize, bytesPerChecksum),statistics);\n    } \n\\ No newline at end of file\n",
      "actualSource": "  protected HdfsDataOutputStream primitiveCreate(Path f,\n    FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n    short replication, long blockSize, Progressable progress,\n    int bytesPerChecksum) throws IOException {\n    statistics.incrementWriteOps(1);\n    return new HdfsDataOutputStream(dfs.primitiveCreate(getPathName(f),\n        absolutePermission, flag, true, replication, blockSize,\n        progress, bufferSize, bytesPerChecksum),statistics);\n   } ",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {}
    },
    "ea32198db4e783f0c0b93a3f74120fe41ded98e8": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-3298. Add HdfsDataOutputStream as a public API.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1330064 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/04/12 4:39 PM",
      "commitName": "ea32198db4e783f0c0b93a3f74120fe41ded98e8",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-3298. Add HdfsDataOutputStream as a public API.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1330064 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/04/12 4:39 PM",
          "commitName": "ea32198db4e783f0c0b93a3f74120fe41ded98e8",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "24/04/12 1:33 PM",
          "commitNameOld": "706e861a859a247661b027f4e473814995556c2e",
          "commitAuthorOld": "Alejandro Abdelnur",
          "daysBetweenCommits": 0.13,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,9 @@\n-  protected FSDataOutputStream primitiveCreate(Path f,\n+  protected HdfsDataOutputStream primitiveCreate(Path f,\n     FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n     short replication, long blockSize, Progressable progress,\n     int bytesPerChecksum) throws IOException {\n     statistics.incrementReadOps(1);\n-    return new FSDataOutputStream(dfs.primitiveCreate(getPathName(f),\n+    return new HdfsDataOutputStream(dfs.primitiveCreate(getPathName(f),\n         absolutePermission, flag, true, replication, blockSize,\n         progress, bufferSize, bytesPerChecksum),statistics);\n    } \n\\ No newline at end of file\n",
          "actualSource": "  protected HdfsDataOutputStream primitiveCreate(Path f,\n    FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n    short replication, long blockSize, Progressable progress,\n    int bytesPerChecksum) throws IOException {\n    statistics.incrementReadOps(1);\n    return new HdfsDataOutputStream(dfs.primitiveCreate(getPathName(f),\n        absolutePermission, flag, true, replication, blockSize,\n        progress, bufferSize, bytesPerChecksum),statistics);\n   } ",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
          "extendedDetails": {
            "oldValue": "FSDataOutputStream",
            "newValue": "HdfsDataOutputStream"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3298. Add HdfsDataOutputStream as a public API.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1330064 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/04/12 4:39 PM",
          "commitName": "ea32198db4e783f0c0b93a3f74120fe41ded98e8",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "24/04/12 1:33 PM",
          "commitNameOld": "706e861a859a247661b027f4e473814995556c2e",
          "commitAuthorOld": "Alejandro Abdelnur",
          "daysBetweenCommits": 0.13,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,9 @@\n-  protected FSDataOutputStream primitiveCreate(Path f,\n+  protected HdfsDataOutputStream primitiveCreate(Path f,\n     FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n     short replication, long blockSize, Progressable progress,\n     int bytesPerChecksum) throws IOException {\n     statistics.incrementReadOps(1);\n-    return new FSDataOutputStream(dfs.primitiveCreate(getPathName(f),\n+    return new HdfsDataOutputStream(dfs.primitiveCreate(getPathName(f),\n         absolutePermission, flag, true, replication, blockSize,\n         progress, bufferSize, bytesPerChecksum),statistics);\n    } \n\\ No newline at end of file\n",
          "actualSource": "  protected HdfsDataOutputStream primitiveCreate(Path f,\n    FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n    short replication, long blockSize, Progressable progress,\n    int bytesPerChecksum) throws IOException {\n    statistics.incrementReadOps(1);\n    return new HdfsDataOutputStream(dfs.primitiveCreate(getPathName(f),\n        absolutePermission, flag, true, replication, blockSize,\n        progress, bufferSize, bytesPerChecksum),statistics);\n   } ",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected FSDataOutputStream primitiveCreate(Path f,\n    FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n    short replication, long blockSize, Progressable progress,\n    int bytesPerChecksum) throws IOException {\n    statistics.incrementReadOps(1);\n    return new FSDataOutputStream(dfs.primitiveCreate(getPathName(f),\n        absolutePermission, flag, true, replication, blockSize,\n        progress, bufferSize, bytesPerChecksum),statistics);\n   } ",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected FSDataOutputStream primitiveCreate(Path f,\n    FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n    short replication, long blockSize, Progressable progress,\n    int bytesPerChecksum) throws IOException {\n    statistics.incrementReadOps(1);\n    return new FSDataOutputStream(dfs.primitiveCreate(getPathName(f),\n        absolutePermission, flag, true, replication, blockSize,\n        progress, bufferSize, bytesPerChecksum),statistics);\n   } ",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,9 @@\n+  protected FSDataOutputStream primitiveCreate(Path f,\n+    FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n+    short replication, long blockSize, Progressable progress,\n+    int bytesPerChecksum) throws IOException {\n+    statistics.incrementReadOps(1);\n+    return new FSDataOutputStream(dfs.primitiveCreate(getPathName(f),\n+        absolutePermission, flag, true, replication, blockSize,\n+        progress, bufferSize, bytesPerChecksum),statistics);\n+   } \n\\ No newline at end of file\n",
      "actualSource": "  protected FSDataOutputStream primitiveCreate(Path f,\n    FsPermission absolutePermission, EnumSet\u003cCreateFlag\u003e flag, int bufferSize,\n    short replication, long blockSize, Progressable progress,\n    int bytesPerChecksum) throws IOException {\n    statistics.incrementReadOps(1);\n    return new FSDataOutputStream(dfs.primitiveCreate(getPathName(f),\n        absolutePermission, flag, true, replication, blockSize,\n        progress, bufferSize, bytesPerChecksum),statistics);\n   } ",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/DistributedFileSystem.java"
    }
  }
}