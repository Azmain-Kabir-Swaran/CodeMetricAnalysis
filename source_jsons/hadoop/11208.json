{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "URLDispatcher.java",
  "functionName": "channelRead0",
  "functionId": "channelRead0___ctx-ChannelHandlerContext__req-HttpRequest",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/URLDispatcher.java",
  "functionStartLine": 44,
  "functionEndLine": 57,
  "numCommitsSeen": 3,
  "timeTaken": 1744,
  "changeHistory": [
    "88da9f6b6782423acd8ab7eb7d938720de7f3c0f",
    "ada233b7cd7db39e609bb57e487fee8cec59cd48",
    "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4"
  ],
  "changeHistoryShort": {
    "88da9f6b6782423acd8ab7eb7d938720de7f3c0f": "Ybodychange",
    "ada233b7cd7db39e609bb57e487fee8cec59cd48": "Ybodychange",
    "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4": "Yintroduced"
  },
  "changeHistoryDetails": {
    "88da9f6b6782423acd8ab7eb7d938720de7f3c0f": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-8377. Support HTTP/2 in datanode. Contributed by Duo Zhang.\"\n\nThis reverts commit ada233b7cd7db39e609bb57e487fee8cec59cd48.\n",
      "commitDate": "26/01/17 1:42 PM",
      "commitName": "88da9f6b6782423acd8ab7eb7d938720de7f3c0f",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "24/05/15 10:30 PM",
      "commitNameOld": "ada233b7cd7db39e609bb57e487fee8cec59cd48",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 612.68,
      "commitsBetweenForRepo": 4350,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   protected void channelRead0(ChannelHandlerContext ctx, HttpRequest req)\n-    throws Exception {\n-    String uri \u003d req.uri();\n+      throws Exception {\n+    String uri \u003d req.getUri();\n     ChannelPipeline p \u003d ctx.pipeline();\n     if (uri.startsWith(WEBHDFS_PREFIX)) {\n       WebHdfsHandler h \u003d new WebHdfsHandler(conf, confForCreate);\n       p.replace(this, WebHdfsHandler.class.getSimpleName(), h);\n       h.channelRead0(ctx, req);\n     } else {\n       SimpleHttpProxyHandler h \u003d new SimpleHttpProxyHandler(proxyHost);\n       p.replace(this, SimpleHttpProxyHandler.class.getSimpleName(), h);\n       h.channelRead0(ctx, req);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void channelRead0(ChannelHandlerContext ctx, HttpRequest req)\n      throws Exception {\n    String uri \u003d req.getUri();\n    ChannelPipeline p \u003d ctx.pipeline();\n    if (uri.startsWith(WEBHDFS_PREFIX)) {\n      WebHdfsHandler h \u003d new WebHdfsHandler(conf, confForCreate);\n      p.replace(this, WebHdfsHandler.class.getSimpleName(), h);\n      h.channelRead0(ctx, req);\n    } else {\n      SimpleHttpProxyHandler h \u003d new SimpleHttpProxyHandler(proxyHost);\n      p.replace(this, SimpleHttpProxyHandler.class.getSimpleName(), h);\n      h.channelRead0(ctx, req);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/URLDispatcher.java",
      "extendedDetails": {}
    },
    "ada233b7cd7db39e609bb57e487fee8cec59cd48": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8377. Support HTTP/2 in datanode. Contributed by Duo Zhang.\n",
      "commitDate": "24/05/15 10:30 PM",
      "commitName": "ada233b7cd7db39e609bb57e487fee8cec59cd48",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "17/11/14 11:42 AM",
      "commitNameOld": "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 188.41,
      "commitsBetweenForRepo": 1569,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   protected void channelRead0(ChannelHandlerContext ctx, HttpRequest req)\n     throws Exception {\n-    String uri \u003d req.getUri();\n+    String uri \u003d req.uri();\n     ChannelPipeline p \u003d ctx.pipeline();\n     if (uri.startsWith(WEBHDFS_PREFIX)) {\n       WebHdfsHandler h \u003d new WebHdfsHandler(conf, confForCreate);\n       p.replace(this, WebHdfsHandler.class.getSimpleName(), h);\n       h.channelRead0(ctx, req);\n     } else {\n       SimpleHttpProxyHandler h \u003d new SimpleHttpProxyHandler(proxyHost);\n       p.replace(this, SimpleHttpProxyHandler.class.getSimpleName(), h);\n       h.channelRead0(ctx, req);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void channelRead0(ChannelHandlerContext ctx, HttpRequest req)\n    throws Exception {\n    String uri \u003d req.uri();\n    ChannelPipeline p \u003d ctx.pipeline();\n    if (uri.startsWith(WEBHDFS_PREFIX)) {\n      WebHdfsHandler h \u003d new WebHdfsHandler(conf, confForCreate);\n      p.replace(this, WebHdfsHandler.class.getSimpleName(), h);\n      h.channelRead0(ctx, req);\n    } else {\n      SimpleHttpProxyHandler h \u003d new SimpleHttpProxyHandler(proxyHost);\n      p.replace(this, SimpleHttpProxyHandler.class.getSimpleName(), h);\n      h.channelRead0(ctx, req);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/URLDispatcher.java",
      "extendedDetails": {}
    },
    "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7279. Use netty to implement DatanodeWebHdfsMethods. Contributed by Haohui Mai.\n",
      "commitDate": "17/11/14 11:42 AM",
      "commitName": "bf8e4332cb4c33d0287ae6ecca61b335402ac1c4",
      "commitAuthor": "Haohui Mai",
      "diff": "@@ -0,0 +1,14 @@\n+  protected void channelRead0(ChannelHandlerContext ctx, HttpRequest req)\n+    throws Exception {\n+    String uri \u003d req.getUri();\n+    ChannelPipeline p \u003d ctx.pipeline();\n+    if (uri.startsWith(WEBHDFS_PREFIX)) {\n+      WebHdfsHandler h \u003d new WebHdfsHandler(conf, confForCreate);\n+      p.replace(this, WebHdfsHandler.class.getSimpleName(), h);\n+      h.channelRead0(ctx, req);\n+    } else {\n+      SimpleHttpProxyHandler h \u003d new SimpleHttpProxyHandler(proxyHost);\n+      p.replace(this, SimpleHttpProxyHandler.class.getSimpleName(), h);\n+      h.channelRead0(ctx, req);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected void channelRead0(ChannelHandlerContext ctx, HttpRequest req)\n    throws Exception {\n    String uri \u003d req.getUri();\n    ChannelPipeline p \u003d ctx.pipeline();\n    if (uri.startsWith(WEBHDFS_PREFIX)) {\n      WebHdfsHandler h \u003d new WebHdfsHandler(conf, confForCreate);\n      p.replace(this, WebHdfsHandler.class.getSimpleName(), h);\n      h.channelRead0(ctx, req);\n    } else {\n      SimpleHttpProxyHandler h \u003d new SimpleHttpProxyHandler(proxyHost);\n      p.replace(this, SimpleHttpProxyHandler.class.getSimpleName(), h);\n      h.channelRead0(ctx, req);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/URLDispatcher.java"
    }
  }
}