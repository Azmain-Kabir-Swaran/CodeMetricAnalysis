{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Server.java",
  "functionName": "setupResponseForProtobuf",
  "functionId": "setupResponseForProtobuf___header-RpcResponseHeaderProto__rv-Writable",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
  "functionStartLine": 3285,
  "functionEndLine": 3307,
  "numCommitsSeen": 162,
  "timeTaken": 3095,
  "changeHistory": [
    "1654497f98fb7f2de8214d2fbad305b7a2854816",
    "39d1b1d747b1e325792b897b3264272f32b756a9"
  ],
  "changeHistoryShort": {
    "1654497f98fb7f2de8214d2fbad305b7a2854816": "Ybodychange",
    "39d1b1d747b1e325792b897b3264272f32b756a9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1654497f98fb7f2de8214d2fbad305b7a2854816": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16557. [pb-upgrade] Upgrade protobuf.version to 3.7.1 (#1432)\n\nHADOOP-16557. [pb-upgrade] Upgrade protobuf.version to 3.7.1. Contributed by Vinayakumar B.",
      "commitDate": "20/09/19 3:38 AM",
      "commitName": "1654497f98fb7f2de8214d2fbad305b7a2854816",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "06/09/19 10:28 AM",
      "commitNameOld": "a23417533e1ee052893baf207ec636c4993c5994",
      "commitAuthorOld": "Erik Krogen",
      "daysBetweenCommits": 13.72,
      "commitsBetweenForRepo": 114,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,23 @@\n   private byte[] setupResponseForProtobuf(\n       RpcResponseHeaderProto header, Writable rv) throws IOException {\n     Message payload \u003d (rv !\u003d null)\n         ? ((RpcWritable.ProtobufWrapper)rv).getMessage() : null;\n     int length \u003d getDelimitedLength(header);\n     if (payload !\u003d null) {\n       length +\u003d getDelimitedLength(payload);\n     }\n     byte[] buf \u003d new byte[length + 4];\n     CodedOutputStream cos \u003d CodedOutputStream.newInstance(buf);\n     // the stream only supports little endian ints\n     cos.writeRawByte((byte)((length \u003e\u003e\u003e 24) \u0026 0xFF));\n     cos.writeRawByte((byte)((length \u003e\u003e\u003e 16) \u0026 0xFF));\n     cos.writeRawByte((byte)((length \u003e\u003e\u003e  8) \u0026 0xFF));\n     cos.writeRawByte((byte)((length \u003e\u003e\u003e  0) \u0026 0xFF));\n-    cos.writeRawVarint32(header.getSerializedSize());\n+    cos.writeUInt32NoTag(header.getSerializedSize());\n     header.writeTo(cos);\n     if (payload !\u003d null) {\n-      cos.writeRawVarint32(payload.getSerializedSize());\n+      cos.writeUInt32NoTag(payload.getSerializedSize());\n       payload.writeTo(cos);\n     }\n     return buf;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private byte[] setupResponseForProtobuf(\n      RpcResponseHeaderProto header, Writable rv) throws IOException {\n    Message payload \u003d (rv !\u003d null)\n        ? ((RpcWritable.ProtobufWrapper)rv).getMessage() : null;\n    int length \u003d getDelimitedLength(header);\n    if (payload !\u003d null) {\n      length +\u003d getDelimitedLength(payload);\n    }\n    byte[] buf \u003d new byte[length + 4];\n    CodedOutputStream cos \u003d CodedOutputStream.newInstance(buf);\n    // the stream only supports little endian ints\n    cos.writeRawByte((byte)((length \u003e\u003e\u003e 24) \u0026 0xFF));\n    cos.writeRawByte((byte)((length \u003e\u003e\u003e 16) \u0026 0xFF));\n    cos.writeRawByte((byte)((length \u003e\u003e\u003e  8) \u0026 0xFF));\n    cos.writeRawByte((byte)((length \u003e\u003e\u003e  0) \u0026 0xFF));\n    cos.writeUInt32NoTag(header.getSerializedSize());\n    header.writeTo(cos);\n    if (payload !\u003d null) {\n      cos.writeUInt32NoTag(payload.getSerializedSize());\n      payload.writeTo(cos);\n    }\n    return buf;\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "39d1b1d747b1e325792b897b3264272f32b756a9": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13549. Eliminate intermediate buffer for server-side PB encoding. Contributed by Daryn Sharp.\n",
      "commitDate": "06/09/16 8:02 AM",
      "commitName": "39d1b1d747b1e325792b897b3264272f32b756a9",
      "commitAuthor": "Kihwal Lee",
      "diff": "@@ -0,0 +1,23 @@\n+  private byte[] setupResponseForProtobuf(\n+      RpcResponseHeaderProto header, Writable rv) throws IOException {\n+    Message payload \u003d (rv !\u003d null)\n+        ? ((RpcWritable.ProtobufWrapper)rv).getMessage() : null;\n+    int length \u003d getDelimitedLength(header);\n+    if (payload !\u003d null) {\n+      length +\u003d getDelimitedLength(payload);\n+    }\n+    byte[] buf \u003d new byte[length + 4];\n+    CodedOutputStream cos \u003d CodedOutputStream.newInstance(buf);\n+    // the stream only supports little endian ints\n+    cos.writeRawByte((byte)((length \u003e\u003e\u003e 24) \u0026 0xFF));\n+    cos.writeRawByte((byte)((length \u003e\u003e\u003e 16) \u0026 0xFF));\n+    cos.writeRawByte((byte)((length \u003e\u003e\u003e  8) \u0026 0xFF));\n+    cos.writeRawByte((byte)((length \u003e\u003e\u003e  0) \u0026 0xFF));\n+    cos.writeRawVarint32(header.getSerializedSize());\n+    header.writeTo(cos);\n+    if (payload !\u003d null) {\n+      cos.writeRawVarint32(payload.getSerializedSize());\n+      payload.writeTo(cos);\n+    }\n+    return buf;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private byte[] setupResponseForProtobuf(\n      RpcResponseHeaderProto header, Writable rv) throws IOException {\n    Message payload \u003d (rv !\u003d null)\n        ? ((RpcWritable.ProtobufWrapper)rv).getMessage() : null;\n    int length \u003d getDelimitedLength(header);\n    if (payload !\u003d null) {\n      length +\u003d getDelimitedLength(payload);\n    }\n    byte[] buf \u003d new byte[length + 4];\n    CodedOutputStream cos \u003d CodedOutputStream.newInstance(buf);\n    // the stream only supports little endian ints\n    cos.writeRawByte((byte)((length \u003e\u003e\u003e 24) \u0026 0xFF));\n    cos.writeRawByte((byte)((length \u003e\u003e\u003e 16) \u0026 0xFF));\n    cos.writeRawByte((byte)((length \u003e\u003e\u003e  8) \u0026 0xFF));\n    cos.writeRawByte((byte)((length \u003e\u003e\u003e  0) \u0026 0xFF));\n    cos.writeRawVarint32(header.getSerializedSize());\n    header.writeTo(cos);\n    if (payload !\u003d null) {\n      cos.writeRawVarint32(payload.getSerializedSize());\n      payload.writeTo(cos);\n    }\n    return buf;\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java"
    }
  }
}