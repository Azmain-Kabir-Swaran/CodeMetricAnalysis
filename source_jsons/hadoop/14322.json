{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "QJournalProtocolServerSideTranslatorPB.java",
  "functionName": "startLogSegment",
  "functionId": "startLogSegment___controller-RpcController__req-StartLogSegmentRequestProto",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/protocolPB/QJournalProtocolServerSideTranslatorPB.java",
  "functionStartLine": 187,
  "functionEndLine": 198,
  "numCommitsSeen": 22,
  "timeTaken": 1350,
  "changeHistory": [
    "9dab514b22f49322738935cfd915c2b4eba50b88",
    "8f70a25b1c5df498c441a9b3475a8ada5a92111f",
    "74d4573a23db5586c6e47ff2277aa7c35237da34"
  ],
  "changeHistoryShort": {
    "9dab514b22f49322738935cfd915c2b4eba50b88": "Ybodychange",
    "8f70a25b1c5df498c441a9b3475a8ada5a92111f": "Ybodychange",
    "74d4573a23db5586c6e47ff2277aa7c35237da34": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9dab514b22f49322738935cfd915c2b4eba50b88": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6038. Allow JournalNode to handle editlog produced by new release with future layoutversion. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1579813 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/03/14 4:06 PM",
      "commitName": "9dab514b22f49322738935cfd915c2b4eba50b88",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "19/02/14 3:56 PM",
      "commitNameOld": "e891c55f8ba4ca8a751bb3a48cf1eaa03cab88bd",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 28.97,
      "commitsBetweenForRepo": 264,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,12 @@\n   public StartLogSegmentResponseProto startLogSegment(RpcController controller,\n       StartLogSegmentRequestProto req) throws ServiceException {\n     try {\n-      impl.startLogSegment(convert(req.getReqInfo()),\n-          req.getTxid());\n+      int layoutVersion \u003d req.hasLayoutVersion() ? req.getLayoutVersion()\n+          : NameNodeLayoutVersion.CURRENT_LAYOUT_VERSION;\n+      impl.startLogSegment(convert(req.getReqInfo()), req.getTxid(),\n+          layoutVersion);\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     return VOID_START_LOG_SEGMENT_RESPONSE;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public StartLogSegmentResponseProto startLogSegment(RpcController controller,\n      StartLogSegmentRequestProto req) throws ServiceException {\n    try {\n      int layoutVersion \u003d req.hasLayoutVersion() ? req.getLayoutVersion()\n          : NameNodeLayoutVersion.CURRENT_LAYOUT_VERSION;\n      impl.startLogSegment(convert(req.getReqInfo()), req.getTxid(),\n          layoutVersion);\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    return VOID_START_LOG_SEGMENT_RESPONSE;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/protocolPB/QJournalProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "8f70a25b1c5df498c441a9b3475a8ada5a92111f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4393. Make empty request and responses in protocol translators can be static final members. Contributed by Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1434844 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/01/13 10:21 AM",
      "commitName": "8f70a25b1c5df498c441a9b3475a8ada5a92111f",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "10/09/12 11:33 PM",
      "commitNameOld": "a93ba1648ac78ae0ad9e7c75c35e8594d8c48af4",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 128.49,
      "commitsBetweenForRepo": 642,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,10 @@\n   public StartLogSegmentResponseProto startLogSegment(RpcController controller,\n       StartLogSegmentRequestProto req) throws ServiceException {\n     try {\n       impl.startLogSegment(convert(req.getReqInfo()),\n           req.getTxid());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n-    return StartLogSegmentResponseProto.newBuilder().build();\n+    return VOID_START_LOG_SEGMENT_RESPONSE;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public StartLogSegmentResponseProto startLogSegment(RpcController controller,\n      StartLogSegmentRequestProto req) throws ServiceException {\n    try {\n      impl.startLogSegment(convert(req.getReqInfo()),\n          req.getTxid());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    return VOID_START_LOG_SEGMENT_RESPONSE;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/protocolPB/QJournalProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "74d4573a23db5586c6e47ff2277aa7c35237da34": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1363596 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/07/12 5:25 PM",
      "commitName": "74d4573a23db5586c6e47ff2277aa7c35237da34",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,10 @@\n+  public StartLogSegmentResponseProto startLogSegment(RpcController controller,\n+      StartLogSegmentRequestProto req) throws ServiceException {\n+    try {\n+      impl.startLogSegment(convert(req.getReqInfo()),\n+          req.getTxid());\n+    } catch (IOException e) {\n+      throw new ServiceException(e);\n+    }\n+    return StartLogSegmentResponseProto.newBuilder().build();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public StartLogSegmentResponseProto startLogSegment(RpcController controller,\n      StartLogSegmentRequestProto req) throws ServiceException {\n    try {\n      impl.startLogSegment(convert(req.getReqInfo()),\n          req.getTxid());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    return StartLogSegmentResponseProto.newBuilder().build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/protocolPB/QJournalProtocolServerSideTranslatorPB.java"
    }
  }
}