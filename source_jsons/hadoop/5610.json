{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CacheManager.java",
  "functionName": "modifyDirective",
  "functionId": "modifyDirective___info-CacheDirectiveInfo__pc-FSPermissionChecker__flags-EnumSet__CacheFlag__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
  "functionStartLine": 624,
  "functionEndLine": 673,
  "numCommitsSeen": 133,
  "timeTaken": 4246,
  "changeHistory": [
    "93e23a99157c30b51752fc49748c3c210745a187",
    "d85c017d0488930d806f267141057fc73e68c728",
    "b9ae3087c0f83bfeeea47ded8e19932b46fd2350",
    "991c453ca3ac141a3f286f74af8401f83c38b230",
    "9da451cac57f3cd64c2c047675e5b60ca88ecf83",
    "13edb391d06c479720202eb5ac81f1c71fe64748",
    "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
    "ce35e0950cef9250ce2ceffb3b8bfcff533c6b92",
    "f79b3e6b17450e9d34c483046b7437b09dd72016"
  ],
  "changeHistoryShort": {
    "93e23a99157c30b51752fc49748c3c210745a187": "Ybodychange",
    "d85c017d0488930d806f267141057fc73e68c728": "Ybodychange",
    "b9ae3087c0f83bfeeea47ded8e19932b46fd2350": "Ybodychange",
    "991c453ca3ac141a3f286f74af8401f83c38b230": "Ymultichange(Yparameterchange,Ybodychange)",
    "9da451cac57f3cd64c2c047675e5b60ca88ecf83": "Ybodychange",
    "13edb391d06c479720202eb5ac81f1c71fe64748": "Ymultichange(Yparameterchange,Ybodychange)",
    "f91a45a96c21db9e5d40097c7d3f5d005ae10dde": "Ymultichange(Yparameterchange,Ybodychange)",
    "ce35e0950cef9250ce2ceffb3b8bfcff533c6b92": "Ybodychange",
    "f79b3e6b17450e9d34c483046b7437b09dd72016": "Yintroduced"
  },
  "changeHistoryDetails": {
    "93e23a99157c30b51752fc49748c3c210745a187": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6613. Improve logging in caching classes. (wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1607697 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/07/14 10:13 AM",
      "commitName": "93e23a99157c30b51752fc49748c3c210745a187",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "15/05/14 6:18 PM",
      "commitNameOld": "8f48760663070529ff09927d1772010fffe5f438",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 48.66,
      "commitsBetweenForRepo": 297,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,50 @@\n   public void modifyDirective(CacheDirectiveInfo info,\n       FSPermissionChecker pc, EnumSet\u003cCacheFlag\u003e flags) throws IOException {\n     assert namesystem.hasWriteLock();\n     String idString \u003d\n         (info.getId() \u003d\u003d null) ?\n             \"(null)\" : info.getId().toString();\n     try {\n       // Check for invalid IDs.\n       Long id \u003d info.getId();\n       if (id \u003d\u003d null) {\n         throw new InvalidRequestException(\"Must supply an ID.\");\n       }\n       CacheDirective prevEntry \u003d getById(id);\n       checkWritePermission(pc, prevEntry.getPool());\n \n       // Fill in defaults\n       CacheDirectiveInfo infoWithDefaults \u003d\n           createFromInfoAndDefaults(info, prevEntry);\n       CacheDirectiveInfo.Builder builder \u003d\n           new CacheDirectiveInfo.Builder(infoWithDefaults);\n \n       // Do validation\n       validatePath(infoWithDefaults);\n       validateReplication(infoWithDefaults, (short)-1);\n       // Need to test the pool being set here to avoid rejecting a modify for a\n       // directive that\u0027s already been forced into a pool\n       CachePool srcPool \u003d prevEntry.getPool();\n       CachePool destPool \u003d getCachePool(validatePoolName(infoWithDefaults));\n       if (!srcPool.getPoolName().equals(destPool.getPoolName())) {\n         checkWritePermission(pc, destPool);\n         if (!flags.contains(CacheFlag.FORCE)) {\n           checkLimit(destPool, infoWithDefaults.getPath().toUri().getPath(),\n               infoWithDefaults.getReplication());\n         }\n       }\n       // Verify the expiration against the destination pool\n       validateExpiryTime(infoWithDefaults, destPool.getMaxRelativeExpiryMs());\n \n       // Indicate changes to the CRM\n       setNeedsRescan();\n \n       // Validation passed\n       removeInternal(prevEntry);\n       addInternal(new CacheDirective(builder.build()), destPool);\n     } catch (IOException e) {\n       LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n       throw e;\n     }\n-    LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n-        info+ \".\");\n+    LOG.info(\"modifyDirective of {} successfully applied {}.\", idString, info);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void modifyDirective(CacheDirectiveInfo info,\n      FSPermissionChecker pc, EnumSet\u003cCacheFlag\u003e flags) throws IOException {\n    assert namesystem.hasWriteLock();\n    String idString \u003d\n        (info.getId() \u003d\u003d null) ?\n            \"(null)\" : info.getId().toString();\n    try {\n      // Check for invalid IDs.\n      Long id \u003d info.getId();\n      if (id \u003d\u003d null) {\n        throw new InvalidRequestException(\"Must supply an ID.\");\n      }\n      CacheDirective prevEntry \u003d getById(id);\n      checkWritePermission(pc, prevEntry.getPool());\n\n      // Fill in defaults\n      CacheDirectiveInfo infoWithDefaults \u003d\n          createFromInfoAndDefaults(info, prevEntry);\n      CacheDirectiveInfo.Builder builder \u003d\n          new CacheDirectiveInfo.Builder(infoWithDefaults);\n\n      // Do validation\n      validatePath(infoWithDefaults);\n      validateReplication(infoWithDefaults, (short)-1);\n      // Need to test the pool being set here to avoid rejecting a modify for a\n      // directive that\u0027s already been forced into a pool\n      CachePool srcPool \u003d prevEntry.getPool();\n      CachePool destPool \u003d getCachePool(validatePoolName(infoWithDefaults));\n      if (!srcPool.getPoolName().equals(destPool.getPoolName())) {\n        checkWritePermission(pc, destPool);\n        if (!flags.contains(CacheFlag.FORCE)) {\n          checkLimit(destPool, infoWithDefaults.getPath().toUri().getPath(),\n              infoWithDefaults.getReplication());\n        }\n      }\n      // Verify the expiration against the destination pool\n      validateExpiryTime(infoWithDefaults, destPool.getMaxRelativeExpiryMs());\n\n      // Indicate changes to the CRM\n      setNeedsRescan();\n\n      // Validation passed\n      removeInternal(prevEntry);\n      addInternal(new CacheDirective(builder.build()), destPool);\n    } catch (IOException e) {\n      LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n      throw e;\n    }\n    LOG.info(\"modifyDirective of {} successfully applied {}.\", idString, info);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "d85c017d0488930d806f267141057fc73e68c728": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5651. Remove dfs.namenode.caching.enabled and improve CRM locking. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1555002 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/01/14 6:45 PM",
      "commitName": "d85c017d0488930d806f267141057fc73e68c728",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "31/12/13 4:01 PM",
      "commitNameOld": "07e4fb1455abc33584fc666ef745abe256ebd7d1",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 2.11,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,51 @@\n   public void modifyDirective(CacheDirectiveInfo info,\n       FSPermissionChecker pc, EnumSet\u003cCacheFlag\u003e flags) throws IOException {\n     assert namesystem.hasWriteLock();\n     String idString \u003d\n         (info.getId() \u003d\u003d null) ?\n             \"(null)\" : info.getId().toString();\n     try {\n       // Check for invalid IDs.\n       Long id \u003d info.getId();\n       if (id \u003d\u003d null) {\n         throw new InvalidRequestException(\"Must supply an ID.\");\n       }\n       CacheDirective prevEntry \u003d getById(id);\n       checkWritePermission(pc, prevEntry.getPool());\n \n       // Fill in defaults\n       CacheDirectiveInfo infoWithDefaults \u003d\n           createFromInfoAndDefaults(info, prevEntry);\n       CacheDirectiveInfo.Builder builder \u003d\n           new CacheDirectiveInfo.Builder(infoWithDefaults);\n \n       // Do validation\n       validatePath(infoWithDefaults);\n       validateReplication(infoWithDefaults, (short)-1);\n       // Need to test the pool being set here to avoid rejecting a modify for a\n       // directive that\u0027s already been forced into a pool\n       CachePool srcPool \u003d prevEntry.getPool();\n       CachePool destPool \u003d getCachePool(validatePoolName(infoWithDefaults));\n       if (!srcPool.getPoolName().equals(destPool.getPoolName())) {\n         checkWritePermission(pc, destPool);\n         if (!flags.contains(CacheFlag.FORCE)) {\n           checkLimit(destPool, infoWithDefaults.getPath().toUri().getPath(),\n               infoWithDefaults.getReplication());\n         }\n       }\n       // Verify the expiration against the destination pool\n       validateExpiryTime(infoWithDefaults, destPool.getMaxRelativeExpiryMs());\n \n       // Indicate changes to the CRM\n-      if (monitor !\u003d null) {\n-        monitor.setNeedsRescan();\n-      }\n+      setNeedsRescan();\n \n       // Validation passed\n       removeInternal(prevEntry);\n       addInternal(new CacheDirective(builder.build()), destPool);\n     } catch (IOException e) {\n       LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n       throw e;\n     }\n     LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n         info+ \".\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void modifyDirective(CacheDirectiveInfo info,\n      FSPermissionChecker pc, EnumSet\u003cCacheFlag\u003e flags) throws IOException {\n    assert namesystem.hasWriteLock();\n    String idString \u003d\n        (info.getId() \u003d\u003d null) ?\n            \"(null)\" : info.getId().toString();\n    try {\n      // Check for invalid IDs.\n      Long id \u003d info.getId();\n      if (id \u003d\u003d null) {\n        throw new InvalidRequestException(\"Must supply an ID.\");\n      }\n      CacheDirective prevEntry \u003d getById(id);\n      checkWritePermission(pc, prevEntry.getPool());\n\n      // Fill in defaults\n      CacheDirectiveInfo infoWithDefaults \u003d\n          createFromInfoAndDefaults(info, prevEntry);\n      CacheDirectiveInfo.Builder builder \u003d\n          new CacheDirectiveInfo.Builder(infoWithDefaults);\n\n      // Do validation\n      validatePath(infoWithDefaults);\n      validateReplication(infoWithDefaults, (short)-1);\n      // Need to test the pool being set here to avoid rejecting a modify for a\n      // directive that\u0027s already been forced into a pool\n      CachePool srcPool \u003d prevEntry.getPool();\n      CachePool destPool \u003d getCachePool(validatePoolName(infoWithDefaults));\n      if (!srcPool.getPoolName().equals(destPool.getPoolName())) {\n        checkWritePermission(pc, destPool);\n        if (!flags.contains(CacheFlag.FORCE)) {\n          checkLimit(destPool, infoWithDefaults.getPath().toUri().getPath(),\n              infoWithDefaults.getReplication());\n        }\n      }\n      // Verify the expiration against the destination pool\n      validateExpiryTime(infoWithDefaults, destPool.getMaxRelativeExpiryMs());\n\n      // Indicate changes to the CRM\n      setNeedsRescan();\n\n      // Validation passed\n      removeInternal(prevEntry);\n      addInternal(new CacheDirective(builder.build()), destPool);\n    } catch (IOException e) {\n      LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n      throw e;\n    }\n    LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n        info+ \".\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "b9ae3087c0f83bfeeea47ded8e19932b46fd2350": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5636. Enforce a max TTL per cache pool (awang via cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1552841 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/12/13 3:27 PM",
      "commitName": "b9ae3087c0f83bfeeea47ded8e19932b46fd2350",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "17/12/13 10:47 AM",
      "commitNameOld": "991c453ca3ac141a3f286f74af8401f83c38b230",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 3.19,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,53 @@\n   public void modifyDirective(CacheDirectiveInfo info,\n       FSPermissionChecker pc, EnumSet\u003cCacheFlag\u003e flags) throws IOException {\n     assert namesystem.hasWriteLock();\n     String idString \u003d\n         (info.getId() \u003d\u003d null) ?\n             \"(null)\" : info.getId().toString();\n     try {\n       // Check for invalid IDs.\n       Long id \u003d info.getId();\n       if (id \u003d\u003d null) {\n         throw new InvalidRequestException(\"Must supply an ID.\");\n       }\n       CacheDirective prevEntry \u003d getById(id);\n       checkWritePermission(pc, prevEntry.getPool());\n-      String path \u003d prevEntry.getPath();\n-      if (info.getPath() !\u003d null) {\n-        path \u003d validatePath(info);\n-      }\n \n-      short replication \u003d prevEntry.getReplication();\n-      replication \u003d validateReplication(info, replication);\n+      // Fill in defaults\n+      CacheDirectiveInfo infoWithDefaults \u003d\n+          createFromInfoAndDefaults(info, prevEntry);\n+      CacheDirectiveInfo.Builder builder \u003d\n+          new CacheDirectiveInfo.Builder(infoWithDefaults);\n \n-      long expiryTime \u003d prevEntry.getExpiryTime();\n-      expiryTime \u003d validateExpiryTime(info, expiryTime);\n-\n-      CachePool pool \u003d prevEntry.getPool();\n-      if (info.getPool() !\u003d null) {\n-        pool \u003d getCachePool(validatePoolName(info));\n-        checkWritePermission(pc, pool);\n+      // Do validation\n+      validatePath(infoWithDefaults);\n+      validateReplication(infoWithDefaults, (short)-1);\n+      // Need to test the pool being set here to avoid rejecting a modify for a\n+      // directive that\u0027s already been forced into a pool\n+      CachePool srcPool \u003d prevEntry.getPool();\n+      CachePool destPool \u003d getCachePool(validatePoolName(infoWithDefaults));\n+      if (!srcPool.getPoolName().equals(destPool.getPoolName())) {\n+        checkWritePermission(pc, destPool);\n         if (!flags.contains(CacheFlag.FORCE)) {\n-          // Can\u0027t kick and wait if caching is disabled\n-          if (monitor !\u003d null) {\n-            monitor.waitForRescan();\n-          }\n-          checkLimit(pool, path, replication);\n+          checkLimit(destPool, infoWithDefaults.getPath().toUri().getPath(),\n+              infoWithDefaults.getReplication());\n         }\n       }\n+      // Verify the expiration against the destination pool\n+      validateExpiryTime(infoWithDefaults, destPool.getMaxRelativeExpiryMs());\n+\n+      // Indicate changes to the CRM\n+      if (monitor !\u003d null) {\n+        monitor.setNeedsRescan();\n+      }\n+\n+      // Validation passed\n       removeInternal(prevEntry);\n-      CacheDirective newEntry \u003d\n-          new CacheDirective(id, path, replication, expiryTime);\n-      addInternal(newEntry, pool);\n+      addInternal(new CacheDirective(builder.build()), destPool);\n     } catch (IOException e) {\n       LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n       throw e;\n     }\n     LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n         info+ \".\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void modifyDirective(CacheDirectiveInfo info,\n      FSPermissionChecker pc, EnumSet\u003cCacheFlag\u003e flags) throws IOException {\n    assert namesystem.hasWriteLock();\n    String idString \u003d\n        (info.getId() \u003d\u003d null) ?\n            \"(null)\" : info.getId().toString();\n    try {\n      // Check for invalid IDs.\n      Long id \u003d info.getId();\n      if (id \u003d\u003d null) {\n        throw new InvalidRequestException(\"Must supply an ID.\");\n      }\n      CacheDirective prevEntry \u003d getById(id);\n      checkWritePermission(pc, prevEntry.getPool());\n\n      // Fill in defaults\n      CacheDirectiveInfo infoWithDefaults \u003d\n          createFromInfoAndDefaults(info, prevEntry);\n      CacheDirectiveInfo.Builder builder \u003d\n          new CacheDirectiveInfo.Builder(infoWithDefaults);\n\n      // Do validation\n      validatePath(infoWithDefaults);\n      validateReplication(infoWithDefaults, (short)-1);\n      // Need to test the pool being set here to avoid rejecting a modify for a\n      // directive that\u0027s already been forced into a pool\n      CachePool srcPool \u003d prevEntry.getPool();\n      CachePool destPool \u003d getCachePool(validatePoolName(infoWithDefaults));\n      if (!srcPool.getPoolName().equals(destPool.getPoolName())) {\n        checkWritePermission(pc, destPool);\n        if (!flags.contains(CacheFlag.FORCE)) {\n          checkLimit(destPool, infoWithDefaults.getPath().toUri().getPath(),\n              infoWithDefaults.getReplication());\n        }\n      }\n      // Verify the expiration against the destination pool\n      validateExpiryTime(infoWithDefaults, destPool.getMaxRelativeExpiryMs());\n\n      // Indicate changes to the CRM\n      if (monitor !\u003d null) {\n        monitor.setNeedsRescan();\n      }\n\n      // Validation passed\n      removeInternal(prevEntry);\n      addInternal(new CacheDirective(builder.build()), destPool);\n    } catch (IOException e) {\n      LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n      throw e;\n    }\n    LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n        info+ \".\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "991c453ca3ac141a3f286f74af8401f83c38b230": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5431. Support cachepool-based limit management in path-based caching. (awang via cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1551651 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/12/13 10:47 AM",
      "commitName": "991c453ca3ac141a3f286f74af8401f83c38b230",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5431. Support cachepool-based limit management in path-based caching. (awang via cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1551651 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "17/12/13 10:47 AM",
          "commitName": "991c453ca3ac141a3f286f74af8401f83c38b230",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "05/12/13 1:09 PM",
          "commitNameOld": "55e5b0653c34a5f4146ce5a97a5b4a88a976d88a",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 11.9,
          "commitsBetweenForRepo": 67,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,48 @@\n   public void modifyDirective(CacheDirectiveInfo info,\n-      FSPermissionChecker pc) throws IOException {\n+      FSPermissionChecker pc, EnumSet\u003cCacheFlag\u003e flags) throws IOException {\n     assert namesystem.hasWriteLock();\n     String idString \u003d\n         (info.getId() \u003d\u003d null) ?\n             \"(null)\" : info.getId().toString();\n     try {\n       // Check for invalid IDs.\n       Long id \u003d info.getId();\n       if (id \u003d\u003d null) {\n         throw new InvalidRequestException(\"Must supply an ID.\");\n       }\n       CacheDirective prevEntry \u003d getById(id);\n       checkWritePermission(pc, prevEntry.getPool());\n       String path \u003d prevEntry.getPath();\n       if (info.getPath() !\u003d null) {\n         path \u003d validatePath(info);\n       }\n \n       short replication \u003d prevEntry.getReplication();\n       replication \u003d validateReplication(info, replication);\n \n       long expiryTime \u003d prevEntry.getExpiryTime();\n       expiryTime \u003d validateExpiryTime(info, expiryTime);\n \n       CachePool pool \u003d prevEntry.getPool();\n       if (info.getPool() !\u003d null) {\n         pool \u003d getCachePool(validatePoolName(info));\n         checkWritePermission(pc, pool);\n+        if (!flags.contains(CacheFlag.FORCE)) {\n+          // Can\u0027t kick and wait if caching is disabled\n+          if (monitor !\u003d null) {\n+            monitor.waitForRescan();\n+          }\n+          checkLimit(pool, path, replication);\n+        }\n       }\n       removeInternal(prevEntry);\n       CacheDirective newEntry \u003d\n           new CacheDirective(id, path, replication, expiryTime);\n       addInternal(newEntry, pool);\n     } catch (IOException e) {\n       LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n       throw e;\n     }\n     LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n         info+ \".\");\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void modifyDirective(CacheDirectiveInfo info,\n      FSPermissionChecker pc, EnumSet\u003cCacheFlag\u003e flags) throws IOException {\n    assert namesystem.hasWriteLock();\n    String idString \u003d\n        (info.getId() \u003d\u003d null) ?\n            \"(null)\" : info.getId().toString();\n    try {\n      // Check for invalid IDs.\n      Long id \u003d info.getId();\n      if (id \u003d\u003d null) {\n        throw new InvalidRequestException(\"Must supply an ID.\");\n      }\n      CacheDirective prevEntry \u003d getById(id);\n      checkWritePermission(pc, prevEntry.getPool());\n      String path \u003d prevEntry.getPath();\n      if (info.getPath() !\u003d null) {\n        path \u003d validatePath(info);\n      }\n\n      short replication \u003d prevEntry.getReplication();\n      replication \u003d validateReplication(info, replication);\n\n      long expiryTime \u003d prevEntry.getExpiryTime();\n      expiryTime \u003d validateExpiryTime(info, expiryTime);\n\n      CachePool pool \u003d prevEntry.getPool();\n      if (info.getPool() !\u003d null) {\n        pool \u003d getCachePool(validatePoolName(info));\n        checkWritePermission(pc, pool);\n        if (!flags.contains(CacheFlag.FORCE)) {\n          // Can\u0027t kick and wait if caching is disabled\n          if (monitor !\u003d null) {\n            monitor.waitForRescan();\n          }\n          checkLimit(pool, path, replication);\n        }\n      }\n      removeInternal(prevEntry);\n      CacheDirective newEntry \u003d\n          new CacheDirective(id, path, replication, expiryTime);\n      addInternal(newEntry, pool);\n    } catch (IOException e) {\n      LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n      throw e;\n    }\n    LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n        info+ \".\");\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "[info-CacheDirectiveInfo, pc-FSPermissionChecker]",
            "newValue": "[info-CacheDirectiveInfo, pc-FSPermissionChecker, flags-EnumSet\u003cCacheFlag\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5431. Support cachepool-based limit management in path-based caching. (awang via cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1551651 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "17/12/13 10:47 AM",
          "commitName": "991c453ca3ac141a3f286f74af8401f83c38b230",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "05/12/13 1:09 PM",
          "commitNameOld": "55e5b0653c34a5f4146ce5a97a5b4a88a976d88a",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 11.9,
          "commitsBetweenForRepo": 67,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,48 @@\n   public void modifyDirective(CacheDirectiveInfo info,\n-      FSPermissionChecker pc) throws IOException {\n+      FSPermissionChecker pc, EnumSet\u003cCacheFlag\u003e flags) throws IOException {\n     assert namesystem.hasWriteLock();\n     String idString \u003d\n         (info.getId() \u003d\u003d null) ?\n             \"(null)\" : info.getId().toString();\n     try {\n       // Check for invalid IDs.\n       Long id \u003d info.getId();\n       if (id \u003d\u003d null) {\n         throw new InvalidRequestException(\"Must supply an ID.\");\n       }\n       CacheDirective prevEntry \u003d getById(id);\n       checkWritePermission(pc, prevEntry.getPool());\n       String path \u003d prevEntry.getPath();\n       if (info.getPath() !\u003d null) {\n         path \u003d validatePath(info);\n       }\n \n       short replication \u003d prevEntry.getReplication();\n       replication \u003d validateReplication(info, replication);\n \n       long expiryTime \u003d prevEntry.getExpiryTime();\n       expiryTime \u003d validateExpiryTime(info, expiryTime);\n \n       CachePool pool \u003d prevEntry.getPool();\n       if (info.getPool() !\u003d null) {\n         pool \u003d getCachePool(validatePoolName(info));\n         checkWritePermission(pc, pool);\n+        if (!flags.contains(CacheFlag.FORCE)) {\n+          // Can\u0027t kick and wait if caching is disabled\n+          if (monitor !\u003d null) {\n+            monitor.waitForRescan();\n+          }\n+          checkLimit(pool, path, replication);\n+        }\n       }\n       removeInternal(prevEntry);\n       CacheDirective newEntry \u003d\n           new CacheDirective(id, path, replication, expiryTime);\n       addInternal(newEntry, pool);\n     } catch (IOException e) {\n       LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n       throw e;\n     }\n     LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n         info+ \".\");\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void modifyDirective(CacheDirectiveInfo info,\n      FSPermissionChecker pc, EnumSet\u003cCacheFlag\u003e flags) throws IOException {\n    assert namesystem.hasWriteLock();\n    String idString \u003d\n        (info.getId() \u003d\u003d null) ?\n            \"(null)\" : info.getId().toString();\n    try {\n      // Check for invalid IDs.\n      Long id \u003d info.getId();\n      if (id \u003d\u003d null) {\n        throw new InvalidRequestException(\"Must supply an ID.\");\n      }\n      CacheDirective prevEntry \u003d getById(id);\n      checkWritePermission(pc, prevEntry.getPool());\n      String path \u003d prevEntry.getPath();\n      if (info.getPath() !\u003d null) {\n        path \u003d validatePath(info);\n      }\n\n      short replication \u003d prevEntry.getReplication();\n      replication \u003d validateReplication(info, replication);\n\n      long expiryTime \u003d prevEntry.getExpiryTime();\n      expiryTime \u003d validateExpiryTime(info, expiryTime);\n\n      CachePool pool \u003d prevEntry.getPool();\n      if (info.getPool() !\u003d null) {\n        pool \u003d getCachePool(validatePoolName(info));\n        checkWritePermission(pc, pool);\n        if (!flags.contains(CacheFlag.FORCE)) {\n          // Can\u0027t kick and wait if caching is disabled\n          if (monitor !\u003d null) {\n            monitor.waitForRescan();\n          }\n          checkLimit(pool, path, replication);\n        }\n      }\n      removeInternal(prevEntry);\n      CacheDirective newEntry \u003d\n          new CacheDirective(id, path, replication, expiryTime);\n      addInternal(newEntry, pool);\n    } catch (IOException e) {\n      LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n      throw e;\n    }\n    LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n        info+ \".\");\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "9da451cac57f3cd64c2c047675e5b60ca88ecf83": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5430. Support TTL on CacheDirectives. Contributed by Andrew Wang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546301 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/11/13 11:20 PM",
      "commitName": "9da451cac57f3cd64c2c047675e5b60ca88ecf83",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "27/11/13 9:55 AM",
      "commitNameOld": "13edb391d06c479720202eb5ac81f1c71fe64748",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 0.56,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,41 @@\n   public void modifyDirective(CacheDirectiveInfo info,\n       FSPermissionChecker pc) throws IOException {\n     assert namesystem.hasWriteLock();\n     String idString \u003d\n         (info.getId() \u003d\u003d null) ?\n             \"(null)\" : info.getId().toString();\n     try {\n       // Check for invalid IDs.\n       Long id \u003d info.getId();\n       if (id \u003d\u003d null) {\n         throw new InvalidRequestException(\"Must supply an ID.\");\n       }\n       CacheDirective prevEntry \u003d getById(id);\n       checkWritePermission(pc, prevEntry.getPool());\n       String path \u003d prevEntry.getPath();\n       if (info.getPath() !\u003d null) {\n         path \u003d validatePath(info);\n       }\n+\n       short replication \u003d prevEntry.getReplication();\n-      if (info.getReplication() !\u003d null) {\n-        replication \u003d validateReplication(info, replication);\n-      }\n+      replication \u003d validateReplication(info, replication);\n+\n+      long expiryTime \u003d prevEntry.getExpiryTime();\n+      expiryTime \u003d validateExpiryTime(info, expiryTime);\n+\n       CachePool pool \u003d prevEntry.getPool();\n       if (info.getPool() !\u003d null) {\n         pool \u003d getCachePool(validatePoolName(info));\n         checkWritePermission(pc, pool);\n       }\n       removeInternal(prevEntry);\n       CacheDirective newEntry \u003d\n-          new CacheDirective(id, path, replication);\n+          new CacheDirective(id, path, replication, expiryTime);\n       addInternal(newEntry, pool);\n     } catch (IOException e) {\n       LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n       throw e;\n     }\n     LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n         info+ \".\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void modifyDirective(CacheDirectiveInfo info,\n      FSPermissionChecker pc) throws IOException {\n    assert namesystem.hasWriteLock();\n    String idString \u003d\n        (info.getId() \u003d\u003d null) ?\n            \"(null)\" : info.getId().toString();\n    try {\n      // Check for invalid IDs.\n      Long id \u003d info.getId();\n      if (id \u003d\u003d null) {\n        throw new InvalidRequestException(\"Must supply an ID.\");\n      }\n      CacheDirective prevEntry \u003d getById(id);\n      checkWritePermission(pc, prevEntry.getPool());\n      String path \u003d prevEntry.getPath();\n      if (info.getPath() !\u003d null) {\n        path \u003d validatePath(info);\n      }\n\n      short replication \u003d prevEntry.getReplication();\n      replication \u003d validateReplication(info, replication);\n\n      long expiryTime \u003d prevEntry.getExpiryTime();\n      expiryTime \u003d validateExpiryTime(info, expiryTime);\n\n      CachePool pool \u003d prevEntry.getPool();\n      if (info.getPool() !\u003d null) {\n        pool \u003d getCachePool(validatePoolName(info));\n        checkWritePermission(pc, pool);\n      }\n      removeInternal(prevEntry);\n      CacheDirective newEntry \u003d\n          new CacheDirective(id, path, replication, expiryTime);\n      addInternal(newEntry, pool);\n    } catch (IOException e) {\n      LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n      throw e;\n    }\n    LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n        info+ \".\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "13edb391d06c479720202eb5ac81f1c71fe64748": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5556. Add some more NameNode cache statistics, cache pool stats (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546143 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/11/13 9:55 AM",
      "commitName": "13edb391d06c479720202eb5ac81f1c71fe64748",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5556. Add some more NameNode cache statistics, cache pool stats (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546143 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/11/13 9:55 AM",
          "commitName": "13edb391d06c479720202eb5ac81f1c71fe64748",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "21/11/13 9:12 AM",
          "commitNameOld": "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 6.03,
          "commitsBetweenForRepo": 22,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,38 @@\n-  public void modifyDirective(CacheDirectiveInfo directive,\n+  public void modifyDirective(CacheDirectiveInfo info,\n       FSPermissionChecker pc) throws IOException {\n     assert namesystem.hasWriteLock();\n     String idString \u003d\n-        (directive.getId() \u003d\u003d null) ?\n-            \"(null)\" : directive.getId().toString();\n+        (info.getId() \u003d\u003d null) ?\n+            \"(null)\" : info.getId().toString();\n     try {\n       // Check for invalid IDs.\n-      Long id \u003d directive.getId();\n+      Long id \u003d info.getId();\n       if (id \u003d\u003d null) {\n         throw new InvalidRequestException(\"Must supply an ID.\");\n       }\n       CacheDirective prevEntry \u003d getById(id);\n       checkWritePermission(pc, prevEntry.getPool());\n       String path \u003d prevEntry.getPath();\n-      if (directive.getPath() !\u003d null) {\n-        path \u003d validatePath(directive);\n+      if (info.getPath() !\u003d null) {\n+        path \u003d validatePath(info);\n       }\n       short replication \u003d prevEntry.getReplication();\n-      if (directive.getReplication() !\u003d null) {\n-        replication \u003d validateReplication(directive, replication);\n+      if (info.getReplication() !\u003d null) {\n+        replication \u003d validateReplication(info, replication);\n       }\n       CachePool pool \u003d prevEntry.getPool();\n-      if (directive.getPool() !\u003d null) {\n-        pool \u003d getCachePool(validatePoolName(directive));\n+      if (info.getPool() !\u003d null) {\n+        pool \u003d getCachePool(validatePoolName(info));\n         checkWritePermission(pc, pool);\n       }\n       removeInternal(prevEntry);\n       CacheDirective newEntry \u003d\n-          new CacheDirective(id, path, replication, pool);\n-      addInternal(newEntry);\n+          new CacheDirective(id, path, replication);\n+      addInternal(newEntry, pool);\n     } catch (IOException e) {\n       LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n       throw e;\n     }\n     LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n-        directive + \".\");\n+        info+ \".\");\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void modifyDirective(CacheDirectiveInfo info,\n      FSPermissionChecker pc) throws IOException {\n    assert namesystem.hasWriteLock();\n    String idString \u003d\n        (info.getId() \u003d\u003d null) ?\n            \"(null)\" : info.getId().toString();\n    try {\n      // Check for invalid IDs.\n      Long id \u003d info.getId();\n      if (id \u003d\u003d null) {\n        throw new InvalidRequestException(\"Must supply an ID.\");\n      }\n      CacheDirective prevEntry \u003d getById(id);\n      checkWritePermission(pc, prevEntry.getPool());\n      String path \u003d prevEntry.getPath();\n      if (info.getPath() !\u003d null) {\n        path \u003d validatePath(info);\n      }\n      short replication \u003d prevEntry.getReplication();\n      if (info.getReplication() !\u003d null) {\n        replication \u003d validateReplication(info, replication);\n      }\n      CachePool pool \u003d prevEntry.getPool();\n      if (info.getPool() !\u003d null) {\n        pool \u003d getCachePool(validatePoolName(info));\n        checkWritePermission(pc, pool);\n      }\n      removeInternal(prevEntry);\n      CacheDirective newEntry \u003d\n          new CacheDirective(id, path, replication);\n      addInternal(newEntry, pool);\n    } catch (IOException e) {\n      LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n      throw e;\n    }\n    LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n        info+ \".\");\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "[directive-CacheDirectiveInfo, pc-FSPermissionChecker]",
            "newValue": "[info-CacheDirectiveInfo, pc-FSPermissionChecker]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5556. Add some more NameNode cache statistics, cache pool stats (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546143 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/11/13 9:55 AM",
          "commitName": "13edb391d06c479720202eb5ac81f1c71fe64748",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "21/11/13 9:12 AM",
          "commitNameOld": "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 6.03,
          "commitsBetweenForRepo": 22,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,38 @@\n-  public void modifyDirective(CacheDirectiveInfo directive,\n+  public void modifyDirective(CacheDirectiveInfo info,\n       FSPermissionChecker pc) throws IOException {\n     assert namesystem.hasWriteLock();\n     String idString \u003d\n-        (directive.getId() \u003d\u003d null) ?\n-            \"(null)\" : directive.getId().toString();\n+        (info.getId() \u003d\u003d null) ?\n+            \"(null)\" : info.getId().toString();\n     try {\n       // Check for invalid IDs.\n-      Long id \u003d directive.getId();\n+      Long id \u003d info.getId();\n       if (id \u003d\u003d null) {\n         throw new InvalidRequestException(\"Must supply an ID.\");\n       }\n       CacheDirective prevEntry \u003d getById(id);\n       checkWritePermission(pc, prevEntry.getPool());\n       String path \u003d prevEntry.getPath();\n-      if (directive.getPath() !\u003d null) {\n-        path \u003d validatePath(directive);\n+      if (info.getPath() !\u003d null) {\n+        path \u003d validatePath(info);\n       }\n       short replication \u003d prevEntry.getReplication();\n-      if (directive.getReplication() !\u003d null) {\n-        replication \u003d validateReplication(directive, replication);\n+      if (info.getReplication() !\u003d null) {\n+        replication \u003d validateReplication(info, replication);\n       }\n       CachePool pool \u003d prevEntry.getPool();\n-      if (directive.getPool() !\u003d null) {\n-        pool \u003d getCachePool(validatePoolName(directive));\n+      if (info.getPool() !\u003d null) {\n+        pool \u003d getCachePool(validatePoolName(info));\n         checkWritePermission(pc, pool);\n       }\n       removeInternal(prevEntry);\n       CacheDirective newEntry \u003d\n-          new CacheDirective(id, path, replication, pool);\n-      addInternal(newEntry);\n+          new CacheDirective(id, path, replication);\n+      addInternal(newEntry, pool);\n     } catch (IOException e) {\n       LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n       throw e;\n     }\n     LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n-        directive + \".\");\n+        info+ \".\");\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void modifyDirective(CacheDirectiveInfo info,\n      FSPermissionChecker pc) throws IOException {\n    assert namesystem.hasWriteLock();\n    String idString \u003d\n        (info.getId() \u003d\u003d null) ?\n            \"(null)\" : info.getId().toString();\n    try {\n      // Check for invalid IDs.\n      Long id \u003d info.getId();\n      if (id \u003d\u003d null) {\n        throw new InvalidRequestException(\"Must supply an ID.\");\n      }\n      CacheDirective prevEntry \u003d getById(id);\n      checkWritePermission(pc, prevEntry.getPool());\n      String path \u003d prevEntry.getPath();\n      if (info.getPath() !\u003d null) {\n        path \u003d validatePath(info);\n      }\n      short replication \u003d prevEntry.getReplication();\n      if (info.getReplication() !\u003d null) {\n        replication \u003d validateReplication(info, replication);\n      }\n      CachePool pool \u003d prevEntry.getPool();\n      if (info.getPool() !\u003d null) {\n        pool \u003d getCachePool(validatePoolName(info));\n        checkWritePermission(pc, pool);\n      }\n      removeInternal(prevEntry);\n      CacheDirective newEntry \u003d\n          new CacheDirective(id, path, replication);\n      addInternal(newEntry, pool);\n    } catch (IOException e) {\n      LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n      throw e;\n    }\n    LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n        info+ \".\");\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "f91a45a96c21db9e5d40097c7d3f5d005ae10dde": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5473. Consistent naming of user-visible caching classes and methods (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544252 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/11/13 9:12 AM",
      "commitName": "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5473. Consistent naming of user-visible caching classes and methods (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544252 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/11/13 9:12 AM",
          "commitName": "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "18/11/13 6:01 PM",
          "commitNameOld": "4f15d0af4f3633bfa35f7cb7c1cc15ef545597d0",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 2.63,
          "commitsBetweenForRepo": 32,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,38 @@\n-  public void modifyDirective(PathBasedCacheDirective directive,\n+  public void modifyDirective(CacheDirectiveInfo directive,\n       FSPermissionChecker pc) throws IOException {\n     assert namesystem.hasWriteLock();\n     String idString \u003d\n         (directive.getId() \u003d\u003d null) ?\n             \"(null)\" : directive.getId().toString();\n     try {\n       // Check for invalid IDs.\n       Long id \u003d directive.getId();\n       if (id \u003d\u003d null) {\n         throw new InvalidRequestException(\"Must supply an ID.\");\n       }\n-      PathBasedCacheEntry prevEntry \u003d getById(id);\n+      CacheDirective prevEntry \u003d getById(id);\n       checkWritePermission(pc, prevEntry.getPool());\n       String path \u003d prevEntry.getPath();\n       if (directive.getPath() !\u003d null) {\n         path \u003d validatePath(directive);\n       }\n       short replication \u003d prevEntry.getReplication();\n       if (directive.getReplication() !\u003d null) {\n         replication \u003d validateReplication(directive, replication);\n       }\n       CachePool pool \u003d prevEntry.getPool();\n       if (directive.getPool() !\u003d null) {\n         pool \u003d getCachePool(validatePoolName(directive));\n         checkWritePermission(pc, pool);\n       }\n       removeInternal(prevEntry);\n-      PathBasedCacheEntry newEntry \u003d\n-          new PathBasedCacheEntry(id, path, replication, pool);\n+      CacheDirective newEntry \u003d\n+          new CacheDirective(id, path, replication, pool);\n       addInternal(newEntry);\n     } catch (IOException e) {\n       LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n       throw e;\n     }\n     LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n         directive + \".\");\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void modifyDirective(CacheDirectiveInfo directive,\n      FSPermissionChecker pc) throws IOException {\n    assert namesystem.hasWriteLock();\n    String idString \u003d\n        (directive.getId() \u003d\u003d null) ?\n            \"(null)\" : directive.getId().toString();\n    try {\n      // Check for invalid IDs.\n      Long id \u003d directive.getId();\n      if (id \u003d\u003d null) {\n        throw new InvalidRequestException(\"Must supply an ID.\");\n      }\n      CacheDirective prevEntry \u003d getById(id);\n      checkWritePermission(pc, prevEntry.getPool());\n      String path \u003d prevEntry.getPath();\n      if (directive.getPath() !\u003d null) {\n        path \u003d validatePath(directive);\n      }\n      short replication \u003d prevEntry.getReplication();\n      if (directive.getReplication() !\u003d null) {\n        replication \u003d validateReplication(directive, replication);\n      }\n      CachePool pool \u003d prevEntry.getPool();\n      if (directive.getPool() !\u003d null) {\n        pool \u003d getCachePool(validatePoolName(directive));\n        checkWritePermission(pc, pool);\n      }\n      removeInternal(prevEntry);\n      CacheDirective newEntry \u003d\n          new CacheDirective(id, path, replication, pool);\n      addInternal(newEntry);\n    } catch (IOException e) {\n      LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n      throw e;\n    }\n    LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n        directive + \".\");\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "[directive-PathBasedCacheDirective, pc-FSPermissionChecker]",
            "newValue": "[directive-CacheDirectiveInfo, pc-FSPermissionChecker]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5473. Consistent naming of user-visible caching classes and methods (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544252 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/11/13 9:12 AM",
          "commitName": "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "18/11/13 6:01 PM",
          "commitNameOld": "4f15d0af4f3633bfa35f7cb7c1cc15ef545597d0",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 2.63,
          "commitsBetweenForRepo": 32,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,38 @@\n-  public void modifyDirective(PathBasedCacheDirective directive,\n+  public void modifyDirective(CacheDirectiveInfo directive,\n       FSPermissionChecker pc) throws IOException {\n     assert namesystem.hasWriteLock();\n     String idString \u003d\n         (directive.getId() \u003d\u003d null) ?\n             \"(null)\" : directive.getId().toString();\n     try {\n       // Check for invalid IDs.\n       Long id \u003d directive.getId();\n       if (id \u003d\u003d null) {\n         throw new InvalidRequestException(\"Must supply an ID.\");\n       }\n-      PathBasedCacheEntry prevEntry \u003d getById(id);\n+      CacheDirective prevEntry \u003d getById(id);\n       checkWritePermission(pc, prevEntry.getPool());\n       String path \u003d prevEntry.getPath();\n       if (directive.getPath() !\u003d null) {\n         path \u003d validatePath(directive);\n       }\n       short replication \u003d prevEntry.getReplication();\n       if (directive.getReplication() !\u003d null) {\n         replication \u003d validateReplication(directive, replication);\n       }\n       CachePool pool \u003d prevEntry.getPool();\n       if (directive.getPool() !\u003d null) {\n         pool \u003d getCachePool(validatePoolName(directive));\n         checkWritePermission(pc, pool);\n       }\n       removeInternal(prevEntry);\n-      PathBasedCacheEntry newEntry \u003d\n-          new PathBasedCacheEntry(id, path, replication, pool);\n+      CacheDirective newEntry \u003d\n+          new CacheDirective(id, path, replication, pool);\n       addInternal(newEntry);\n     } catch (IOException e) {\n       LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n       throw e;\n     }\n     LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n         directive + \".\");\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void modifyDirective(CacheDirectiveInfo directive,\n      FSPermissionChecker pc) throws IOException {\n    assert namesystem.hasWriteLock();\n    String idString \u003d\n        (directive.getId() \u003d\u003d null) ?\n            \"(null)\" : directive.getId().toString();\n    try {\n      // Check for invalid IDs.\n      Long id \u003d directive.getId();\n      if (id \u003d\u003d null) {\n        throw new InvalidRequestException(\"Must supply an ID.\");\n      }\n      CacheDirective prevEntry \u003d getById(id);\n      checkWritePermission(pc, prevEntry.getPool());\n      String path \u003d prevEntry.getPath();\n      if (directive.getPath() !\u003d null) {\n        path \u003d validatePath(directive);\n      }\n      short replication \u003d prevEntry.getReplication();\n      if (directive.getReplication() !\u003d null) {\n        replication \u003d validateReplication(directive, replication);\n      }\n      CachePool pool \u003d prevEntry.getPool();\n      if (directive.getPool() !\u003d null) {\n        pool \u003d getCachePool(validatePoolName(directive));\n        checkWritePermission(pc, pool);\n      }\n      removeInternal(prevEntry);\n      CacheDirective newEntry \u003d\n          new CacheDirective(id, path, replication, pool);\n      addInternal(newEntry);\n    } catch (IOException e) {\n      LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n      throw e;\n    }\n    LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n        directive + \".\");\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "ce35e0950cef9250ce2ceffb3b8bfcff533c6b92": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5471. CacheAdmin -listPools fails when user lacks permissions to view all pools (Andrew Wang via Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541323 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/11/13 3:52 PM",
      "commitName": "ce35e0950cef9250ce2ceffb3b8bfcff533c6b92",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "07/11/13 2:07 PM",
      "commitNameOld": "f79b3e6b17450e9d34c483046b7437b09dd72016",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 5.07,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,38 @@\n   public void modifyDirective(PathBasedCacheDirective directive,\n       FSPermissionChecker pc) throws IOException {\n     assert namesystem.hasWriteLock();\n     String idString \u003d\n         (directive.getId() \u003d\u003d null) ?\n             \"(null)\" : directive.getId().toString();\n     try {\n       // Check for invalid IDs.\n       Long id \u003d directive.getId();\n       if (id \u003d\u003d null) {\n-        throw new IdNotFoundException(\"modifyDirective: \" +\n-            \"no ID to modify was supplied.\");\n+        throw new InvalidRequestException(\"Must supply an ID.\");\n       }\n-      if (id \u003c\u003d 0) {\n-        throw new IdNotFoundException(\"modifyDirective \" + id +\n-            \": invalid non-positive directive ID.\");\n-      }\n-      // Find the entry.\n-      PathBasedCacheEntry prevEntry \u003d entriesById.get(id);\n-      if (prevEntry \u003d\u003d null) {\n-        throw new IdNotFoundException(\"modifyDirective \" + id +\n-            \": id not found.\");\n-      }\n-      if ((pc !\u003d null) \u0026\u0026\n-          (!pc.checkPermission(prevEntry.getPool(), FsAction.WRITE))) {\n-        throw new AccessControlException(\"modifyDirective \" + id +\n-            \": permission denied for initial pool \" + prevEntry.getPool());\n-      }\n+      PathBasedCacheEntry prevEntry \u003d getById(id);\n+      checkWritePermission(pc, prevEntry.getPool());\n       String path \u003d prevEntry.getPath();\n       if (directive.getPath() !\u003d null) {\n-        path \u003d directive.getPath().toUri().getPath();\n-        if (!DFSUtil.isValidName(path)) {\n-          throw new IOException(\"modifyDirective \" + id + \": new path \" +\n-              path + \" is not valid.\");\n-        }\n+        path \u003d validatePath(directive);\n       }\n-      short replication \u003d (directive.getReplication() !\u003d null) ?\n-          directive.getReplication() : prevEntry.getReplication();\n-      if (replication \u003c\u003d 0) {\n-        throw new IOException(\"modifyDirective: replication \" + replication +\n-            \" is invalid.\");\n+      short replication \u003d prevEntry.getReplication();\n+      if (directive.getReplication() !\u003d null) {\n+        replication \u003d validateReplication(directive, replication);\n       }\n       CachePool pool \u003d prevEntry.getPool();\n       if (directive.getPool() !\u003d null) {\n-        pool \u003d cachePools.get(directive.getPool());\n-        if (pool \u003d\u003d null) {\n-          throw new IdNotFoundException(\"modifyDirective \" + id +\n-              \": pool \" + directive.getPool() + \" not found.\");\n-        }\n-        if (directive.getPool().isEmpty()) {\n-          throw new IdNotFoundException(\"modifyDirective: pool name was \" +\n-              \"empty.\");\n-        }\n-        if ((pc !\u003d null) \u0026\u0026\n-            (!pc.checkPermission(pool, FsAction.WRITE))) {\n-          throw new AccessControlException(\"modifyDirective \" + id +\n-              \": permission denied for target pool \" + pool);\n-        }\n+        pool \u003d getCachePool(validatePoolName(directive));\n+        checkWritePermission(pc, pool);\n       }\n       removeInternal(prevEntry);\n       PathBasedCacheEntry newEntry \u003d\n           new PathBasedCacheEntry(id, path, replication, pool);\n       addInternal(newEntry);\n     } catch (IOException e) {\n-      LOG.warn(\"modifyDirective \" + idString + \": failed.\", e);\n+      LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n       throw e;\n     }\n-    LOG.info(\"modifyDirective \" + idString + \": successfully applied \" +\n-        directive);\n+    LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n+        directive + \".\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void modifyDirective(PathBasedCacheDirective directive,\n      FSPermissionChecker pc) throws IOException {\n    assert namesystem.hasWriteLock();\n    String idString \u003d\n        (directive.getId() \u003d\u003d null) ?\n            \"(null)\" : directive.getId().toString();\n    try {\n      // Check for invalid IDs.\n      Long id \u003d directive.getId();\n      if (id \u003d\u003d null) {\n        throw new InvalidRequestException(\"Must supply an ID.\");\n      }\n      PathBasedCacheEntry prevEntry \u003d getById(id);\n      checkWritePermission(pc, prevEntry.getPool());\n      String path \u003d prevEntry.getPath();\n      if (directive.getPath() !\u003d null) {\n        path \u003d validatePath(directive);\n      }\n      short replication \u003d prevEntry.getReplication();\n      if (directive.getReplication() !\u003d null) {\n        replication \u003d validateReplication(directive, replication);\n      }\n      CachePool pool \u003d prevEntry.getPool();\n      if (directive.getPool() !\u003d null) {\n        pool \u003d getCachePool(validatePoolName(directive));\n        checkWritePermission(pc, pool);\n      }\n      removeInternal(prevEntry);\n      PathBasedCacheEntry newEntry \u003d\n          new PathBasedCacheEntry(id, path, replication, pool);\n      addInternal(newEntry);\n    } catch (IOException e) {\n      LOG.warn(\"modifyDirective of \" + idString + \" failed: \", e);\n      throw e;\n    }\n    LOG.info(\"modifyDirective of \" + idString + \" successfully applied \" +\n        directive + \".\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "f79b3e6b17450e9d34c483046b7437b09dd72016": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5326. add modifyDirective to cacheAdmin (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1539839 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/11/13 2:07 PM",
      "commitName": "f79b3e6b17450e9d34c483046b7437b09dd72016",
      "commitAuthor": "Colin McCabe",
      "diff": "@@ -0,0 +1,70 @@\n+  public void modifyDirective(PathBasedCacheDirective directive,\n+      FSPermissionChecker pc) throws IOException {\n+    assert namesystem.hasWriteLock();\n+    String idString \u003d\n+        (directive.getId() \u003d\u003d null) ?\n+            \"(null)\" : directive.getId().toString();\n+    try {\n+      // Check for invalid IDs.\n+      Long id \u003d directive.getId();\n+      if (id \u003d\u003d null) {\n+        throw new IdNotFoundException(\"modifyDirective: \" +\n+            \"no ID to modify was supplied.\");\n+      }\n+      if (id \u003c\u003d 0) {\n+        throw new IdNotFoundException(\"modifyDirective \" + id +\n+            \": invalid non-positive directive ID.\");\n+      }\n+      // Find the entry.\n+      PathBasedCacheEntry prevEntry \u003d entriesById.get(id);\n+      if (prevEntry \u003d\u003d null) {\n+        throw new IdNotFoundException(\"modifyDirective \" + id +\n+            \": id not found.\");\n+      }\n+      if ((pc !\u003d null) \u0026\u0026\n+          (!pc.checkPermission(prevEntry.getPool(), FsAction.WRITE))) {\n+        throw new AccessControlException(\"modifyDirective \" + id +\n+            \": permission denied for initial pool \" + prevEntry.getPool());\n+      }\n+      String path \u003d prevEntry.getPath();\n+      if (directive.getPath() !\u003d null) {\n+        path \u003d directive.getPath().toUri().getPath();\n+        if (!DFSUtil.isValidName(path)) {\n+          throw new IOException(\"modifyDirective \" + id + \": new path \" +\n+              path + \" is not valid.\");\n+        }\n+      }\n+      short replication \u003d (directive.getReplication() !\u003d null) ?\n+          directive.getReplication() : prevEntry.getReplication();\n+      if (replication \u003c\u003d 0) {\n+        throw new IOException(\"modifyDirective: replication \" + replication +\n+            \" is invalid.\");\n+      }\n+      CachePool pool \u003d prevEntry.getPool();\n+      if (directive.getPool() !\u003d null) {\n+        pool \u003d cachePools.get(directive.getPool());\n+        if (pool \u003d\u003d null) {\n+          throw new IdNotFoundException(\"modifyDirective \" + id +\n+              \": pool \" + directive.getPool() + \" not found.\");\n+        }\n+        if (directive.getPool().isEmpty()) {\n+          throw new IdNotFoundException(\"modifyDirective: pool name was \" +\n+              \"empty.\");\n+        }\n+        if ((pc !\u003d null) \u0026\u0026\n+            (!pc.checkPermission(pool, FsAction.WRITE))) {\n+          throw new AccessControlException(\"modifyDirective \" + id +\n+              \": permission denied for target pool \" + pool);\n+        }\n+      }\n+      removeInternal(prevEntry);\n+      PathBasedCacheEntry newEntry \u003d\n+          new PathBasedCacheEntry(id, path, replication, pool);\n+      addInternal(newEntry);\n+    } catch (IOException e) {\n+      LOG.warn(\"modifyDirective \" + idString + \": failed.\", e);\n+      throw e;\n+    }\n+    LOG.info(\"modifyDirective \" + idString + \": successfully applied \" +\n+        directive);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void modifyDirective(PathBasedCacheDirective directive,\n      FSPermissionChecker pc) throws IOException {\n    assert namesystem.hasWriteLock();\n    String idString \u003d\n        (directive.getId() \u003d\u003d null) ?\n            \"(null)\" : directive.getId().toString();\n    try {\n      // Check for invalid IDs.\n      Long id \u003d directive.getId();\n      if (id \u003d\u003d null) {\n        throw new IdNotFoundException(\"modifyDirective: \" +\n            \"no ID to modify was supplied.\");\n      }\n      if (id \u003c\u003d 0) {\n        throw new IdNotFoundException(\"modifyDirective \" + id +\n            \": invalid non-positive directive ID.\");\n      }\n      // Find the entry.\n      PathBasedCacheEntry prevEntry \u003d entriesById.get(id);\n      if (prevEntry \u003d\u003d null) {\n        throw new IdNotFoundException(\"modifyDirective \" + id +\n            \": id not found.\");\n      }\n      if ((pc !\u003d null) \u0026\u0026\n          (!pc.checkPermission(prevEntry.getPool(), FsAction.WRITE))) {\n        throw new AccessControlException(\"modifyDirective \" + id +\n            \": permission denied for initial pool \" + prevEntry.getPool());\n      }\n      String path \u003d prevEntry.getPath();\n      if (directive.getPath() !\u003d null) {\n        path \u003d directive.getPath().toUri().getPath();\n        if (!DFSUtil.isValidName(path)) {\n          throw new IOException(\"modifyDirective \" + id + \": new path \" +\n              path + \" is not valid.\");\n        }\n      }\n      short replication \u003d (directive.getReplication() !\u003d null) ?\n          directive.getReplication() : prevEntry.getReplication();\n      if (replication \u003c\u003d 0) {\n        throw new IOException(\"modifyDirective: replication \" + replication +\n            \" is invalid.\");\n      }\n      CachePool pool \u003d prevEntry.getPool();\n      if (directive.getPool() !\u003d null) {\n        pool \u003d cachePools.get(directive.getPool());\n        if (pool \u003d\u003d null) {\n          throw new IdNotFoundException(\"modifyDirective \" + id +\n              \": pool \" + directive.getPool() + \" not found.\");\n        }\n        if (directive.getPool().isEmpty()) {\n          throw new IdNotFoundException(\"modifyDirective: pool name was \" +\n              \"empty.\");\n        }\n        if ((pc !\u003d null) \u0026\u0026\n            (!pc.checkPermission(pool, FsAction.WRITE))) {\n          throw new AccessControlException(\"modifyDirective \" + id +\n              \": permission denied for target pool \" + pool);\n        }\n      }\n      removeInternal(prevEntry);\n      PathBasedCacheEntry newEntry \u003d\n          new PathBasedCacheEntry(id, path, replication, pool);\n      addInternal(newEntry);\n    } catch (IOException e) {\n      LOG.warn(\"modifyDirective \" + idString + \": failed.\", e);\n      throw e;\n    }\n    LOG.info(\"modifyDirective \" + idString + \": successfully applied \" +\n        directive);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java"
    }
  }
}