{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "StreamBaseRecordReader.java",
  "functionName": "getStatus",
  "functionId": "getStatus___record-CharSequence",
  "sourceFilePath": "hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/mapreduce/StreamBaseRecordReader.java",
  "functionStartLine": 120,
  "functionEndLine": 138,
  "numCommitsSeen": 2,
  "timeTaken": 570,
  "changeHistory": [
    "9c87911c4ab35faead3e4729951b2855fb20e3b0"
  ],
  "changeHistoryShort": {
    "9c87911c4ab35faead3e4729951b2855fb20e3b0": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9c87911c4ab35faead3e4729951b2855fb20e3b0": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-8521. Port StreamInputFormat to new Map Reduce API (madhukara phatak via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1360238 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/07/12 8:44 AM",
      "commitName": "9c87911c4ab35faead3e4729951b2855fb20e3b0",
      "commitAuthor": "Robert Joseph Evans",
      "diff": "@@ -0,0 +1,19 @@\n+  String getStatus(CharSequence record) {\n+    long pos \u003d -1;\n+    try {\n+      pos \u003d getPos();\n+    } catch (IOException io) {\n+    }\n+    String recStr;\n+    if (record.length() \u003e statusMaxRecordChars_) {\n+      recStr \u003d record.subSequence(0, statusMaxRecordChars_) + \"...\";\n+    } else {\n+      recStr \u003d record.toString();\n+    }\n+    String unqualSplit \u003d split_.getPath().getName() + \":\" + split_.getStart()\n+        + \"+\" + split_.getLength();\n+    String status \u003d \"HSTR \" + StreamUtil.getHost() + \" \" + numRec_ + \". pos\u003d\"\n+        + pos + \" \" + unqualSplit + \" Processing record\u003d\" + recStr;\n+    status +\u003d \" \" + splitName_;\n+    return status;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  String getStatus(CharSequence record) {\n    long pos \u003d -1;\n    try {\n      pos \u003d getPos();\n    } catch (IOException io) {\n    }\n    String recStr;\n    if (record.length() \u003e statusMaxRecordChars_) {\n      recStr \u003d record.subSequence(0, statusMaxRecordChars_) + \"...\";\n    } else {\n      recStr \u003d record.toString();\n    }\n    String unqualSplit \u003d split_.getPath().getName() + \":\" + split_.getStart()\n        + \"+\" + split_.getLength();\n    String status \u003d \"HSTR \" + StreamUtil.getHost() + \" \" + numRec_ + \". pos\u003d\"\n        + pos + \" \" + unqualSplit + \" Processing record\u003d\" + recStr;\n    status +\u003d \" \" + splitName_;\n    return status;\n  }",
      "path": "hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/mapreduce/StreamBaseRecordReader.java"
    }
  }
}