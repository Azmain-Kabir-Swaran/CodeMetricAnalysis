{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ErasureCodingWork.java",
  "functionName": "createReplicationWork",
  "functionId": "createReplicationWork___sourceIndex-int__target-DatanodeStorageInfo",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ErasureCodingWork.java",
  "functionStartLine": 154,
  "functionEndLine": 168,
  "numCommitsSeen": 13,
  "timeTaken": 1199,
  "changeHistory": [
    "96f7dc1992246a16031f613e55dc39ea0d64acd1",
    "743a99f2dbc9a27e19f92ff3551937d90dba2e89"
  ],
  "changeHistoryShort": {
    "96f7dc1992246a16031f613e55dc39ea0d64acd1": "Ybodychange",
    "743a99f2dbc9a27e19f92ff3551937d90dba2e89": "Yintroduced"
  },
  "changeHistoryDetails": {
    "96f7dc1992246a16031f613e55dc39ea0d64acd1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14796. Define LOG instead of BlockManager.LOG in ErasureCodingWork/ReplicationWork. Contributed by Fei Hui.\n",
      "commitDate": "30/08/19 2:01 AM",
      "commitName": "96f7dc1992246a16031f613e55dc39ea0d64acd1",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "12/02/18 7:17 AM",
      "commitNameOld": "96bb6a51ec4a470e9b287c94e377444a9f97c410",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 563.74,
      "commitsBetweenForRepo": 4924,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,15 @@\n   private void createReplicationWork(int sourceIndex,\n       DatanodeStorageInfo target) {\n     BlockInfoStriped stripedBlk \u003d (BlockInfoStriped) getBlock();\n     final byte blockIndex \u003d liveBlockIndicies[sourceIndex];\n     final DatanodeDescriptor source \u003d getSrcNodes()[sourceIndex];\n     final long internBlkLen \u003d StripedBlockUtil.getInternalBlockLength(\n         stripedBlk.getNumBytes(), stripedBlk.getCellSize(),\n         stripedBlk.getDataBlockNum(), blockIndex);\n     final Block targetBlk \u003d new Block(stripedBlk.getBlockId() + blockIndex,\n         internBlkLen, stripedBlk.getGenerationStamp());\n     source.addBlockToBeReplicated(targetBlk,\n         new DatanodeStorageInfo[] {target});\n-    if (BlockManager.LOG.isDebugEnabled()) {\n-      BlockManager.LOG.debug(\"Add replication task from source {} to \"\n-          + \"target {} for EC block {}\", source, target, targetBlk);\n-    }\n+    LOG.debug(\"Add replication task from source {} to \"\n+        + \"target {} for EC block {}\", source, target, targetBlk);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void createReplicationWork(int sourceIndex,\n      DatanodeStorageInfo target) {\n    BlockInfoStriped stripedBlk \u003d (BlockInfoStriped) getBlock();\n    final byte blockIndex \u003d liveBlockIndicies[sourceIndex];\n    final DatanodeDescriptor source \u003d getSrcNodes()[sourceIndex];\n    final long internBlkLen \u003d StripedBlockUtil.getInternalBlockLength(\n        stripedBlk.getNumBytes(), stripedBlk.getCellSize(),\n        stripedBlk.getDataBlockNum(), blockIndex);\n    final Block targetBlk \u003d new Block(stripedBlk.getBlockId() + blockIndex,\n        internBlkLen, stripedBlk.getGenerationStamp());\n    source.addBlockToBeReplicated(targetBlk,\n        new DatanodeStorageInfo[] {target});\n    LOG.debug(\"Add replication task from source {} to \"\n        + \"target {} for EC block {}\", source, target, targetBlk);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ErasureCodingWork.java",
      "extendedDetails": {}
    },
    "743a99f2dbc9a27e19f92ff3551937d90dba2e89": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-8786. Erasure coding: use simple replication for internal blocks on decommissioning datanodes. Contributed by Rakesh R.\n",
      "commitDate": "08/03/16 10:24 AM",
      "commitName": "743a99f2dbc9a27e19f92ff3551937d90dba2e89",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,17 @@\n+  private void createReplicationWork(int sourceIndex,\n+      DatanodeStorageInfo target) {\n+    BlockInfoStriped stripedBlk \u003d (BlockInfoStriped) getBlock();\n+    final byte blockIndex \u003d liveBlockIndicies[sourceIndex];\n+    final DatanodeDescriptor source \u003d getSrcNodes()[sourceIndex];\n+    final long internBlkLen \u003d StripedBlockUtil.getInternalBlockLength(\n+        stripedBlk.getNumBytes(), stripedBlk.getCellSize(),\n+        stripedBlk.getDataBlockNum(), blockIndex);\n+    final Block targetBlk \u003d new Block(stripedBlk.getBlockId() + blockIndex,\n+        internBlkLen, stripedBlk.getGenerationStamp());\n+    source.addBlockToBeReplicated(targetBlk,\n+        new DatanodeStorageInfo[] {target});\n+    if (BlockManager.LOG.isDebugEnabled()) {\n+      BlockManager.LOG.debug(\"Add replication task from source {} to \"\n+          + \"target {} for EC block {}\", source, target, targetBlk);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void createReplicationWork(int sourceIndex,\n      DatanodeStorageInfo target) {\n    BlockInfoStriped stripedBlk \u003d (BlockInfoStriped) getBlock();\n    final byte blockIndex \u003d liveBlockIndicies[sourceIndex];\n    final DatanodeDescriptor source \u003d getSrcNodes()[sourceIndex];\n    final long internBlkLen \u003d StripedBlockUtil.getInternalBlockLength(\n        stripedBlk.getNumBytes(), stripedBlk.getCellSize(),\n        stripedBlk.getDataBlockNum(), blockIndex);\n    final Block targetBlk \u003d new Block(stripedBlk.getBlockId() + blockIndex,\n        internBlkLen, stripedBlk.getGenerationStamp());\n    source.addBlockToBeReplicated(targetBlk,\n        new DatanodeStorageInfo[] {target});\n    if (BlockManager.LOG.isDebugEnabled()) {\n      BlockManager.LOG.debug(\"Add replication task from source {} to \"\n          + \"target {} for EC block {}\", source, target, targetBlk);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ErasureCodingWork.java"
    }
  }
}