{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HHXORErasureDecodingStep.java",
  "functionName": "doDecodeByPiggyBack",
  "functionId": "doDecodeByPiggyBack___inputs-ByteBuffer[]__outputs-ByteBuffer__piggyBack-ByteBuffer__erasedLocationToFix-int",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/coder/HHXORErasureDecodingStep.java",
  "functionStartLine": 224,
  "functionEndLine": 244,
  "numCommitsSeen": 3,
  "timeTaken": 601,
  "changeHistory": [
    "1bb31fb22e6f8e6df8e9ff4e94adf20308b4c743"
  ],
  "changeHistoryShort": {
    "1bb31fb22e6f8e6df8e9ff4e94adf20308b4c743": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1bb31fb22e6f8e6df8e9ff4e94adf20308b4c743": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-11828. Implement the Hitchhiker erasure coding algorithm. Contributed by Jack Liu Quan.\n\nChange-Id: If43475ccc2574df60949c947af562722db076251\n",
      "commitDate": "21/01/16 10:30 AM",
      "commitName": "1bb31fb22e6f8e6df8e9ff4e94adf20308b4c743",
      "commitAuthor": "Zhe Zhang",
      "diff": "@@ -0,0 +1,21 @@\n+  private void doDecodeByPiggyBack(ByteBuffer[] inputs,\n+                                   ByteBuffer outputs,\n+                                   ByteBuffer piggyBack,\n+                                   int erasedLocationToFix) {\n+    final int thisPiggyBackSetIdx \u003d piggyBackFullIndex[erasedLocationToFix];\n+    final int startIndex \u003d piggyBackIndex[thisPiggyBackSetIdx - 1];\n+    final int endIndex \u003d piggyBackIndex[thisPiggyBackSetIdx];\n+\n+    // recover first sub-stripe data by XOR piggyback\n+    int bufSize \u003d piggyBack.remaining();\n+    for (int i \u003d piggyBack.position();\n+         i \u003c piggyBack.position() + bufSize; i++) {\n+      for (int j \u003d startIndex; j \u003c endIndex; j++) {\n+        if (inputs[j] !\u003d null) {\n+          piggyBack.put(i, (byte)\n+                  (piggyBack.get(i) ^ inputs[j].get(inputs[j].position() + i)));\n+        }\n+      }\n+      outputs.put(outputs.position() + i, piggyBack.get(i));\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void doDecodeByPiggyBack(ByteBuffer[] inputs,\n                                   ByteBuffer outputs,\n                                   ByteBuffer piggyBack,\n                                   int erasedLocationToFix) {\n    final int thisPiggyBackSetIdx \u003d piggyBackFullIndex[erasedLocationToFix];\n    final int startIndex \u003d piggyBackIndex[thisPiggyBackSetIdx - 1];\n    final int endIndex \u003d piggyBackIndex[thisPiggyBackSetIdx];\n\n    // recover first sub-stripe data by XOR piggyback\n    int bufSize \u003d piggyBack.remaining();\n    for (int i \u003d piggyBack.position();\n         i \u003c piggyBack.position() + bufSize; i++) {\n      for (int j \u003d startIndex; j \u003c endIndex; j++) {\n        if (inputs[j] !\u003d null) {\n          piggyBack.put(i, (byte)\n                  (piggyBack.get(i) ^ inputs[j].get(inputs[j].position() + i)));\n        }\n      }\n      outputs.put(outputs.position() + i, piggyBack.get(i));\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/coder/HHXORErasureDecodingStep.java"
    }
  }
}