{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LogCLIHelpers.java",
  "functionName": "dumpAllContainersLogs",
  "functionId": "dumpAllContainersLogs___options-ContainerLogsRequest",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
  "functionStartLine": 233,
  "functionEndLine": 254,
  "numCommitsSeen": 68,
  "timeTaken": 13056,
  "changeHistory": [
    "460ba7fb14114f44e14a660f533f32c54e504478",
    "63231a2a3008794c5ebcbc9d3855638fc5f28216",
    "91cc070d67533ebb3325b982eba2135e0d175a82",
    "871dc420f8a4f151189c0925e062c64859a8f275",
    "8528d85a68c0e6ea71026df4d3026e7edc206b2d",
    "e605d47df05619c6b1c18aca59f709899498da75",
    "eb471632349deac4b62f8dec853c8ceb64c9617a",
    "0bc05e40fa7e183efe8463ada459c621da3ce3bf",
    "bde819abbbcea940cfa6426a9e4920e6c8dc9cf1",
    "ef1757790d89cc72f88f5330761b1c8901c59e94",
    "9e37fe3b7a3b5f0a193d228bb5e065f41acd2835",
    "6dd6ca442aba8612c3780399a42bb473e4483021",
    "58e9f24e0f06efede21085b7ffe36af042fa7b38",
    "e90718fa5a0e7c18592af61534668acebb9db51b",
    "64ec743e6c5384a7b68e4f9852ed12e261643c1f",
    "6ff600d9e3496008d81361c17ea427a8675cd0d4",
    "67699c2d187a8480a46acf5031652ff19196823d",
    "e1fdf62123625e4ba399af02f8aad500637d29d1",
    "6ba0375b21c4ce07d2b6b592c4963f705c35222b",
    "c27601fefebd0af887a12d684bfc6f90d9fc0321",
    "47a381e306877750b5a3ce5d76e0a5ff652ec188",
    "670fa24b48acb407c22fbfdde87ae3123dcbf449",
    "fafe8cd28e726566509c679e19d7da622f29f90d",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "460ba7fb14114f44e14a660f533f32c54e504478": "Ybodychange",
    "63231a2a3008794c5ebcbc9d3855638fc5f28216": "Ybodychange",
    "91cc070d67533ebb3325b982eba2135e0d175a82": "Ybodychange",
    "871dc420f8a4f151189c0925e062c64859a8f275": "Ybodychange",
    "8528d85a68c0e6ea71026df4d3026e7edc206b2d": "Ybodychange",
    "e605d47df05619c6b1c18aca59f709899498da75": "Ybodychange",
    "eb471632349deac4b62f8dec853c8ceb64c9617a": "Ybodychange",
    "0bc05e40fa7e183efe8463ada459c621da3ce3bf": "Ybodychange",
    "bde819abbbcea940cfa6426a9e4920e6c8dc9cf1": "Ymultichange(Yparameterchange,Ybodychange)",
    "ef1757790d89cc72f88f5330761b1c8901c59e94": "Ymultichange(Yparameterchange,Ybodychange)",
    "9e37fe3b7a3b5f0a193d228bb5e065f41acd2835": "Ybodychange",
    "6dd6ca442aba8612c3780399a42bb473e4483021": "Ybodychange",
    "58e9f24e0f06efede21085b7ffe36af042fa7b38": "Ybodychange",
    "e90718fa5a0e7c18592af61534668acebb9db51b": "Ybodychange",
    "64ec743e6c5384a7b68e4f9852ed12e261643c1f": "Ybodychange",
    "6ff600d9e3496008d81361c17ea427a8675cd0d4": "Ymultichange(Ymovefromfile,Ymodifierchange)",
    "67699c2d187a8480a46acf5031652ff19196823d": "Ymultichange(Yparameterchange,Ybodychange)",
    "e1fdf62123625e4ba399af02f8aad500637d29d1": "Yfilerename",
    "6ba0375b21c4ce07d2b6b592c4963f705c35222b": "Ymultichange(Yreturntypechange,Ybodychange)",
    "c27601fefebd0af887a12d684bfc6f90d9fc0321": "Ymultichange(Yfilerename,Ybodychange)",
    "47a381e306877750b5a3ce5d76e0a5ff652ec188": "Ymultichange(Yparameterchange,Ybodychange)",
    "670fa24b48acb407c22fbfdde87ae3123dcbf449": "Ybodychange",
    "fafe8cd28e726566509c679e19d7da622f29f90d": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "460ba7fb14114f44e14a660f533f32c54e504478": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9558.  Fixed LogAggregation test cases.\n            Contributed by Prabhu Joseph\n",
      "commitDate": "23/05/19 3:38 PM",
      "commitName": "460ba7fb14114f44e14a660f533f32c54e504478",
      "commitAuthor": "Eric Yang",
      "commitDateOld": "06/05/19 4:48 PM",
      "commitNameOld": "49e1292ea3e4d00ab0b0191bd8c4ea4d2afed671",
      "commitAuthorOld": "Eric Yang",
      "daysBetweenCommits": 16.95,
      "commitsBetweenForRepo": 93,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,22 @@\n   public int dumpAllContainersLogs(ContainerLogsRequest options)\n       throws IOException {\n     LogAggregationFileController fc \u003d null;\n     try {\n       fc \u003d this.getFileController(\n           options.getAppId(), options.getAppOwner());\n     } catch (IOException ex) {\n       System.err.println(ex);\n     }\n     boolean foundAnyLogs \u003d false;\n     if (fc !\u003d null) {\n       foundAnyLogs \u003d fc.readAggregatedLogs(options, null);\n     }\n     if (!foundAnyLogs) {\n       emptyLogDir(LogAggregationUtils.getRemoteAppLogDir(\n-          conf, options.getAppId(), options.getAppOwner())\n+          conf, options.getAppId(), options.getAppOwner(),\n+          fc.getRemoteRootLogDir(), fc.getRemoteRootLogDirSuffix())\n           .toString());\n       return -1;\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAllContainersLogs(ContainerLogsRequest options)\n      throws IOException {\n    LogAggregationFileController fc \u003d null;\n    try {\n      fc \u003d this.getFileController(\n          options.getAppId(), options.getAppOwner());\n    } catch (IOException ex) {\n      System.err.println(ex);\n    }\n    boolean foundAnyLogs \u003d false;\n    if (fc !\u003d null) {\n      foundAnyLogs \u003d fc.readAggregatedLogs(options, null);\n    }\n    if (!foundAnyLogs) {\n      emptyLogDir(LogAggregationUtils.getRemoteAppLogDir(\n          conf, options.getAppId(), options.getAppOwner(),\n          fc.getRemoteRootLogDir(), fc.getRemoteRootLogDirSuffix())\n          .toString());\n      return -1;\n    }\n    return 0;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "63231a2a3008794c5ebcbc9d3855638fc5f28216": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7148. TestLogsCLI fails in trunk and branch-2 and javadoc error. Contributed by Xuan Gong.\n",
      "commitDate": "06/09/17 1:19 PM",
      "commitName": "63231a2a3008794c5ebcbc9d3855638fc5f28216",
      "commitAuthor": "Junping Du",
      "commitDateOld": "31/08/17 4:41 PM",
      "commitNameOld": "91cc070d67533ebb3325b982eba2135e0d175a82",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 5.86,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,21 @@\n   public int dumpAllContainersLogs(ContainerLogsRequest options)\n       throws IOException {\n-    boolean foundAnyLogs \u003d getFileController(options.getAppId(),\n-        options.getAppOwner()).readAggregatedLogs(\n-        options, null);\n+    LogAggregationFileController fc \u003d null;\n+    try {\n+      fc \u003d this.getFileController(\n+          options.getAppId(), options.getAppOwner());\n+    } catch (IOException ex) {\n+      System.err.println(ex);\n+    }\n+    boolean foundAnyLogs \u003d false;\n+    if (fc !\u003d null) {\n+      foundAnyLogs \u003d fc.readAggregatedLogs(options, null);\n+    }\n     if (!foundAnyLogs) {\n       emptyLogDir(LogAggregationUtils.getRemoteAppLogDir(\n           conf, options.getAppId(), options.getAppOwner())\n           .toString());\n       return -1;\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAllContainersLogs(ContainerLogsRequest options)\n      throws IOException {\n    LogAggregationFileController fc \u003d null;\n    try {\n      fc \u003d this.getFileController(\n          options.getAppId(), options.getAppOwner());\n    } catch (IOException ex) {\n      System.err.println(ex);\n    }\n    boolean foundAnyLogs \u003d false;\n    if (fc !\u003d null) {\n      foundAnyLogs \u003d fc.readAggregatedLogs(options, null);\n    }\n    if (!foundAnyLogs) {\n      emptyLogDir(LogAggregationUtils.getRemoteAppLogDir(\n          conf, options.getAppId(), options.getAppOwner())\n          .toString());\n      return -1;\n    }\n    return 0;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "91cc070d67533ebb3325b982eba2135e0d175a82": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6877. Create an abstract log reader for extendability. Contributed by Xuan Gong.\n",
      "commitDate": "31/08/17 4:41 PM",
      "commitName": "91cc070d67533ebb3325b982eba2135e0d175a82",
      "commitAuthor": "Junping Du",
      "commitDateOld": "14/03/17 12:58 PM",
      "commitNameOld": "871dc420f8a4f151189c0925e062c64859a8f275",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 170.16,
      "commitsBetweenForRepo": 1032,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,13 @@\n   public int dumpAllContainersLogs(ContainerLogsRequest options)\n       throws IOException {\n-    ApplicationId appId \u003d options.getAppId();\n-    String appOwner \u003d options.getAppOwner();\n-    String localDir \u003d options.getOutputLocalDir();\n-    List\u003cString\u003e logTypes \u003d new ArrayList\u003cString\u003e(options.getLogTypes());\n-    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n-        appId, appOwner);\n-    if (nodeFiles \u003d\u003d null) {\n-      return -1;\n-    }\n-    boolean foundAnyLogs \u003d false;\n-    while (nodeFiles.hasNext()) {\n-      FileStatus thisNodeFile \u003d nodeFiles.next();\n-      if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n-        Path p \u003d new Path(\"har:///\"\n-            + thisNodeFile.getPath().toUri().getRawPath());\n-        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n-        continue;\n-      }\n-      if (!thisNodeFile.getPath().getName()\n-          .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n-        AggregatedLogFormat.LogReader reader \u003d\n-            new AggregatedLogFormat.LogReader(getConf(),\n-                thisNodeFile.getPath());\n-        try {\n-\n-          DataInputStream valueStream;\n-          LogKey key \u003d new LogKey();\n-          valueStream \u003d reader.next(key);\n-\n-          while (valueStream !\u003d null) {\n-            PrintStream out \u003d createPrintStream(localDir,\n-                thisNodeFile.getPath().getName(), key.toString());\n-            try {\n-              String containerString \u003d String.format(\n-                  CONTAINER_ON_NODE_PATTERN, key,\n-                  thisNodeFile.getPath().getName());\n-              out.println(containerString);\n-              out.println(\"LogAggregationType: AGGREGATED\");\n-              out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n-              while (true) {\n-                try {\n-                  if (logTypes \u003d\u003d null || logTypes.isEmpty()) {\n-                    LogReader.readAContainerLogsForALogType(valueStream, out,\n-                        thisNodeFile.getModificationTime(),\n-                        options.getBytes());\n-                    foundAnyLogs \u003d true;\n-                  } else {\n-                    int result \u003d LogReader.readContainerLogsForALogType(\n-                        valueStream, out, thisNodeFile.getModificationTime(),\n-                        logTypes, options.getBytes());\n-                    if (result \u003d\u003d 0) {\n-                      foundAnyLogs \u003d true;\n-                    }\n-                  }\n-                } catch (EOFException eof) {\n-                  break;\n-                }\n-              }\n-            } finally {\n-              closePrintStream(out);\n-            }\n-\n-            // Next container\n-            key \u003d new LogKey();\n-            valueStream \u003d reader.next(key);\n-          }\n-        } finally {\n-          reader.close();\n-        }\n-      }\n-    }\n+    boolean foundAnyLogs \u003d getFileController(options.getAppId(),\n+        options.getAppOwner()).readAggregatedLogs(\n+        options, null);\n     if (!foundAnyLogs) {\n-      emptyLogDir(LogAggregationUtils.getRemoteAppLogDir(conf, appId, appOwner)\n+      emptyLogDir(LogAggregationUtils.getRemoteAppLogDir(\n+          conf, options.getAppId(), options.getAppOwner())\n           .toString());\n       return -1;\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAllContainersLogs(ContainerLogsRequest options)\n      throws IOException {\n    boolean foundAnyLogs \u003d getFileController(options.getAppId(),\n        options.getAppOwner()).readAggregatedLogs(\n        options, null);\n    if (!foundAnyLogs) {\n      emptyLogDir(LogAggregationUtils.getRemoteAppLogDir(\n          conf, options.getAppId(), options.getAppOwner())\n          .toString());\n      return -1;\n    }\n    return 0;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "871dc420f8a4f151189c0925e062c64859a8f275": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6313. YARN logs cli should provide logs for a completed container even when application is still running. Contributed by Xuan Gong.\n\n(cherry picked from commit b88f5e0f7858d1d89b79dfd325b767c34416052d)\n",
      "commitDate": "14/03/17 12:58 PM",
      "commitName": "871dc420f8a4f151189c0925e062c64859a8f275",
      "commitAuthor": "Junping Du",
      "commitDateOld": "24/01/17 3:26 PM",
      "commitNameOld": "8528d85a68c0e6ea71026df4d3026e7edc206b2d",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 48.86,
      "commitsBetweenForRepo": 264,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,79 +1,80 @@\n   public int dumpAllContainersLogs(ContainerLogsRequest options)\n       throws IOException {\n     ApplicationId appId \u003d options.getAppId();\n     String appOwner \u003d options.getAppOwner();\n     String localDir \u003d options.getOutputLocalDir();\n     List\u003cString\u003e logTypes \u003d new ArrayList\u003cString\u003e(options.getLogTypes());\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n         appId, appOwner);\n     if (nodeFiles \u003d\u003d null) {\n       return -1;\n     }\n     boolean foundAnyLogs \u003d false;\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n         Path p \u003d new Path(\"har:///\"\n             + thisNodeFile.getPath().toUri().getRawPath());\n         nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n         continue;\n       }\n       if (!thisNodeFile.getPath().getName()\n           .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n         AggregatedLogFormat.LogReader reader \u003d\n             new AggregatedLogFormat.LogReader(getConf(),\n                 thisNodeFile.getPath());\n         try {\n \n           DataInputStream valueStream;\n           LogKey key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n \n           while (valueStream !\u003d null) {\n             PrintStream out \u003d createPrintStream(localDir,\n                 thisNodeFile.getPath().getName(), key.toString());\n             try {\n               String containerString \u003d String.format(\n                   CONTAINER_ON_NODE_PATTERN, key,\n                   thisNodeFile.getPath().getName());\n               out.println(containerString);\n+              out.println(\"LogAggregationType: AGGREGATED\");\n               out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n               while (true) {\n                 try {\n                   if (logTypes \u003d\u003d null || logTypes.isEmpty()) {\n                     LogReader.readAContainerLogsForALogType(valueStream, out,\n                         thisNodeFile.getModificationTime(),\n                         options.getBytes());\n                     foundAnyLogs \u003d true;\n                   } else {\n                     int result \u003d LogReader.readContainerLogsForALogType(\n                         valueStream, out, thisNodeFile.getModificationTime(),\n                         logTypes, options.getBytes());\n                     if (result \u003d\u003d 0) {\n                       foundAnyLogs \u003d true;\n                     }\n                   }\n                 } catch (EOFException eof) {\n                   break;\n                 }\n               }\n             } finally {\n               closePrintStream(out);\n             }\n \n             // Next container\n             key \u003d new LogKey();\n             valueStream \u003d reader.next(key);\n           }\n         } finally {\n           reader.close();\n         }\n       }\n     }\n     if (!foundAnyLogs) {\n       emptyLogDir(LogAggregationUtils.getRemoteAppLogDir(conf, appId, appOwner)\n           .toString());\n       return -1;\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAllContainersLogs(ContainerLogsRequest options)\n      throws IOException {\n    ApplicationId appId \u003d options.getAppId();\n    String appOwner \u003d options.getAppOwner();\n    String localDir \u003d options.getOutputLocalDir();\n    List\u003cString\u003e logTypes \u003d new ArrayList\u003cString\u003e(options.getLogTypes());\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n        appId, appOwner);\n    if (nodeFiles \u003d\u003d null) {\n      return -1;\n    }\n    boolean foundAnyLogs \u003d false;\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n        Path p \u003d new Path(\"har:///\"\n            + thisNodeFile.getPath().toUri().getRawPath());\n        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n        continue;\n      }\n      if (!thisNodeFile.getPath().getName()\n          .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d\n            new AggregatedLogFormat.LogReader(getConf(),\n                thisNodeFile.getPath());\n        try {\n\n          DataInputStream valueStream;\n          LogKey key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n\n          while (valueStream !\u003d null) {\n            PrintStream out \u003d createPrintStream(localDir,\n                thisNodeFile.getPath().getName(), key.toString());\n            try {\n              String containerString \u003d String.format(\n                  CONTAINER_ON_NODE_PATTERN, key,\n                  thisNodeFile.getPath().getName());\n              out.println(containerString);\n              out.println(\"LogAggregationType: AGGREGATED\");\n              out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n              while (true) {\n                try {\n                  if (logTypes \u003d\u003d null || logTypes.isEmpty()) {\n                    LogReader.readAContainerLogsForALogType(valueStream, out,\n                        thisNodeFile.getModificationTime(),\n                        options.getBytes());\n                    foundAnyLogs \u003d true;\n                  } else {\n                    int result \u003d LogReader.readContainerLogsForALogType(\n                        valueStream, out, thisNodeFile.getModificationTime(),\n                        logTypes, options.getBytes());\n                    if (result \u003d\u003d 0) {\n                      foundAnyLogs \u003d true;\n                    }\n                  }\n                } catch (EOFException eof) {\n                  break;\n                }\n              }\n            } finally {\n              closePrintStream(out);\n            }\n\n            // Next container\n            key \u003d new LogKey();\n            valueStream \u003d reader.next(key);\n          }\n        } finally {\n          reader.close();\n        }\n      }\n    }\n    if (!foundAnyLogs) {\n      emptyLogDir(LogAggregationUtils.getRemoteAppLogDir(conf, appId, appOwner)\n          .toString());\n      return -1;\n    }\n    return 0;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "8528d85a68c0e6ea71026df4d3026e7edc206b2d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6099. Improve webservice to list aggregated log files. Contributed by Xuan Gong.\n",
      "commitDate": "24/01/17 3:26 PM",
      "commitName": "8528d85a68c0e6ea71026df4d3026e7edc206b2d",
      "commitAuthor": "Junping Du",
      "commitDateOld": "25/10/16 12:15 PM",
      "commitNameOld": "c88c1dc50c0ec4521bc93f39726248026e68063a",
      "commitAuthorOld": "Xiao Chen",
      "daysBetweenCommits": 91.17,
      "commitsBetweenForRepo": 591,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,79 @@\n   public int dumpAllContainersLogs(ContainerLogsRequest options)\n       throws IOException {\n     ApplicationId appId \u003d options.getAppId();\n     String appOwner \u003d options.getAppOwner();\n     String localDir \u003d options.getOutputLocalDir();\n     List\u003cString\u003e logTypes \u003d new ArrayList\u003cString\u003e(options.getLogTypes());\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n         appId, appOwner);\n     if (nodeFiles \u003d\u003d null) {\n       return -1;\n     }\n     boolean foundAnyLogs \u003d false;\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n         Path p \u003d new Path(\"har:///\"\n             + thisNodeFile.getPath().toUri().getRawPath());\n         nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n         continue;\n       }\n       if (!thisNodeFile.getPath().getName()\n           .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n         AggregatedLogFormat.LogReader reader \u003d\n             new AggregatedLogFormat.LogReader(getConf(),\n                 thisNodeFile.getPath());\n         try {\n \n           DataInputStream valueStream;\n           LogKey key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n \n           while (valueStream !\u003d null) {\n             PrintStream out \u003d createPrintStream(localDir,\n                 thisNodeFile.getPath().getName(), key.toString());\n             try {\n               String containerString \u003d String.format(\n                   CONTAINER_ON_NODE_PATTERN, key,\n                   thisNodeFile.getPath().getName());\n               out.println(containerString);\n               out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n               while (true) {\n                 try {\n                   if (logTypes \u003d\u003d null || logTypes.isEmpty()) {\n                     LogReader.readAContainerLogsForALogType(valueStream, out,\n                         thisNodeFile.getModificationTime(),\n                         options.getBytes());\n                     foundAnyLogs \u003d true;\n                   } else {\n                     int result \u003d LogReader.readContainerLogsForALogType(\n                         valueStream, out, thisNodeFile.getModificationTime(),\n                         logTypes, options.getBytes());\n                     if (result \u003d\u003d 0) {\n                       foundAnyLogs \u003d true;\n                     }\n                   }\n                 } catch (EOFException eof) {\n                   break;\n                 }\n               }\n             } finally {\n               closePrintStream(out);\n             }\n \n             // Next container\n             key \u003d new LogKey();\n             valueStream \u003d reader.next(key);\n           }\n         } finally {\n           reader.close();\n         }\n       }\n     }\n     if (!foundAnyLogs) {\n-      emptyLogDir(getRemoteAppLogDir(appId, appOwner).toString());\n+      emptyLogDir(LogAggregationUtils.getRemoteAppLogDir(conf, appId, appOwner)\n+          .toString());\n       return -1;\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAllContainersLogs(ContainerLogsRequest options)\n      throws IOException {\n    ApplicationId appId \u003d options.getAppId();\n    String appOwner \u003d options.getAppOwner();\n    String localDir \u003d options.getOutputLocalDir();\n    List\u003cString\u003e logTypes \u003d new ArrayList\u003cString\u003e(options.getLogTypes());\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n        appId, appOwner);\n    if (nodeFiles \u003d\u003d null) {\n      return -1;\n    }\n    boolean foundAnyLogs \u003d false;\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n        Path p \u003d new Path(\"har:///\"\n            + thisNodeFile.getPath().toUri().getRawPath());\n        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n        continue;\n      }\n      if (!thisNodeFile.getPath().getName()\n          .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d\n            new AggregatedLogFormat.LogReader(getConf(),\n                thisNodeFile.getPath());\n        try {\n\n          DataInputStream valueStream;\n          LogKey key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n\n          while (valueStream !\u003d null) {\n            PrintStream out \u003d createPrintStream(localDir,\n                thisNodeFile.getPath().getName(), key.toString());\n            try {\n              String containerString \u003d String.format(\n                  CONTAINER_ON_NODE_PATTERN, key,\n                  thisNodeFile.getPath().getName());\n              out.println(containerString);\n              out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n              while (true) {\n                try {\n                  if (logTypes \u003d\u003d null || logTypes.isEmpty()) {\n                    LogReader.readAContainerLogsForALogType(valueStream, out,\n                        thisNodeFile.getModificationTime(),\n                        options.getBytes());\n                    foundAnyLogs \u003d true;\n                  } else {\n                    int result \u003d LogReader.readContainerLogsForALogType(\n                        valueStream, out, thisNodeFile.getModificationTime(),\n                        logTypes, options.getBytes());\n                    if (result \u003d\u003d 0) {\n                      foundAnyLogs \u003d true;\n                    }\n                  }\n                } catch (EOFException eof) {\n                  break;\n                }\n              }\n            } finally {\n              closePrintStream(out);\n            }\n\n            // Next container\n            key \u003d new LogKey();\n            valueStream \u003d reader.next(key);\n          }\n        } finally {\n          reader.close();\n        }\n      }\n    }\n    if (!foundAnyLogs) {\n      emptyLogDir(LogAggregationUtils.getRemoteAppLogDir(conf, appId, appOwner)\n          .toString());\n      return -1;\n    }\n    return 0;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "e605d47df05619c6b1c18aca59f709899498da75": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5470. Differentiate exactly match with regex in yarn log CLI. Contributed by Xuan Gong.\n",
      "commitDate": "05/08/16 10:55 AM",
      "commitName": "e605d47df05619c6b1c18aca59f709899498da75",
      "commitAuthor": "Junping Du",
      "commitDateOld": "19/07/16 7:17 AM",
      "commitNameOld": "dc2f4b6ac8a6f8848457046cf9e1362d8f48495d",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 17.15,
      "commitsBetweenForRepo": 128,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,78 @@\n   public int dumpAllContainersLogs(ContainerLogsRequest options)\n       throws IOException {\n     ApplicationId appId \u003d options.getAppId();\n     String appOwner \u003d options.getAppOwner();\n     String localDir \u003d options.getOutputLocalDir();\n-    List\u003cString\u003e logTypes \u003d options.getLogTypes();\n+    List\u003cString\u003e logTypes \u003d new ArrayList\u003cString\u003e(options.getLogTypes());\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n         appId, appOwner);\n     if (nodeFiles \u003d\u003d null) {\n       return -1;\n     }\n     boolean foundAnyLogs \u003d false;\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n         Path p \u003d new Path(\"har:///\"\n             + thisNodeFile.getPath().toUri().getRawPath());\n         nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n         continue;\n       }\n       if (!thisNodeFile.getPath().getName()\n           .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n         AggregatedLogFormat.LogReader reader \u003d\n             new AggregatedLogFormat.LogReader(getConf(),\n                 thisNodeFile.getPath());\n         try {\n \n           DataInputStream valueStream;\n           LogKey key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n \n           while (valueStream !\u003d null) {\n             PrintStream out \u003d createPrintStream(localDir,\n                 thisNodeFile.getPath().getName(), key.toString());\n             try {\n               String containerString \u003d String.format(\n                   CONTAINER_ON_NODE_PATTERN, key,\n                   thisNodeFile.getPath().getName());\n               out.println(containerString);\n               out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n               while (true) {\n                 try {\n                   if (logTypes \u003d\u003d null || logTypes.isEmpty()) {\n                     LogReader.readAContainerLogsForALogType(valueStream, out,\n                         thisNodeFile.getModificationTime(),\n                         options.getBytes());\n                     foundAnyLogs \u003d true;\n                   } else {\n                     int result \u003d LogReader.readContainerLogsForALogType(\n                         valueStream, out, thisNodeFile.getModificationTime(),\n                         logTypes, options.getBytes());\n                     if (result \u003d\u003d 0) {\n                       foundAnyLogs \u003d true;\n                     }\n                   }\n                 } catch (EOFException eof) {\n                   break;\n                 }\n               }\n             } finally {\n               closePrintStream(out);\n             }\n \n             // Next container\n             key \u003d new LogKey();\n             valueStream \u003d reader.next(key);\n           }\n         } finally {\n           reader.close();\n         }\n       }\n     }\n     if (!foundAnyLogs) {\n       emptyLogDir(getRemoteAppLogDir(appId, appOwner).toString());\n       return -1;\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAllContainersLogs(ContainerLogsRequest options)\n      throws IOException {\n    ApplicationId appId \u003d options.getAppId();\n    String appOwner \u003d options.getAppOwner();\n    String localDir \u003d options.getOutputLocalDir();\n    List\u003cString\u003e logTypes \u003d new ArrayList\u003cString\u003e(options.getLogTypes());\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n        appId, appOwner);\n    if (nodeFiles \u003d\u003d null) {\n      return -1;\n    }\n    boolean foundAnyLogs \u003d false;\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n        Path p \u003d new Path(\"har:///\"\n            + thisNodeFile.getPath().toUri().getRawPath());\n        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n        continue;\n      }\n      if (!thisNodeFile.getPath().getName()\n          .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d\n            new AggregatedLogFormat.LogReader(getConf(),\n                thisNodeFile.getPath());\n        try {\n\n          DataInputStream valueStream;\n          LogKey key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n\n          while (valueStream !\u003d null) {\n            PrintStream out \u003d createPrintStream(localDir,\n                thisNodeFile.getPath().getName(), key.toString());\n            try {\n              String containerString \u003d String.format(\n                  CONTAINER_ON_NODE_PATTERN, key,\n                  thisNodeFile.getPath().getName());\n              out.println(containerString);\n              out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n              while (true) {\n                try {\n                  if (logTypes \u003d\u003d null || logTypes.isEmpty()) {\n                    LogReader.readAContainerLogsForALogType(valueStream, out,\n                        thisNodeFile.getModificationTime(),\n                        options.getBytes());\n                    foundAnyLogs \u003d true;\n                  } else {\n                    int result \u003d LogReader.readContainerLogsForALogType(\n                        valueStream, out, thisNodeFile.getModificationTime(),\n                        logTypes, options.getBytes());\n                    if (result \u003d\u003d 0) {\n                      foundAnyLogs \u003d true;\n                    }\n                  }\n                } catch (EOFException eof) {\n                  break;\n                }\n              }\n            } finally {\n              closePrintStream(out);\n            }\n\n            // Next container\n            key \u003d new LogKey();\n            valueStream \u003d reader.next(key);\n          }\n        } finally {\n          reader.close();\n        }\n      }\n    }\n    if (!foundAnyLogs) {\n      emptyLogDir(getRemoteAppLogDir(appId, appOwner).toString());\n      return -1;\n    }\n    return 0;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "eb471632349deac4b62f8dec853c8ceb64c9617a": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5200. Enhanced \"yarn logs\" to be able to get a list of containers whose logs are aggregated via a \"show_container_log_info\" option. Contributed by Xuan Gong.\n",
      "commitDate": "13/07/16 10:54 AM",
      "commitName": "eb471632349deac4b62f8dec853c8ceb64c9617a",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "22/06/16 9:48 PM",
      "commitNameOld": "6ab5aa1c1f82f81726c6daa38b3db90d8c3ad856",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 20.55,
      "commitsBetweenForRepo": 266,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,78 @@\n   public int dumpAllContainersLogs(ContainerLogsRequest options)\n       throws IOException {\n     ApplicationId appId \u003d options.getAppId();\n     String appOwner \u003d options.getAppOwner();\n     String localDir \u003d options.getOutputLocalDir();\n     List\u003cString\u003e logTypes \u003d options.getLogTypes();\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n         appId, appOwner);\n     if (nodeFiles \u003d\u003d null) {\n       return -1;\n     }\n     boolean foundAnyLogs \u003d false;\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n         Path p \u003d new Path(\"har:///\"\n             + thisNodeFile.getPath().toUri().getRawPath());\n         nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n         continue;\n       }\n       if (!thisNodeFile.getPath().getName()\n           .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n         AggregatedLogFormat.LogReader reader \u003d\n             new AggregatedLogFormat.LogReader(getConf(),\n                 thisNodeFile.getPath());\n         try {\n \n           DataInputStream valueStream;\n           LogKey key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n \n           while (valueStream !\u003d null) {\n             PrintStream out \u003d createPrintStream(localDir,\n                 thisNodeFile.getPath().getName(), key.toString());\n             try {\n-              String containerString \u003d\n-                  \"\\n\\nContainer: \" + key + \" on \"\n-                  + thisNodeFile.getPath().getName();\n+              String containerString \u003d String.format(\n+                  CONTAINER_ON_NODE_PATTERN, key,\n+                  thisNodeFile.getPath().getName());\n               out.println(containerString);\n               out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n               while (true) {\n                 try {\n                   if (logTypes \u003d\u003d null || logTypes.isEmpty()) {\n                     LogReader.readAContainerLogsForALogType(valueStream, out,\n                         thisNodeFile.getModificationTime(),\n                         options.getBytes());\n                     foundAnyLogs \u003d true;\n                   } else {\n                     int result \u003d LogReader.readContainerLogsForALogType(\n                         valueStream, out, thisNodeFile.getModificationTime(),\n                         logTypes, options.getBytes());\n                     if (result \u003d\u003d 0) {\n                       foundAnyLogs \u003d true;\n                     }\n                   }\n                 } catch (EOFException eof) {\n                   break;\n                 }\n               }\n             } finally {\n               closePrintStream(out);\n             }\n \n             // Next container\n             key \u003d new LogKey();\n             valueStream \u003d reader.next(key);\n           }\n         } finally {\n           reader.close();\n         }\n       }\n     }\n     if (!foundAnyLogs) {\n       emptyLogDir(getRemoteAppLogDir(appId, appOwner).toString());\n       return -1;\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAllContainersLogs(ContainerLogsRequest options)\n      throws IOException {\n    ApplicationId appId \u003d options.getAppId();\n    String appOwner \u003d options.getAppOwner();\n    String localDir \u003d options.getOutputLocalDir();\n    List\u003cString\u003e logTypes \u003d options.getLogTypes();\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n        appId, appOwner);\n    if (nodeFiles \u003d\u003d null) {\n      return -1;\n    }\n    boolean foundAnyLogs \u003d false;\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n        Path p \u003d new Path(\"har:///\"\n            + thisNodeFile.getPath().toUri().getRawPath());\n        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n        continue;\n      }\n      if (!thisNodeFile.getPath().getName()\n          .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d\n            new AggregatedLogFormat.LogReader(getConf(),\n                thisNodeFile.getPath());\n        try {\n\n          DataInputStream valueStream;\n          LogKey key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n\n          while (valueStream !\u003d null) {\n            PrintStream out \u003d createPrintStream(localDir,\n                thisNodeFile.getPath().getName(), key.toString());\n            try {\n              String containerString \u003d String.format(\n                  CONTAINER_ON_NODE_PATTERN, key,\n                  thisNodeFile.getPath().getName());\n              out.println(containerString);\n              out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n              while (true) {\n                try {\n                  if (logTypes \u003d\u003d null || logTypes.isEmpty()) {\n                    LogReader.readAContainerLogsForALogType(valueStream, out,\n                        thisNodeFile.getModificationTime(),\n                        options.getBytes());\n                    foundAnyLogs \u003d true;\n                  } else {\n                    int result \u003d LogReader.readContainerLogsForALogType(\n                        valueStream, out, thisNodeFile.getModificationTime(),\n                        logTypes, options.getBytes());\n                    if (result \u003d\u003d 0) {\n                      foundAnyLogs \u003d true;\n                    }\n                  }\n                } catch (EOFException eof) {\n                  break;\n                }\n              }\n            } finally {\n              closePrintStream(out);\n            }\n\n            // Next container\n            key \u003d new LogKey();\n            valueStream \u003d reader.next(key);\n          }\n        } finally {\n          reader.close();\n        }\n      }\n    }\n    if (!foundAnyLogs) {\n      emptyLogDir(getRemoteAppLogDir(appId, appOwner).toString());\n      return -1;\n    }\n    return 0;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "0bc05e40fa7e183efe8463ada459c621da3ce3bf": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5088. Improve \"yarn log\" command-line to read the last K bytes for the log files. Contributed by Xuan Gong\n",
      "commitDate": "01/06/16 1:44 PM",
      "commitName": "0bc05e40fa7e183efe8463ada459c621da3ce3bf",
      "commitAuthor": "Xuan",
      "commitDateOld": "26/05/16 11:49 PM",
      "commitNameOld": "bde819abbbcea940cfa6426a9e4920e6c8dc9cf1",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 5.58,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,78 @@\n   public int dumpAllContainersLogs(ContainerLogsRequest options)\n       throws IOException {\n     ApplicationId appId \u003d options.getAppId();\n     String appOwner \u003d options.getAppOwner();\n     String localDir \u003d options.getOutputLocalDir();\n     List\u003cString\u003e logTypes \u003d options.getLogTypes();\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n         appId, appOwner);\n     if (nodeFiles \u003d\u003d null) {\n       return -1;\n     }\n     boolean foundAnyLogs \u003d false;\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n         Path p \u003d new Path(\"har:///\"\n             + thisNodeFile.getPath().toUri().getRawPath());\n         nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n         continue;\n       }\n       if (!thisNodeFile.getPath().getName()\n           .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n         AggregatedLogFormat.LogReader reader \u003d\n             new AggregatedLogFormat.LogReader(getConf(),\n                 thisNodeFile.getPath());\n         try {\n \n           DataInputStream valueStream;\n           LogKey key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n \n           while (valueStream !\u003d null) {\n             PrintStream out \u003d createPrintStream(localDir,\n                 thisNodeFile.getPath().getName(), key.toString());\n             try {\n               String containerString \u003d\n                   \"\\n\\nContainer: \" + key + \" on \"\n                   + thisNodeFile.getPath().getName();\n               out.println(containerString);\n               out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n               while (true) {\n                 try {\n                   if (logTypes \u003d\u003d null || logTypes.isEmpty()) {\n                     LogReader.readAContainerLogsForALogType(valueStream, out,\n-                        thisNodeFile.getModificationTime());\n+                        thisNodeFile.getModificationTime(),\n+                        options.getBytes());\n                     foundAnyLogs \u003d true;\n                   } else {\n                     int result \u003d LogReader.readContainerLogsForALogType(\n                         valueStream, out, thisNodeFile.getModificationTime(),\n-                        logTypes);\n+                        logTypes, options.getBytes());\n                     if (result \u003d\u003d 0) {\n                       foundAnyLogs \u003d true;\n                     }\n                   }\n                 } catch (EOFException eof) {\n                   break;\n                 }\n               }\n             } finally {\n               closePrintStream(out);\n             }\n \n             // Next container\n             key \u003d new LogKey();\n             valueStream \u003d reader.next(key);\n           }\n         } finally {\n           reader.close();\n         }\n       }\n     }\n     if (!foundAnyLogs) {\n       emptyLogDir(getRemoteAppLogDir(appId, appOwner).toString());\n       return -1;\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAllContainersLogs(ContainerLogsRequest options)\n      throws IOException {\n    ApplicationId appId \u003d options.getAppId();\n    String appOwner \u003d options.getAppOwner();\n    String localDir \u003d options.getOutputLocalDir();\n    List\u003cString\u003e logTypes \u003d options.getLogTypes();\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n        appId, appOwner);\n    if (nodeFiles \u003d\u003d null) {\n      return -1;\n    }\n    boolean foundAnyLogs \u003d false;\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n        Path p \u003d new Path(\"har:///\"\n            + thisNodeFile.getPath().toUri().getRawPath());\n        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n        continue;\n      }\n      if (!thisNodeFile.getPath().getName()\n          .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d\n            new AggregatedLogFormat.LogReader(getConf(),\n                thisNodeFile.getPath());\n        try {\n\n          DataInputStream valueStream;\n          LogKey key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n\n          while (valueStream !\u003d null) {\n            PrintStream out \u003d createPrintStream(localDir,\n                thisNodeFile.getPath().getName(), key.toString());\n            try {\n              String containerString \u003d\n                  \"\\n\\nContainer: \" + key + \" on \"\n                  + thisNodeFile.getPath().getName();\n              out.println(containerString);\n              out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n              while (true) {\n                try {\n                  if (logTypes \u003d\u003d null || logTypes.isEmpty()) {\n                    LogReader.readAContainerLogsForALogType(valueStream, out,\n                        thisNodeFile.getModificationTime(),\n                        options.getBytes());\n                    foundAnyLogs \u003d true;\n                  } else {\n                    int result \u003d LogReader.readContainerLogsForALogType(\n                        valueStream, out, thisNodeFile.getModificationTime(),\n                        logTypes, options.getBytes());\n                    if (result \u003d\u003d 0) {\n                      foundAnyLogs \u003d true;\n                    }\n                  }\n                } catch (EOFException eof) {\n                  break;\n                }\n              }\n            } finally {\n              closePrintStream(out);\n            }\n\n            // Next container\n            key \u003d new LogKey();\n            valueStream \u003d reader.next(key);\n          }\n        } finally {\n          reader.close();\n        }\n      }\n    }\n    if (!foundAnyLogs) {\n      emptyLogDir(getRemoteAppLogDir(appId, appOwner).toString());\n      return -1;\n    }\n    return 0;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "bde819abbbcea940cfa6426a9e4920e6c8dc9cf1": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-5089. Improve \"yarn log\" command-line \"logFiles\" option to support\nregex. Contributed by Xuan Gong\n",
      "commitDate": "26/05/16 11:49 PM",
      "commitName": "bde819abbbcea940cfa6426a9e4920e6c8dc9cf1",
      "commitAuthor": "Xuan",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-5089. Improve \"yarn log\" command-line \"logFiles\" option to support\nregex. Contributed by Xuan Gong\n",
          "commitDate": "26/05/16 11:49 PM",
          "commitName": "bde819abbbcea940cfa6426a9e4920e6c8dc9cf1",
          "commitAuthor": "Xuan",
          "commitDateOld": "18/05/16 10:14 AM",
          "commitNameOld": "ef1757790d89cc72f88f5330761b1c8901c59e94",
          "commitAuthorOld": "Varun Vasudev",
          "daysBetweenCommits": 8.57,
          "commitsBetweenForRepo": 66,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,64 +1,77 @@\n-  public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n-      String localDir) throws IOException {\n+  public int dumpAllContainersLogs(ContainerLogsRequest options)\n+      throws IOException {\n+    ApplicationId appId \u003d options.getAppId();\n+    String appOwner \u003d options.getAppOwner();\n+    String localDir \u003d options.getOutputLocalDir();\n+    List\u003cString\u003e logTypes \u003d options.getLogTypes();\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n         appId, appOwner);\n     if (nodeFiles \u003d\u003d null) {\n       return -1;\n     }\n     boolean foundAnyLogs \u003d false;\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n         Path p \u003d new Path(\"har:///\"\n             + thisNodeFile.getPath().toUri().getRawPath());\n         nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n         continue;\n       }\n       if (!thisNodeFile.getPath().getName()\n           .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n         AggregatedLogFormat.LogReader reader \u003d\n             new AggregatedLogFormat.LogReader(getConf(),\n                 thisNodeFile.getPath());\n         try {\n \n           DataInputStream valueStream;\n           LogKey key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n \n           while (valueStream !\u003d null) {\n             PrintStream out \u003d createPrintStream(localDir,\n                 thisNodeFile.getPath().getName(), key.toString());\n             try {\n               String containerString \u003d\n                   \"\\n\\nContainer: \" + key + \" on \"\n                   + thisNodeFile.getPath().getName();\n               out.println(containerString);\n               out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n               while (true) {\n                 try {\n-                  LogReader.readAContainerLogsForALogType(valueStream, out,\n-                      thisNodeFile.getModificationTime());\n-                  foundAnyLogs \u003d true;\n+                  if (logTypes \u003d\u003d null || logTypes.isEmpty()) {\n+                    LogReader.readAContainerLogsForALogType(valueStream, out,\n+                        thisNodeFile.getModificationTime());\n+                    foundAnyLogs \u003d true;\n+                  } else {\n+                    int result \u003d LogReader.readContainerLogsForALogType(\n+                        valueStream, out, thisNodeFile.getModificationTime(),\n+                        logTypes);\n+                    if (result \u003d\u003d 0) {\n+                      foundAnyLogs \u003d true;\n+                    }\n+                  }\n                 } catch (EOFException eof) {\n                   break;\n                 }\n               }\n             } finally {\n               closePrintStream(out);\n             }\n \n             // Next container\n             key \u003d new LogKey();\n             valueStream \u003d reader.next(key);\n           }\n         } finally {\n           reader.close();\n         }\n       }\n     }\n     if (!foundAnyLogs) {\n       emptyLogDir(getRemoteAppLogDir(appId, appOwner).toString());\n       return -1;\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public int dumpAllContainersLogs(ContainerLogsRequest options)\n      throws IOException {\n    ApplicationId appId \u003d options.getAppId();\n    String appOwner \u003d options.getAppOwner();\n    String localDir \u003d options.getOutputLocalDir();\n    List\u003cString\u003e logTypes \u003d options.getLogTypes();\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n        appId, appOwner);\n    if (nodeFiles \u003d\u003d null) {\n      return -1;\n    }\n    boolean foundAnyLogs \u003d false;\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n        Path p \u003d new Path(\"har:///\"\n            + thisNodeFile.getPath().toUri().getRawPath());\n        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n        continue;\n      }\n      if (!thisNodeFile.getPath().getName()\n          .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d\n            new AggregatedLogFormat.LogReader(getConf(),\n                thisNodeFile.getPath());\n        try {\n\n          DataInputStream valueStream;\n          LogKey key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n\n          while (valueStream !\u003d null) {\n            PrintStream out \u003d createPrintStream(localDir,\n                thisNodeFile.getPath().getName(), key.toString());\n            try {\n              String containerString \u003d\n                  \"\\n\\nContainer: \" + key + \" on \"\n                  + thisNodeFile.getPath().getName();\n              out.println(containerString);\n              out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n              while (true) {\n                try {\n                  if (logTypes \u003d\u003d null || logTypes.isEmpty()) {\n                    LogReader.readAContainerLogsForALogType(valueStream, out,\n                        thisNodeFile.getModificationTime());\n                    foundAnyLogs \u003d true;\n                  } else {\n                    int result \u003d LogReader.readContainerLogsForALogType(\n                        valueStream, out, thisNodeFile.getModificationTime(),\n                        logTypes);\n                    if (result \u003d\u003d 0) {\n                      foundAnyLogs \u003d true;\n                    }\n                  }\n                } catch (EOFException eof) {\n                  break;\n                }\n              }\n            } finally {\n              closePrintStream(out);\n            }\n\n            // Next container\n            key \u003d new LogKey();\n            valueStream \u003d reader.next(key);\n          }\n        } finally {\n          reader.close();\n        }\n      }\n    }\n    if (!foundAnyLogs) {\n      emptyLogDir(getRemoteAppLogDir(appId, appOwner).toString());\n      return -1;\n    }\n    return 0;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
          "extendedDetails": {
            "oldValue": "[appId-ApplicationId, appOwner-String, localDir-String]",
            "newValue": "[options-ContainerLogsRequest]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-5089. Improve \"yarn log\" command-line \"logFiles\" option to support\nregex. Contributed by Xuan Gong\n",
          "commitDate": "26/05/16 11:49 PM",
          "commitName": "bde819abbbcea940cfa6426a9e4920e6c8dc9cf1",
          "commitAuthor": "Xuan",
          "commitDateOld": "18/05/16 10:14 AM",
          "commitNameOld": "ef1757790d89cc72f88f5330761b1c8901c59e94",
          "commitAuthorOld": "Varun Vasudev",
          "daysBetweenCommits": 8.57,
          "commitsBetweenForRepo": 66,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,64 +1,77 @@\n-  public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n-      String localDir) throws IOException {\n+  public int dumpAllContainersLogs(ContainerLogsRequest options)\n+      throws IOException {\n+    ApplicationId appId \u003d options.getAppId();\n+    String appOwner \u003d options.getAppOwner();\n+    String localDir \u003d options.getOutputLocalDir();\n+    List\u003cString\u003e logTypes \u003d options.getLogTypes();\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n         appId, appOwner);\n     if (nodeFiles \u003d\u003d null) {\n       return -1;\n     }\n     boolean foundAnyLogs \u003d false;\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n         Path p \u003d new Path(\"har:///\"\n             + thisNodeFile.getPath().toUri().getRawPath());\n         nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n         continue;\n       }\n       if (!thisNodeFile.getPath().getName()\n           .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n         AggregatedLogFormat.LogReader reader \u003d\n             new AggregatedLogFormat.LogReader(getConf(),\n                 thisNodeFile.getPath());\n         try {\n \n           DataInputStream valueStream;\n           LogKey key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n \n           while (valueStream !\u003d null) {\n             PrintStream out \u003d createPrintStream(localDir,\n                 thisNodeFile.getPath().getName(), key.toString());\n             try {\n               String containerString \u003d\n                   \"\\n\\nContainer: \" + key + \" on \"\n                   + thisNodeFile.getPath().getName();\n               out.println(containerString);\n               out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n               while (true) {\n                 try {\n-                  LogReader.readAContainerLogsForALogType(valueStream, out,\n-                      thisNodeFile.getModificationTime());\n-                  foundAnyLogs \u003d true;\n+                  if (logTypes \u003d\u003d null || logTypes.isEmpty()) {\n+                    LogReader.readAContainerLogsForALogType(valueStream, out,\n+                        thisNodeFile.getModificationTime());\n+                    foundAnyLogs \u003d true;\n+                  } else {\n+                    int result \u003d LogReader.readContainerLogsForALogType(\n+                        valueStream, out, thisNodeFile.getModificationTime(),\n+                        logTypes);\n+                    if (result \u003d\u003d 0) {\n+                      foundAnyLogs \u003d true;\n+                    }\n+                  }\n                 } catch (EOFException eof) {\n                   break;\n                 }\n               }\n             } finally {\n               closePrintStream(out);\n             }\n \n             // Next container\n             key \u003d new LogKey();\n             valueStream \u003d reader.next(key);\n           }\n         } finally {\n           reader.close();\n         }\n       }\n     }\n     if (!foundAnyLogs) {\n       emptyLogDir(getRemoteAppLogDir(appId, appOwner).toString());\n       return -1;\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public int dumpAllContainersLogs(ContainerLogsRequest options)\n      throws IOException {\n    ApplicationId appId \u003d options.getAppId();\n    String appOwner \u003d options.getAppOwner();\n    String localDir \u003d options.getOutputLocalDir();\n    List\u003cString\u003e logTypes \u003d options.getLogTypes();\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n        appId, appOwner);\n    if (nodeFiles \u003d\u003d null) {\n      return -1;\n    }\n    boolean foundAnyLogs \u003d false;\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n        Path p \u003d new Path(\"har:///\"\n            + thisNodeFile.getPath().toUri().getRawPath());\n        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n        continue;\n      }\n      if (!thisNodeFile.getPath().getName()\n          .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d\n            new AggregatedLogFormat.LogReader(getConf(),\n                thisNodeFile.getPath());\n        try {\n\n          DataInputStream valueStream;\n          LogKey key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n\n          while (valueStream !\u003d null) {\n            PrintStream out \u003d createPrintStream(localDir,\n                thisNodeFile.getPath().getName(), key.toString());\n            try {\n              String containerString \u003d\n                  \"\\n\\nContainer: \" + key + \" on \"\n                  + thisNodeFile.getPath().getName();\n              out.println(containerString);\n              out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n              while (true) {\n                try {\n                  if (logTypes \u003d\u003d null || logTypes.isEmpty()) {\n                    LogReader.readAContainerLogsForALogType(valueStream, out,\n                        thisNodeFile.getModificationTime());\n                    foundAnyLogs \u003d true;\n                  } else {\n                    int result \u003d LogReader.readContainerLogsForALogType(\n                        valueStream, out, thisNodeFile.getModificationTime(),\n                        logTypes);\n                    if (result \u003d\u003d 0) {\n                      foundAnyLogs \u003d true;\n                    }\n                  }\n                } catch (EOFException eof) {\n                  break;\n                }\n              }\n            } finally {\n              closePrintStream(out);\n            }\n\n            // Next container\n            key \u003d new LogKey();\n            valueStream \u003d reader.next(key);\n          }\n        } finally {\n          reader.close();\n        }\n      }\n    }\n    if (!foundAnyLogs) {\n      emptyLogDir(getRemoteAppLogDir(appId, appOwner).toString());\n      return -1;\n    }\n    return 0;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
          "extendedDetails": {}
        }
      ]
    },
    "ef1757790d89cc72f88f5330761b1c8901c59e94": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-4913. Yarn logs should take a -out option to write to a directory. Contributed by Xuan Gong.\n",
      "commitDate": "18/05/16 10:14 AM",
      "commitName": "ef1757790d89cc72f88f5330761b1c8901c59e94",
      "commitAuthor": "Varun Vasudev",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-4913. Yarn logs should take a -out option to write to a directory. Contributed by Xuan Gong.\n",
          "commitDate": "18/05/16 10:14 AM",
          "commitName": "ef1757790d89cc72f88f5330761b1c8901c59e94",
          "commitAuthor": "Varun Vasudev",
          "commitDateOld": "09/05/16 10:41 PM",
          "commitNameOld": "87f5e351337a905af5215af76c72b9312616cd4f",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 8.48,
          "commitsBetweenForRepo": 78,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,59 +1,64 @@\n   public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n-      PrintStream out) throws IOException {\n+      String localDir) throws IOException {\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n         appId, appOwner);\n     if (nodeFiles \u003d\u003d null) {\n       return -1;\n     }\n     boolean foundAnyLogs \u003d false;\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n         Path p \u003d new Path(\"har:///\"\n             + thisNodeFile.getPath().toUri().getRawPath());\n         nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n         continue;\n       }\n       if (!thisNodeFile.getPath().getName()\n           .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n         AggregatedLogFormat.LogReader reader \u003d\n             new AggregatedLogFormat.LogReader(getConf(),\n                 thisNodeFile.getPath());\n         try {\n \n           DataInputStream valueStream;\n           LogKey key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n \n           while (valueStream !\u003d null) {\n-\n-            String containerString \u003d\n-                \"\\n\\nContainer: \" + key + \" on \"\n-                + thisNodeFile.getPath().getName();\n-            out.println(containerString);\n-            out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n-            while (true) {\n-              try {\n-                LogReader.readAContainerLogsForALogType(valueStream, out,\n-                    thisNodeFile.getModificationTime());\n-                foundAnyLogs \u003d true;\n-              } catch (EOFException eof) {\n-                break;\n+            PrintStream out \u003d createPrintStream(localDir,\n+                thisNodeFile.getPath().getName(), key.toString());\n+            try {\n+              String containerString \u003d\n+                  \"\\n\\nContainer: \" + key + \" on \"\n+                  + thisNodeFile.getPath().getName();\n+              out.println(containerString);\n+              out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n+              while (true) {\n+                try {\n+                  LogReader.readAContainerLogsForALogType(valueStream, out,\n+                      thisNodeFile.getModificationTime());\n+                  foundAnyLogs \u003d true;\n+                } catch (EOFException eof) {\n+                  break;\n+                }\n               }\n+            } finally {\n+              closePrintStream(out);\n             }\n \n             // Next container\n             key \u003d new LogKey();\n             valueStream \u003d reader.next(key);\n           }\n         } finally {\n           reader.close();\n         }\n       }\n     }\n     if (!foundAnyLogs) {\n       emptyLogDir(getRemoteAppLogDir(appId, appOwner).toString());\n       return -1;\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      String localDir) throws IOException {\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n        appId, appOwner);\n    if (nodeFiles \u003d\u003d null) {\n      return -1;\n    }\n    boolean foundAnyLogs \u003d false;\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n        Path p \u003d new Path(\"har:///\"\n            + thisNodeFile.getPath().toUri().getRawPath());\n        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n        continue;\n      }\n      if (!thisNodeFile.getPath().getName()\n          .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d\n            new AggregatedLogFormat.LogReader(getConf(),\n                thisNodeFile.getPath());\n        try {\n\n          DataInputStream valueStream;\n          LogKey key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n\n          while (valueStream !\u003d null) {\n            PrintStream out \u003d createPrintStream(localDir,\n                thisNodeFile.getPath().getName(), key.toString());\n            try {\n              String containerString \u003d\n                  \"\\n\\nContainer: \" + key + \" on \"\n                  + thisNodeFile.getPath().getName();\n              out.println(containerString);\n              out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n              while (true) {\n                try {\n                  LogReader.readAContainerLogsForALogType(valueStream, out,\n                      thisNodeFile.getModificationTime());\n                  foundAnyLogs \u003d true;\n                } catch (EOFException eof) {\n                  break;\n                }\n              }\n            } finally {\n              closePrintStream(out);\n            }\n\n            // Next container\n            key \u003d new LogKey();\n            valueStream \u003d reader.next(key);\n          }\n        } finally {\n          reader.close();\n        }\n      }\n    }\n    if (!foundAnyLogs) {\n      emptyLogDir(getRemoteAppLogDir(appId, appOwner).toString());\n      return -1;\n    }\n    return 0;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
          "extendedDetails": {
            "oldValue": "[appId-ApplicationId, appOwner-String, out-PrintStream]",
            "newValue": "[appId-ApplicationId, appOwner-String, localDir-String]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-4913. Yarn logs should take a -out option to write to a directory. Contributed by Xuan Gong.\n",
          "commitDate": "18/05/16 10:14 AM",
          "commitName": "ef1757790d89cc72f88f5330761b1c8901c59e94",
          "commitAuthor": "Varun Vasudev",
          "commitDateOld": "09/05/16 10:41 PM",
          "commitNameOld": "87f5e351337a905af5215af76c72b9312616cd4f",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 8.48,
          "commitsBetweenForRepo": 78,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,59 +1,64 @@\n   public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n-      PrintStream out) throws IOException {\n+      String localDir) throws IOException {\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n         appId, appOwner);\n     if (nodeFiles \u003d\u003d null) {\n       return -1;\n     }\n     boolean foundAnyLogs \u003d false;\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n         Path p \u003d new Path(\"har:///\"\n             + thisNodeFile.getPath().toUri().getRawPath());\n         nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n         continue;\n       }\n       if (!thisNodeFile.getPath().getName()\n           .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n         AggregatedLogFormat.LogReader reader \u003d\n             new AggregatedLogFormat.LogReader(getConf(),\n                 thisNodeFile.getPath());\n         try {\n \n           DataInputStream valueStream;\n           LogKey key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n \n           while (valueStream !\u003d null) {\n-\n-            String containerString \u003d\n-                \"\\n\\nContainer: \" + key + \" on \"\n-                + thisNodeFile.getPath().getName();\n-            out.println(containerString);\n-            out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n-            while (true) {\n-              try {\n-                LogReader.readAContainerLogsForALogType(valueStream, out,\n-                    thisNodeFile.getModificationTime());\n-                foundAnyLogs \u003d true;\n-              } catch (EOFException eof) {\n-                break;\n+            PrintStream out \u003d createPrintStream(localDir,\n+                thisNodeFile.getPath().getName(), key.toString());\n+            try {\n+              String containerString \u003d\n+                  \"\\n\\nContainer: \" + key + \" on \"\n+                  + thisNodeFile.getPath().getName();\n+              out.println(containerString);\n+              out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n+              while (true) {\n+                try {\n+                  LogReader.readAContainerLogsForALogType(valueStream, out,\n+                      thisNodeFile.getModificationTime());\n+                  foundAnyLogs \u003d true;\n+                } catch (EOFException eof) {\n+                  break;\n+                }\n               }\n+            } finally {\n+              closePrintStream(out);\n             }\n \n             // Next container\n             key \u003d new LogKey();\n             valueStream \u003d reader.next(key);\n           }\n         } finally {\n           reader.close();\n         }\n       }\n     }\n     if (!foundAnyLogs) {\n       emptyLogDir(getRemoteAppLogDir(appId, appOwner).toString());\n       return -1;\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      String localDir) throws IOException {\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n        appId, appOwner);\n    if (nodeFiles \u003d\u003d null) {\n      return -1;\n    }\n    boolean foundAnyLogs \u003d false;\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n        Path p \u003d new Path(\"har:///\"\n            + thisNodeFile.getPath().toUri().getRawPath());\n        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n        continue;\n      }\n      if (!thisNodeFile.getPath().getName()\n          .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d\n            new AggregatedLogFormat.LogReader(getConf(),\n                thisNodeFile.getPath());\n        try {\n\n          DataInputStream valueStream;\n          LogKey key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n\n          while (valueStream !\u003d null) {\n            PrintStream out \u003d createPrintStream(localDir,\n                thisNodeFile.getPath().getName(), key.toString());\n            try {\n              String containerString \u003d\n                  \"\\n\\nContainer: \" + key + \" on \"\n                  + thisNodeFile.getPath().getName();\n              out.println(containerString);\n              out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n              while (true) {\n                try {\n                  LogReader.readAContainerLogsForALogType(valueStream, out,\n                      thisNodeFile.getModificationTime());\n                  foundAnyLogs \u003d true;\n                } catch (EOFException eof) {\n                  break;\n                }\n              }\n            } finally {\n              closePrintStream(out);\n            }\n\n            // Next container\n            key \u003d new LogKey();\n            valueStream \u003d reader.next(key);\n          }\n        } finally {\n          reader.close();\n        }\n      }\n    }\n    if (!foundAnyLogs) {\n      emptyLogDir(getRemoteAppLogDir(appId, appOwner).toString());\n      return -1;\n    }\n    return 0;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
          "extendedDetails": {}
        }
      ]
    },
    "9e37fe3b7a3b5f0a193d228bb5e065f41acd2835": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4905. Improved \"yarn logs\" command-line to optionally show log metadata also. Contributed by Xuan Gong.\n",
      "commitDate": "04/05/16 2:16 PM",
      "commitName": "9e37fe3b7a3b5f0a193d228bb5e065f41acd2835",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "27/04/16 3:26 AM",
      "commitNameOld": "66b07d83740a2ec3e6bfb2bfd064863bae37a1b5",
      "commitAuthorOld": "Varun Vasudev",
      "daysBetweenCommits": 7.45,
      "commitsBetweenForRepo": 41,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,57 @@\n   public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n       PrintStream out) throws IOException {\n-    Path remoteRootLogDir \u003d new Path(getConf().get(\n-        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n-        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n-    String user \u003d appOwner;\n-    String logDirSuffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n-    // TODO Change this to get a list of files from the LAS.\n-    Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n-        remoteRootLogDir, appId, user, logDirSuffix);\n-    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n-    try {\n-      Path qualifiedLogDir \u003d\n-          FileContext.getFileContext(getConf()).makeQualified(remoteAppLogDir);\n-      nodeFiles \u003d FileContext.getFileContext(qualifiedLogDir.toUri(),\n-          getConf()).listStatus(remoteAppLogDir);\n-    } catch (FileNotFoundException fnf) {\n-      logDirNotExist(remoteAppLogDir.toString());\n+    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n+        appId, appOwner);\n+    if (nodeFiles \u003d\u003d null) {\n       return -1;\n     }\n     boolean foundAnyLogs \u003d false;\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n         Path p \u003d new Path(\"har:///\"\n             + thisNodeFile.getPath().toUri().getRawPath());\n         nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n         continue;\n       }\n       if (!thisNodeFile.getPath().getName()\n         .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n         AggregatedLogFormat.LogReader reader \u003d\n             new AggregatedLogFormat.LogReader(getConf(), thisNodeFile.getPath());\n         try {\n \n           DataInputStream valueStream;\n           LogKey key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n \n           while (valueStream !\u003d null) {\n \n             String containerString \u003d\n                 \"\\n\\nContainer: \" + key + \" on \" + thisNodeFile.getPath().getName();\n             out.println(containerString);\n             out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n             while (true) {\n               try {\n                 LogReader.readAContainerLogsForALogType(valueStream, out,\n                   thisNodeFile.getModificationTime());\n                 foundAnyLogs \u003d true;\n               } catch (EOFException eof) {\n                 break;\n               }\n             }\n \n             // Next container\n             key \u003d new LogKey();\n             valueStream \u003d reader.next(key);\n           }\n         } finally {\n           reader.close();\n         }\n       }\n     }\n     if (! foundAnyLogs) {\n-      emptyLogDir(remoteAppLogDir.toString());\n+      emptyLogDir(getRemoteAppLogDir(appId, appOwner).toString());\n       return -1;\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      PrintStream out) throws IOException {\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d getRemoteNodeFileDir(\n        appId, appOwner);\n    if (nodeFiles \u003d\u003d null) {\n      return -1;\n    }\n    boolean foundAnyLogs \u003d false;\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n        Path p \u003d new Path(\"har:///\"\n            + thisNodeFile.getPath().toUri().getRawPath());\n        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n        continue;\n      }\n      if (!thisNodeFile.getPath().getName()\n        .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d\n            new AggregatedLogFormat.LogReader(getConf(), thisNodeFile.getPath());\n        try {\n\n          DataInputStream valueStream;\n          LogKey key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n\n          while (valueStream !\u003d null) {\n\n            String containerString \u003d\n                \"\\n\\nContainer: \" + key + \" on \" + thisNodeFile.getPath().getName();\n            out.println(containerString);\n            out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n            while (true) {\n              try {\n                LogReader.readAContainerLogsForALogType(valueStream, out,\n                  thisNodeFile.getModificationTime());\n                foundAnyLogs \u003d true;\n              } catch (EOFException eof) {\n                break;\n              }\n            }\n\n            // Next container\n            key \u003d new LogKey();\n            valueStream \u003d reader.next(key);\n          }\n        } finally {\n          reader.close();\n        }\n      }\n    }\n    if (! foundAnyLogs) {\n      emptyLogDir(getRemoteAppLogDir(appId, appOwner).toString());\n      return -1;\n    }\n    return 0;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "6dd6ca442aba8612c3780399a42bb473e4483021": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4086. Allow Aggregated Log readers to handle HAR files (rkanter)\n",
      "commitDate": "09/09/15 6:03 PM",
      "commitName": "6dd6ca442aba8612c3780399a42bb473e4483021",
      "commitAuthor": "Robert Kanter",
      "commitDateOld": "13/04/15 5:29 PM",
      "commitNameOld": "a77d628339afaf2f5a085c73fd81a805b18348c9",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 149.02,
      "commitsBetweenForRepo": 1082,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,64 +1,70 @@\n   public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n       PrintStream out) throws IOException {\n     Path remoteRootLogDir \u003d new Path(getConf().get(\n         YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n         YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String user \u003d appOwner;\n     String logDirSuffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n     // TODO Change this to get a list of files from the LAS.\n     Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n         remoteRootLogDir, appId, user, logDirSuffix);\n     RemoteIterator\u003cFileStatus\u003e nodeFiles;\n     try {\n       Path qualifiedLogDir \u003d\n           FileContext.getFileContext(getConf()).makeQualified(remoteAppLogDir);\n       nodeFiles \u003d FileContext.getFileContext(qualifiedLogDir.toUri(),\n           getConf()).listStatus(remoteAppLogDir);\n     } catch (FileNotFoundException fnf) {\n       logDirNotExist(remoteAppLogDir.toString());\n       return -1;\n     }\n     boolean foundAnyLogs \u003d false;\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n+      if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n+        Path p \u003d new Path(\"har:///\"\n+            + thisNodeFile.getPath().toUri().getRawPath());\n+        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n+        continue;\n+      }\n       if (!thisNodeFile.getPath().getName()\n         .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n         AggregatedLogFormat.LogReader reader \u003d\n             new AggregatedLogFormat.LogReader(getConf(), thisNodeFile.getPath());\n         try {\n \n           DataInputStream valueStream;\n           LogKey key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n \n           while (valueStream !\u003d null) {\n \n             String containerString \u003d\n                 \"\\n\\nContainer: \" + key + \" on \" + thisNodeFile.getPath().getName();\n             out.println(containerString);\n             out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n             while (true) {\n               try {\n                 LogReader.readAContainerLogsForALogType(valueStream, out,\n                   thisNodeFile.getModificationTime());\n                 foundAnyLogs \u003d true;\n               } catch (EOFException eof) {\n                 break;\n               }\n             }\n \n             // Next container\n             key \u003d new LogKey();\n             valueStream \u003d reader.next(key);\n           }\n         } finally {\n           reader.close();\n         }\n       }\n     }\n     if (! foundAnyLogs) {\n       emptyLogDir(remoteAppLogDir.toString());\n       return -1;\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      PrintStream out) throws IOException {\n    Path remoteRootLogDir \u003d new Path(getConf().get(\n        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user \u003d appOwner;\n    String logDirSuffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    // TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n        remoteRootLogDir, appId, user, logDirSuffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n    try {\n      Path qualifiedLogDir \u003d\n          FileContext.getFileContext(getConf()).makeQualified(remoteAppLogDir);\n      nodeFiles \u003d FileContext.getFileContext(qualifiedLogDir.toUri(),\n          getConf()).listStatus(remoteAppLogDir);\n    } catch (FileNotFoundException fnf) {\n      logDirNotExist(remoteAppLogDir.toString());\n      return -1;\n    }\n    boolean foundAnyLogs \u003d false;\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      if (thisNodeFile.getPath().getName().equals(appId + \".har\")) {\n        Path p \u003d new Path(\"har:///\"\n            + thisNodeFile.getPath().toUri().getRawPath());\n        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n        continue;\n      }\n      if (!thisNodeFile.getPath().getName()\n        .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d\n            new AggregatedLogFormat.LogReader(getConf(), thisNodeFile.getPath());\n        try {\n\n          DataInputStream valueStream;\n          LogKey key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n\n          while (valueStream !\u003d null) {\n\n            String containerString \u003d\n                \"\\n\\nContainer: \" + key + \" on \" + thisNodeFile.getPath().getName();\n            out.println(containerString);\n            out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n            while (true) {\n              try {\n                LogReader.readAContainerLogsForALogType(valueStream, out,\n                  thisNodeFile.getModificationTime());\n                foundAnyLogs \u003d true;\n              } catch (EOFException eof) {\n                break;\n              }\n            }\n\n            // Next container\n            key \u003d new LogKey();\n            valueStream \u003d reader.next(key);\n          }\n        } finally {\n          reader.close();\n        }\n      }\n    }\n    if (! foundAnyLogs) {\n      emptyLogDir(remoteAppLogDir.toString());\n      return -1;\n    }\n    return 0;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "58e9f24e0f06efede21085b7ffe36af042fa7b38": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2788. Fixed backwards compatiblity issues with log-aggregation feature that were caused when adding log-upload-time via YARN-2703. Contributed by Xuan Gong.\n",
      "commitDate": "03/11/14 1:16 PM",
      "commitName": "58e9f24e0f06efede21085b7ffe36af042fa7b38",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "20/10/14 10:21 PM",
      "commitNameOld": "171f2376d23d51b61b9c9b3804ee86dbd4de033a",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 13.66,
      "commitsBetweenForRepo": 138,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,64 @@\n   public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n       PrintStream out) throws IOException {\n     Path remoteRootLogDir \u003d new Path(getConf().get(\n         YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n         YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String user \u003d appOwner;\n     String logDirSuffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n     // TODO Change this to get a list of files from the LAS.\n     Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n         remoteRootLogDir, appId, user, logDirSuffix);\n     RemoteIterator\u003cFileStatus\u003e nodeFiles;\n     try {\n       Path qualifiedLogDir \u003d\n           FileContext.getFileContext(getConf()).makeQualified(remoteAppLogDir);\n       nodeFiles \u003d FileContext.getFileContext(qualifiedLogDir.toUri(),\n           getConf()).listStatus(remoteAppLogDir);\n     } catch (FileNotFoundException fnf) {\n       logDirNotExist(remoteAppLogDir.toString());\n       return -1;\n     }\n     boolean foundAnyLogs \u003d false;\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       if (!thisNodeFile.getPath().getName()\n         .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n         AggregatedLogFormat.LogReader reader \u003d\n             new AggregatedLogFormat.LogReader(getConf(), thisNodeFile.getPath());\n         try {\n \n           DataInputStream valueStream;\n           LogKey key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n \n           while (valueStream !\u003d null) {\n+\n             String containerString \u003d\n                 \"\\n\\nContainer: \" + key + \" on \" + thisNodeFile.getPath().getName();\n             out.println(containerString);\n             out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n             while (true) {\n               try {\n-                LogReader.readAContainerLogsForALogType(valueStream, out);\n+                LogReader.readAContainerLogsForALogType(valueStream, out,\n+                  thisNodeFile.getModificationTime());\n                 foundAnyLogs \u003d true;\n               } catch (EOFException eof) {\n                 break;\n               }\n             }\n \n             // Next container\n             key \u003d new LogKey();\n             valueStream \u003d reader.next(key);\n           }\n         } finally {\n           reader.close();\n         }\n       }\n     }\n     if (! foundAnyLogs) {\n       emptyLogDir(remoteAppLogDir.toString());\n       return -1;\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      PrintStream out) throws IOException {\n    Path remoteRootLogDir \u003d new Path(getConf().get(\n        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user \u003d appOwner;\n    String logDirSuffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    // TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n        remoteRootLogDir, appId, user, logDirSuffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n    try {\n      Path qualifiedLogDir \u003d\n          FileContext.getFileContext(getConf()).makeQualified(remoteAppLogDir);\n      nodeFiles \u003d FileContext.getFileContext(qualifiedLogDir.toUri(),\n          getConf()).listStatus(remoteAppLogDir);\n    } catch (FileNotFoundException fnf) {\n      logDirNotExist(remoteAppLogDir.toString());\n      return -1;\n    }\n    boolean foundAnyLogs \u003d false;\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      if (!thisNodeFile.getPath().getName()\n        .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d\n            new AggregatedLogFormat.LogReader(getConf(), thisNodeFile.getPath());\n        try {\n\n          DataInputStream valueStream;\n          LogKey key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n\n          while (valueStream !\u003d null) {\n\n            String containerString \u003d\n                \"\\n\\nContainer: \" + key + \" on \" + thisNodeFile.getPath().getName();\n            out.println(containerString);\n            out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n            while (true) {\n              try {\n                LogReader.readAContainerLogsForALogType(valueStream, out,\n                  thisNodeFile.getModificationTime());\n                foundAnyLogs \u003d true;\n              } catch (EOFException eof) {\n                break;\n              }\n            }\n\n            // Next container\n            key \u003d new LogKey();\n            valueStream \u003d reader.next(key);\n          }\n        } finally {\n          reader.close();\n        }\n      }\n    }\n    if (! foundAnyLogs) {\n      emptyLogDir(remoteAppLogDir.toString());\n      return -1;\n    }\n    return 0;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "e90718fa5a0e7c18592af61534668acebb9db51b": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2582. Fixed Log CLI and Web UI for showing aggregated logs of LRS. Contributed Xuan Gong.\n",
      "commitDate": "20/10/14 1:38 PM",
      "commitName": "e90718fa5a0e7c18592af61534668acebb9db51b",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "20/05/14 9:19 AM",
      "commitNameOld": "64ec743e6c5384a7b68e4f9852ed12e261643c1f",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 153.18,
      "commitsBetweenForRepo": 1320,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,55 +1,62 @@\n   public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n       PrintStream out) throws IOException {\n     Path remoteRootLogDir \u003d new Path(getConf().get(\n         YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n         YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String user \u003d appOwner;\n     String logDirSuffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n     // TODO Change this to get a list of files from the LAS.\n     Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n         remoteRootLogDir, appId, user, logDirSuffix);\n     RemoteIterator\u003cFileStatus\u003e nodeFiles;\n     try {\n       Path qualifiedLogDir \u003d\n           FileContext.getFileContext(getConf()).makeQualified(remoteAppLogDir);\n       nodeFiles \u003d FileContext.getFileContext(qualifiedLogDir.toUri(),\n           getConf()).listStatus(remoteAppLogDir);\n     } catch (FileNotFoundException fnf) {\n-      System.out.println(\"Logs not available at \" + remoteAppLogDir.toString());\n-      System.out\n-          .println(\"Log aggregation has not completed or is not enabled.\");\n+      logDirNotExist(remoteAppLogDir.toString());\n       return -1;\n     }\n+    boolean foundAnyLogs \u003d false;\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n-      AggregatedLogFormat.LogReader reader \u003d new AggregatedLogFormat.LogReader(\n-          getConf(), new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n-      try {\n+      if (!thisNodeFile.getPath().getName()\n+        .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n+        AggregatedLogFormat.LogReader reader \u003d\n+            new AggregatedLogFormat.LogReader(getConf(), thisNodeFile.getPath());\n+        try {\n \n-        DataInputStream valueStream;\n-        LogKey key \u003d new LogKey();\n-        valueStream \u003d reader.next(key);\n-\n-        while (valueStream !\u003d null) {\n-          String containerString \u003d \"\\n\\nContainer: \" + key + \" on \"\n-              + thisNodeFile.getPath().getName();\n-          out.println(containerString);\n-          out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n-          while (true) {\n-            try {\n-              LogReader.readAContainerLogsForALogType(valueStream, out);\n-            } catch (EOFException eof) {\n-              break;\n-            }\n-          }\n-\n-          // Next container\n-          key \u003d new LogKey();\n+          DataInputStream valueStream;\n+          LogKey key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n+\n+          while (valueStream !\u003d null) {\n+            String containerString \u003d\n+                \"\\n\\nContainer: \" + key + \" on \" + thisNodeFile.getPath().getName();\n+            out.println(containerString);\n+            out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n+            while (true) {\n+              try {\n+                LogReader.readAContainerLogsForALogType(valueStream, out);\n+                foundAnyLogs \u003d true;\n+              } catch (EOFException eof) {\n+                break;\n+              }\n+            }\n+\n+            // Next container\n+            key \u003d new LogKey();\n+            valueStream \u003d reader.next(key);\n+          }\n+        } finally {\n+          reader.close();\n         }\n-      } finally {\n-        reader.close();\n       }\n     }\n+    if (! foundAnyLogs) {\n+      emptyLogDir(remoteAppLogDir.toString());\n+      return -1;\n+    }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      PrintStream out) throws IOException {\n    Path remoteRootLogDir \u003d new Path(getConf().get(\n        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user \u003d appOwner;\n    String logDirSuffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    // TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n        remoteRootLogDir, appId, user, logDirSuffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n    try {\n      Path qualifiedLogDir \u003d\n          FileContext.getFileContext(getConf()).makeQualified(remoteAppLogDir);\n      nodeFiles \u003d FileContext.getFileContext(qualifiedLogDir.toUri(),\n          getConf()).listStatus(remoteAppLogDir);\n    } catch (FileNotFoundException fnf) {\n      logDirNotExist(remoteAppLogDir.toString());\n      return -1;\n    }\n    boolean foundAnyLogs \u003d false;\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      if (!thisNodeFile.getPath().getName()\n        .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d\n            new AggregatedLogFormat.LogReader(getConf(), thisNodeFile.getPath());\n        try {\n\n          DataInputStream valueStream;\n          LogKey key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n\n          while (valueStream !\u003d null) {\n            String containerString \u003d\n                \"\\n\\nContainer: \" + key + \" on \" + thisNodeFile.getPath().getName();\n            out.println(containerString);\n            out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n            while (true) {\n              try {\n                LogReader.readAContainerLogsForALogType(valueStream, out);\n                foundAnyLogs \u003d true;\n              } catch (EOFException eof) {\n                break;\n              }\n            }\n\n            // Next container\n            key \u003d new LogKey();\n            valueStream \u003d reader.next(key);\n          }\n        } finally {\n          reader.close();\n        }\n      }\n    }\n    if (! foundAnyLogs) {\n      emptyLogDir(remoteAppLogDir.toString());\n      return -1;\n    }\n    return 0;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "64ec743e6c5384a7b68e4f9852ed12e261643c1f": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2050. Fix LogCLIHelpers to create the correct FileContext. Contributed by Ming Ma\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1596310 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/05/14 9:19 AM",
      "commitName": "64ec743e6c5384a7b68e4f9852ed12e261643c1f",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "03/10/13 7:36 PM",
      "commitNameOld": "6ff600d9e3496008d81361c17ea427a8675cd0d4",
      "commitAuthorOld": "Hitesh Shah",
      "daysBetweenCommits": 228.57,
      "commitsBetweenForRepo": 1551,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,52 +1,55 @@\n   public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n       PrintStream out) throws IOException {\n     Path remoteRootLogDir \u003d new Path(getConf().get(\n         YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n         YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String user \u003d appOwner;\n     String logDirSuffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n     // TODO Change this to get a list of files from the LAS.\n     Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n         remoteRootLogDir, appId, user, logDirSuffix);\n     RemoteIterator\u003cFileStatus\u003e nodeFiles;\n     try {\n-      nodeFiles \u003d FileContext.getFileContext().listStatus(remoteAppLogDir);\n+      Path qualifiedLogDir \u003d\n+          FileContext.getFileContext(getConf()).makeQualified(remoteAppLogDir);\n+      nodeFiles \u003d FileContext.getFileContext(qualifiedLogDir.toUri(),\n+          getConf()).listStatus(remoteAppLogDir);\n     } catch (FileNotFoundException fnf) {\n       System.out.println(\"Logs not available at \" + remoteAppLogDir.toString());\n       System.out\n           .println(\"Log aggregation has not completed or is not enabled.\");\n       return -1;\n     }\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       AggregatedLogFormat.LogReader reader \u003d new AggregatedLogFormat.LogReader(\n           getConf(), new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n       try {\n \n         DataInputStream valueStream;\n         LogKey key \u003d new LogKey();\n         valueStream \u003d reader.next(key);\n \n         while (valueStream !\u003d null) {\n           String containerString \u003d \"\\n\\nContainer: \" + key + \" on \"\n               + thisNodeFile.getPath().getName();\n           out.println(containerString);\n           out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n           while (true) {\n             try {\n               LogReader.readAContainerLogsForALogType(valueStream, out);\n             } catch (EOFException eof) {\n               break;\n             }\n           }\n \n           // Next container\n           key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n         }\n       } finally {\n         reader.close();\n       }\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      PrintStream out) throws IOException {\n    Path remoteRootLogDir \u003d new Path(getConf().get(\n        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user \u003d appOwner;\n    String logDirSuffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    // TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n        remoteRootLogDir, appId, user, logDirSuffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n    try {\n      Path qualifiedLogDir \u003d\n          FileContext.getFileContext(getConf()).makeQualified(remoteAppLogDir);\n      nodeFiles \u003d FileContext.getFileContext(qualifiedLogDir.toUri(),\n          getConf()).listStatus(remoteAppLogDir);\n    } catch (FileNotFoundException fnf) {\n      System.out.println(\"Logs not available at \" + remoteAppLogDir.toString());\n      System.out\n          .println(\"Log aggregation has not completed or is not enabled.\");\n      return -1;\n    }\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d new AggregatedLogFormat.LogReader(\n          getConf(), new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          String containerString \u003d \"\\n\\nContainer: \" + key + \" on \"\n              + thisNodeFile.getPath().getName();\n          out.println(containerString);\n          out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n    return 0;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
      "extendedDetails": {}
    },
    "6ff600d9e3496008d81361c17ea427a8675cd0d4": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange)",
      "commitMessage": "YARN-1131.  logs command should return an appropriate error message if YARN application is still running. Contributed by Siddharth Seth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1529068 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/10/13 7:36 PM",
      "commitName": "6ff600d9e3496008d81361c17ea427a8675cd0d4",
      "commitAuthor": "Hitesh Shah",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "YARN-1131.  logs command should return an appropriate error message if YARN application is still running. Contributed by Siddharth Seth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1529068 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "03/10/13 7:36 PM",
          "commitName": "6ff600d9e3496008d81361c17ea427a8675cd0d4",
          "commitAuthor": "Hitesh Shah",
          "commitDateOld": "03/10/13 6:30 PM",
          "commitNameOld": "d8ea364d07f782f8693b1ac0c340d4bd8d471c32",
          "commitAuthorOld": "Sanford Ryza",
          "daysBetweenCommits": 0.05,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,55 +1,52 @@\n-  private int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n+  public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n       PrintStream out) throws IOException {\n-    Path remoteRootLogDir \u003d\n-        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n-            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n+    Path remoteRootLogDir \u003d new Path(getConf().get(\n+        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n+        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String user \u003d appOwner;\n-    String logDirSuffix \u003d\n-        LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n-    //TODO Change this to get a list of files from the LAS.\n-    Path remoteAppLogDir \u003d\n-        LogAggregationUtils.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n-            logDirSuffix);\n+    String logDirSuffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n+    // TODO Change this to get a list of files from the LAS.\n+    Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n+        remoteRootLogDir, appId, user, logDirSuffix);\n     RemoteIterator\u003cFileStatus\u003e nodeFiles;\n     try {\n       nodeFiles \u003d FileContext.getFileContext().listStatus(remoteAppLogDir);\n     } catch (FileNotFoundException fnf) {\n-      System.out.println(\"Logs not available at \"\n-          + remoteAppLogDir.toString());\n-      System.out.println(\n-          \"Log aggregation has not completed or is not enabled.\");\n+      System.out.println(\"Logs not available at \" + remoteAppLogDir.toString());\n+      System.out\n+          .println(\"Log aggregation has not completed or is not enabled.\");\n       return -1;\n     }\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n-      AggregatedLogFormat.LogReader reader \u003d\n-          new AggregatedLogFormat.LogReader(getConf(),\n-              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n+      AggregatedLogFormat.LogReader reader \u003d new AggregatedLogFormat.LogReader(\n+          getConf(), new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n       try {\n \n         DataInputStream valueStream;\n         LogKey key \u003d new LogKey();\n         valueStream \u003d reader.next(key);\n \n         while (valueStream !\u003d null) {\n-          String containerString \u003d \"\\n\\nContainer: \" + key + \" on \" + thisNodeFile.getPath().getName();\n+          String containerString \u003d \"\\n\\nContainer: \" + key + \" on \"\n+              + thisNodeFile.getPath().getName();\n           out.println(containerString);\n           out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n           while (true) {\n             try {\n               LogReader.readAContainerLogsForALogType(valueStream, out);\n             } catch (EOFException eof) {\n               break;\n             }\n           }\n \n           // Next container\n           key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n         }\n       } finally {\n         reader.close();\n       }\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      PrintStream out) throws IOException {\n    Path remoteRootLogDir \u003d new Path(getConf().get(\n        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user \u003d appOwner;\n    String logDirSuffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    // TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n        remoteRootLogDir, appId, user, logDirSuffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n    try {\n      nodeFiles \u003d FileContext.getFileContext().listStatus(remoteAppLogDir);\n    } catch (FileNotFoundException fnf) {\n      System.out.println(\"Logs not available at \" + remoteAppLogDir.toString());\n      System.out\n          .println(\"Log aggregation has not completed or is not enabled.\");\n      return -1;\n    }\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d new AggregatedLogFormat.LogReader(\n          getConf(), new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          String containerString \u003d \"\\n\\nContainer: \" + key + \" on \"\n              + thisNodeFile.getPath().getName();\n          out.println(containerString);\n          out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n    return 0;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
          "extendedDetails": {
            "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java",
            "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
            "oldMethodName": "dumpAllContainersLogs",
            "newMethodName": "dumpAllContainersLogs"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-1131.  logs command should return an appropriate error message if YARN application is still running. Contributed by Siddharth Seth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1529068 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "03/10/13 7:36 PM",
          "commitName": "6ff600d9e3496008d81361c17ea427a8675cd0d4",
          "commitAuthor": "Hitesh Shah",
          "commitDateOld": "03/10/13 6:30 PM",
          "commitNameOld": "d8ea364d07f782f8693b1ac0c340d4bd8d471c32",
          "commitAuthorOld": "Sanford Ryza",
          "daysBetweenCommits": 0.05,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,55 +1,52 @@\n-  private int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n+  public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n       PrintStream out) throws IOException {\n-    Path remoteRootLogDir \u003d\n-        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n-            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n+    Path remoteRootLogDir \u003d new Path(getConf().get(\n+        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n+        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String user \u003d appOwner;\n-    String logDirSuffix \u003d\n-        LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n-    //TODO Change this to get a list of files from the LAS.\n-    Path remoteAppLogDir \u003d\n-        LogAggregationUtils.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n-            logDirSuffix);\n+    String logDirSuffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n+    // TODO Change this to get a list of files from the LAS.\n+    Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n+        remoteRootLogDir, appId, user, logDirSuffix);\n     RemoteIterator\u003cFileStatus\u003e nodeFiles;\n     try {\n       nodeFiles \u003d FileContext.getFileContext().listStatus(remoteAppLogDir);\n     } catch (FileNotFoundException fnf) {\n-      System.out.println(\"Logs not available at \"\n-          + remoteAppLogDir.toString());\n-      System.out.println(\n-          \"Log aggregation has not completed or is not enabled.\");\n+      System.out.println(\"Logs not available at \" + remoteAppLogDir.toString());\n+      System.out\n+          .println(\"Log aggregation has not completed or is not enabled.\");\n       return -1;\n     }\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n-      AggregatedLogFormat.LogReader reader \u003d\n-          new AggregatedLogFormat.LogReader(getConf(),\n-              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n+      AggregatedLogFormat.LogReader reader \u003d new AggregatedLogFormat.LogReader(\n+          getConf(), new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n       try {\n \n         DataInputStream valueStream;\n         LogKey key \u003d new LogKey();\n         valueStream \u003d reader.next(key);\n \n         while (valueStream !\u003d null) {\n-          String containerString \u003d \"\\n\\nContainer: \" + key + \" on \" + thisNodeFile.getPath().getName();\n+          String containerString \u003d \"\\n\\nContainer: \" + key + \" on \"\n+              + thisNodeFile.getPath().getName();\n           out.println(containerString);\n           out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n           while (true) {\n             try {\n               LogReader.readAContainerLogsForALogType(valueStream, out);\n             } catch (EOFException eof) {\n               break;\n             }\n           }\n \n           // Next container\n           key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n         }\n       } finally {\n         reader.close();\n       }\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      PrintStream out) throws IOException {\n    Path remoteRootLogDir \u003d new Path(getConf().get(\n        YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n        YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user \u003d appOwner;\n    String logDirSuffix \u003d LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    // TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir \u003d LogAggregationUtils.getRemoteAppLogDir(\n        remoteRootLogDir, appId, user, logDirSuffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n    try {\n      nodeFiles \u003d FileContext.getFileContext().listStatus(remoteAppLogDir);\n    } catch (FileNotFoundException fnf) {\n      System.out.println(\"Logs not available at \" + remoteAppLogDir.toString());\n      System.out\n          .println(\"Log aggregation has not completed or is not enabled.\");\n      return -1;\n    }\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d new AggregatedLogFormat.LogReader(\n          getConf(), new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          String containerString \u003d \"\\n\\nContainer: \" + key + \" on \"\n              + thisNodeFile.getPath().getName();\n          out.println(containerString);\n          out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n    return 0;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogCLIHelpers.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[public]"
          }
        }
      ]
    },
    "67699c2d187a8480a46acf5031652ff19196823d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-200. yarn log does not output all needed information, and is in a binary format. Contributed by Ravi Prakash\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1458466 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/03/13 12:29 PM",
      "commitName": "67699c2d187a8480a46acf5031652ff19196823d",
      "commitAuthor": "Jason Darrell Lowe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-200. yarn log does not output all needed information, and is in a binary format. Contributed by Ravi Prakash\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1458466 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "19/03/13 12:29 PM",
          "commitName": "67699c2d187a8480a46acf5031652ff19196823d",
          "commitAuthor": "Jason Darrell Lowe",
          "commitDateOld": "07/08/12 10:22 PM",
          "commitNameOld": "e1fdf62123625e4ba399af02f8aad500637d29d1",
          "commitAuthorOld": "Arun Murthy",
          "daysBetweenCommits": 223.59,
          "commitsBetweenForRepo": 1140,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,52 +1,55 @@\n   private int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n-      DataOutputStream out) throws IOException {\n+      PrintStream out) throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String user \u003d appOwner;\n     String logDirSuffix \u003d\n         LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n     //TODO Change this to get a list of files from the LAS.\n     Path remoteAppLogDir \u003d\n         LogAggregationUtils.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n             logDirSuffix);\n     RemoteIterator\u003cFileStatus\u003e nodeFiles;\n     try {\n       nodeFiles \u003d FileContext.getFileContext().listStatus(remoteAppLogDir);\n     } catch (FileNotFoundException fnf) {\n       System.out.println(\"Logs not available at \"\n           + remoteAppLogDir.toString());\n       System.out.println(\n           \"Log aggregation has not completed or is not enabled.\");\n       return -1;\n     }\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       AggregatedLogFormat.LogReader reader \u003d\n           new AggregatedLogFormat.LogReader(getConf(),\n               new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n       try {\n \n         DataInputStream valueStream;\n         LogKey key \u003d new LogKey();\n         valueStream \u003d reader.next(key);\n \n         while (valueStream !\u003d null) {\n+          String containerString \u003d \"\\n\\nContainer: \" + key + \" on \" + thisNodeFile.getPath().getName();\n+          out.println(containerString);\n+          out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n           while (true) {\n             try {\n               LogReader.readAContainerLogsForALogType(valueStream, out);\n             } catch (EOFException eof) {\n               break;\n             }\n           }\n \n           // Next container\n           key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n         }\n       } finally {\n         reader.close();\n       }\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      PrintStream out) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user \u003d appOwner;\n    String logDirSuffix \u003d\n        LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    //TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir \u003d\n        LogAggregationUtils.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n            logDirSuffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n    try {\n      nodeFiles \u003d FileContext.getFileContext().listStatus(remoteAppLogDir);\n    } catch (FileNotFoundException fnf) {\n      System.out.println(\"Logs not available at \"\n          + remoteAppLogDir.toString());\n      System.out.println(\n          \"Log aggregation has not completed or is not enabled.\");\n      return -1;\n    }\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d\n          new AggregatedLogFormat.LogReader(getConf(),\n              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          String containerString \u003d \"\\n\\nContainer: \" + key + \" on \" + thisNodeFile.getPath().getName();\n          out.println(containerString);\n          out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n    return 0;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java",
          "extendedDetails": {
            "oldValue": "[appId-ApplicationId, appOwner-String, out-DataOutputStream]",
            "newValue": "[appId-ApplicationId, appOwner-String, out-PrintStream]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-200. yarn log does not output all needed information, and is in a binary format. Contributed by Ravi Prakash\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1458466 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "19/03/13 12:29 PM",
          "commitName": "67699c2d187a8480a46acf5031652ff19196823d",
          "commitAuthor": "Jason Darrell Lowe",
          "commitDateOld": "07/08/12 10:22 PM",
          "commitNameOld": "e1fdf62123625e4ba399af02f8aad500637d29d1",
          "commitAuthorOld": "Arun Murthy",
          "daysBetweenCommits": 223.59,
          "commitsBetweenForRepo": 1140,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,52 +1,55 @@\n   private int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n-      DataOutputStream out) throws IOException {\n+      PrintStream out) throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String user \u003d appOwner;\n     String logDirSuffix \u003d\n         LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n     //TODO Change this to get a list of files from the LAS.\n     Path remoteAppLogDir \u003d\n         LogAggregationUtils.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n             logDirSuffix);\n     RemoteIterator\u003cFileStatus\u003e nodeFiles;\n     try {\n       nodeFiles \u003d FileContext.getFileContext().listStatus(remoteAppLogDir);\n     } catch (FileNotFoundException fnf) {\n       System.out.println(\"Logs not available at \"\n           + remoteAppLogDir.toString());\n       System.out.println(\n           \"Log aggregation has not completed or is not enabled.\");\n       return -1;\n     }\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       AggregatedLogFormat.LogReader reader \u003d\n           new AggregatedLogFormat.LogReader(getConf(),\n               new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n       try {\n \n         DataInputStream valueStream;\n         LogKey key \u003d new LogKey();\n         valueStream \u003d reader.next(key);\n \n         while (valueStream !\u003d null) {\n+          String containerString \u003d \"\\n\\nContainer: \" + key + \" on \" + thisNodeFile.getPath().getName();\n+          out.println(containerString);\n+          out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n           while (true) {\n             try {\n               LogReader.readAContainerLogsForALogType(valueStream, out);\n             } catch (EOFException eof) {\n               break;\n             }\n           }\n \n           // Next container\n           key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n         }\n       } finally {\n         reader.close();\n       }\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      PrintStream out) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user \u003d appOwner;\n    String logDirSuffix \u003d\n        LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    //TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir \u003d\n        LogAggregationUtils.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n            logDirSuffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n    try {\n      nodeFiles \u003d FileContext.getFileContext().listStatus(remoteAppLogDir);\n    } catch (FileNotFoundException fnf) {\n      System.out.println(\"Logs not available at \"\n          + remoteAppLogDir.toString());\n      System.out.println(\n          \"Log aggregation has not completed or is not enabled.\");\n      return -1;\n    }\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d\n          new AggregatedLogFormat.LogReader(getConf(),\n              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          String containerString \u003d \"\\n\\nContainer: \" + key + \" on \" + thisNodeFile.getPath().getName();\n          out.println(containerString);\n          out.println(StringUtils.repeat(\"\u003d\", containerString.length()));\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n    return 0;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java",
          "extendedDetails": {}
        }
      ]
    },
    "e1fdf62123625e4ba399af02f8aad500637d29d1": {
      "type": "Yfilerename",
      "commitMessage": "YARN-1. Promote YARN to be a sub-project of Apache Hadoop.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370666 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/12 10:22 PM",
      "commitName": "e1fdf62123625e4ba399af02f8aad500637d29d1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "07/08/12 7:53 PM",
      "commitNameOld": "34554d1e11ee1d5b564d7d9ed3e6d55931d72749",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      DataOutputStream out) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user \u003d appOwner;\n    String logDirSuffix \u003d\n        LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    //TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir \u003d\n        LogAggregationUtils.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n            logDirSuffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n    try {\n      nodeFiles \u003d FileContext.getFileContext().listStatus(remoteAppLogDir);\n    } catch (FileNotFoundException fnf) {\n      System.out.println(\"Logs not available at \"\n          + remoteAppLogDir.toString());\n      System.out.println(\n          \"Log aggregation has not completed or is not enabled.\");\n      return -1;\n    }\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d\n          new AggregatedLogFormat.LogReader(getConf(),\n              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n    return 0;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java"
      }
    },
    "6ba0375b21c4ce07d2b6b592c4963f705c35222b": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "MAPREDUCE-3744. Fix the yarn logs command line. Improve error messages for mapred job -logs. (Contributed by Jason Lowe)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1239433 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/02/12 5:43 PM",
      "commitName": "6ba0375b21c4ce07d2b6b592c4963f705c35222b",
      "commitAuthor": "Siddharth Seth",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "MAPREDUCE-3744. Fix the yarn logs command line. Improve error messages for mapred job -logs. (Contributed by Jason Lowe)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1239433 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "01/02/12 5:43 PM",
          "commitName": "6ba0375b21c4ce07d2b6b592c4963f705c35222b",
          "commitAuthor": "Siddharth Seth",
          "commitDateOld": "03/11/11 1:02 AM",
          "commitNameOld": "c27601fefebd0af887a12d684bfc6f90d9fc0321",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 90.74,
          "commitsBetweenForRepo": 447,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,52 @@\n-  private void dumpAllContainersLogs(ApplicationId appId, String appOwner,\n+  private int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n       DataOutputStream out) throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String user \u003d appOwner;\n     String logDirSuffix \u003d\n-        getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n-            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n+        LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n     //TODO Change this to get a list of files from the LAS.\n     Path remoteAppLogDir \u003d\n         LogAggregationUtils.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n             logDirSuffix);\n-    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n-        FileContext.getFileContext().listStatus(remoteAppLogDir);\n+    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n+    try {\n+      nodeFiles \u003d FileContext.getFileContext().listStatus(remoteAppLogDir);\n+    } catch (FileNotFoundException fnf) {\n+      System.out.println(\"Logs not available at \"\n+          + remoteAppLogDir.toString());\n+      System.out.println(\n+          \"Log aggregation has not completed or is not enabled.\");\n+      return -1;\n+    }\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       AggregatedLogFormat.LogReader reader \u003d\n           new AggregatedLogFormat.LogReader(getConf(),\n               new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n       try {\n \n         DataInputStream valueStream;\n         LogKey key \u003d new LogKey();\n         valueStream \u003d reader.next(key);\n \n         while (valueStream !\u003d null) {\n           while (true) {\n             try {\n               LogReader.readAContainerLogsForALogType(valueStream, out);\n             } catch (EOFException eof) {\n               break;\n             }\n           }\n \n           // Next container\n           key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n         }\n       } finally {\n         reader.close();\n       }\n     }\n+    return 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      DataOutputStream out) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user \u003d appOwner;\n    String logDirSuffix \u003d\n        LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    //TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir \u003d\n        LogAggregationUtils.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n            logDirSuffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n    try {\n      nodeFiles \u003d FileContext.getFileContext().listStatus(remoteAppLogDir);\n    } catch (FileNotFoundException fnf) {\n      System.out.println(\"Logs not available at \"\n          + remoteAppLogDir.toString());\n      System.out.println(\n          \"Log aggregation has not completed or is not enabled.\");\n      return -1;\n    }\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d\n          new AggregatedLogFormat.LogReader(getConf(),\n              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n    return 0;\n  }",
          "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java",
          "extendedDetails": {
            "oldValue": "void",
            "newValue": "int"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-3744. Fix the yarn logs command line. Improve error messages for mapred job -logs. (Contributed by Jason Lowe)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1239433 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "01/02/12 5:43 PM",
          "commitName": "6ba0375b21c4ce07d2b6b592c4963f705c35222b",
          "commitAuthor": "Siddharth Seth",
          "commitDateOld": "03/11/11 1:02 AM",
          "commitNameOld": "c27601fefebd0af887a12d684bfc6f90d9fc0321",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 90.74,
          "commitsBetweenForRepo": 447,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,52 @@\n-  private void dumpAllContainersLogs(ApplicationId appId, String appOwner,\n+  private int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n       DataOutputStream out) throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String user \u003d appOwner;\n     String logDirSuffix \u003d\n-        getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n-            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n+        LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n     //TODO Change this to get a list of files from the LAS.\n     Path remoteAppLogDir \u003d\n         LogAggregationUtils.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n             logDirSuffix);\n-    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n-        FileContext.getFileContext().listStatus(remoteAppLogDir);\n+    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n+    try {\n+      nodeFiles \u003d FileContext.getFileContext().listStatus(remoteAppLogDir);\n+    } catch (FileNotFoundException fnf) {\n+      System.out.println(\"Logs not available at \"\n+          + remoteAppLogDir.toString());\n+      System.out.println(\n+          \"Log aggregation has not completed or is not enabled.\");\n+      return -1;\n+    }\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       AggregatedLogFormat.LogReader reader \u003d\n           new AggregatedLogFormat.LogReader(getConf(),\n               new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n       try {\n \n         DataInputStream valueStream;\n         LogKey key \u003d new LogKey();\n         valueStream \u003d reader.next(key);\n \n         while (valueStream !\u003d null) {\n           while (true) {\n             try {\n               LogReader.readAContainerLogsForALogType(valueStream, out);\n             } catch (EOFException eof) {\n               break;\n             }\n           }\n \n           // Next container\n           key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n         }\n       } finally {\n         reader.close();\n       }\n     }\n+    return 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      DataOutputStream out) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user \u003d appOwner;\n    String logDirSuffix \u003d\n        LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    //TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir \u003d\n        LogAggregationUtils.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n            logDirSuffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles;\n    try {\n      nodeFiles \u003d FileContext.getFileContext().listStatus(remoteAppLogDir);\n    } catch (FileNotFoundException fnf) {\n      System.out.println(\"Logs not available at \"\n          + remoteAppLogDir.toString());\n      System.out.println(\n          \"Log aggregation has not completed or is not enabled.\");\n      return -1;\n    }\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d\n          new AggregatedLogFormat.LogReader(getConf(),\n              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n    return 0;\n  }",
          "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java",
          "extendedDetails": {}
        }
      ]
    },
    "c27601fefebd0af887a12d684bfc6f90d9fc0321": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "MAPREDUCE-3297. Moved log related components into yarn-common so that HistoryServer and clients can use them without depending on the yarn-server-nodemanager module. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1196986 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/11/11 1:02 AM",
      "commitName": "c27601fefebd0af887a12d684bfc6f90d9fc0321",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "MAPREDUCE-3297. Moved log related components into yarn-common so that HistoryServer and clients can use them without depending on the yarn-server-nodemanager module. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1196986 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "03/11/11 1:02 AM",
          "commitName": "c27601fefebd0af887a12d684bfc6f90d9fc0321",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/11/11 12:06 AM",
          "commitNameOld": "0df4878033b797b9313c887ca9d75f8ea104d029",
          "commitAuthorOld": "Arun Murthy",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,44 @@\n   private void dumpAllContainersLogs(ApplicationId appId, String appOwner,\n       DataOutputStream out) throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String user \u003d appOwner;\n     String logDirSuffix \u003d\n         getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n     //TODO Change this to get a list of files from the LAS.\n     Path remoteAppLogDir \u003d\n-        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n+        LogAggregationUtils.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n             logDirSuffix);\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n         FileContext.getFileContext().listStatus(remoteAppLogDir);\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       AggregatedLogFormat.LogReader reader \u003d\n           new AggregatedLogFormat.LogReader(getConf(),\n               new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n       try {\n \n         DataInputStream valueStream;\n         LogKey key \u003d new LogKey();\n         valueStream \u003d reader.next(key);\n \n         while (valueStream !\u003d null) {\n           while (true) {\n             try {\n               LogReader.readAContainerLogsForALogType(valueStream, out);\n             } catch (EOFException eof) {\n               break;\n             }\n           }\n \n           // Next container\n           key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n         }\n       } finally {\n         reader.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      DataOutputStream out) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user \u003d appOwner;\n    String logDirSuffix \u003d\n        getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n    //TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir \u003d\n        LogAggregationUtils.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n            logDirSuffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n        FileContext.getFileContext().listStatus(remoteAppLogDir);\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d\n          new AggregatedLogFormat.LogReader(getConf(),\n              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java",
          "extendedDetails": {
            "oldPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java",
            "newPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-3297. Moved log related components into yarn-common so that HistoryServer and clients can use them without depending on the yarn-server-nodemanager module. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1196986 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "03/11/11 1:02 AM",
          "commitName": "c27601fefebd0af887a12d684bfc6f90d9fc0321",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/11/11 12:06 AM",
          "commitNameOld": "0df4878033b797b9313c887ca9d75f8ea104d029",
          "commitAuthorOld": "Arun Murthy",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,44 @@\n   private void dumpAllContainersLogs(ApplicationId appId, String appOwner,\n       DataOutputStream out) throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     String user \u003d appOwner;\n     String logDirSuffix \u003d\n         getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n     //TODO Change this to get a list of files from the LAS.\n     Path remoteAppLogDir \u003d\n-        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n+        LogAggregationUtils.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n             logDirSuffix);\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n         FileContext.getFileContext().listStatus(remoteAppLogDir);\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       AggregatedLogFormat.LogReader reader \u003d\n           new AggregatedLogFormat.LogReader(getConf(),\n               new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n       try {\n \n         DataInputStream valueStream;\n         LogKey key \u003d new LogKey();\n         valueStream \u003d reader.next(key);\n \n         while (valueStream !\u003d null) {\n           while (true) {\n             try {\n               LogReader.readAContainerLogsForALogType(valueStream, out);\n             } catch (EOFException eof) {\n               break;\n             }\n           }\n \n           // Next container\n           key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n         }\n       } finally {\n         reader.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      DataOutputStream out) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user \u003d appOwner;\n    String logDirSuffix \u003d\n        getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n    //TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir \u003d\n        LogAggregationUtils.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n            logDirSuffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n        FileContext.getFileContext().listStatus(remoteAppLogDir);\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d\n          new AggregatedLogFormat.LogReader(getConf(),\n              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogDumper.java",
          "extendedDetails": {}
        }
      ]
    },
    "47a381e306877750b5a3ce5d76e0a5ff652ec188": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "MAPREDUCE-3146. Added a MR specific command line to dump logs for a given TaskAttemptID. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195349 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/10/11 11:42 PM",
      "commitName": "47a381e306877750b5a3ce5d76e0a5ff652ec188",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-3146. Added a MR specific command line to dump logs for a given TaskAttemptID. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195349 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/10/11 11:42 PM",
          "commitName": "47a381e306877750b5a3ce5d76e0a5ff652ec188",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "27/10/11 11:45 PM",
          "commitNameOld": "670fa24b48acb407c22fbfdde87ae3123dcbf449",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 3.0,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,44 @@\n-      dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n-          throws IOException {\n+  private void dumpAllContainersLogs(ApplicationId appId, String appOwner,\n+      DataOutputStream out) throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n-    String user \u003d UserGroupInformation.getCurrentUser().getShortUserName();\n+    String user \u003d appOwner;\n     String logDirSuffix \u003d\n         getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n     //TODO Change this to get a list of files from the LAS.\n     Path remoteAppLogDir \u003d\n         LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n             logDirSuffix);\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n         FileContext.getFileContext().listStatus(remoteAppLogDir);\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       AggregatedLogFormat.LogReader reader \u003d\n           new AggregatedLogFormat.LogReader(getConf(),\n               new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n       try {\n \n         DataInputStream valueStream;\n         LogKey key \u003d new LogKey();\n         valueStream \u003d reader.next(key);\n \n         while (valueStream !\u003d null) {\n           while (true) {\n             try {\n               LogReader.readAContainerLogsForALogType(valueStream, out);\n             } catch (EOFException eof) {\n               break;\n             }\n           }\n \n           // Next container\n           key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n         }\n       } finally {\n         reader.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      DataOutputStream out) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user \u003d appOwner;\n    String logDirSuffix \u003d\n        getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n    //TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir \u003d\n        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n            logDirSuffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n        FileContext.getFileContext().listStatus(remoteAppLogDir);\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d\n          new AggregatedLogFormat.LogReader(getConf(),\n              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java",
          "extendedDetails": {
            "oldValue": "[appId-ApplicationId, out-DataOutputStream]",
            "newValue": "[appId-ApplicationId, appOwner-String, out-DataOutputStream]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-3146. Added a MR specific command line to dump logs for a given TaskAttemptID. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195349 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/10/11 11:42 PM",
          "commitName": "47a381e306877750b5a3ce5d76e0a5ff652ec188",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "27/10/11 11:45 PM",
          "commitNameOld": "670fa24b48acb407c22fbfdde87ae3123dcbf449",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 3.0,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,44 @@\n-      dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n-          throws IOException {\n+  private void dumpAllContainersLogs(ApplicationId appId, String appOwner,\n+      DataOutputStream out) throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n-    String user \u003d UserGroupInformation.getCurrentUser().getShortUserName();\n+    String user \u003d appOwner;\n     String logDirSuffix \u003d\n         getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n     //TODO Change this to get a list of files from the LAS.\n     Path remoteAppLogDir \u003d\n         LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n             logDirSuffix);\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n         FileContext.getFileContext().listStatus(remoteAppLogDir);\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       AggregatedLogFormat.LogReader reader \u003d\n           new AggregatedLogFormat.LogReader(getConf(),\n               new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n       try {\n \n         DataInputStream valueStream;\n         LogKey key \u003d new LogKey();\n         valueStream \u003d reader.next(key);\n \n         while (valueStream !\u003d null) {\n           while (true) {\n             try {\n               LogReader.readAContainerLogsForALogType(valueStream, out);\n             } catch (EOFException eof) {\n               break;\n             }\n           }\n \n           // Next container\n           key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n         }\n       } finally {\n         reader.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      DataOutputStream out) throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user \u003d appOwner;\n    String logDirSuffix \u003d\n        getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n    //TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir \u003d\n        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n            logDirSuffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n        FileContext.getFileContext().listStatus(remoteAppLogDir);\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d\n          new AggregatedLogFormat.LogReader(getConf(),\n              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java",
          "extendedDetails": {}
        }
      ]
    },
    "670fa24b48acb407c22fbfdde87ae3123dcbf449": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2989. Modified JobHistory to link to task and AM logs from the JobHistoryServer. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1190174 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/10/11 11:45 PM",
      "commitName": "670fa24b48acb407c22fbfdde87ae3123dcbf449",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "08/09/11 6:44 PM",
      "commitNameOld": "fafe8cd28e726566509c679e19d7da622f29f90d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 49.21,
      "commitsBetweenForRepo": 395,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,44 @@\n       dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n           throws IOException {\n     Path remoteRootLogDir \u003d\n         new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n             YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n+    String user \u003d UserGroupInformation.getCurrentUser().getShortUserName();\n+    String logDirSuffix \u003d\n+        getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n+            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n+    //TODO Change this to get a list of files from the LAS.\n     Path remoteAppLogDir \u003d\n-        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId);\n+        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n+            logDirSuffix);\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n         FileContext.getFileContext().listStatus(remoteAppLogDir);\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       AggregatedLogFormat.LogReader reader \u003d\n           new AggregatedLogFormat.LogReader(getConf(),\n-              LogAggregationService.getRemoteNodeLogFileForApp(\n-                  remoteRootLogDir, appId, thisNodeFile.getPath().getName()));\n+              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n       try {\n \n         DataInputStream valueStream;\n         LogKey key \u003d new LogKey();\n         valueStream \u003d reader.next(key);\n \n         while (valueStream !\u003d null) {\n           while (true) {\n             try {\n               LogReader.readAContainerLogsForALogType(valueStream, out);\n             } catch (EOFException eof) {\n               break;\n             }\n           }\n \n           // Next container\n           key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n         }\n       } finally {\n         reader.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "      dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n          throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user \u003d UserGroupInformation.getCurrentUser().getShortUserName();\n    String logDirSuffix \u003d\n        getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n    //TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir \u003d\n        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n            logDirSuffix);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n        FileContext.getFileContext().listStatus(remoteAppLogDir);\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d\n          new AggregatedLogFormat.LogReader(getConf(),\n              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java",
      "extendedDetails": {}
    },
    "fafe8cd28e726566509c679e19d7da622f29f90d": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2864. Normalize configuration variable names for YARN. Contributed by Robert Evans.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1166955 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/09/11 6:44 PM",
      "commitName": "fafe8cd28e726566509c679e19d7da622f29f90d",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 15.06,
      "commitsBetweenForRepo": 86,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,39 @@\n       dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n           throws IOException {\n     Path remoteRootLogDir \u003d\n-        new Path(getConf().get(NMConfig.REMOTE_USER_LOG_DIR,\n-            NMConfig.DEFAULT_REMOTE_APP_LOG_DIR));\n+        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n+            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n     Path remoteAppLogDir \u003d\n         LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId);\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n         FileContext.getFileContext().listStatus(remoteAppLogDir);\n     while (nodeFiles.hasNext()) {\n       FileStatus thisNodeFile \u003d nodeFiles.next();\n       AggregatedLogFormat.LogReader reader \u003d\n           new AggregatedLogFormat.LogReader(getConf(),\n               LogAggregationService.getRemoteNodeLogFileForApp(\n                   remoteRootLogDir, appId, thisNodeFile.getPath().getName()));\n       try {\n \n         DataInputStream valueStream;\n         LogKey key \u003d new LogKey();\n         valueStream \u003d reader.next(key);\n \n         while (valueStream !\u003d null) {\n           while (true) {\n             try {\n               LogReader.readAContainerLogsForALogType(valueStream, out);\n             } catch (EOFException eof) {\n               break;\n             }\n           }\n \n           // Next container\n           key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n         }\n       } finally {\n         reader.close();\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "      dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n          throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    Path remoteAppLogDir \u003d\n        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n        FileContext.getFileContext().listStatus(remoteAppLogDir);\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d\n          new AggregatedLogFormat.LogReader(getConf(),\n              LogAggregationService.getRemoteNodeLogFileForApp(\n                  remoteRootLogDir, appId, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "      dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n          throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(NMConfig.REMOTE_USER_LOG_DIR,\n            NMConfig.DEFAULT_REMOTE_APP_LOG_DIR));\n    Path remoteAppLogDir \u003d\n        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n        FileContext.getFileContext().listStatus(remoteAppLogDir);\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d\n          new AggregatedLogFormat.LogReader(getConf(),\n              LogAggregationService.getRemoteNodeLogFileForApp(\n                  remoteRootLogDir, appId, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java",
        "newPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,39 @@\n+      dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n+          throws IOException {\n+    Path remoteRootLogDir \u003d\n+        new Path(getConf().get(NMConfig.REMOTE_USER_LOG_DIR,\n+            NMConfig.DEFAULT_REMOTE_APP_LOG_DIR));\n+    Path remoteAppLogDir \u003d\n+        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId);\n+    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n+        FileContext.getFileContext().listStatus(remoteAppLogDir);\n+    while (nodeFiles.hasNext()) {\n+      FileStatus thisNodeFile \u003d nodeFiles.next();\n+      AggregatedLogFormat.LogReader reader \u003d\n+          new AggregatedLogFormat.LogReader(getConf(),\n+              LogAggregationService.getRemoteNodeLogFileForApp(\n+                  remoteRootLogDir, appId, thisNodeFile.getPath().getName()));\n+      try {\n+\n+        DataInputStream valueStream;\n+        LogKey key \u003d new LogKey();\n+        valueStream \u003d reader.next(key);\n+\n+        while (valueStream !\u003d null) {\n+          while (true) {\n+            try {\n+              LogReader.readAContainerLogsForALogType(valueStream, out);\n+            } catch (EOFException eof) {\n+              break;\n+            }\n+          }\n+\n+          // Next container\n+          key \u003d new LogKey();\n+          valueStream \u003d reader.next(key);\n+        }\n+      } finally {\n+        reader.close();\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "      dumpAllContainersLogs(ApplicationId appId, DataOutputStream out)\n          throws IOException {\n    Path remoteRootLogDir \u003d\n        new Path(getConf().get(NMConfig.REMOTE_USER_LOG_DIR,\n            NMConfig.DEFAULT_REMOTE_APP_LOG_DIR));\n    Path remoteAppLogDir \u003d\n        LogAggregationService.getRemoteAppLogDir(remoteRootLogDir, appId);\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d\n        FileContext.getFileContext().listStatus(remoteAppLogDir);\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile \u003d nodeFiles.next();\n      AggregatedLogFormat.LogReader reader \u003d\n          new AggregatedLogFormat.LogReader(getConf(),\n              LogAggregationService.getRemoteNodeLogFileForApp(\n                  remoteRootLogDir, appId, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key \u003d new LogKey();\n        valueStream \u003d reader.next(key);\n\n        while (valueStream !\u003d null) {\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n  }",
      "path": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java"
    }
  }
}