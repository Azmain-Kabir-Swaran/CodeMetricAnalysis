{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "QueuePriorityContainerCandidateSelector.java",
  "functionName": "canPreemptEnoughResourceForAsked",
  "functionId": "canPreemptEnoughResourceForAsked___requiredResource-Resource__demandingQueue-String__schedulerNode-FiCaSchedulerNode__lookingForNewReservationPlacement-boolean__newlySelectedContainers-List__RMContainer__",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/QueuePriorityContainerCandidateSelector.java",
  "functionStartLine": 185,
  "functionEndLine": 273,
  "numCommitsSeen": 8,
  "timeTaken": 2072,
  "changeHistory": [
    "e81596d06d226f1cfa44b2390ce3095ed4dee621",
    "ce832059db077fa95922198b066a737ed4f609fe"
  ],
  "changeHistoryShort": {
    "e81596d06d226f1cfa44b2390ce3095ed4dee621": "Ybodychange",
    "ce832059db077fa95922198b066a737ed4f609fe": "Yintroduced"
  },
  "changeHistoryDetails": {
    "e81596d06d226f1cfa44b2390ce3095ed4dee621": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7172. ResourceCalculator.fitsIn() should not take a cluster resource parameter. (Sen Zhao via wangda)\n\nChange-Id: Icc3670c9381ce7591ca69ec12da5aa52d3612d34\n",
      "commitDate": "17/09/17 9:20 PM",
      "commitName": "e81596d06d226f1cfa44b2390ce3095ed4dee621",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "11/05/17 11:03 AM",
      "commitNameOld": "4aae2d40a3e2e732e09b4b8a82623cacc0dc8861",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 129.43,
      "commitsBetweenForRepo": 870,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,89 @@\n   private boolean canPreemptEnoughResourceForAsked(Resource requiredResource,\n       String demandingQueue, FiCaSchedulerNode schedulerNode,\n       boolean lookingForNewReservationPlacement,\n       List\u003cRMContainer\u003e newlySelectedContainers) {\n     // Do not check touched nodes again.\n     if (touchedNodes.contains(schedulerNode.getNodeID())) {\n       return false;\n     }\n \n     TempSchedulerNode node \u003d tempSchedulerNodeMap.get(schedulerNode.getNodeID());\n     if (null \u003d\u003d node) {\n       node \u003d TempSchedulerNode.fromSchedulerNode(schedulerNode);\n       tempSchedulerNodeMap.put(schedulerNode.getNodeID(), node);\n     }\n \n     if (null !\u003d schedulerNode.getReservedContainer()\n         \u0026\u0026 lookingForNewReservationPlacement) {\n       // Node reserved by the others, skip this node\n       // We will not try to move the reservation to node which reserved already.\n       return false;\n     }\n \n     // Need to preemption \u003d asked - (node.total - node.allocated)\n     Resource lacking \u003d Resources.subtract(requiredResource, Resources\n         .subtract(node.getTotalResource(), node.getAllocatedResource()));\n \n     // On each host, simply check if we could preempt containers from\n     // lower-prioritized queues or not\n     List\u003cRMContainer\u003e runningContainers \u003d node.getRunningContainers();\n     Collections.sort(runningContainers, CONTAINER_CREATION_TIME_COMPARATOR);\n \n     // First of all, consider already selected containers\n     for (RMContainer runningContainer : runningContainers) {\n       if (CapacitySchedulerPreemptionUtils.isContainerAlreadySelected(\n           runningContainer, selectedCandidates)) {\n         Resources.subtractFrom(lacking,\n             runningContainer.getAllocatedResource());\n       }\n     }\n \n     // If we already can allocate the reserved container after preemption,\n     // skip following steps\n-    if (Resources.fitsIn(rc, clusterResource, lacking,\n-        Resources.none())) {\n+    if (Resources.fitsIn(rc, lacking, Resources.none())) {\n       return true;\n     }\n \n     Resource allowed \u003d Resources.clone(totalPreemptionAllowed);\n     Resource selected \u003d Resources.createResource(0);\n \n     for (RMContainer runningContainer : runningContainers) {\n       if (CapacitySchedulerPreemptionUtils.isContainerAlreadySelected(\n           runningContainer, selectedCandidates)) {\n         // ignore selected containers\n         continue;\n       }\n \n       // Only preempt resource from queue with lower priority\n       if (!preemptionAllowed(demandingQueue,\n           runningContainer.getQueueName())) {\n         continue;\n       }\n \n       // Don\u0027t preempt AM container\n       if (runningContainer.isAMContainer()) {\n         continue;\n       }\n \n       // Not allow to preempt more than limit\n       if (Resources.greaterThanOrEqual(rc, clusterResource, allowed,\n           runningContainer.getAllocatedResource())) {\n         Resources.subtractFrom(allowed,\n             runningContainer.getAllocatedResource());\n         Resources.subtractFrom(lacking,\n             runningContainer.getAllocatedResource());\n         Resources.addTo(selected, runningContainer.getAllocatedResource());\n \n         if (null !\u003d newlySelectedContainers) {\n           newlySelectedContainers.add(runningContainer);\n         }\n       }\n \n       // Lacking \u003c\u003d 0 means we can allocate the reserved container\n-      if (Resources.fitsIn(rc, clusterResource, lacking, Resources.none())) {\n+      if (Resources.fitsIn(rc, lacking, Resources.none())) {\n         return true;\n       }\n     }\n \n     return false;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean canPreemptEnoughResourceForAsked(Resource requiredResource,\n      String demandingQueue, FiCaSchedulerNode schedulerNode,\n      boolean lookingForNewReservationPlacement,\n      List\u003cRMContainer\u003e newlySelectedContainers) {\n    // Do not check touched nodes again.\n    if (touchedNodes.contains(schedulerNode.getNodeID())) {\n      return false;\n    }\n\n    TempSchedulerNode node \u003d tempSchedulerNodeMap.get(schedulerNode.getNodeID());\n    if (null \u003d\u003d node) {\n      node \u003d TempSchedulerNode.fromSchedulerNode(schedulerNode);\n      tempSchedulerNodeMap.put(schedulerNode.getNodeID(), node);\n    }\n\n    if (null !\u003d schedulerNode.getReservedContainer()\n        \u0026\u0026 lookingForNewReservationPlacement) {\n      // Node reserved by the others, skip this node\n      // We will not try to move the reservation to node which reserved already.\n      return false;\n    }\n\n    // Need to preemption \u003d asked - (node.total - node.allocated)\n    Resource lacking \u003d Resources.subtract(requiredResource, Resources\n        .subtract(node.getTotalResource(), node.getAllocatedResource()));\n\n    // On each host, simply check if we could preempt containers from\n    // lower-prioritized queues or not\n    List\u003cRMContainer\u003e runningContainers \u003d node.getRunningContainers();\n    Collections.sort(runningContainers, CONTAINER_CREATION_TIME_COMPARATOR);\n\n    // First of all, consider already selected containers\n    for (RMContainer runningContainer : runningContainers) {\n      if (CapacitySchedulerPreemptionUtils.isContainerAlreadySelected(\n          runningContainer, selectedCandidates)) {\n        Resources.subtractFrom(lacking,\n            runningContainer.getAllocatedResource());\n      }\n    }\n\n    // If we already can allocate the reserved container after preemption,\n    // skip following steps\n    if (Resources.fitsIn(rc, lacking, Resources.none())) {\n      return true;\n    }\n\n    Resource allowed \u003d Resources.clone(totalPreemptionAllowed);\n    Resource selected \u003d Resources.createResource(0);\n\n    for (RMContainer runningContainer : runningContainers) {\n      if (CapacitySchedulerPreemptionUtils.isContainerAlreadySelected(\n          runningContainer, selectedCandidates)) {\n        // ignore selected containers\n        continue;\n      }\n\n      // Only preempt resource from queue with lower priority\n      if (!preemptionAllowed(demandingQueue,\n          runningContainer.getQueueName())) {\n        continue;\n      }\n\n      // Don\u0027t preempt AM container\n      if (runningContainer.isAMContainer()) {\n        continue;\n      }\n\n      // Not allow to preempt more than limit\n      if (Resources.greaterThanOrEqual(rc, clusterResource, allowed,\n          runningContainer.getAllocatedResource())) {\n        Resources.subtractFrom(allowed,\n            runningContainer.getAllocatedResource());\n        Resources.subtractFrom(lacking,\n            runningContainer.getAllocatedResource());\n        Resources.addTo(selected, runningContainer.getAllocatedResource());\n\n        if (null !\u003d newlySelectedContainers) {\n          newlySelectedContainers.add(runningContainer);\n        }\n      }\n\n      // Lacking \u003c\u003d 0 means we can allocate the reserved container\n      if (Resources.fitsIn(rc, lacking, Resources.none())) {\n        return true;\n      }\n    }\n\n    return false;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/QueuePriorityContainerCandidateSelector.java",
      "extendedDetails": {}
    },
    "ce832059db077fa95922198b066a737ed4f609fe": {
      "type": "Yintroduced",
      "commitMessage": "YARN-5864. Capacity Scheduler - Queue Priorities. (wangda)\n",
      "commitDate": "23/01/17 10:52 AM",
      "commitName": "ce832059db077fa95922198b066a737ed4f609fe",
      "commitAuthor": "Wangda Tan",
      "diff": "@@ -0,0 +1,90 @@\n+  private boolean canPreemptEnoughResourceForAsked(Resource requiredResource,\n+      String demandingQueue, FiCaSchedulerNode schedulerNode,\n+      boolean lookingForNewReservationPlacement,\n+      List\u003cRMContainer\u003e newlySelectedContainers) {\n+    // Do not check touched nodes again.\n+    if (touchedNodes.contains(schedulerNode.getNodeID())) {\n+      return false;\n+    }\n+\n+    TempSchedulerNode node \u003d tempSchedulerNodeMap.get(schedulerNode.getNodeID());\n+    if (null \u003d\u003d node) {\n+      node \u003d TempSchedulerNode.fromSchedulerNode(schedulerNode);\n+      tempSchedulerNodeMap.put(schedulerNode.getNodeID(), node);\n+    }\n+\n+    if (null !\u003d schedulerNode.getReservedContainer()\n+        \u0026\u0026 lookingForNewReservationPlacement) {\n+      // Node reserved by the others, skip this node\n+      // We will not try to move the reservation to node which reserved already.\n+      return false;\n+    }\n+\n+    // Need to preemption \u003d asked - (node.total - node.allocated)\n+    Resource lacking \u003d Resources.subtract(requiredResource, Resources\n+        .subtract(node.getTotalResource(), node.getAllocatedResource()));\n+\n+    // On each host, simply check if we could preempt containers from\n+    // lower-prioritized queues or not\n+    List\u003cRMContainer\u003e runningContainers \u003d node.getRunningContainers();\n+    Collections.sort(runningContainers, CONTAINER_CREATION_TIME_COMPARATOR);\n+\n+    // First of all, consider already selected containers\n+    for (RMContainer runningContainer : runningContainers) {\n+      if (CapacitySchedulerPreemptionUtils.isContainerAlreadySelected(\n+          runningContainer, selectedCandidates)) {\n+        Resources.subtractFrom(lacking,\n+            runningContainer.getAllocatedResource());\n+      }\n+    }\n+\n+    // If we already can allocate the reserved container after preemption,\n+    // skip following steps\n+    if (Resources.fitsIn(rc, clusterResource, lacking,\n+        Resources.none())) {\n+      return true;\n+    }\n+\n+    Resource allowed \u003d Resources.clone(totalPreemptionAllowed);\n+    Resource selected \u003d Resources.createResource(0);\n+\n+    for (RMContainer runningContainer : runningContainers) {\n+      if (CapacitySchedulerPreemptionUtils.isContainerAlreadySelected(\n+          runningContainer, selectedCandidates)) {\n+        // ignore selected containers\n+        continue;\n+      }\n+\n+      // Only preempt resource from queue with lower priority\n+      if (!preemptionAllowed(demandingQueue,\n+          runningContainer.getQueueName())) {\n+        continue;\n+      }\n+\n+      // Don\u0027t preempt AM container\n+      if (runningContainer.isAMContainer()) {\n+        continue;\n+      }\n+\n+      // Not allow to preempt more than limit\n+      if (Resources.greaterThanOrEqual(rc, clusterResource, allowed,\n+          runningContainer.getAllocatedResource())) {\n+        Resources.subtractFrom(allowed,\n+            runningContainer.getAllocatedResource());\n+        Resources.subtractFrom(lacking,\n+            runningContainer.getAllocatedResource());\n+        Resources.addTo(selected, runningContainer.getAllocatedResource());\n+\n+        if (null !\u003d newlySelectedContainers) {\n+          newlySelectedContainers.add(runningContainer);\n+        }\n+      }\n+\n+      // Lacking \u003c\u003d 0 means we can allocate the reserved container\n+      if (Resources.fitsIn(rc, clusterResource, lacking, Resources.none())) {\n+        return true;\n+      }\n+    }\n+\n+    return false;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean canPreemptEnoughResourceForAsked(Resource requiredResource,\n      String demandingQueue, FiCaSchedulerNode schedulerNode,\n      boolean lookingForNewReservationPlacement,\n      List\u003cRMContainer\u003e newlySelectedContainers) {\n    // Do not check touched nodes again.\n    if (touchedNodes.contains(schedulerNode.getNodeID())) {\n      return false;\n    }\n\n    TempSchedulerNode node \u003d tempSchedulerNodeMap.get(schedulerNode.getNodeID());\n    if (null \u003d\u003d node) {\n      node \u003d TempSchedulerNode.fromSchedulerNode(schedulerNode);\n      tempSchedulerNodeMap.put(schedulerNode.getNodeID(), node);\n    }\n\n    if (null !\u003d schedulerNode.getReservedContainer()\n        \u0026\u0026 lookingForNewReservationPlacement) {\n      // Node reserved by the others, skip this node\n      // We will not try to move the reservation to node which reserved already.\n      return false;\n    }\n\n    // Need to preemption \u003d asked - (node.total - node.allocated)\n    Resource lacking \u003d Resources.subtract(requiredResource, Resources\n        .subtract(node.getTotalResource(), node.getAllocatedResource()));\n\n    // On each host, simply check if we could preempt containers from\n    // lower-prioritized queues or not\n    List\u003cRMContainer\u003e runningContainers \u003d node.getRunningContainers();\n    Collections.sort(runningContainers, CONTAINER_CREATION_TIME_COMPARATOR);\n\n    // First of all, consider already selected containers\n    for (RMContainer runningContainer : runningContainers) {\n      if (CapacitySchedulerPreemptionUtils.isContainerAlreadySelected(\n          runningContainer, selectedCandidates)) {\n        Resources.subtractFrom(lacking,\n            runningContainer.getAllocatedResource());\n      }\n    }\n\n    // If we already can allocate the reserved container after preemption,\n    // skip following steps\n    if (Resources.fitsIn(rc, clusterResource, lacking,\n        Resources.none())) {\n      return true;\n    }\n\n    Resource allowed \u003d Resources.clone(totalPreemptionAllowed);\n    Resource selected \u003d Resources.createResource(0);\n\n    for (RMContainer runningContainer : runningContainers) {\n      if (CapacitySchedulerPreemptionUtils.isContainerAlreadySelected(\n          runningContainer, selectedCandidates)) {\n        // ignore selected containers\n        continue;\n      }\n\n      // Only preempt resource from queue with lower priority\n      if (!preemptionAllowed(demandingQueue,\n          runningContainer.getQueueName())) {\n        continue;\n      }\n\n      // Don\u0027t preempt AM container\n      if (runningContainer.isAMContainer()) {\n        continue;\n      }\n\n      // Not allow to preempt more than limit\n      if (Resources.greaterThanOrEqual(rc, clusterResource, allowed,\n          runningContainer.getAllocatedResource())) {\n        Resources.subtractFrom(allowed,\n            runningContainer.getAllocatedResource());\n        Resources.subtractFrom(lacking,\n            runningContainer.getAllocatedResource());\n        Resources.addTo(selected, runningContainer.getAllocatedResource());\n\n        if (null !\u003d newlySelectedContainers) {\n          newlySelectedContainers.add(runningContainer);\n        }\n      }\n\n      // Lacking \u003c\u003d 0 means we can allocate the reserved container\n      if (Resources.fitsIn(rc, clusterResource, lacking, Resources.none())) {\n        return true;\n      }\n    }\n\n    return false;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/QueuePriorityContainerCandidateSelector.java"
    }
  }
}