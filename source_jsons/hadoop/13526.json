{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockInfoStriped.java",
  "functionName": "spaceConsumed",
  "functionId": "spaceConsumed",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.java",
  "functionStartLine": 207,
  "functionEndLine": 214,
  "numCommitsSeen": 30,
  "timeTaken": 2891,
  "changeHistory": [
    "c09dc258a8f64fab852bf6f26187163480dbee3c",
    "1d37a8812160bb030244a1e6b1c753f962d8d2ed",
    "744ef1779202621b2034b97926ad7ebcc67f433a",
    "77d94dd5ece2b12b0dfcc7e3b3094318115779b5",
    "ab76e1fe36b52f291c70630ca1cd0861b74fc20f",
    "91c741a2a171129638071306482c019d007972ab",
    "abf833a7b228fff2bca4f69cd9df99d532380038",
    "26773d9d6c10479982a3cdbea3a0933f4476add3"
  ],
  "changeHistoryShort": {
    "c09dc258a8f64fab852bf6f26187163480dbee3c": "Ybodychange",
    "1d37a8812160bb030244a1e6b1c753f962d8d2ed": "Ybodychange",
    "744ef1779202621b2034b97926ad7ebcc67f433a": "Ybodychange",
    "77d94dd5ece2b12b0dfcc7e3b3094318115779b5": "Ybodychange",
    "ab76e1fe36b52f291c70630ca1cd0861b74fc20f": "Ybodychange",
    "91c741a2a171129638071306482c019d007972ab": "Ybodychange",
    "abf833a7b228fff2bca4f69cd9df99d532380038": "Ybodychange",
    "26773d9d6c10479982a3cdbea3a0933f4476add3": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c09dc258a8f64fab852bf6f26187163480dbee3c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8882. Erasure Coding: Use datablocks, parityblocks and cell size from ErasureCodingPolicy. Contributed by Vinayakumar B.\n\nChange-Id: Ic56da0b426f47c63dac440aef6f5fc8554f6cf13\n",
      "commitDate": "23/09/15 1:34 PM",
      "commitName": "c09dc258a8f64fab852bf6f26187163480dbee3c",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "01/09/15 2:48 PM",
      "commitNameOld": "53358fe680a11c1b66a7f60733d11c1f4efe0232",
      "commitAuthorOld": "",
      "daysBetweenCommits": 21.95,
      "commitsBetweenForRepo": 141,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,8 @@\n   public long spaceConsumed() {\n     // In case striped blocks, total usage by this striped blocks should\n     // be the total of data blocks and parity blocks because\n     // `getNumBytes` is the total of actual data block size.\n     return StripedBlockUtil.spaceConsumedByStripedBlock(getNumBytes(),\n         ecPolicy.getNumDataUnits(), ecPolicy.getNumParityUnits(),\n-        BLOCK_STRIPED_CELL_SIZE);\n+        ecPolicy.getCellSize());\n     }\n\\ No newline at end of file\n",
      "actualSource": "  public long spaceConsumed() {\n    // In case striped blocks, total usage by this striped blocks should\n    // be the total of data blocks and parity blocks because\n    // `getNumBytes` is the total of actual data block size.\n    return StripedBlockUtil.spaceConsumedByStripedBlock(getNumBytes(),\n        ecPolicy.getNumDataUnits(), ecPolicy.getNumParityUnits(),\n        ecPolicy.getCellSize());\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.java",
      "extendedDetails": {}
    },
    "1d37a8812160bb030244a1e6b1c753f962d8d2ed": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8854. Erasure coding: add ECPolicy to replace schema+cellSize in hadoop-hdfs. Contributed by Walter Su.\n",
      "commitDate": "13/08/15 10:04 AM",
      "commitName": "1d37a8812160bb030244a1e6b1c753f962d8d2ed",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "15/07/15 8:13 PM",
      "commitNameOld": "4fdd9abd7e43a0fb7b569982954a8f9660b9268b",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 28.58,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,8 @@\n   public long spaceConsumed() {\n     // In case striped blocks, total usage by this striped blocks should\n     // be the total of data blocks and parity blocks because\n     // `getNumBytes` is the total of actual data block size.\n     return StripedBlockUtil.spaceConsumedByStripedBlock(getNumBytes(),\n-        this.schema.getNumDataUnits(), this.schema.getNumParityUnits(),\n+        ecPolicy.getNumDataUnits(), ecPolicy.getNumParityUnits(),\n         BLOCK_STRIPED_CELL_SIZE);\n     }\n\\ No newline at end of file\n",
      "actualSource": "  public long spaceConsumed() {\n    // In case striped blocks, total usage by this striped blocks should\n    // be the total of data blocks and parity blocks because\n    // `getNumBytes` is the total of actual data block size.\n    return StripedBlockUtil.spaceConsumedByStripedBlock(getNumBytes(),\n        ecPolicy.getNumDataUnits(), ecPolicy.getNumParityUnits(),\n        BLOCK_STRIPED_CELL_SIZE);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.java",
      "extendedDetails": {}
    },
    "744ef1779202621b2034b97926ad7ebcc67f433a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8427. Remove dataBlockNum and parityBlockNum from BlockInfoStriped. Contributed by Kai Sasaki.\n",
      "commitDate": "26/05/15 12:02 PM",
      "commitName": "744ef1779202621b2034b97926ad7ebcc67f433a",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "26/05/15 12:02 PM",
      "commitNameOld": "c9103e9cacc67a614940e32fa87c5dbc3daa60de",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,8 @@\n   public long spaceConsumed() {\n     // In case striped blocks, total usage by this striped blocks should\n     // be the total of data blocks and parity blocks because\n     // `getNumBytes` is the total of actual data block size.\n     return StripedBlockUtil.spaceConsumedByStripedBlock(getNumBytes(),\n-        dataBlockNum, parityBlockNum, BLOCK_STRIPED_CELL_SIZE);\n+        this.schema.getNumDataUnits(), this.schema.getNumParityUnits(),\n+        BLOCK_STRIPED_CELL_SIZE);\n     }\n\\ No newline at end of file\n",
      "actualSource": "  public long spaceConsumed() {\n    // In case striped blocks, total usage by this striped blocks should\n    // be the total of data blocks and parity blocks because\n    // `getNumBytes` is the total of actual data block size.\n    return StripedBlockUtil.spaceConsumedByStripedBlock(getNumBytes(),\n        this.schema.getNumDataUnits(), this.schema.getNumParityUnits(),\n        BLOCK_STRIPED_CELL_SIZE);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.java",
      "extendedDetails": {}
    },
    "77d94dd5ece2b12b0dfcc7e3b3094318115779b5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7949. WebImageViewer need support file size calculation with striped blocks. Contributed by Rakesh R.\n",
      "commitDate": "26/05/15 11:59 AM",
      "commitName": "77d94dd5ece2b12b0dfcc7e3b3094318115779b5",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "26/05/15 11:59 AM",
      "commitNameOld": "f6e1160ef1e946a5f6c9503b06832e6b84c36edb",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,7 @@\n   public long spaceConsumed() {\n     // In case striped blocks, total usage by this striped blocks should\n     // be the total of data blocks and parity blocks because\n     // `getNumBytes` is the total of actual data block size.\n-\n-    // 0. Calculate the total bytes per stripes \u003cNum Bytes per Stripes\u003e\n-    long numBytesPerStripe \u003d dataBlockNum * BLOCK_STRIPED_CELL_SIZE;\n-    if (getNumBytes() % numBytesPerStripe \u003d\u003d 0) {\n-      return getNumBytes() / dataBlockNum * getTotalBlockNum();\n-    }\n-    // 1. Calculate the number of stripes in this block group. \u003cNum Stripes\u003e\n-    long numStripes \u003d (getNumBytes() - 1) / numBytesPerStripe + 1;\n-    // 2. Calculate the parity cell length in the last stripe. Note that the\n-    //    size of parity cells should equal the size of the first cell, if it\n-    //    is not full. \u003cLast Stripe Parity Cell Length\u003e\n-    long lastStripeParityCellLen \u003d Math.min(getNumBytes() % numBytesPerStripe,\n-        BLOCK_STRIPED_CELL_SIZE);\n-    // 3. Total consumed space is the total of\n-    //     - The total of the full cells of data blocks and parity blocks.\n-    //     - The remaining of data block which does not make a stripe.\n-    //     - The last parity block cells. These size should be same\n-    //       to the first cell in this stripe.\n-    return getTotalBlockNum() * (BLOCK_STRIPED_CELL_SIZE * (numStripes - 1))\n-        + getNumBytes() % numBytesPerStripe\n-        + lastStripeParityCellLen * parityBlockNum;\n-  }\n\\ No newline at end of file\n+    return StripedBlockUtil.spaceConsumedByStripedBlock(getNumBytes(),\n+        dataBlockNum, parityBlockNum, BLOCK_STRIPED_CELL_SIZE);\n+    }\n\\ No newline at end of file\n",
      "actualSource": "  public long spaceConsumed() {\n    // In case striped blocks, total usage by this striped blocks should\n    // be the total of data blocks and parity blocks because\n    // `getNumBytes` is the total of actual data block size.\n    return StripedBlockUtil.spaceConsumedByStripedBlock(getNumBytes(),\n        dataBlockNum, parityBlockNum, BLOCK_STRIPED_CELL_SIZE);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.java",
      "extendedDetails": {}
    },
    "ab76e1fe36b52f291c70630ca1cd0861b74fc20f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7937. Erasure Coding: INodeFile quota computation unit tests. Contributed by Kai Sasaki.\n",
      "commitDate": "26/05/15 11:59 AM",
      "commitName": "ab76e1fe36b52f291c70630ca1cd0861b74fc20f",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "26/05/15 11:55 AM",
      "commitNameOld": "91c741a2a171129638071306482c019d007972ab",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,26 @@\n   public long spaceConsumed() {\n     // In case striped blocks, total usage by this striped blocks should\n     // be the total of data blocks and parity blocks because\n     // `getNumBytes` is the total of actual data block size.\n-    return ((getNumBytes() - 1) / (dataBlockNum * BLOCK_STRIPED_CELL_SIZE) + 1)\n-        * BLOCK_STRIPED_CELL_SIZE * parityBlockNum + getNumBytes();\n+\n+    // 0. Calculate the total bytes per stripes \u003cNum Bytes per Stripes\u003e\n+    long numBytesPerStripe \u003d dataBlockNum * BLOCK_STRIPED_CELL_SIZE;\n+    if (getNumBytes() % numBytesPerStripe \u003d\u003d 0) {\n+      return getNumBytes() / dataBlockNum * getTotalBlockNum();\n+    }\n+    // 1. Calculate the number of stripes in this block group. \u003cNum Stripes\u003e\n+    long numStripes \u003d (getNumBytes() - 1) / numBytesPerStripe + 1;\n+    // 2. Calculate the parity cell length in the last stripe. Note that the\n+    //    size of parity cells should equal the size of the first cell, if it\n+    //    is not full. \u003cLast Stripe Parity Cell Length\u003e\n+    long lastStripeParityCellLen \u003d Math.min(getNumBytes() % numBytesPerStripe,\n+        BLOCK_STRIPED_CELL_SIZE);\n+    // 3. Total consumed space is the total of\n+    //     - The total of the full cells of data blocks and parity blocks.\n+    //     - The remaining of data block which does not make a stripe.\n+    //     - The last parity block cells. These size should be same\n+    //       to the first cell in this stripe.\n+    return getTotalBlockNum() * (BLOCK_STRIPED_CELL_SIZE * (numStripes - 1))\n+        + getNumBytes() % numBytesPerStripe\n+        + lastStripeParityCellLen * parityBlockNum;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public long spaceConsumed() {\n    // In case striped blocks, total usage by this striped blocks should\n    // be the total of data blocks and parity blocks because\n    // `getNumBytes` is the total of actual data block size.\n\n    // 0. Calculate the total bytes per stripes \u003cNum Bytes per Stripes\u003e\n    long numBytesPerStripe \u003d dataBlockNum * BLOCK_STRIPED_CELL_SIZE;\n    if (getNumBytes() % numBytesPerStripe \u003d\u003d 0) {\n      return getNumBytes() / dataBlockNum * getTotalBlockNum();\n    }\n    // 1. Calculate the number of stripes in this block group. \u003cNum Stripes\u003e\n    long numStripes \u003d (getNumBytes() - 1) / numBytesPerStripe + 1;\n    // 2. Calculate the parity cell length in the last stripe. Note that the\n    //    size of parity cells should equal the size of the first cell, if it\n    //    is not full. \u003cLast Stripe Parity Cell Length\u003e\n    long lastStripeParityCellLen \u003d Math.min(getNumBytes() % numBytesPerStripe,\n        BLOCK_STRIPED_CELL_SIZE);\n    // 3. Total consumed space is the total of\n    //     - The total of the full cells of data blocks and parity blocks.\n    //     - The remaining of data block which does not make a stripe.\n    //     - The last parity block cells. These size should be same\n    //       to the first cell in this stripe.\n    return getTotalBlockNum() * (BLOCK_STRIPED_CELL_SIZE * (numStripes - 1))\n        + getNumBytes() % numBytesPerStripe\n        + lastStripeParityCellLen * parityBlockNum;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.java",
      "extendedDetails": {}
    },
    "91c741a2a171129638071306482c019d007972ab": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7782. Erasure coding: pread from files in striped layout. Contributed by Zhe Zhang and Jing Zhao\n",
      "commitDate": "26/05/15 11:55 AM",
      "commitName": "91c741a2a171129638071306482c019d007972ab",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "26/05/15 11:43 AM",
      "commitNameOld": "abf833a7b228fff2bca4f69cd9df99d532380038",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n   public long spaceConsumed() {\n     // In case striped blocks, total usage by this striped blocks should\n     // be the total of data blocks and parity blocks because\n     // `getNumBytes` is the total of actual data block size.\n-    return ((getNumBytes() - 1) / (dataBlockNum * BLOCK_STRIPED_CHUNK_SIZE) + 1)\n-        * BLOCK_STRIPED_CHUNK_SIZE * parityBlockNum + getNumBytes();\n+    return ((getNumBytes() - 1) / (dataBlockNum * BLOCK_STRIPED_CELL_SIZE) + 1)\n+        * BLOCK_STRIPED_CELL_SIZE * parityBlockNum + getNumBytes();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public long spaceConsumed() {\n    // In case striped blocks, total usage by this striped blocks should\n    // be the total of data blocks and parity blocks because\n    // `getNumBytes` is the total of actual data block size.\n    return ((getNumBytes() - 1) / (dataBlockNum * BLOCK_STRIPED_CELL_SIZE) + 1)\n        * BLOCK_STRIPED_CELL_SIZE * parityBlockNum + getNumBytes();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.java",
      "extendedDetails": {}
    },
    "abf833a7b228fff2bca4f69cd9df99d532380038": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7907. Erasure Coding: track invalid, corrupt, and under-recovery striped blocks in NameNode. Contributed by Jing Zhao.\n",
      "commitDate": "26/05/15 11:43 AM",
      "commitName": "abf833a7b228fff2bca4f69cd9df99d532380038",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "26/05/15 11:43 AM",
      "commitNameOld": "d0d75a833907f6cf723a42a007ca04e0004a8e52",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n   public long spaceConsumed() {\n     // In case striped blocks, total usage by this striped blocks should\n     // be the total of data blocks and parity blocks because\n     // `getNumBytes` is the total of actual data block size.\n-    return ((getNumBytes() - 1) / (dataBlockNum * chunkSize) + 1)\n-        * chunkSize * parityBlockNum + getNumBytes();\n+    return ((getNumBytes() - 1) / (dataBlockNum * BLOCK_STRIPED_CHUNK_SIZE) + 1)\n+        * BLOCK_STRIPED_CHUNK_SIZE * parityBlockNum + getNumBytes();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public long spaceConsumed() {\n    // In case striped blocks, total usage by this striped blocks should\n    // be the total of data blocks and parity blocks because\n    // `getNumBytes` is the total of actual data block size.\n    return ((getNumBytes() - 1) / (dataBlockNum * BLOCK_STRIPED_CHUNK_SIZE) + 1)\n        * BLOCK_STRIPED_CHUNK_SIZE * parityBlockNum + getNumBytes();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.java",
      "extendedDetails": {}
    },
    "26773d9d6c10479982a3cdbea3a0933f4476add3": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7826. Erasure Coding: Update INodeFile quota computation for striped blocks. Contributed by Kai Sasaki.\n",
      "commitDate": "26/05/15 11:32 AM",
      "commitName": "26773d9d6c10479982a3cdbea3a0933f4476add3",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,7 @@\n+  public long spaceConsumed() {\n+    // In case striped blocks, total usage by this striped blocks should\n+    // be the total of data blocks and parity blocks because\n+    // `getNumBytes` is the total of actual data block size.\n+    return ((getNumBytes() - 1) / (dataBlockNum * chunkSize) + 1)\n+        * chunkSize * parityBlockNum + getNumBytes();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public long spaceConsumed() {\n    // In case striped blocks, total usage by this striped blocks should\n    // be the total of data blocks and parity blocks because\n    // `getNumBytes` is the total of actual data block size.\n    return ((getNumBytes() - 1) / (dataBlockNum * chunkSize) + 1)\n        * chunkSize * parityBlockNum + getNumBytes();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.java"
    }
  }
}