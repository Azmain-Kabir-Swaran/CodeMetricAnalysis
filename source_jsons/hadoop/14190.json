{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "IPCLoggerChannel.java",
  "functionName": "createParallelExecutor",
  "functionId": "createParallelExecutor",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/IPCLoggerChannel.java",
  "functionStartLine": 274,
  "functionEndLine": 287,
  "numCommitsSeen": 70,
  "timeTaken": 3961,
  "changeHistory": [
    "6c9f75cf16b4a321a3b6965b76c53033843ce178",
    "dc32f583afffc372f78fb45211c3e7ce13f6a4be",
    "eb96a3093ea34a7749410a63c72b6d0a9636d80f",
    "faa4455be512e070fa420084be8d1be5c72f3b08",
    "c95a1674b61ef2a6963dc64604986ef90a8c636d"
  ],
  "changeHistoryShort": {
    "6c9f75cf16b4a321a3b6965b76c53033843ce178": "Ybodychange",
    "dc32f583afffc372f78fb45211c3e7ce13f6a4be": "Ybodychange",
    "eb96a3093ea34a7749410a63c72b6d0a9636d80f": "Ybodychange",
    "faa4455be512e070fa420084be8d1be5c72f3b08": "Ymultichange(Yrename,Ybodychange)",
    "c95a1674b61ef2a6963dc64604986ef90a8c636d": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6c9f75cf16b4a321a3b6965b76c53033843ce178": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15373. Fix number of threads in IPCLoggerChannel#createParallelExecutor. Contributed by Ayush Saxena.\n",
      "commitDate": "26/05/20 3:56 AM",
      "commitName": "6c9f75cf16b4a321a3b6965b76c53033843ce178",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "28/12/19 4:32 AM",
      "commitNameOld": "dc32f583afffc372f78fb45211c3e7ce13f6a4be",
      "commitAuthorOld": "Takanobu Asanuma",
      "daysBetweenCommits": 149.93,
      "commitsBetweenForRepo": 505,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,14 @@\n   protected ExecutorService createParallelExecutor() {\n     int numThreads \u003d\n         conf.getInt(DFSConfigKeys.DFS_QJOURNAL_PARALLEL_READ_NUM_THREADS_KEY,\n             DFSConfigKeys.DFS_QJOURNAL_PARALLEL_READ_NUM_THREADS_DEFAULT);\n-    return new ThreadPoolExecutor(1, numThreads, 60L, TimeUnit.SECONDS,\n+    ThreadPoolExecutor threadPoolExecutor \u003d new ThreadPoolExecutor(numThreads,\n+        numThreads, 60L, TimeUnit.SECONDS,\n         new LinkedBlockingQueue\u003c\u003e(),\n         new ThreadFactoryBuilder().setDaemon(true)\n             .setNameFormat(\"Logger channel (from parallel executor) to \" + addr)\n             .setUncaughtExceptionHandler(UncaughtExceptionHandlers.systemExit())\n             .build());\n+    threadPoolExecutor.allowCoreThreadTimeOut(true);\n+    return threadPoolExecutor;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected ExecutorService createParallelExecutor() {\n    int numThreads \u003d\n        conf.getInt(DFSConfigKeys.DFS_QJOURNAL_PARALLEL_READ_NUM_THREADS_KEY,\n            DFSConfigKeys.DFS_QJOURNAL_PARALLEL_READ_NUM_THREADS_DEFAULT);\n    ThreadPoolExecutor threadPoolExecutor \u003d new ThreadPoolExecutor(numThreads,\n        numThreads, 60L, TimeUnit.SECONDS,\n        new LinkedBlockingQueue\u003c\u003e(),\n        new ThreadFactoryBuilder().setDaemon(true)\n            .setNameFormat(\"Logger channel (from parallel executor) to \" + addr)\n            .setUncaughtExceptionHandler(UncaughtExceptionHandlers.systemExit())\n            .build());\n    threadPoolExecutor.allowCoreThreadTimeOut(true);\n    return threadPoolExecutor;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/IPCLoggerChannel.java",
      "extendedDetails": {}
    },
    "dc32f583afffc372f78fb45211c3e7ce13f6a4be": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14934. [SBN Read] Standby NN throws many InterruptedExceptions when dfs.ha.tail-edits.period is 0. Contributed by Ayush Saxena.\n",
      "commitDate": "28/12/19 4:32 AM",
      "commitName": "dc32f583afffc372f78fb45211c3e7ce13f6a4be",
      "commitAuthor": "Takanobu Asanuma",
      "commitDateOld": "24/09/19 12:46 PM",
      "commitNameOld": "eb96a3093ea34a7749410a63c72b6d0a9636d80f",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 94.7,
      "commitsBetweenForRepo": 425,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n   protected ExecutorService createParallelExecutor() {\n     int numThreads \u003d\n         conf.getInt(DFSConfigKeys.DFS_QJOURNAL_PARALLEL_READ_NUM_THREADS_KEY,\n             DFSConfigKeys.DFS_QJOURNAL_PARALLEL_READ_NUM_THREADS_DEFAULT);\n-    return new HadoopThreadPoolExecutor(1, numThreads, 60L,\n-        TimeUnit.SECONDS, new LinkedBlockingQueue\u003c\u003e(),\n+    return new ThreadPoolExecutor(1, numThreads, 60L, TimeUnit.SECONDS,\n+        new LinkedBlockingQueue\u003c\u003e(),\n         new ThreadFactoryBuilder().setDaemon(true)\n             .setNameFormat(\"Logger channel (from parallel executor) to \" + addr)\n             .setUncaughtExceptionHandler(UncaughtExceptionHandlers.systemExit())\n             .build());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected ExecutorService createParallelExecutor() {\n    int numThreads \u003d\n        conf.getInt(DFSConfigKeys.DFS_QJOURNAL_PARALLEL_READ_NUM_THREADS_KEY,\n            DFSConfigKeys.DFS_QJOURNAL_PARALLEL_READ_NUM_THREADS_DEFAULT);\n    return new ThreadPoolExecutor(1, numThreads, 60L, TimeUnit.SECONDS,\n        new LinkedBlockingQueue\u003c\u003e(),\n        new ThreadFactoryBuilder().setDaemon(true)\n            .setNameFormat(\"Logger channel (from parallel executor) to \" + addr)\n            .setUncaughtExceptionHandler(UncaughtExceptionHandlers.systemExit())\n            .build());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/IPCLoggerChannel.java",
      "extendedDetails": {}
    },
    "eb96a3093ea34a7749410a63c72b6d0a9636d80f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14655. [SBN Read] Namenode crashes if one of The JN is down. Contributed by Ayush Saxena.\n",
      "commitDate": "24/09/19 12:46 PM",
      "commitName": "eb96a3093ea34a7749410a63c72b6d0a9636d80f",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "08/08/19 1:50 PM",
      "commitNameOld": "6ad9a11494c3aea146d7741bf0ad52ce16ad08e6",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 46.96,
      "commitsBetweenForRepo": 433,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,11 @@\n   protected ExecutorService createParallelExecutor() {\n-    return Executors.newCachedThreadPool(\n-        new ThreadFactoryBuilder()\n-            .setDaemon(true)\n+    int numThreads \u003d\n+        conf.getInt(DFSConfigKeys.DFS_QJOURNAL_PARALLEL_READ_NUM_THREADS_KEY,\n+            DFSConfigKeys.DFS_QJOURNAL_PARALLEL_READ_NUM_THREADS_DEFAULT);\n+    return new HadoopThreadPoolExecutor(1, numThreads, 60L,\n+        TimeUnit.SECONDS, new LinkedBlockingQueue\u003c\u003e(),\n+        new ThreadFactoryBuilder().setDaemon(true)\n             .setNameFormat(\"Logger channel (from parallel executor) to \" + addr)\n-            .setUncaughtExceptionHandler(\n-                UncaughtExceptionHandlers.systemExit())\n+            .setUncaughtExceptionHandler(UncaughtExceptionHandlers.systemExit())\n             .build());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected ExecutorService createParallelExecutor() {\n    int numThreads \u003d\n        conf.getInt(DFSConfigKeys.DFS_QJOURNAL_PARALLEL_READ_NUM_THREADS_KEY,\n            DFSConfigKeys.DFS_QJOURNAL_PARALLEL_READ_NUM_THREADS_DEFAULT);\n    return new HadoopThreadPoolExecutor(1, numThreads, 60L,\n        TimeUnit.SECONDS, new LinkedBlockingQueue\u003c\u003e(),\n        new ThreadFactoryBuilder().setDaemon(true)\n            .setNameFormat(\"Logger channel (from parallel executor) to \" + addr)\n            .setUncaughtExceptionHandler(UncaughtExceptionHandlers.systemExit())\n            .build());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/IPCLoggerChannel.java",
      "extendedDetails": {}
    },
    "faa4455be512e070fa420084be8d1be5c72f3b08": {
      "type": "Ymultichange(Yrename,Ybodychange)",
      "commitMessage": "HDFS-6634. inotify in HDFS. Contributed by James Thomas.\n",
      "commitDate": "02/09/14 2:02 PM",
      "commitName": "faa4455be512e070fa420084be8d1be5c72f3b08",
      "commitAuthor": "Andrew Wang",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-6634. inotify in HDFS. Contributed by James Thomas.\n",
          "commitDate": "02/09/14 2:02 PM",
          "commitName": "faa4455be512e070fa420084be8d1be5c72f3b08",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "24/03/14 4:32 PM",
          "commitNameOld": "c2ef7e239eb0e81cf8a3e971378e9e696202de67",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 161.9,
          "commitsBetweenForRepo": 1116,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,9 @@\n-  protected ExecutorService createExecutor() {\n-    return Executors.newSingleThreadExecutor(\n+  protected ExecutorService createParallelExecutor() {\n+    return Executors.newCachedThreadPool(\n         new ThreadFactoryBuilder()\n-          .setDaemon(true)\n-          .setNameFormat(\"Logger channel to \" + addr)\n-          .setUncaughtExceptionHandler(\n-              UncaughtExceptionHandlers.systemExit())\n-          .build());\n+            .setDaemon(true)\n+            .setNameFormat(\"Logger channel (from parallel executor) to \" + addr)\n+            .setUncaughtExceptionHandler(\n+                UncaughtExceptionHandlers.systemExit())\n+            .build());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected ExecutorService createParallelExecutor() {\n    return Executors.newCachedThreadPool(\n        new ThreadFactoryBuilder()\n            .setDaemon(true)\n            .setNameFormat(\"Logger channel (from parallel executor) to \" + addr)\n            .setUncaughtExceptionHandler(\n                UncaughtExceptionHandlers.systemExit())\n            .build());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/IPCLoggerChannel.java",
          "extendedDetails": {
            "oldValue": "createExecutor",
            "newValue": "createParallelExecutor"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6634. inotify in HDFS. Contributed by James Thomas.\n",
          "commitDate": "02/09/14 2:02 PM",
          "commitName": "faa4455be512e070fa420084be8d1be5c72f3b08",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "24/03/14 4:32 PM",
          "commitNameOld": "c2ef7e239eb0e81cf8a3e971378e9e696202de67",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 161.9,
          "commitsBetweenForRepo": 1116,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,9 @@\n-  protected ExecutorService createExecutor() {\n-    return Executors.newSingleThreadExecutor(\n+  protected ExecutorService createParallelExecutor() {\n+    return Executors.newCachedThreadPool(\n         new ThreadFactoryBuilder()\n-          .setDaemon(true)\n-          .setNameFormat(\"Logger channel to \" + addr)\n-          .setUncaughtExceptionHandler(\n-              UncaughtExceptionHandlers.systemExit())\n-          .build());\n+            .setDaemon(true)\n+            .setNameFormat(\"Logger channel (from parallel executor) to \" + addr)\n+            .setUncaughtExceptionHandler(\n+                UncaughtExceptionHandlers.systemExit())\n+            .build());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected ExecutorService createParallelExecutor() {\n    return Executors.newCachedThreadPool(\n        new ThreadFactoryBuilder()\n            .setDaemon(true)\n            .setNameFormat(\"Logger channel (from parallel executor) to \" + addr)\n            .setUncaughtExceptionHandler(\n                UncaughtExceptionHandlers.systemExit())\n            .build());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/IPCLoggerChannel.java",
          "extendedDetails": {}
        }
      ]
    },
    "c95a1674b61ef2a6963dc64604986ef90a8c636d": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3799. QJM: handle empty log segments during recovery. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1373183 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/08/12 5:57 PM",
      "commitName": "c95a1674b61ef2a6963dc64604986ef90a8c636d",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,9 @@\n+  protected ExecutorService createExecutor() {\n+    return Executors.newSingleThreadExecutor(\n+        new ThreadFactoryBuilder()\n+          .setDaemon(true)\n+          .setNameFormat(\"Logger channel to \" + addr)\n+          .setUncaughtExceptionHandler(\n+              UncaughtExceptionHandlers.systemExit())\n+          .build());\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected ExecutorService createExecutor() {\n    return Executors.newSingleThreadExecutor(\n        new ThreadFactoryBuilder()\n          .setDaemon(true)\n          .setNameFormat(\"Logger channel to \" + addr)\n          .setUncaughtExceptionHandler(\n              UncaughtExceptionHandlers.systemExit())\n          .build());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/IPCLoggerChannel.java"
    }
  }
}