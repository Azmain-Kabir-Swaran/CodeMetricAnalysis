{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RouterClientProtocol.java",
  "functionName": "reportBadBlocks",
  "functionId": "reportBadBlocks___blocks-LocatedBlock[]",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
  "functionStartLine": 1653,
  "functionEndLine": 1680,
  "numCommitsSeen": 40,
  "timeTaken": 1697,
  "changeHistory": [
    "6425ed27ea638da75f656204d6df4adad1d91fe1"
  ],
  "changeHistoryShort": {
    "6425ed27ea638da75f656204d6df4adad1d91fe1": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6425ed27ea638da75f656204d6df4adad1d91fe1": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13790. RBF: Move ClientProtocol APIs to its own module. Contributed by Chao Sun.\n",
      "commitDate": "19/08/18 11:50 PM",
      "commitName": "6425ed27ea638da75f656204d6df4adad1d91fe1",
      "commitAuthor": "Brahma Reddy Battula",
      "diff": "@@ -0,0 +1,28 @@\n+  public void reportBadBlocks(LocatedBlock[] blocks) throws IOException {\n+    rpcServer.checkOperation(NameNode.OperationCategory.WRITE);\n+\n+    // Block pool id -\u003e blocks\n+    Map\u003cString, List\u003cLocatedBlock\u003e\u003e blockLocations \u003d new HashMap\u003c\u003e();\n+    for (LocatedBlock block : blocks) {\n+      String bpId \u003d block.getBlock().getBlockPoolId();\n+      List\u003cLocatedBlock\u003e bpBlocks \u003d blockLocations.get(bpId);\n+      if (bpBlocks \u003d\u003d null) {\n+        bpBlocks \u003d new LinkedList\u003c\u003e();\n+        blockLocations.put(bpId, bpBlocks);\n+      }\n+      bpBlocks.add(block);\n+    }\n+\n+    // Invoke each block pool\n+    for (Map.Entry\u003cString, List\u003cLocatedBlock\u003e\u003e entry : blockLocations.entrySet()) {\n+      String bpId \u003d entry.getKey();\n+      List\u003cLocatedBlock\u003e bpBlocks \u003d entry.getValue();\n+\n+      LocatedBlock[] bpBlocksArray \u003d\n+          bpBlocks.toArray(new LocatedBlock[bpBlocks.size()]);\n+      RemoteMethod method \u003d new RemoteMethod(\"reportBadBlocks\",\n+          new Class\u003c?\u003e[] {LocatedBlock[].class},\n+          new Object[] {bpBlocksArray});\n+      rpcClient.invokeSingleBlockPool(bpId, method);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void reportBadBlocks(LocatedBlock[] blocks) throws IOException {\n    rpcServer.checkOperation(NameNode.OperationCategory.WRITE);\n\n    // Block pool id -\u003e blocks\n    Map\u003cString, List\u003cLocatedBlock\u003e\u003e blockLocations \u003d new HashMap\u003c\u003e();\n    for (LocatedBlock block : blocks) {\n      String bpId \u003d block.getBlock().getBlockPoolId();\n      List\u003cLocatedBlock\u003e bpBlocks \u003d blockLocations.get(bpId);\n      if (bpBlocks \u003d\u003d null) {\n        bpBlocks \u003d new LinkedList\u003c\u003e();\n        blockLocations.put(bpId, bpBlocks);\n      }\n      bpBlocks.add(block);\n    }\n\n    // Invoke each block pool\n    for (Map.Entry\u003cString, List\u003cLocatedBlock\u003e\u003e entry : blockLocations.entrySet()) {\n      String bpId \u003d entry.getKey();\n      List\u003cLocatedBlock\u003e bpBlocks \u003d entry.getValue();\n\n      LocatedBlock[] bpBlocksArray \u003d\n          bpBlocks.toArray(new LocatedBlock[bpBlocks.size()]);\n      RemoteMethod method \u003d new RemoteMethod(\"reportBadBlocks\",\n          new Class\u003c?\u003e[] {LocatedBlock[].class},\n          new Object[] {bpBlocksArray});\n      rpcClient.invokeSingleBlockPool(bpId, method);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java"
    }
  }
}