{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSDirStatAndListingOp.java",
  "functionName": "getContentSummaryInt",
  "functionId": "getContentSummaryInt___fsd-FSDirectory__pc-FSPermissionChecker__iip-INodesInPath",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java",
  "functionStartLine": 508,
  "functionEndLine": 530,
  "numCommitsSeen": 335,
  "timeTaken": 15230,
  "changeHistory": [
    "84a1321f6aa0af6895564a7c47f8f264656f0294",
    "f413ee33df301659c4ca9024380c2354983dcc84",
    "a1f12bb543778ddc243205eaa962e99da4d8f135",
    "a29fe100b3c671954b759add5923a2b44af9e6a4",
    "3f4275310203de4ccfb15337f3c503e25408a265",
    "285b31e75e51ec8e3a796c2cb0208739368ca9b8",
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
    "0af44ea8462437f8e7a8271b15a19677fd7f05a1",
    "0689363343a281a6f7f6f395227668bddc2663eb",
    "fe67e30bc2794e7ff073cf938ee80eba805d1e69",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "84a1321f6aa0af6895564a7c47f8f264656f0294": "Ymultichange(Yparameterchange,Ybodychange)",
    "f413ee33df301659c4ca9024380c2354983dcc84": "Ybodychange",
    "a1f12bb543778ddc243205eaa962e99da4d8f135": "Ybodychange",
    "a29fe100b3c671954b759add5923a2b44af9e6a4": "Ybodychange",
    "3f4275310203de4ccfb15337f3c503e25408a265": "Ybodychange",
    "285b31e75e51ec8e3a796c2cb0208739368ca9b8": "Ybodychange",
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19": "Ymultichange(Yparameterchange,Ybodychange)",
    "0af44ea8462437f8e7a8271b15a19677fd7f05a1": "Ymultichange(Ymovefromfile,Ymodifierchange,Yexceptionschange,Ybodychange,Yrename,Yparameterchange)",
    "0689363343a281a6f7f6f395227668bddc2663eb": "Ybodychange",
    "fe67e30bc2794e7ff073cf938ee80eba805d1e69": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "84a1321f6aa0af6895564a7c47f8f264656f0294": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-13136. Avoid taking FSN lock while doing group member lookup for FSD permission check. Contributed by Xiaoyu Yao.\n",
      "commitDate": "22/02/18 11:32 AM",
      "commitName": "84a1321f6aa0af6895564a7c47f8f264656f0294",
      "commitAuthor": "Xiaoyu Yao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13136. Avoid taking FSN lock while doing group member lookup for FSD permission check. Contributed by Xiaoyu Yao.\n",
          "commitDate": "22/02/18 11:32 AM",
          "commitName": "84a1321f6aa0af6895564a7c47f8f264656f0294",
          "commitAuthor": "Xiaoyu Yao",
          "commitDateOld": "11/12/17 8:14 PM",
          "commitNameOld": "693169ef34f856a27dc09d90a45fb4ec5b66ed2c",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 72.64,
          "commitsBetweenForRepo": 423,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,23 @@\n   private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n-      INodesInPath iip) throws IOException {\n+      FSPermissionChecker pc, INodesInPath iip) throws IOException {\n     fsd.readLock();\n     try {\n       INode targetNode \u003d iip.getLastINode();\n       if (targetNode \u003d\u003d null) {\n         throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n       }\n       else {\n         // Make it relinquish locks everytime contentCountLimit entries are\n         // processed. 0 means disabled. I.e. blocking for the entire duration.\n         ContentSummaryComputationContext cscc \u003d\n             new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n-                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec(),\n-                fsd.getPermissionChecker());\n+                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec(), pc);\n         ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(\n             iip.getPathSnapshotId(), cscc);\n         fsd.addYieldCount(cscc.getYieldCount());\n         return cs;\n       }\n     } finally {\n       fsd.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n      FSPermissionChecker pc, INodesInPath iip) throws IOException {\n    fsd.readLock();\n    try {\n      INode targetNode \u003d iip.getLastINode();\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n      }\n      else {\n        // Make it relinquish locks everytime contentCountLimit entries are\n        // processed. 0 means disabled. I.e. blocking for the entire duration.\n        ContentSummaryComputationContext cscc \u003d\n            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec(), pc);\n        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(\n            iip.getPathSnapshotId(), cscc);\n        fsd.addYieldCount(cscc.getYieldCount());\n        return cs;\n      }\n    } finally {\n      fsd.readUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java",
          "extendedDetails": {
            "oldValue": "[fsd-FSDirectory, iip-INodesInPath]",
            "newValue": "[fsd-FSDirectory, pc-FSPermissionChecker, iip-INodesInPath]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13136. Avoid taking FSN lock while doing group member lookup for FSD permission check. Contributed by Xiaoyu Yao.\n",
          "commitDate": "22/02/18 11:32 AM",
          "commitName": "84a1321f6aa0af6895564a7c47f8f264656f0294",
          "commitAuthor": "Xiaoyu Yao",
          "commitDateOld": "11/12/17 8:14 PM",
          "commitNameOld": "693169ef34f856a27dc09d90a45fb4ec5b66ed2c",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 72.64,
          "commitsBetweenForRepo": 423,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,23 @@\n   private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n-      INodesInPath iip) throws IOException {\n+      FSPermissionChecker pc, INodesInPath iip) throws IOException {\n     fsd.readLock();\n     try {\n       INode targetNode \u003d iip.getLastINode();\n       if (targetNode \u003d\u003d null) {\n         throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n       }\n       else {\n         // Make it relinquish locks everytime contentCountLimit entries are\n         // processed. 0 means disabled. I.e. blocking for the entire duration.\n         ContentSummaryComputationContext cscc \u003d\n             new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n-                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec(),\n-                fsd.getPermissionChecker());\n+                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec(), pc);\n         ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(\n             iip.getPathSnapshotId(), cscc);\n         fsd.addYieldCount(cscc.getYieldCount());\n         return cs;\n       }\n     } finally {\n       fsd.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n      FSPermissionChecker pc, INodesInPath iip) throws IOException {\n    fsd.readLock();\n    try {\n      INode targetNode \u003d iip.getLastINode();\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n      }\n      else {\n        // Make it relinquish locks everytime contentCountLimit entries are\n        // processed. 0 means disabled. I.e. blocking for the entire duration.\n        ContentSummaryComputationContext cscc \u003d\n            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec(), pc);\n        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(\n            iip.getPathSnapshotId(), cscc);\n        fsd.addYieldCount(cscc.getYieldCount());\n        return cs;\n      }\n    } finally {\n      fsd.readUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java",
          "extendedDetails": {}
        }
      ]
    },
    "f413ee33df301659c4ca9024380c2354983dcc84": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12130. Optimizing permission check for getContentSummary.  Contributed by  Chen Liang\n",
      "commitDate": "14/07/17 2:35 PM",
      "commitName": "f413ee33df301659c4ca9024380c2354983dcc84",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "14/07/17 2:34 PM",
      "commitNameOld": "a1f12bb543778ddc243205eaa962e99da4d8f135",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,24 @@\n   private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n       INodesInPath iip) throws IOException {\n     fsd.readLock();\n     try {\n       INode targetNode \u003d iip.getLastINode();\n       if (targetNode \u003d\u003d null) {\n         throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n       }\n       else {\n         // Make it relinquish locks everytime contentCountLimit entries are\n         // processed. 0 means disabled. I.e. blocking for the entire duration.\n         ContentSummaryComputationContext cscc \u003d\n             new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n-                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec());\n+                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec(),\n+                fsd.getPermissionChecker());\n         ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(\n             iip.getPathSnapshotId(), cscc);\n         fsd.addYieldCount(cscc.getYieldCount());\n         return cs;\n       }\n     } finally {\n       fsd.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n      INodesInPath iip) throws IOException {\n    fsd.readLock();\n    try {\n      INode targetNode \u003d iip.getLastINode();\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n      }\n      else {\n        // Make it relinquish locks everytime contentCountLimit entries are\n        // processed. 0 means disabled. I.e. blocking for the entire duration.\n        ContentSummaryComputationContext cscc \u003d\n            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec(),\n                fsd.getPermissionChecker());\n        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(\n            iip.getPathSnapshotId(), cscc);\n        fsd.addYieldCount(cscc.getYieldCount());\n        return cs;\n      }\n    } finally {\n      fsd.readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java",
      "extendedDetails": {}
    },
    "a1f12bb543778ddc243205eaa962e99da4d8f135": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-12130. Optimizing permission check for getContentSummary.\" to fix commit message.\n\nThis reverts commit a29fe100b3c671954b759add5923a2b44af9e6a4.\n",
      "commitDate": "14/07/17 2:34 PM",
      "commitName": "a1f12bb543778ddc243205eaa962e99da4d8f135",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "14/07/17 1:36 PM",
      "commitNameOld": "a29fe100b3c671954b759add5923a2b44af9e6a4",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,23 @@\n   private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n       INodesInPath iip) throws IOException {\n     fsd.readLock();\n     try {\n       INode targetNode \u003d iip.getLastINode();\n       if (targetNode \u003d\u003d null) {\n         throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n       }\n       else {\n         // Make it relinquish locks everytime contentCountLimit entries are\n         // processed. 0 means disabled. I.e. blocking for the entire duration.\n         ContentSummaryComputationContext cscc \u003d\n             new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n-                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec(),\n-                fsd.getPermissionChecker());\n+                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec());\n         ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(\n             iip.getPathSnapshotId(), cscc);\n         fsd.addYieldCount(cscc.getYieldCount());\n         return cs;\n       }\n     } finally {\n       fsd.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n      INodesInPath iip) throws IOException {\n    fsd.readLock();\n    try {\n      INode targetNode \u003d iip.getLastINode();\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n      }\n      else {\n        // Make it relinquish locks everytime contentCountLimit entries are\n        // processed. 0 means disabled. I.e. blocking for the entire duration.\n        ContentSummaryComputationContext cscc \u003d\n            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec());\n        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(\n            iip.getPathSnapshotId(), cscc);\n        fsd.addYieldCount(cscc.getYieldCount());\n        return cs;\n      }\n    } finally {\n      fsd.readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java",
      "extendedDetails": {}
    },
    "a29fe100b3c671954b759add5923a2b44af9e6a4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12130. Optimizing permission check for getContentSummary.\n",
      "commitDate": "14/07/17 1:36 PM",
      "commitName": "a29fe100b3c671954b759add5923a2b44af9e6a4",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "24/03/17 11:44 AM",
      "commitNameOld": "52b00600df921763725396ed92194d3338167655",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 112.08,
      "commitsBetweenForRepo": 585,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,24 @@\n   private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n       INodesInPath iip) throws IOException {\n     fsd.readLock();\n     try {\n       INode targetNode \u003d iip.getLastINode();\n       if (targetNode \u003d\u003d null) {\n         throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n       }\n       else {\n         // Make it relinquish locks everytime contentCountLimit entries are\n         // processed. 0 means disabled. I.e. blocking for the entire duration.\n         ContentSummaryComputationContext cscc \u003d\n             new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n-                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec());\n+                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec(),\n+                fsd.getPermissionChecker());\n         ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(\n             iip.getPathSnapshotId(), cscc);\n         fsd.addYieldCount(cscc.getYieldCount());\n         return cs;\n       }\n     } finally {\n       fsd.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n      INodesInPath iip) throws IOException {\n    fsd.readLock();\n    try {\n      INode targetNode \u003d iip.getLastINode();\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n      }\n      else {\n        // Make it relinquish locks everytime contentCountLimit entries are\n        // processed. 0 means disabled. I.e. blocking for the entire duration.\n        ContentSummaryComputationContext cscc \u003d\n            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec(),\n                fsd.getPermissionChecker());\n        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(\n            iip.getPathSnapshotId(), cscc);\n        fsd.addYieldCount(cscc.getYieldCount());\n        return cs;\n      }\n    } finally {\n      fsd.readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java",
      "extendedDetails": {}
    },
    "3f4275310203de4ccfb15337f3c503e25408a265": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9063. Correctly handle snapshot path for getContentSummary. Contributed by Jing Zhao.\n",
      "commitDate": "18/09/15 9:26 AM",
      "commitName": "3f4275310203de4ccfb15337f3c503e25408a265",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "11/08/15 10:28 AM",
      "commitNameOld": "1fc3c779a422bafdb86ad1a5b2349802dda1cb62",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 37.96,
      "commitsBetweenForRepo": 233,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,23 @@\n   private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n       INodesInPath iip) throws IOException {\n     fsd.readLock();\n     try {\n       INode targetNode \u003d iip.getLastINode();\n       if (targetNode \u003d\u003d null) {\n         throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n       }\n       else {\n         // Make it relinquish locks everytime contentCountLimit entries are\n         // processed. 0 means disabled. I.e. blocking for the entire duration.\n         ContentSummaryComputationContext cscc \u003d\n             new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                 fsd.getContentCountLimit(), fsd.getContentSleepMicroSec());\n-        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n+        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(\n+            iip.getPathSnapshotId(), cscc);\n         fsd.addYieldCount(cscc.getYieldCount());\n         return cs;\n       }\n     } finally {\n       fsd.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n      INodesInPath iip) throws IOException {\n    fsd.readLock();\n    try {\n      INode targetNode \u003d iip.getLastINode();\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n      }\n      else {\n        // Make it relinquish locks everytime contentCountLimit entries are\n        // processed. 0 means disabled. I.e. blocking for the entire duration.\n        ContentSummaryComputationContext cscc \u003d\n            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec());\n        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(\n            iip.getPathSnapshotId(), cscc);\n        fsd.addYieldCount(cscc.getYieldCount());\n        return cs;\n      }\n    } finally {\n      fsd.readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java",
      "extendedDetails": {}
    },
    "285b31e75e51ec8e3a796c2cb0208739368ca9b8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8046. Allow better control of getContentSummary. Contributed by Kihwal Lee.\n",
      "commitDate": "08/04/15 1:38 PM",
      "commitName": "285b31e75e51ec8e3a796c2cb0208739368ca9b8",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "24/03/15 4:02 PM",
      "commitNameOld": "53a28afe293e5bf185c8d4f2c7aea212e66015c2",
      "commitAuthorOld": "Jitendra Pandey",
      "daysBetweenCommits": 14.9,
      "commitsBetweenForRepo": 123,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n       INodesInPath iip) throws IOException {\n     fsd.readLock();\n     try {\n       INode targetNode \u003d iip.getLastINode();\n       if (targetNode \u003d\u003d null) {\n         throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n       }\n       else {\n         // Make it relinquish locks everytime contentCountLimit entries are\n         // processed. 0 means disabled. I.e. blocking for the entire duration.\n         ContentSummaryComputationContext cscc \u003d\n             new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n-                fsd.getContentCountLimit());\n+                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec());\n         ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n         fsd.addYieldCount(cscc.getYieldCount());\n         return cs;\n       }\n     } finally {\n       fsd.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n      INodesInPath iip) throws IOException {\n    fsd.readLock();\n    try {\n      INode targetNode \u003d iip.getLastINode();\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n      }\n      else {\n        // Make it relinquish locks everytime contentCountLimit entries are\n        // processed. 0 means disabled. I.e. blocking for the entire duration.\n        ContentSummaryComputationContext cscc \u003d\n            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                fsd.getContentCountLimit(), fsd.getContentSleepMicroSec());\n        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n        fsd.addYieldCount(cscc.getYieldCount());\n        return cs;\n      }\n    } finally {\n      fsd.readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java",
      "extendedDetails": {}
    },
    "c78e3a7cdd10c40454e9acb06986ba6d8573cb19": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7059. Avoid resolving path multiple times. Contributed by Jing Zhao.\n",
      "commitDate": "12/12/14 3:13 PM",
      "commitName": "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7059. Avoid resolving path multiple times. Contributed by Jing Zhao.\n",
          "commitDate": "12/12/14 3:13 PM",
          "commitName": "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "11/12/14 12:36 PM",
          "commitNameOld": "b9f6d0c956f0278c8b9b83e05b523a442a730ebb",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 1.11,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,22 @@\n-  private static ContentSummary getContentSummaryInt(\n-      FSDirectory fsd, String src) throws IOException {\n-    String srcs \u003d FSDirectory.normalizePath(src);\n+  private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n+      INodesInPath iip) throws IOException {\n     fsd.readLock();\n     try {\n-      INode targetNode \u003d fsd.getNode(srcs, false);\n+      INode targetNode \u003d iip.getLastINode();\n       if (targetNode \u003d\u003d null) {\n-        throw new FileNotFoundException(\"File does not exist: \" + srcs);\n+        throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n       }\n       else {\n         // Make it relinquish locks everytime contentCountLimit entries are\n         // processed. 0 means disabled. I.e. blocking for the entire duration.\n         ContentSummaryComputationContext cscc \u003d\n             new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                 fsd.getContentCountLimit());\n         ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n         fsd.addYieldCount(cscc.getYieldCount());\n         return cs;\n       }\n     } finally {\n       fsd.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n      INodesInPath iip) throws IOException {\n    fsd.readLock();\n    try {\n      INode targetNode \u003d iip.getLastINode();\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n      }\n      else {\n        // Make it relinquish locks everytime contentCountLimit entries are\n        // processed. 0 means disabled. I.e. blocking for the entire duration.\n        ContentSummaryComputationContext cscc \u003d\n            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                fsd.getContentCountLimit());\n        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n        fsd.addYieldCount(cscc.getYieldCount());\n        return cs;\n      }\n    } finally {\n      fsd.readUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java",
          "extendedDetails": {
            "oldValue": "[fsd-FSDirectory, src-String]",
            "newValue": "[fsd-FSDirectory, iip-INodesInPath]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7059. Avoid resolving path multiple times. Contributed by Jing Zhao.\n",
          "commitDate": "12/12/14 3:13 PM",
          "commitName": "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "11/12/14 12:36 PM",
          "commitNameOld": "b9f6d0c956f0278c8b9b83e05b523a442a730ebb",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 1.11,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,22 @@\n-  private static ContentSummary getContentSummaryInt(\n-      FSDirectory fsd, String src) throws IOException {\n-    String srcs \u003d FSDirectory.normalizePath(src);\n+  private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n+      INodesInPath iip) throws IOException {\n     fsd.readLock();\n     try {\n-      INode targetNode \u003d fsd.getNode(srcs, false);\n+      INode targetNode \u003d iip.getLastINode();\n       if (targetNode \u003d\u003d null) {\n-        throw new FileNotFoundException(\"File does not exist: \" + srcs);\n+        throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n       }\n       else {\n         // Make it relinquish locks everytime contentCountLimit entries are\n         // processed. 0 means disabled. I.e. blocking for the entire duration.\n         ContentSummaryComputationContext cscc \u003d\n             new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                 fsd.getContentCountLimit());\n         ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n         fsd.addYieldCount(cscc.getYieldCount());\n         return cs;\n       }\n     } finally {\n       fsd.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static ContentSummary getContentSummaryInt(FSDirectory fsd,\n      INodesInPath iip) throws IOException {\n    fsd.readLock();\n    try {\n      INode targetNode \u003d iip.getLastINode();\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + iip.getPath());\n      }\n      else {\n        // Make it relinquish locks everytime contentCountLimit entries are\n        // processed. 0 means disabled. I.e. blocking for the entire duration.\n        ContentSummaryComputationContext cscc \u003d\n            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                fsd.getContentCountLimit());\n        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n        fsd.addYieldCount(cscc.getYieldCount());\n        return cs;\n      }\n    } finally {\n      fsd.readUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java",
          "extendedDetails": {}
        }
      ]
    },
    "0af44ea8462437f8e7a8271b15a19677fd7f05a1": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Yexceptionschange,Ybodychange,Yrename,Yparameterchange)",
      "commitMessage": "HDFS-7450. Consolidate the implementation of GetFileInfo(), GetListings() and GetContentSummary() into a single class. Contributed by Haohui Mai.\n",
      "commitDate": "01/12/14 9:36 PM",
      "commitName": "0af44ea8462437f8e7a8271b15a19677fd7f05a1",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-7450. Consolidate the implementation of GetFileInfo(), GetListings() and GetContentSummary() into a single class. Contributed by Haohui Mai.\n",
          "commitDate": "01/12/14 9:36 PM",
          "commitName": "0af44ea8462437f8e7a8271b15a19677fd7f05a1",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "01/12/14 9:21 PM",
          "commitNameOld": "9fa29902575ac3774bf3728e7bcde7f3eefb1d4c",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,23 @@\n-  ContentSummary getContentSummary(String src) \n-    throws FileNotFoundException, UnresolvedLinkException {\n-    String srcs \u003d normalizePath(src);\n-    readLock();\n+  private static ContentSummary getContentSummaryInt(\n+      FSDirectory fsd, String src) throws IOException {\n+    String srcs \u003d FSDirectory.normalizePath(src);\n+    fsd.readLock();\n     try {\n-      INode targetNode \u003d getNode(srcs, false);\n+      INode targetNode \u003d fsd.getNode(srcs, false);\n       if (targetNode \u003d\u003d null) {\n         throw new FileNotFoundException(\"File does not exist: \" + srcs);\n       }\n       else {\n         // Make it relinquish locks everytime contentCountLimit entries are\n         // processed. 0 means disabled. I.e. blocking for the entire duration.\n         ContentSummaryComputationContext cscc \u003d\n-\n-            new ContentSummaryComputationContext(this, getFSNamesystem(),\n-            contentCountLimit);\n+            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n+                fsd.getContentCountLimit());\n         ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n-        yieldCount +\u003d cscc.getYieldCount();\n+        fsd.addYieldCount(cscc.getYieldCount());\n         return cs;\n       }\n     } finally {\n-      readUnlock();\n+      fsd.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static ContentSummary getContentSummaryInt(\n      FSDirectory fsd, String src) throws IOException {\n    String srcs \u003d FSDirectory.normalizePath(src);\n    fsd.readLock();\n    try {\n      INode targetNode \u003d fsd.getNode(srcs, false);\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + srcs);\n      }\n      else {\n        // Make it relinquish locks everytime contentCountLimit entries are\n        // processed. 0 means disabled. I.e. blocking for the entire duration.\n        ContentSummaryComputationContext cscc \u003d\n            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                fsd.getContentCountLimit());\n        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n        fsd.addYieldCount(cscc.getYieldCount());\n        return cs;\n      }\n    } finally {\n      fsd.readUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java",
            "oldMethodName": "getContentSummary",
            "newMethodName": "getContentSummaryInt"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-7450. Consolidate the implementation of GetFileInfo(), GetListings() and GetContentSummary() into a single class. Contributed by Haohui Mai.\n",
          "commitDate": "01/12/14 9:36 PM",
          "commitName": "0af44ea8462437f8e7a8271b15a19677fd7f05a1",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "01/12/14 9:21 PM",
          "commitNameOld": "9fa29902575ac3774bf3728e7bcde7f3eefb1d4c",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,23 @@\n-  ContentSummary getContentSummary(String src) \n-    throws FileNotFoundException, UnresolvedLinkException {\n-    String srcs \u003d normalizePath(src);\n-    readLock();\n+  private static ContentSummary getContentSummaryInt(\n+      FSDirectory fsd, String src) throws IOException {\n+    String srcs \u003d FSDirectory.normalizePath(src);\n+    fsd.readLock();\n     try {\n-      INode targetNode \u003d getNode(srcs, false);\n+      INode targetNode \u003d fsd.getNode(srcs, false);\n       if (targetNode \u003d\u003d null) {\n         throw new FileNotFoundException(\"File does not exist: \" + srcs);\n       }\n       else {\n         // Make it relinquish locks everytime contentCountLimit entries are\n         // processed. 0 means disabled. I.e. blocking for the entire duration.\n         ContentSummaryComputationContext cscc \u003d\n-\n-            new ContentSummaryComputationContext(this, getFSNamesystem(),\n-            contentCountLimit);\n+            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n+                fsd.getContentCountLimit());\n         ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n-        yieldCount +\u003d cscc.getYieldCount();\n+        fsd.addYieldCount(cscc.getYieldCount());\n         return cs;\n       }\n     } finally {\n-      readUnlock();\n+      fsd.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static ContentSummary getContentSummaryInt(\n      FSDirectory fsd, String src) throws IOException {\n    String srcs \u003d FSDirectory.normalizePath(src);\n    fsd.readLock();\n    try {\n      INode targetNode \u003d fsd.getNode(srcs, false);\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + srcs);\n      }\n      else {\n        // Make it relinquish locks everytime contentCountLimit entries are\n        // processed. 0 means disabled. I.e. blocking for the entire duration.\n        ContentSummaryComputationContext cscc \u003d\n            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                fsd.getContentCountLimit());\n        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n        fsd.addYieldCount(cscc.getYieldCount());\n        return cs;\n      }\n    } finally {\n      fsd.readUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[private, static]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-7450. Consolidate the implementation of GetFileInfo(), GetListings() and GetContentSummary() into a single class. Contributed by Haohui Mai.\n",
          "commitDate": "01/12/14 9:36 PM",
          "commitName": "0af44ea8462437f8e7a8271b15a19677fd7f05a1",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "01/12/14 9:21 PM",
          "commitNameOld": "9fa29902575ac3774bf3728e7bcde7f3eefb1d4c",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,23 @@\n-  ContentSummary getContentSummary(String src) \n-    throws FileNotFoundException, UnresolvedLinkException {\n-    String srcs \u003d normalizePath(src);\n-    readLock();\n+  private static ContentSummary getContentSummaryInt(\n+      FSDirectory fsd, String src) throws IOException {\n+    String srcs \u003d FSDirectory.normalizePath(src);\n+    fsd.readLock();\n     try {\n-      INode targetNode \u003d getNode(srcs, false);\n+      INode targetNode \u003d fsd.getNode(srcs, false);\n       if (targetNode \u003d\u003d null) {\n         throw new FileNotFoundException(\"File does not exist: \" + srcs);\n       }\n       else {\n         // Make it relinquish locks everytime contentCountLimit entries are\n         // processed. 0 means disabled. I.e. blocking for the entire duration.\n         ContentSummaryComputationContext cscc \u003d\n-\n-            new ContentSummaryComputationContext(this, getFSNamesystem(),\n-            contentCountLimit);\n+            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n+                fsd.getContentCountLimit());\n         ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n-        yieldCount +\u003d cscc.getYieldCount();\n+        fsd.addYieldCount(cscc.getYieldCount());\n         return cs;\n       }\n     } finally {\n-      readUnlock();\n+      fsd.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static ContentSummary getContentSummaryInt(\n      FSDirectory fsd, String src) throws IOException {\n    String srcs \u003d FSDirectory.normalizePath(src);\n    fsd.readLock();\n    try {\n      INode targetNode \u003d fsd.getNode(srcs, false);\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + srcs);\n      }\n      else {\n        // Make it relinquish locks everytime contentCountLimit entries are\n        // processed. 0 means disabled. I.e. blocking for the entire duration.\n        ContentSummaryComputationContext cscc \u003d\n            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                fsd.getContentCountLimit());\n        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n        fsd.addYieldCount(cscc.getYieldCount());\n        return cs;\n      }\n    } finally {\n      fsd.readUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java",
          "extendedDetails": {
            "oldValue": "[FileNotFoundException, UnresolvedLinkException]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7450. Consolidate the implementation of GetFileInfo(), GetListings() and GetContentSummary() into a single class. Contributed by Haohui Mai.\n",
          "commitDate": "01/12/14 9:36 PM",
          "commitName": "0af44ea8462437f8e7a8271b15a19677fd7f05a1",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "01/12/14 9:21 PM",
          "commitNameOld": "9fa29902575ac3774bf3728e7bcde7f3eefb1d4c",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,23 @@\n-  ContentSummary getContentSummary(String src) \n-    throws FileNotFoundException, UnresolvedLinkException {\n-    String srcs \u003d normalizePath(src);\n-    readLock();\n+  private static ContentSummary getContentSummaryInt(\n+      FSDirectory fsd, String src) throws IOException {\n+    String srcs \u003d FSDirectory.normalizePath(src);\n+    fsd.readLock();\n     try {\n-      INode targetNode \u003d getNode(srcs, false);\n+      INode targetNode \u003d fsd.getNode(srcs, false);\n       if (targetNode \u003d\u003d null) {\n         throw new FileNotFoundException(\"File does not exist: \" + srcs);\n       }\n       else {\n         // Make it relinquish locks everytime contentCountLimit entries are\n         // processed. 0 means disabled. I.e. blocking for the entire duration.\n         ContentSummaryComputationContext cscc \u003d\n-\n-            new ContentSummaryComputationContext(this, getFSNamesystem(),\n-            contentCountLimit);\n+            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n+                fsd.getContentCountLimit());\n         ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n-        yieldCount +\u003d cscc.getYieldCount();\n+        fsd.addYieldCount(cscc.getYieldCount());\n         return cs;\n       }\n     } finally {\n-      readUnlock();\n+      fsd.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static ContentSummary getContentSummaryInt(\n      FSDirectory fsd, String src) throws IOException {\n    String srcs \u003d FSDirectory.normalizePath(src);\n    fsd.readLock();\n    try {\n      INode targetNode \u003d fsd.getNode(srcs, false);\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + srcs);\n      }\n      else {\n        // Make it relinquish locks everytime contentCountLimit entries are\n        // processed. 0 means disabled. I.e. blocking for the entire duration.\n        ContentSummaryComputationContext cscc \u003d\n            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                fsd.getContentCountLimit());\n        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n        fsd.addYieldCount(cscc.getYieldCount());\n        return cs;\n      }\n    } finally {\n      fsd.readUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java",
          "extendedDetails": {}
        },
        {
          "type": "Yrename",
          "commitMessage": "HDFS-7450. Consolidate the implementation of GetFileInfo(), GetListings() and GetContentSummary() into a single class. Contributed by Haohui Mai.\n",
          "commitDate": "01/12/14 9:36 PM",
          "commitName": "0af44ea8462437f8e7a8271b15a19677fd7f05a1",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "01/12/14 9:21 PM",
          "commitNameOld": "9fa29902575ac3774bf3728e7bcde7f3eefb1d4c",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,23 @@\n-  ContentSummary getContentSummary(String src) \n-    throws FileNotFoundException, UnresolvedLinkException {\n-    String srcs \u003d normalizePath(src);\n-    readLock();\n+  private static ContentSummary getContentSummaryInt(\n+      FSDirectory fsd, String src) throws IOException {\n+    String srcs \u003d FSDirectory.normalizePath(src);\n+    fsd.readLock();\n     try {\n-      INode targetNode \u003d getNode(srcs, false);\n+      INode targetNode \u003d fsd.getNode(srcs, false);\n       if (targetNode \u003d\u003d null) {\n         throw new FileNotFoundException(\"File does not exist: \" + srcs);\n       }\n       else {\n         // Make it relinquish locks everytime contentCountLimit entries are\n         // processed. 0 means disabled. I.e. blocking for the entire duration.\n         ContentSummaryComputationContext cscc \u003d\n-\n-            new ContentSummaryComputationContext(this, getFSNamesystem(),\n-            contentCountLimit);\n+            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n+                fsd.getContentCountLimit());\n         ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n-        yieldCount +\u003d cscc.getYieldCount();\n+        fsd.addYieldCount(cscc.getYieldCount());\n         return cs;\n       }\n     } finally {\n-      readUnlock();\n+      fsd.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static ContentSummary getContentSummaryInt(\n      FSDirectory fsd, String src) throws IOException {\n    String srcs \u003d FSDirectory.normalizePath(src);\n    fsd.readLock();\n    try {\n      INode targetNode \u003d fsd.getNode(srcs, false);\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + srcs);\n      }\n      else {\n        // Make it relinquish locks everytime contentCountLimit entries are\n        // processed. 0 means disabled. I.e. blocking for the entire duration.\n        ContentSummaryComputationContext cscc \u003d\n            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                fsd.getContentCountLimit());\n        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n        fsd.addYieldCount(cscc.getYieldCount());\n        return cs;\n      }\n    } finally {\n      fsd.readUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java",
          "extendedDetails": {
            "oldValue": "getContentSummary",
            "newValue": "getContentSummaryInt"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7450. Consolidate the implementation of GetFileInfo(), GetListings() and GetContentSummary() into a single class. Contributed by Haohui Mai.\n",
          "commitDate": "01/12/14 9:36 PM",
          "commitName": "0af44ea8462437f8e7a8271b15a19677fd7f05a1",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "01/12/14 9:21 PM",
          "commitNameOld": "9fa29902575ac3774bf3728e7bcde7f3eefb1d4c",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,23 @@\n-  ContentSummary getContentSummary(String src) \n-    throws FileNotFoundException, UnresolvedLinkException {\n-    String srcs \u003d normalizePath(src);\n-    readLock();\n+  private static ContentSummary getContentSummaryInt(\n+      FSDirectory fsd, String src) throws IOException {\n+    String srcs \u003d FSDirectory.normalizePath(src);\n+    fsd.readLock();\n     try {\n-      INode targetNode \u003d getNode(srcs, false);\n+      INode targetNode \u003d fsd.getNode(srcs, false);\n       if (targetNode \u003d\u003d null) {\n         throw new FileNotFoundException(\"File does not exist: \" + srcs);\n       }\n       else {\n         // Make it relinquish locks everytime contentCountLimit entries are\n         // processed. 0 means disabled. I.e. blocking for the entire duration.\n         ContentSummaryComputationContext cscc \u003d\n-\n-            new ContentSummaryComputationContext(this, getFSNamesystem(),\n-            contentCountLimit);\n+            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n+                fsd.getContentCountLimit());\n         ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n-        yieldCount +\u003d cscc.getYieldCount();\n+        fsd.addYieldCount(cscc.getYieldCount());\n         return cs;\n       }\n     } finally {\n-      readUnlock();\n+      fsd.readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static ContentSummary getContentSummaryInt(\n      FSDirectory fsd, String src) throws IOException {\n    String srcs \u003d FSDirectory.normalizePath(src);\n    fsd.readLock();\n    try {\n      INode targetNode \u003d fsd.getNode(srcs, false);\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + srcs);\n      }\n      else {\n        // Make it relinquish locks everytime contentCountLimit entries are\n        // processed. 0 means disabled. I.e. blocking for the entire duration.\n        ContentSummaryComputationContext cscc \u003d\n            new ContentSummaryComputationContext(fsd, fsd.getFSNamesystem(),\n                fsd.getContentCountLimit());\n        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n        fsd.addYieldCount(cscc.getYieldCount());\n        return cs;\n      }\n    } finally {\n      fsd.readUnlock();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java",
          "extendedDetails": {
            "oldValue": "[src-String]",
            "newValue": "[fsd-FSDirectory, src-String]"
          }
        }
      ]
    },
    "0689363343a281a6f7f6f395227668bddc2663eb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6304. Consolidate the logic of path resolution in FSDirectory. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1591411 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/04/14 10:44 AM",
      "commitName": "0689363343a281a6f7f6f395227668bddc2663eb",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "24/04/14 7:05 PM",
      "commitNameOld": "10a037cccb00c9f791da394bf2dc05985fb80612",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 5.65,
      "commitsBetweenForRepo": 24,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   ContentSummary getContentSummary(String src) \n     throws FileNotFoundException, UnresolvedLinkException {\n     String srcs \u003d normalizePath(src);\n     readLock();\n     try {\n-      INode targetNode \u003d rootDir.getNode(srcs, false);\n+      INode targetNode \u003d getNode(srcs, false);\n       if (targetNode \u003d\u003d null) {\n         throw new FileNotFoundException(\"File does not exist: \" + srcs);\n       }\n       else {\n         // Make it relinquish locks everytime contentCountLimit entries are\n         // processed. 0 means disabled. I.e. blocking for the entire duration.\n         ContentSummaryComputationContext cscc \u003d\n \n             new ContentSummaryComputationContext(this, getFSNamesystem(),\n             contentCountLimit);\n         ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n         yieldCount +\u003d cscc.getYieldCount();\n         return cs;\n       }\n     } finally {\n       readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  ContentSummary getContentSummary(String src) \n    throws FileNotFoundException, UnresolvedLinkException {\n    String srcs \u003d normalizePath(src);\n    readLock();\n    try {\n      INode targetNode \u003d getNode(srcs, false);\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + srcs);\n      }\n      else {\n        // Make it relinquish locks everytime contentCountLimit entries are\n        // processed. 0 means disabled. I.e. blocking for the entire duration.\n        ContentSummaryComputationContext cscc \u003d\n\n            new ContentSummaryComputationContext(this, getFSNamesystem(),\n            contentCountLimit);\n        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n        yieldCount +\u003d cscc.getYieldCount();\n        return cs;\n      }\n    } finally {\n      readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "fe67e30bc2794e7ff073cf938ee80eba805d1e69": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4995. Make getContentSummary less expensive. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541971 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/11/13 8:49 AM",
      "commitName": "fe67e30bc2794e7ff073cf938ee80eba805d1e69",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "16/10/13 7:14 PM",
      "commitNameOld": "34f08944b7c8d58f531a3f3bf3d4ee4cd3fa643a",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 28.61,
      "commitsBetweenForRepo": 141,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,24 @@\n   ContentSummary getContentSummary(String src) \n     throws FileNotFoundException, UnresolvedLinkException {\n     String srcs \u003d normalizePath(src);\n     readLock();\n     try {\n       INode targetNode \u003d rootDir.getNode(srcs, false);\n       if (targetNode \u003d\u003d null) {\n         throw new FileNotFoundException(\"File does not exist: \" + srcs);\n       }\n       else {\n-        return targetNode.computeContentSummary();\n+        // Make it relinquish locks everytime contentCountLimit entries are\n+        // processed. 0 means disabled. I.e. blocking for the entire duration.\n+        ContentSummaryComputationContext cscc \u003d\n+\n+            new ContentSummaryComputationContext(this, getFSNamesystem(),\n+            contentCountLimit);\n+        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n+        yieldCount +\u003d cscc.getYieldCount();\n+        return cs;\n       }\n     } finally {\n       readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  ContentSummary getContentSummary(String src) \n    throws FileNotFoundException, UnresolvedLinkException {\n    String srcs \u003d normalizePath(src);\n    readLock();\n    try {\n      INode targetNode \u003d rootDir.getNode(srcs, false);\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + srcs);\n      }\n      else {\n        // Make it relinquish locks everytime contentCountLimit entries are\n        // processed. 0 means disabled. I.e. blocking for the entire duration.\n        ContentSummaryComputationContext cscc \u003d\n\n            new ContentSummaryComputationContext(this, getFSNamesystem(),\n            contentCountLimit);\n        ContentSummary cs \u003d targetNode.computeAndConvertContentSummary(cscc);\n        yieldCount +\u003d cscc.getYieldCount();\n        return cs;\n      }\n    } finally {\n      readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  ContentSummary getContentSummary(String src) \n    throws FileNotFoundException, UnresolvedLinkException {\n    String srcs \u003d normalizePath(src);\n    readLock();\n    try {\n      INode targetNode \u003d rootDir.getNode(srcs, false);\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + srcs);\n      }\n      else {\n        return targetNode.computeContentSummary();\n      }\n    } finally {\n      readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  ContentSummary getContentSummary(String src) \n    throws FileNotFoundException, UnresolvedLinkException {\n    String srcs \u003d normalizePath(src);\n    readLock();\n    try {\n      INode targetNode \u003d rootDir.getNode(srcs, false);\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + srcs);\n      }\n      else {\n        return targetNode.computeContentSummary();\n      }\n    } finally {\n      readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,16 @@\n+  ContentSummary getContentSummary(String src) \n+    throws FileNotFoundException, UnresolvedLinkException {\n+    String srcs \u003d normalizePath(src);\n+    readLock();\n+    try {\n+      INode targetNode \u003d rootDir.getNode(srcs, false);\n+      if (targetNode \u003d\u003d null) {\n+        throw new FileNotFoundException(\"File does not exist: \" + srcs);\n+      }\n+      else {\n+        return targetNode.computeContentSummary();\n+      }\n+    } finally {\n+      readUnlock();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  ContentSummary getContentSummary(String src) \n    throws FileNotFoundException, UnresolvedLinkException {\n    String srcs \u003d normalizePath(src);\n    readLock();\n    try {\n      INode targetNode \u003d rootDir.getNode(srcs, false);\n      if (targetNode \u003d\u003d null) {\n        throw new FileNotFoundException(\"File does not exist: \" + srcs);\n      }\n      else {\n        return targetNode.computeContentSummary();\n      }\n    } finally {\n      readUnlock();\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java"
    }
  }
}