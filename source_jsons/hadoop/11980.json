{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FsDatasetImpl.java",
  "functionName": "finalizeNewReplica",
  "functionId": "finalizeNewReplica___newReplicaInfo-ReplicaInfo__block-ExtendedBlock",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
  "functionStartLine": 1105,
  "functionEndLine": 1120,
  "numCommitsSeen": 197,
  "timeTaken": 2374,
  "changeHistory": [
    "aa45faf0b20c922b0d147ece9fa01fb95a5b0dec"
  ],
  "changeHistoryShort": {
    "aa45faf0b20c922b0d147ece9fa01fb95a5b0dec": "Yintroduced"
  },
  "changeHistoryDetails": {
    "aa45faf0b20c922b0d147ece9fa01fb95a5b0dec": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-12942. Synchronization issue in FSDataSetImpl#moveBlock. Contributed by Ajay Kumar.\n",
      "commitDate": "01/02/18 6:03 PM",
      "commitName": "aa45faf0b20c922b0d147ece9fa01fb95a5b0dec",
      "commitAuthor": "Anu Engineer",
      "diff": "@@ -0,0 +1,16 @@\n+  void finalizeNewReplica(ReplicaInfo newReplicaInfo,\n+      ExtendedBlock block) throws IOException {\n+    // Finalize the copied files\n+    try {\n+      String bpid \u003d block.getBlockPoolId();\n+      finalizeReplica(bpid, newReplicaInfo);\n+      FsVolumeImpl volume \u003d (FsVolumeImpl) newReplicaInfo.getVolume();\n+      volume.incrNumBlocks(bpid);\n+    } catch (IOException ioe) {\n+      // Cleanup block data and metadata\n+      // Decrement of dfsUsed and noOfBlocks for volume not required\n+      newReplicaInfo.deleteBlockData();\n+      newReplicaInfo.deleteMetadata();\n+      throw ioe;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void finalizeNewReplica(ReplicaInfo newReplicaInfo,\n      ExtendedBlock block) throws IOException {\n    // Finalize the copied files\n    try {\n      String bpid \u003d block.getBlockPoolId();\n      finalizeReplica(bpid, newReplicaInfo);\n      FsVolumeImpl volume \u003d (FsVolumeImpl) newReplicaInfo.getVolume();\n      volume.incrNumBlocks(bpid);\n    } catch (IOException ioe) {\n      // Cleanup block data and metadata\n      // Decrement of dfsUsed and noOfBlocks for volume not required\n      newReplicaInfo.deleteBlockData();\n      newReplicaInfo.deleteMetadata();\n      throw ioe;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java"
    }
  }
}