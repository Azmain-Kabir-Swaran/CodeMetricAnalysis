{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockStorageMovementNeeded.java",
  "functionName": "removeItemTrackInfo",
  "functionId": "removeItemTrackInfo___trackInfo-ItemInfo__isSuccess-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementNeeded.java",
  "functionStartLine": 165,
  "functionEndLine": 189,
  "numCommitsSeen": 38,
  "timeTaken": 9192,
  "changeHistory": [
    "39ed3a66dbb01383ed16b141183fc48bfd2e613d",
    "66e8f9b31529226309c924226a53dead3e6fcf11",
    "8467ec24fb74f30371d5a13e893fc56309ee9372",
    "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d",
    "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
    "78420719eb1f138c6f10558befb7bc8ebcc28a54",
    "c561cb316e365ef674784cd6cf0b12c0fbc271a3",
    "68017e3349e3b71a9c49f2ccea2558231ff8485d",
    "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064"
  ],
  "changeHistoryShort": {
    "39ed3a66dbb01383ed16b141183fc48bfd2e613d": "Ybodychange",
    "66e8f9b31529226309c924226a53dead3e6fcf11": "Ymultichange(Yparameterchange,Ybodychange)",
    "8467ec24fb74f30371d5a13e893fc56309ee9372": "Ymultichange(Yparameterchange,Ybodychange)",
    "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d": "Ybodychange",
    "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d": "Ybodychange",
    "78420719eb1f138c6f10558befb7bc8ebcc28a54": "Yfilerename",
    "c561cb316e365ef674784cd6cf0b12c0fbc271a3": "Ymultichange(Yparameterchange,Ybodychange)",
    "68017e3349e3b71a9c49f2ccea2558231ff8485d": "Ybodychange",
    "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923": "Ybodychange",
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064": "Yintroduced"
  },
  "changeHistoryDetails": {
    "39ed3a66dbb01383ed16b141183fc48bfd2e613d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13076: [SPS]: Cleanup work for HDFS-10285 merge. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "39ed3a66dbb01383ed16b141183fc48bfd2e613d",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "66e8f9b31529226309c924226a53dead3e6fcf11",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,25 @@\n   public synchronized void removeItemTrackInfo(ItemInfo trackInfo,\n       boolean isSuccess) throws IOException {\n     if (trackInfo.isDir()) {\n       // If track is part of some start inode then reduce the pending\n       // directory work count.\n       long startId \u003d trackInfo.getStartPath();\n       if (!ctxt.isFileExist(startId)) {\n         // directory deleted just remove it.\n         this.pendingWorkForDirectory.remove(startId);\n-        updateStatus(startId, isSuccess);\n       } else {\n         DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n         if (pendingWork !\u003d null) {\n           pendingWork.decrementPendingWorkCount();\n           if (pendingWork.isDirWorkDone()) {\n             ctxt.removeSPSHint(startId);\n             pendingWorkForDirectory.remove(startId);\n-            pendingWork.setFailure(!isSuccess);\n-            updateStatus(startId, pendingWork.isPolicySatisfied());\n           }\n-          pendingWork.setFailure(isSuccess);\n         }\n       }\n     } else {\n       // Remove xAttr if trackID doesn\u0027t exist in\n       // storageMovementAttemptedItems or file policy satisfied.\n       ctxt.removeSPSHint(trackInfo.getFile());\n-      updateStatus(trackInfo.getFile(), isSuccess);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void removeItemTrackInfo(ItemInfo trackInfo,\n      boolean isSuccess) throws IOException {\n    if (trackInfo.isDir()) {\n      // If track is part of some start inode then reduce the pending\n      // directory work count.\n      long startId \u003d trackInfo.getStartPath();\n      if (!ctxt.isFileExist(startId)) {\n        // directory deleted just remove it.\n        this.pendingWorkForDirectory.remove(startId);\n      } else {\n        DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n        if (pendingWork !\u003d null) {\n          pendingWork.decrementPendingWorkCount();\n          if (pendingWork.isDirWorkDone()) {\n            ctxt.removeSPSHint(startId);\n            pendingWorkForDirectory.remove(startId);\n          }\n        }\n      }\n    } else {\n      // Remove xAttr if trackID doesn\u0027t exist in\n      // storageMovementAttemptedItems or file policy satisfied.\n      ctxt.removeSPSHint(trackInfo.getFile());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementNeeded.java",
      "extendedDetails": {}
    },
    "66e8f9b31529226309c924226a53dead3e6fcf11": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-13381 : [SPS]: Use DFSUtilClient#makePathFromFileId() to prepare satisfier file path. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "66e8f9b31529226309c924226a53dead3e6fcf11",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13381 : [SPS]: Use DFSUtilClient#makePathFromFileId() to prepare satisfier file path. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "66e8f9b31529226309c924226a53dead3e6fcf11",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,30 +1,30 @@\n-  public synchronized void removeItemTrackInfo(ItemInfo\u003cT\u003e trackInfo,\n+  public synchronized void removeItemTrackInfo(ItemInfo trackInfo,\n       boolean isSuccess) throws IOException {\n     if (trackInfo.isDir()) {\n       // If track is part of some start inode then reduce the pending\n       // directory work count.\n-      T startId \u003d trackInfo.getStartPath();\n+      long startId \u003d trackInfo.getStartPath();\n       if (!ctxt.isFileExist(startId)) {\n         // directory deleted just remove it.\n         this.pendingWorkForDirectory.remove(startId);\n         updateStatus(startId, isSuccess);\n       } else {\n         DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n         if (pendingWork !\u003d null) {\n           pendingWork.decrementPendingWorkCount();\n           if (pendingWork.isDirWorkDone()) {\n             ctxt.removeSPSHint(startId);\n             pendingWorkForDirectory.remove(startId);\n             pendingWork.setFailure(!isSuccess);\n             updateStatus(startId, pendingWork.isPolicySatisfied());\n           }\n           pendingWork.setFailure(isSuccess);\n         }\n       }\n     } else {\n       // Remove xAttr if trackID doesn\u0027t exist in\n       // storageMovementAttemptedItems or file policy satisfied.\n       ctxt.removeSPSHint(trackInfo.getFile());\n       updateStatus(trackInfo.getFile(), isSuccess);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void removeItemTrackInfo(ItemInfo trackInfo,\n      boolean isSuccess) throws IOException {\n    if (trackInfo.isDir()) {\n      // If track is part of some start inode then reduce the pending\n      // directory work count.\n      long startId \u003d trackInfo.getStartPath();\n      if (!ctxt.isFileExist(startId)) {\n        // directory deleted just remove it.\n        this.pendingWorkForDirectory.remove(startId);\n        updateStatus(startId, isSuccess);\n      } else {\n        DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n        if (pendingWork !\u003d null) {\n          pendingWork.decrementPendingWorkCount();\n          if (pendingWork.isDirWorkDone()) {\n            ctxt.removeSPSHint(startId);\n            pendingWorkForDirectory.remove(startId);\n            pendingWork.setFailure(!isSuccess);\n            updateStatus(startId, pendingWork.isPolicySatisfied());\n          }\n          pendingWork.setFailure(isSuccess);\n        }\n      }\n    } else {\n      // Remove xAttr if trackID doesn\u0027t exist in\n      // storageMovementAttemptedItems or file policy satisfied.\n      ctxt.removeSPSHint(trackInfo.getFile());\n      updateStatus(trackInfo.getFile(), isSuccess);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementNeeded.java",
          "extendedDetails": {
            "oldValue": "[trackInfo-ItemInfo\u003cT\u003e, isSuccess-boolean]",
            "newValue": "[trackInfo-ItemInfo, isSuccess-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13381 : [SPS]: Use DFSUtilClient#makePathFromFileId() to prepare satisfier file path. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "66e8f9b31529226309c924226a53dead3e6fcf11",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,30 +1,30 @@\n-  public synchronized void removeItemTrackInfo(ItemInfo\u003cT\u003e trackInfo,\n+  public synchronized void removeItemTrackInfo(ItemInfo trackInfo,\n       boolean isSuccess) throws IOException {\n     if (trackInfo.isDir()) {\n       // If track is part of some start inode then reduce the pending\n       // directory work count.\n-      T startId \u003d trackInfo.getStartPath();\n+      long startId \u003d trackInfo.getStartPath();\n       if (!ctxt.isFileExist(startId)) {\n         // directory deleted just remove it.\n         this.pendingWorkForDirectory.remove(startId);\n         updateStatus(startId, isSuccess);\n       } else {\n         DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n         if (pendingWork !\u003d null) {\n           pendingWork.decrementPendingWorkCount();\n           if (pendingWork.isDirWorkDone()) {\n             ctxt.removeSPSHint(startId);\n             pendingWorkForDirectory.remove(startId);\n             pendingWork.setFailure(!isSuccess);\n             updateStatus(startId, pendingWork.isPolicySatisfied());\n           }\n           pendingWork.setFailure(isSuccess);\n         }\n       }\n     } else {\n       // Remove xAttr if trackID doesn\u0027t exist in\n       // storageMovementAttemptedItems or file policy satisfied.\n       ctxt.removeSPSHint(trackInfo.getFile());\n       updateStatus(trackInfo.getFile(), isSuccess);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void removeItemTrackInfo(ItemInfo trackInfo,\n      boolean isSuccess) throws IOException {\n    if (trackInfo.isDir()) {\n      // If track is part of some start inode then reduce the pending\n      // directory work count.\n      long startId \u003d trackInfo.getStartPath();\n      if (!ctxt.isFileExist(startId)) {\n        // directory deleted just remove it.\n        this.pendingWorkForDirectory.remove(startId);\n        updateStatus(startId, isSuccess);\n      } else {\n        DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n        if (pendingWork !\u003d null) {\n          pendingWork.decrementPendingWorkCount();\n          if (pendingWork.isDirWorkDone()) {\n            ctxt.removeSPSHint(startId);\n            pendingWorkForDirectory.remove(startId);\n            pendingWork.setFailure(!isSuccess);\n            updateStatus(startId, pendingWork.isPolicySatisfied());\n          }\n          pendingWork.setFailure(isSuccess);\n        }\n      }\n    } else {\n      // Remove xAttr if trackID doesn\u0027t exist in\n      // storageMovementAttemptedItems or file policy satisfied.\n      ctxt.removeSPSHint(trackInfo.getFile());\n      updateStatus(trackInfo.getFile(), isSuccess);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementNeeded.java",
          "extendedDetails": {}
        }
      ]
    },
    "8467ec24fb74f30371d5a13e893fc56309ee9372": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-13110: [SPS]: Reduce the number of APIs in NamenodeProtocol used by external satisfier. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "8467ec24fb74f30371d5a13e893fc56309ee9372",
      "commitAuthor": "Rakesh Radhakrishnan",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13110: [SPS]: Reduce the number of APIs in NamenodeProtocol used by external satisfier. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,30 +1,30 @@\n-  public synchronized void removeItemTrackInfo(ItemInfo trackInfo,\n+  public synchronized void removeItemTrackInfo(ItemInfo\u003cT\u003e trackInfo,\n       boolean isSuccess) throws IOException {\n     if (trackInfo.isDir()) {\n       // If track is part of some start inode then reduce the pending\n       // directory work count.\n-      long startId \u003d trackInfo.getStartId();\n+      T startId \u003d trackInfo.getStartPath();\n       if (!ctxt.isFileExist(startId)) {\n         // directory deleted just remove it.\n         this.pendingWorkForDirectory.remove(startId);\n         updateStatus(startId, isSuccess);\n       } else {\n         DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n         if (pendingWork !\u003d null) {\n           pendingWork.decrementPendingWorkCount();\n           if (pendingWork.isDirWorkDone()) {\n             ctxt.removeSPSHint(startId);\n             pendingWorkForDirectory.remove(startId);\n             pendingWork.setFailure(!isSuccess);\n             updateStatus(startId, pendingWork.isPolicySatisfied());\n           }\n           pendingWork.setFailure(isSuccess);\n         }\n       }\n     } else {\n       // Remove xAttr if trackID doesn\u0027t exist in\n       // storageMovementAttemptedItems or file policy satisfied.\n-      ctxt.removeSPSHint(trackInfo.getFileId());\n-      updateStatus(trackInfo.getStartId(), isSuccess);\n+      ctxt.removeSPSHint(trackInfo.getFile());\n+      updateStatus(trackInfo.getFile(), isSuccess);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void removeItemTrackInfo(ItemInfo\u003cT\u003e trackInfo,\n      boolean isSuccess) throws IOException {\n    if (trackInfo.isDir()) {\n      // If track is part of some start inode then reduce the pending\n      // directory work count.\n      T startId \u003d trackInfo.getStartPath();\n      if (!ctxt.isFileExist(startId)) {\n        // directory deleted just remove it.\n        this.pendingWorkForDirectory.remove(startId);\n        updateStatus(startId, isSuccess);\n      } else {\n        DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n        if (pendingWork !\u003d null) {\n          pendingWork.decrementPendingWorkCount();\n          if (pendingWork.isDirWorkDone()) {\n            ctxt.removeSPSHint(startId);\n            pendingWorkForDirectory.remove(startId);\n            pendingWork.setFailure(!isSuccess);\n            updateStatus(startId, pendingWork.isPolicySatisfied());\n          }\n          pendingWork.setFailure(isSuccess);\n        }\n      }\n    } else {\n      // Remove xAttr if trackID doesn\u0027t exist in\n      // storageMovementAttemptedItems or file policy satisfied.\n      ctxt.removeSPSHint(trackInfo.getFile());\n      updateStatus(trackInfo.getFile(), isSuccess);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementNeeded.java",
          "extendedDetails": {
            "oldValue": "[trackInfo-ItemInfo, isSuccess-boolean]",
            "newValue": "[trackInfo-ItemInfo\u003cT\u003e, isSuccess-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13110: [SPS]: Reduce the number of APIs in NamenodeProtocol used by external satisfier. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,30 +1,30 @@\n-  public synchronized void removeItemTrackInfo(ItemInfo trackInfo,\n+  public synchronized void removeItemTrackInfo(ItemInfo\u003cT\u003e trackInfo,\n       boolean isSuccess) throws IOException {\n     if (trackInfo.isDir()) {\n       // If track is part of some start inode then reduce the pending\n       // directory work count.\n-      long startId \u003d trackInfo.getStartId();\n+      T startId \u003d trackInfo.getStartPath();\n       if (!ctxt.isFileExist(startId)) {\n         // directory deleted just remove it.\n         this.pendingWorkForDirectory.remove(startId);\n         updateStatus(startId, isSuccess);\n       } else {\n         DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n         if (pendingWork !\u003d null) {\n           pendingWork.decrementPendingWorkCount();\n           if (pendingWork.isDirWorkDone()) {\n             ctxt.removeSPSHint(startId);\n             pendingWorkForDirectory.remove(startId);\n             pendingWork.setFailure(!isSuccess);\n             updateStatus(startId, pendingWork.isPolicySatisfied());\n           }\n           pendingWork.setFailure(isSuccess);\n         }\n       }\n     } else {\n       // Remove xAttr if trackID doesn\u0027t exist in\n       // storageMovementAttemptedItems or file policy satisfied.\n-      ctxt.removeSPSHint(trackInfo.getFileId());\n-      updateStatus(trackInfo.getStartId(), isSuccess);\n+      ctxt.removeSPSHint(trackInfo.getFile());\n+      updateStatus(trackInfo.getFile(), isSuccess);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void removeItemTrackInfo(ItemInfo\u003cT\u003e trackInfo,\n      boolean isSuccess) throws IOException {\n    if (trackInfo.isDir()) {\n      // If track is part of some start inode then reduce the pending\n      // directory work count.\n      T startId \u003d trackInfo.getStartPath();\n      if (!ctxt.isFileExist(startId)) {\n        // directory deleted just remove it.\n        this.pendingWorkForDirectory.remove(startId);\n        updateStatus(startId, isSuccess);\n      } else {\n        DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n        if (pendingWork !\u003d null) {\n          pendingWork.decrementPendingWorkCount();\n          if (pendingWork.isDirWorkDone()) {\n            ctxt.removeSPSHint(startId);\n            pendingWorkForDirectory.remove(startId);\n            pendingWork.setFailure(!isSuccess);\n            updateStatus(startId, pendingWork.isPolicySatisfied());\n          }\n          pendingWork.setFailure(isSuccess);\n        }\n      }\n    } else {\n      // Remove xAttr if trackID doesn\u0027t exist in\n      // storageMovementAttemptedItems or file policy satisfied.\n      ctxt.removeSPSHint(trackInfo.getFile());\n      updateStatus(trackInfo.getFile(), isSuccess);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementNeeded.java",
          "extendedDetails": {}
        }
      ]
    },
    "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12911. [SPS]: Modularize the SPS code and expose necessary interfaces for external/internal implementations. Contributed by Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,30 @@\n   public synchronized void removeItemTrackInfo(ItemInfo trackInfo,\n       boolean isSuccess) throws IOException {\n     if (trackInfo.isDir()) {\n       // If track is part of some start inode then reduce the pending\n       // directory work count.\n       long startId \u003d trackInfo.getStartId();\n       if (!ctxt.isFileExist(startId)) {\n         // directory deleted just remove it.\n         this.pendingWorkForDirectory.remove(startId);\n         updateStatus(startId, isSuccess);\n       } else {\n         DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n         if (pendingWork !\u003d null) {\n           pendingWork.decrementPendingWorkCount();\n           if (pendingWork.isDirWorkDone()) {\n             ctxt.removeSPSHint(startId);\n             pendingWorkForDirectory.remove(startId);\n             pendingWork.setFailure(!isSuccess);\n             updateStatus(startId, pendingWork.isPolicySatisfied());\n           }\n           pendingWork.setFailure(isSuccess);\n         }\n       }\n     } else {\n       // Remove xAttr if trackID doesn\u0027t exist in\n       // storageMovementAttemptedItems or file policy satisfied.\n-      ctxt.removeSPSHint(trackInfo.getTrackId());\n+      ctxt.removeSPSHint(trackInfo.getFileId());\n       updateStatus(trackInfo.getStartId(), isSuccess);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void removeItemTrackInfo(ItemInfo trackInfo,\n      boolean isSuccess) throws IOException {\n    if (trackInfo.isDir()) {\n      // If track is part of some start inode then reduce the pending\n      // directory work count.\n      long startId \u003d trackInfo.getStartId();\n      if (!ctxt.isFileExist(startId)) {\n        // directory deleted just remove it.\n        this.pendingWorkForDirectory.remove(startId);\n        updateStatus(startId, isSuccess);\n      } else {\n        DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n        if (pendingWork !\u003d null) {\n          pendingWork.decrementPendingWorkCount();\n          if (pendingWork.isDirWorkDone()) {\n            ctxt.removeSPSHint(startId);\n            pendingWorkForDirectory.remove(startId);\n            pendingWork.setFailure(!isSuccess);\n            updateStatus(startId, pendingWork.isPolicySatisfied());\n          }\n          pendingWork.setFailure(isSuccess);\n        }\n      }\n    } else {\n      // Remove xAttr if trackID doesn\u0027t exist in\n      // storageMovementAttemptedItems or file policy satisfied.\n      ctxt.removeSPSHint(trackInfo.getFileId());\n      updateStatus(trackInfo.getStartId(), isSuccess);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementNeeded.java",
      "extendedDetails": {}
    },
    "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12982 : [SPS]: Reduce the locking and cleanup the Namesystem access. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "78420719eb1f138c6f10558befb7bc8ebcc28a54",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,30 @@\n   public synchronized void removeItemTrackInfo(ItemInfo trackInfo,\n       boolean isSuccess) throws IOException {\n     if (trackInfo.isDir()) {\n       // If track is part of some start inode then reduce the pending\n       // directory work count.\n       long startId \u003d trackInfo.getStartId();\n-      INode inode \u003d namesystem.getFSDirectory().getInode(startId);\n-      if (inode \u003d\u003d null) {\n+      if (!ctxt.isFileExist(startId)) {\n         // directory deleted just remove it.\n         this.pendingWorkForDirectory.remove(startId);\n         updateStatus(startId, isSuccess);\n       } else {\n         DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n         if (pendingWork !\u003d null) {\n           pendingWork.decrementPendingWorkCount();\n           if (pendingWork.isDirWorkDone()) {\n-            namesystem.removeXattr(startId, XATTR_SATISFY_STORAGE_POLICY);\n+            ctxt.removeSPSHint(startId);\n             pendingWorkForDirectory.remove(startId);\n             pendingWork.setFailure(!isSuccess);\n             updateStatus(startId, pendingWork.isPolicySatisfied());\n           }\n           pendingWork.setFailure(isSuccess);\n         }\n       }\n     } else {\n       // Remove xAttr if trackID doesn\u0027t exist in\n       // storageMovementAttemptedItems or file policy satisfied.\n-      namesystem.removeXattr(trackInfo.getTrackId(),\n-          XATTR_SATISFY_STORAGE_POLICY);\n+      ctxt.removeSPSHint(trackInfo.getTrackId());\n       updateStatus(trackInfo.getStartId(), isSuccess);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void removeItemTrackInfo(ItemInfo trackInfo,\n      boolean isSuccess) throws IOException {\n    if (trackInfo.isDir()) {\n      // If track is part of some start inode then reduce the pending\n      // directory work count.\n      long startId \u003d trackInfo.getStartId();\n      if (!ctxt.isFileExist(startId)) {\n        // directory deleted just remove it.\n        this.pendingWorkForDirectory.remove(startId);\n        updateStatus(startId, isSuccess);\n      } else {\n        DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n        if (pendingWork !\u003d null) {\n          pendingWork.decrementPendingWorkCount();\n          if (pendingWork.isDirWorkDone()) {\n            ctxt.removeSPSHint(startId);\n            pendingWorkForDirectory.remove(startId);\n            pendingWork.setFailure(!isSuccess);\n            updateStatus(startId, pendingWork.isPolicySatisfied());\n          }\n          pendingWork.setFailure(isSuccess);\n        }\n      }\n    } else {\n      // Remove xAttr if trackID doesn\u0027t exist in\n      // storageMovementAttemptedItems or file policy satisfied.\n      ctxt.removeSPSHint(trackInfo.getTrackId());\n      updateStatus(trackInfo.getStartId(), isSuccess);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementNeeded.java",
      "extendedDetails": {}
    },
    "78420719eb1f138c6f10558befb7bc8ebcc28a54": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-12955: [SPS]: Move SPS classes to a separate package. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "78420719eb1f138c6f10558befb7bc8ebcc28a54",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "c561cb316e365ef674784cd6cf0b12c0fbc271a3",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public synchronized void removeItemTrackInfo(ItemInfo trackInfo,\n      boolean isSuccess) throws IOException {\n    if (trackInfo.isDir()) {\n      // If track is part of some start inode then reduce the pending\n      // directory work count.\n      long startId \u003d trackInfo.getStartId();\n      INode inode \u003d namesystem.getFSDirectory().getInode(startId);\n      if (inode \u003d\u003d null) {\n        // directory deleted just remove it.\n        this.pendingWorkForDirectory.remove(startId);\n        updateStatus(startId, isSuccess);\n      } else {\n        DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n        if (pendingWork !\u003d null) {\n          pendingWork.decrementPendingWorkCount();\n          if (pendingWork.isDirWorkDone()) {\n            namesystem.removeXattr(startId, XATTR_SATISFY_STORAGE_POLICY);\n            pendingWorkForDirectory.remove(startId);\n            pendingWork.setFailure(!isSuccess);\n            updateStatus(startId, pendingWork.isPolicySatisfied());\n          }\n          pendingWork.setFailure(isSuccess);\n        }\n      }\n    } else {\n      // Remove xAttr if trackID doesn\u0027t exist in\n      // storageMovementAttemptedItems or file policy satisfied.\n      namesystem.removeXattr(trackInfo.getTrackId(),\n          XATTR_SATISFY_STORAGE_POLICY);\n      updateStatus(trackInfo.getStartId(), isSuccess);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementNeeded.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementNeeded.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementNeeded.java"
      }
    },
    "c561cb316e365ef674784cd6cf0b12c0fbc271a3": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-12106: [SPS]: Improve storage policy satisfier configurations. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "c561cb316e365ef674784cd6cf0b12c0fbc271a3",
      "commitAuthor": "Surendra Singh Lilhore",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-12106: [SPS]: Improve storage policy satisfier configurations. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "c561cb316e365ef674784cd6cf0b12c0fbc271a3",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "68017e3349e3b71a9c49f2ccea2558231ff8485d",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,30 +1,32 @@\n-  public synchronized void removeItemTrackInfo(ItemInfo trackInfo)\n-      throws IOException {\n+  public synchronized void removeItemTrackInfo(ItemInfo trackInfo,\n+      boolean isSuccess) throws IOException {\n     if (trackInfo.isDir()) {\n       // If track is part of some start inode then reduce the pending\n       // directory work count.\n       long startId \u003d trackInfo.getStartId();\n       INode inode \u003d namesystem.getFSDirectory().getInode(startId);\n       if (inode \u003d\u003d null) {\n         // directory deleted just remove it.\n         this.pendingWorkForDirectory.remove(startId);\n-        markSuccess(startId);\n+        updateStatus(startId, isSuccess);\n       } else {\n         DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n         if (pendingWork !\u003d null) {\n           pendingWork.decrementPendingWorkCount();\n           if (pendingWork.isDirWorkDone()) {\n             namesystem.removeXattr(startId, XATTR_SATISFY_STORAGE_POLICY);\n             pendingWorkForDirectory.remove(startId);\n-            markSuccess(startId);\n+            pendingWork.setFailure(!isSuccess);\n+            updateStatus(startId, pendingWork.isPolicySatisfied());\n           }\n+          pendingWork.setFailure(isSuccess);\n         }\n       }\n     } else {\n       // Remove xAttr if trackID doesn\u0027t exist in\n       // storageMovementAttemptedItems or file policy satisfied.\n       namesystem.removeXattr(trackInfo.getTrackId(),\n           XATTR_SATISFY_STORAGE_POLICY);\n-      markSuccess(trackInfo.getStartId());\n+      updateStatus(trackInfo.getStartId(), isSuccess);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void removeItemTrackInfo(ItemInfo trackInfo,\n      boolean isSuccess) throws IOException {\n    if (trackInfo.isDir()) {\n      // If track is part of some start inode then reduce the pending\n      // directory work count.\n      long startId \u003d trackInfo.getStartId();\n      INode inode \u003d namesystem.getFSDirectory().getInode(startId);\n      if (inode \u003d\u003d null) {\n        // directory deleted just remove it.\n        this.pendingWorkForDirectory.remove(startId);\n        updateStatus(startId, isSuccess);\n      } else {\n        DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n        if (pendingWork !\u003d null) {\n          pendingWork.decrementPendingWorkCount();\n          if (pendingWork.isDirWorkDone()) {\n            namesystem.removeXattr(startId, XATTR_SATISFY_STORAGE_POLICY);\n            pendingWorkForDirectory.remove(startId);\n            pendingWork.setFailure(!isSuccess);\n            updateStatus(startId, pendingWork.isPolicySatisfied());\n          }\n          pendingWork.setFailure(isSuccess);\n        }\n      }\n    } else {\n      // Remove xAttr if trackID doesn\u0027t exist in\n      // storageMovementAttemptedItems or file policy satisfied.\n      namesystem.removeXattr(trackInfo.getTrackId(),\n          XATTR_SATISFY_STORAGE_POLICY);\n      updateStatus(trackInfo.getStartId(), isSuccess);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementNeeded.java",
          "extendedDetails": {
            "oldValue": "[trackInfo-ItemInfo]",
            "newValue": "[trackInfo-ItemInfo, isSuccess-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-12106: [SPS]: Improve storage policy satisfier configurations. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "c561cb316e365ef674784cd6cf0b12c0fbc271a3",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "68017e3349e3b71a9c49f2ccea2558231ff8485d",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,30 +1,32 @@\n-  public synchronized void removeItemTrackInfo(ItemInfo trackInfo)\n-      throws IOException {\n+  public synchronized void removeItemTrackInfo(ItemInfo trackInfo,\n+      boolean isSuccess) throws IOException {\n     if (trackInfo.isDir()) {\n       // If track is part of some start inode then reduce the pending\n       // directory work count.\n       long startId \u003d trackInfo.getStartId();\n       INode inode \u003d namesystem.getFSDirectory().getInode(startId);\n       if (inode \u003d\u003d null) {\n         // directory deleted just remove it.\n         this.pendingWorkForDirectory.remove(startId);\n-        markSuccess(startId);\n+        updateStatus(startId, isSuccess);\n       } else {\n         DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n         if (pendingWork !\u003d null) {\n           pendingWork.decrementPendingWorkCount();\n           if (pendingWork.isDirWorkDone()) {\n             namesystem.removeXattr(startId, XATTR_SATISFY_STORAGE_POLICY);\n             pendingWorkForDirectory.remove(startId);\n-            markSuccess(startId);\n+            pendingWork.setFailure(!isSuccess);\n+            updateStatus(startId, pendingWork.isPolicySatisfied());\n           }\n+          pendingWork.setFailure(isSuccess);\n         }\n       }\n     } else {\n       // Remove xAttr if trackID doesn\u0027t exist in\n       // storageMovementAttemptedItems or file policy satisfied.\n       namesystem.removeXattr(trackInfo.getTrackId(),\n           XATTR_SATISFY_STORAGE_POLICY);\n-      markSuccess(trackInfo.getStartId());\n+      updateStatus(trackInfo.getStartId(), isSuccess);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void removeItemTrackInfo(ItemInfo trackInfo,\n      boolean isSuccess) throws IOException {\n    if (trackInfo.isDir()) {\n      // If track is part of some start inode then reduce the pending\n      // directory work count.\n      long startId \u003d trackInfo.getStartId();\n      INode inode \u003d namesystem.getFSDirectory().getInode(startId);\n      if (inode \u003d\u003d null) {\n        // directory deleted just remove it.\n        this.pendingWorkForDirectory.remove(startId);\n        updateStatus(startId, isSuccess);\n      } else {\n        DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n        if (pendingWork !\u003d null) {\n          pendingWork.decrementPendingWorkCount();\n          if (pendingWork.isDirWorkDone()) {\n            namesystem.removeXattr(startId, XATTR_SATISFY_STORAGE_POLICY);\n            pendingWorkForDirectory.remove(startId);\n            pendingWork.setFailure(!isSuccess);\n            updateStatus(startId, pendingWork.isPolicySatisfied());\n          }\n          pendingWork.setFailure(isSuccess);\n        }\n      }\n    } else {\n      // Remove xAttr if trackID doesn\u0027t exist in\n      // storageMovementAttemptedItems or file policy satisfied.\n      namesystem.removeXattr(trackInfo.getTrackId(),\n          XATTR_SATISFY_STORAGE_POLICY);\n      updateStatus(trackInfo.getStartId(), isSuccess);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementNeeded.java",
          "extendedDetails": {}
        }
      ]
    },
    "68017e3349e3b71a9c49f2ccea2558231ff8485d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12310: [SPS]: Provide an option to track the status of in progress requests. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "68017e3349e3b71a9c49f2ccea2558231ff8485d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,30 @@\n   public synchronized void removeItemTrackInfo(ItemInfo trackInfo)\n       throws IOException {\n     if (trackInfo.isDir()) {\n       // If track is part of some start inode then reduce the pending\n       // directory work count.\n       long startId \u003d trackInfo.getStartId();\n       INode inode \u003d namesystem.getFSDirectory().getInode(startId);\n       if (inode \u003d\u003d null) {\n         // directory deleted just remove it.\n         this.pendingWorkForDirectory.remove(startId);\n+        markSuccess(startId);\n       } else {\n         DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n         if (pendingWork !\u003d null) {\n           pendingWork.decrementPendingWorkCount();\n           if (pendingWork.isDirWorkDone()) {\n             namesystem.removeXattr(startId, XATTR_SATISFY_STORAGE_POLICY);\n             pendingWorkForDirectory.remove(startId);\n+            markSuccess(startId);\n           }\n         }\n       }\n     } else {\n       // Remove xAttr if trackID doesn\u0027t exist in\n       // storageMovementAttemptedItems or file policy satisfied.\n       namesystem.removeXattr(trackInfo.getTrackId(),\n           XATTR_SATISFY_STORAGE_POLICY);\n+      markSuccess(trackInfo.getStartId());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void removeItemTrackInfo(ItemInfo trackInfo)\n      throws IOException {\n    if (trackInfo.isDir()) {\n      // If track is part of some start inode then reduce the pending\n      // directory work count.\n      long startId \u003d trackInfo.getStartId();\n      INode inode \u003d namesystem.getFSDirectory().getInode(startId);\n      if (inode \u003d\u003d null) {\n        // directory deleted just remove it.\n        this.pendingWorkForDirectory.remove(startId);\n        markSuccess(startId);\n      } else {\n        DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n        if (pendingWork !\u003d null) {\n          pendingWork.decrementPendingWorkCount();\n          if (pendingWork.isDirWorkDone()) {\n            namesystem.removeXattr(startId, XATTR_SATISFY_STORAGE_POLICY);\n            pendingWorkForDirectory.remove(startId);\n            markSuccess(startId);\n          }\n        }\n      }\n    } else {\n      // Remove xAttr if trackID doesn\u0027t exist in\n      // storageMovementAttemptedItems or file policy satisfied.\n      namesystem.removeXattr(trackInfo.getTrackId(),\n          XATTR_SATISFY_STORAGE_POLICY);\n      markSuccess(trackInfo.getStartId());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementNeeded.java",
      "extendedDetails": {}
    },
    "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12291: [SPS]: Provide a mechanism to recursively iterate and satisfy storage policy of all the files under the given dir. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,27 @@\n   public synchronized void removeItemTrackInfo(ItemInfo trackInfo)\n       throws IOException {\n     if (trackInfo.isDir()) {\n-      // If track is part of some root then reduce the pending directory work\n-      // count.\n-      long rootId \u003d trackInfo.getRootId();\n-      INode inode \u003d namesystem.getFSDirectory().getInode(rootId);\n+      // If track is part of some start inode then reduce the pending\n+      // directory work count.\n+      long startId \u003d trackInfo.getStartId();\n+      INode inode \u003d namesystem.getFSDirectory().getInode(startId);\n       if (inode \u003d\u003d null) {\n         // directory deleted just remove it.\n-        this.pendingWorkForDirectory.remove(rootId);\n+        this.pendingWorkForDirectory.remove(startId);\n       } else {\n-        if (pendingWorkForDirectory.get(rootId) !\u003d null) {\n-          Integer pendingWork \u003d pendingWorkForDirectory.get(rootId) - 1;\n-          pendingWorkForDirectory.put(rootId, pendingWork);\n-          if (pendingWork \u003c\u003d 0) {\n-            namesystem.removeXattr(rootId, XATTR_SATISFY_STORAGE_POLICY);\n-            pendingWorkForDirectory.remove(rootId);\n+        DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n+        if (pendingWork !\u003d null) {\n+          pendingWork.decrementPendingWorkCount();\n+          if (pendingWork.isDirWorkDone()) {\n+            namesystem.removeXattr(startId, XATTR_SATISFY_STORAGE_POLICY);\n+            pendingWorkForDirectory.remove(startId);\n           }\n         }\n       }\n     } else {\n       // Remove xAttr if trackID doesn\u0027t exist in\n       // storageMovementAttemptedItems or file policy satisfied.\n       namesystem.removeXattr(trackInfo.getTrackId(),\n           XATTR_SATISFY_STORAGE_POLICY);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void removeItemTrackInfo(ItemInfo trackInfo)\n      throws IOException {\n    if (trackInfo.isDir()) {\n      // If track is part of some start inode then reduce the pending\n      // directory work count.\n      long startId \u003d trackInfo.getStartId();\n      INode inode \u003d namesystem.getFSDirectory().getInode(startId);\n      if (inode \u003d\u003d null) {\n        // directory deleted just remove it.\n        this.pendingWorkForDirectory.remove(startId);\n      } else {\n        DirPendingWorkInfo pendingWork \u003d pendingWorkForDirectory.get(startId);\n        if (pendingWork !\u003d null) {\n          pendingWork.decrementPendingWorkCount();\n          if (pendingWork.isDirWorkDone()) {\n            namesystem.removeXattr(startId, XATTR_SATISFY_STORAGE_POLICY);\n            pendingWorkForDirectory.remove(startId);\n          }\n        }\n      }\n    } else {\n      // Remove xAttr if trackID doesn\u0027t exist in\n      // storageMovementAttemptedItems or file policy satisfied.\n      namesystem.removeXattr(trackInfo.getTrackId(),\n          XATTR_SATISFY_STORAGE_POLICY);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementNeeded.java",
      "extendedDetails": {}
    },
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-12225: [SPS]: Optimize extended attributes for tracking SPS movements. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
      "commitAuthor": "Uma Maheswara Rao G",
      "diff": "@@ -0,0 +1,27 @@\n+  public synchronized void removeItemTrackInfo(ItemInfo trackInfo)\n+      throws IOException {\n+    if (trackInfo.isDir()) {\n+      // If track is part of some root then reduce the pending directory work\n+      // count.\n+      long rootId \u003d trackInfo.getRootId();\n+      INode inode \u003d namesystem.getFSDirectory().getInode(rootId);\n+      if (inode \u003d\u003d null) {\n+        // directory deleted just remove it.\n+        this.pendingWorkForDirectory.remove(rootId);\n+      } else {\n+        if (pendingWorkForDirectory.get(rootId) !\u003d null) {\n+          Integer pendingWork \u003d pendingWorkForDirectory.get(rootId) - 1;\n+          pendingWorkForDirectory.put(rootId, pendingWork);\n+          if (pendingWork \u003c\u003d 0) {\n+            namesystem.removeXattr(rootId, XATTR_SATISFY_STORAGE_POLICY);\n+            pendingWorkForDirectory.remove(rootId);\n+          }\n+        }\n+      }\n+    } else {\n+      // Remove xAttr if trackID doesn\u0027t exist in\n+      // storageMovementAttemptedItems or file policy satisfied.\n+      namesystem.removeXattr(trackInfo.getTrackId(),\n+          XATTR_SATISFY_STORAGE_POLICY);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void removeItemTrackInfo(ItemInfo trackInfo)\n      throws IOException {\n    if (trackInfo.isDir()) {\n      // If track is part of some root then reduce the pending directory work\n      // count.\n      long rootId \u003d trackInfo.getRootId();\n      INode inode \u003d namesystem.getFSDirectory().getInode(rootId);\n      if (inode \u003d\u003d null) {\n        // directory deleted just remove it.\n        this.pendingWorkForDirectory.remove(rootId);\n      } else {\n        if (pendingWorkForDirectory.get(rootId) !\u003d null) {\n          Integer pendingWork \u003d pendingWorkForDirectory.get(rootId) - 1;\n          pendingWorkForDirectory.put(rootId, pendingWork);\n          if (pendingWork \u003c\u003d 0) {\n            namesystem.removeXattr(rootId, XATTR_SATISFY_STORAGE_POLICY);\n            pendingWorkForDirectory.remove(rootId);\n          }\n        }\n      }\n    } else {\n      // Remove xAttr if trackID doesn\u0027t exist in\n      // storageMovementAttemptedItems or file policy satisfied.\n      namesystem.removeXattr(trackInfo.getTrackId(),\n          XATTR_SATISFY_STORAGE_POLICY);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementNeeded.java"
    }
  }
}