{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PersistentLongFile.java",
  "functionName": "readFile",
  "functionId": "readFile___file-File__defaultVal-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/PersistentLongFile.java",
  "functionStartLine": 91,
  "functionEndLine": 108,
  "numCommitsSeen": 6,
  "timeTaken": 2098,
  "changeHistory": [
    "f3296501e09fa7f1e81548dfcefa56f20fe337ca",
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
    "14556cc5d8fee8f8a846e4f65572828553be386c",
    "6449f524552f8c24d20b314ad21f6c579fa08e85",
    "8dd3148e734fa9d1db761ce65410fdc49c0fe1d5"
  ],
  "changeHistoryShort": {
    "f3296501e09fa7f1e81548dfcefa56f20fe337ca": "Ybodychange",
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568": "Ybodychange",
    "14556cc5d8fee8f8a846e4f65572828553be386c": "Ybodychange",
    "6449f524552f8c24d20b314ad21f6c579fa08e85": "Ybodychange",
    "8dd3148e734fa9d1db761ce65410fdc49c0fe1d5": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f3296501e09fa7f1e81548dfcefa56f20fe337ca": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14043. Tolerate corrupted seen_txid file. Contributed by Lukas Majercak.\n",
      "commitDate": "05/11/18 4:48 PM",
      "commitName": "f3296501e09fa7f1e81548dfcefa56f20fe337ca",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "06/09/18 2:48 PM",
      "commitNameOld": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 60.13,
      "commitsBetweenForRepo": 607,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,18 @@\n   public static long readFile(File file, long defaultVal) throws IOException {\n     long val \u003d defaultVal;\n     if (file.exists()) {\n       BufferedReader br \u003d \n           new BufferedReader(new InputStreamReader(new FileInputStream(\n               file), Charsets.UTF_8));\n       try {\n         val \u003d Long.parseLong(br.readLine());\n         br.close();\n         br \u003d null;\n+      } catch (NumberFormatException e) {\n+        throw new IOException(e);\n       } finally {\n         IOUtils.cleanupWithLogger(LOG, br);\n       }\n     }\n     return val;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static long readFile(File file, long defaultVal) throws IOException {\n    long val \u003d defaultVal;\n    if (file.exists()) {\n      BufferedReader br \u003d \n          new BufferedReader(new InputStreamReader(new FileInputStream(\n              file), Charsets.UTF_8));\n      try {\n        val \u003d Long.parseLong(br.readLine());\n        br.close();\n        br \u003d null;\n      } catch (NumberFormatException e) {\n        throw new IOException(e);\n      } finally {\n        IOUtils.cleanupWithLogger(LOG, br);\n      }\n    }\n    return val;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/PersistentLongFile.java",
      "extendedDetails": {}
    },
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13695. Move logging to slf4j in HDFS package. Contributed by Ian Pickering.\n",
      "commitDate": "06/09/18 2:48 PM",
      "commitName": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "26/03/14 2:27 PM",
      "commitNameOld": "14556cc5d8fee8f8a846e4f65572828553be386c",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 1625.01,
      "commitsBetweenForRepo": 12405,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n   public static long readFile(File file, long defaultVal) throws IOException {\n     long val \u003d defaultVal;\n     if (file.exists()) {\n       BufferedReader br \u003d \n           new BufferedReader(new InputStreamReader(new FileInputStream(\n               file), Charsets.UTF_8));\n       try {\n         val \u003d Long.parseLong(br.readLine());\n         br.close();\n         br \u003d null;\n       } finally {\n-        IOUtils.cleanup(LOG, br);\n+        IOUtils.cleanupWithLogger(LOG, br);\n       }\n     }\n     return val;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static long readFile(File file, long defaultVal) throws IOException {\n    long val \u003d defaultVal;\n    if (file.exists()) {\n      BufferedReader br \u003d \n          new BufferedReader(new InputStreamReader(new FileInputStream(\n              file), Charsets.UTF_8));\n      try {\n        val \u003d Long.parseLong(br.readLine());\n        br.close();\n        br \u003d null;\n      } finally {\n        IOUtils.cleanupWithLogger(LOG, br);\n      }\n    }\n    return val;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/PersistentLongFile.java",
      "extendedDetails": {}
    },
    "14556cc5d8fee8f8a846e4f65572828553be386c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6155. Fix Boxing/unboxing to parse a primitive findbugs warnings. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1582068 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/03/14 2:27 PM",
      "commitName": "14556cc5d8fee8f8a846e4f65572828553be386c",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "09/01/13 6:30 PM",
      "commitNameOld": "6449f524552f8c24d20b314ad21f6c579fa08e85",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 440.79,
      "commitsBetweenForRepo": 2868,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n   public static long readFile(File file, long defaultVal) throws IOException {\n     long val \u003d defaultVal;\n     if (file.exists()) {\n       BufferedReader br \u003d \n           new BufferedReader(new InputStreamReader(new FileInputStream(\n               file), Charsets.UTF_8));\n       try {\n-        val \u003d Long.valueOf(br.readLine());\n+        val \u003d Long.parseLong(br.readLine());\n         br.close();\n         br \u003d null;\n       } finally {\n         IOUtils.cleanup(LOG, br);\n       }\n     }\n     return val;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static long readFile(File file, long defaultVal) throws IOException {\n    long val \u003d defaultVal;\n    if (file.exists()) {\n      BufferedReader br \u003d \n          new BufferedReader(new InputStreamReader(new FileInputStream(\n              file), Charsets.UTF_8));\n      try {\n        val \u003d Long.parseLong(br.readLine());\n        br.close();\n        br \u003d null;\n      } finally {\n        IOUtils.cleanup(LOG, br);\n      }\n    }\n    return val;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/PersistentLongFile.java",
      "extendedDetails": {}
    },
    "6449f524552f8c24d20b314ad21f6c579fa08e85": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4032. Specify the charset explicitly rather than rely on the default. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1431179 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/13 6:30 PM",
      "commitName": "6449f524552f8c24d20b314ad21f6c579fa08e85",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "19/09/12 11:52 AM",
      "commitNameOld": "663e7484c04c197eed53f10a7808140f1c955277",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 112.32,
      "commitsBetweenForRepo": 546,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,16 @@\n   public static long readFile(File file, long defaultVal) throws IOException {\n     long val \u003d defaultVal;\n     if (file.exists()) {\n-      BufferedReader br \u003d new BufferedReader(new FileReader(file));\n+      BufferedReader br \u003d \n+          new BufferedReader(new InputStreamReader(new FileInputStream(\n+              file), Charsets.UTF_8));\n       try {\n         val \u003d Long.valueOf(br.readLine());\n         br.close();\n         br \u003d null;\n       } finally {\n         IOUtils.cleanup(LOG, br);\n       }\n     }\n     return val;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static long readFile(File file, long defaultVal) throws IOException {\n    long val \u003d defaultVal;\n    if (file.exists()) {\n      BufferedReader br \u003d \n          new BufferedReader(new InputStreamReader(new FileInputStream(\n              file), Charsets.UTF_8));\n      try {\n        val \u003d Long.valueOf(br.readLine());\n        br.close();\n        br \u003d null;\n      } finally {\n        IOUtils.cleanup(LOG, br);\n      }\n    }\n    return val;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/PersistentLongFile.java",
      "extendedDetails": {}
    },
    "8dd3148e734fa9d1db761ce65410fdc49c0fe1d5": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3190. Simple refactors in existing NN code to assist QuorumJournalManager extension. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1356525 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/07/12 4:59 PM",
      "commitName": "8dd3148e734fa9d1db761ce65410fdc49c0fe1d5",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,14 @@\n+  public static long readFile(File file, long defaultVal) throws IOException {\n+    long val \u003d defaultVal;\n+    if (file.exists()) {\n+      BufferedReader br \u003d new BufferedReader(new FileReader(file));\n+      try {\n+        val \u003d Long.valueOf(br.readLine());\n+        br.close();\n+        br \u003d null;\n+      } finally {\n+        IOUtils.cleanup(LOG, br);\n+      }\n+    }\n+    return val;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static long readFile(File file, long defaultVal) throws IOException {\n    long val \u003d defaultVal;\n    if (file.exists()) {\n      BufferedReader br \u003d new BufferedReader(new FileReader(file));\n      try {\n        val \u003d Long.valueOf(br.readLine());\n        br.close();\n        br \u003d null;\n      } finally {\n        IOUtils.cleanup(LOG, br);\n      }\n    }\n    return val;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/PersistentLongFile.java"
    }
  }
}