{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DistributedPentomino.java",
  "functionName": "run",
  "functionId": "run___args-String[]",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/dancing/DistributedPentomino.java",
  "functionStartLine": 169,
  "functionEndLine": 227,
  "numCommitsSeen": 9,
  "timeTaken": 4988,
  "changeHistory": [
    "bd69fb2d44403e930d1fc0868ed1dd2a49dd9659",
    "d9a21df34b23efeeae83fe0d2674cbbfc81b2912",
    "e45b10365568185d0fd22546a4b666fa77dea7a9",
    "26447229ba2c3d43db978c1b3ce95613669182ee",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "bd69fb2d44403e930d1fc0868ed1dd2a49dd9659": "Ybodychange",
    "d9a21df34b23efeeae83fe0d2674cbbfc81b2912": "Ybodychange",
    "e45b10365568185d0fd22546a4b666fa77dea7a9": "Ybodychange",
    "26447229ba2c3d43db978c1b3ce95613669182ee": "Yfilerename",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "bd69fb2d44403e930d1fc0868ed1dd2a49dd9659": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5800. Use Job#getInstance instead of deprecated constructors. (aajisaka)\n",
      "commitDate": "03/02/15 2:30 PM",
      "commitName": "bd69fb2d44403e930d1fc0868ed1dd2a49dd9659",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "15/01/13 5:53 AM",
      "commitNameOld": "d9a21df34b23efeeae83fe0d2674cbbfc81b2912",
      "commitAuthorOld": "Harsh J",
      "daysBetweenCommits": 749.36,
      "commitsBetweenForRepo": 5233,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,59 +1,59 @@\n   public int run(String[] args) throws Exception {\n     Configuration conf \u003d getConf();\n     if (args.length \u003d\u003d 0) {\n       System.out.println(\"Usage: pentomino \u003coutput\u003e [-depth #] [-height #] [-width #]\");\n       ToolRunner.printGenericCommandUsage(System.out);\n       return 2;\n     }\n     // check for passed parameters, otherwise use defaults\n     int width \u003d conf.getInt(Pentomino.WIDTH, PENT_WIDTH);\n     int height \u003d conf.getInt(Pentomino.HEIGHT, PENT_HEIGHT);\n     int depth \u003d conf.getInt(Pentomino.DEPTH, PENT_DEPTH);\n     for (int i \u003d 0; i \u003c args.length; i++) {\n       if (args[i].equalsIgnoreCase(\"-depth\")) {\n         depth \u003d Integer.parseInt(args[++i].trim());\n       } else if (args[i].equalsIgnoreCase(\"-height\")) {\n         height \u003d Integer.parseInt(args[++i].trim());\n       } else if (args[i].equalsIgnoreCase(\"-width\") ) {\n         width \u003d Integer.parseInt(args[++i].trim());\n       }\n     }\n     // now set the values within conf for M/R tasks to read, this\n     // will ensure values are set preventing MAPREDUCE-4678\n     conf.setInt(Pentomino.WIDTH, width);\n     conf.setInt(Pentomino.HEIGHT, height);\n     conf.setInt(Pentomino.DEPTH, depth);\n     Class\u003c? extends Pentomino\u003e pentClass \u003d conf.getClass(Pentomino.CLASS, \n       OneSidedPentomino.class, Pentomino.class);\n     int numMaps \u003d conf.getInt(MRJobConfig.NUM_MAPS, DEFAULT_MAPS);\n     Path output \u003d new Path(args[0]);\n     Path input \u003d new Path(output + \"_input\");\n     FileSystem fileSys \u003d FileSystem.get(conf);\n     try {\n-      Job job \u003d new Job(conf);\n+      Job job \u003d Job.getInstance(conf);\n       FileInputFormat.setInputPaths(job, input);\n       FileOutputFormat.setOutputPath(job, output);\n       job.setJarByClass(PentMap.class);\n       \n       job.setJobName(\"dancingElephant\");\n       Pentomino pent \u003d ReflectionUtils.newInstance(pentClass, conf);\n       pent.initialize(width, height);\n       long inputSize \u003d createInputDirectory(fileSys, input, pent, depth);\n       // for forcing the number of maps\n       FileInputFormat.setMaxInputSplitSize(job, (inputSize/numMaps));\n    \n       // the keys are the prefix strings\n       job.setOutputKeyClass(Text.class);\n       // the values are puzzle solutions\n       job.setOutputValueClass(Text.class);\n       \n       job.setMapperClass(PentMap.class);        \n       job.setReducerClass(Reducer.class);\n       \n       job.setNumReduceTasks(1);\n       \n       return (job.waitForCompletion(true) ? 0 : 1);\n       } finally {\n       fileSys.delete(input, true);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    Configuration conf \u003d getConf();\n    if (args.length \u003d\u003d 0) {\n      System.out.println(\"Usage: pentomino \u003coutput\u003e [-depth #] [-height #] [-width #]\");\n      ToolRunner.printGenericCommandUsage(System.out);\n      return 2;\n    }\n    // check for passed parameters, otherwise use defaults\n    int width \u003d conf.getInt(Pentomino.WIDTH, PENT_WIDTH);\n    int height \u003d conf.getInt(Pentomino.HEIGHT, PENT_HEIGHT);\n    int depth \u003d conf.getInt(Pentomino.DEPTH, PENT_DEPTH);\n    for (int i \u003d 0; i \u003c args.length; i++) {\n      if (args[i].equalsIgnoreCase(\"-depth\")) {\n        depth \u003d Integer.parseInt(args[++i].trim());\n      } else if (args[i].equalsIgnoreCase(\"-height\")) {\n        height \u003d Integer.parseInt(args[++i].trim());\n      } else if (args[i].equalsIgnoreCase(\"-width\") ) {\n        width \u003d Integer.parseInt(args[++i].trim());\n      }\n    }\n    // now set the values within conf for M/R tasks to read, this\n    // will ensure values are set preventing MAPREDUCE-4678\n    conf.setInt(Pentomino.WIDTH, width);\n    conf.setInt(Pentomino.HEIGHT, height);\n    conf.setInt(Pentomino.DEPTH, depth);\n    Class\u003c? extends Pentomino\u003e pentClass \u003d conf.getClass(Pentomino.CLASS, \n      OneSidedPentomino.class, Pentomino.class);\n    int numMaps \u003d conf.getInt(MRJobConfig.NUM_MAPS, DEFAULT_MAPS);\n    Path output \u003d new Path(args[0]);\n    Path input \u003d new Path(output + \"_input\");\n    FileSystem fileSys \u003d FileSystem.get(conf);\n    try {\n      Job job \u003d Job.getInstance(conf);\n      FileInputFormat.setInputPaths(job, input);\n      FileOutputFormat.setOutputPath(job, output);\n      job.setJarByClass(PentMap.class);\n      \n      job.setJobName(\"dancingElephant\");\n      Pentomino pent \u003d ReflectionUtils.newInstance(pentClass, conf);\n      pent.initialize(width, height);\n      long inputSize \u003d createInputDirectory(fileSys, input, pent, depth);\n      // for forcing the number of maps\n      FileInputFormat.setMaxInputSplitSize(job, (inputSize/numMaps));\n   \n      // the keys are the prefix strings\n      job.setOutputKeyClass(Text.class);\n      // the values are puzzle solutions\n      job.setOutputValueClass(Text.class);\n      \n      job.setMapperClass(PentMap.class);        \n      job.setReducerClass(Reducer.class);\n      \n      job.setNumReduceTasks(1);\n      \n      return (job.waitForCompletion(true) ? 0 : 1);\n      } finally {\n      fileSys.delete(input, true);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/dancing/DistributedPentomino.java",
      "extendedDetails": {}
    },
    "d9a21df34b23efeeae83fe0d2674cbbfc81b2912": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4925. The pentomino option parser may be buggy. Contributed by Karthik Kambatla. (harsh)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1433414 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/01/13 5:53 AM",
      "commitName": "d9a21df34b23efeeae83fe0d2674cbbfc81b2912",
      "commitAuthor": "Harsh J",
      "commitDateOld": "14/11/12 4:16 PM",
      "commitNameOld": "905b17876c44634545a68300ff2f2d73fb86d3b7",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 61.57,
      "commitsBetweenForRepo": 251,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,59 +1,59 @@\n   public int run(String[] args) throws Exception {\n     Configuration conf \u003d getConf();\n     if (args.length \u003d\u003d 0) {\n       System.out.println(\"Usage: pentomino \u003coutput\u003e [-depth #] [-height #] [-width #]\");\n       ToolRunner.printGenericCommandUsage(System.out);\n       return 2;\n     }\n     // check for passed parameters, otherwise use defaults\n-    int width \u003d PENT_WIDTH;\n-    int height \u003d PENT_HEIGHT;\n-    int depth \u003d PENT_DEPTH;\n+    int width \u003d conf.getInt(Pentomino.WIDTH, PENT_WIDTH);\n+    int height \u003d conf.getInt(Pentomino.HEIGHT, PENT_HEIGHT);\n+    int depth \u003d conf.getInt(Pentomino.DEPTH, PENT_DEPTH);\n     for (int i \u003d 0; i \u003c args.length; i++) {\n       if (args[i].equalsIgnoreCase(\"-depth\")) {\n-          depth \u003d Integer.parseInt(args[i++].trim());\n+        depth \u003d Integer.parseInt(args[++i].trim());\n       } else if (args[i].equalsIgnoreCase(\"-height\")) {\n-\t  height \u003d Integer.parseInt(args[i++].trim());\n+        height \u003d Integer.parseInt(args[++i].trim());\n       } else if (args[i].equalsIgnoreCase(\"-width\") ) {\n-\t  width \u003d Integer.parseInt(args[i++].trim()); \n+        width \u003d Integer.parseInt(args[++i].trim());\n       }\n     }\n     // now set the values within conf for M/R tasks to read, this\n     // will ensure values are set preventing MAPREDUCE-4678\n     conf.setInt(Pentomino.WIDTH, width);\n     conf.setInt(Pentomino.HEIGHT, height);\n     conf.setInt(Pentomino.DEPTH, depth);\n     Class\u003c? extends Pentomino\u003e pentClass \u003d conf.getClass(Pentomino.CLASS, \n       OneSidedPentomino.class, Pentomino.class);\n     int numMaps \u003d conf.getInt(MRJobConfig.NUM_MAPS, DEFAULT_MAPS);\n     Path output \u003d new Path(args[0]);\n     Path input \u003d new Path(output + \"_input\");\n     FileSystem fileSys \u003d FileSystem.get(conf);\n     try {\n       Job job \u003d new Job(conf);\n       FileInputFormat.setInputPaths(job, input);\n       FileOutputFormat.setOutputPath(job, output);\n       job.setJarByClass(PentMap.class);\n       \n       job.setJobName(\"dancingElephant\");\n       Pentomino pent \u003d ReflectionUtils.newInstance(pentClass, conf);\n       pent.initialize(width, height);\n       long inputSize \u003d createInputDirectory(fileSys, input, pent, depth);\n       // for forcing the number of maps\n       FileInputFormat.setMaxInputSplitSize(job, (inputSize/numMaps));\n    \n       // the keys are the prefix strings\n       job.setOutputKeyClass(Text.class);\n       // the values are puzzle solutions\n       job.setOutputValueClass(Text.class);\n       \n       job.setMapperClass(PentMap.class);        \n       job.setReducerClass(Reducer.class);\n       \n       job.setNumReduceTasks(1);\n       \n       return (job.waitForCompletion(true) ? 0 : 1);\n       } finally {\n       fileSys.delete(input, true);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    Configuration conf \u003d getConf();\n    if (args.length \u003d\u003d 0) {\n      System.out.println(\"Usage: pentomino \u003coutput\u003e [-depth #] [-height #] [-width #]\");\n      ToolRunner.printGenericCommandUsage(System.out);\n      return 2;\n    }\n    // check for passed parameters, otherwise use defaults\n    int width \u003d conf.getInt(Pentomino.WIDTH, PENT_WIDTH);\n    int height \u003d conf.getInt(Pentomino.HEIGHT, PENT_HEIGHT);\n    int depth \u003d conf.getInt(Pentomino.DEPTH, PENT_DEPTH);\n    for (int i \u003d 0; i \u003c args.length; i++) {\n      if (args[i].equalsIgnoreCase(\"-depth\")) {\n        depth \u003d Integer.parseInt(args[++i].trim());\n      } else if (args[i].equalsIgnoreCase(\"-height\")) {\n        height \u003d Integer.parseInt(args[++i].trim());\n      } else if (args[i].equalsIgnoreCase(\"-width\") ) {\n        width \u003d Integer.parseInt(args[++i].trim());\n      }\n    }\n    // now set the values within conf for M/R tasks to read, this\n    // will ensure values are set preventing MAPREDUCE-4678\n    conf.setInt(Pentomino.WIDTH, width);\n    conf.setInt(Pentomino.HEIGHT, height);\n    conf.setInt(Pentomino.DEPTH, depth);\n    Class\u003c? extends Pentomino\u003e pentClass \u003d conf.getClass(Pentomino.CLASS, \n      OneSidedPentomino.class, Pentomino.class);\n    int numMaps \u003d conf.getInt(MRJobConfig.NUM_MAPS, DEFAULT_MAPS);\n    Path output \u003d new Path(args[0]);\n    Path input \u003d new Path(output + \"_input\");\n    FileSystem fileSys \u003d FileSystem.get(conf);\n    try {\n      Job job \u003d new Job(conf);\n      FileInputFormat.setInputPaths(job, input);\n      FileOutputFormat.setOutputPath(job, output);\n      job.setJarByClass(PentMap.class);\n      \n      job.setJobName(\"dancingElephant\");\n      Pentomino pent \u003d ReflectionUtils.newInstance(pentClass, conf);\n      pent.initialize(width, height);\n      long inputSize \u003d createInputDirectory(fileSys, input, pent, depth);\n      // for forcing the number of maps\n      FileInputFormat.setMaxInputSplitSize(job, (inputSize/numMaps));\n   \n      // the keys are the prefix strings\n      job.setOutputKeyClass(Text.class);\n      // the values are puzzle solutions\n      job.setOutputValueClass(Text.class);\n      \n      job.setMapperClass(PentMap.class);        \n      job.setReducerClass(Reducer.class);\n      \n      job.setNumReduceTasks(1);\n      \n      return (job.waitForCompletion(true) ? 0 : 1);\n      } finally {\n      fileSys.delete(input, true);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/dancing/DistributedPentomino.java",
      "extendedDetails": {}
    },
    "e45b10365568185d0fd22546a4b666fa77dea7a9": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4678. Running the Pentomino example with defaults throws java.lang.NegativeArraySizeException. Contributed by Chris McConnell. (harsh)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1391551 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/09/12 9:48 AM",
      "commitName": "e45b10365568185d0fd22546a4b666fa77dea7a9",
      "commitAuthor": "Harsh J",
      "commitDateOld": "18/11/11 5:24 PM",
      "commitNameOld": "26447229ba2c3d43db978c1b3ce95613669182ee",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 314.64,
      "commitsBetweenForRepo": 2000,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,45 +1,59 @@\n   public int run(String[] args) throws Exception {\n+    Configuration conf \u003d getConf();\n     if (args.length \u003d\u003d 0) {\n-      System.out.println(\"pentomino \u003coutput\u003e\");\n+      System.out.println(\"Usage: pentomino \u003coutput\u003e [-depth #] [-height #] [-width #]\");\n       ToolRunner.printGenericCommandUsage(System.out);\n       return 2;\n     }\n-\n-    Configuration conf \u003d getConf();\n-    int width \u003d conf.getInt(Pentomino.WIDTH, PENT_WIDTH);\n-    int height \u003d conf.getInt(Pentomino.HEIGHT, PENT_HEIGHT);\n-    int depth \u003d conf.getInt(Pentomino.DEPTH, PENT_DEPTH);\n+    // check for passed parameters, otherwise use defaults\n+    int width \u003d PENT_WIDTH;\n+    int height \u003d PENT_HEIGHT;\n+    int depth \u003d PENT_DEPTH;\n+    for (int i \u003d 0; i \u003c args.length; i++) {\n+      if (args[i].equalsIgnoreCase(\"-depth\")) {\n+          depth \u003d Integer.parseInt(args[i++].trim());\n+      } else if (args[i].equalsIgnoreCase(\"-height\")) {\n+\t  height \u003d Integer.parseInt(args[i++].trim());\n+      } else if (args[i].equalsIgnoreCase(\"-width\") ) {\n+\t  width \u003d Integer.parseInt(args[i++].trim()); \n+      }\n+    }\n+    // now set the values within conf for M/R tasks to read, this\n+    // will ensure values are set preventing MAPREDUCE-4678\n+    conf.setInt(Pentomino.WIDTH, width);\n+    conf.setInt(Pentomino.HEIGHT, height);\n+    conf.setInt(Pentomino.DEPTH, depth);\n     Class\u003c? extends Pentomino\u003e pentClass \u003d conf.getClass(Pentomino.CLASS, \n       OneSidedPentomino.class, Pentomino.class);\n     int numMaps \u003d conf.getInt(MRJobConfig.NUM_MAPS, DEFAULT_MAPS);\n     Path output \u003d new Path(args[0]);\n     Path input \u003d new Path(output + \"_input\");\n     FileSystem fileSys \u003d FileSystem.get(conf);\n     try {\n       Job job \u003d new Job(conf);\n       FileInputFormat.setInputPaths(job, input);\n       FileOutputFormat.setOutputPath(job, output);\n       job.setJarByClass(PentMap.class);\n       \n       job.setJobName(\"dancingElephant\");\n       Pentomino pent \u003d ReflectionUtils.newInstance(pentClass, conf);\n       pent.initialize(width, height);\n       long inputSize \u003d createInputDirectory(fileSys, input, pent, depth);\n       // for forcing the number of maps\n       FileInputFormat.setMaxInputSplitSize(job, (inputSize/numMaps));\n    \n       // the keys are the prefix strings\n       job.setOutputKeyClass(Text.class);\n       // the values are puzzle solutions\n       job.setOutputValueClass(Text.class);\n       \n       job.setMapperClass(PentMap.class);        \n       job.setReducerClass(Reducer.class);\n       \n       job.setNumReduceTasks(1);\n       \n       return (job.waitForCompletion(true) ? 0 : 1);\n       } finally {\n       fileSys.delete(input, true);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    Configuration conf \u003d getConf();\n    if (args.length \u003d\u003d 0) {\n      System.out.println(\"Usage: pentomino \u003coutput\u003e [-depth #] [-height #] [-width #]\");\n      ToolRunner.printGenericCommandUsage(System.out);\n      return 2;\n    }\n    // check for passed parameters, otherwise use defaults\n    int width \u003d PENT_WIDTH;\n    int height \u003d PENT_HEIGHT;\n    int depth \u003d PENT_DEPTH;\n    for (int i \u003d 0; i \u003c args.length; i++) {\n      if (args[i].equalsIgnoreCase(\"-depth\")) {\n          depth \u003d Integer.parseInt(args[i++].trim());\n      } else if (args[i].equalsIgnoreCase(\"-height\")) {\n\t  height \u003d Integer.parseInt(args[i++].trim());\n      } else if (args[i].equalsIgnoreCase(\"-width\") ) {\n\t  width \u003d Integer.parseInt(args[i++].trim()); \n      }\n    }\n    // now set the values within conf for M/R tasks to read, this\n    // will ensure values are set preventing MAPREDUCE-4678\n    conf.setInt(Pentomino.WIDTH, width);\n    conf.setInt(Pentomino.HEIGHT, height);\n    conf.setInt(Pentomino.DEPTH, depth);\n    Class\u003c? extends Pentomino\u003e pentClass \u003d conf.getClass(Pentomino.CLASS, \n      OneSidedPentomino.class, Pentomino.class);\n    int numMaps \u003d conf.getInt(MRJobConfig.NUM_MAPS, DEFAULT_MAPS);\n    Path output \u003d new Path(args[0]);\n    Path input \u003d new Path(output + \"_input\");\n    FileSystem fileSys \u003d FileSystem.get(conf);\n    try {\n      Job job \u003d new Job(conf);\n      FileInputFormat.setInputPaths(job, input);\n      FileOutputFormat.setOutputPath(job, output);\n      job.setJarByClass(PentMap.class);\n      \n      job.setJobName(\"dancingElephant\");\n      Pentomino pent \u003d ReflectionUtils.newInstance(pentClass, conf);\n      pent.initialize(width, height);\n      long inputSize \u003d createInputDirectory(fileSys, input, pent, depth);\n      // for forcing the number of maps\n      FileInputFormat.setMaxInputSplitSize(job, (inputSize/numMaps));\n   \n      // the keys are the prefix strings\n      job.setOutputKeyClass(Text.class);\n      // the values are puzzle solutions\n      job.setOutputValueClass(Text.class);\n      \n      job.setMapperClass(PentMap.class);        \n      job.setReducerClass(Reducer.class);\n      \n      job.setNumReduceTasks(1);\n      \n      return (job.waitForCompletion(true) ? 0 : 1);\n      } finally {\n      fileSys.delete(input, true);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/dancing/DistributedPentomino.java",
      "extendedDetails": {}
    },
    "26447229ba2c3d43db978c1b3ce95613669182ee": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7590. Mavenize streaming and MR examples. (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1203941 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/11/11 5:24 PM",
      "commitName": "26447229ba2c3d43db978c1b3ce95613669182ee",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "18/11/11 1:04 AM",
      "commitNameOld": "905a127850d5e0cba85c2e075f989fa0f5cf129a",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.68,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int run(String[] args) throws Exception {\n    if (args.length \u003d\u003d 0) {\n      System.out.println(\"pentomino \u003coutput\u003e\");\n      ToolRunner.printGenericCommandUsage(System.out);\n      return 2;\n    }\n\n    Configuration conf \u003d getConf();\n    int width \u003d conf.getInt(Pentomino.WIDTH, PENT_WIDTH);\n    int height \u003d conf.getInt(Pentomino.HEIGHT, PENT_HEIGHT);\n    int depth \u003d conf.getInt(Pentomino.DEPTH, PENT_DEPTH);\n    Class\u003c? extends Pentomino\u003e pentClass \u003d conf.getClass(Pentomino.CLASS, \n      OneSidedPentomino.class, Pentomino.class);\n    int numMaps \u003d conf.getInt(MRJobConfig.NUM_MAPS, DEFAULT_MAPS);\n    Path output \u003d new Path(args[0]);\n    Path input \u003d new Path(output + \"_input\");\n    FileSystem fileSys \u003d FileSystem.get(conf);\n    try {\n      Job job \u003d new Job(conf);\n      FileInputFormat.setInputPaths(job, input);\n      FileOutputFormat.setOutputPath(job, output);\n      job.setJarByClass(PentMap.class);\n      \n      job.setJobName(\"dancingElephant\");\n      Pentomino pent \u003d ReflectionUtils.newInstance(pentClass, conf);\n      pent.initialize(width, height);\n      long inputSize \u003d createInputDirectory(fileSys, input, pent, depth);\n      // for forcing the number of maps\n      FileInputFormat.setMaxInputSplitSize(job, (inputSize/numMaps));\n   \n      // the keys are the prefix strings\n      job.setOutputKeyClass(Text.class);\n      // the values are puzzle solutions\n      job.setOutputValueClass(Text.class);\n      \n      job.setMapperClass(PentMap.class);        \n      job.setReducerClass(Reducer.class);\n      \n      job.setNumReduceTasks(1);\n      \n      return (job.waitForCompletion(true) ? 0 : 1);\n      } finally {\n      fileSys.delete(input, true);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/dancing/DistributedPentomino.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/src/examples/org/apache/hadoop/examples/dancing/DistributedPentomino.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/dancing/DistributedPentomino.java"
      }
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int run(String[] args) throws Exception {\n    if (args.length \u003d\u003d 0) {\n      System.out.println(\"pentomino \u003coutput\u003e\");\n      ToolRunner.printGenericCommandUsage(System.out);\n      return 2;\n    }\n\n    Configuration conf \u003d getConf();\n    int width \u003d conf.getInt(Pentomino.WIDTH, PENT_WIDTH);\n    int height \u003d conf.getInt(Pentomino.HEIGHT, PENT_HEIGHT);\n    int depth \u003d conf.getInt(Pentomino.DEPTH, PENT_DEPTH);\n    Class\u003c? extends Pentomino\u003e pentClass \u003d conf.getClass(Pentomino.CLASS, \n      OneSidedPentomino.class, Pentomino.class);\n    int numMaps \u003d conf.getInt(MRJobConfig.NUM_MAPS, DEFAULT_MAPS);\n    Path output \u003d new Path(args[0]);\n    Path input \u003d new Path(output + \"_input\");\n    FileSystem fileSys \u003d FileSystem.get(conf);\n    try {\n      Job job \u003d new Job(conf);\n      FileInputFormat.setInputPaths(job, input);\n      FileOutputFormat.setOutputPath(job, output);\n      job.setJarByClass(PentMap.class);\n      \n      job.setJobName(\"dancingElephant\");\n      Pentomino pent \u003d ReflectionUtils.newInstance(pentClass, conf);\n      pent.initialize(width, height);\n      long inputSize \u003d createInputDirectory(fileSys, input, pent, depth);\n      // for forcing the number of maps\n      FileInputFormat.setMaxInputSplitSize(job, (inputSize/numMaps));\n   \n      // the keys are the prefix strings\n      job.setOutputKeyClass(Text.class);\n      // the values are puzzle solutions\n      job.setOutputValueClass(Text.class);\n      \n      job.setMapperClass(PentMap.class);        \n      job.setReducerClass(Reducer.class);\n      \n      job.setNumReduceTasks(1);\n      \n      return (job.waitForCompletion(true) ? 0 : 1);\n      } finally {\n      fileSys.delete(input, true);\n    }\n  }",
      "path": "hadoop-mapreduce-project/src/examples/org/apache/hadoop/examples/dancing/DistributedPentomino.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/src/examples/org/apache/hadoop/examples/dancing/DistributedPentomino.java",
        "newPath": "hadoop-mapreduce-project/src/examples/org/apache/hadoop/examples/dancing/DistributedPentomino.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int run(String[] args) throws Exception {\n    if (args.length \u003d\u003d 0) {\n      System.out.println(\"pentomino \u003coutput\u003e\");\n      ToolRunner.printGenericCommandUsage(System.out);\n      return 2;\n    }\n\n    Configuration conf \u003d getConf();\n    int width \u003d conf.getInt(Pentomino.WIDTH, PENT_WIDTH);\n    int height \u003d conf.getInt(Pentomino.HEIGHT, PENT_HEIGHT);\n    int depth \u003d conf.getInt(Pentomino.DEPTH, PENT_DEPTH);\n    Class\u003c? extends Pentomino\u003e pentClass \u003d conf.getClass(Pentomino.CLASS, \n      OneSidedPentomino.class, Pentomino.class);\n    int numMaps \u003d conf.getInt(MRJobConfig.NUM_MAPS, DEFAULT_MAPS);\n    Path output \u003d new Path(args[0]);\n    Path input \u003d new Path(output + \"_input\");\n    FileSystem fileSys \u003d FileSystem.get(conf);\n    try {\n      Job job \u003d new Job(conf);\n      FileInputFormat.setInputPaths(job, input);\n      FileOutputFormat.setOutputPath(job, output);\n      job.setJarByClass(PentMap.class);\n      \n      job.setJobName(\"dancingElephant\");\n      Pentomino pent \u003d ReflectionUtils.newInstance(pentClass, conf);\n      pent.initialize(width, height);\n      long inputSize \u003d createInputDirectory(fileSys, input, pent, depth);\n      // for forcing the number of maps\n      FileInputFormat.setMaxInputSplitSize(job, (inputSize/numMaps));\n   \n      // the keys are the prefix strings\n      job.setOutputKeyClass(Text.class);\n      // the values are puzzle solutions\n      job.setOutputValueClass(Text.class);\n      \n      job.setMapperClass(PentMap.class);        \n      job.setReducerClass(Reducer.class);\n      \n      job.setNumReduceTasks(1);\n      \n      return (job.waitForCompletion(true) ? 0 : 1);\n      } finally {\n      fileSys.delete(input, true);\n    }\n  }",
      "path": "hadoop-mapreduce/src/examples/org/apache/hadoop/examples/dancing/DistributedPentomino.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/examples/org/apache/hadoop/examples/dancing/DistributedPentomino.java",
        "newPath": "hadoop-mapreduce/src/examples/org/apache/hadoop/examples/dancing/DistributedPentomino.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,45 @@\n+  public int run(String[] args) throws Exception {\n+    if (args.length \u003d\u003d 0) {\n+      System.out.println(\"pentomino \u003coutput\u003e\");\n+      ToolRunner.printGenericCommandUsage(System.out);\n+      return 2;\n+    }\n+\n+    Configuration conf \u003d getConf();\n+    int width \u003d conf.getInt(Pentomino.WIDTH, PENT_WIDTH);\n+    int height \u003d conf.getInt(Pentomino.HEIGHT, PENT_HEIGHT);\n+    int depth \u003d conf.getInt(Pentomino.DEPTH, PENT_DEPTH);\n+    Class\u003c? extends Pentomino\u003e pentClass \u003d conf.getClass(Pentomino.CLASS, \n+      OneSidedPentomino.class, Pentomino.class);\n+    int numMaps \u003d conf.getInt(MRJobConfig.NUM_MAPS, DEFAULT_MAPS);\n+    Path output \u003d new Path(args[0]);\n+    Path input \u003d new Path(output + \"_input\");\n+    FileSystem fileSys \u003d FileSystem.get(conf);\n+    try {\n+      Job job \u003d new Job(conf);\n+      FileInputFormat.setInputPaths(job, input);\n+      FileOutputFormat.setOutputPath(job, output);\n+      job.setJarByClass(PentMap.class);\n+      \n+      job.setJobName(\"dancingElephant\");\n+      Pentomino pent \u003d ReflectionUtils.newInstance(pentClass, conf);\n+      pent.initialize(width, height);\n+      long inputSize \u003d createInputDirectory(fileSys, input, pent, depth);\n+      // for forcing the number of maps\n+      FileInputFormat.setMaxInputSplitSize(job, (inputSize/numMaps));\n+   \n+      // the keys are the prefix strings\n+      job.setOutputKeyClass(Text.class);\n+      // the values are puzzle solutions\n+      job.setOutputValueClass(Text.class);\n+      \n+      job.setMapperClass(PentMap.class);        \n+      job.setReducerClass(Reducer.class);\n+      \n+      job.setNumReduceTasks(1);\n+      \n+      return (job.waitForCompletion(true) ? 0 : 1);\n+      } finally {\n+      fileSys.delete(input, true);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    if (args.length \u003d\u003d 0) {\n      System.out.println(\"pentomino \u003coutput\u003e\");\n      ToolRunner.printGenericCommandUsage(System.out);\n      return 2;\n    }\n\n    Configuration conf \u003d getConf();\n    int width \u003d conf.getInt(Pentomino.WIDTH, PENT_WIDTH);\n    int height \u003d conf.getInt(Pentomino.HEIGHT, PENT_HEIGHT);\n    int depth \u003d conf.getInt(Pentomino.DEPTH, PENT_DEPTH);\n    Class\u003c? extends Pentomino\u003e pentClass \u003d conf.getClass(Pentomino.CLASS, \n      OneSidedPentomino.class, Pentomino.class);\n    int numMaps \u003d conf.getInt(MRJobConfig.NUM_MAPS, DEFAULT_MAPS);\n    Path output \u003d new Path(args[0]);\n    Path input \u003d new Path(output + \"_input\");\n    FileSystem fileSys \u003d FileSystem.get(conf);\n    try {\n      Job job \u003d new Job(conf);\n      FileInputFormat.setInputPaths(job, input);\n      FileOutputFormat.setOutputPath(job, output);\n      job.setJarByClass(PentMap.class);\n      \n      job.setJobName(\"dancingElephant\");\n      Pentomino pent \u003d ReflectionUtils.newInstance(pentClass, conf);\n      pent.initialize(width, height);\n      long inputSize \u003d createInputDirectory(fileSys, input, pent, depth);\n      // for forcing the number of maps\n      FileInputFormat.setMaxInputSplitSize(job, (inputSize/numMaps));\n   \n      // the keys are the prefix strings\n      job.setOutputKeyClass(Text.class);\n      // the values are puzzle solutions\n      job.setOutputValueClass(Text.class);\n      \n      job.setMapperClass(PentMap.class);        \n      job.setReducerClass(Reducer.class);\n      \n      job.setNumReduceTasks(1);\n      \n      return (job.waitForCompletion(true) ? 0 : 1);\n      } finally {\n      fileSys.delete(input, true);\n    }\n  }",
      "path": "mapreduce/src/examples/org/apache/hadoop/examples/dancing/DistributedPentomino.java"
    }
  }
}