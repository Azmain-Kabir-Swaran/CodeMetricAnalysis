{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSNamesystem.java",
  "functionName": "startFile",
  "functionId": "startFile___src-String__permissions-PermissionStatus__holder-String__clientMachine-String__flag-EnumSet__CreateFlag____createParent-boolean__replication-short__blockSize-long__supportedVersions-CryptoProtocolVersion[]__ecPolicyName-String__storagePolicy-String__logRetryCache-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
  "functionStartLine": 2598,
  "functionEndLine": 2615,
  "numCommitsSeen": 3347,
  "timeTaken": 32680,
  "changeHistory": [
    "0d7a5ac5f526801367a9ec963e6d72783b637d55",
    "9b90e52f1ec22c18cd535af2a569defcef65b093",
    "a7312715a66dec5173c3a0a78dff4e0333e7f0b1",
    "2b6bcfdafa91223a4116e3e9304579f5f91dccac",
    "8e253cb93030642f5a7324bad0f161cd0ad33206",
    "e96ce6f3e3e549202ce3c48d4733ba34098870ad"
  ],
  "changeHistoryShort": {
    "0d7a5ac5f526801367a9ec963e6d72783b637d55": "Ymultichange(Yparameterchange,Ybodychange)",
    "9b90e52f1ec22c18cd535af2a569defcef65b093": "Ybodychange",
    "a7312715a66dec5173c3a0a78dff4e0333e7f0b1": "Ymultichange(Yparameterchange,Ybodychange)",
    "2b6bcfdafa91223a4116e3e9304579f5f91dccac": "Ymultichange(Yexceptionschange,Ybodychange)",
    "8e253cb93030642f5a7324bad0f161cd0ad33206": "Ymultichange(Yparameterchange,Ybodychange)",
    "e96ce6f3e3e549202ce3c48d4733ba34098870ad": "Ymultichange(Yparameterchange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "0d7a5ac5f526801367a9ec963e6d72783b637d55": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-13209. DistributedFileSystem.create should allow an option to provide StoragePolicy. Contributed by Ayush Saxena.\n",
      "commitDate": "14/02/19 8:43 AM",
      "commitName": "0d7a5ac5f526801367a9ec963e6d72783b637d55",
      "commitAuthor": "Surendra Singh Lilhore",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13209. DistributedFileSystem.create should allow an option to provide StoragePolicy. Contributed by Ayush Saxena.\n",
          "commitDate": "14/02/19 8:43 AM",
          "commitName": "0d7a5ac5f526801367a9ec963e6d72783b637d55",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "25/01/19 7:37 AM",
          "commitNameOld": "45caeee6cfcf1ae3355cd880402159cf31e94a8a",
          "commitAuthorOld": "Dinesh Chitlangia",
          "daysBetweenCommits": 20.05,
          "commitsBetweenForRepo": 127,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,18 @@\n   HdfsFileStatus startFile(String src, PermissionStatus permissions,\n       String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n       boolean createParent, short replication, long blockSize,\n       CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n-      boolean logRetryCache) throws IOException {\n+      String storagePolicy, boolean logRetryCache) throws IOException {\n \n     HdfsFileStatus status;\n     try {\n       status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n           createParent, replication, blockSize, supportedVersions, ecPolicyName,\n-          logRetryCache);\n+          storagePolicy, logRetryCache);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"create\", src);\n       throw e;\n     }\n     logAuditEvent(true, \"create\", src, status);\n     return status;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HdfsFileStatus startFile(String src, PermissionStatus permissions,\n      String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n      boolean createParent, short replication, long blockSize,\n      CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n      String storagePolicy, boolean logRetryCache) throws IOException {\n\n    HdfsFileStatus status;\n    try {\n      status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n          createParent, replication, blockSize, supportedVersions, ecPolicyName,\n          storagePolicy, logRetryCache);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"create\", src);\n      throw e;\n    }\n    logAuditEvent(true, \"create\", src, status);\n    return status;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[src-String, permissions-PermissionStatus, holder-String, clientMachine-String, flag-EnumSet\u003cCreateFlag\u003e, createParent-boolean, replication-short, blockSize-long, supportedVersions-CryptoProtocolVersion[], ecPolicyName-String, logRetryCache-boolean]",
            "newValue": "[src-String, permissions-PermissionStatus, holder-String, clientMachine-String, flag-EnumSet\u003cCreateFlag\u003e, createParent-boolean, replication-short, blockSize-long, supportedVersions-CryptoProtocolVersion[], ecPolicyName-String, storagePolicy-String, logRetryCache-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13209. DistributedFileSystem.create should allow an option to provide StoragePolicy. Contributed by Ayush Saxena.\n",
          "commitDate": "14/02/19 8:43 AM",
          "commitName": "0d7a5ac5f526801367a9ec963e6d72783b637d55",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "25/01/19 7:37 AM",
          "commitNameOld": "45caeee6cfcf1ae3355cd880402159cf31e94a8a",
          "commitAuthorOld": "Dinesh Chitlangia",
          "daysBetweenCommits": 20.05,
          "commitsBetweenForRepo": 127,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,18 @@\n   HdfsFileStatus startFile(String src, PermissionStatus permissions,\n       String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n       boolean createParent, short replication, long blockSize,\n       CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n-      boolean logRetryCache) throws IOException {\n+      String storagePolicy, boolean logRetryCache) throws IOException {\n \n     HdfsFileStatus status;\n     try {\n       status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n           createParent, replication, blockSize, supportedVersions, ecPolicyName,\n-          logRetryCache);\n+          storagePolicy, logRetryCache);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"create\", src);\n       throw e;\n     }\n     logAuditEvent(true, \"create\", src, status);\n     return status;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HdfsFileStatus startFile(String src, PermissionStatus permissions,\n      String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n      boolean createParent, short replication, long blockSize,\n      CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n      String storagePolicy, boolean logRetryCache) throws IOException {\n\n    HdfsFileStatus status;\n    try {\n      status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n          createParent, replication, blockSize, supportedVersions, ecPolicyName,\n          storagePolicy, logRetryCache);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"create\", src);\n      throw e;\n    }\n    logAuditEvent(true, \"create\", src, status);\n    return status;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "9b90e52f1ec22c18cd535af2a569defcef65b093": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11641. Reduce cost of audit logging by using FileStatus instead of HdfsFileStatus. Contributed by Daryn Sharp.\n",
      "commitDate": "16/05/17 9:28 AM",
      "commitName": "9b90e52f1ec22c18cd535af2a569defcef65b093",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "04/05/17 11:39 AM",
      "commitNameOld": "c2a52ef9c29459ff9ef3e23b29e14912bfdb1405",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 11.91,
      "commitsBetweenForRepo": 58,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   HdfsFileStatus startFile(String src, PermissionStatus permissions,\n       String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n       boolean createParent, short replication, long blockSize,\n       CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n       boolean logRetryCache) throws IOException {\n \n     HdfsFileStatus status;\n     try {\n       status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n           createParent, replication, blockSize, supportedVersions, ecPolicyName,\n           logRetryCache);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"create\", src);\n       throw e;\n     }\n-    logAuditEvent(true, \"create\", src, null, status);\n+    logAuditEvent(true, \"create\", src, status);\n     return status;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HdfsFileStatus startFile(String src, PermissionStatus permissions,\n      String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n      boolean createParent, short replication, long blockSize,\n      CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n      boolean logRetryCache) throws IOException {\n\n    HdfsFileStatus status;\n    try {\n      status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n          createParent, replication, blockSize, supportedVersions, ecPolicyName,\n          logRetryCache);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"create\", src);\n      throw e;\n    }\n    logAuditEvent(true, \"create\", src, status);\n    return status;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "a7312715a66dec5173c3a0a78dff4e0333e7f0b1": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-10996. Ability to specify per-file EC policy at create time. Contributed by SammiChen.\n",
      "commitDate": "12/04/17 12:27 PM",
      "commitName": "a7312715a66dec5173c3a0a78dff4e0333e7f0b1",
      "commitAuthor": "Andrew Wang",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-10996. Ability to specify per-file EC policy at create time. Contributed by SammiChen.\n",
          "commitDate": "12/04/17 12:27 PM",
          "commitName": "a7312715a66dec5173c3a0a78dff4e0333e7f0b1",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "11/04/17 10:03 PM",
          "commitNameOld": "23b1a7bdf1b546c1e29d7010cf139b6d700461fc",
          "commitAuthorOld": "Chris Nauroth",
          "daysBetweenCommits": 0.6,
          "commitsBetweenForRepo": 8,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,18 @@\n   HdfsFileStatus startFile(String src, PermissionStatus permissions,\n       String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n-      boolean createParent, short replication, long blockSize, \n-      CryptoProtocolVersion[] supportedVersions, boolean logRetryCache)\n-      throws IOException {\n+      boolean createParent, short replication, long blockSize,\n+      CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n+      boolean logRetryCache) throws IOException {\n \n     HdfsFileStatus status;\n     try {\n       status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n-          createParent, replication, blockSize, supportedVersions,\n+          createParent, replication, blockSize, supportedVersions, ecPolicyName,\n           logRetryCache);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"create\", src);\n       throw e;\n     }\n     logAuditEvent(true, \"create\", src, null, status);\n     return status;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HdfsFileStatus startFile(String src, PermissionStatus permissions,\n      String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n      boolean createParent, short replication, long blockSize,\n      CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n      boolean logRetryCache) throws IOException {\n\n    HdfsFileStatus status;\n    try {\n      status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n          createParent, replication, blockSize, supportedVersions, ecPolicyName,\n          logRetryCache);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"create\", src);\n      throw e;\n    }\n    logAuditEvent(true, \"create\", src, null, status);\n    return status;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[src-String, permissions-PermissionStatus, holder-String, clientMachine-String, flag-EnumSet\u003cCreateFlag\u003e, createParent-boolean, replication-short, blockSize-long, supportedVersions-CryptoProtocolVersion[], logRetryCache-boolean]",
            "newValue": "[src-String, permissions-PermissionStatus, holder-String, clientMachine-String, flag-EnumSet\u003cCreateFlag\u003e, createParent-boolean, replication-short, blockSize-long, supportedVersions-CryptoProtocolVersion[], ecPolicyName-String, logRetryCache-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10996. Ability to specify per-file EC policy at create time. Contributed by SammiChen.\n",
          "commitDate": "12/04/17 12:27 PM",
          "commitName": "a7312715a66dec5173c3a0a78dff4e0333e7f0b1",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "11/04/17 10:03 PM",
          "commitNameOld": "23b1a7bdf1b546c1e29d7010cf139b6d700461fc",
          "commitAuthorOld": "Chris Nauroth",
          "daysBetweenCommits": 0.6,
          "commitsBetweenForRepo": 8,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,18 @@\n   HdfsFileStatus startFile(String src, PermissionStatus permissions,\n       String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n-      boolean createParent, short replication, long blockSize, \n-      CryptoProtocolVersion[] supportedVersions, boolean logRetryCache)\n-      throws IOException {\n+      boolean createParent, short replication, long blockSize,\n+      CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n+      boolean logRetryCache) throws IOException {\n \n     HdfsFileStatus status;\n     try {\n       status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n-          createParent, replication, blockSize, supportedVersions,\n+          createParent, replication, blockSize, supportedVersions, ecPolicyName,\n           logRetryCache);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"create\", src);\n       throw e;\n     }\n     logAuditEvent(true, \"create\", src, null, status);\n     return status;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HdfsFileStatus startFile(String src, PermissionStatus permissions,\n      String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n      boolean createParent, short replication, long blockSize,\n      CryptoProtocolVersion[] supportedVersions, String ecPolicyName,\n      boolean logRetryCache) throws IOException {\n\n    HdfsFileStatus status;\n    try {\n      status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n          createParent, replication, blockSize, supportedVersions, ecPolicyName,\n          logRetryCache);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"create\", src);\n      throw e;\n    }\n    logAuditEvent(true, \"create\", src, null, status);\n    return status;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "2b6bcfdafa91223a4116e3e9304579f5f91dccac": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-8421. Move startFile() and related functions into FSDirWriteFileOp. Contributed by Haohui Mai.\n",
      "commitDate": "21/05/15 8:08 AM",
      "commitName": "2b6bcfdafa91223a4116e3e9304579f5f91dccac",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-8421. Move startFile() and related functions into FSDirWriteFileOp. Contributed by Haohui Mai.\n",
          "commitDate": "21/05/15 8:08 AM",
          "commitName": "2b6bcfdafa91223a4116e3e9304579f5f91dccac",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "18/05/15 12:37 PM",
          "commitNameOld": "cdfae446ad285db979a79bf55665363fd943702c",
          "commitAuthorOld": "Ravi Prakash",
          "daysBetweenCommits": 2.81,
          "commitsBetweenForRepo": 32,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,18 @@\n   HdfsFileStatus startFile(String src, PermissionStatus permissions,\n       String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n       boolean createParent, short replication, long blockSize, \n       CryptoProtocolVersion[] supportedVersions, boolean logRetryCache)\n-      throws AccessControlException, SafeModeException,\n-      FileAlreadyExistsException, UnresolvedLinkException,\n-      FileNotFoundException, ParentNotDirectoryException, IOException {\n+      throws IOException {\n \n-    HdfsFileStatus status \u003d null;\n+    HdfsFileStatus status;\n     try {\n       status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n           createParent, replication, blockSize, supportedVersions,\n           logRetryCache);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"create\", src);\n       throw e;\n     }\n+    logAuditEvent(true, \"create\", src, null, status);\n     return status;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HdfsFileStatus startFile(String src, PermissionStatus permissions,\n      String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n      boolean createParent, short replication, long blockSize, \n      CryptoProtocolVersion[] supportedVersions, boolean logRetryCache)\n      throws IOException {\n\n    HdfsFileStatus status;\n    try {\n      status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n          createParent, replication, blockSize, supportedVersions,\n          logRetryCache);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"create\", src);\n      throw e;\n    }\n    logAuditEvent(true, \"create\", src, null, status);\n    return status;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[AccessControlException, SafeModeException, FileAlreadyExistsException, UnresolvedLinkException, FileNotFoundException, ParentNotDirectoryException, IOException]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8421. Move startFile() and related functions into FSDirWriteFileOp. Contributed by Haohui Mai.\n",
          "commitDate": "21/05/15 8:08 AM",
          "commitName": "2b6bcfdafa91223a4116e3e9304579f5f91dccac",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "18/05/15 12:37 PM",
          "commitNameOld": "cdfae446ad285db979a79bf55665363fd943702c",
          "commitAuthorOld": "Ravi Prakash",
          "daysBetweenCommits": 2.81,
          "commitsBetweenForRepo": 32,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,18 @@\n   HdfsFileStatus startFile(String src, PermissionStatus permissions,\n       String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n       boolean createParent, short replication, long blockSize, \n       CryptoProtocolVersion[] supportedVersions, boolean logRetryCache)\n-      throws AccessControlException, SafeModeException,\n-      FileAlreadyExistsException, UnresolvedLinkException,\n-      FileNotFoundException, ParentNotDirectoryException, IOException {\n+      throws IOException {\n \n-    HdfsFileStatus status \u003d null;\n+    HdfsFileStatus status;\n     try {\n       status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n           createParent, replication, blockSize, supportedVersions,\n           logRetryCache);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"create\", src);\n       throw e;\n     }\n+    logAuditEvent(true, \"create\", src, null, status);\n     return status;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HdfsFileStatus startFile(String src, PermissionStatus permissions,\n      String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n      boolean createParent, short replication, long blockSize, \n      CryptoProtocolVersion[] supportedVersions, boolean logRetryCache)\n      throws IOException {\n\n    HdfsFileStatus status;\n    try {\n      status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n          createParent, replication, blockSize, supportedVersions,\n          logRetryCache);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"create\", src);\n      throw e;\n    }\n    logAuditEvent(true, \"create\", src, null, status);\n    return status;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "8e253cb93030642f5a7324bad0f161cd0ad33206": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7412. Move RetryCache to NameNodeRpcServer. Contributed by Haohui Mai.\n",
      "commitDate": "24/11/14 11:11 AM",
      "commitName": "8e253cb93030642f5a7324bad0f161cd0ad33206",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7412. Move RetryCache to NameNodeRpcServer. Contributed by Haohui Mai.\n",
          "commitDate": "24/11/14 11:11 AM",
          "commitName": "8e253cb93030642f5a7324bad0f161cd0ad33206",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "24/11/14 10:46 AM",
          "commitNameOld": "daacbc18d739d030822df0b75205eeb067f89850",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 0.02,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,19 @@\n   HdfsFileStatus startFile(String src, PermissionStatus permissions,\n       String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n       boolean createParent, short replication, long blockSize, \n-      CryptoProtocolVersion[] supportedVersions)\n+      CryptoProtocolVersion[] supportedVersions, boolean logRetryCache)\n       throws AccessControlException, SafeModeException,\n       FileAlreadyExistsException, UnresolvedLinkException,\n       FileNotFoundException, ParentNotDirectoryException, IOException {\n+\n     HdfsFileStatus status \u003d null;\n-    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache,\n-        null);\n-    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n-      return (HdfsFileStatus) cacheEntry.getPayload();\n-    }\n-    \n     try {\n       status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n           createParent, replication, blockSize, supportedVersions,\n-          cacheEntry !\u003d null);\n+          logRetryCache);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"create\", src);\n       throw e;\n-    } finally {\n-      RetryCache.setState(cacheEntry, status !\u003d null, status);\n     }\n     return status;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HdfsFileStatus startFile(String src, PermissionStatus permissions,\n      String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n      boolean createParent, short replication, long blockSize, \n      CryptoProtocolVersion[] supportedVersions, boolean logRetryCache)\n      throws AccessControlException, SafeModeException,\n      FileAlreadyExistsException, UnresolvedLinkException,\n      FileNotFoundException, ParentNotDirectoryException, IOException {\n\n    HdfsFileStatus status \u003d null;\n    try {\n      status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n          createParent, replication, blockSize, supportedVersions,\n          logRetryCache);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"create\", src);\n      throw e;\n    }\n    return status;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[src-String, permissions-PermissionStatus, holder-String, clientMachine-String, flag-EnumSet\u003cCreateFlag\u003e, createParent-boolean, replication-short, blockSize-long, supportedVersions-CryptoProtocolVersion[]]",
            "newValue": "[src-String, permissions-PermissionStatus, holder-String, clientMachine-String, flag-EnumSet\u003cCreateFlag\u003e, createParent-boolean, replication-short, blockSize-long, supportedVersions-CryptoProtocolVersion[], logRetryCache-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7412. Move RetryCache to NameNodeRpcServer. Contributed by Haohui Mai.\n",
          "commitDate": "24/11/14 11:11 AM",
          "commitName": "8e253cb93030642f5a7324bad0f161cd0ad33206",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "24/11/14 10:46 AM",
          "commitNameOld": "daacbc18d739d030822df0b75205eeb067f89850",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 0.02,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,19 @@\n   HdfsFileStatus startFile(String src, PermissionStatus permissions,\n       String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n       boolean createParent, short replication, long blockSize, \n-      CryptoProtocolVersion[] supportedVersions)\n+      CryptoProtocolVersion[] supportedVersions, boolean logRetryCache)\n       throws AccessControlException, SafeModeException,\n       FileAlreadyExistsException, UnresolvedLinkException,\n       FileNotFoundException, ParentNotDirectoryException, IOException {\n+\n     HdfsFileStatus status \u003d null;\n-    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache,\n-        null);\n-    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n-      return (HdfsFileStatus) cacheEntry.getPayload();\n-    }\n-    \n     try {\n       status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n           createParent, replication, blockSize, supportedVersions,\n-          cacheEntry !\u003d null);\n+          logRetryCache);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"create\", src);\n       throw e;\n-    } finally {\n-      RetryCache.setState(cacheEntry, status !\u003d null, status);\n     }\n     return status;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HdfsFileStatus startFile(String src, PermissionStatus permissions,\n      String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n      boolean createParent, short replication, long blockSize, \n      CryptoProtocolVersion[] supportedVersions, boolean logRetryCache)\n      throws AccessControlException, SafeModeException,\n      FileAlreadyExistsException, UnresolvedLinkException,\n      FileNotFoundException, ParentNotDirectoryException, IOException {\n\n    HdfsFileStatus status \u003d null;\n    try {\n      status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n          createParent, replication, blockSize, supportedVersions,\n          logRetryCache);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"create\", src);\n      throw e;\n    }\n    return status;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "e96ce6f3e3e549202ce3c48d4733ba34098870ad": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7077. Separate CipherSuite from crypto protocol version. (wang)\n",
      "commitDate": "25/09/14 6:40 PM",
      "commitName": "e96ce6f3e3e549202ce3c48d4733ba34098870ad",
      "commitAuthor": "Andrew Wang",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7077. Separate CipherSuite from crypto protocol version. (wang)\n",
          "commitDate": "25/09/14 6:40 PM",
          "commitName": "e96ce6f3e3e549202ce3c48d4733ba34098870ad",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "24/09/14 7:11 PM",
          "commitNameOld": "428a76663a0de5d0d74cc9525273ddc470760e44",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 0.98,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,26 @@\n   HdfsFileStatus startFile(String src, PermissionStatus permissions,\n       String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n       boolean createParent, short replication, long blockSize, \n-      List\u003cCipherSuite\u003e cipherSuites)\n+      CryptoProtocolVersion[] supportedVersions)\n       throws AccessControlException, SafeModeException,\n       FileAlreadyExistsException, UnresolvedLinkException,\n       FileNotFoundException, ParentNotDirectoryException, IOException {\n     HdfsFileStatus status \u003d null;\n     CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache,\n         null);\n     if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n       return (HdfsFileStatus) cacheEntry.getPayload();\n     }\n     \n     try {\n       status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n-          createParent, replication, blockSize, cipherSuites,\n+          createParent, replication, blockSize, supportedVersions,\n           cacheEntry !\u003d null);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"create\", src);\n       throw e;\n     } finally {\n       RetryCache.setState(cacheEntry, status !\u003d null, status);\n     }\n     return status;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HdfsFileStatus startFile(String src, PermissionStatus permissions,\n      String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n      boolean createParent, short replication, long blockSize, \n      CryptoProtocolVersion[] supportedVersions)\n      throws AccessControlException, SafeModeException,\n      FileAlreadyExistsException, UnresolvedLinkException,\n      FileNotFoundException, ParentNotDirectoryException, IOException {\n    HdfsFileStatus status \u003d null;\n    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache,\n        null);\n    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n      return (HdfsFileStatus) cacheEntry.getPayload();\n    }\n    \n    try {\n      status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n          createParent, replication, blockSize, supportedVersions,\n          cacheEntry !\u003d null);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"create\", src);\n      throw e;\n    } finally {\n      RetryCache.setState(cacheEntry, status !\u003d null, status);\n    }\n    return status;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[src-String, permissions-PermissionStatus, holder-String, clientMachine-String, flag-EnumSet\u003cCreateFlag\u003e, createParent-boolean, replication-short, blockSize-long, cipherSuites-List\u003cCipherSuite\u003e]",
            "newValue": "[src-String, permissions-PermissionStatus, holder-String, clientMachine-String, flag-EnumSet\u003cCreateFlag\u003e, createParent-boolean, replication-short, blockSize-long, supportedVersions-CryptoProtocolVersion[]]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7077. Separate CipherSuite from crypto protocol version. (wang)\n",
          "commitDate": "25/09/14 6:40 PM",
          "commitName": "e96ce6f3e3e549202ce3c48d4733ba34098870ad",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "24/09/14 7:11 PM",
          "commitNameOld": "428a76663a0de5d0d74cc9525273ddc470760e44",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 0.98,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,26 @@\n   HdfsFileStatus startFile(String src, PermissionStatus permissions,\n       String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n       boolean createParent, short replication, long blockSize, \n-      List\u003cCipherSuite\u003e cipherSuites)\n+      CryptoProtocolVersion[] supportedVersions)\n       throws AccessControlException, SafeModeException,\n       FileAlreadyExistsException, UnresolvedLinkException,\n       FileNotFoundException, ParentNotDirectoryException, IOException {\n     HdfsFileStatus status \u003d null;\n     CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache,\n         null);\n     if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n       return (HdfsFileStatus) cacheEntry.getPayload();\n     }\n     \n     try {\n       status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n-          createParent, replication, blockSize, cipherSuites,\n+          createParent, replication, blockSize, supportedVersions,\n           cacheEntry !\u003d null);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"create\", src);\n       throw e;\n     } finally {\n       RetryCache.setState(cacheEntry, status !\u003d null, status);\n     }\n     return status;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HdfsFileStatus startFile(String src, PermissionStatus permissions,\n      String holder, String clientMachine, EnumSet\u003cCreateFlag\u003e flag,\n      boolean createParent, short replication, long blockSize, \n      CryptoProtocolVersion[] supportedVersions)\n      throws AccessControlException, SafeModeException,\n      FileAlreadyExistsException, UnresolvedLinkException,\n      FileNotFoundException, ParentNotDirectoryException, IOException {\n    HdfsFileStatus status \u003d null;\n    CacheEntryWithPayload cacheEntry \u003d RetryCache.waitForCompletion(retryCache,\n        null);\n    if (cacheEntry !\u003d null \u0026\u0026 cacheEntry.isSuccess()) {\n      return (HdfsFileStatus) cacheEntry.getPayload();\n    }\n    \n    try {\n      status \u003d startFileInt(src, permissions, holder, clientMachine, flag,\n          createParent, replication, blockSize, supportedVersions,\n          cacheEntry !\u003d null);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"create\", src);\n      throw e;\n    } finally {\n      RetryCache.setState(cacheEntry, status !\u003d null, status);\n    }\n    return status;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}