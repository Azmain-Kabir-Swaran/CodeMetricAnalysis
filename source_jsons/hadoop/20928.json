{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Job.java",
  "functionName": "printTaskEvents",
  "functionId": "printTaskEvents___events-TaskCompletionEvent[]__filter-Job.TaskStatusFilter__profiling-boolean__mapRanges-IntegerRanges__reduceRanges-IntegerRanges",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java",
  "functionStartLine": 1676,
  "functionEndLine": 1713,
  "numCommitsSeen": 43,
  "timeTaken": 5006,
  "changeHistory": [
    "cf5dd3293278c21747222b1ea2ef37a276565fa5",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "cf5dd3293278c21747222b1ea2ef37a276565fa5": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "cf5dd3293278c21747222b1ea2ef37a276565fa5": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3889. job client tries to use /tasklog interface, but that doesn\u0027t exist anymore (Devaraj K via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1352330 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/06/12 2:22 PM",
      "commitName": "cf5dd3293278c21747222b1ea2ef37a276565fa5",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "09/04/12 2:52 PM",
      "commitNameOld": "48ab08f1c62696e99d7d94c275b68709c499b7bf",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 71.98,
      "commitsBetweenForRepo": 419,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,38 @@\n   private void printTaskEvents(TaskCompletionEvent[] events,\n       Job.TaskStatusFilter filter, boolean profiling, IntegerRanges mapRanges,\n       IntegerRanges reduceRanges) throws IOException, InterruptedException {\n     for (TaskCompletionEvent event : events) {\n-      TaskCompletionEvent.Status status \u003d event.getStatus();\n-      if (profiling \u0026\u0026 shouldDownloadProfile() \u0026\u0026\n-         (status \u003d\u003d TaskCompletionEvent.Status.SUCCEEDED ||\n-            status \u003d\u003d TaskCompletionEvent.Status.FAILED) \u0026\u0026\n-            (event.isMapTask() ? mapRanges : reduceRanges).\n-              isIncluded(event.idWithinJob())) {\n-        downloadProfile(event);\n-      }\n       switch (filter) {\n       case NONE:\n         break;\n       case SUCCEEDED:\n         if (event.getStatus() \u003d\u003d \n           TaskCompletionEvent.Status.SUCCEEDED) {\n           LOG.info(event.toString());\n-          displayTaskLogs(event.getTaskAttemptId(), event.getTaskTrackerHttp());\n         }\n         break; \n       case FAILED:\n         if (event.getStatus() \u003d\u003d \n           TaskCompletionEvent.Status.FAILED) {\n           LOG.info(event.toString());\n           // Displaying the task diagnostic information\n           TaskAttemptID taskId \u003d event.getTaskAttemptId();\n           String[] taskDiagnostics \u003d getTaskDiagnostics(taskId); \n           if (taskDiagnostics !\u003d null) {\n             for (String diagnostics : taskDiagnostics) {\n               System.err.println(diagnostics);\n             }\n           }\n-          // Displaying the task logs\n-          displayTaskLogs(event.getTaskAttemptId(), event.getTaskTrackerHttp());\n         }\n         break; \n       case KILLED:\n         if (event.getStatus() \u003d\u003d TaskCompletionEvent.Status.KILLED){\n           LOG.info(event.toString());\n         }\n         break; \n       case ALL:\n         LOG.info(event.toString());\n-        displayTaskLogs(event.getTaskAttemptId(), event.getTaskTrackerHttp());\n         break;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void printTaskEvents(TaskCompletionEvent[] events,\n      Job.TaskStatusFilter filter, boolean profiling, IntegerRanges mapRanges,\n      IntegerRanges reduceRanges) throws IOException, InterruptedException {\n    for (TaskCompletionEvent event : events) {\n      switch (filter) {\n      case NONE:\n        break;\n      case SUCCEEDED:\n        if (event.getStatus() \u003d\u003d \n          TaskCompletionEvent.Status.SUCCEEDED) {\n          LOG.info(event.toString());\n        }\n        break; \n      case FAILED:\n        if (event.getStatus() \u003d\u003d \n          TaskCompletionEvent.Status.FAILED) {\n          LOG.info(event.toString());\n          // Displaying the task diagnostic information\n          TaskAttemptID taskId \u003d event.getTaskAttemptId();\n          String[] taskDiagnostics \u003d getTaskDiagnostics(taskId); \n          if (taskDiagnostics !\u003d null) {\n            for (String diagnostics : taskDiagnostics) {\n              System.err.println(diagnostics);\n            }\n          }\n        }\n        break; \n      case KILLED:\n        if (event.getStatus() \u003d\u003d TaskCompletionEvent.Status.KILLED){\n          LOG.info(event.toString());\n        }\n        break; \n      case ALL:\n        LOG.info(event.toString());\n        break;\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void printTaskEvents(TaskCompletionEvent[] events,\n      Job.TaskStatusFilter filter, boolean profiling, IntegerRanges mapRanges,\n      IntegerRanges reduceRanges) throws IOException, InterruptedException {\n    for (TaskCompletionEvent event : events) {\n      TaskCompletionEvent.Status status \u003d event.getStatus();\n      if (profiling \u0026\u0026 shouldDownloadProfile() \u0026\u0026\n         (status \u003d\u003d TaskCompletionEvent.Status.SUCCEEDED ||\n            status \u003d\u003d TaskCompletionEvent.Status.FAILED) \u0026\u0026\n            (event.isMapTask() ? mapRanges : reduceRanges).\n              isIncluded(event.idWithinJob())) {\n        downloadProfile(event);\n      }\n      switch (filter) {\n      case NONE:\n        break;\n      case SUCCEEDED:\n        if (event.getStatus() \u003d\u003d \n          TaskCompletionEvent.Status.SUCCEEDED) {\n          LOG.info(event.toString());\n          displayTaskLogs(event.getTaskAttemptId(), event.getTaskTrackerHttp());\n        }\n        break; \n      case FAILED:\n        if (event.getStatus() \u003d\u003d \n          TaskCompletionEvent.Status.FAILED) {\n          LOG.info(event.toString());\n          // Displaying the task diagnostic information\n          TaskAttemptID taskId \u003d event.getTaskAttemptId();\n          String[] taskDiagnostics \u003d getTaskDiagnostics(taskId); \n          if (taskDiagnostics !\u003d null) {\n            for (String diagnostics : taskDiagnostics) {\n              System.err.println(diagnostics);\n            }\n          }\n          // Displaying the task logs\n          displayTaskLogs(event.getTaskAttemptId(), event.getTaskTrackerHttp());\n        }\n        break; \n      case KILLED:\n        if (event.getStatus() \u003d\u003d TaskCompletionEvent.Status.KILLED){\n          LOG.info(event.toString());\n        }\n        break; \n      case ALL:\n        LOG.info(event.toString());\n        displayTaskLogs(event.getTaskAttemptId(), event.getTaskTrackerHttp());\n        break;\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void printTaskEvents(TaskCompletionEvent[] events,\n      Job.TaskStatusFilter filter, boolean profiling, IntegerRanges mapRanges,\n      IntegerRanges reduceRanges) throws IOException, InterruptedException {\n    for (TaskCompletionEvent event : events) {\n      TaskCompletionEvent.Status status \u003d event.getStatus();\n      if (profiling \u0026\u0026 shouldDownloadProfile() \u0026\u0026\n         (status \u003d\u003d TaskCompletionEvent.Status.SUCCEEDED ||\n            status \u003d\u003d TaskCompletionEvent.Status.FAILED) \u0026\u0026\n            (event.isMapTask() ? mapRanges : reduceRanges).\n              isIncluded(event.idWithinJob())) {\n        downloadProfile(event);\n      }\n      switch (filter) {\n      case NONE:\n        break;\n      case SUCCEEDED:\n        if (event.getStatus() \u003d\u003d \n          TaskCompletionEvent.Status.SUCCEEDED) {\n          LOG.info(event.toString());\n          displayTaskLogs(event.getTaskAttemptId(), event.getTaskTrackerHttp());\n        }\n        break; \n      case FAILED:\n        if (event.getStatus() \u003d\u003d \n          TaskCompletionEvent.Status.FAILED) {\n          LOG.info(event.toString());\n          // Displaying the task diagnostic information\n          TaskAttemptID taskId \u003d event.getTaskAttemptId();\n          String[] taskDiagnostics \u003d getTaskDiagnostics(taskId); \n          if (taskDiagnostics !\u003d null) {\n            for (String diagnostics : taskDiagnostics) {\n              System.err.println(diagnostics);\n            }\n          }\n          // Displaying the task logs\n          displayTaskLogs(event.getTaskAttemptId(), event.getTaskTrackerHttp());\n        }\n        break; \n      case KILLED:\n        if (event.getStatus() \u003d\u003d TaskCompletionEvent.Status.KILLED){\n          LOG.info(event.toString());\n        }\n        break; \n      case ALL:\n        LOG.info(event.toString());\n        displayTaskLogs(event.getTaskAttemptId(), event.getTaskTrackerHttp());\n        break;\n      }\n    }\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/java/org/apache/hadoop/mapreduce/Job.java",
        "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Job.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,50 @@\n+  private void printTaskEvents(TaskCompletionEvent[] events,\n+      Job.TaskStatusFilter filter, boolean profiling, IntegerRanges mapRanges,\n+      IntegerRanges reduceRanges) throws IOException, InterruptedException {\n+    for (TaskCompletionEvent event : events) {\n+      TaskCompletionEvent.Status status \u003d event.getStatus();\n+      if (profiling \u0026\u0026 shouldDownloadProfile() \u0026\u0026\n+         (status \u003d\u003d TaskCompletionEvent.Status.SUCCEEDED ||\n+            status \u003d\u003d TaskCompletionEvent.Status.FAILED) \u0026\u0026\n+            (event.isMapTask() ? mapRanges : reduceRanges).\n+              isIncluded(event.idWithinJob())) {\n+        downloadProfile(event);\n+      }\n+      switch (filter) {\n+      case NONE:\n+        break;\n+      case SUCCEEDED:\n+        if (event.getStatus() \u003d\u003d \n+          TaskCompletionEvent.Status.SUCCEEDED) {\n+          LOG.info(event.toString());\n+          displayTaskLogs(event.getTaskAttemptId(), event.getTaskTrackerHttp());\n+        }\n+        break; \n+      case FAILED:\n+        if (event.getStatus() \u003d\u003d \n+          TaskCompletionEvent.Status.FAILED) {\n+          LOG.info(event.toString());\n+          // Displaying the task diagnostic information\n+          TaskAttemptID taskId \u003d event.getTaskAttemptId();\n+          String[] taskDiagnostics \u003d getTaskDiagnostics(taskId); \n+          if (taskDiagnostics !\u003d null) {\n+            for (String diagnostics : taskDiagnostics) {\n+              System.err.println(diagnostics);\n+            }\n+          }\n+          // Displaying the task logs\n+          displayTaskLogs(event.getTaskAttemptId(), event.getTaskTrackerHttp());\n+        }\n+        break; \n+      case KILLED:\n+        if (event.getStatus() \u003d\u003d TaskCompletionEvent.Status.KILLED){\n+          LOG.info(event.toString());\n+        }\n+        break; \n+      case ALL:\n+        LOG.info(event.toString());\n+        displayTaskLogs(event.getTaskAttemptId(), event.getTaskTrackerHttp());\n+        break;\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void printTaskEvents(TaskCompletionEvent[] events,\n      Job.TaskStatusFilter filter, boolean profiling, IntegerRanges mapRanges,\n      IntegerRanges reduceRanges) throws IOException, InterruptedException {\n    for (TaskCompletionEvent event : events) {\n      TaskCompletionEvent.Status status \u003d event.getStatus();\n      if (profiling \u0026\u0026 shouldDownloadProfile() \u0026\u0026\n         (status \u003d\u003d TaskCompletionEvent.Status.SUCCEEDED ||\n            status \u003d\u003d TaskCompletionEvent.Status.FAILED) \u0026\u0026\n            (event.isMapTask() ? mapRanges : reduceRanges).\n              isIncluded(event.idWithinJob())) {\n        downloadProfile(event);\n      }\n      switch (filter) {\n      case NONE:\n        break;\n      case SUCCEEDED:\n        if (event.getStatus() \u003d\u003d \n          TaskCompletionEvent.Status.SUCCEEDED) {\n          LOG.info(event.toString());\n          displayTaskLogs(event.getTaskAttemptId(), event.getTaskTrackerHttp());\n        }\n        break; \n      case FAILED:\n        if (event.getStatus() \u003d\u003d \n          TaskCompletionEvent.Status.FAILED) {\n          LOG.info(event.toString());\n          // Displaying the task diagnostic information\n          TaskAttemptID taskId \u003d event.getTaskAttemptId();\n          String[] taskDiagnostics \u003d getTaskDiagnostics(taskId); \n          if (taskDiagnostics !\u003d null) {\n            for (String diagnostics : taskDiagnostics) {\n              System.err.println(diagnostics);\n            }\n          }\n          // Displaying the task logs\n          displayTaskLogs(event.getTaskAttemptId(), event.getTaskTrackerHttp());\n        }\n        break; \n      case KILLED:\n        if (event.getStatus() \u003d\u003d TaskCompletionEvent.Status.KILLED){\n          LOG.info(event.toString());\n        }\n        break; \n      case ALL:\n        LOG.info(event.toString());\n        displayTaskLogs(event.getTaskAttemptId(), event.getTaskTrackerHttp());\n        break;\n      }\n    }\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapreduce/Job.java"
    }
  }
}