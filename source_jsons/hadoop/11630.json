{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPoolSlice.java",
  "functionName": "addToReplicasMap",
  "functionId": "addToReplicasMap___volumeMap-ReplicaMap__dir-File__lazyWriteReplicaMap-RamDiskReplicaTracker(modifiers-final)__isFinalized-boolean__exceptions-List__IOException____subTaskQueue-Queue__RecursiveAction__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
  "functionStartLine": 677,
  "functionEndLine": 711,
  "numCommitsSeen": 125,
  "timeTaken": 4744,
  "changeHistory": [
    "5689355783de005ebc604f4403dc5129a286bfca",
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
    "fc1031af749435dc95efea6745b1b2300ce29446",
    "b9f6d0c956f0278c8b9b83e05b523a442a730ebb",
    "b2d5ed36bcb80e2581191dcdc3976e825c959142",
    "ccdf0054a354fc110124b83de742c2ee6076449e"
  ],
  "changeHistoryShort": {
    "5689355783de005ebc604f4403dc5129a286bfca": "Ymultichange(Yparameterchange,Ybodychange)",
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": "Ybodychange",
    "fc1031af749435dc95efea6745b1b2300ce29446": "Ybodychange",
    "b9f6d0c956f0278c8b9b83e05b523a442a730ebb": "Ybodychange",
    "b2d5ed36bcb80e2581191dcdc3976e825c959142": "Ymultichange(Yparameterchange,Ybodychange)",
    "ccdf0054a354fc110124b83de742c2ee6076449e": "Ybodychange"
  },
  "changeHistoryDetails": {
    "5689355783de005ebc604f4403dc5129a286bfca": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-13768. Adding replicas to volume map makes DataNode start slowly. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "01/10/18 6:43 PM",
      "commitName": "5689355783de005ebc604f4403dc5129a286bfca",
      "commitAuthor": "Yiqun Lin",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13768. Adding replicas to volume map makes DataNode start slowly. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "01/10/18 6:43 PM",
          "commitName": "5689355783de005ebc604f4403dc5129a286bfca",
          "commitAuthor": "Yiqun Lin",
          "commitDateOld": "06/09/18 2:48 PM",
          "commitNameOld": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
          "commitAuthorOld": "Giovanni Matteo Fumarola",
          "daysBetweenCommits": 25.16,
          "commitsBetweenForRepo": 264,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,35 @@\n   void addToReplicasMap(ReplicaMap volumeMap, File dir,\n-                        final RamDiskReplicaTracker lazyWriteReplicaMap,\n-                        boolean isFinalized)\n+      final RamDiskReplicaTracker lazyWriteReplicaMap, boolean isFinalized,\n+      List\u003cIOException\u003e exceptions, Queue\u003cRecursiveAction\u003e subTaskQueue)\n       throws IOException {\n     File[] files \u003d fileIoProvider.listFiles(volume, dir);\n-    for (File file : files) {\n+    Arrays.sort(files, FILE_COMPARATOR);\n+    for (int i \u003d 0; i \u003c files.length; i++) {\n+      File file \u003d files[i];\n       if (file.isDirectory()) {\n-        addToReplicasMap(volumeMap, file, lazyWriteReplicaMap, isFinalized);\n+        // Launch new sub task.\n+        AddReplicaProcessor subTask \u003d new AddReplicaProcessor(volumeMap, file,\n+            lazyWriteReplicaMap, isFinalized, exceptions, subTaskQueue);\n+        subTask.fork();\n+        subTaskQueue.add(subTask);\n       }\n \n       if (isFinalized \u0026\u0026 FsDatasetUtil.isUnlinkTmpFile(file)) {\n         file \u003d recoverTempUnlinkedBlock(file);\n         if (file \u003d\u003d null) { // the original block still exists, so we cover it\n           // in another iteration and can continue here\n           continue;\n         }\n       }\n       if (!Block.isBlockFilename(file)) {\n         continue;\n       }\n \n       long genStamp \u003d FsDatasetUtil.getGenerationStampFromFile(\n-          files, file);\n+          files, file, i);\n       long blockId \u003d Block.filename2id(file.getName());\n       Block block \u003d new Block(blockId, file.length(), genStamp);\n       addReplicaToReplicasMap(block, volumeMap, lazyWriteReplicaMap,\n           isFinalized);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void addToReplicasMap(ReplicaMap volumeMap, File dir,\n      final RamDiskReplicaTracker lazyWriteReplicaMap, boolean isFinalized,\n      List\u003cIOException\u003e exceptions, Queue\u003cRecursiveAction\u003e subTaskQueue)\n      throws IOException {\n    File[] files \u003d fileIoProvider.listFiles(volume, dir);\n    Arrays.sort(files, FILE_COMPARATOR);\n    for (int i \u003d 0; i \u003c files.length; i++) {\n      File file \u003d files[i];\n      if (file.isDirectory()) {\n        // Launch new sub task.\n        AddReplicaProcessor subTask \u003d new AddReplicaProcessor(volumeMap, file,\n            lazyWriteReplicaMap, isFinalized, exceptions, subTaskQueue);\n        subTask.fork();\n        subTaskQueue.add(subTask);\n      }\n\n      if (isFinalized \u0026\u0026 FsDatasetUtil.isUnlinkTmpFile(file)) {\n        file \u003d recoverTempUnlinkedBlock(file);\n        if (file \u003d\u003d null) { // the original block still exists, so we cover it\n          // in another iteration and can continue here\n          continue;\n        }\n      }\n      if (!Block.isBlockFilename(file)) {\n        continue;\n      }\n\n      long genStamp \u003d FsDatasetUtil.getGenerationStampFromFile(\n          files, file, i);\n      long blockId \u003d Block.filename2id(file.getName());\n      Block block \u003d new Block(blockId, file.length(), genStamp);\n      addReplicaToReplicasMap(block, volumeMap, lazyWriteReplicaMap,\n          isFinalized);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
          "extendedDetails": {
            "oldValue": "[volumeMap-ReplicaMap, dir-File, lazyWriteReplicaMap-RamDiskReplicaTracker(modifiers-final), isFinalized-boolean]",
            "newValue": "[volumeMap-ReplicaMap, dir-File, lazyWriteReplicaMap-RamDiskReplicaTracker(modifiers-final), isFinalized-boolean, exceptions-List\u003cIOException\u003e, subTaskQueue-Queue\u003cRecursiveAction\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13768. Adding replicas to volume map makes DataNode start slowly. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "01/10/18 6:43 PM",
          "commitName": "5689355783de005ebc604f4403dc5129a286bfca",
          "commitAuthor": "Yiqun Lin",
          "commitDateOld": "06/09/18 2:48 PM",
          "commitNameOld": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
          "commitAuthorOld": "Giovanni Matteo Fumarola",
          "daysBetweenCommits": 25.16,
          "commitsBetweenForRepo": 264,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,35 @@\n   void addToReplicasMap(ReplicaMap volumeMap, File dir,\n-                        final RamDiskReplicaTracker lazyWriteReplicaMap,\n-                        boolean isFinalized)\n+      final RamDiskReplicaTracker lazyWriteReplicaMap, boolean isFinalized,\n+      List\u003cIOException\u003e exceptions, Queue\u003cRecursiveAction\u003e subTaskQueue)\n       throws IOException {\n     File[] files \u003d fileIoProvider.listFiles(volume, dir);\n-    for (File file : files) {\n+    Arrays.sort(files, FILE_COMPARATOR);\n+    for (int i \u003d 0; i \u003c files.length; i++) {\n+      File file \u003d files[i];\n       if (file.isDirectory()) {\n-        addToReplicasMap(volumeMap, file, lazyWriteReplicaMap, isFinalized);\n+        // Launch new sub task.\n+        AddReplicaProcessor subTask \u003d new AddReplicaProcessor(volumeMap, file,\n+            lazyWriteReplicaMap, isFinalized, exceptions, subTaskQueue);\n+        subTask.fork();\n+        subTaskQueue.add(subTask);\n       }\n \n       if (isFinalized \u0026\u0026 FsDatasetUtil.isUnlinkTmpFile(file)) {\n         file \u003d recoverTempUnlinkedBlock(file);\n         if (file \u003d\u003d null) { // the original block still exists, so we cover it\n           // in another iteration and can continue here\n           continue;\n         }\n       }\n       if (!Block.isBlockFilename(file)) {\n         continue;\n       }\n \n       long genStamp \u003d FsDatasetUtil.getGenerationStampFromFile(\n-          files, file);\n+          files, file, i);\n       long blockId \u003d Block.filename2id(file.getName());\n       Block block \u003d new Block(blockId, file.length(), genStamp);\n       addReplicaToReplicasMap(block, volumeMap, lazyWriteReplicaMap,\n           isFinalized);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void addToReplicasMap(ReplicaMap volumeMap, File dir,\n      final RamDiskReplicaTracker lazyWriteReplicaMap, boolean isFinalized,\n      List\u003cIOException\u003e exceptions, Queue\u003cRecursiveAction\u003e subTaskQueue)\n      throws IOException {\n    File[] files \u003d fileIoProvider.listFiles(volume, dir);\n    Arrays.sort(files, FILE_COMPARATOR);\n    for (int i \u003d 0; i \u003c files.length; i++) {\n      File file \u003d files[i];\n      if (file.isDirectory()) {\n        // Launch new sub task.\n        AddReplicaProcessor subTask \u003d new AddReplicaProcessor(volumeMap, file,\n            lazyWriteReplicaMap, isFinalized, exceptions, subTaskQueue);\n        subTask.fork();\n        subTaskQueue.add(subTask);\n      }\n\n      if (isFinalized \u0026\u0026 FsDatasetUtil.isUnlinkTmpFile(file)) {\n        file \u003d recoverTempUnlinkedBlock(file);\n        if (file \u003d\u003d null) { // the original block still exists, so we cover it\n          // in another iteration and can continue here\n          continue;\n        }\n      }\n      if (!Block.isBlockFilename(file)) {\n        continue;\n      }\n\n      long genStamp \u003d FsDatasetUtil.getGenerationStampFromFile(\n          files, file, i);\n      long blockId \u003d Block.filename2id(file.getName());\n      Block block \u003d new Block(blockId, file.length(), genStamp);\n      addReplicaToReplicasMap(block, volumeMap, lazyWriteReplicaMap,\n          isFinalized);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
          "extendedDetails": {}
        }
      ]
    },
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10958. Add instrumentation hooks around Datanode disk IO.\n",
      "commitDate": "14/12/16 11:18 AM",
      "commitName": "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "06/12/16 11:05 AM",
      "commitNameOld": "df983b524ab68ea0c70cee9033bfff2d28052cbf",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 8.01,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,29 @@\n   void addToReplicasMap(ReplicaMap volumeMap, File dir,\n                         final RamDiskReplicaTracker lazyWriteReplicaMap,\n                         boolean isFinalized)\n       throws IOException {\n-    File files[] \u003d FileUtil.listFiles(dir);\n+    File[] files \u003d fileIoProvider.listFiles(volume, dir);\n     for (File file : files) {\n       if (file.isDirectory()) {\n         addToReplicasMap(volumeMap, file, lazyWriteReplicaMap, isFinalized);\n       }\n \n       if (isFinalized \u0026\u0026 FsDatasetUtil.isUnlinkTmpFile(file)) {\n         file \u003d recoverTempUnlinkedBlock(file);\n         if (file \u003d\u003d null) { // the original block still exists, so we cover it\n           // in another iteration and can continue here\n           continue;\n         }\n       }\n-      if (!Block.isBlockFilename(file))\n+      if (!Block.isBlockFilename(file)) {\n         continue;\n+      }\n \n       long genStamp \u003d FsDatasetUtil.getGenerationStampFromFile(\n           files, file);\n       long blockId \u003d Block.filename2id(file.getName());\n       Block block \u003d new Block(blockId, file.length(), genStamp);\n       addReplicaToReplicasMap(block, volumeMap, lazyWriteReplicaMap,\n           isFinalized);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addToReplicasMap(ReplicaMap volumeMap, File dir,\n                        final RamDiskReplicaTracker lazyWriteReplicaMap,\n                        boolean isFinalized)\n      throws IOException {\n    File[] files \u003d fileIoProvider.listFiles(volume, dir);\n    for (File file : files) {\n      if (file.isDirectory()) {\n        addToReplicasMap(volumeMap, file, lazyWriteReplicaMap, isFinalized);\n      }\n\n      if (isFinalized \u0026\u0026 FsDatasetUtil.isUnlinkTmpFile(file)) {\n        file \u003d recoverTempUnlinkedBlock(file);\n        if (file \u003d\u003d null) { // the original block still exists, so we cover it\n          // in another iteration and can continue here\n          continue;\n        }\n      }\n      if (!Block.isBlockFilename(file)) {\n        continue;\n      }\n\n      long genStamp \u003d FsDatasetUtil.getGenerationStampFromFile(\n          files, file);\n      long blockId \u003d Block.filename2id(file.getName());\n      Block block \u003d new Block(blockId, file.length(), genStamp);\n      addReplicaToReplicasMap(block, volumeMap, lazyWriteReplicaMap,\n          isFinalized);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
      "extendedDetails": {}
    },
    "fc1031af749435dc95efea6745b1b2300ce29446": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7928. Scanning blocks from disk during rolling upgrade startup takes a lot of time if disks are busy. Contributed by Rushabh Shah.\n",
      "commitDate": "25/03/15 12:42 PM",
      "commitName": "fc1031af749435dc95efea6745b1b2300ce29446",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "11/12/14 12:36 PM",
      "commitNameOld": "b9f6d0c956f0278c8b9b83e05b523a442a730ebb",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 103.96,
      "commitsBetweenForRepo": 825,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,85 +1,28 @@\n   void addToReplicasMap(ReplicaMap volumeMap, File dir,\n                         final RamDiskReplicaTracker lazyWriteReplicaMap,\n                         boolean isFinalized)\n       throws IOException {\n     File files[] \u003d FileUtil.listFiles(dir);\n     for (File file : files) {\n       if (file.isDirectory()) {\n         addToReplicasMap(volumeMap, file, lazyWriteReplicaMap, isFinalized);\n       }\n \n       if (isFinalized \u0026\u0026 FsDatasetUtil.isUnlinkTmpFile(file)) {\n         file \u003d recoverTempUnlinkedBlock(file);\n         if (file \u003d\u003d null) { // the original block still exists, so we cover it\n           // in another iteration and can continue here\n           continue;\n         }\n       }\n       if (!Block.isBlockFilename(file))\n         continue;\n       \n       long genStamp \u003d FsDatasetUtil.getGenerationStampFromFile(\n           files, file);\n       long blockId \u003d Block.filename2id(file.getName());\n-      ReplicaInfo newReplica \u003d null;\n-      if (isFinalized) {\n-        newReplica \u003d new FinalizedReplica(blockId, \n-            file.length(), genStamp, volume, file.getParentFile());\n-      } else {\n-\n-        boolean loadRwr \u003d true;\n-        File restartMeta \u003d new File(file.getParent()  +\n-            File.pathSeparator + \".\" + file.getName() + \".restart\");\n-        Scanner sc \u003d null;\n-        try {\n-          sc \u003d new Scanner(restartMeta, \"UTF-8\");\n-          // The restart meta file exists\n-          if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e Time.now())) {\n-            // It didn\u0027t expire. Load the replica as a RBW.\n-            // We don\u0027t know the expected block length, so just use 0\n-            // and don\u0027t reserve any more space for writes.\n-            newReplica \u003d new ReplicaBeingWritten(blockId,\n-                validateIntegrityAndSetLength(file, genStamp),\n-                genStamp, volume, file.getParentFile(), null, 0);\n-            loadRwr \u003d false;\n-          }\n-          sc.close();\n-          if (!restartMeta.delete()) {\n-            FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n-              restartMeta.getPath());\n-          }\n-        } catch (FileNotFoundException fnfe) {\n-          // nothing to do hereFile dir \u003d\n-        } finally {\n-          if (sc !\u003d null) {\n-            sc.close();\n-          }\n-        }\n-        // Restart meta doesn\u0027t exist or expired.\n-        if (loadRwr) {\n-          newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n-              validateIntegrityAndSetLength(file, genStamp),\n-              genStamp, volume, file.getParentFile());\n-        }\n-      }\n-\n-      ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n-      if (oldReplica \u003d\u003d null) {\n-        volumeMap.add(bpid, newReplica);\n-      } else {\n-        // We have multiple replicas of the same block so decide which one\n-        // to keep.\n-        newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n-      }\n-\n-      // If we are retaining a replica on transient storage make sure\n-      // it is in the lazyWriteReplicaMap so it can be persisted\n-      // eventually.\n-      if (newReplica.getVolume().isTransientStorage()) {\n-        lazyWriteReplicaMap.addReplica(bpid, blockId,\n-                                       (FsVolumeImpl) newReplica.getVolume());\n-      } else {\n-        lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n-      }\n+      Block block \u003d new Block(blockId, file.length(), genStamp); \n+      addReplicaToReplicasMap(block, volumeMap, lazyWriteReplicaMap, \n+          isFinalized);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addToReplicasMap(ReplicaMap volumeMap, File dir,\n                        final RamDiskReplicaTracker lazyWriteReplicaMap,\n                        boolean isFinalized)\n      throws IOException {\n    File files[] \u003d FileUtil.listFiles(dir);\n    for (File file : files) {\n      if (file.isDirectory()) {\n        addToReplicasMap(volumeMap, file, lazyWriteReplicaMap, isFinalized);\n      }\n\n      if (isFinalized \u0026\u0026 FsDatasetUtil.isUnlinkTmpFile(file)) {\n        file \u003d recoverTempUnlinkedBlock(file);\n        if (file \u003d\u003d null) { // the original block still exists, so we cover it\n          // in another iteration and can continue here\n          continue;\n        }\n      }\n      if (!Block.isBlockFilename(file))\n        continue;\n      \n      long genStamp \u003d FsDatasetUtil.getGenerationStampFromFile(\n          files, file);\n      long blockId \u003d Block.filename2id(file.getName());\n      Block block \u003d new Block(blockId, file.length(), genStamp); \n      addReplicaToReplicasMap(block, volumeMap, lazyWriteReplicaMap, \n          isFinalized);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
      "extendedDetails": {}
    },
    "b9f6d0c956f0278c8b9b83e05b523a442a730ebb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7515. Fix new findbugs warnings in hadoop-hdfs. Contributed by Haohui Mai.\n",
      "commitDate": "11/12/14 12:36 PM",
      "commitName": "b9f6d0c956f0278c8b9b83e05b523a442a730ebb",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/11/14 9:57 AM",
      "commitNameOld": "058af60c56207907f2bedf76df4284e86d923e0c",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 15.11,
      "commitsBetweenForRepo": 103,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,85 +1,85 @@\n   void addToReplicasMap(ReplicaMap volumeMap, File dir,\n                         final RamDiskReplicaTracker lazyWriteReplicaMap,\n                         boolean isFinalized)\n       throws IOException {\n     File files[] \u003d FileUtil.listFiles(dir);\n     for (File file : files) {\n       if (file.isDirectory()) {\n         addToReplicasMap(volumeMap, file, lazyWriteReplicaMap, isFinalized);\n       }\n \n       if (isFinalized \u0026\u0026 FsDatasetUtil.isUnlinkTmpFile(file)) {\n         file \u003d recoverTempUnlinkedBlock(file);\n         if (file \u003d\u003d null) { // the original block still exists, so we cover it\n           // in another iteration and can continue here\n           continue;\n         }\n       }\n       if (!Block.isBlockFilename(file))\n         continue;\n       \n       long genStamp \u003d FsDatasetUtil.getGenerationStampFromFile(\n           files, file);\n       long blockId \u003d Block.filename2id(file.getName());\n       ReplicaInfo newReplica \u003d null;\n       if (isFinalized) {\n         newReplica \u003d new FinalizedReplica(blockId, \n             file.length(), genStamp, volume, file.getParentFile());\n       } else {\n \n         boolean loadRwr \u003d true;\n         File restartMeta \u003d new File(file.getParent()  +\n             File.pathSeparator + \".\" + file.getName() + \".restart\");\n         Scanner sc \u003d null;\n         try {\n-          sc \u003d new Scanner(restartMeta);\n+          sc \u003d new Scanner(restartMeta, \"UTF-8\");\n           // The restart meta file exists\n           if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e Time.now())) {\n             // It didn\u0027t expire. Load the replica as a RBW.\n             // We don\u0027t know the expected block length, so just use 0\n             // and don\u0027t reserve any more space for writes.\n             newReplica \u003d new ReplicaBeingWritten(blockId,\n                 validateIntegrityAndSetLength(file, genStamp),\n                 genStamp, volume, file.getParentFile(), null, 0);\n             loadRwr \u003d false;\n           }\n           sc.close();\n           if (!restartMeta.delete()) {\n             FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n               restartMeta.getPath());\n           }\n         } catch (FileNotFoundException fnfe) {\n           // nothing to do hereFile dir \u003d\n         } finally {\n           if (sc !\u003d null) {\n             sc.close();\n           }\n         }\n         // Restart meta doesn\u0027t exist or expired.\n         if (loadRwr) {\n           newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n               validateIntegrityAndSetLength(file, genStamp),\n               genStamp, volume, file.getParentFile());\n         }\n       }\n \n       ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n       if (oldReplica \u003d\u003d null) {\n         volumeMap.add(bpid, newReplica);\n       } else {\n         // We have multiple replicas of the same block so decide which one\n         // to keep.\n         newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n       }\n \n       // If we are retaining a replica on transient storage make sure\n       // it is in the lazyWriteReplicaMap so it can be persisted\n       // eventually.\n       if (newReplica.getVolume().isTransientStorage()) {\n         lazyWriteReplicaMap.addReplica(bpid, blockId,\n                                        (FsVolumeImpl) newReplica.getVolume());\n       } else {\n         lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addToReplicasMap(ReplicaMap volumeMap, File dir,\n                        final RamDiskReplicaTracker lazyWriteReplicaMap,\n                        boolean isFinalized)\n      throws IOException {\n    File files[] \u003d FileUtil.listFiles(dir);\n    for (File file : files) {\n      if (file.isDirectory()) {\n        addToReplicasMap(volumeMap, file, lazyWriteReplicaMap, isFinalized);\n      }\n\n      if (isFinalized \u0026\u0026 FsDatasetUtil.isUnlinkTmpFile(file)) {\n        file \u003d recoverTempUnlinkedBlock(file);\n        if (file \u003d\u003d null) { // the original block still exists, so we cover it\n          // in another iteration and can continue here\n          continue;\n        }\n      }\n      if (!Block.isBlockFilename(file))\n        continue;\n      \n      long genStamp \u003d FsDatasetUtil.getGenerationStampFromFile(\n          files, file);\n      long blockId \u003d Block.filename2id(file.getName());\n      ReplicaInfo newReplica \u003d null;\n      if (isFinalized) {\n        newReplica \u003d new FinalizedReplica(blockId, \n            file.length(), genStamp, volume, file.getParentFile());\n      } else {\n\n        boolean loadRwr \u003d true;\n        File restartMeta \u003d new File(file.getParent()  +\n            File.pathSeparator + \".\" + file.getName() + \".restart\");\n        Scanner sc \u003d null;\n        try {\n          sc \u003d new Scanner(restartMeta, \"UTF-8\");\n          // The restart meta file exists\n          if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e Time.now())) {\n            // It didn\u0027t expire. Load the replica as a RBW.\n            // We don\u0027t know the expected block length, so just use 0\n            // and don\u0027t reserve any more space for writes.\n            newReplica \u003d new ReplicaBeingWritten(blockId,\n                validateIntegrityAndSetLength(file, genStamp),\n                genStamp, volume, file.getParentFile(), null, 0);\n            loadRwr \u003d false;\n          }\n          sc.close();\n          if (!restartMeta.delete()) {\n            FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n              restartMeta.getPath());\n          }\n        } catch (FileNotFoundException fnfe) {\n          // nothing to do hereFile dir \u003d\n        } finally {\n          if (sc !\u003d null) {\n            sc.close();\n          }\n        }\n        // Restart meta doesn\u0027t exist or expired.\n        if (loadRwr) {\n          newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n              validateIntegrityAndSetLength(file, genStamp),\n              genStamp, volume, file.getParentFile());\n        }\n      }\n\n      ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n      if (oldReplica \u003d\u003d null) {\n        volumeMap.add(bpid, newReplica);\n      } else {\n        // We have multiple replicas of the same block so decide which one\n        // to keep.\n        newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n      }\n\n      // If we are retaining a replica on transient storage make sure\n      // it is in the lazyWriteReplicaMap so it can be persisted\n      // eventually.\n      if (newReplica.getVolume().isTransientStorage()) {\n        lazyWriteReplicaMap.addReplica(bpid, blockId,\n                                       (FsVolumeImpl) newReplica.getVolume());\n      } else {\n        lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
      "extendedDetails": {}
    },
    "b2d5ed36bcb80e2581191dcdc3976e825c959142": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7100. Make eviction scheme pluggable. (Arpit Agarwal)\n",
      "commitDate": "20/09/14 1:25 PM",
      "commitName": "b2d5ed36bcb80e2581191dcdc3976e825c959142",
      "commitAuthor": "arp",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7100. Make eviction scheme pluggable. (Arpit Agarwal)\n",
          "commitDate": "20/09/14 1:25 PM",
          "commitName": "b2d5ed36bcb80e2581191dcdc3976e825c959142",
          "commitAuthor": "arp",
          "commitDateOld": "17/09/14 3:25 PM",
          "commitNameOld": "4eab083b1b7faf4485274d1d30256cde08e11915",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 2.92,
          "commitsBetweenForRepo": 45,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,84 +1,85 @@\n   void addToReplicasMap(ReplicaMap volumeMap, File dir,\n-                        final LazyWriteReplicaTracker lazyWriteReplicaMap,\n+                        final RamDiskReplicaTracker lazyWriteReplicaMap,\n                         boolean isFinalized)\n       throws IOException {\n     File files[] \u003d FileUtil.listFiles(dir);\n     for (File file : files) {\n       if (file.isDirectory()) {\n         addToReplicasMap(volumeMap, file, lazyWriteReplicaMap, isFinalized);\n       }\n \n       if (isFinalized \u0026\u0026 FsDatasetUtil.isUnlinkTmpFile(file)) {\n         file \u003d recoverTempUnlinkedBlock(file);\n         if (file \u003d\u003d null) { // the original block still exists, so we cover it\n           // in another iteration and can continue here\n           continue;\n         }\n       }\n       if (!Block.isBlockFilename(file))\n         continue;\n       \n       long genStamp \u003d FsDatasetUtil.getGenerationStampFromFile(\n           files, file);\n       long blockId \u003d Block.filename2id(file.getName());\n       ReplicaInfo newReplica \u003d null;\n       if (isFinalized) {\n         newReplica \u003d new FinalizedReplica(blockId, \n             file.length(), genStamp, volume, file.getParentFile());\n       } else {\n \n         boolean loadRwr \u003d true;\n         File restartMeta \u003d new File(file.getParent()  +\n             File.pathSeparator + \".\" + file.getName() + \".restart\");\n         Scanner sc \u003d null;\n         try {\n           sc \u003d new Scanner(restartMeta);\n           // The restart meta file exists\n           if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e Time.now())) {\n             // It didn\u0027t expire. Load the replica as a RBW.\n             // We don\u0027t know the expected block length, so just use 0\n             // and don\u0027t reserve any more space for writes.\n             newReplica \u003d new ReplicaBeingWritten(blockId,\n                 validateIntegrityAndSetLength(file, genStamp),\n                 genStamp, volume, file.getParentFile(), null, 0);\n             loadRwr \u003d false;\n           }\n           sc.close();\n           if (!restartMeta.delete()) {\n             FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n               restartMeta.getPath());\n           }\n         } catch (FileNotFoundException fnfe) {\n           // nothing to do hereFile dir \u003d\n         } finally {\n           if (sc !\u003d null) {\n             sc.close();\n           }\n         }\n         // Restart meta doesn\u0027t exist or expired.\n         if (loadRwr) {\n           newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n               validateIntegrityAndSetLength(file, genStamp),\n               genStamp, volume, file.getParentFile());\n         }\n       }\n \n       ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n       if (oldReplica \u003d\u003d null) {\n         volumeMap.add(bpid, newReplica);\n       } else {\n         // We have multiple replicas of the same block so decide which one\n         // to keep.\n         newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n       }\n \n       // If we are retaining a replica on transient storage make sure\n       // it is in the lazyWriteReplicaMap so it can be persisted\n       // eventually.\n       if (newReplica.getVolume().isTransientStorage()) {\n-        lazyWriteReplicaMap.addReplica(bpid, blockId, newReplica.getVolume());\n+        lazyWriteReplicaMap.addReplica(bpid, blockId,\n+                                       (FsVolumeImpl) newReplica.getVolume());\n       } else {\n         lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void addToReplicasMap(ReplicaMap volumeMap, File dir,\n                        final RamDiskReplicaTracker lazyWriteReplicaMap,\n                        boolean isFinalized)\n      throws IOException {\n    File files[] \u003d FileUtil.listFiles(dir);\n    for (File file : files) {\n      if (file.isDirectory()) {\n        addToReplicasMap(volumeMap, file, lazyWriteReplicaMap, isFinalized);\n      }\n\n      if (isFinalized \u0026\u0026 FsDatasetUtil.isUnlinkTmpFile(file)) {\n        file \u003d recoverTempUnlinkedBlock(file);\n        if (file \u003d\u003d null) { // the original block still exists, so we cover it\n          // in another iteration and can continue here\n          continue;\n        }\n      }\n      if (!Block.isBlockFilename(file))\n        continue;\n      \n      long genStamp \u003d FsDatasetUtil.getGenerationStampFromFile(\n          files, file);\n      long blockId \u003d Block.filename2id(file.getName());\n      ReplicaInfo newReplica \u003d null;\n      if (isFinalized) {\n        newReplica \u003d new FinalizedReplica(blockId, \n            file.length(), genStamp, volume, file.getParentFile());\n      } else {\n\n        boolean loadRwr \u003d true;\n        File restartMeta \u003d new File(file.getParent()  +\n            File.pathSeparator + \".\" + file.getName() + \".restart\");\n        Scanner sc \u003d null;\n        try {\n          sc \u003d new Scanner(restartMeta);\n          // The restart meta file exists\n          if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e Time.now())) {\n            // It didn\u0027t expire. Load the replica as a RBW.\n            // We don\u0027t know the expected block length, so just use 0\n            // and don\u0027t reserve any more space for writes.\n            newReplica \u003d new ReplicaBeingWritten(blockId,\n                validateIntegrityAndSetLength(file, genStamp),\n                genStamp, volume, file.getParentFile(), null, 0);\n            loadRwr \u003d false;\n          }\n          sc.close();\n          if (!restartMeta.delete()) {\n            FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n              restartMeta.getPath());\n          }\n        } catch (FileNotFoundException fnfe) {\n          // nothing to do hereFile dir \u003d\n        } finally {\n          if (sc !\u003d null) {\n            sc.close();\n          }\n        }\n        // Restart meta doesn\u0027t exist or expired.\n        if (loadRwr) {\n          newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n              validateIntegrityAndSetLength(file, genStamp),\n              genStamp, volume, file.getParentFile());\n        }\n      }\n\n      ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n      if (oldReplica \u003d\u003d null) {\n        volumeMap.add(bpid, newReplica);\n      } else {\n        // We have multiple replicas of the same block so decide which one\n        // to keep.\n        newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n      }\n\n      // If we are retaining a replica on transient storage make sure\n      // it is in the lazyWriteReplicaMap so it can be persisted\n      // eventually.\n      if (newReplica.getVolume().isTransientStorage()) {\n        lazyWriteReplicaMap.addReplica(bpid, blockId,\n                                       (FsVolumeImpl) newReplica.getVolume());\n      } else {\n        lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
          "extendedDetails": {
            "oldValue": "[volumeMap-ReplicaMap, dir-File, lazyWriteReplicaMap-LazyWriteReplicaTracker(modifiers-final), isFinalized-boolean]",
            "newValue": "[volumeMap-ReplicaMap, dir-File, lazyWriteReplicaMap-RamDiskReplicaTracker(modifiers-final), isFinalized-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7100. Make eviction scheme pluggable. (Arpit Agarwal)\n",
          "commitDate": "20/09/14 1:25 PM",
          "commitName": "b2d5ed36bcb80e2581191dcdc3976e825c959142",
          "commitAuthor": "arp",
          "commitDateOld": "17/09/14 3:25 PM",
          "commitNameOld": "4eab083b1b7faf4485274d1d30256cde08e11915",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 2.92,
          "commitsBetweenForRepo": 45,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,84 +1,85 @@\n   void addToReplicasMap(ReplicaMap volumeMap, File dir,\n-                        final LazyWriteReplicaTracker lazyWriteReplicaMap,\n+                        final RamDiskReplicaTracker lazyWriteReplicaMap,\n                         boolean isFinalized)\n       throws IOException {\n     File files[] \u003d FileUtil.listFiles(dir);\n     for (File file : files) {\n       if (file.isDirectory()) {\n         addToReplicasMap(volumeMap, file, lazyWriteReplicaMap, isFinalized);\n       }\n \n       if (isFinalized \u0026\u0026 FsDatasetUtil.isUnlinkTmpFile(file)) {\n         file \u003d recoverTempUnlinkedBlock(file);\n         if (file \u003d\u003d null) { // the original block still exists, so we cover it\n           // in another iteration and can continue here\n           continue;\n         }\n       }\n       if (!Block.isBlockFilename(file))\n         continue;\n       \n       long genStamp \u003d FsDatasetUtil.getGenerationStampFromFile(\n           files, file);\n       long blockId \u003d Block.filename2id(file.getName());\n       ReplicaInfo newReplica \u003d null;\n       if (isFinalized) {\n         newReplica \u003d new FinalizedReplica(blockId, \n             file.length(), genStamp, volume, file.getParentFile());\n       } else {\n \n         boolean loadRwr \u003d true;\n         File restartMeta \u003d new File(file.getParent()  +\n             File.pathSeparator + \".\" + file.getName() + \".restart\");\n         Scanner sc \u003d null;\n         try {\n           sc \u003d new Scanner(restartMeta);\n           // The restart meta file exists\n           if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e Time.now())) {\n             // It didn\u0027t expire. Load the replica as a RBW.\n             // We don\u0027t know the expected block length, so just use 0\n             // and don\u0027t reserve any more space for writes.\n             newReplica \u003d new ReplicaBeingWritten(blockId,\n                 validateIntegrityAndSetLength(file, genStamp),\n                 genStamp, volume, file.getParentFile(), null, 0);\n             loadRwr \u003d false;\n           }\n           sc.close();\n           if (!restartMeta.delete()) {\n             FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n               restartMeta.getPath());\n           }\n         } catch (FileNotFoundException fnfe) {\n           // nothing to do hereFile dir \u003d\n         } finally {\n           if (sc !\u003d null) {\n             sc.close();\n           }\n         }\n         // Restart meta doesn\u0027t exist or expired.\n         if (loadRwr) {\n           newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n               validateIntegrityAndSetLength(file, genStamp),\n               genStamp, volume, file.getParentFile());\n         }\n       }\n \n       ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n       if (oldReplica \u003d\u003d null) {\n         volumeMap.add(bpid, newReplica);\n       } else {\n         // We have multiple replicas of the same block so decide which one\n         // to keep.\n         newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n       }\n \n       // If we are retaining a replica on transient storage make sure\n       // it is in the lazyWriteReplicaMap so it can be persisted\n       // eventually.\n       if (newReplica.getVolume().isTransientStorage()) {\n-        lazyWriteReplicaMap.addReplica(bpid, blockId, newReplica.getVolume());\n+        lazyWriteReplicaMap.addReplica(bpid, blockId,\n+                                       (FsVolumeImpl) newReplica.getVolume());\n       } else {\n         lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void addToReplicasMap(ReplicaMap volumeMap, File dir,\n                        final RamDiskReplicaTracker lazyWriteReplicaMap,\n                        boolean isFinalized)\n      throws IOException {\n    File files[] \u003d FileUtil.listFiles(dir);\n    for (File file : files) {\n      if (file.isDirectory()) {\n        addToReplicasMap(volumeMap, file, lazyWriteReplicaMap, isFinalized);\n      }\n\n      if (isFinalized \u0026\u0026 FsDatasetUtil.isUnlinkTmpFile(file)) {\n        file \u003d recoverTempUnlinkedBlock(file);\n        if (file \u003d\u003d null) { // the original block still exists, so we cover it\n          // in another iteration and can continue here\n          continue;\n        }\n      }\n      if (!Block.isBlockFilename(file))\n        continue;\n      \n      long genStamp \u003d FsDatasetUtil.getGenerationStampFromFile(\n          files, file);\n      long blockId \u003d Block.filename2id(file.getName());\n      ReplicaInfo newReplica \u003d null;\n      if (isFinalized) {\n        newReplica \u003d new FinalizedReplica(blockId, \n            file.length(), genStamp, volume, file.getParentFile());\n      } else {\n\n        boolean loadRwr \u003d true;\n        File restartMeta \u003d new File(file.getParent()  +\n            File.pathSeparator + \".\" + file.getName() + \".restart\");\n        Scanner sc \u003d null;\n        try {\n          sc \u003d new Scanner(restartMeta);\n          // The restart meta file exists\n          if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e Time.now())) {\n            // It didn\u0027t expire. Load the replica as a RBW.\n            // We don\u0027t know the expected block length, so just use 0\n            // and don\u0027t reserve any more space for writes.\n            newReplica \u003d new ReplicaBeingWritten(blockId,\n                validateIntegrityAndSetLength(file, genStamp),\n                genStamp, volume, file.getParentFile(), null, 0);\n            loadRwr \u003d false;\n          }\n          sc.close();\n          if (!restartMeta.delete()) {\n            FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n              restartMeta.getPath());\n          }\n        } catch (FileNotFoundException fnfe) {\n          // nothing to do hereFile dir \u003d\n        } finally {\n          if (sc !\u003d null) {\n            sc.close();\n          }\n        }\n        // Restart meta doesn\u0027t exist or expired.\n        if (loadRwr) {\n          newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n              validateIntegrityAndSetLength(file, genStamp),\n              genStamp, volume, file.getParentFile());\n        }\n      }\n\n      ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n      if (oldReplica \u003d\u003d null) {\n        volumeMap.add(bpid, newReplica);\n      } else {\n        // We have multiple replicas of the same block so decide which one\n        // to keep.\n        newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n      }\n\n      // If we are retaining a replica on transient storage make sure\n      // it is in the lazyWriteReplicaMap so it can be persisted\n      // eventually.\n      if (newReplica.getVolume().isTransientStorage()) {\n        lazyWriteReplicaMap.addReplica(bpid, blockId,\n                                       (FsVolumeImpl) newReplica.getVolume());\n      } else {\n        lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
          "extendedDetails": {}
        }
      ]
    },
    "ccdf0054a354fc110124b83de742c2ee6076449e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6977. Delete all copies when a block is deleted from the block space. (Arpit Agarwal)\n",
      "commitDate": "08/09/14 10:35 AM",
      "commitName": "ccdf0054a354fc110124b83de742c2ee6076449e",
      "commitAuthor": "arp",
      "commitDateOld": "07/09/14 2:46 PM",
      "commitNameOld": "eb8284d50e1aa9f196556ed20b4b5e3f330e65fe",
      "commitAuthorOld": "",
      "daysBetweenCommits": 0.83,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,84 @@\n   void addToReplicasMap(ReplicaMap volumeMap, File dir,\n                         final LazyWriteReplicaTracker lazyWriteReplicaMap,\n                         boolean isFinalized)\n       throws IOException {\n     File files[] \u003d FileUtil.listFiles(dir);\n     for (File file : files) {\n       if (file.isDirectory()) {\n         addToReplicasMap(volumeMap, file, lazyWriteReplicaMap, isFinalized);\n       }\n \n       if (isFinalized \u0026\u0026 FsDatasetUtil.isUnlinkTmpFile(file)) {\n         file \u003d recoverTempUnlinkedBlock(file);\n         if (file \u003d\u003d null) { // the original block still exists, so we cover it\n           // in another iteration and can continue here\n           continue;\n         }\n       }\n       if (!Block.isBlockFilename(file))\n         continue;\n       \n       long genStamp \u003d FsDatasetUtil.getGenerationStampFromFile(\n           files, file);\n       long blockId \u003d Block.filename2id(file.getName());\n       ReplicaInfo newReplica \u003d null;\n       if (isFinalized) {\n         newReplica \u003d new FinalizedReplica(blockId, \n             file.length(), genStamp, volume, file.getParentFile());\n       } else {\n \n         boolean loadRwr \u003d true;\n         File restartMeta \u003d new File(file.getParent()  +\n             File.pathSeparator + \".\" + file.getName() + \".restart\");\n         Scanner sc \u003d null;\n         try {\n           sc \u003d new Scanner(restartMeta);\n           // The restart meta file exists\n           if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e Time.now())) {\n             // It didn\u0027t expire. Load the replica as a RBW.\n             // We don\u0027t know the expected block length, so just use 0\n             // and don\u0027t reserve any more space for writes.\n             newReplica \u003d new ReplicaBeingWritten(blockId,\n                 validateIntegrityAndSetLength(file, genStamp),\n                 genStamp, volume, file.getParentFile(), null, 0);\n             loadRwr \u003d false;\n           }\n           sc.close();\n           if (!restartMeta.delete()) {\n             FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n               restartMeta.getPath());\n           }\n         } catch (FileNotFoundException fnfe) {\n           // nothing to do hereFile dir \u003d\n         } finally {\n           if (sc !\u003d null) {\n             sc.close();\n           }\n         }\n         // Restart meta doesn\u0027t exist or expired.\n         if (loadRwr) {\n           newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n               validateIntegrityAndSetLength(file, genStamp),\n               genStamp, volume, file.getParentFile());\n         }\n       }\n \n       ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n       if (oldReplica \u003d\u003d null) {\n         volumeMap.add(bpid, newReplica);\n       } else {\n         // We have multiple replicas of the same block so decide which one\n         // to keep.\n         newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n       }\n \n       // If we are retaining a replica on transient storage make sure\n       // it is in the lazyWriteReplicaMap so it can be persisted\n       // eventually.\n       if (newReplica.getVolume().isTransientStorage()) {\n         lazyWriteReplicaMap.addReplica(bpid, blockId, newReplica.getVolume());\n       } else {\n-        lazyWriteReplicaMap.discardReplica(bpid, blockId, true);\n+        lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addToReplicasMap(ReplicaMap volumeMap, File dir,\n                        final LazyWriteReplicaTracker lazyWriteReplicaMap,\n                        boolean isFinalized)\n      throws IOException {\n    File files[] \u003d FileUtil.listFiles(dir);\n    for (File file : files) {\n      if (file.isDirectory()) {\n        addToReplicasMap(volumeMap, file, lazyWriteReplicaMap, isFinalized);\n      }\n\n      if (isFinalized \u0026\u0026 FsDatasetUtil.isUnlinkTmpFile(file)) {\n        file \u003d recoverTempUnlinkedBlock(file);\n        if (file \u003d\u003d null) { // the original block still exists, so we cover it\n          // in another iteration and can continue here\n          continue;\n        }\n      }\n      if (!Block.isBlockFilename(file))\n        continue;\n      \n      long genStamp \u003d FsDatasetUtil.getGenerationStampFromFile(\n          files, file);\n      long blockId \u003d Block.filename2id(file.getName());\n      ReplicaInfo newReplica \u003d null;\n      if (isFinalized) {\n        newReplica \u003d new FinalizedReplica(blockId, \n            file.length(), genStamp, volume, file.getParentFile());\n      } else {\n\n        boolean loadRwr \u003d true;\n        File restartMeta \u003d new File(file.getParent()  +\n            File.pathSeparator + \".\" + file.getName() + \".restart\");\n        Scanner sc \u003d null;\n        try {\n          sc \u003d new Scanner(restartMeta);\n          // The restart meta file exists\n          if (sc.hasNextLong() \u0026\u0026 (sc.nextLong() \u003e Time.now())) {\n            // It didn\u0027t expire. Load the replica as a RBW.\n            // We don\u0027t know the expected block length, so just use 0\n            // and don\u0027t reserve any more space for writes.\n            newReplica \u003d new ReplicaBeingWritten(blockId,\n                validateIntegrityAndSetLength(file, genStamp),\n                genStamp, volume, file.getParentFile(), null, 0);\n            loadRwr \u003d false;\n          }\n          sc.close();\n          if (!restartMeta.delete()) {\n            FsDatasetImpl.LOG.warn(\"Failed to delete restart meta file: \" +\n              restartMeta.getPath());\n          }\n        } catch (FileNotFoundException fnfe) {\n          // nothing to do hereFile dir \u003d\n        } finally {\n          if (sc !\u003d null) {\n            sc.close();\n          }\n        }\n        // Restart meta doesn\u0027t exist or expired.\n        if (loadRwr) {\n          newReplica \u003d new ReplicaWaitingToBeRecovered(blockId,\n              validateIntegrityAndSetLength(file, genStamp),\n              genStamp, volume, file.getParentFile());\n        }\n      }\n\n      ReplicaInfo oldReplica \u003d volumeMap.get(bpid, newReplica.getBlockId());\n      if (oldReplica \u003d\u003d null) {\n        volumeMap.add(bpid, newReplica);\n      } else {\n        // We have multiple replicas of the same block so decide which one\n        // to keep.\n        newReplica \u003d resolveDuplicateReplicas(newReplica, oldReplica, volumeMap);\n      }\n\n      // If we are retaining a replica on transient storage make sure\n      // it is in the lazyWriteReplicaMap so it can be persisted\n      // eventually.\n      if (newReplica.getVolume().isTransientStorage()) {\n        lazyWriteReplicaMap.addReplica(bpid, blockId, newReplica.getVolume());\n      } else {\n        lazyWriteReplicaMap.discardReplica(bpid, blockId, false);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
      "extendedDetails": {}
    }
  }
}