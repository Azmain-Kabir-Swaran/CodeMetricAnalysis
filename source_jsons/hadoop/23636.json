{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JobInfo.java",
  "functionName": "countTasksAndAttempts",
  "functionId": "countTasksAndAttempts___job-Job",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/webapp/dao/JobInfo.java",
  "functionStartLine": 273,
  "functionEndLine": 339,
  "numCommitsSeen": 14,
  "timeTaken": 1375,
  "changeHistory": [
    "87866d4a5653c4828a4f4a6f76c58b1b889e7e5b",
    "5fd460e688a6df5d6093bae4b7add73f8d44162c",
    "0ea8570be578be60e2f32849900a1c50506d78d3",
    "d9ba4670ed0134816d5d063d48394e31b51c3b35",
    "a3e8f6836b489f8f2ddd785ae038df729c85059f",
    "be32d25c546a7d4f98604e142940c483213b485b"
  ],
  "changeHistoryShort": {
    "87866d4a5653c4828a4f4a6f76c58b1b889e7e5b": "Ybodychange",
    "5fd460e688a6df5d6093bae4b7add73f8d44162c": "Ybodychange",
    "0ea8570be578be60e2f32849900a1c50506d78d3": "Ymultichange(Ymovefromfile,Ybodychange)",
    "d9ba4670ed0134816d5d063d48394e31b51c3b35": "Ybodychange",
    "a3e8f6836b489f8f2ddd785ae038df729c85059f": "Ybodychange",
    "be32d25c546a7d4f98604e142940c483213b485b": "Yintroduced"
  },
  "changeHistoryDetails": {
    "87866d4a5653c4828a4f4a6f76c58b1b889e7e5b": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5789. Average Reduce time is incorrect on Job Overview page. Contributed by Rushabh S Shah\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1577202 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/03/14 8:35 AM",
      "commitName": "87866d4a5653c4828a4f4a6f76c58b1b889e7e5b",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "10/12/13 9:17 AM",
      "commitNameOld": "ee5351bf22e113d39db3839432bc7d6c743cc736",
      "commitAuthorOld": "Jonathan Turner Eagles",
      "daysBetweenCommits": 92.93,
      "commitsBetweenForRepo": 685,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,67 @@\n   private void countTasksAndAttempts(Job job) {\n     numReduces \u003d 0;\n     numMaps \u003d 0;\n     final Map\u003cTaskId, Task\u003e tasks \u003d job.getTasks();\n     if (tasks \u003d\u003d null) {\n       return;\n     }\n     for (Task task : tasks.values()) {\n       // Attempts counts\n       Map\u003cTaskAttemptId, TaskAttempt\u003e attempts \u003d task.getAttempts();\n       int successful, failed, killed;\n       for (TaskAttempt attempt : attempts.values()) {\n \n         successful \u003d 0;\n         failed \u003d 0;\n         killed \u003d 0;\n         if (TaskAttemptStateUI.NEW.correspondsTo(attempt.getState())) {\n           // Do Nothing\n         } else if (TaskAttemptStateUI.RUNNING.correspondsTo(attempt.getState())) {\n           // Do Nothing\n         } else if (TaskAttemptStateUI.SUCCESSFUL.correspondsTo(attempt\n             .getState())) {\n           ++successful;\n         } else if (TaskAttemptStateUI.FAILED.correspondsTo(attempt.getState())) {\n           ++failed;\n         } else if (TaskAttemptStateUI.KILLED.correspondsTo(attempt.getState())) {\n           ++killed;\n         }\n \n         switch (task.getType()) {\n         case MAP:\n           successfulMapAttempts +\u003d successful;\n           failedMapAttempts +\u003d failed;\n           killedMapAttempts +\u003d killed;\n           if (attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n             numMaps++;\n             avgMapTime +\u003d (attempt.getFinishTime() - attempt.getLaunchTime());\n           }\n           break;\n         case REDUCE:\n           successfulReduceAttempts +\u003d successful;\n           failedReduceAttempts +\u003d failed;\n           killedReduceAttempts +\u003d killed;\n           if (attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n             numReduces++;\n             avgShuffleTime +\u003d (attempt.getShuffleFinishTime() - attempt\n                 .getLaunchTime());\n             avgMergeTime +\u003d attempt.getSortFinishTime()\n                 - attempt.getShuffleFinishTime();\n             avgReduceTime +\u003d (attempt.getFinishTime() - attempt\n-                .getShuffleFinishTime());\n+                .getSortFinishTime());\n           }\n           break;\n         }\n       }\n     }\n \n     if (numMaps \u003e 0) {\n       avgMapTime \u003d avgMapTime / numMaps;\n     }\n \n     if (numReduces \u003e 0) {\n       avgReduceTime \u003d avgReduceTime / numReduces;\n       avgShuffleTime \u003d avgShuffleTime / numReduces;\n       avgMergeTime \u003d avgMergeTime / numReduces;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void countTasksAndAttempts(Job job) {\n    numReduces \u003d 0;\n    numMaps \u003d 0;\n    final Map\u003cTaskId, Task\u003e tasks \u003d job.getTasks();\n    if (tasks \u003d\u003d null) {\n      return;\n    }\n    for (Task task : tasks.values()) {\n      // Attempts counts\n      Map\u003cTaskAttemptId, TaskAttempt\u003e attempts \u003d task.getAttempts();\n      int successful, failed, killed;\n      for (TaskAttempt attempt : attempts.values()) {\n\n        successful \u003d 0;\n        failed \u003d 0;\n        killed \u003d 0;\n        if (TaskAttemptStateUI.NEW.correspondsTo(attempt.getState())) {\n          // Do Nothing\n        } else if (TaskAttemptStateUI.RUNNING.correspondsTo(attempt.getState())) {\n          // Do Nothing\n        } else if (TaskAttemptStateUI.SUCCESSFUL.correspondsTo(attempt\n            .getState())) {\n          ++successful;\n        } else if (TaskAttemptStateUI.FAILED.correspondsTo(attempt.getState())) {\n          ++failed;\n        } else if (TaskAttemptStateUI.KILLED.correspondsTo(attempt.getState())) {\n          ++killed;\n        }\n\n        switch (task.getType()) {\n        case MAP:\n          successfulMapAttempts +\u003d successful;\n          failedMapAttempts +\u003d failed;\n          killedMapAttempts +\u003d killed;\n          if (attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n            numMaps++;\n            avgMapTime +\u003d (attempt.getFinishTime() - attempt.getLaunchTime());\n          }\n          break;\n        case REDUCE:\n          successfulReduceAttempts +\u003d successful;\n          failedReduceAttempts +\u003d failed;\n          killedReduceAttempts +\u003d killed;\n          if (attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n            numReduces++;\n            avgShuffleTime +\u003d (attempt.getShuffleFinishTime() - attempt\n                .getLaunchTime());\n            avgMergeTime +\u003d attempt.getSortFinishTime()\n                - attempt.getShuffleFinishTime();\n            avgReduceTime +\u003d (attempt.getFinishTime() - attempt\n                .getSortFinishTime());\n          }\n          break;\n        }\n      }\n    }\n\n    if (numMaps \u003e 0) {\n      avgMapTime \u003d avgMapTime / numMaps;\n    }\n\n    if (numReduces \u003e 0) {\n      avgReduceTime \u003d avgReduceTime / numReduces;\n      avgShuffleTime \u003d avgShuffleTime / numReduces;\n      avgMergeTime \u003d avgMergeTime / numReduces;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/webapp/dao/JobInfo.java",
      "extendedDetails": {}
    },
    "5fd460e688a6df5d6093bae4b7add73f8d44162c": {
      "type": "Ybodychange",
      "commitMessage": "MAPREUDUCE-5059. Change average merge time on Job overview page to be the time delta between the end of the shuffle and the start of the reduce. Contributed by Omkar Vinit Joshi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1467120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/04/13 3:27 PM",
      "commitName": "5fd460e688a6df5d6093bae4b7add73f8d44162c",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "06/03/12 11:52 AM",
      "commitNameOld": "4ce5f6553fe8bd1c82b3a4bbd8ed4351874dd4ab",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 401.11,
      "commitsBetweenForRepo": 2204,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,67 @@\n   private void countTasksAndAttempts(Job job) {\n     numReduces \u003d 0;\n     numMaps \u003d 0;\n     final Map\u003cTaskId, Task\u003e tasks \u003d job.getTasks();\n     if (tasks \u003d\u003d null) {\n       return;\n     }\n     for (Task task : tasks.values()) {\n       // Attempts counts\n       Map\u003cTaskAttemptId, TaskAttempt\u003e attempts \u003d task.getAttempts();\n       int successful, failed, killed;\n       for (TaskAttempt attempt : attempts.values()) {\n \n         successful \u003d 0;\n         failed \u003d 0;\n         killed \u003d 0;\n         if (TaskAttemptStateUI.NEW.correspondsTo(attempt.getState())) {\n           // Do Nothing\n         } else if (TaskAttemptStateUI.RUNNING.correspondsTo(attempt.getState())) {\n           // Do Nothing\n         } else if (TaskAttemptStateUI.SUCCESSFUL.correspondsTo(attempt\n             .getState())) {\n           ++successful;\n         } else if (TaskAttemptStateUI.FAILED.correspondsTo(attempt.getState())) {\n           ++failed;\n         } else if (TaskAttemptStateUI.KILLED.correspondsTo(attempt.getState())) {\n           ++killed;\n         }\n \n         switch (task.getType()) {\n         case MAP:\n           successfulMapAttempts +\u003d successful;\n           failedMapAttempts +\u003d failed;\n           killedMapAttempts +\u003d killed;\n           if (attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n             numMaps++;\n             avgMapTime +\u003d (attempt.getFinishTime() - attempt.getLaunchTime());\n           }\n           break;\n         case REDUCE:\n           successfulReduceAttempts +\u003d successful;\n           failedReduceAttempts +\u003d failed;\n           killedReduceAttempts +\u003d killed;\n           if (attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n             numReduces++;\n             avgShuffleTime +\u003d (attempt.getShuffleFinishTime() - attempt\n                 .getLaunchTime());\n             avgMergeTime +\u003d attempt.getSortFinishTime()\n-                - attempt.getLaunchTime();\n+                - attempt.getShuffleFinishTime();\n             avgReduceTime +\u003d (attempt.getFinishTime() - attempt\n                 .getShuffleFinishTime());\n           }\n           break;\n         }\n       }\n     }\n \n     if (numMaps \u003e 0) {\n       avgMapTime \u003d avgMapTime / numMaps;\n     }\n \n     if (numReduces \u003e 0) {\n       avgReduceTime \u003d avgReduceTime / numReduces;\n       avgShuffleTime \u003d avgShuffleTime / numReduces;\n       avgMergeTime \u003d avgMergeTime / numReduces;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void countTasksAndAttempts(Job job) {\n    numReduces \u003d 0;\n    numMaps \u003d 0;\n    final Map\u003cTaskId, Task\u003e tasks \u003d job.getTasks();\n    if (tasks \u003d\u003d null) {\n      return;\n    }\n    for (Task task : tasks.values()) {\n      // Attempts counts\n      Map\u003cTaskAttemptId, TaskAttempt\u003e attempts \u003d task.getAttempts();\n      int successful, failed, killed;\n      for (TaskAttempt attempt : attempts.values()) {\n\n        successful \u003d 0;\n        failed \u003d 0;\n        killed \u003d 0;\n        if (TaskAttemptStateUI.NEW.correspondsTo(attempt.getState())) {\n          // Do Nothing\n        } else if (TaskAttemptStateUI.RUNNING.correspondsTo(attempt.getState())) {\n          // Do Nothing\n        } else if (TaskAttemptStateUI.SUCCESSFUL.correspondsTo(attempt\n            .getState())) {\n          ++successful;\n        } else if (TaskAttemptStateUI.FAILED.correspondsTo(attempt.getState())) {\n          ++failed;\n        } else if (TaskAttemptStateUI.KILLED.correspondsTo(attempt.getState())) {\n          ++killed;\n        }\n\n        switch (task.getType()) {\n        case MAP:\n          successfulMapAttempts +\u003d successful;\n          failedMapAttempts +\u003d failed;\n          killedMapAttempts +\u003d killed;\n          if (attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n            numMaps++;\n            avgMapTime +\u003d (attempt.getFinishTime() - attempt.getLaunchTime());\n          }\n          break;\n        case REDUCE:\n          successfulReduceAttempts +\u003d successful;\n          failedReduceAttempts +\u003d failed;\n          killedReduceAttempts +\u003d killed;\n          if (attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n            numReduces++;\n            avgShuffleTime +\u003d (attempt.getShuffleFinishTime() - attempt\n                .getLaunchTime());\n            avgMergeTime +\u003d attempt.getSortFinishTime()\n                - attempt.getShuffleFinishTime();\n            avgReduceTime +\u003d (attempt.getFinishTime() - attempt\n                .getShuffleFinishTime());\n          }\n          break;\n        }\n      }\n    }\n\n    if (numMaps \u003e 0) {\n      avgMapTime \u003d avgMapTime / numMaps;\n    }\n\n    if (numReduces \u003e 0) {\n      avgReduceTime \u003d avgReduceTime / numReduces;\n      avgShuffleTime \u003d avgShuffleTime / numReduces;\n      avgMergeTime \u003d avgMergeTime / numReduces;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/webapp/dao/JobInfo.java",
      "extendedDetails": {}
    },
    "0ea8570be578be60e2f32849900a1c50506d78d3": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "MAPREDUCE-2863. Support web services for YARN and MR components. (Thomas Graves via vinodkv)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213975 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/12/11 3:05 PM",
      "commitName": "0ea8570be578be60e2f32849900a1c50506d78d3",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "MAPREDUCE-2863. Support web services for YARN and MR components. (Thomas Graves via vinodkv)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213975 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/12/11 3:05 PM",
          "commitName": "0ea8570be578be60e2f32849900a1c50506d78d3",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "13/12/11 2:59 PM",
          "commitNameOld": "37b8cc3f190972c150b6fb1103d6b7a319b9bfc1",
          "commitAuthorOld": "Thomas White",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,66 +1,67 @@\n   private void countTasksAndAttempts(Job job) {\n     numReduces \u003d 0;\n     numMaps \u003d 0;\n-    Map\u003cTaskId, Task\u003e tasks \u003d job.getTasks();\n+    final Map\u003cTaskId, Task\u003e tasks \u003d job.getTasks();\n+    if (tasks \u003d\u003d null) {\n+      return;\n+    }\n     for (Task task : tasks.values()) {\n       // Attempts counts\n       Map\u003cTaskAttemptId, TaskAttempt\u003e attempts \u003d task.getAttempts();\n+      int successful, failed, killed;\n       for (TaskAttempt attempt : attempts.values()) {\n \n-        int successful \u003d 0, failed \u003d 0, killed \u003d0;\n-\n+        successful \u003d 0;\n+        failed \u003d 0;\n+        killed \u003d 0;\n         if (TaskAttemptStateUI.NEW.correspondsTo(attempt.getState())) {\n-          //Do Nothing\n-        } else if (TaskAttemptStateUI.RUNNING.correspondsTo(attempt\n-            .getState())) {\n-          //Do Nothing\n+          // Do Nothing\n+        } else if (TaskAttemptStateUI.RUNNING.correspondsTo(attempt.getState())) {\n+          // Do Nothing\n         } else if (TaskAttemptStateUI.SUCCESSFUL.correspondsTo(attempt\n             .getState())) {\n           ++successful;\n-        } else if (TaskAttemptStateUI.FAILED\n-            .correspondsTo(attempt.getState())) {\n+        } else if (TaskAttemptStateUI.FAILED.correspondsTo(attempt.getState())) {\n           ++failed;\n-        } else if (TaskAttemptStateUI.KILLED\n-            .correspondsTo(attempt.getState())) {\n+        } else if (TaskAttemptStateUI.KILLED.correspondsTo(attempt.getState())) {\n           ++killed;\n         }\n \n         switch (task.getType()) {\n         case MAP:\n           successfulMapAttempts +\u003d successful;\n           failedMapAttempts +\u003d failed;\n           killedMapAttempts +\u003d killed;\n-          if(attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n+          if (attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n             numMaps++;\n-            avgMapTime +\u003d (attempt.getFinishTime() -\n-                attempt.getLaunchTime());\n+            avgMapTime +\u003d (attempt.getFinishTime() - attempt.getLaunchTime());\n           }\n           break;\n         case REDUCE:\n           successfulReduceAttempts +\u003d successful;\n           failedReduceAttempts +\u003d failed;\n           killedReduceAttempts +\u003d killed;\n-          if(attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n+          if (attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n             numReduces++;\n-            avgShuffleTime +\u003d (attempt.getShuffleFinishTime() - \n-                attempt.getLaunchTime());\n-            avgSortTime +\u003d attempt.getSortFinishTime() - \n-                attempt.getLaunchTime();\n-            avgReduceTime +\u003d (attempt.getFinishTime() -\n-                attempt.getShuffleFinishTime());\n+            avgShuffleTime +\u003d (attempt.getShuffleFinishTime() - attempt\n+                .getLaunchTime());\n+            avgMergeTime +\u003d attempt.getSortFinishTime()\n+                - attempt.getLaunchTime();\n+            avgReduceTime +\u003d (attempt.getFinishTime() - attempt\n+                .getShuffleFinishTime());\n           }\n           break;\n         }\n       }\n     }\n \n-    if(numMaps \u003e 0) {\n+    if (numMaps \u003e 0) {\n       avgMapTime \u003d avgMapTime / numMaps;\n     }\n-    \n-    if(numReduces \u003e 0) {\n+\n+    if (numReduces \u003e 0) {\n       avgReduceTime \u003d avgReduceTime / numReduces;\n       avgShuffleTime \u003d avgShuffleTime / numReduces;\n-      avgSortTime \u003d avgSortTime / numReduces;\n+      avgMergeTime \u003d avgMergeTime / numReduces;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void countTasksAndAttempts(Job job) {\n    numReduces \u003d 0;\n    numMaps \u003d 0;\n    final Map\u003cTaskId, Task\u003e tasks \u003d job.getTasks();\n    if (tasks \u003d\u003d null) {\n      return;\n    }\n    for (Task task : tasks.values()) {\n      // Attempts counts\n      Map\u003cTaskAttemptId, TaskAttempt\u003e attempts \u003d task.getAttempts();\n      int successful, failed, killed;\n      for (TaskAttempt attempt : attempts.values()) {\n\n        successful \u003d 0;\n        failed \u003d 0;\n        killed \u003d 0;\n        if (TaskAttemptStateUI.NEW.correspondsTo(attempt.getState())) {\n          // Do Nothing\n        } else if (TaskAttemptStateUI.RUNNING.correspondsTo(attempt.getState())) {\n          // Do Nothing\n        } else if (TaskAttemptStateUI.SUCCESSFUL.correspondsTo(attempt\n            .getState())) {\n          ++successful;\n        } else if (TaskAttemptStateUI.FAILED.correspondsTo(attempt.getState())) {\n          ++failed;\n        } else if (TaskAttemptStateUI.KILLED.correspondsTo(attempt.getState())) {\n          ++killed;\n        }\n\n        switch (task.getType()) {\n        case MAP:\n          successfulMapAttempts +\u003d successful;\n          failedMapAttempts +\u003d failed;\n          killedMapAttempts +\u003d killed;\n          if (attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n            numMaps++;\n            avgMapTime +\u003d (attempt.getFinishTime() - attempt.getLaunchTime());\n          }\n          break;\n        case REDUCE:\n          successfulReduceAttempts +\u003d successful;\n          failedReduceAttempts +\u003d failed;\n          killedReduceAttempts +\u003d killed;\n          if (attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n            numReduces++;\n            avgShuffleTime +\u003d (attempt.getShuffleFinishTime() - attempt\n                .getLaunchTime());\n            avgMergeTime +\u003d attempt.getSortFinishTime()\n                - attempt.getLaunchTime();\n            avgReduceTime +\u003d (attempt.getFinishTime() - attempt\n                .getShuffleFinishTime());\n          }\n          break;\n        }\n      }\n    }\n\n    if (numMaps \u003e 0) {\n      avgMapTime \u003d avgMapTime / numMaps;\n    }\n\n    if (numReduces \u003e 0) {\n      avgReduceTime \u003d avgReduceTime / numReduces;\n      avgShuffleTime \u003d avgShuffleTime / numReduces;\n      avgMergeTime \u003d avgMergeTime / numReduces;\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/webapp/dao/JobInfo.java",
          "extendedDetails": {
            "oldPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/webapp/HsJobBlock.java",
            "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/webapp/dao/JobInfo.java",
            "oldMethodName": "countTasksAndAttempts",
            "newMethodName": "countTasksAndAttempts"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-2863. Support web services for YARN and MR components. (Thomas Graves via vinodkv)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213975 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/12/11 3:05 PM",
          "commitName": "0ea8570be578be60e2f32849900a1c50506d78d3",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "13/12/11 2:59 PM",
          "commitNameOld": "37b8cc3f190972c150b6fb1103d6b7a319b9bfc1",
          "commitAuthorOld": "Thomas White",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,66 +1,67 @@\n   private void countTasksAndAttempts(Job job) {\n     numReduces \u003d 0;\n     numMaps \u003d 0;\n-    Map\u003cTaskId, Task\u003e tasks \u003d job.getTasks();\n+    final Map\u003cTaskId, Task\u003e tasks \u003d job.getTasks();\n+    if (tasks \u003d\u003d null) {\n+      return;\n+    }\n     for (Task task : tasks.values()) {\n       // Attempts counts\n       Map\u003cTaskAttemptId, TaskAttempt\u003e attempts \u003d task.getAttempts();\n+      int successful, failed, killed;\n       for (TaskAttempt attempt : attempts.values()) {\n \n-        int successful \u003d 0, failed \u003d 0, killed \u003d0;\n-\n+        successful \u003d 0;\n+        failed \u003d 0;\n+        killed \u003d 0;\n         if (TaskAttemptStateUI.NEW.correspondsTo(attempt.getState())) {\n-          //Do Nothing\n-        } else if (TaskAttemptStateUI.RUNNING.correspondsTo(attempt\n-            .getState())) {\n-          //Do Nothing\n+          // Do Nothing\n+        } else if (TaskAttemptStateUI.RUNNING.correspondsTo(attempt.getState())) {\n+          // Do Nothing\n         } else if (TaskAttemptStateUI.SUCCESSFUL.correspondsTo(attempt\n             .getState())) {\n           ++successful;\n-        } else if (TaskAttemptStateUI.FAILED\n-            .correspondsTo(attempt.getState())) {\n+        } else if (TaskAttemptStateUI.FAILED.correspondsTo(attempt.getState())) {\n           ++failed;\n-        } else if (TaskAttemptStateUI.KILLED\n-            .correspondsTo(attempt.getState())) {\n+        } else if (TaskAttemptStateUI.KILLED.correspondsTo(attempt.getState())) {\n           ++killed;\n         }\n \n         switch (task.getType()) {\n         case MAP:\n           successfulMapAttempts +\u003d successful;\n           failedMapAttempts +\u003d failed;\n           killedMapAttempts +\u003d killed;\n-          if(attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n+          if (attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n             numMaps++;\n-            avgMapTime +\u003d (attempt.getFinishTime() -\n-                attempt.getLaunchTime());\n+            avgMapTime +\u003d (attempt.getFinishTime() - attempt.getLaunchTime());\n           }\n           break;\n         case REDUCE:\n           successfulReduceAttempts +\u003d successful;\n           failedReduceAttempts +\u003d failed;\n           killedReduceAttempts +\u003d killed;\n-          if(attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n+          if (attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n             numReduces++;\n-            avgShuffleTime +\u003d (attempt.getShuffleFinishTime() - \n-                attempt.getLaunchTime());\n-            avgSortTime +\u003d attempt.getSortFinishTime() - \n-                attempt.getLaunchTime();\n-            avgReduceTime +\u003d (attempt.getFinishTime() -\n-                attempt.getShuffleFinishTime());\n+            avgShuffleTime +\u003d (attempt.getShuffleFinishTime() - attempt\n+                .getLaunchTime());\n+            avgMergeTime +\u003d attempt.getSortFinishTime()\n+                - attempt.getLaunchTime();\n+            avgReduceTime +\u003d (attempt.getFinishTime() - attempt\n+                .getShuffleFinishTime());\n           }\n           break;\n         }\n       }\n     }\n \n-    if(numMaps \u003e 0) {\n+    if (numMaps \u003e 0) {\n       avgMapTime \u003d avgMapTime / numMaps;\n     }\n-    \n-    if(numReduces \u003e 0) {\n+\n+    if (numReduces \u003e 0) {\n       avgReduceTime \u003d avgReduceTime / numReduces;\n       avgShuffleTime \u003d avgShuffleTime / numReduces;\n-      avgSortTime \u003d avgSortTime / numReduces;\n+      avgMergeTime \u003d avgMergeTime / numReduces;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void countTasksAndAttempts(Job job) {\n    numReduces \u003d 0;\n    numMaps \u003d 0;\n    final Map\u003cTaskId, Task\u003e tasks \u003d job.getTasks();\n    if (tasks \u003d\u003d null) {\n      return;\n    }\n    for (Task task : tasks.values()) {\n      // Attempts counts\n      Map\u003cTaskAttemptId, TaskAttempt\u003e attempts \u003d task.getAttempts();\n      int successful, failed, killed;\n      for (TaskAttempt attempt : attempts.values()) {\n\n        successful \u003d 0;\n        failed \u003d 0;\n        killed \u003d 0;\n        if (TaskAttemptStateUI.NEW.correspondsTo(attempt.getState())) {\n          // Do Nothing\n        } else if (TaskAttemptStateUI.RUNNING.correspondsTo(attempt.getState())) {\n          // Do Nothing\n        } else if (TaskAttemptStateUI.SUCCESSFUL.correspondsTo(attempt\n            .getState())) {\n          ++successful;\n        } else if (TaskAttemptStateUI.FAILED.correspondsTo(attempt.getState())) {\n          ++failed;\n        } else if (TaskAttemptStateUI.KILLED.correspondsTo(attempt.getState())) {\n          ++killed;\n        }\n\n        switch (task.getType()) {\n        case MAP:\n          successfulMapAttempts +\u003d successful;\n          failedMapAttempts +\u003d failed;\n          killedMapAttempts +\u003d killed;\n          if (attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n            numMaps++;\n            avgMapTime +\u003d (attempt.getFinishTime() - attempt.getLaunchTime());\n          }\n          break;\n        case REDUCE:\n          successfulReduceAttempts +\u003d successful;\n          failedReduceAttempts +\u003d failed;\n          killedReduceAttempts +\u003d killed;\n          if (attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n            numReduces++;\n            avgShuffleTime +\u003d (attempt.getShuffleFinishTime() - attempt\n                .getLaunchTime());\n            avgMergeTime +\u003d attempt.getSortFinishTime()\n                - attempt.getLaunchTime();\n            avgReduceTime +\u003d (attempt.getFinishTime() - attempt\n                .getShuffleFinishTime());\n          }\n          break;\n        }\n      }\n    }\n\n    if (numMaps \u003e 0) {\n      avgMapTime \u003d avgMapTime / numMaps;\n    }\n\n    if (numReduces \u003e 0) {\n      avgReduceTime \u003d avgReduceTime / numReduces;\n      avgShuffleTime \u003d avgShuffleTime / numReduces;\n      avgMergeTime \u003d avgMergeTime / numReduces;\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/webapp/dao/JobInfo.java",
          "extendedDetails": {}
        }
      ]
    },
    "d9ba4670ed0134816d5d063d48394e31b51c3b35": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2672. MR-279: JobHistory Server needs Analysis this job. (Robert Evans via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1171297 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/09/11 3:21 PM",
      "commitName": "d9ba4670ed0134816d5d063d48394e31b51c3b35",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "13/09/11 3:55 PM",
      "commitNameOld": "a3e8f6836b489f8f2ddd785ae038df729c85059f",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 1.98,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,66 @@\n   private void countTasksAndAttempts(Job job) {\n+    numReduces \u003d 0;\n+    numMaps \u003d 0;\n     Map\u003cTaskId, Task\u003e tasks \u003d job.getTasks();\n     for (Task task : tasks.values()) {\n       // Attempts counts\n       Map\u003cTaskAttemptId, TaskAttempt\u003e attempts \u003d task.getAttempts();\n       for (TaskAttempt attempt : attempts.values()) {\n \n         int successful \u003d 0, failed \u003d 0, killed \u003d0;\n \n         if (TaskAttemptStateUI.NEW.correspondsTo(attempt.getState())) {\n           //Do Nothing\n         } else if (TaskAttemptStateUI.RUNNING.correspondsTo(attempt\n             .getState())) {\n           //Do Nothing\n         } else if (TaskAttemptStateUI.SUCCESSFUL.correspondsTo(attempt\n             .getState())) {\n           ++successful;\n         } else if (TaskAttemptStateUI.FAILED\n             .correspondsTo(attempt.getState())) {\n           ++failed;\n         } else if (TaskAttemptStateUI.KILLED\n             .correspondsTo(attempt.getState())) {\n           ++killed;\n         }\n \n         switch (task.getType()) {\n         case MAP:\n           successfulMapAttempts +\u003d successful;\n           failedMapAttempts +\u003d failed;\n           killedMapAttempts +\u003d killed;\n+          if(attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n+            numMaps++;\n+            avgMapTime +\u003d (attempt.getFinishTime() -\n+                attempt.getLaunchTime());\n+          }\n           break;\n         case REDUCE:\n           successfulReduceAttempts +\u003d successful;\n           failedReduceAttempts +\u003d failed;\n           killedReduceAttempts +\u003d killed;\n+          if(attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n+            numReduces++;\n+            avgShuffleTime +\u003d (attempt.getShuffleFinishTime() - \n+                attempt.getLaunchTime());\n+            avgSortTime +\u003d attempt.getSortFinishTime() - \n+                attempt.getLaunchTime();\n+            avgReduceTime +\u003d (attempt.getFinishTime() -\n+                attempt.getShuffleFinishTime());\n+          }\n           break;\n         }\n       }\n     }\n+\n+    if(numMaps \u003e 0) {\n+      avgMapTime \u003d avgMapTime / numMaps;\n+    }\n+    \n+    if(numReduces \u003e 0) {\n+      avgReduceTime \u003d avgReduceTime / numReduces;\n+      avgShuffleTime \u003d avgShuffleTime / numReduces;\n+      avgSortTime \u003d avgSortTime / numReduces;\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void countTasksAndAttempts(Job job) {\n    numReduces \u003d 0;\n    numMaps \u003d 0;\n    Map\u003cTaskId, Task\u003e tasks \u003d job.getTasks();\n    for (Task task : tasks.values()) {\n      // Attempts counts\n      Map\u003cTaskAttemptId, TaskAttempt\u003e attempts \u003d task.getAttempts();\n      for (TaskAttempt attempt : attempts.values()) {\n\n        int successful \u003d 0, failed \u003d 0, killed \u003d0;\n\n        if (TaskAttemptStateUI.NEW.correspondsTo(attempt.getState())) {\n          //Do Nothing\n        } else if (TaskAttemptStateUI.RUNNING.correspondsTo(attempt\n            .getState())) {\n          //Do Nothing\n        } else if (TaskAttemptStateUI.SUCCESSFUL.correspondsTo(attempt\n            .getState())) {\n          ++successful;\n        } else if (TaskAttemptStateUI.FAILED\n            .correspondsTo(attempt.getState())) {\n          ++failed;\n        } else if (TaskAttemptStateUI.KILLED\n            .correspondsTo(attempt.getState())) {\n          ++killed;\n        }\n\n        switch (task.getType()) {\n        case MAP:\n          successfulMapAttempts +\u003d successful;\n          failedMapAttempts +\u003d failed;\n          killedMapAttempts +\u003d killed;\n          if(attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n            numMaps++;\n            avgMapTime +\u003d (attempt.getFinishTime() -\n                attempt.getLaunchTime());\n          }\n          break;\n        case REDUCE:\n          successfulReduceAttempts +\u003d successful;\n          failedReduceAttempts +\u003d failed;\n          killedReduceAttempts +\u003d killed;\n          if(attempt.getState() \u003d\u003d TaskAttemptState.SUCCEEDED) {\n            numReduces++;\n            avgShuffleTime +\u003d (attempt.getShuffleFinishTime() - \n                attempt.getLaunchTime());\n            avgSortTime +\u003d attempt.getSortFinishTime() - \n                attempt.getLaunchTime();\n            avgReduceTime +\u003d (attempt.getFinishTime() -\n                attempt.getShuffleFinishTime());\n          }\n          break;\n        }\n      }\n    }\n\n    if(numMaps \u003e 0) {\n      avgMapTime \u003d avgMapTime / numMaps;\n    }\n    \n    if(numReduces \u003e 0) {\n      avgReduceTime \u003d avgReduceTime / numReduces;\n      avgShuffleTime \u003d avgShuffleTime / numReduces;\n      avgSortTime \u003d avgSortTime / numReduces;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/webapp/HsJobBlock.java",
      "extendedDetails": {}
    },
    "a3e8f6836b489f8f2ddd785ae038df729c85059f": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2676. MR-279: JobHistory Job page needs reformatted. (Robert Evans via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1170379 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/09/11 3:55 PM",
      "commitName": "a3e8f6836b489f8f2ddd785ae038df729c85059f",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "12/09/11 7:24 AM",
      "commitNameOld": "be32d25c546a7d4f98604e142940c483213b485b",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 1.35,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,40 @@\n   private void countTasksAndAttempts(Job job) {\n     Map\u003cTaskId, Task\u003e tasks \u003d job.getTasks();\n     for (Task task : tasks.values()) {\n-      switch (task.getType()) {\n-      case MAP:\n-        // Task counts\n-        switch (task.getState()) {\n-        case RUNNING:\n-          ++runningMapTasks;\n-          break;\n-        case SCHEDULED:\n-          ++pendingMapTasks;\n-          break;\n-        }\n-        break;\n-      case REDUCE:\n-        // Task counts\n-        switch (task.getState()) {\n-        case RUNNING:\n-          ++runningReduceTasks;\n-          break;\n-        case SCHEDULED:\n-          ++pendingReduceTasks;\n-          break;\n-        }\n-        break;\n-      }\n-\n       // Attempts counts\n       Map\u003cTaskAttemptId, TaskAttempt\u003e attempts \u003d task.getAttempts();\n       for (TaskAttempt attempt : attempts.values()) {\n \n-        int newAttempts \u003d 0, running \u003d 0, successful \u003d 0, failed \u003d 0, killed \u003d0;\n+        int successful \u003d 0, failed \u003d 0, killed \u003d0;\n \n         if (TaskAttemptStateUI.NEW.correspondsTo(attempt.getState())) {\n-          ++newAttempts;\n+          //Do Nothing\n         } else if (TaskAttemptStateUI.RUNNING.correspondsTo(attempt\n             .getState())) {\n-          ++running;\n+          //Do Nothing\n         } else if (TaskAttemptStateUI.SUCCESSFUL.correspondsTo(attempt\n             .getState())) {\n           ++successful;\n         } else if (TaskAttemptStateUI.FAILED\n             .correspondsTo(attempt.getState())) {\n           ++failed;\n         } else if (TaskAttemptStateUI.KILLED\n             .correspondsTo(attempt.getState())) {\n           ++killed;\n         }\n \n         switch (task.getType()) {\n         case MAP:\n-          newMapAttempts +\u003d newAttempts;\n-          runningMapAttempts +\u003d running;\n           successfulMapAttempts +\u003d successful;\n           failedMapAttempts +\u003d failed;\n           killedMapAttempts +\u003d killed;\n           break;\n         case REDUCE:\n-          newReduceAttempts +\u003d newAttempts;\n-          runningReduceAttempts +\u003d running;\n           successfulReduceAttempts +\u003d successful;\n           failedReduceAttempts +\u003d failed;\n           killedReduceAttempts +\u003d killed;\n           break;\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void countTasksAndAttempts(Job job) {\n    Map\u003cTaskId, Task\u003e tasks \u003d job.getTasks();\n    for (Task task : tasks.values()) {\n      // Attempts counts\n      Map\u003cTaskAttemptId, TaskAttempt\u003e attempts \u003d task.getAttempts();\n      for (TaskAttempt attempt : attempts.values()) {\n\n        int successful \u003d 0, failed \u003d 0, killed \u003d0;\n\n        if (TaskAttemptStateUI.NEW.correspondsTo(attempt.getState())) {\n          //Do Nothing\n        } else if (TaskAttemptStateUI.RUNNING.correspondsTo(attempt\n            .getState())) {\n          //Do Nothing\n        } else if (TaskAttemptStateUI.SUCCESSFUL.correspondsTo(attempt\n            .getState())) {\n          ++successful;\n        } else if (TaskAttemptStateUI.FAILED\n            .correspondsTo(attempt.getState())) {\n          ++failed;\n        } else if (TaskAttemptStateUI.KILLED\n            .correspondsTo(attempt.getState())) {\n          ++killed;\n        }\n\n        switch (task.getType()) {\n        case MAP:\n          successfulMapAttempts +\u003d successful;\n          failedMapAttempts +\u003d failed;\n          killedMapAttempts +\u003d killed;\n          break;\n        case REDUCE:\n          successfulReduceAttempts +\u003d successful;\n          failedReduceAttempts +\u003d failed;\n          killedReduceAttempts +\u003d killed;\n          break;\n        }\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/webapp/HsJobBlock.java",
      "extendedDetails": {}
    },
    "be32d25c546a7d4f98604e142940c483213b485b": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-2675. Reformat JobHistory Server main page to be more useful. Contributed by Robert Joseph Evans.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1169763 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/09/11 7:24 AM",
      "commitName": "be32d25c546a7d4f98604e142940c483213b485b",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,69 @@\n+  private void countTasksAndAttempts(Job job) {\n+    Map\u003cTaskId, Task\u003e tasks \u003d job.getTasks();\n+    for (Task task : tasks.values()) {\n+      switch (task.getType()) {\n+      case MAP:\n+        // Task counts\n+        switch (task.getState()) {\n+        case RUNNING:\n+          ++runningMapTasks;\n+          break;\n+        case SCHEDULED:\n+          ++pendingMapTasks;\n+          break;\n+        }\n+        break;\n+      case REDUCE:\n+        // Task counts\n+        switch (task.getState()) {\n+        case RUNNING:\n+          ++runningReduceTasks;\n+          break;\n+        case SCHEDULED:\n+          ++pendingReduceTasks;\n+          break;\n+        }\n+        break;\n+      }\n+\n+      // Attempts counts\n+      Map\u003cTaskAttemptId, TaskAttempt\u003e attempts \u003d task.getAttempts();\n+      for (TaskAttempt attempt : attempts.values()) {\n+\n+        int newAttempts \u003d 0, running \u003d 0, successful \u003d 0, failed \u003d 0, killed \u003d0;\n+\n+        if (TaskAttemptStateUI.NEW.correspondsTo(attempt.getState())) {\n+          ++newAttempts;\n+        } else if (TaskAttemptStateUI.RUNNING.correspondsTo(attempt\n+            .getState())) {\n+          ++running;\n+        } else if (TaskAttemptStateUI.SUCCESSFUL.correspondsTo(attempt\n+            .getState())) {\n+          ++successful;\n+        } else if (TaskAttemptStateUI.FAILED\n+            .correspondsTo(attempt.getState())) {\n+          ++failed;\n+        } else if (TaskAttemptStateUI.KILLED\n+            .correspondsTo(attempt.getState())) {\n+          ++killed;\n+        }\n+\n+        switch (task.getType()) {\n+        case MAP:\n+          newMapAttempts +\u003d newAttempts;\n+          runningMapAttempts +\u003d running;\n+          successfulMapAttempts +\u003d successful;\n+          failedMapAttempts +\u003d failed;\n+          killedMapAttempts +\u003d killed;\n+          break;\n+        case REDUCE:\n+          newReduceAttempts +\u003d newAttempts;\n+          runningReduceAttempts +\u003d running;\n+          successfulReduceAttempts +\u003d successful;\n+          failedReduceAttempts +\u003d failed;\n+          killedReduceAttempts +\u003d killed;\n+          break;\n+        }\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void countTasksAndAttempts(Job job) {\n    Map\u003cTaskId, Task\u003e tasks \u003d job.getTasks();\n    for (Task task : tasks.values()) {\n      switch (task.getType()) {\n      case MAP:\n        // Task counts\n        switch (task.getState()) {\n        case RUNNING:\n          ++runningMapTasks;\n          break;\n        case SCHEDULED:\n          ++pendingMapTasks;\n          break;\n        }\n        break;\n      case REDUCE:\n        // Task counts\n        switch (task.getState()) {\n        case RUNNING:\n          ++runningReduceTasks;\n          break;\n        case SCHEDULED:\n          ++pendingReduceTasks;\n          break;\n        }\n        break;\n      }\n\n      // Attempts counts\n      Map\u003cTaskAttemptId, TaskAttempt\u003e attempts \u003d task.getAttempts();\n      for (TaskAttempt attempt : attempts.values()) {\n\n        int newAttempts \u003d 0, running \u003d 0, successful \u003d 0, failed \u003d 0, killed \u003d0;\n\n        if (TaskAttemptStateUI.NEW.correspondsTo(attempt.getState())) {\n          ++newAttempts;\n        } else if (TaskAttemptStateUI.RUNNING.correspondsTo(attempt\n            .getState())) {\n          ++running;\n        } else if (TaskAttemptStateUI.SUCCESSFUL.correspondsTo(attempt\n            .getState())) {\n          ++successful;\n        } else if (TaskAttemptStateUI.FAILED\n            .correspondsTo(attempt.getState())) {\n          ++failed;\n        } else if (TaskAttemptStateUI.KILLED\n            .correspondsTo(attempt.getState())) {\n          ++killed;\n        }\n\n        switch (task.getType()) {\n        case MAP:\n          newMapAttempts +\u003d newAttempts;\n          runningMapAttempts +\u003d running;\n          successfulMapAttempts +\u003d successful;\n          failedMapAttempts +\u003d failed;\n          killedMapAttempts +\u003d killed;\n          break;\n        case REDUCE:\n          newReduceAttempts +\u003d newAttempts;\n          runningReduceAttempts +\u003d running;\n          successfulReduceAttempts +\u003d successful;\n          failedReduceAttempts +\u003d failed;\n          killedReduceAttempts +\u003d killed;\n          break;\n        }\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/webapp/HsJobBlock.java"
    }
  }
}