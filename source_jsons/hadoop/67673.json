{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "UniformSizeInputFormat.java",
  "functionName": "getSplits",
  "functionId": "getSplits___configuration-Configuration__numSplits-int__totalSizeBytes-long",
  "sourceFilePath": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/UniformSizeInputFormat.java",
  "functionStartLine": 79,
  "functionEndLine": 131,
  "numCommitsSeen": 9,
  "timeTaken": 1720,
  "changeHistory": [
    "bf3fb585aaf2b179836e139c041fc87920a3c886",
    "144f1cf76527e6c75aec77ef683a898580f3cc8d",
    "064c8b25eca9bc825dc07a54d9147d65c9290a03",
    "dfd807afab0fae3839c9cc5d552aa0304444f956",
    "11be7334c4e04b1b3fe12d86f4646cc83c068b05",
    "d06948002fb0cabf72cc0d46bf2fa67d45370f67"
  ],
  "changeHistoryShort": {
    "bf3fb585aaf2b179836e139c041fc87920a3c886": "Ybodychange",
    "144f1cf76527e6c75aec77ef683a898580f3cc8d": "Ybodychange",
    "064c8b25eca9bc825dc07a54d9147d65c9290a03": "Ybodychange",
    "dfd807afab0fae3839c9cc5d552aa0304444f956": "Ybodychange",
    "11be7334c4e04b1b3fe12d86f4646cc83c068b05": "Ybodychange",
    "d06948002fb0cabf72cc0d46bf2fa67d45370f67": "Yintroduced"
  },
  "changeHistoryDetails": {
    "bf3fb585aaf2b179836e139c041fc87920a3c886": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11794. Enable distcp to copy blocks in parallel. Contributed by Yongjun Zhang, Wei-Chiu Chuang, Xiao Chen, Rosie Li.\n",
      "commitDate": "30/03/17 5:38 PM",
      "commitName": "bf3fb585aaf2b179836e139c041fc87920a3c886",
      "commitAuthor": "Yongjun Zhang",
      "commitDateOld": "30/03/17 5:38 PM",
      "commitNameOld": "144f1cf76527e6c75aec77ef683a898580f3cc8d",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,52 +1,53 @@\n   private List\u003cInputSplit\u003e getSplits(Configuration configuration, int numSplits,\n                                      long totalSizeBytes) throws IOException {\n     List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e(numSplits);\n     long nBytesPerSplit \u003d (long) Math.ceil(totalSizeBytes * 1.0 / numSplits);\n \n     CopyListingFileStatus srcFileStatus \u003d new CopyListingFileStatus();\n     Text srcRelPath \u003d new Text();\n     long currentSplitSize \u003d 0;\n     long lastSplitStart \u003d 0;\n     long lastPosition \u003d 0;\n \n     final Path listingFilePath \u003d getListingFilePath(configuration);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"Average bytes per map: \" + nBytesPerSplit +\n           \", Number of maps: \" + numSplits + \", total size: \" + totalSizeBytes);\n     }\n     SequenceFile.Reader reader\u003dnull;\n     try {\n       reader \u003d getListingFileReader(configuration);\n       while (reader.next(srcRelPath, srcFileStatus)) {\n         // If adding the current file would cause the bytes per map to exceed\n         // limit. Add the current file to new split\n-        if (currentSplitSize + srcFileStatus.getLen() \u003e nBytesPerSplit \u0026\u0026 lastPosition !\u003d 0) {\n+        if (currentSplitSize + srcFileStatus.getChunkLength() \u003e nBytesPerSplit\n+            \u0026\u0026 lastPosition !\u003d 0) {\n           FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n               lastPosition - lastSplitStart, null);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug (\"Creating split : \" + split + \", bytes in split: \" + currentSplitSize);\n           }\n           splits.add(split);\n           lastSplitStart \u003d lastPosition;\n           currentSplitSize \u003d 0;\n         }\n-        currentSplitSize +\u003d srcFileStatus.getLen();\n+        currentSplitSize +\u003d srcFileStatus.getChunkLength();\n         lastPosition \u003d reader.getPosition();\n       }\n       if (lastPosition \u003e lastSplitStart) {\n         FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n             lastPosition - lastSplitStart, null);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Creating split : \" + split + \", bytes in split: \"\n               + currentSplitSize);\n         }\n         splits.add(split);\n       }\n \n     } finally {\n       IOUtils.closeStream(reader);\n     }\n \n     return splits;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cInputSplit\u003e getSplits(Configuration configuration, int numSplits,\n                                     long totalSizeBytes) throws IOException {\n    List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e(numSplits);\n    long nBytesPerSplit \u003d (long) Math.ceil(totalSizeBytes * 1.0 / numSplits);\n\n    CopyListingFileStatus srcFileStatus \u003d new CopyListingFileStatus();\n    Text srcRelPath \u003d new Text();\n    long currentSplitSize \u003d 0;\n    long lastSplitStart \u003d 0;\n    long lastPosition \u003d 0;\n\n    final Path listingFilePath \u003d getListingFilePath(configuration);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Average bytes per map: \" + nBytesPerSplit +\n          \", Number of maps: \" + numSplits + \", total size: \" + totalSizeBytes);\n    }\n    SequenceFile.Reader reader\u003dnull;\n    try {\n      reader \u003d getListingFileReader(configuration);\n      while (reader.next(srcRelPath, srcFileStatus)) {\n        // If adding the current file would cause the bytes per map to exceed\n        // limit. Add the current file to new split\n        if (currentSplitSize + srcFileStatus.getChunkLength() \u003e nBytesPerSplit\n            \u0026\u0026 lastPosition !\u003d 0) {\n          FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n              lastPosition - lastSplitStart, null);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug (\"Creating split : \" + split + \", bytes in split: \" + currentSplitSize);\n          }\n          splits.add(split);\n          lastSplitStart \u003d lastPosition;\n          currentSplitSize \u003d 0;\n        }\n        currentSplitSize +\u003d srcFileStatus.getChunkLength();\n        lastPosition \u003d reader.getPosition();\n      }\n      if (lastPosition \u003e lastSplitStart) {\n        FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n            lastPosition - lastSplitStart, null);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Creating split : \" + split + \", bytes in split: \"\n              + currentSplitSize);\n        }\n        splits.add(split);\n      }\n\n    } finally {\n      IOUtils.closeStream(reader);\n    }\n\n    return splits;\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/UniformSizeInputFormat.java",
      "extendedDetails": {}
    },
    "144f1cf76527e6c75aec77ef683a898580f3cc8d": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HADOOP-11794. Enable distcp to copy blocks in parallel. Contributed by Yongjun Zhang, Wei-Chiu Chuang, Xiao Chen.\"\n\nThis reverts commit 064c8b25eca9bc825dc07a54d9147d65c9290a03.\n",
      "commitDate": "30/03/17 5:38 PM",
      "commitName": "144f1cf76527e6c75aec77ef683a898580f3cc8d",
      "commitAuthor": "Yongjun Zhang",
      "commitDateOld": "30/03/17 5:01 PM",
      "commitNameOld": "064c8b25eca9bc825dc07a54d9147d65c9290a03",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 0.03,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,52 @@\n   private List\u003cInputSplit\u003e getSplits(Configuration configuration, int numSplits,\n                                      long totalSizeBytes) throws IOException {\n     List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e(numSplits);\n     long nBytesPerSplit \u003d (long) Math.ceil(totalSizeBytes * 1.0 / numSplits);\n \n     CopyListingFileStatus srcFileStatus \u003d new CopyListingFileStatus();\n     Text srcRelPath \u003d new Text();\n     long currentSplitSize \u003d 0;\n     long lastSplitStart \u003d 0;\n     long lastPosition \u003d 0;\n \n     final Path listingFilePath \u003d getListingFilePath(configuration);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"Average bytes per map: \" + nBytesPerSplit +\n           \", Number of maps: \" + numSplits + \", total size: \" + totalSizeBytes);\n     }\n     SequenceFile.Reader reader\u003dnull;\n     try {\n       reader \u003d getListingFileReader(configuration);\n       while (reader.next(srcRelPath, srcFileStatus)) {\n         // If adding the current file would cause the bytes per map to exceed\n         // limit. Add the current file to new split\n-        if (currentSplitSize + srcFileStatus.getChunkLength() \u003e nBytesPerSplit\n-            \u0026\u0026 lastPosition !\u003d 0) {\n+        if (currentSplitSize + srcFileStatus.getLen() \u003e nBytesPerSplit \u0026\u0026 lastPosition !\u003d 0) {\n           FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n               lastPosition - lastSplitStart, null);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug (\"Creating split : \" + split + \", bytes in split: \" + currentSplitSize);\n           }\n           splits.add(split);\n           lastSplitStart \u003d lastPosition;\n           currentSplitSize \u003d 0;\n         }\n-        currentSplitSize +\u003d srcFileStatus.getChunkLength();\n+        currentSplitSize +\u003d srcFileStatus.getLen();\n         lastPosition \u003d reader.getPosition();\n       }\n       if (lastPosition \u003e lastSplitStart) {\n         FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n             lastPosition - lastSplitStart, null);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Creating split : \" + split + \", bytes in split: \"\n               + currentSplitSize);\n         }\n         splits.add(split);\n       }\n \n     } finally {\n       IOUtils.closeStream(reader);\n     }\n \n     return splits;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cInputSplit\u003e getSplits(Configuration configuration, int numSplits,\n                                     long totalSizeBytes) throws IOException {\n    List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e(numSplits);\n    long nBytesPerSplit \u003d (long) Math.ceil(totalSizeBytes * 1.0 / numSplits);\n\n    CopyListingFileStatus srcFileStatus \u003d new CopyListingFileStatus();\n    Text srcRelPath \u003d new Text();\n    long currentSplitSize \u003d 0;\n    long lastSplitStart \u003d 0;\n    long lastPosition \u003d 0;\n\n    final Path listingFilePath \u003d getListingFilePath(configuration);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Average bytes per map: \" + nBytesPerSplit +\n          \", Number of maps: \" + numSplits + \", total size: \" + totalSizeBytes);\n    }\n    SequenceFile.Reader reader\u003dnull;\n    try {\n      reader \u003d getListingFileReader(configuration);\n      while (reader.next(srcRelPath, srcFileStatus)) {\n        // If adding the current file would cause the bytes per map to exceed\n        // limit. Add the current file to new split\n        if (currentSplitSize + srcFileStatus.getLen() \u003e nBytesPerSplit \u0026\u0026 lastPosition !\u003d 0) {\n          FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n              lastPosition - lastSplitStart, null);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug (\"Creating split : \" + split + \", bytes in split: \" + currentSplitSize);\n          }\n          splits.add(split);\n          lastSplitStart \u003d lastPosition;\n          currentSplitSize \u003d 0;\n        }\n        currentSplitSize +\u003d srcFileStatus.getLen();\n        lastPosition \u003d reader.getPosition();\n      }\n      if (lastPosition \u003e lastSplitStart) {\n        FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n            lastPosition - lastSplitStart, null);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Creating split : \" + split + \", bytes in split: \"\n              + currentSplitSize);\n        }\n        splits.add(split);\n      }\n\n    } finally {\n      IOUtils.closeStream(reader);\n    }\n\n    return splits;\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/UniformSizeInputFormat.java",
      "extendedDetails": {}
    },
    "064c8b25eca9bc825dc07a54d9147d65c9290a03": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11794. Enable distcp to copy blocks in parallel. Contributed by Yongjun Zhang, Wei-Chiu Chuang, Xiao Chen.\n",
      "commitDate": "30/03/17 5:01 PM",
      "commitName": "064c8b25eca9bc825dc07a54d9147d65c9290a03",
      "commitAuthor": "Yongjun Zhang",
      "commitDateOld": "11/01/16 9:46 AM",
      "commitNameOld": "95f32015ad9273420299130a9f10acdbafe63556",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 444.26,
      "commitsBetweenForRepo": 2995,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,52 +1,53 @@\n   private List\u003cInputSplit\u003e getSplits(Configuration configuration, int numSplits,\n                                      long totalSizeBytes) throws IOException {\n     List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e(numSplits);\n     long nBytesPerSplit \u003d (long) Math.ceil(totalSizeBytes * 1.0 / numSplits);\n \n     CopyListingFileStatus srcFileStatus \u003d new CopyListingFileStatus();\n     Text srcRelPath \u003d new Text();\n     long currentSplitSize \u003d 0;\n     long lastSplitStart \u003d 0;\n     long lastPosition \u003d 0;\n \n     final Path listingFilePath \u003d getListingFilePath(configuration);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"Average bytes per map: \" + nBytesPerSplit +\n           \", Number of maps: \" + numSplits + \", total size: \" + totalSizeBytes);\n     }\n     SequenceFile.Reader reader\u003dnull;\n     try {\n       reader \u003d getListingFileReader(configuration);\n       while (reader.next(srcRelPath, srcFileStatus)) {\n         // If adding the current file would cause the bytes per map to exceed\n         // limit. Add the current file to new split\n-        if (currentSplitSize + srcFileStatus.getLen() \u003e nBytesPerSplit \u0026\u0026 lastPosition !\u003d 0) {\n+        if (currentSplitSize + srcFileStatus.getChunkLength() \u003e nBytesPerSplit\n+            \u0026\u0026 lastPosition !\u003d 0) {\n           FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n               lastPosition - lastSplitStart, null);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug (\"Creating split : \" + split + \", bytes in split: \" + currentSplitSize);\n           }\n           splits.add(split);\n           lastSplitStart \u003d lastPosition;\n           currentSplitSize \u003d 0;\n         }\n-        currentSplitSize +\u003d srcFileStatus.getLen();\n+        currentSplitSize +\u003d srcFileStatus.getChunkLength();\n         lastPosition \u003d reader.getPosition();\n       }\n       if (lastPosition \u003e lastSplitStart) {\n         FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n             lastPosition - lastSplitStart, null);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Creating split : \" + split + \", bytes in split: \"\n               + currentSplitSize);\n         }\n         splits.add(split);\n       }\n \n     } finally {\n       IOUtils.closeStream(reader);\n     }\n \n     return splits;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cInputSplit\u003e getSplits(Configuration configuration, int numSplits,\n                                     long totalSizeBytes) throws IOException {\n    List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e(numSplits);\n    long nBytesPerSplit \u003d (long) Math.ceil(totalSizeBytes * 1.0 / numSplits);\n\n    CopyListingFileStatus srcFileStatus \u003d new CopyListingFileStatus();\n    Text srcRelPath \u003d new Text();\n    long currentSplitSize \u003d 0;\n    long lastSplitStart \u003d 0;\n    long lastPosition \u003d 0;\n\n    final Path listingFilePath \u003d getListingFilePath(configuration);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Average bytes per map: \" + nBytesPerSplit +\n          \", Number of maps: \" + numSplits + \", total size: \" + totalSizeBytes);\n    }\n    SequenceFile.Reader reader\u003dnull;\n    try {\n      reader \u003d getListingFileReader(configuration);\n      while (reader.next(srcRelPath, srcFileStatus)) {\n        // If adding the current file would cause the bytes per map to exceed\n        // limit. Add the current file to new split\n        if (currentSplitSize + srcFileStatus.getChunkLength() \u003e nBytesPerSplit\n            \u0026\u0026 lastPosition !\u003d 0) {\n          FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n              lastPosition - lastSplitStart, null);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug (\"Creating split : \" + split + \", bytes in split: \" + currentSplitSize);\n          }\n          splits.add(split);\n          lastSplitStart \u003d lastPosition;\n          currentSplitSize \u003d 0;\n        }\n        currentSplitSize +\u003d srcFileStatus.getChunkLength();\n        lastPosition \u003d reader.getPosition();\n      }\n      if (lastPosition \u003e lastSplitStart) {\n        FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n            lastPosition - lastSplitStart, null);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Creating split : \" + split + \", bytes in split: \"\n              + currentSplitSize);\n        }\n        splits.add(split);\n      }\n\n    } finally {\n      IOUtils.closeStream(reader);\n    }\n\n    return splits;\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/UniformSizeInputFormat.java",
      "extendedDetails": {}
    },
    "dfd807afab0fae3839c9cc5d552aa0304444f956": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12428. Fix inconsistency between log-level guards and statements. Contributed by Jagadesh Kiran N and Jackie Chang.\n",
      "commitDate": "21/09/15 8:54 PM",
      "commitName": "dfd807afab0fae3839c9cc5d552aa0304444f956",
      "commitAuthor": "Tsuyoshi Ozawa",
      "commitDateOld": "03/03/15 1:06 AM",
      "commitNameOld": "9ae7f9eb7baeb244e1b95aabc93ad8124870b9a9",
      "commitAuthorOld": "Tsuyoshi Ozawa",
      "daysBetweenCommits": 202.78,
      "commitsBetweenForRepo": 1527,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,52 @@\n   private List\u003cInputSplit\u003e getSplits(Configuration configuration, int numSplits,\n                                      long totalSizeBytes) throws IOException {\n     List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e(numSplits);\n     long nBytesPerSplit \u003d (long) Math.ceil(totalSizeBytes * 1.0 / numSplits);\n \n     CopyListingFileStatus srcFileStatus \u003d new CopyListingFileStatus();\n     Text srcRelPath \u003d new Text();\n     long currentSplitSize \u003d 0;\n     long lastSplitStart \u003d 0;\n     long lastPosition \u003d 0;\n \n     final Path listingFilePath \u003d getListingFilePath(configuration);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"Average bytes per map: \" + nBytesPerSplit +\n           \", Number of maps: \" + numSplits + \", total size: \" + totalSizeBytes);\n     }\n     SequenceFile.Reader reader\u003dnull;\n     try {\n       reader \u003d getListingFileReader(configuration);\n       while (reader.next(srcRelPath, srcFileStatus)) {\n         // If adding the current file would cause the bytes per map to exceed\n         // limit. Add the current file to new split\n         if (currentSplitSize + srcFileStatus.getLen() \u003e nBytesPerSplit \u0026\u0026 lastPosition !\u003d 0) {\n           FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n               lastPosition - lastSplitStart, null);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug (\"Creating split : \" + split + \", bytes in split: \" + currentSplitSize);\n           }\n           splits.add(split);\n           lastSplitStart \u003d lastPosition;\n           currentSplitSize \u003d 0;\n         }\n         currentSplitSize +\u003d srcFileStatus.getLen();\n         lastPosition \u003d reader.getPosition();\n       }\n       if (lastPosition \u003e lastSplitStart) {\n         FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n             lastPosition - lastSplitStart, null);\n         if (LOG.isDebugEnabled()) {\n-          LOG.info (\"Creating split : \" + split + \", bytes in split: \" + currentSplitSize);\n+          LOG.debug(\"Creating split : \" + split + \", bytes in split: \"\n+              + currentSplitSize);\n         }\n         splits.add(split);\n       }\n \n     } finally {\n       IOUtils.closeStream(reader);\n     }\n \n     return splits;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cInputSplit\u003e getSplits(Configuration configuration, int numSplits,\n                                     long totalSizeBytes) throws IOException {\n    List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e(numSplits);\n    long nBytesPerSplit \u003d (long) Math.ceil(totalSizeBytes * 1.0 / numSplits);\n\n    CopyListingFileStatus srcFileStatus \u003d new CopyListingFileStatus();\n    Text srcRelPath \u003d new Text();\n    long currentSplitSize \u003d 0;\n    long lastSplitStart \u003d 0;\n    long lastPosition \u003d 0;\n\n    final Path listingFilePath \u003d getListingFilePath(configuration);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Average bytes per map: \" + nBytesPerSplit +\n          \", Number of maps: \" + numSplits + \", total size: \" + totalSizeBytes);\n    }\n    SequenceFile.Reader reader\u003dnull;\n    try {\n      reader \u003d getListingFileReader(configuration);\n      while (reader.next(srcRelPath, srcFileStatus)) {\n        // If adding the current file would cause the bytes per map to exceed\n        // limit. Add the current file to new split\n        if (currentSplitSize + srcFileStatus.getLen() \u003e nBytesPerSplit \u0026\u0026 lastPosition !\u003d 0) {\n          FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n              lastPosition - lastSplitStart, null);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug (\"Creating split : \" + split + \", bytes in split: \" + currentSplitSize);\n          }\n          splits.add(split);\n          lastSplitStart \u003d lastPosition;\n          currentSplitSize \u003d 0;\n        }\n        currentSplitSize +\u003d srcFileStatus.getLen();\n        lastPosition \u003d reader.getPosition();\n      }\n      if (lastPosition \u003e lastSplitStart) {\n        FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n            lastPosition - lastSplitStart, null);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Creating split : \" + split + \", bytes in split: \"\n              + currentSplitSize);\n        }\n        splits.add(split);\n      }\n\n    } finally {\n      IOUtils.closeStream(reader);\n    }\n\n    return splits;\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/UniformSizeInputFormat.java",
      "extendedDetails": {}
    },
    "11be7334c4e04b1b3fe12d86f4646cc83c068b05": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5809. Enhance distcp to support preserving HDFS ACLs. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1595283 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/05/14 11:25 AM",
      "commitName": "11be7334c4e04b1b3fe12d86f4646cc83c068b05",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "25/01/12 10:36 PM",
      "commitNameOld": "d06948002fb0cabf72cc0d46bf2fa67d45370f67",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 841.49,
      "commitsBetweenForRepo": 5343,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,51 @@\n   private List\u003cInputSplit\u003e getSplits(Configuration configuration, int numSplits,\n                                      long totalSizeBytes) throws IOException {\n     List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e(numSplits);\n     long nBytesPerSplit \u003d (long) Math.ceil(totalSizeBytes * 1.0 / numSplits);\n \n-    FileStatus srcFileStatus \u003d new FileStatus();\n+    CopyListingFileStatus srcFileStatus \u003d new CopyListingFileStatus();\n     Text srcRelPath \u003d new Text();\n     long currentSplitSize \u003d 0;\n     long lastSplitStart \u003d 0;\n     long lastPosition \u003d 0;\n \n     final Path listingFilePath \u003d getListingFilePath(configuration);\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"Average bytes per map: \" + nBytesPerSplit +\n           \", Number of maps: \" + numSplits + \", total size: \" + totalSizeBytes);\n     }\n     SequenceFile.Reader reader\u003dnull;\n     try {\n       reader \u003d getListingFileReader(configuration);\n       while (reader.next(srcRelPath, srcFileStatus)) {\n         // If adding the current file would cause the bytes per map to exceed\n         // limit. Add the current file to new split\n         if (currentSplitSize + srcFileStatus.getLen() \u003e nBytesPerSplit \u0026\u0026 lastPosition !\u003d 0) {\n           FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n               lastPosition - lastSplitStart, null);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug (\"Creating split : \" + split + \", bytes in split: \" + currentSplitSize);\n           }\n           splits.add(split);\n           lastSplitStart \u003d lastPosition;\n           currentSplitSize \u003d 0;\n         }\n         currentSplitSize +\u003d srcFileStatus.getLen();\n         lastPosition \u003d reader.getPosition();\n       }\n       if (lastPosition \u003e lastSplitStart) {\n         FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n             lastPosition - lastSplitStart, null);\n         if (LOG.isDebugEnabled()) {\n           LOG.info (\"Creating split : \" + split + \", bytes in split: \" + currentSplitSize);\n         }\n         splits.add(split);\n       }\n \n     } finally {\n       IOUtils.closeStream(reader);\n     }\n \n     return splits;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cInputSplit\u003e getSplits(Configuration configuration, int numSplits,\n                                     long totalSizeBytes) throws IOException {\n    List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e(numSplits);\n    long nBytesPerSplit \u003d (long) Math.ceil(totalSizeBytes * 1.0 / numSplits);\n\n    CopyListingFileStatus srcFileStatus \u003d new CopyListingFileStatus();\n    Text srcRelPath \u003d new Text();\n    long currentSplitSize \u003d 0;\n    long lastSplitStart \u003d 0;\n    long lastPosition \u003d 0;\n\n    final Path listingFilePath \u003d getListingFilePath(configuration);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Average bytes per map: \" + nBytesPerSplit +\n          \", Number of maps: \" + numSplits + \", total size: \" + totalSizeBytes);\n    }\n    SequenceFile.Reader reader\u003dnull;\n    try {\n      reader \u003d getListingFileReader(configuration);\n      while (reader.next(srcRelPath, srcFileStatus)) {\n        // If adding the current file would cause the bytes per map to exceed\n        // limit. Add the current file to new split\n        if (currentSplitSize + srcFileStatus.getLen() \u003e nBytesPerSplit \u0026\u0026 lastPosition !\u003d 0) {\n          FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n              lastPosition - lastSplitStart, null);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug (\"Creating split : \" + split + \", bytes in split: \" + currentSplitSize);\n          }\n          splits.add(split);\n          lastSplitStart \u003d lastPosition;\n          currentSplitSize \u003d 0;\n        }\n        currentSplitSize +\u003d srcFileStatus.getLen();\n        lastPosition \u003d reader.getPosition();\n      }\n      if (lastPosition \u003e lastSplitStart) {\n        FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n            lastPosition - lastSplitStart, null);\n        if (LOG.isDebugEnabled()) {\n          LOG.info (\"Creating split : \" + split + \", bytes in split: \" + currentSplitSize);\n        }\n        splits.add(split);\n      }\n\n    } finally {\n      IOUtils.closeStream(reader);\n    }\n\n    return splits;\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/UniformSizeInputFormat.java",
      "extendedDetails": {}
    },
    "d06948002fb0cabf72cc0d46bf2fa67d45370f67": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-2765. DistCp Rewrite. (Mithun Radhakrishnan via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1236045 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/01/12 10:36 PM",
      "commitName": "d06948002fb0cabf72cc0d46bf2fa67d45370f67",
      "commitAuthor": "Mahadev Konar",
      "diff": "@@ -0,0 +1,51 @@\n+  private List\u003cInputSplit\u003e getSplits(Configuration configuration, int numSplits,\n+                                     long totalSizeBytes) throws IOException {\n+    List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e(numSplits);\n+    long nBytesPerSplit \u003d (long) Math.ceil(totalSizeBytes * 1.0 / numSplits);\n+\n+    FileStatus srcFileStatus \u003d new FileStatus();\n+    Text srcRelPath \u003d new Text();\n+    long currentSplitSize \u003d 0;\n+    long lastSplitStart \u003d 0;\n+    long lastPosition \u003d 0;\n+\n+    final Path listingFilePath \u003d getListingFilePath(configuration);\n+\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Average bytes per map: \" + nBytesPerSplit +\n+          \", Number of maps: \" + numSplits + \", total size: \" + totalSizeBytes);\n+    }\n+    SequenceFile.Reader reader\u003dnull;\n+    try {\n+      reader \u003d getListingFileReader(configuration);\n+      while (reader.next(srcRelPath, srcFileStatus)) {\n+        // If adding the current file would cause the bytes per map to exceed\n+        // limit. Add the current file to new split\n+        if (currentSplitSize + srcFileStatus.getLen() \u003e nBytesPerSplit \u0026\u0026 lastPosition !\u003d 0) {\n+          FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n+              lastPosition - lastSplitStart, null);\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug (\"Creating split : \" + split + \", bytes in split: \" + currentSplitSize);\n+          }\n+          splits.add(split);\n+          lastSplitStart \u003d lastPosition;\n+          currentSplitSize \u003d 0;\n+        }\n+        currentSplitSize +\u003d srcFileStatus.getLen();\n+        lastPosition \u003d reader.getPosition();\n+      }\n+      if (lastPosition \u003e lastSplitStart) {\n+        FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n+            lastPosition - lastSplitStart, null);\n+        if (LOG.isDebugEnabled()) {\n+          LOG.info (\"Creating split : \" + split + \", bytes in split: \" + currentSplitSize);\n+        }\n+        splits.add(split);\n+      }\n+\n+    } finally {\n+      IOUtils.closeStream(reader);\n+    }\n+\n+    return splits;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cInputSplit\u003e getSplits(Configuration configuration, int numSplits,\n                                     long totalSizeBytes) throws IOException {\n    List\u003cInputSplit\u003e splits \u003d new ArrayList\u003cInputSplit\u003e(numSplits);\n    long nBytesPerSplit \u003d (long) Math.ceil(totalSizeBytes * 1.0 / numSplits);\n\n    FileStatus srcFileStatus \u003d new FileStatus();\n    Text srcRelPath \u003d new Text();\n    long currentSplitSize \u003d 0;\n    long lastSplitStart \u003d 0;\n    long lastPosition \u003d 0;\n\n    final Path listingFilePath \u003d getListingFilePath(configuration);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Average bytes per map: \" + nBytesPerSplit +\n          \", Number of maps: \" + numSplits + \", total size: \" + totalSizeBytes);\n    }\n    SequenceFile.Reader reader\u003dnull;\n    try {\n      reader \u003d getListingFileReader(configuration);\n      while (reader.next(srcRelPath, srcFileStatus)) {\n        // If adding the current file would cause the bytes per map to exceed\n        // limit. Add the current file to new split\n        if (currentSplitSize + srcFileStatus.getLen() \u003e nBytesPerSplit \u0026\u0026 lastPosition !\u003d 0) {\n          FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n              lastPosition - lastSplitStart, null);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug (\"Creating split : \" + split + \", bytes in split: \" + currentSplitSize);\n          }\n          splits.add(split);\n          lastSplitStart \u003d lastPosition;\n          currentSplitSize \u003d 0;\n        }\n        currentSplitSize +\u003d srcFileStatus.getLen();\n        lastPosition \u003d reader.getPosition();\n      }\n      if (lastPosition \u003e lastSplitStart) {\n        FileSplit split \u003d new FileSplit(listingFilePath, lastSplitStart,\n            lastPosition - lastSplitStart, null);\n        if (LOG.isDebugEnabled()) {\n          LOG.info (\"Creating split : \" + split + \", bytes in split: \" + currentSplitSize);\n        }\n        splits.add(split);\n      }\n\n    } finally {\n      IOUtils.closeStream(reader);\n    }\n\n    return splits;\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/UniformSizeInputFormat.java"
    }
  }
}