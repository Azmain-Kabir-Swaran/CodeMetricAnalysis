{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImageFormatPBINode.java",
  "functionName": "serializeINodeDirectorySection",
  "functionId": "serializeINodeDirectorySection___out-OutputStream",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.java",
  "functionStartLine": 702,
  "functionEndLine": 760,
  "numCommitsSeen": 63,
  "timeTaken": 3993,
  "changeHistory": [
    "b67812ea2111fa11bdd76096b923c93e1bdf2923",
    "377f95bbe8d2d171b5d7b0bfa7559e67ca4aae46",
    "23854443efa62aa70a1c30c32c3816750e5d7a5b",
    "2624b20291629b4565ea45590b66f2c38f96df67",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305"
  ],
  "changeHistoryShort": {
    "b67812ea2111fa11bdd76096b923c93e1bdf2923": "Ybodychange",
    "377f95bbe8d2d171b5d7b0bfa7559e67ca4aae46": "Ybodychange",
    "23854443efa62aa70a1c30c32c3816750e5d7a5b": "Ybodychange",
    "2624b20291629b4565ea45590b66f2c38f96df67": "Ybodychange",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b67812ea2111fa11bdd76096b923c93e1bdf2923": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14617. Improve fsimage load time by writing sub-sections to the fsimage index (#1028). Contributed by  Stephen O\u0027Donnell.\n\nReviewed-by: He Xiaoqiao \u003chexiaoqiao@apache.org\u003e",
      "commitDate": "22/08/19 5:09 PM",
      "commitName": "b67812ea2111fa11bdd76096b923c93e1bdf2923",
      "commitAuthor": "Stephen O\u0027Donnell",
      "commitDateOld": "22/07/19 8:07 PM",
      "commitNameOld": "377f95bbe8d2d171b5d7b0bfa7559e67ca4aae46",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 30.88,
      "commitsBetweenForRepo": 299,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,59 @@\n     void serializeINodeDirectorySection(OutputStream out) throws IOException {\n       FSDirectory dir \u003d fsn.getFSDirectory();\n       Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d dir.getINodeMap()\n           .getMapIterator();\n       final ArrayList\u003cINodeReference\u003e refList \u003d parent.getSaverContext()\n           .getRefList();\n       int i \u003d 0;\n+      int outputInodes \u003d 0;\n       while (iter.hasNext()) {\n         INodeWithAdditionalFields n \u003d iter.next();\n         if (!n.isDirectory()) {\n           continue;\n         }\n \n         ReadOnlyList\u003cINode\u003e children \u003d n.asDirectory().getChildrenList(\n             Snapshot.CURRENT_STATE_ID);\n         if (children.size() \u003e 0) {\n           INodeDirectorySection.DirEntry.Builder b \u003d INodeDirectorySection.\n               DirEntry.newBuilder().setParent(n.getId());\n           for (INode inode : children) {\n             // Error if the child inode doesn\u0027t exist in inodeMap\n             if (dir.getInode(inode.getId()) \u003d\u003d null) {\n               FSImage.LOG.error(\n                   \"FSImageFormatPBINode#serializeINodeDirectorySection: \" +\n                       \"Dangling child pointer found. Missing INode in \" +\n                       \"inodeMap: id\u003d\" + inode.getId() +\n                       \"; path\u003d\" + inode.getFullPathName() +\n                       \"; parent\u003d\" + (inode.getParent() \u003d\u003d null ? \"null\" :\n                       inode.getParent().getFullPathName()));\n               ++numImageErrors;\n             }\n             if (!inode.isReference()) {\n               // Serialization must ensure that children are in order, related\n               // to HDFS-13693\n               b.addChildren(inode.getId());\n             } else {\n               refList.add(inode.asReference());\n               b.addRefChildren(refList.size() - 1);\n             }\n+            outputInodes++;\n           }\n           INodeDirectorySection.DirEntry e \u003d b.build();\n           e.writeDelimitedTo(out);\n         }\n \n         ++i;\n         if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n           context.checkCancelled();\n         }\n+        if (outputInodes \u003e\u003d parent.getInodesPerSubSection()) {\n+          outputInodes \u003d 0;\n+          parent.commitSubSection(summary,\n+              FSImageFormatProtobuf.SectionName.INODE_DIR_SUB);\n+        }\n       }\n-      parent.commitSection(summary,\n-          FSImageFormatProtobuf.SectionName.INODE_DIR);\n+      parent.commitSectionAndSubSection(summary,\n+          FSImageFormatProtobuf.SectionName.INODE_DIR,\n+          FSImageFormatProtobuf.SectionName.INODE_DIR_SUB);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void serializeINodeDirectorySection(OutputStream out) throws IOException {\n      FSDirectory dir \u003d fsn.getFSDirectory();\n      Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d dir.getINodeMap()\n          .getMapIterator();\n      final ArrayList\u003cINodeReference\u003e refList \u003d parent.getSaverContext()\n          .getRefList();\n      int i \u003d 0;\n      int outputInodes \u003d 0;\n      while (iter.hasNext()) {\n        INodeWithAdditionalFields n \u003d iter.next();\n        if (!n.isDirectory()) {\n          continue;\n        }\n\n        ReadOnlyList\u003cINode\u003e children \u003d n.asDirectory().getChildrenList(\n            Snapshot.CURRENT_STATE_ID);\n        if (children.size() \u003e 0) {\n          INodeDirectorySection.DirEntry.Builder b \u003d INodeDirectorySection.\n              DirEntry.newBuilder().setParent(n.getId());\n          for (INode inode : children) {\n            // Error if the child inode doesn\u0027t exist in inodeMap\n            if (dir.getInode(inode.getId()) \u003d\u003d null) {\n              FSImage.LOG.error(\n                  \"FSImageFormatPBINode#serializeINodeDirectorySection: \" +\n                      \"Dangling child pointer found. Missing INode in \" +\n                      \"inodeMap: id\u003d\" + inode.getId() +\n                      \"; path\u003d\" + inode.getFullPathName() +\n                      \"; parent\u003d\" + (inode.getParent() \u003d\u003d null ? \"null\" :\n                      inode.getParent().getFullPathName()));\n              ++numImageErrors;\n            }\n            if (!inode.isReference()) {\n              // Serialization must ensure that children are in order, related\n              // to HDFS-13693\n              b.addChildren(inode.getId());\n            } else {\n              refList.add(inode.asReference());\n              b.addRefChildren(refList.size() - 1);\n            }\n            outputInodes++;\n          }\n          INodeDirectorySection.DirEntry e \u003d b.build();\n          e.writeDelimitedTo(out);\n        }\n\n        ++i;\n        if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n          context.checkCancelled();\n        }\n        if (outputInodes \u003e\u003d parent.getInodesPerSubSection()) {\n          outputInodes \u003d 0;\n          parent.commitSubSection(summary,\n              FSImageFormatProtobuf.SectionName.INODE_DIR_SUB);\n        }\n      }\n      parent.commitSectionAndSubSection(summary,\n          FSImageFormatProtobuf.SectionName.INODE_DIR,\n          FSImageFormatProtobuf.SectionName.INODE_DIR_SUB);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.java",
      "extendedDetails": {}
    },
    "377f95bbe8d2d171b5d7b0bfa7559e67ca4aae46": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13693. Remove unnecessary search in INodeDirectory.addChild during image loading. Contributed by Lisheng Sun.\n",
      "commitDate": "22/07/19 8:07 PM",
      "commitName": "377f95bbe8d2d171b5d7b0bfa7559e67ca4aae46",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "18/10/18 10:53 AM",
      "commitNameOld": "0e56c883cd2310f3ff9d62afb306b1ab27419c36",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 277.39,
      "commitsBetweenForRepo": 1993,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,51 @@\n     void serializeINodeDirectorySection(OutputStream out) throws IOException {\n       FSDirectory dir \u003d fsn.getFSDirectory();\n       Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d dir.getINodeMap()\n           .getMapIterator();\n       final ArrayList\u003cINodeReference\u003e refList \u003d parent.getSaverContext()\n           .getRefList();\n       int i \u003d 0;\n       while (iter.hasNext()) {\n         INodeWithAdditionalFields n \u003d iter.next();\n         if (!n.isDirectory()) {\n           continue;\n         }\n \n         ReadOnlyList\u003cINode\u003e children \u003d n.asDirectory().getChildrenList(\n             Snapshot.CURRENT_STATE_ID);\n         if (children.size() \u003e 0) {\n           INodeDirectorySection.DirEntry.Builder b \u003d INodeDirectorySection.\n               DirEntry.newBuilder().setParent(n.getId());\n           for (INode inode : children) {\n             // Error if the child inode doesn\u0027t exist in inodeMap\n             if (dir.getInode(inode.getId()) \u003d\u003d null) {\n               FSImage.LOG.error(\n                   \"FSImageFormatPBINode#serializeINodeDirectorySection: \" +\n                       \"Dangling child pointer found. Missing INode in \" +\n                       \"inodeMap: id\u003d\" + inode.getId() +\n                       \"; path\u003d\" + inode.getFullPathName() +\n                       \"; parent\u003d\" + (inode.getParent() \u003d\u003d null ? \"null\" :\n                       inode.getParent().getFullPathName()));\n               ++numImageErrors;\n             }\n             if (!inode.isReference()) {\n+              // Serialization must ensure that children are in order, related\n+              // to HDFS-13693\n               b.addChildren(inode.getId());\n             } else {\n               refList.add(inode.asReference());\n               b.addRefChildren(refList.size() - 1);\n             }\n           }\n           INodeDirectorySection.DirEntry e \u003d b.build();\n           e.writeDelimitedTo(out);\n         }\n \n         ++i;\n         if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n           context.checkCancelled();\n         }\n       }\n       parent.commitSection(summary,\n           FSImageFormatProtobuf.SectionName.INODE_DIR);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void serializeINodeDirectorySection(OutputStream out) throws IOException {\n      FSDirectory dir \u003d fsn.getFSDirectory();\n      Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d dir.getINodeMap()\n          .getMapIterator();\n      final ArrayList\u003cINodeReference\u003e refList \u003d parent.getSaverContext()\n          .getRefList();\n      int i \u003d 0;\n      while (iter.hasNext()) {\n        INodeWithAdditionalFields n \u003d iter.next();\n        if (!n.isDirectory()) {\n          continue;\n        }\n\n        ReadOnlyList\u003cINode\u003e children \u003d n.asDirectory().getChildrenList(\n            Snapshot.CURRENT_STATE_ID);\n        if (children.size() \u003e 0) {\n          INodeDirectorySection.DirEntry.Builder b \u003d INodeDirectorySection.\n              DirEntry.newBuilder().setParent(n.getId());\n          for (INode inode : children) {\n            // Error if the child inode doesn\u0027t exist in inodeMap\n            if (dir.getInode(inode.getId()) \u003d\u003d null) {\n              FSImage.LOG.error(\n                  \"FSImageFormatPBINode#serializeINodeDirectorySection: \" +\n                      \"Dangling child pointer found. Missing INode in \" +\n                      \"inodeMap: id\u003d\" + inode.getId() +\n                      \"; path\u003d\" + inode.getFullPathName() +\n                      \"; parent\u003d\" + (inode.getParent() \u003d\u003d null ? \"null\" :\n                      inode.getParent().getFullPathName()));\n              ++numImageErrors;\n            }\n            if (!inode.isReference()) {\n              // Serialization must ensure that children are in order, related\n              // to HDFS-13693\n              b.addChildren(inode.getId());\n            } else {\n              refList.add(inode.asReference());\n              b.addRefChildren(refList.size() - 1);\n            }\n          }\n          INodeDirectorySection.DirEntry e \u003d b.build();\n          e.writeDelimitedTo(out);\n        }\n\n        ++i;\n        if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n          context.checkCancelled();\n        }\n      }\n      parent.commitSection(summary,\n          FSImageFormatProtobuf.SectionName.INODE_DIR);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.java",
      "extendedDetails": {}
    },
    "23854443efa62aa70a1c30c32c3816750e5d7a5b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13813. Exit NameNode if dangling child inode is detected when saving FsImage. Contributed by Siyao Meng.\n",
      "commitDate": "13/08/18 4:12 PM",
      "commitName": "23854443efa62aa70a1c30c32c3816750e5d7a5b",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "14/09/17 6:08 PM",
      "commitNameOld": "ae8f55b93243560bd891962d6c64320ddc62a7d7",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 332.92,
      "commitsBetweenForRepo": 2979,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,49 @@\n     void serializeINodeDirectorySection(OutputStream out) throws IOException {\n-      Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d fsn.getFSDirectory()\n-          .getINodeMap().getMapIterator();\n+      FSDirectory dir \u003d fsn.getFSDirectory();\n+      Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d dir.getINodeMap()\n+          .getMapIterator();\n       final ArrayList\u003cINodeReference\u003e refList \u003d parent.getSaverContext()\n           .getRefList();\n       int i \u003d 0;\n       while (iter.hasNext()) {\n         INodeWithAdditionalFields n \u003d iter.next();\n         if (!n.isDirectory()) {\n           continue;\n         }\n \n         ReadOnlyList\u003cINode\u003e children \u003d n.asDirectory().getChildrenList(\n             Snapshot.CURRENT_STATE_ID);\n         if (children.size() \u003e 0) {\n           INodeDirectorySection.DirEntry.Builder b \u003d INodeDirectorySection.\n               DirEntry.newBuilder().setParent(n.getId());\n           for (INode inode : children) {\n+            // Error if the child inode doesn\u0027t exist in inodeMap\n+            if (dir.getInode(inode.getId()) \u003d\u003d null) {\n+              FSImage.LOG.error(\n+                  \"FSImageFormatPBINode#serializeINodeDirectorySection: \" +\n+                      \"Dangling child pointer found. Missing INode in \" +\n+                      \"inodeMap: id\u003d\" + inode.getId() +\n+                      \"; path\u003d\" + inode.getFullPathName() +\n+                      \"; parent\u003d\" + (inode.getParent() \u003d\u003d null ? \"null\" :\n+                      inode.getParent().getFullPathName()));\n+              ++numImageErrors;\n+            }\n             if (!inode.isReference()) {\n               b.addChildren(inode.getId());\n             } else {\n               refList.add(inode.asReference());\n               b.addRefChildren(refList.size() - 1);\n             }\n           }\n           INodeDirectorySection.DirEntry e \u003d b.build();\n           e.writeDelimitedTo(out);\n         }\n \n         ++i;\n         if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n           context.checkCancelled();\n         }\n       }\n       parent.commitSection(summary,\n           FSImageFormatProtobuf.SectionName.INODE_DIR);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void serializeINodeDirectorySection(OutputStream out) throws IOException {\n      FSDirectory dir \u003d fsn.getFSDirectory();\n      Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d dir.getINodeMap()\n          .getMapIterator();\n      final ArrayList\u003cINodeReference\u003e refList \u003d parent.getSaverContext()\n          .getRefList();\n      int i \u003d 0;\n      while (iter.hasNext()) {\n        INodeWithAdditionalFields n \u003d iter.next();\n        if (!n.isDirectory()) {\n          continue;\n        }\n\n        ReadOnlyList\u003cINode\u003e children \u003d n.asDirectory().getChildrenList(\n            Snapshot.CURRENT_STATE_ID);\n        if (children.size() \u003e 0) {\n          INodeDirectorySection.DirEntry.Builder b \u003d INodeDirectorySection.\n              DirEntry.newBuilder().setParent(n.getId());\n          for (INode inode : children) {\n            // Error if the child inode doesn\u0027t exist in inodeMap\n            if (dir.getInode(inode.getId()) \u003d\u003d null) {\n              FSImage.LOG.error(\n                  \"FSImageFormatPBINode#serializeINodeDirectorySection: \" +\n                      \"Dangling child pointer found. Missing INode in \" +\n                      \"inodeMap: id\u003d\" + inode.getId() +\n                      \"; path\u003d\" + inode.getFullPathName() +\n                      \"; parent\u003d\" + (inode.getParent() \u003d\u003d null ? \"null\" :\n                      inode.getParent().getFullPathName()));\n              ++numImageErrors;\n            }\n            if (!inode.isReference()) {\n              b.addChildren(inode.getId());\n            } else {\n              refList.add(inode.asReference());\n              b.addRefChildren(refList.size() - 1);\n            }\n          }\n          INodeDirectorySection.DirEntry e \u003d b.build();\n          e.writeDelimitedTo(out);\n        }\n\n        ++i;\n        if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n          context.checkCancelled();\n        }\n      }\n      parent.commitSection(summary,\n          FSImageFormatProtobuf.SectionName.INODE_DIR);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.java",
      "extendedDetails": {}
    },
    "2624b20291629b4565ea45590b66f2c38f96df67": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5847. Consolidate INodeReference into a separate section. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1567812 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/02/14 4:00 PM",
      "commitName": "2624b20291629b4565ea45590b66f2c38f96df67",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "10/02/14 3:13 PM",
      "commitNameOld": "5c978a43c3052cc1466b23653c354399186b4e10",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 2.03,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,37 @@\n     void serializeINodeDirectorySection(OutputStream out) throws IOException {\n       Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d fsn.getFSDirectory()\n           .getINodeMap().getMapIterator();\n+      final ArrayList\u003cINodeReference\u003e refList \u003d parent.getSaverContext()\n+          .getRefList();\n       int i \u003d 0;\n       while (iter.hasNext()) {\n         INodeWithAdditionalFields n \u003d iter.next();\n         if (!n.isDirectory()) {\n           continue;\n         }\n \n         ReadOnlyList\u003cINode\u003e children \u003d n.asDirectory().getChildrenList(\n             Snapshot.CURRENT_STATE_ID);\n         if (children.size() \u003e 0) {\n           INodeDirectorySection.DirEntry.Builder b \u003d INodeDirectorySection.\n               DirEntry.newBuilder().setParent(n.getId());\n-          List\u003cINodeReference\u003e refs \u003d new ArrayList\u003cINodeReference\u003e();\n           for (INode inode : children) {\n             if (!inode.isReference()) {\n               b.addChildren(inode.getId());\n             } else {\n-              refs.add(inode.asReference());\n+              refList.add(inode.asReference());\n+              b.addRefChildren(refList.size() - 1);\n             }\n           }\n-          b.setNumOfRef(refs.size());\n           INodeDirectorySection.DirEntry e \u003d b.build();\n           e.writeDelimitedTo(out);\n-          for (INodeReference ref : refs) {\n-            INodeSection.INodeReference.Builder rb \u003d buildINodeReference(ref);\n-            rb.build().writeDelimitedTo(out);\n-          }\n         }\n \n         ++i;\n         if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n           context.checkCancelled();\n         }\n       }\n       parent.commitSection(summary,\n           FSImageFormatProtobuf.SectionName.INODE_DIR);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void serializeINodeDirectorySection(OutputStream out) throws IOException {\n      Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d fsn.getFSDirectory()\n          .getINodeMap().getMapIterator();\n      final ArrayList\u003cINodeReference\u003e refList \u003d parent.getSaverContext()\n          .getRefList();\n      int i \u003d 0;\n      while (iter.hasNext()) {\n        INodeWithAdditionalFields n \u003d iter.next();\n        if (!n.isDirectory()) {\n          continue;\n        }\n\n        ReadOnlyList\u003cINode\u003e children \u003d n.asDirectory().getChildrenList(\n            Snapshot.CURRENT_STATE_ID);\n        if (children.size() \u003e 0) {\n          INodeDirectorySection.DirEntry.Builder b \u003d INodeDirectorySection.\n              DirEntry.newBuilder().setParent(n.getId());\n          for (INode inode : children) {\n            if (!inode.isReference()) {\n              b.addChildren(inode.getId());\n            } else {\n              refList.add(inode.asReference());\n              b.addRefChildren(refList.size() - 1);\n            }\n          }\n          INodeDirectorySection.DirEntry e \u003d b.build();\n          e.writeDelimitedTo(out);\n        }\n\n        ++i;\n        if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n          context.checkCancelled();\n        }\n      }\n      parent.commitSection(summary,\n          FSImageFormatProtobuf.SectionName.INODE_DIR);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.java",
      "extendedDetails": {}
    },
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5698. Use protobuf to serialize / deserialize FSImage. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1566359 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/02/14 11:18 AM",
      "commitName": "a2edb11b68ae01a44092cb14ac2717a6aad93305",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,40 @@\n+    void serializeINodeDirectorySection(OutputStream out) throws IOException {\n+      Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d fsn.getFSDirectory()\n+          .getINodeMap().getMapIterator();\n+      int i \u003d 0;\n+      while (iter.hasNext()) {\n+        INodeWithAdditionalFields n \u003d iter.next();\n+        if (!n.isDirectory()) {\n+          continue;\n+        }\n+\n+        ReadOnlyList\u003cINode\u003e children \u003d n.asDirectory().getChildrenList(\n+            Snapshot.CURRENT_STATE_ID);\n+        if (children.size() \u003e 0) {\n+          INodeDirectorySection.DirEntry.Builder b \u003d INodeDirectorySection.\n+              DirEntry.newBuilder().setParent(n.getId());\n+          List\u003cINodeReference\u003e refs \u003d new ArrayList\u003cINodeReference\u003e();\n+          for (INode inode : children) {\n+            if (!inode.isReference()) {\n+              b.addChildren(inode.getId());\n+            } else {\n+              refs.add(inode.asReference());\n+            }\n+          }\n+          b.setNumOfRef(refs.size());\n+          INodeDirectorySection.DirEntry e \u003d b.build();\n+          e.writeDelimitedTo(out);\n+          for (INodeReference ref : refs) {\n+            INodeSection.INodeReference.Builder rb \u003d buildINodeReference(ref);\n+            rb.build().writeDelimitedTo(out);\n+          }\n+        }\n+\n+        ++i;\n+        if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n+          context.checkCancelled();\n+        }\n+      }\n+      parent.commitSection(summary,\n+          FSImageFormatProtobuf.SectionName.INODE_DIR);\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    void serializeINodeDirectorySection(OutputStream out) throws IOException {\n      Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d fsn.getFSDirectory()\n          .getINodeMap().getMapIterator();\n      int i \u003d 0;\n      while (iter.hasNext()) {\n        INodeWithAdditionalFields n \u003d iter.next();\n        if (!n.isDirectory()) {\n          continue;\n        }\n\n        ReadOnlyList\u003cINode\u003e children \u003d n.asDirectory().getChildrenList(\n            Snapshot.CURRENT_STATE_ID);\n        if (children.size() \u003e 0) {\n          INodeDirectorySection.DirEntry.Builder b \u003d INodeDirectorySection.\n              DirEntry.newBuilder().setParent(n.getId());\n          List\u003cINodeReference\u003e refs \u003d new ArrayList\u003cINodeReference\u003e();\n          for (INode inode : children) {\n            if (!inode.isReference()) {\n              b.addChildren(inode.getId());\n            } else {\n              refs.add(inode.asReference());\n            }\n          }\n          b.setNumOfRef(refs.size());\n          INodeDirectorySection.DirEntry e \u003d b.build();\n          e.writeDelimitedTo(out);\n          for (INodeReference ref : refs) {\n            INodeSection.INodeReference.Builder rb \u003d buildINodeReference(ref);\n            rb.build().writeDelimitedTo(out);\n          }\n        }\n\n        ++i;\n        if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n          context.checkCancelled();\n        }\n      }\n      parent.commitSection(summary,\n          FSImageFormatProtobuf.SectionName.INODE_DIR);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.java"
    }
  }
}