{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSOutputStream.java",
  "functionName": "flushOrSync",
  "functionId": "flushOrSync___isSync-boolean__syncFlags-EnumSet__SyncFlag__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
  "functionStartLine": 627,
  "functionEndLine": 748,
  "numCommitsSeen": 190,
  "timeTaken": 10854,
  "changeHistory": [
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8",
    "6ee0539ede78b640f01c5eac18ded161182a7835",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "1c13519e1e7588c3e2974138d37bf3449ca8b3df",
    "efc510a570cf880e7df1b69932aa41932658ee51",
    "7947e5b53b9ac9524b535b0384c1c355b74723ff",
    "a16bfff71bd7f00e06e1f59bfe5445a154bb8c66",
    "952640fa4cbdc23fe8781e5627c2e8eab565c535",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f",
    "2848db814a98b83e7546f65a2751e56fb5b2dbe0",
    "394ba94c5d2801fbc5d95c7872eeeede28eed1eb",
    "36ccf097a95eae0761de7b657752e4808a86c094",
    "463aec11718e47d4aabb86a7a539cb973460aae6",
    "ab638e77b811d9592470f7d342cd11a66efbbf0d",
    "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc",
    "f26d2adbf98890cfe350c17241f5049b89a11e3c",
    "f2f5cdb5554d294a29ebf465101c5607fd56e244",
    "1c309f763be3dd2e3d7d1616d2c960ff80cf9b03",
    "571da54179f731eb8421ffc681169799588f76bc",
    "735046ebecd9e803398be56fbf79dbde5226b4c1",
    "83cf475050dba27e72b4e399491638c670621175",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": "Ybodychange",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": "Ybodychange",
    "6ee0539ede78b640f01c5eac18ded161182a7835": "Ybodychange",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": "Ybodychange",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "1c13519e1e7588c3e2974138d37bf3449ca8b3df": "Ybodychange",
    "efc510a570cf880e7df1b69932aa41932658ee51": "Ybodychange",
    "7947e5b53b9ac9524b535b0384c1c355b74723ff": "Ybodychange",
    "a16bfff71bd7f00e06e1f59bfe5445a154bb8c66": "Ybodychange",
    "952640fa4cbdc23fe8781e5627c2e8eab565c535": "Ybodychange",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": "Ybodychange",
    "2848db814a98b83e7546f65a2751e56fb5b2dbe0": "Ybodychange",
    "394ba94c5d2801fbc5d95c7872eeeede28eed1eb": "Ybodychange",
    "36ccf097a95eae0761de7b657752e4808a86c094": "Ybodychange",
    "463aec11718e47d4aabb86a7a539cb973460aae6": "Ybodychange",
    "ab638e77b811d9592470f7d342cd11a66efbbf0d": "Ybodychange",
    "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc": "Ybodychange",
    "f26d2adbf98890cfe350c17241f5049b89a11e3c": "Ybodychange",
    "f2f5cdb5554d294a29ebf465101c5607fd56e244": "Ybodychange",
    "1c309f763be3dd2e3d7d1616d2c960ff80cf9b03": "Ybodychange",
    "571da54179f731eb8421ffc681169799588f76bc": "Ymultichange(Yparameterchange,Ybodychange)",
    "735046ebecd9e803398be56fbf79dbde5226b4c1": "Ybodychange",
    "83cf475050dba27e72b4e399491638c670621175": "Ymultichange(Yrename,Yparameterchange,Ymodifierchange,Ybodychange)",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8979. Clean up checkstyle warnings in hadoop-hdfs-client module. Contributed by Mingliang Liu.\n",
      "commitDate": "03/10/15 11:38 AM",
      "commitName": "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "30/09/15 8:39 AM",
      "commitNameOld": "6c17d315287020368689fa078a40a1eaedf89d5b",
      "commitAuthorOld": "",
      "daysBetweenCommits": 3.12,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,121 +1,122 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n       synchronized (this) {\n         // flush checksum buffer, but keep checksum buffer intact if we do not\n         // need to end the current block\n         int numKept \u003d flushBuffer(!endBlock, true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         DFSClient.LOG.debug(\"DFSClient flush():  bytesCurBlock\u003d{}, \"\n                 + \"lastFlushOffset\u003d{}, createNewBlock\u003d{}\",\n             getStreamer().getBytesCurBlock(), lastFlushOffset, endBlock);\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d getStreamer().getBytesCurBlock()) {\n           assert getStreamer().getBytesCurBlock() \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d getStreamer().getBytesCurBlock();\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet if we do not end the block right now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 getStreamer().getBytesCurBlock(), getStreamer()\n                     .getAndIncCurrentSeqno(), false);\n           }\n         } else {\n           if (isSync \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet if we do not end the block right\n             // now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 getStreamer().getBytesCurBlock(), getStreamer()\n                     .getAndIncCurrentSeqno(), false);\n           } else if (currentPacket !\u003d null) {\n             // just discard the current packet since it is already been sent.\n             currentPacket.releaseBuffer(byteArrayManager);\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.setSyncBlock(isSync);\n           enqueueCurrentPacket();\n         }\n         if (endBlock \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0) {\n           // Need to end the current block, thus send an empty packet to\n           // indicate this is the end of the block and reset bytesCurBlock\n           currentPacket \u003d createPacket(0, 0, getStreamer().getBytesCurBlock(),\n               getStreamer().getAndIncCurrentSeqno(), true);\n           currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n           enqueueCurrentPacket();\n           getStreamer().setBytesCurBlock(0);\n           lastFlushOffset \u003d 0;\n         } else {\n           // Restore state of stream. Record the last flush offset\n           // of the last full chunk that was flushed.\n           getStreamer().setBytesCurBlock(\n               getStreamer().getBytesCurBlock() - numKept);\n         }\n \n         toWaitFor \u003d getStreamer().getLastQueuedSeqno();\n       } // end synchronized\n \n       getStreamer().waitForAckedSeqno(toWaitFor);\n \n       // update the block length first time irrespective of flag\n       if (updateLength || getStreamer().getPersistBlocks().get()) {\n         synchronized (this) {\n           if (!getStreamer().streamerClosed()\n               \u0026\u0026 getStreamer().getBlock() !\u003d null) {\n             lastBlockLength \u003d getStreamer().getBlock().getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is required, then persist block locations on\n       // namenode.\n       if (getStreamer().getPersistBlocks().getAndSet(false) || updateLength) {\n         try {\n           dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n               lastBlockLength);\n         } catch (IOException ioe) {\n-          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n-          // If we got an error here, it might be because some other thread called\n-          // close before our hflush completed. In that case, we should throw an\n-          // exception that the stream is closed.\n+          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src,\n+              ioe);\n+          // If we got an error here, it might be because some other thread\n+          // called close before our hflush completed. In that case, we should\n+          // throw an exception that the stream is closed.\n           checkClosed();\n-          // If we aren\u0027t closed but failed to sync, we should expose that to the\n-          // caller.\n+          // If we aren\u0027t closed but failed to sync, we should expose that to\n+          // the caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (!getStreamer().streamerClosed()) {\n           getStreamer().setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n-      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n-      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n-      // but instead just propagate the error\n+      // This kind of error doesn\u0027t mean that the stream itself is broken - just\n+      // the flushing thread got interrupted. So, we shouldn\u0027t close down the\n+      // writer, but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!isClosed()) {\n           getStreamer().getLastException().set(e);\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n      synchronized (this) {\n        // flush checksum buffer, but keep checksum buffer intact if we do not\n        // need to end the current block\n        int numKept \u003d flushBuffer(!endBlock, true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        DFSClient.LOG.debug(\"DFSClient flush():  bytesCurBlock\u003d{}, \"\n                + \"lastFlushOffset\u003d{}, createNewBlock\u003d{}\",\n            getStreamer().getBytesCurBlock(), lastFlushOffset, endBlock);\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d getStreamer().getBytesCurBlock()) {\n          assert getStreamer().getBytesCurBlock() \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d getStreamer().getBytesCurBlock();\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet if we do not end the block right now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                getStreamer().getBytesCurBlock(), getStreamer()\n                    .getAndIncCurrentSeqno(), false);\n          }\n        } else {\n          if (isSync \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet if we do not end the block right\n            // now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                getStreamer().getBytesCurBlock(), getStreamer()\n                    .getAndIncCurrentSeqno(), false);\n          } else if (currentPacket !\u003d null) {\n            // just discard the current packet since it is already been sent.\n            currentPacket.releaseBuffer(byteArrayManager);\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.setSyncBlock(isSync);\n          enqueueCurrentPacket();\n        }\n        if (endBlock \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0) {\n          // Need to end the current block, thus send an empty packet to\n          // indicate this is the end of the block and reset bytesCurBlock\n          currentPacket \u003d createPacket(0, 0, getStreamer().getBytesCurBlock(),\n              getStreamer().getAndIncCurrentSeqno(), true);\n          currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n          enqueueCurrentPacket();\n          getStreamer().setBytesCurBlock(0);\n          lastFlushOffset \u003d 0;\n        } else {\n          // Restore state of stream. Record the last flush offset\n          // of the last full chunk that was flushed.\n          getStreamer().setBytesCurBlock(\n              getStreamer().getBytesCurBlock() - numKept);\n        }\n\n        toWaitFor \u003d getStreamer().getLastQueuedSeqno();\n      } // end synchronized\n\n      getStreamer().waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || getStreamer().getPersistBlocks().get()) {\n        synchronized (this) {\n          if (!getStreamer().streamerClosed()\n              \u0026\u0026 getStreamer().getBlock() !\u003d null) {\n            lastBlockLength \u003d getStreamer().getBlock().getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (getStreamer().getPersistBlocks().getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n              lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src,\n              ioe);\n          // If we got an error here, it might be because some other thread\n          // called close before our hflush completed. In that case, we should\n          // throw an exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to\n          // the caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (!getStreamer().streamerClosed()) {\n          getStreamer().setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just\n      // the flushing thread got interrupted. So, we shouldn\u0027t close down the\n      // writer, but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!isClosed()) {\n          getStreamer().getLastException().set(e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8971. Remove guards when calling LOG.debug() and LOG.trace() in client package. Contributed by Mingliang Liu.\n",
      "commitDate": "29/09/15 5:52 PM",
      "commitName": "39285e6a1978ea5e53bdc1b0aef62421382124a8",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:51 PM",
      "commitNameOld": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,124 +1,121 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n       synchronized (this) {\n         // flush checksum buffer, but keep checksum buffer intact if we do not\n         // need to end the current block\n         int numKept \u003d flushBuffer(!endBlock, true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n-        if (DFSClient.LOG.isDebugEnabled()) {\n-          DFSClient.LOG.debug(\"DFSClient flush(): \"\n-              + \" bytesCurBlock\u003d\" + getStreamer().getBytesCurBlock()\n-              + \" lastFlushOffset\u003d\" + lastFlushOffset\n-              + \" createNewBlock\u003d\" + endBlock);\n-        }\n+        DFSClient.LOG.debug(\"DFSClient flush():  bytesCurBlock\u003d{}, \"\n+                + \"lastFlushOffset\u003d{}, createNewBlock\u003d{}\",\n+            getStreamer().getBytesCurBlock(), lastFlushOffset, endBlock);\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d getStreamer().getBytesCurBlock()) {\n           assert getStreamer().getBytesCurBlock() \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d getStreamer().getBytesCurBlock();\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet if we do not end the block right now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 getStreamer().getBytesCurBlock(), getStreamer()\n                     .getAndIncCurrentSeqno(), false);\n           }\n         } else {\n           if (isSync \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet if we do not end the block right\n             // now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 getStreamer().getBytesCurBlock(), getStreamer()\n                     .getAndIncCurrentSeqno(), false);\n           } else if (currentPacket !\u003d null) {\n             // just discard the current packet since it is already been sent.\n             currentPacket.releaseBuffer(byteArrayManager);\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.setSyncBlock(isSync);\n           enqueueCurrentPacket();\n         }\n         if (endBlock \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0) {\n           // Need to end the current block, thus send an empty packet to\n           // indicate this is the end of the block and reset bytesCurBlock\n           currentPacket \u003d createPacket(0, 0, getStreamer().getBytesCurBlock(),\n               getStreamer().getAndIncCurrentSeqno(), true);\n           currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n           enqueueCurrentPacket();\n           getStreamer().setBytesCurBlock(0);\n           lastFlushOffset \u003d 0;\n         } else {\n           // Restore state of stream. Record the last flush offset\n           // of the last full chunk that was flushed.\n           getStreamer().setBytesCurBlock(\n               getStreamer().getBytesCurBlock() - numKept);\n         }\n \n         toWaitFor \u003d getStreamer().getLastQueuedSeqno();\n       } // end synchronized\n \n       getStreamer().waitForAckedSeqno(toWaitFor);\n \n       // update the block length first time irrespective of flag\n       if (updateLength || getStreamer().getPersistBlocks().get()) {\n         synchronized (this) {\n           if (!getStreamer().streamerClosed()\n               \u0026\u0026 getStreamer().getBlock() !\u003d null) {\n             lastBlockLength \u003d getStreamer().getBlock().getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is required, then persist block locations on\n       // namenode.\n       if (getStreamer().getPersistBlocks().getAndSet(false) || updateLength) {\n         try {\n           dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n               lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (!getStreamer().streamerClosed()) {\n           getStreamer().setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!isClosed()) {\n           getStreamer().getLastException().set(e);\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n      synchronized (this) {\n        // flush checksum buffer, but keep checksum buffer intact if we do not\n        // need to end the current block\n        int numKept \u003d flushBuffer(!endBlock, true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        DFSClient.LOG.debug(\"DFSClient flush():  bytesCurBlock\u003d{}, \"\n                + \"lastFlushOffset\u003d{}, createNewBlock\u003d{}\",\n            getStreamer().getBytesCurBlock(), lastFlushOffset, endBlock);\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d getStreamer().getBytesCurBlock()) {\n          assert getStreamer().getBytesCurBlock() \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d getStreamer().getBytesCurBlock();\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet if we do not end the block right now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                getStreamer().getBytesCurBlock(), getStreamer()\n                    .getAndIncCurrentSeqno(), false);\n          }\n        } else {\n          if (isSync \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet if we do not end the block right\n            // now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                getStreamer().getBytesCurBlock(), getStreamer()\n                    .getAndIncCurrentSeqno(), false);\n          } else if (currentPacket !\u003d null) {\n            // just discard the current packet since it is already been sent.\n            currentPacket.releaseBuffer(byteArrayManager);\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.setSyncBlock(isSync);\n          enqueueCurrentPacket();\n        }\n        if (endBlock \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0) {\n          // Need to end the current block, thus send an empty packet to\n          // indicate this is the end of the block and reset bytesCurBlock\n          currentPacket \u003d createPacket(0, 0, getStreamer().getBytesCurBlock(),\n              getStreamer().getAndIncCurrentSeqno(), true);\n          currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n          enqueueCurrentPacket();\n          getStreamer().setBytesCurBlock(0);\n          lastFlushOffset \u003d 0;\n        } else {\n          // Restore state of stream. Record the last flush offset\n          // of the last full chunk that was flushed.\n          getStreamer().setBytesCurBlock(\n              getStreamer().getBytesCurBlock() - numKept);\n        }\n\n        toWaitFor \u003d getStreamer().getLastQueuedSeqno();\n      } // end synchronized\n\n      getStreamer().waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || getStreamer().getPersistBlocks().get()) {\n        synchronized (this) {\n          if (!getStreamer().streamerClosed()\n              \u0026\u0026 getStreamer().getBlock() !\u003d null) {\n            lastBlockLength \u003d getStreamer().getBlock().getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (getStreamer().getPersistBlocks().getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n              lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (!getStreamer().streamerClosed()) {\n          getStreamer().setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!isClosed()) {\n          getStreamer().getLastException().set(e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "6ee0539ede78b640f01c5eac18ded161182a7835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\"\n\nThis reverts commit d5a9a3daa0224249221ffa7b8bd5751ab2feca56.\n",
      "commitDate": "29/09/15 5:51 PM",
      "commitName": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:48 PM",
      "commitNameOld": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,121 +1,124 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n       synchronized (this) {\n         // flush checksum buffer, but keep checksum buffer intact if we do not\n         // need to end the current block\n         int numKept \u003d flushBuffer(!endBlock, true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n-        DFSClient.LOG.debug(\"DFSClient flush():  bytesCurBlock\u003d{}, \"\n-                + \"lastFlushOffset\u003d{}, createNewBlock\u003d{}\",\n-            getStreamer().getBytesCurBlock(), lastFlushOffset, endBlock);\n+        if (DFSClient.LOG.isDebugEnabled()) {\n+          DFSClient.LOG.debug(\"DFSClient flush(): \"\n+              + \" bytesCurBlock\u003d\" + getStreamer().getBytesCurBlock()\n+              + \" lastFlushOffset\u003d\" + lastFlushOffset\n+              + \" createNewBlock\u003d\" + endBlock);\n+        }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d getStreamer().getBytesCurBlock()) {\n           assert getStreamer().getBytesCurBlock() \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d getStreamer().getBytesCurBlock();\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet if we do not end the block right now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 getStreamer().getBytesCurBlock(), getStreamer()\n                     .getAndIncCurrentSeqno(), false);\n           }\n         } else {\n           if (isSync \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet if we do not end the block right\n             // now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 getStreamer().getBytesCurBlock(), getStreamer()\n                     .getAndIncCurrentSeqno(), false);\n           } else if (currentPacket !\u003d null) {\n             // just discard the current packet since it is already been sent.\n             currentPacket.releaseBuffer(byteArrayManager);\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.setSyncBlock(isSync);\n           enqueueCurrentPacket();\n         }\n         if (endBlock \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0) {\n           // Need to end the current block, thus send an empty packet to\n           // indicate this is the end of the block and reset bytesCurBlock\n           currentPacket \u003d createPacket(0, 0, getStreamer().getBytesCurBlock(),\n               getStreamer().getAndIncCurrentSeqno(), true);\n           currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n           enqueueCurrentPacket();\n           getStreamer().setBytesCurBlock(0);\n           lastFlushOffset \u003d 0;\n         } else {\n           // Restore state of stream. Record the last flush offset\n           // of the last full chunk that was flushed.\n           getStreamer().setBytesCurBlock(\n               getStreamer().getBytesCurBlock() - numKept);\n         }\n \n         toWaitFor \u003d getStreamer().getLastQueuedSeqno();\n       } // end synchronized\n \n       getStreamer().waitForAckedSeqno(toWaitFor);\n \n       // update the block length first time irrespective of flag\n       if (updateLength || getStreamer().getPersistBlocks().get()) {\n         synchronized (this) {\n           if (!getStreamer().streamerClosed()\n               \u0026\u0026 getStreamer().getBlock() !\u003d null) {\n             lastBlockLength \u003d getStreamer().getBlock().getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is required, then persist block locations on\n       // namenode.\n       if (getStreamer().getPersistBlocks().getAndSet(false) || updateLength) {\n         try {\n           dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n               lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (!getStreamer().streamerClosed()) {\n           getStreamer().setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!isClosed()) {\n           getStreamer().getLastException().set(e);\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n      synchronized (this) {\n        // flush checksum buffer, but keep checksum buffer intact if we do not\n        // need to end the current block\n        int numKept \u003d flushBuffer(!endBlock, true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"DFSClient flush(): \"\n              + \" bytesCurBlock\u003d\" + getStreamer().getBytesCurBlock()\n              + \" lastFlushOffset\u003d\" + lastFlushOffset\n              + \" createNewBlock\u003d\" + endBlock);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d getStreamer().getBytesCurBlock()) {\n          assert getStreamer().getBytesCurBlock() \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d getStreamer().getBytesCurBlock();\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet if we do not end the block right now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                getStreamer().getBytesCurBlock(), getStreamer()\n                    .getAndIncCurrentSeqno(), false);\n          }\n        } else {\n          if (isSync \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet if we do not end the block right\n            // now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                getStreamer().getBytesCurBlock(), getStreamer()\n                    .getAndIncCurrentSeqno(), false);\n          } else if (currentPacket !\u003d null) {\n            // just discard the current packet since it is already been sent.\n            currentPacket.releaseBuffer(byteArrayManager);\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.setSyncBlock(isSync);\n          enqueueCurrentPacket();\n        }\n        if (endBlock \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0) {\n          // Need to end the current block, thus send an empty packet to\n          // indicate this is the end of the block and reset bytesCurBlock\n          currentPacket \u003d createPacket(0, 0, getStreamer().getBytesCurBlock(),\n              getStreamer().getAndIncCurrentSeqno(), true);\n          currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n          enqueueCurrentPacket();\n          getStreamer().setBytesCurBlock(0);\n          lastFlushOffset \u003d 0;\n        } else {\n          // Restore state of stream. Record the last flush offset\n          // of the last full chunk that was flushed.\n          getStreamer().setBytesCurBlock(\n              getStreamer().getBytesCurBlock() - numKept);\n        }\n\n        toWaitFor \u003d getStreamer().getLastQueuedSeqno();\n      } // end synchronized\n\n      getStreamer().waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || getStreamer().getPersistBlocks().get()) {\n        synchronized (this) {\n          if (!getStreamer().streamerClosed()\n              \u0026\u0026 getStreamer().getBlock() !\u003d null) {\n            lastBlockLength \u003d getStreamer().getBlock().getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (getStreamer().getPersistBlocks().getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n              lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (!getStreamer().streamerClosed()) {\n          getStreamer().setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!isClosed()) {\n          getStreamer().getLastException().set(e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "29/09/15 5:48 PM",
      "commitName": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/09/15 7:42 AM",
      "commitNameOld": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 1.42,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,124 +1,121 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n       synchronized (this) {\n         // flush checksum buffer, but keep checksum buffer intact if we do not\n         // need to end the current block\n         int numKept \u003d flushBuffer(!endBlock, true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n-        if (DFSClient.LOG.isDebugEnabled()) {\n-          DFSClient.LOG.debug(\"DFSClient flush(): \"\n-              + \" bytesCurBlock\u003d\" + getStreamer().getBytesCurBlock()\n-              + \" lastFlushOffset\u003d\" + lastFlushOffset\n-              + \" createNewBlock\u003d\" + endBlock);\n-        }\n+        DFSClient.LOG.debug(\"DFSClient flush():  bytesCurBlock\u003d{}, \"\n+                + \"lastFlushOffset\u003d{}, createNewBlock\u003d{}\",\n+            getStreamer().getBytesCurBlock(), lastFlushOffset, endBlock);\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d getStreamer().getBytesCurBlock()) {\n           assert getStreamer().getBytesCurBlock() \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d getStreamer().getBytesCurBlock();\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet if we do not end the block right now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 getStreamer().getBytesCurBlock(), getStreamer()\n                     .getAndIncCurrentSeqno(), false);\n           }\n         } else {\n           if (isSync \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet if we do not end the block right\n             // now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 getStreamer().getBytesCurBlock(), getStreamer()\n                     .getAndIncCurrentSeqno(), false);\n           } else if (currentPacket !\u003d null) {\n             // just discard the current packet since it is already been sent.\n             currentPacket.releaseBuffer(byteArrayManager);\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.setSyncBlock(isSync);\n           enqueueCurrentPacket();\n         }\n         if (endBlock \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0) {\n           // Need to end the current block, thus send an empty packet to\n           // indicate this is the end of the block and reset bytesCurBlock\n           currentPacket \u003d createPacket(0, 0, getStreamer().getBytesCurBlock(),\n               getStreamer().getAndIncCurrentSeqno(), true);\n           currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n           enqueueCurrentPacket();\n           getStreamer().setBytesCurBlock(0);\n           lastFlushOffset \u003d 0;\n         } else {\n           // Restore state of stream. Record the last flush offset\n           // of the last full chunk that was flushed.\n           getStreamer().setBytesCurBlock(\n               getStreamer().getBytesCurBlock() - numKept);\n         }\n \n         toWaitFor \u003d getStreamer().getLastQueuedSeqno();\n       } // end synchronized\n \n       getStreamer().waitForAckedSeqno(toWaitFor);\n \n       // update the block length first time irrespective of flag\n       if (updateLength || getStreamer().getPersistBlocks().get()) {\n         synchronized (this) {\n           if (!getStreamer().streamerClosed()\n               \u0026\u0026 getStreamer().getBlock() !\u003d null) {\n             lastBlockLength \u003d getStreamer().getBlock().getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is required, then persist block locations on\n       // namenode.\n       if (getStreamer().getPersistBlocks().getAndSet(false) || updateLength) {\n         try {\n           dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n               lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (!getStreamer().streamerClosed()) {\n           getStreamer().setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!isClosed()) {\n           getStreamer().getLastException().set(e);\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n      synchronized (this) {\n        // flush checksum buffer, but keep checksum buffer intact if we do not\n        // need to end the current block\n        int numKept \u003d flushBuffer(!endBlock, true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        DFSClient.LOG.debug(\"DFSClient flush():  bytesCurBlock\u003d{}, \"\n                + \"lastFlushOffset\u003d{}, createNewBlock\u003d{}\",\n            getStreamer().getBytesCurBlock(), lastFlushOffset, endBlock);\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d getStreamer().getBytesCurBlock()) {\n          assert getStreamer().getBytesCurBlock() \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d getStreamer().getBytesCurBlock();\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet if we do not end the block right now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                getStreamer().getBytesCurBlock(), getStreamer()\n                    .getAndIncCurrentSeqno(), false);\n          }\n        } else {\n          if (isSync \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet if we do not end the block right\n            // now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                getStreamer().getBytesCurBlock(), getStreamer()\n                    .getAndIncCurrentSeqno(), false);\n          } else if (currentPacket !\u003d null) {\n            // just discard the current packet since it is already been sent.\n            currentPacket.releaseBuffer(byteArrayManager);\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.setSyncBlock(isSync);\n          enqueueCurrentPacket();\n        }\n        if (endBlock \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0) {\n          // Need to end the current block, thus send an empty packet to\n          // indicate this is the end of the block and reset bytesCurBlock\n          currentPacket \u003d createPacket(0, 0, getStreamer().getBytesCurBlock(),\n              getStreamer().getAndIncCurrentSeqno(), true);\n          currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n          enqueueCurrentPacket();\n          getStreamer().setBytesCurBlock(0);\n          lastFlushOffset \u003d 0;\n        } else {\n          // Restore state of stream. Record the last flush offset\n          // of the last full chunk that was flushed.\n          getStreamer().setBytesCurBlock(\n              getStreamer().getBytesCurBlock() - numKept);\n        }\n\n        toWaitFor \u003d getStreamer().getLastQueuedSeqno();\n      } // end synchronized\n\n      getStreamer().waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || getStreamer().getPersistBlocks().get()) {\n        synchronized (this) {\n          if (!getStreamer().streamerClosed()\n              \u0026\u0026 getStreamer().getBlock() !\u003d null) {\n            lastBlockLength \u003d getStreamer().getBlock().getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (getStreamer().getPersistBlocks().getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n              lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (!getStreamer().streamerClosed()) {\n          getStreamer().setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!isClosed()) {\n          getStreamer().getLastException().set(e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n      synchronized (this) {\n        // flush checksum buffer, but keep checksum buffer intact if we do not\n        // need to end the current block\n        int numKept \u003d flushBuffer(!endBlock, true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"DFSClient flush(): \"\n              + \" bytesCurBlock\u003d\" + getStreamer().getBytesCurBlock()\n              + \" lastFlushOffset\u003d\" + lastFlushOffset\n              + \" createNewBlock\u003d\" + endBlock);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d getStreamer().getBytesCurBlock()) {\n          assert getStreamer().getBytesCurBlock() \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d getStreamer().getBytesCurBlock();\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet if we do not end the block right now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                getStreamer().getBytesCurBlock(), getStreamer()\n                    .getAndIncCurrentSeqno(), false);\n          }\n        } else {\n          if (isSync \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet if we do not end the block right\n            // now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                getStreamer().getBytesCurBlock(), getStreamer()\n                    .getAndIncCurrentSeqno(), false);\n          } else if (currentPacket !\u003d null) {\n            // just discard the current packet since it is already been sent.\n            currentPacket.releaseBuffer(byteArrayManager);\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.setSyncBlock(isSync);\n          enqueueCurrentPacket();\n        }\n        if (endBlock \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0) {\n          // Need to end the current block, thus send an empty packet to\n          // indicate this is the end of the block and reset bytesCurBlock\n          currentPacket \u003d createPacket(0, 0, getStreamer().getBytesCurBlock(),\n              getStreamer().getAndIncCurrentSeqno(), true);\n          currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n          enqueueCurrentPacket();\n          getStreamer().setBytesCurBlock(0);\n          lastFlushOffset \u003d 0;\n        } else {\n          // Restore state of stream. Record the last flush offset\n          // of the last full chunk that was flushed.\n          getStreamer().setBytesCurBlock(\n              getStreamer().getBytesCurBlock() - numKept);\n        }\n\n        toWaitFor \u003d getStreamer().getLastQueuedSeqno();\n      } // end synchronized\n\n      getStreamer().waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || getStreamer().getPersistBlocks().get()) {\n        synchronized (this) {\n          if (!getStreamer().streamerClosed()\n              \u0026\u0026 getStreamer().getBlock() !\u003d null) {\n            lastBlockLength \u003d getStreamer().getBlock().getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (getStreamer().getPersistBlocks().getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n              lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (!getStreamer().streamerClosed()) {\n          getStreamer().setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!isClosed()) {\n          getStreamer().getLastException().set(e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java"
      }
    },
    "1c13519e1e7588c3e2974138d37bf3449ca8b3df": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8605. Merge Refactor of DFSOutputStream from HDFS-7285 branch. (vinayakumarb)\n",
      "commitDate": "18/06/15 8:48 AM",
      "commitName": "1c13519e1e7588c3e2974138d37bf3449ca8b3df",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "16/06/15 6:08 PM",
      "commitNameOld": "d4929f448f95815af99100780a08b172e0262c17",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 1.61,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,126 +1,124 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n       synchronized (this) {\n         // flush checksum buffer, but keep checksum buffer intact if we do not\n         // need to end the current block\n         int numKept \u003d flushBuffer(!endBlock, true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\"DFSClient flush(): \"\n               + \" bytesCurBlock\u003d\" + getStreamer().getBytesCurBlock()\n               + \" lastFlushOffset\u003d\" + lastFlushOffset\n               + \" createNewBlock\u003d\" + endBlock);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d getStreamer().getBytesCurBlock()) {\n           assert getStreamer().getBytesCurBlock() \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d getStreamer().getBytesCurBlock();\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet if we do not end the block right now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 getStreamer().getBytesCurBlock(), getStreamer()\n                     .getAndIncCurrentSeqno(), false);\n           }\n         } else {\n           if (isSync \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet if we do not end the block right\n             // now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 getStreamer().getBytesCurBlock(), getStreamer()\n                     .getAndIncCurrentSeqno(), false);\n           } else if (currentPacket !\u003d null) {\n             // just discard the current packet since it is already been sent.\n             currentPacket.releaseBuffer(byteArrayManager);\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.setSyncBlock(isSync);\n-          getStreamer().waitAndQueuePacket(currentPacket);\n-          currentPacket \u003d null;\n+          enqueueCurrentPacket();\n         }\n         if (endBlock \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0) {\n           // Need to end the current block, thus send an empty packet to\n           // indicate this is the end of the block and reset bytesCurBlock\n           currentPacket \u003d createPacket(0, 0, getStreamer().getBytesCurBlock(),\n               getStreamer().getAndIncCurrentSeqno(), true);\n           currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n-          getStreamer().waitAndQueuePacket(currentPacket);\n-          currentPacket \u003d null;\n+          enqueueCurrentPacket();\n           getStreamer().setBytesCurBlock(0);\n           lastFlushOffset \u003d 0;\n         } else {\n           // Restore state of stream. Record the last flush offset\n           // of the last full chunk that was flushed.\n           getStreamer().setBytesCurBlock(\n               getStreamer().getBytesCurBlock() - numKept);\n         }\n \n         toWaitFor \u003d getStreamer().getLastQueuedSeqno();\n       } // end synchronized\n \n       getStreamer().waitForAckedSeqno(toWaitFor);\n \n       // update the block length first time irrespective of flag\n       if (updateLength || getStreamer().getPersistBlocks().get()) {\n         synchronized (this) {\n           if (!getStreamer().streamerClosed()\n               \u0026\u0026 getStreamer().getBlock() !\u003d null) {\n             lastBlockLength \u003d getStreamer().getBlock().getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is required, then persist block locations on\n       // namenode.\n       if (getStreamer().getPersistBlocks().getAndSet(false) || updateLength) {\n         try {\n           dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n               lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (!getStreamer().streamerClosed()) {\n           getStreamer().setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!isClosed()) {\n           getStreamer().getLastException().set(e);\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n      synchronized (this) {\n        // flush checksum buffer, but keep checksum buffer intact if we do not\n        // need to end the current block\n        int numKept \u003d flushBuffer(!endBlock, true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"DFSClient flush(): \"\n              + \" bytesCurBlock\u003d\" + getStreamer().getBytesCurBlock()\n              + \" lastFlushOffset\u003d\" + lastFlushOffset\n              + \" createNewBlock\u003d\" + endBlock);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d getStreamer().getBytesCurBlock()) {\n          assert getStreamer().getBytesCurBlock() \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d getStreamer().getBytesCurBlock();\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet if we do not end the block right now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                getStreamer().getBytesCurBlock(), getStreamer()\n                    .getAndIncCurrentSeqno(), false);\n          }\n        } else {\n          if (isSync \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet if we do not end the block right\n            // now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                getStreamer().getBytesCurBlock(), getStreamer()\n                    .getAndIncCurrentSeqno(), false);\n          } else if (currentPacket !\u003d null) {\n            // just discard the current packet since it is already been sent.\n            currentPacket.releaseBuffer(byteArrayManager);\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.setSyncBlock(isSync);\n          enqueueCurrentPacket();\n        }\n        if (endBlock \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0) {\n          // Need to end the current block, thus send an empty packet to\n          // indicate this is the end of the block and reset bytesCurBlock\n          currentPacket \u003d createPacket(0, 0, getStreamer().getBytesCurBlock(),\n              getStreamer().getAndIncCurrentSeqno(), true);\n          currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n          enqueueCurrentPacket();\n          getStreamer().setBytesCurBlock(0);\n          lastFlushOffset \u003d 0;\n        } else {\n          // Restore state of stream. Record the last flush offset\n          // of the last full chunk that was flushed.\n          getStreamer().setBytesCurBlock(\n              getStreamer().getBytesCurBlock() - numKept);\n        }\n\n        toWaitFor \u003d getStreamer().getLastQueuedSeqno();\n      } // end synchronized\n\n      getStreamer().waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || getStreamer().getPersistBlocks().get()) {\n        synchronized (this) {\n          if (!getStreamer().streamerClosed()\n              \u0026\u0026 getStreamer().getBlock() !\u003d null) {\n            lastBlockLength \u003d getStreamer().getBlock().getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (getStreamer().getPersistBlocks().getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n              lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (!getStreamer().streamerClosed()) {\n          getStreamer().setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!isClosed()) {\n          getStreamer().getLastException().set(e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "efc510a570cf880e7df1b69932aa41932658ee51": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8386. Improve synchronization of \u0027streamer\u0027 reference in DFSOutputStream. Contributed by Rakesh R.\n",
      "commitDate": "02/06/15 3:39 PM",
      "commitName": "efc510a570cf880e7df1b69932aa41932658ee51",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "30/04/15 7:27 PM",
      "commitNameOld": "98a61766286321468bf801a9f17a843d7eae8d9e",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 32.84,
      "commitsBetweenForRepo": 337,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,121 +1,126 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n       synchronized (this) {\n         // flush checksum buffer, but keep checksum buffer intact if we do not\n         // need to end the current block\n         int numKept \u003d flushBuffer(!endBlock, true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\"DFSClient flush(): \"\n-              + \" bytesCurBlock\u003d\" + streamer.getBytesCurBlock()\n+              + \" bytesCurBlock\u003d\" + getStreamer().getBytesCurBlock()\n               + \" lastFlushOffset\u003d\" + lastFlushOffset\n               + \" createNewBlock\u003d\" + endBlock);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n-        if (lastFlushOffset !\u003d streamer.getBytesCurBlock()) {\n-          assert streamer.getBytesCurBlock() \u003e lastFlushOffset;\n+        if (lastFlushOffset !\u003d getStreamer().getBytesCurBlock()) {\n+          assert getStreamer().getBytesCurBlock() \u003e lastFlushOffset;\n           // record the valid offset of this flush\n-          lastFlushOffset \u003d streamer.getBytesCurBlock();\n+          lastFlushOffset \u003d getStreamer().getBytesCurBlock();\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet if we do not end the block right now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n-                streamer.getBytesCurBlock(), streamer.getAndIncCurrentSeqno(), false);\n+                getStreamer().getBytesCurBlock(), getStreamer()\n+                    .getAndIncCurrentSeqno(), false);\n           }\n         } else {\n-          if (isSync \u0026\u0026 streamer.getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n+          if (isSync \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n-            // So send an empty sync packet if we do not end the block right now\n+            // So send an empty sync packet if we do not end the block right\n+            // now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n-                streamer.getBytesCurBlock(), streamer.getAndIncCurrentSeqno(), false);\n+                getStreamer().getBytesCurBlock(), getStreamer()\n+                    .getAndIncCurrentSeqno(), false);\n           } else if (currentPacket !\u003d null) {\n             // just discard the current packet since it is already been sent.\n             currentPacket.releaseBuffer(byteArrayManager);\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.setSyncBlock(isSync);\n-          streamer.waitAndQueuePacket(currentPacket);\n+          getStreamer().waitAndQueuePacket(currentPacket);\n           currentPacket \u003d null;\n         }\n-        if (endBlock \u0026\u0026 streamer.getBytesCurBlock() \u003e 0) {\n+        if (endBlock \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0) {\n           // Need to end the current block, thus send an empty packet to\n           // indicate this is the end of the block and reset bytesCurBlock\n-          currentPacket \u003d createPacket(0, 0, streamer.getBytesCurBlock(),\n-              streamer.getAndIncCurrentSeqno(), true);\n+          currentPacket \u003d createPacket(0, 0, getStreamer().getBytesCurBlock(),\n+              getStreamer().getAndIncCurrentSeqno(), true);\n           currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n-          streamer.waitAndQueuePacket(currentPacket);\n+          getStreamer().waitAndQueuePacket(currentPacket);\n           currentPacket \u003d null;\n-          streamer.setBytesCurBlock(0);\n+          getStreamer().setBytesCurBlock(0);\n           lastFlushOffset \u003d 0;\n         } else {\n           // Restore state of stream. Record the last flush offset\n           // of the last full chunk that was flushed.\n-          streamer.setBytesCurBlock(streamer.getBytesCurBlock() - numKept);\n+          getStreamer().setBytesCurBlock(\n+              getStreamer().getBytesCurBlock() - numKept);\n         }\n \n-        toWaitFor \u003d streamer.getLastQueuedSeqno();\n+        toWaitFor \u003d getStreamer().getLastQueuedSeqno();\n       } // end synchronized\n \n-      streamer.waitForAckedSeqno(toWaitFor);\n+      getStreamer().waitForAckedSeqno(toWaitFor);\n \n       // update the block length first time irrespective of flag\n-      if (updateLength || streamer.getPersistBlocks().get()) {\n+      if (updateLength || getStreamer().getPersistBlocks().get()) {\n         synchronized (this) {\n-          if (!streamer.streamerClosed() \u0026\u0026 streamer.getBlock() !\u003d null) {\n-            lastBlockLength \u003d streamer.getBlock().getNumBytes();\n+          if (!getStreamer().streamerClosed()\n+              \u0026\u0026 getStreamer().getBlock() !\u003d null) {\n+            lastBlockLength \u003d getStreamer().getBlock().getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is required, then persist block locations on\n       // namenode.\n-      if (streamer.getPersistBlocks().getAndSet(false) || updateLength) {\n+      if (getStreamer().getPersistBlocks().getAndSet(false) || updateLength) {\n         try {\n           dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n               lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n-        if (!streamer.streamerClosed()) {\n-          streamer.setHflush();\n+        if (!getStreamer().streamerClosed()) {\n+          getStreamer().setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!isClosed()) {\n-          streamer.getLastException().set(e);\n+          getStreamer().getLastException().set(e);\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n      synchronized (this) {\n        // flush checksum buffer, but keep checksum buffer intact if we do not\n        // need to end the current block\n        int numKept \u003d flushBuffer(!endBlock, true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"DFSClient flush(): \"\n              + \" bytesCurBlock\u003d\" + getStreamer().getBytesCurBlock()\n              + \" lastFlushOffset\u003d\" + lastFlushOffset\n              + \" createNewBlock\u003d\" + endBlock);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d getStreamer().getBytesCurBlock()) {\n          assert getStreamer().getBytesCurBlock() \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d getStreamer().getBytesCurBlock();\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet if we do not end the block right now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                getStreamer().getBytesCurBlock(), getStreamer()\n                    .getAndIncCurrentSeqno(), false);\n          }\n        } else {\n          if (isSync \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet if we do not end the block right\n            // now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                getStreamer().getBytesCurBlock(), getStreamer()\n                    .getAndIncCurrentSeqno(), false);\n          } else if (currentPacket !\u003d null) {\n            // just discard the current packet since it is already been sent.\n            currentPacket.releaseBuffer(byteArrayManager);\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.setSyncBlock(isSync);\n          getStreamer().waitAndQueuePacket(currentPacket);\n          currentPacket \u003d null;\n        }\n        if (endBlock \u0026\u0026 getStreamer().getBytesCurBlock() \u003e 0) {\n          // Need to end the current block, thus send an empty packet to\n          // indicate this is the end of the block and reset bytesCurBlock\n          currentPacket \u003d createPacket(0, 0, getStreamer().getBytesCurBlock(),\n              getStreamer().getAndIncCurrentSeqno(), true);\n          currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n          getStreamer().waitAndQueuePacket(currentPacket);\n          currentPacket \u003d null;\n          getStreamer().setBytesCurBlock(0);\n          lastFlushOffset \u003d 0;\n        } else {\n          // Restore state of stream. Record the last flush offset\n          // of the last full chunk that was flushed.\n          getStreamer().setBytesCurBlock(\n              getStreamer().getBytesCurBlock() - numKept);\n        }\n\n        toWaitFor \u003d getStreamer().getLastQueuedSeqno();\n      } // end synchronized\n\n      getStreamer().waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || getStreamer().getPersistBlocks().get()) {\n        synchronized (this) {\n          if (!getStreamer().streamerClosed()\n              \u0026\u0026 getStreamer().getBlock() !\u003d null) {\n            lastBlockLength \u003d getStreamer().getBlock().getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (getStreamer().getPersistBlocks().getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n              lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (!getStreamer().streamerClosed()) {\n          getStreamer().setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!isClosed()) {\n          getStreamer().getLastException().set(e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "7947e5b53b9ac9524b535b0384c1c355b74723ff": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8283. DataStreamer cleanup and some minor improvement. Contributed by Tsz Wo Nicholas Sze.\n",
      "commitDate": "29/04/15 10:41 AM",
      "commitName": "7947e5b53b9ac9524b535b0384c1c355b74723ff",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "24/04/15 12:21 AM",
      "commitNameOld": "c8d72907ff5a4cb9ce1effca8ad9b69689d11d1d",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 5.43,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,121 +1,121 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n       synchronized (this) {\n         // flush checksum buffer, but keep checksum buffer intact if we do not\n         // need to end the current block\n         int numKept \u003d flushBuffer(!endBlock, true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\"DFSClient flush(): \"\n               + \" bytesCurBlock\u003d\" + streamer.getBytesCurBlock()\n               + \" lastFlushOffset\u003d\" + lastFlushOffset\n               + \" createNewBlock\u003d\" + endBlock);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d streamer.getBytesCurBlock()) {\n           assert streamer.getBytesCurBlock() \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d streamer.getBytesCurBlock();\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet if we do not end the block right now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 streamer.getBytesCurBlock(), streamer.getAndIncCurrentSeqno(), false);\n           }\n         } else {\n           if (isSync \u0026\u0026 streamer.getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet if we do not end the block right now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 streamer.getBytesCurBlock(), streamer.getAndIncCurrentSeqno(), false);\n           } else if (currentPacket !\u003d null) {\n             // just discard the current packet since it is already been sent.\n             currentPacket.releaseBuffer(byteArrayManager);\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.setSyncBlock(isSync);\n           streamer.waitAndQueuePacket(currentPacket);\n           currentPacket \u003d null;\n         }\n         if (endBlock \u0026\u0026 streamer.getBytesCurBlock() \u003e 0) {\n           // Need to end the current block, thus send an empty packet to\n           // indicate this is the end of the block and reset bytesCurBlock\n           currentPacket \u003d createPacket(0, 0, streamer.getBytesCurBlock(),\n               streamer.getAndIncCurrentSeqno(), true);\n           currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n           streamer.waitAndQueuePacket(currentPacket);\n           currentPacket \u003d null;\n           streamer.setBytesCurBlock(0);\n           lastFlushOffset \u003d 0;\n         } else {\n           // Restore state of stream. Record the last flush offset\n           // of the last full chunk that was flushed.\n           streamer.setBytesCurBlock(streamer.getBytesCurBlock() - numKept);\n         }\n \n         toWaitFor \u003d streamer.getLastQueuedSeqno();\n       } // end synchronized\n \n       streamer.waitForAckedSeqno(toWaitFor);\n \n       // update the block length first time irrespective of flag\n       if (updateLength || streamer.getPersistBlocks().get()) {\n         synchronized (this) {\n           if (!streamer.streamerClosed() \u0026\u0026 streamer.getBlock() !\u003d null) {\n             lastBlockLength \u003d streamer.getBlock().getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is required, then persist block locations on\n       // namenode.\n       if (streamer.getPersistBlocks().getAndSet(false) || updateLength) {\n         try {\n           dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n               lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (!streamer.streamerClosed()) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!isClosed()) {\n-          streamer.getLastException().set(new IOException(\"IOException flush: \" + e));\n+          streamer.getLastException().set(e);\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n      synchronized (this) {\n        // flush checksum buffer, but keep checksum buffer intact if we do not\n        // need to end the current block\n        int numKept \u003d flushBuffer(!endBlock, true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"DFSClient flush(): \"\n              + \" bytesCurBlock\u003d\" + streamer.getBytesCurBlock()\n              + \" lastFlushOffset\u003d\" + lastFlushOffset\n              + \" createNewBlock\u003d\" + endBlock);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d streamer.getBytesCurBlock()) {\n          assert streamer.getBytesCurBlock() \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d streamer.getBytesCurBlock();\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet if we do not end the block right now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                streamer.getBytesCurBlock(), streamer.getAndIncCurrentSeqno(), false);\n          }\n        } else {\n          if (isSync \u0026\u0026 streamer.getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet if we do not end the block right now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                streamer.getBytesCurBlock(), streamer.getAndIncCurrentSeqno(), false);\n          } else if (currentPacket !\u003d null) {\n            // just discard the current packet since it is already been sent.\n            currentPacket.releaseBuffer(byteArrayManager);\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.setSyncBlock(isSync);\n          streamer.waitAndQueuePacket(currentPacket);\n          currentPacket \u003d null;\n        }\n        if (endBlock \u0026\u0026 streamer.getBytesCurBlock() \u003e 0) {\n          // Need to end the current block, thus send an empty packet to\n          // indicate this is the end of the block and reset bytesCurBlock\n          currentPacket \u003d createPacket(0, 0, streamer.getBytesCurBlock(),\n              streamer.getAndIncCurrentSeqno(), true);\n          currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n          streamer.waitAndQueuePacket(currentPacket);\n          currentPacket \u003d null;\n          streamer.setBytesCurBlock(0);\n          lastFlushOffset \u003d 0;\n        } else {\n          // Restore state of stream. Record the last flush offset\n          // of the last full chunk that was flushed.\n          streamer.setBytesCurBlock(streamer.getBytesCurBlock() - numKept);\n        }\n\n        toWaitFor \u003d streamer.getLastQueuedSeqno();\n      } // end synchronized\n\n      streamer.waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || streamer.getPersistBlocks().get()) {\n        synchronized (this) {\n          if (!streamer.streamerClosed() \u0026\u0026 streamer.getBlock() !\u003d null) {\n            lastBlockLength \u003d streamer.getBlock().getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (streamer.getPersistBlocks().getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n              lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (!streamer.streamerClosed()) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!isClosed()) {\n          streamer.getLastException().set(e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "a16bfff71bd7f00e06e1f59bfe5445a154bb8c66": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7854. Separate class DataStreamer out of DFSOutputStream. Contributed by Li Bo.\n",
      "commitDate": "24/03/15 11:06 AM",
      "commitName": "a16bfff71bd7f00e06e1f59bfe5445a154bb8c66",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "20/03/15 12:02 PM",
      "commitNameOld": "75ead273bea8a7dad61c4f99c3a16cab2697c498",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 3.96,
      "commitsBetweenForRepo": 37,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,118 +1,121 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n       synchronized (this) {\n         // flush checksum buffer, but keep checksum buffer intact if we do not\n         // need to end the current block\n         int numKept \u003d flushBuffer(!endBlock, true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\"DFSClient flush(): \"\n-              + \" bytesCurBlock\u003d\" + bytesCurBlock\n+              + \" bytesCurBlock\u003d\" + streamer.getBytesCurBlock()\n               + \" lastFlushOffset\u003d\" + lastFlushOffset\n               + \" createNewBlock\u003d\" + endBlock);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n-        if (lastFlushOffset !\u003d bytesCurBlock) {\n-          assert bytesCurBlock \u003e lastFlushOffset;\n+        if (lastFlushOffset !\u003d streamer.getBytesCurBlock()) {\n+          assert streamer.getBytesCurBlock() \u003e lastFlushOffset;\n           // record the valid offset of this flush\n-          lastFlushOffset \u003d bytesCurBlock;\n+          lastFlushOffset \u003d streamer.getBytesCurBlock();\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet if we do not end the block right now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n-                bytesCurBlock, currentSeqno++, false);\n+                streamer.getBytesCurBlock(), streamer.getAndIncCurrentSeqno(), false);\n           }\n         } else {\n-          if (isSync \u0026\u0026 bytesCurBlock \u003e 0 \u0026\u0026 !endBlock) {\n+          if (isSync \u0026\u0026 streamer.getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet if we do not end the block right now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n-                bytesCurBlock, currentSeqno++, false);\n+                streamer.getBytesCurBlock(), streamer.getAndIncCurrentSeqno(), false);\n           } else if (currentPacket !\u003d null) {\n             // just discard the current packet since it is already been sent.\n             currentPacket.releaseBuffer(byteArrayManager);\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.setSyncBlock(isSync);\n-          waitAndQueueCurrentPacket();          \n+          streamer.waitAndQueuePacket(currentPacket);\n+          currentPacket \u003d null;\n         }\n-        if (endBlock \u0026\u0026 bytesCurBlock \u003e 0) {\n+        if (endBlock \u0026\u0026 streamer.getBytesCurBlock() \u003e 0) {\n           // Need to end the current block, thus send an empty packet to\n           // indicate this is the end of the block and reset bytesCurBlock\n-          currentPacket \u003d createPacket(0, 0, bytesCurBlock, currentSeqno++, true);\n+          currentPacket \u003d createPacket(0, 0, streamer.getBytesCurBlock(),\n+              streamer.getAndIncCurrentSeqno(), true);\n           currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n-          waitAndQueueCurrentPacket();\n-          bytesCurBlock \u003d 0;\n+          streamer.waitAndQueuePacket(currentPacket);\n+          currentPacket \u003d null;\n+          streamer.setBytesCurBlock(0);\n           lastFlushOffset \u003d 0;\n         } else {\n           // Restore state of stream. Record the last flush offset\n           // of the last full chunk that was flushed.\n-          bytesCurBlock -\u003d numKept;\n+          streamer.setBytesCurBlock(streamer.getBytesCurBlock() - numKept);\n         }\n \n-        toWaitFor \u003d lastQueuedSeqno;\n+        toWaitFor \u003d streamer.getLastQueuedSeqno();\n       } // end synchronized\n \n-      waitForAckedSeqno(toWaitFor);\n+      streamer.waitForAckedSeqno(toWaitFor);\n \n       // update the block length first time irrespective of flag\n-      if (updateLength || persistBlocks.get()) {\n+      if (updateLength || streamer.getPersistBlocks().get()) {\n         synchronized (this) {\n-          if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n-            lastBlockLength \u003d streamer.block.getNumBytes();\n+          if (!streamer.streamerClosed() \u0026\u0026 streamer.getBlock() !\u003d null) {\n+            lastBlockLength \u003d streamer.getBlock().getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is required, then persist block locations on\n       // namenode.\n-      if (persistBlocks.getAndSet(false) || updateLength) {\n+      if (streamer.getPersistBlocks().getAndSet(false) || updateLength) {\n         try {\n           dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n               lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n-        if (streamer !\u003d null) {\n+        if (!streamer.streamerClosed()) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!isClosed()) {\n-          lastException.set(new IOException(\"IOException flush: \" + e));\n+          streamer.getLastException().set(new IOException(\"IOException flush: \" + e));\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n      synchronized (this) {\n        // flush checksum buffer, but keep checksum buffer intact if we do not\n        // need to end the current block\n        int numKept \u003d flushBuffer(!endBlock, true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"DFSClient flush(): \"\n              + \" bytesCurBlock\u003d\" + streamer.getBytesCurBlock()\n              + \" lastFlushOffset\u003d\" + lastFlushOffset\n              + \" createNewBlock\u003d\" + endBlock);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d streamer.getBytesCurBlock()) {\n          assert streamer.getBytesCurBlock() \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d streamer.getBytesCurBlock();\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet if we do not end the block right now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                streamer.getBytesCurBlock(), streamer.getAndIncCurrentSeqno(), false);\n          }\n        } else {\n          if (isSync \u0026\u0026 streamer.getBytesCurBlock() \u003e 0 \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet if we do not end the block right now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                streamer.getBytesCurBlock(), streamer.getAndIncCurrentSeqno(), false);\n          } else if (currentPacket !\u003d null) {\n            // just discard the current packet since it is already been sent.\n            currentPacket.releaseBuffer(byteArrayManager);\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.setSyncBlock(isSync);\n          streamer.waitAndQueuePacket(currentPacket);\n          currentPacket \u003d null;\n        }\n        if (endBlock \u0026\u0026 streamer.getBytesCurBlock() \u003e 0) {\n          // Need to end the current block, thus send an empty packet to\n          // indicate this is the end of the block and reset bytesCurBlock\n          currentPacket \u003d createPacket(0, 0, streamer.getBytesCurBlock(),\n              streamer.getAndIncCurrentSeqno(), true);\n          currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n          streamer.waitAndQueuePacket(currentPacket);\n          currentPacket \u003d null;\n          streamer.setBytesCurBlock(0);\n          lastFlushOffset \u003d 0;\n        } else {\n          // Restore state of stream. Record the last flush offset\n          // of the last full chunk that was flushed.\n          streamer.setBytesCurBlock(streamer.getBytesCurBlock() - numKept);\n        }\n\n        toWaitFor \u003d streamer.getLastQueuedSeqno();\n      } // end synchronized\n\n      streamer.waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || streamer.getPersistBlocks().get()) {\n        synchronized (this) {\n          if (!streamer.streamerClosed() \u0026\u0026 streamer.getBlock() !\u003d null) {\n            lastBlockLength \u003d streamer.getBlock().getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (streamer.getPersistBlocks().getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n              lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (!streamer.streamerClosed()) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!isClosed()) {\n          streamer.getLastException().set(new IOException(\"IOException flush: \" + e));\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "952640fa4cbdc23fe8781e5627c2e8eab565c535": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7855. Separate class Packet from DFSOutputStream. Contributed by Li Bo.\n",
      "commitDate": "05/03/15 10:58 AM",
      "commitName": "952640fa4cbdc23fe8781e5627c2e8eab565c535",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "01/03/15 11:03 PM",
      "commitNameOld": "67ed59348d638d56e6752ba2c71fdcd69567546d",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 3.5,
      "commitsBetweenForRepo": 39,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,119 +1,118 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n       synchronized (this) {\n         // flush checksum buffer, but keep checksum buffer intact if we do not\n         // need to end the current block\n         int numKept \u003d flushBuffer(!endBlock, true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\"DFSClient flush(): \"\n               + \" bytesCurBlock\u003d\" + bytesCurBlock\n               + \" lastFlushOffset\u003d\" + lastFlushOffset\n               + \" createNewBlock\u003d\" + endBlock);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet if we do not end the block right now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n-                bytesCurBlock, currentSeqno++);\n+                bytesCurBlock, currentSeqno++, false);\n           }\n         } else {\n           if (isSync \u0026\u0026 bytesCurBlock \u003e 0 \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet if we do not end the block right now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n-                bytesCurBlock, currentSeqno++);\n+                bytesCurBlock, currentSeqno++, false);\n           } else if (currentPacket !\u003d null) {\n             // just discard the current packet since it is already been sent.\n             currentPacket.releaseBuffer(byteArrayManager);\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n-          currentPacket.syncBlock \u003d isSync;\n+          currentPacket.setSyncBlock(isSync);\n           waitAndQueueCurrentPacket();          \n         }\n         if (endBlock \u0026\u0026 bytesCurBlock \u003e 0) {\n           // Need to end the current block, thus send an empty packet to\n           // indicate this is the end of the block and reset bytesCurBlock\n-          currentPacket \u003d createPacket(0, 0, bytesCurBlock, currentSeqno++);\n-          currentPacket.lastPacketInBlock \u003d true;\n-          currentPacket.syncBlock \u003d shouldSyncBlock || isSync;\n+          currentPacket \u003d createPacket(0, 0, bytesCurBlock, currentSeqno++, true);\n+          currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n           waitAndQueueCurrentPacket();\n           bytesCurBlock \u003d 0;\n           lastFlushOffset \u003d 0;\n         } else {\n           // Restore state of stream. Record the last flush offset\n           // of the last full chunk that was flushed.\n           bytesCurBlock -\u003d numKept;\n         }\n \n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n \n       // update the block length first time irrespective of flag\n       if (updateLength || persistBlocks.get()) {\n         synchronized (this) {\n           if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n             lastBlockLength \u003d streamer.block.getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is required, then persist block locations on\n       // namenode.\n       if (persistBlocks.getAndSet(false) || updateLength) {\n         try {\n           dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n               lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!isClosed()) {\n           lastException.set(new IOException(\"IOException flush: \" + e));\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n      synchronized (this) {\n        // flush checksum buffer, but keep checksum buffer intact if we do not\n        // need to end the current block\n        int numKept \u003d flushBuffer(!endBlock, true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"DFSClient flush(): \"\n              + \" bytesCurBlock\u003d\" + bytesCurBlock\n              + \" lastFlushOffset\u003d\" + lastFlushOffset\n              + \" createNewBlock\u003d\" + endBlock);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet if we do not end the block right now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, false);\n          }\n        } else {\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0 \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet if we do not end the block right now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, false);\n          } else if (currentPacket !\u003d null) {\n            // just discard the current packet since it is already been sent.\n            currentPacket.releaseBuffer(byteArrayManager);\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.setSyncBlock(isSync);\n          waitAndQueueCurrentPacket();          \n        }\n        if (endBlock \u0026\u0026 bytesCurBlock \u003e 0) {\n          // Need to end the current block, thus send an empty packet to\n          // indicate this is the end of the block and reset bytesCurBlock\n          currentPacket \u003d createPacket(0, 0, bytesCurBlock, currentSeqno++, true);\n          currentPacket.setSyncBlock(shouldSyncBlock || isSync);\n          waitAndQueueCurrentPacket();\n          bytesCurBlock \u003d 0;\n          lastFlushOffset \u003d 0;\n        } else {\n          // Restore state of stream. Record the last flush offset\n          // of the last full chunk that was flushed.\n          bytesCurBlock -\u003d numKept;\n        }\n\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || persistBlocks.get()) {\n        synchronized (this) {\n          if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n            lastBlockLength \u003d streamer.block.getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (persistBlocks.getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n              lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!isClosed()) {\n          lastException.set(new IOException(\"IOException flush: \" + e));\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7423. various typos and message formatting fixes in nfs daemon and doc. (Charles Lamb via yliu)\n",
      "commitDate": "28/01/15 12:56 PM",
      "commitName": "f37849188b05a6251584de1aed5e66d5dfa7da4f",
      "commitAuthor": "yliu",
      "commitDateOld": "27/01/15 12:58 PM",
      "commitNameOld": "2848db814a98b83e7546f65a2751e56fb5b2dbe0",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 1.0,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,119 +1,119 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n       synchronized (this) {\n         // flush checksum buffer, but keep checksum buffer intact if we do not\n         // need to end the current block\n         int numKept \u003d flushBuffer(!endBlock, true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n-          DFSClient.LOG.debug(\"DFSClient flush():\"\n+          DFSClient.LOG.debug(\"DFSClient flush(): \"\n               + \" bytesCurBlock\u003d\" + bytesCurBlock\n               + \" lastFlushOffset\u003d\" + lastFlushOffset\n               + \" createNewBlock\u003d\" + endBlock);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet if we do not end the block right now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++);\n           }\n         } else {\n           if (isSync \u0026\u0026 bytesCurBlock \u003e 0 \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet if we do not end the block right now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++);\n           } else if (currentPacket !\u003d null) {\n             // just discard the current packet since it is already been sent.\n             currentPacket.releaseBuffer(byteArrayManager);\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.syncBlock \u003d isSync;\n           waitAndQueueCurrentPacket();          \n         }\n         if (endBlock \u0026\u0026 bytesCurBlock \u003e 0) {\n           // Need to end the current block, thus send an empty packet to\n           // indicate this is the end of the block and reset bytesCurBlock\n           currentPacket \u003d createPacket(0, 0, bytesCurBlock, currentSeqno++);\n           currentPacket.lastPacketInBlock \u003d true;\n           currentPacket.syncBlock \u003d shouldSyncBlock || isSync;\n           waitAndQueueCurrentPacket();\n           bytesCurBlock \u003d 0;\n           lastFlushOffset \u003d 0;\n         } else {\n           // Restore state of stream. Record the last flush offset\n           // of the last full chunk that was flushed.\n           bytesCurBlock -\u003d numKept;\n         }\n \n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n \n       // update the block length first time irrespective of flag\n       if (updateLength || persistBlocks.get()) {\n         synchronized (this) {\n           if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n             lastBlockLength \u003d streamer.block.getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is required, then persist block locations on\n       // namenode.\n       if (persistBlocks.getAndSet(false) || updateLength) {\n         try {\n           dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n               lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!isClosed()) {\n-          lastException.set(new IOException(\"IOException flush:\" + e));\n+          lastException.set(new IOException(\"IOException flush: \" + e));\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n      synchronized (this) {\n        // flush checksum buffer, but keep checksum buffer intact if we do not\n        // need to end the current block\n        int numKept \u003d flushBuffer(!endBlock, true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"DFSClient flush(): \"\n              + \" bytesCurBlock\u003d\" + bytesCurBlock\n              + \" lastFlushOffset\u003d\" + lastFlushOffset\n              + \" createNewBlock\u003d\" + endBlock);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet if we do not end the block right now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++);\n          }\n        } else {\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0 \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet if we do not end the block right now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++);\n          } else if (currentPacket !\u003d null) {\n            // just discard the current packet since it is already been sent.\n            currentPacket.releaseBuffer(byteArrayManager);\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.syncBlock \u003d isSync;\n          waitAndQueueCurrentPacket();          \n        }\n        if (endBlock \u0026\u0026 bytesCurBlock \u003e 0) {\n          // Need to end the current block, thus send an empty packet to\n          // indicate this is the end of the block and reset bytesCurBlock\n          currentPacket \u003d createPacket(0, 0, bytesCurBlock, currentSeqno++);\n          currentPacket.lastPacketInBlock \u003d true;\n          currentPacket.syncBlock \u003d shouldSyncBlock || isSync;\n          waitAndQueueCurrentPacket();\n          bytesCurBlock \u003d 0;\n          lastFlushOffset \u003d 0;\n        } else {\n          // Restore state of stream. Record the last flush offset\n          // of the last full chunk that was flushed.\n          bytesCurBlock -\u003d numKept;\n        }\n\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || persistBlocks.get()) {\n        synchronized (this) {\n          if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n            lastBlockLength \u003d streamer.block.getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (persistBlocks.getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n              lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!isClosed()) {\n          lastException.set(new IOException(\"IOException flush: \" + e));\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "2848db814a98b83e7546f65a2751e56fb5b2dbe0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3689. Add support for variable length block. Contributed by Jing Zhao.\n",
      "commitDate": "27/01/15 12:58 PM",
      "commitName": "2848db814a98b83e7546f65a2751e56fb5b2dbe0",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "11/12/14 12:36 PM",
      "commitNameOld": "b9f6d0c956f0278c8b9b83e05b523a442a730ebb",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 47.02,
      "commitsBetweenForRepo": 264,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,119 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n+      boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n       synchronized (this) {\n-        // flush checksum buffer, but keep checksum buffer intact\n-        int numKept \u003d flushBuffer(true, true);\n+        // flush checksum buffer, but keep checksum buffer intact if we do not\n+        // need to end the current block\n+        int numKept \u003d flushBuffer(!endBlock, true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n-          DFSClient.LOG.debug(\n-            \"DFSClient flush() :\" +\n-            \" bytesCurBlock \" + bytesCurBlock +\n-            \" lastFlushOffset \" + lastFlushOffset);\n+          DFSClient.LOG.debug(\"DFSClient flush():\"\n+              + \" bytesCurBlock\u003d\" + bytesCurBlock\n+              + \" lastFlushOffset\u003d\" + lastFlushOffset\n+              + \" createNewBlock\u003d\" + endBlock);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n-          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n+          if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // but sync was requested.\n-            // Send an empty packet\n+            // Send an empty packet if we do not end the block right now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++);\n           }\n         } else {\n-          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n+          if (isSync \u0026\u0026 bytesCurBlock \u003e 0 \u0026\u0026 !endBlock) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n-            // So send an empty sync packet.\n+            // So send an empty sync packet if we do not end the block right now\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++);\n           } else if (currentPacket !\u003d null) {\n             // just discard the current packet since it is already been sent.\n             currentPacket.releaseBuffer(byteArrayManager);\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.syncBlock \u003d isSync;\n           waitAndQueueCurrentPacket();          \n         }\n-        // Restore state of stream. Record the last flush offset \n-        // of the last full chunk that was flushed.\n-        //\n-        bytesCurBlock -\u003d numKept;\n+        if (endBlock \u0026\u0026 bytesCurBlock \u003e 0) {\n+          // Need to end the current block, thus send an empty packet to\n+          // indicate this is the end of the block and reset bytesCurBlock\n+          currentPacket \u003d createPacket(0, 0, bytesCurBlock, currentSeqno++);\n+          currentPacket.lastPacketInBlock \u003d true;\n+          currentPacket.syncBlock \u003d shouldSyncBlock || isSync;\n+          waitAndQueueCurrentPacket();\n+          bytesCurBlock \u003d 0;\n+          lastFlushOffset \u003d 0;\n+        } else {\n+          // Restore state of stream. Record the last flush offset\n+          // of the last full chunk that was flushed.\n+          bytesCurBlock -\u003d numKept;\n+        }\n+\n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n \n       // update the block length first time irrespective of flag\n       if (updateLength || persistBlocks.get()) {\n         synchronized (this) {\n           if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n             lastBlockLength \u003d streamer.block.getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is required, then persist block locations on\n       // namenode.\n       if (persistBlocks.getAndSet(false) || updateLength) {\n         try {\n-          dfsClient.namenode.fsync(src, fileId,\n-              dfsClient.clientName, lastBlockLength);\n+          dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n+              lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!isClosed()) {\n           lastException.set(new IOException(\"IOException flush:\" + e));\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      boolean endBlock \u003d syncFlags.contains(SyncFlag.END_BLOCK);\n      synchronized (this) {\n        // flush checksum buffer, but keep checksum buffer intact if we do not\n        // need to end the current block\n        int numKept \u003d flushBuffer(!endBlock, true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\"DFSClient flush():\"\n              + \" bytesCurBlock\u003d\" + bytesCurBlock\n              + \" lastFlushOffset\u003d\" + lastFlushOffset\n              + \" createNewBlock\u003d\" + endBlock);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet if we do not end the block right now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++);\n          }\n        } else {\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0 \u0026\u0026 !endBlock) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet if we do not end the block right now\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++);\n          } else if (currentPacket !\u003d null) {\n            // just discard the current packet since it is already been sent.\n            currentPacket.releaseBuffer(byteArrayManager);\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.syncBlock \u003d isSync;\n          waitAndQueueCurrentPacket();          \n        }\n        if (endBlock \u0026\u0026 bytesCurBlock \u003e 0) {\n          // Need to end the current block, thus send an empty packet to\n          // indicate this is the end of the block and reset bytesCurBlock\n          currentPacket \u003d createPacket(0, 0, bytesCurBlock, currentSeqno++);\n          currentPacket.lastPacketInBlock \u003d true;\n          currentPacket.syncBlock \u003d shouldSyncBlock || isSync;\n          waitAndQueueCurrentPacket();\n          bytesCurBlock \u003d 0;\n          lastFlushOffset \u003d 0;\n        } else {\n          // Restore state of stream. Record the last flush offset\n          // of the last full chunk that was flushed.\n          bytesCurBlock -\u003d numKept;\n        }\n\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || persistBlocks.get()) {\n        synchronized (this) {\n          if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n            lastBlockLength \u003d streamer.block.getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (persistBlocks.getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,\n              lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!isClosed()) {\n          lastException.set(new IOException(\"IOException flush:\" + e));\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "394ba94c5d2801fbc5d95c7872eeeede28eed1eb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7358. Clients may get stuck waiting when using ByteArrayManager.\n",
      "commitDate": "13/11/14 12:28 PM",
      "commitName": "394ba94c5d2801fbc5d95c7872eeeede28eed1eb",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "05/11/14 10:51 AM",
      "commitNameOld": "56257fab1d5a7f66bebd9149c7df0436c0a57adb",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 8.07,
      "commitsBetweenForRepo": 93,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,105 +1,106 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       synchronized (this) {\n         // flush checksum buffer, but keep checksum buffer intact\n         int numKept \u003d flushBuffer(true, true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\n             \"DFSClient flush() :\" +\n             \" bytesCurBlock \" + bytesCurBlock +\n             \" lastFlushOffset \" + lastFlushOffset);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++);\n           }\n         } else {\n           if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet.\n             currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++);\n-          } else {\n+          } else if (currentPacket !\u003d null) {\n             // just discard the current packet since it is already been sent.\n+            currentPacket.releaseBuffer(byteArrayManager);\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.syncBlock \u003d isSync;\n           waitAndQueueCurrentPacket();          \n         }\n         // Restore state of stream. Record the last flush offset \n         // of the last full chunk that was flushed.\n         //\n         bytesCurBlock -\u003d numKept;\n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n \n       // update the block length first time irrespective of flag\n       if (updateLength || persistBlocks.get()) {\n         synchronized (this) {\n           if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n             lastBlockLength \u003d streamer.block.getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is required, then persist block locations on\n       // namenode.\n       if (persistBlocks.getAndSet(false) || updateLength) {\n         try {\n           dfsClient.namenode.fsync(src, fileId,\n               dfsClient.clientName, lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n-        if (!closed) {\n+        if (!isClosed()) {\n           lastException.set(new IOException(\"IOException flush:\" + e));\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      synchronized (this) {\n        // flush checksum buffer, but keep checksum buffer intact\n        int numKept \u003d flushBuffer(true, true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() :\" +\n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++);\n          }\n        } else {\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet.\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++);\n          } else if (currentPacket !\u003d null) {\n            // just discard the current packet since it is already been sent.\n            currentPacket.releaseBuffer(byteArrayManager);\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.syncBlock \u003d isSync;\n          waitAndQueueCurrentPacket();          \n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock -\u003d numKept;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || persistBlocks.get()) {\n        synchronized (this) {\n          if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n            lastBlockLength \u003d streamer.block.getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (persistBlocks.getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, fileId,\n              dfsClient.clientName, lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!isClosed()) {\n          lastException.set(new IOException(\"IOException flush:\" + e));\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "36ccf097a95eae0761de7b657752e4808a86c094": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7276. Limit the number of byte arrays used by DFSOutputStream and provide a mechanism for recycling arrays.\n",
      "commitDate": "01/11/14 11:22 AM",
      "commitName": "36ccf097a95eae0761de7b657752e4808a86c094",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "27/10/14 9:38 AM",
      "commitNameOld": "463aec11718e47d4aabb86a7a539cb973460aae6",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 5.07,
      "commitsBetweenForRepo": 75,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,105 +1,105 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       synchronized (this) {\n         // flush checksum buffer, but keep checksum buffer intact\n         int numKept \u003d flushBuffer(true, true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\n             \"DFSClient flush() :\" +\n             \" bytesCurBlock \" + bytesCurBlock +\n             \" lastFlushOffset \" + lastFlushOffset);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet\n-            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n-                bytesCurBlock, currentSeqno++, getChecksumSize());\n+            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n+                bytesCurBlock, currentSeqno++);\n           }\n         } else {\n           if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet.\n-            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n-                bytesCurBlock, currentSeqno++, getChecksumSize());\n+            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n+                bytesCurBlock, currentSeqno++);\n           } else {\n             // just discard the current packet since it is already been sent.\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.syncBlock \u003d isSync;\n           waitAndQueueCurrentPacket();          \n         }\n         // Restore state of stream. Record the last flush offset \n         // of the last full chunk that was flushed.\n         //\n         bytesCurBlock -\u003d numKept;\n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n \n       // update the block length first time irrespective of flag\n       if (updateLength || persistBlocks.get()) {\n         synchronized (this) {\n           if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n             lastBlockLength \u003d streamer.block.getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is required, then persist block locations on\n       // namenode.\n       if (persistBlocks.getAndSet(false) || updateLength) {\n         try {\n           dfsClient.namenode.fsync(src, fileId,\n               dfsClient.clientName, lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!closed) {\n           lastException.set(new IOException(\"IOException flush:\" + e));\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      synchronized (this) {\n        // flush checksum buffer, but keep checksum buffer intact\n        int numKept \u003d flushBuffer(true, true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() :\" +\n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++);\n          }\n        } else {\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet.\n            currentPacket \u003d createPacket(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++);\n          } else {\n            // just discard the current packet since it is already been sent.\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.syncBlock \u003d isSync;\n          waitAndQueueCurrentPacket();          \n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock -\u003d numKept;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || persistBlocks.get()) {\n        synchronized (this) {\n          if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n            lastBlockLength \u003d streamer.block.getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (persistBlocks.getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, fileId,\n              dfsClient.clientName, lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!closed) {\n          lastException.set(new IOException(\"IOException flush:\" + e));\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "463aec11718e47d4aabb86a7a539cb973460aae6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6934. Move checksum computation off the hot path when writing to RAM disk. Contributed by Chris Nauroth.\n",
      "commitDate": "27/10/14 9:38 AM",
      "commitName": "463aec11718e47d4aabb86a7a539cb973460aae6",
      "commitAuthor": "cnauroth",
      "commitDateOld": "17/10/14 6:30 PM",
      "commitNameOld": "2e140523d3ccb27809cde4a55e95f7e0006c028f",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 9.63,
      "commitsBetweenForRepo": 71,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,105 +1,105 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       synchronized (this) {\n         // flush checksum buffer, but keep checksum buffer intact\n         int numKept \u003d flushBuffer(true, true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\n             \"DFSClient flush() :\" +\n             \" bytesCurBlock \" + bytesCurBlock +\n             \" lastFlushOffset \" + lastFlushOffset);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n-                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n+                bytesCurBlock, currentSeqno++, getChecksumSize());\n           }\n         } else {\n           if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet.\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n-                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n+                bytesCurBlock, currentSeqno++, getChecksumSize());\n           } else {\n             // just discard the current packet since it is already been sent.\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.syncBlock \u003d isSync;\n           waitAndQueueCurrentPacket();          \n         }\n         // Restore state of stream. Record the last flush offset \n         // of the last full chunk that was flushed.\n         //\n         bytesCurBlock -\u003d numKept;\n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n \n       // update the block length first time irrespective of flag\n       if (updateLength || persistBlocks.get()) {\n         synchronized (this) {\n           if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n             lastBlockLength \u003d streamer.block.getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is required, then persist block locations on\n       // namenode.\n       if (persistBlocks.getAndSet(false) || updateLength) {\n         try {\n           dfsClient.namenode.fsync(src, fileId,\n               dfsClient.clientName, lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!closed) {\n           lastException.set(new IOException(\"IOException flush:\" + e));\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      synchronized (this) {\n        // flush checksum buffer, but keep checksum buffer intact\n        int numKept \u003d flushBuffer(true, true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() :\" +\n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, getChecksumSize());\n          }\n        } else {\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet.\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, getChecksumSize());\n          } else {\n            // just discard the current packet since it is already been sent.\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.syncBlock \u003d isSync;\n          waitAndQueueCurrentPacket();          \n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock -\u003d numKept;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || persistBlocks.get()) {\n        synchronized (this) {\n          if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n            lastBlockLength \u003d streamer.block.getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (persistBlocks.getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, fileId,\n              dfsClient.clientName, lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!closed) {\n          lastException.set(new IOException(\"IOException flush:\" + e));\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "ab638e77b811d9592470f7d342cd11a66efbbf0d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6865. Byte array native checksumming on client side. Contributed by James Thomas.\n",
      "commitDate": "28/08/14 4:44 PM",
      "commitName": "ab638e77b811d9592470f7d342cd11a66efbbf0d",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "20/08/14 6:13 PM",
      "commitNameOld": "6824abc19e12ed142d9f32b8706ef73d97edd1cc",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 7.94,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,120 +1,105 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       synchronized (this) {\n-        /* Record current blockOffset. This might be changed inside\n-         * flushBuffer() where a partial checksum chunk might be flushed.\n-         * After the flush, reset the bytesCurBlock back to its previous value,\n-         * any partial checksum chunk will be sent now and in next packet.\n-         */\n-        long saveOffset \u003d bytesCurBlock;\n-        Packet oldCurrentPacket \u003d currentPacket;\n         // flush checksum buffer, but keep checksum buffer intact\n-        flushBuffer(true);\n+        int numKept \u003d flushBuffer(true, true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\n-            \"DFSClient flush() : saveOffset \" + saveOffset +  \n+            \"DFSClient flush() :\" +\n             \" bytesCurBlock \" + bytesCurBlock +\n             \" lastFlushOffset \" + lastFlushOffset);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n           }\n         } else {\n-          // We already flushed up to this offset.\n-          // This means that we haven\u0027t written anything since the last flush\n-          // (or the beginning of the file). Hence, we should not have any\n-          // packet queued prior to this call, since the last flush set\n-          // currentPacket \u003d null.\n-          assert oldCurrentPacket \u003d\u003d null :\n-            \"Empty flush should not occur with a currentPacket\";\n-\n           if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet.\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n           } else {\n             // just discard the current packet since it is already been sent.\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.syncBlock \u003d isSync;\n           waitAndQueueCurrentPacket();          \n         }\n         // Restore state of stream. Record the last flush offset \n         // of the last full chunk that was flushed.\n         //\n-        bytesCurBlock \u003d saveOffset;\n+        bytesCurBlock -\u003d numKept;\n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n \n       // update the block length first time irrespective of flag\n       if (updateLength || persistBlocks.get()) {\n         synchronized (this) {\n           if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n             lastBlockLength \u003d streamer.block.getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is required, then persist block locations on\n       // namenode.\n       if (persistBlocks.getAndSet(false) || updateLength) {\n         try {\n           dfsClient.namenode.fsync(src, fileId,\n               dfsClient.clientName, lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!closed) {\n           lastException.set(new IOException(\"IOException flush:\" + e));\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      synchronized (this) {\n        // flush checksum buffer, but keep checksum buffer intact\n        int numKept \u003d flushBuffer(true, true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() :\" +\n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n          }\n        } else {\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet.\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n          } else {\n            // just discard the current packet since it is already been sent.\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.syncBlock \u003d isSync;\n          waitAndQueueCurrentPacket();          \n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock -\u003d numKept;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || persistBlocks.get()) {\n        synchronized (this) {\n          if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n            lastBlockLength \u003d streamer.block.getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (persistBlocks.getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, fileId,\n              dfsClient.clientName, lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!closed) {\n          lastException.set(new IOException(\"IOException flush:\" + e));\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6294. Use INode IDs to avoid conflicts when a file open for write is renamed (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1593634 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/05/14 3:36 PM",
      "commitName": "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "25/03/14 9:11 PM",
      "commitNameOld": "1fbb04e367d7c330e6052207f9f11911f4f5f368",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 44.77,
      "commitsBetweenForRepo": 257,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,119 +1,120 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       synchronized (this) {\n         /* Record current blockOffset. This might be changed inside\n          * flushBuffer() where a partial checksum chunk might be flushed.\n          * After the flush, reset the bytesCurBlock back to its previous value,\n          * any partial checksum chunk will be sent now and in next packet.\n          */\n         long saveOffset \u003d bytesCurBlock;\n         Packet oldCurrentPacket \u003d currentPacket;\n         // flush checksum buffer, but keep checksum buffer intact\n         flushBuffer(true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\n             \"DFSClient flush() : saveOffset \" + saveOffset +  \n             \" bytesCurBlock \" + bytesCurBlock +\n             \" lastFlushOffset \" + lastFlushOffset);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n           }\n         } else {\n           // We already flushed up to this offset.\n           // This means that we haven\u0027t written anything since the last flush\n           // (or the beginning of the file). Hence, we should not have any\n           // packet queued prior to this call, since the last flush set\n           // currentPacket \u003d null.\n           assert oldCurrentPacket \u003d\u003d null :\n             \"Empty flush should not occur with a currentPacket\";\n \n           if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet.\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n           } else {\n             // just discard the current packet since it is already been sent.\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.syncBlock \u003d isSync;\n           waitAndQueueCurrentPacket();          \n         }\n         // Restore state of stream. Record the last flush offset \n         // of the last full chunk that was flushed.\n         //\n         bytesCurBlock \u003d saveOffset;\n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n \n       // update the block length first time irrespective of flag\n       if (updateLength || persistBlocks.get()) {\n         synchronized (this) {\n           if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n             lastBlockLength \u003d streamer.block.getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is required, then persist block locations on\n       // namenode.\n       if (persistBlocks.getAndSet(false) || updateLength) {\n         try {\n-          dfsClient.namenode.fsync(src, dfsClient.clientName, lastBlockLength);\n+          dfsClient.namenode.fsync(src, fileId,\n+              dfsClient.clientName, lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!closed) {\n           lastException.set(new IOException(\"IOException flush:\" + e));\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      synchronized (this) {\n        /* Record current blockOffset. This might be changed inside\n         * flushBuffer() where a partial checksum chunk might be flushed.\n         * After the flush, reset the bytesCurBlock back to its previous value,\n         * any partial checksum chunk will be sent now and in next packet.\n         */\n        long saveOffset \u003d bytesCurBlock;\n        Packet oldCurrentPacket \u003d currentPacket;\n        // flush checksum buffer, but keep checksum buffer intact\n        flushBuffer(true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() : saveOffset \" + saveOffset +  \n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n          }\n        } else {\n          // We already flushed up to this offset.\n          // This means that we haven\u0027t written anything since the last flush\n          // (or the beginning of the file). Hence, we should not have any\n          // packet queued prior to this call, since the last flush set\n          // currentPacket \u003d null.\n          assert oldCurrentPacket \u003d\u003d null :\n            \"Empty flush should not occur with a currentPacket\";\n\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet.\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n          } else {\n            // just discard the current packet since it is already been sent.\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.syncBlock \u003d isSync;\n          waitAndQueueCurrentPacket();          \n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock \u003d saveOffset;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || persistBlocks.get()) {\n        synchronized (this) {\n          if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n            lastBlockLength \u003d streamer.block.getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (persistBlocks.getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, fileId,\n              dfsClient.clientName, lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!closed) {\n          lastException.set(new IOException(\"IOException flush:\" + e));\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "f26d2adbf98890cfe350c17241f5049b89a11e3c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4516. Client crash after block allocation and NN switch before lease recovery for the same file can cause readers to fail forever. Contributed by Vinay.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1543829 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/11/13 6:43 AM",
      "commitName": "f26d2adbf98890cfe350c17241f5049b89a11e3c",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "14/11/13 12:11 PM",
      "commitNameOld": "ceea91c9cd8b2a18be13217894ccf1c17198de18",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 5.77,
      "commitsBetweenForRepo": 35,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,118 +1,119 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       synchronized (this) {\n         /* Record current blockOffset. This might be changed inside\n          * flushBuffer() where a partial checksum chunk might be flushed.\n          * After the flush, reset the bytesCurBlock back to its previous value,\n          * any partial checksum chunk will be sent now and in next packet.\n          */\n         long saveOffset \u003d bytesCurBlock;\n         Packet oldCurrentPacket \u003d currentPacket;\n         // flush checksum buffer, but keep checksum buffer intact\n         flushBuffer(true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\n             \"DFSClient flush() : saveOffset \" + saveOffset +  \n             \" bytesCurBlock \" + bytesCurBlock +\n             \" lastFlushOffset \" + lastFlushOffset);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n           }\n         } else {\n           // We already flushed up to this offset.\n           // This means that we haven\u0027t written anything since the last flush\n           // (or the beginning of the file). Hence, we should not have any\n           // packet queued prior to this call, since the last flush set\n           // currentPacket \u003d null.\n           assert oldCurrentPacket \u003d\u003d null :\n             \"Empty flush should not occur with a currentPacket\";\n \n           if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet.\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n           } else {\n             // just discard the current packet since it is already been sent.\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.syncBlock \u003d isSync;\n           waitAndQueueCurrentPacket();          \n         }\n         // Restore state of stream. Record the last flush offset \n         // of the last full chunk that was flushed.\n         //\n         bytesCurBlock \u003d saveOffset;\n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n-      \n-      if (updateLength) {\n+\n+      // update the block length first time irrespective of flag\n+      if (updateLength || persistBlocks.get()) {\n         synchronized (this) {\n           if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n             lastBlockLength \u003d streamer.block.getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is required, then persist block locations on\n       // namenode.\n       if (persistBlocks.getAndSet(false) || updateLength) {\n         try {\n           dfsClient.namenode.fsync(src, dfsClient.clientName, lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!closed) {\n           lastException.set(new IOException(\"IOException flush:\" + e));\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      synchronized (this) {\n        /* Record current blockOffset. This might be changed inside\n         * flushBuffer() where a partial checksum chunk might be flushed.\n         * After the flush, reset the bytesCurBlock back to its previous value,\n         * any partial checksum chunk will be sent now and in next packet.\n         */\n        long saveOffset \u003d bytesCurBlock;\n        Packet oldCurrentPacket \u003d currentPacket;\n        // flush checksum buffer, but keep checksum buffer intact\n        flushBuffer(true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() : saveOffset \" + saveOffset +  \n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n          }\n        } else {\n          // We already flushed up to this offset.\n          // This means that we haven\u0027t written anything since the last flush\n          // (or the beginning of the file). Hence, we should not have any\n          // packet queued prior to this call, since the last flush set\n          // currentPacket \u003d null.\n          assert oldCurrentPacket \u003d\u003d null :\n            \"Empty flush should not occur with a currentPacket\";\n\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet.\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n          } else {\n            // just discard the current packet since it is already been sent.\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.syncBlock \u003d isSync;\n          waitAndQueueCurrentPacket();          \n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock \u003d saveOffset;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n\n      // update the block length first time irrespective of flag\n      if (updateLength || persistBlocks.get()) {\n        synchronized (this) {\n          if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n            lastBlockLength \u003d streamer.block.getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is required, then persist block locations on\n      // namenode.\n      if (persistBlocks.getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, dfsClient.clientName, lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!closed) {\n          lastException.set(new IOException(\"IOException flush:\" + e));\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "f2f5cdb5554d294a29ebf465101c5607fd56e244": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5335. Hive query failed with possible race in dfs output stream. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1531152 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/10/13 4:58 PM",
      "commitName": "f2f5cdb5554d294a29ebf465101c5607fd56e244",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "22/07/13 11:15 AM",
      "commitNameOld": "c1314eb2a382bd9ce045a2fcc4a9e5c1fc368a24",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 80.24,
      "commitsBetweenForRepo": 499,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,118 +1,118 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n     checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       synchronized (this) {\n         /* Record current blockOffset. This might be changed inside\n          * flushBuffer() where a partial checksum chunk might be flushed.\n          * After the flush, reset the bytesCurBlock back to its previous value,\n          * any partial checksum chunk will be sent now and in next packet.\n          */\n         long saveOffset \u003d bytesCurBlock;\n         Packet oldCurrentPacket \u003d currentPacket;\n         // flush checksum buffer, but keep checksum buffer intact\n         flushBuffer(true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\n             \"DFSClient flush() : saveOffset \" + saveOffset +  \n             \" bytesCurBlock \" + bytesCurBlock +\n             \" lastFlushOffset \" + lastFlushOffset);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n           }\n         } else {\n           // We already flushed up to this offset.\n           // This means that we haven\u0027t written anything since the last flush\n           // (or the beginning of the file). Hence, we should not have any\n           // packet queued prior to this call, since the last flush set\n           // currentPacket \u003d null.\n           assert oldCurrentPacket \u003d\u003d null :\n             \"Empty flush should not occur with a currentPacket\";\n \n           if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet.\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n           } else {\n             // just discard the current packet since it is already been sent.\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.syncBlock \u003d isSync;\n           waitAndQueueCurrentPacket();          \n         }\n         // Restore state of stream. Record the last flush offset \n         // of the last full chunk that was flushed.\n         //\n         bytesCurBlock \u003d saveOffset;\n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n       \n       if (updateLength) {\n         synchronized (this) {\n           if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n             lastBlockLength \u003d streamer.block.getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is requried, then persist block locations on\n       // namenode.\n       if (persistBlocks.getAndSet(false) || updateLength) {\n         try {\n           dfsClient.namenode.fsync(src, dfsClient.clientName, lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!closed) {\n-          lastException \u003d new IOException(\"IOException flush:\" + e);\n+          lastException.set(new IOException(\"IOException flush:\" + e));\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      synchronized (this) {\n        /* Record current blockOffset. This might be changed inside\n         * flushBuffer() where a partial checksum chunk might be flushed.\n         * After the flush, reset the bytesCurBlock back to its previous value,\n         * any partial checksum chunk will be sent now and in next packet.\n         */\n        long saveOffset \u003d bytesCurBlock;\n        Packet oldCurrentPacket \u003d currentPacket;\n        // flush checksum buffer, but keep checksum buffer intact\n        flushBuffer(true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() : saveOffset \" + saveOffset +  \n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n          }\n        } else {\n          // We already flushed up to this offset.\n          // This means that we haven\u0027t written anything since the last flush\n          // (or the beginning of the file). Hence, we should not have any\n          // packet queued prior to this call, since the last flush set\n          // currentPacket \u003d null.\n          assert oldCurrentPacket \u003d\u003d null :\n            \"Empty flush should not occur with a currentPacket\";\n\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet.\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n          } else {\n            // just discard the current packet since it is already been sent.\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.syncBlock \u003d isSync;\n          waitAndQueueCurrentPacket();          \n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock \u003d saveOffset;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n      \n      if (updateLength) {\n        synchronized (this) {\n          if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n            lastBlockLength \u003d streamer.block.getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is requried, then persist block locations on\n      // namenode.\n      if (persistBlocks.getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, dfsClient.clientName, lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!closed) {\n          lastException.set(new IOException(\"IOException flush:\" + e));\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "1c309f763be3dd2e3d7d1616d2c960ff80cf9b03": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4906. HDFS Output streams should not accept writes after being closed. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1494303 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/06/13 2:05 PM",
      "commitName": "1c309f763be3dd2e3d7d1616d2c960ff80cf9b03",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "23/05/13 2:35 PM",
      "commitNameOld": "2ad7397c49844b5c12e122779c8760f51fa3a998",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 25.98,
      "commitsBetweenForRepo": 200,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,118 +1,118 @@\n   private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n       throws IOException {\n     dfsClient.checkOpen();\n-    isClosed();\n+    checkClosed();\n     try {\n       long toWaitFor;\n       long lastBlockLength \u003d -1L;\n       boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       synchronized (this) {\n         /* Record current blockOffset. This might be changed inside\n          * flushBuffer() where a partial checksum chunk might be flushed.\n          * After the flush, reset the bytesCurBlock back to its previous value,\n          * any partial checksum chunk will be sent now and in next packet.\n          */\n         long saveOffset \u003d bytesCurBlock;\n         Packet oldCurrentPacket \u003d currentPacket;\n         // flush checksum buffer, but keep checksum buffer intact\n         flushBuffer(true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\n             \"DFSClient flush() : saveOffset \" + saveOffset +  \n             \" bytesCurBlock \" + bytesCurBlock +\n             \" lastFlushOffset \" + lastFlushOffset);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n           }\n         } else {\n           // We already flushed up to this offset.\n           // This means that we haven\u0027t written anything since the last flush\n           // (or the beginning of the file). Hence, we should not have any\n           // packet queued prior to this call, since the last flush set\n           // currentPacket \u003d null.\n           assert oldCurrentPacket \u003d\u003d null :\n             \"Empty flush should not occur with a currentPacket\";\n \n           if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet.\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n           } else {\n             // just discard the current packet since it is already been sent.\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.syncBlock \u003d isSync;\n           waitAndQueueCurrentPacket();          \n         }\n         // Restore state of stream. Record the last flush offset \n         // of the last full chunk that was flushed.\n         //\n         bytesCurBlock \u003d saveOffset;\n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n       \n       if (updateLength) {\n         synchronized (this) {\n           if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n             lastBlockLength \u003d streamer.block.getNumBytes();\n           }\n         }\n       }\n       // If 1) any new blocks were allocated since the last flush, or 2) to\n       // update length in NN is requried, then persist block locations on\n       // namenode.\n       if (persistBlocks.getAndSet(false) || updateLength) {\n         try {\n           dfsClient.namenode.fsync(src, dfsClient.clientName, lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n-          isClosed();\n+          checkClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!closed) {\n           lastException \u003d new IOException(\"IOException flush:\" + e);\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    checkClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      synchronized (this) {\n        /* Record current blockOffset. This might be changed inside\n         * flushBuffer() where a partial checksum chunk might be flushed.\n         * After the flush, reset the bytesCurBlock back to its previous value,\n         * any partial checksum chunk will be sent now and in next packet.\n         */\n        long saveOffset \u003d bytesCurBlock;\n        Packet oldCurrentPacket \u003d currentPacket;\n        // flush checksum buffer, but keep checksum buffer intact\n        flushBuffer(true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() : saveOffset \" + saveOffset +  \n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n          }\n        } else {\n          // We already flushed up to this offset.\n          // This means that we haven\u0027t written anything since the last flush\n          // (or the beginning of the file). Hence, we should not have any\n          // packet queued prior to this call, since the last flush set\n          // currentPacket \u003d null.\n          assert oldCurrentPacket \u003d\u003d null :\n            \"Empty flush should not occur with a currentPacket\";\n\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet.\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n          } else {\n            // just discard the current packet since it is already been sent.\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.syncBlock \u003d isSync;\n          waitAndQueueCurrentPacket();          \n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock \u003d saveOffset;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n      \n      if (updateLength) {\n        synchronized (this) {\n          if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n            lastBlockLength \u003d streamer.block.getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is requried, then persist block locations on\n      // namenode.\n      if (persistBlocks.getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, dfsClient.clientName, lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          checkClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!closed) {\n          lastException \u003d new IOException(\"IOException flush:\" + e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "571da54179f731eb8421ffc681169799588f76bc": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-4213. Add an API to hsync for updating the last block length at the namenode. Contributed by Jing Zhao\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1415799 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/11/12 11:24 AM",
      "commitName": "571da54179f731eb8421ffc681169799588f76bc",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4213. Add an API to hsync for updating the last block length at the namenode. Contributed by Jing Zhao\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1415799 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/11/12 11:24 AM",
          "commitName": "571da54179f731eb8421ffc681169799588f76bc",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "28/10/12 4:10 PM",
          "commitNameOld": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 32.84,
          "commitsBetweenForRepo": 162,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,108 +1,118 @@\n-  private void flushOrSync(boolean isSync) throws IOException {\n+  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n+      throws IOException {\n     dfsClient.checkOpen();\n     isClosed();\n     try {\n       long toWaitFor;\n+      long lastBlockLength \u003d -1L;\n+      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       synchronized (this) {\n         /* Record current blockOffset. This might be changed inside\n          * flushBuffer() where a partial checksum chunk might be flushed.\n          * After the flush, reset the bytesCurBlock back to its previous value,\n          * any partial checksum chunk will be sent now and in next packet.\n          */\n         long saveOffset \u003d bytesCurBlock;\n         Packet oldCurrentPacket \u003d currentPacket;\n         // flush checksum buffer, but keep checksum buffer intact\n         flushBuffer(true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\n             \"DFSClient flush() : saveOffset \" + saveOffset +  \n             \" bytesCurBlock \" + bytesCurBlock +\n             \" lastFlushOffset \" + lastFlushOffset);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n           }\n         } else {\n           // We already flushed up to this offset.\n           // This means that we haven\u0027t written anything since the last flush\n           // (or the beginning of the file). Hence, we should not have any\n           // packet queued prior to this call, since the last flush set\n           // currentPacket \u003d null.\n           assert oldCurrentPacket \u003d\u003d null :\n             \"Empty flush should not occur with a currentPacket\";\n \n           if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet.\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n           } else {\n             // just discard the current packet since it is already been sent.\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.syncBlock \u003d isSync;\n           waitAndQueueCurrentPacket();          \n         }\n         // Restore state of stream. Record the last flush offset \n         // of the last full chunk that was flushed.\n         //\n         bytesCurBlock \u003d saveOffset;\n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n-\n-      // If any new blocks were allocated since the last flush, \n-      // then persist block locations on namenode. \n-      //\n-      if (persistBlocks.getAndSet(false)) {\n+      \n+      if (updateLength) {\n+        synchronized (this) {\n+          if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n+            lastBlockLength \u003d streamer.block.getNumBytes();\n+          }\n+        }\n+      }\n+      // If 1) any new blocks were allocated since the last flush, or 2) to\n+      // update length in NN is requried, then persist block locations on\n+      // namenode.\n+      if (persistBlocks.getAndSet(false) || updateLength) {\n         try {\n-          dfsClient.namenode.fsync(src, dfsClient.clientName);\n+          dfsClient.namenode.fsync(src, dfsClient.clientName, lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           isClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!closed) {\n           lastException \u003d new IOException(\"IOException flush:\" + e);\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    isClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      synchronized (this) {\n        /* Record current blockOffset. This might be changed inside\n         * flushBuffer() where a partial checksum chunk might be flushed.\n         * After the flush, reset the bytesCurBlock back to its previous value,\n         * any partial checksum chunk will be sent now and in next packet.\n         */\n        long saveOffset \u003d bytesCurBlock;\n        Packet oldCurrentPacket \u003d currentPacket;\n        // flush checksum buffer, but keep checksum buffer intact\n        flushBuffer(true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() : saveOffset \" + saveOffset +  \n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n          }\n        } else {\n          // We already flushed up to this offset.\n          // This means that we haven\u0027t written anything since the last flush\n          // (or the beginning of the file). Hence, we should not have any\n          // packet queued prior to this call, since the last flush set\n          // currentPacket \u003d null.\n          assert oldCurrentPacket \u003d\u003d null :\n            \"Empty flush should not occur with a currentPacket\";\n\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet.\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n          } else {\n            // just discard the current packet since it is already been sent.\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.syncBlock \u003d isSync;\n          waitAndQueueCurrentPacket();          \n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock \u003d saveOffset;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n      \n      if (updateLength) {\n        synchronized (this) {\n          if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n            lastBlockLength \u003d streamer.block.getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is requried, then persist block locations on\n      // namenode.\n      if (persistBlocks.getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, dfsClient.clientName, lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          isClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!closed) {\n          lastException \u003d new IOException(\"IOException flush:\" + e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
          "extendedDetails": {
            "oldValue": "[isSync-boolean]",
            "newValue": "[isSync-boolean, syncFlags-EnumSet\u003cSyncFlag\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4213. Add an API to hsync for updating the last block length at the namenode. Contributed by Jing Zhao\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1415799 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/11/12 11:24 AM",
          "commitName": "571da54179f731eb8421ffc681169799588f76bc",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "28/10/12 4:10 PM",
          "commitNameOld": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 32.84,
          "commitsBetweenForRepo": 162,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,108 +1,118 @@\n-  private void flushOrSync(boolean isSync) throws IOException {\n+  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n+      throws IOException {\n     dfsClient.checkOpen();\n     isClosed();\n     try {\n       long toWaitFor;\n+      long lastBlockLength \u003d -1L;\n+      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n       synchronized (this) {\n         /* Record current blockOffset. This might be changed inside\n          * flushBuffer() where a partial checksum chunk might be flushed.\n          * After the flush, reset the bytesCurBlock back to its previous value,\n          * any partial checksum chunk will be sent now and in next packet.\n          */\n         long saveOffset \u003d bytesCurBlock;\n         Packet oldCurrentPacket \u003d currentPacket;\n         // flush checksum buffer, but keep checksum buffer intact\n         flushBuffer(true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\n             \"DFSClient flush() : saveOffset \" + saveOffset +  \n             \" bytesCurBlock \" + bytesCurBlock +\n             \" lastFlushOffset \" + lastFlushOffset);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n           }\n         } else {\n           // We already flushed up to this offset.\n           // This means that we haven\u0027t written anything since the last flush\n           // (or the beginning of the file). Hence, we should not have any\n           // packet queued prior to this call, since the last flush set\n           // currentPacket \u003d null.\n           assert oldCurrentPacket \u003d\u003d null :\n             \"Empty flush should not occur with a currentPacket\";\n \n           if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet.\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                 bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n           } else {\n             // just discard the current packet since it is already been sent.\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.syncBlock \u003d isSync;\n           waitAndQueueCurrentPacket();          \n         }\n         // Restore state of stream. Record the last flush offset \n         // of the last full chunk that was flushed.\n         //\n         bytesCurBlock \u003d saveOffset;\n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n-\n-      // If any new blocks were allocated since the last flush, \n-      // then persist block locations on namenode. \n-      //\n-      if (persistBlocks.getAndSet(false)) {\n+      \n+      if (updateLength) {\n+        synchronized (this) {\n+          if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n+            lastBlockLength \u003d streamer.block.getNumBytes();\n+          }\n+        }\n+      }\n+      // If 1) any new blocks were allocated since the last flush, or 2) to\n+      // update length in NN is requried, then persist block locations on\n+      // namenode.\n+      if (persistBlocks.getAndSet(false) || updateLength) {\n         try {\n-          dfsClient.namenode.fsync(src, dfsClient.clientName);\n+          dfsClient.namenode.fsync(src, dfsClient.clientName, lastBlockLength);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           isClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!closed) {\n           lastException \u003d new IOException(\"IOException flush:\" + e);\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void flushOrSync(boolean isSync, EnumSet\u003cSyncFlag\u003e syncFlags)\n      throws IOException {\n    dfsClient.checkOpen();\n    isClosed();\n    try {\n      long toWaitFor;\n      long lastBlockLength \u003d -1L;\n      boolean updateLength \u003d syncFlags.contains(SyncFlag.UPDATE_LENGTH);\n      synchronized (this) {\n        /* Record current blockOffset. This might be changed inside\n         * flushBuffer() where a partial checksum chunk might be flushed.\n         * After the flush, reset the bytesCurBlock back to its previous value,\n         * any partial checksum chunk will be sent now and in next packet.\n         */\n        long saveOffset \u003d bytesCurBlock;\n        Packet oldCurrentPacket \u003d currentPacket;\n        // flush checksum buffer, but keep checksum buffer intact\n        flushBuffer(true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() : saveOffset \" + saveOffset +  \n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n          }\n        } else {\n          // We already flushed up to this offset.\n          // This means that we haven\u0027t written anything since the last flush\n          // (or the beginning of the file). Hence, we should not have any\n          // packet queued prior to this call, since the last flush set\n          // currentPacket \u003d null.\n          assert oldCurrentPacket \u003d\u003d null :\n            \"Empty flush should not occur with a currentPacket\";\n\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet.\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n          } else {\n            // just discard the current packet since it is already been sent.\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.syncBlock \u003d isSync;\n          waitAndQueueCurrentPacket();          \n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock \u003d saveOffset;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n      \n      if (updateLength) {\n        synchronized (this) {\n          if (streamer !\u003d null \u0026\u0026 streamer.block !\u003d null) {\n            lastBlockLength \u003d streamer.block.getNumBytes();\n          }\n        }\n      }\n      // If 1) any new blocks were allocated since the last flush, or 2) to\n      // update length in NN is requried, then persist block locations on\n      // namenode.\n      if (persistBlocks.getAndSet(false) || updateLength) {\n        try {\n          dfsClient.namenode.fsync(src, dfsClient.clientName, lastBlockLength);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          isClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!closed) {\n          lastException \u003d new IOException(\"IOException flush:\" + e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "735046ebecd9e803398be56fbf79dbde5226b4c1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3851. DFSOutputStream class code cleanup. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1377372 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/08/12 9:00 PM",
      "commitName": "735046ebecd9e803398be56fbf79dbde5226b4c1",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "14/08/12 1:59 PM",
      "commitNameOld": "f98d8eb291be364102b5c3011ce72e8f43eab389",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 11.29,
      "commitsBetweenForRepo": 87,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,108 +1,108 @@\n   private void flushOrSync(boolean isSync) throws IOException {\n     dfsClient.checkOpen();\n     isClosed();\n     try {\n       long toWaitFor;\n       synchronized (this) {\n         /* Record current blockOffset. This might be changed inside\n          * flushBuffer() where a partial checksum chunk might be flushed.\n          * After the flush, reset the bytesCurBlock back to its previous value,\n          * any partial checksum chunk will be sent now and in next packet.\n          */\n         long saveOffset \u003d bytesCurBlock;\n         Packet oldCurrentPacket \u003d currentPacket;\n         // flush checksum buffer, but keep checksum buffer intact\n         flushBuffer(true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\n             \"DFSClient flush() : saveOffset \" + saveOffset +  \n             \" bytesCurBlock \" + bytesCurBlock +\n             \" lastFlushOffset \" + lastFlushOffset);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n           if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n             // Nothing to send right now,\n             // but sync was requested.\n             // Send an empty packet\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n-                bytesCurBlock);\n+                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n           }\n         } else {\n           // We already flushed up to this offset.\n           // This means that we haven\u0027t written anything since the last flush\n           // (or the beginning of the file). Hence, we should not have any\n           // packet queued prior to this call, since the last flush set\n           // currentPacket \u003d null.\n           assert oldCurrentPacket \u003d\u003d null :\n             \"Empty flush should not occur with a currentPacket\";\n \n           if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n             // Nothing to send right now,\n             // and the block was partially written,\n             // and sync was requested.\n             // So send an empty sync packet.\n             currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n-                bytesCurBlock);\n+                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n           } else {\n             // just discard the current packet since it is already been sent.\n             currentPacket \u003d null;\n           }\n         }\n         if (currentPacket !\u003d null) {\n           currentPacket.syncBlock \u003d isSync;\n           waitAndQueueCurrentPacket();          \n         }\n         // Restore state of stream. Record the last flush offset \n         // of the last full chunk that was flushed.\n         //\n         bytesCurBlock \u003d saveOffset;\n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n \n       // If any new blocks were allocated since the last flush, \n       // then persist block locations on namenode. \n       //\n       if (persistBlocks.getAndSet(false)) {\n         try {\n           dfsClient.namenode.fsync(src, dfsClient.clientName);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           isClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!closed) {\n           lastException \u003d new IOException(\"IOException flush:\" + e);\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void flushOrSync(boolean isSync) throws IOException {\n    dfsClient.checkOpen();\n    isClosed();\n    try {\n      long toWaitFor;\n      synchronized (this) {\n        /* Record current blockOffset. This might be changed inside\n         * flushBuffer() where a partial checksum chunk might be flushed.\n         * After the flush, reset the bytesCurBlock back to its previous value,\n         * any partial checksum chunk will be sent now and in next packet.\n         */\n        long saveOffset \u003d bytesCurBlock;\n        Packet oldCurrentPacket \u003d currentPacket;\n        // flush checksum buffer, but keep checksum buffer intact\n        flushBuffer(true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() : saveOffset \" + saveOffset +  \n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n          }\n        } else {\n          // We already flushed up to this offset.\n          // This means that we haven\u0027t written anything since the last flush\n          // (or the beginning of the file). Hence, we should not have any\n          // packet queued prior to this call, since the last flush set\n          // currentPacket \u003d null.\n          assert oldCurrentPacket \u003d\u003d null :\n            \"Empty flush should not occur with a currentPacket\";\n\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet.\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock, currentSeqno++, this.checksum.getChecksumSize());\n          } else {\n            // just discard the current packet since it is already been sent.\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.syncBlock \u003d isSync;\n          waitAndQueueCurrentPacket();          \n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock \u003d saveOffset;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n\n      // If any new blocks were allocated since the last flush, \n      // then persist block locations on namenode. \n      //\n      if (persistBlocks.getAndSet(false)) {\n        try {\n          dfsClient.namenode.fsync(src, dfsClient.clientName);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          isClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!closed) {\n          lastException \u003d new IOException(\"IOException flush:\" + e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "83cf475050dba27e72b4e399491638c670621175": {
      "type": "Ymultichange(Yrename,Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-744. Support hsync in HDFS. Contributed by Lars Hofhans\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1344419 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/05/12 12:10 PM",
      "commitName": "83cf475050dba27e72b4e399491638c670621175",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-744. Support hsync in HDFS. Contributed by Lars Hofhans\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1344419 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/05/12 12:10 PM",
          "commitName": "83cf475050dba27e72b4e399491638c670621175",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "29/05/12 12:37 PM",
          "commitNameOld": "47a29c63291f1f9f09b89ce6f3305c0a2ef27b3f",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.98,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,89 +1,108 @@\n-  public void hflush() throws IOException {\n+  private void flushOrSync(boolean isSync) throws IOException {\n     dfsClient.checkOpen();\n     isClosed();\n     try {\n       long toWaitFor;\n       synchronized (this) {\n         /* Record current blockOffset. This might be changed inside\n          * flushBuffer() where a partial checksum chunk might be flushed.\n          * After the flush, reset the bytesCurBlock back to its previous value,\n          * any partial checksum chunk will be sent now and in next packet.\n          */\n         long saveOffset \u003d bytesCurBlock;\n         Packet oldCurrentPacket \u003d currentPacket;\n         // flush checksum buffer, but keep checksum buffer intact\n         flushBuffer(true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\n             \"DFSClient flush() : saveOffset \" + saveOffset +  \n             \" bytesCurBlock \" + bytesCurBlock +\n             \" lastFlushOffset \" + lastFlushOffset);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n-          waitAndQueueCurrentPacket();\n+          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n+            // Nothing to send right now,\n+            // but sync was requested.\n+            // Send an empty packet\n+            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n+                bytesCurBlock);\n+          }\n         } else {\n           // We already flushed up to this offset.\n           // This means that we haven\u0027t written anything since the last flush\n           // (or the beginning of the file). Hence, we should not have any\n           // packet queued prior to this call, since the last flush set\n           // currentPacket \u003d null.\n           assert oldCurrentPacket \u003d\u003d null :\n             \"Empty flush should not occur with a currentPacket\";\n \n-          // just discard the current packet since it is already been sent.\n-          currentPacket \u003d null;\n+          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n+            // Nothing to send right now,\n+            // and the block was partially written,\n+            // and sync was requested.\n+            // So send an empty sync packet.\n+            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n+                bytesCurBlock);\n+          } else {\n+            // just discard the current packet since it is already been sent.\n+            currentPacket \u003d null;\n+          }\n+        }\n+        if (currentPacket !\u003d null) {\n+          currentPacket.syncBlock \u003d isSync;\n+          waitAndQueueCurrentPacket();          \n         }\n         // Restore state of stream. Record the last flush offset \n         // of the last full chunk that was flushed.\n         //\n         bytesCurBlock \u003d saveOffset;\n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n \n       // If any new blocks were allocated since the last flush, \n       // then persist block locations on namenode. \n       //\n       if (persistBlocks.getAndSet(false)) {\n         try {\n           dfsClient.namenode.fsync(src, dfsClient.clientName);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           isClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!closed) {\n           lastException \u003d new IOException(\"IOException flush:\" + e);\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void flushOrSync(boolean isSync) throws IOException {\n    dfsClient.checkOpen();\n    isClosed();\n    try {\n      long toWaitFor;\n      synchronized (this) {\n        /* Record current blockOffset. This might be changed inside\n         * flushBuffer() where a partial checksum chunk might be flushed.\n         * After the flush, reset the bytesCurBlock back to its previous value,\n         * any partial checksum chunk will be sent now and in next packet.\n         */\n        long saveOffset \u003d bytesCurBlock;\n        Packet oldCurrentPacket \u003d currentPacket;\n        // flush checksum buffer, but keep checksum buffer intact\n        flushBuffer(true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() : saveOffset \" + saveOffset +  \n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock);\n          }\n        } else {\n          // We already flushed up to this offset.\n          // This means that we haven\u0027t written anything since the last flush\n          // (or the beginning of the file). Hence, we should not have any\n          // packet queued prior to this call, since the last flush set\n          // currentPacket \u003d null.\n          assert oldCurrentPacket \u003d\u003d null :\n            \"Empty flush should not occur with a currentPacket\";\n\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet.\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock);\n          } else {\n            // just discard the current packet since it is already been sent.\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.syncBlock \u003d isSync;\n          waitAndQueueCurrentPacket();          \n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock \u003d saveOffset;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n\n      // If any new blocks were allocated since the last flush, \n      // then persist block locations on namenode. \n      //\n      if (persistBlocks.getAndSet(false)) {\n        try {\n          dfsClient.namenode.fsync(src, dfsClient.clientName);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          isClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!closed) {\n          lastException \u003d new IOException(\"IOException flush:\" + e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
          "extendedDetails": {
            "oldValue": "hflush",
            "newValue": "flushOrSync"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-744. Support hsync in HDFS. Contributed by Lars Hofhans\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1344419 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/05/12 12:10 PM",
          "commitName": "83cf475050dba27e72b4e399491638c670621175",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "29/05/12 12:37 PM",
          "commitNameOld": "47a29c63291f1f9f09b89ce6f3305c0a2ef27b3f",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.98,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,89 +1,108 @@\n-  public void hflush() throws IOException {\n+  private void flushOrSync(boolean isSync) throws IOException {\n     dfsClient.checkOpen();\n     isClosed();\n     try {\n       long toWaitFor;\n       synchronized (this) {\n         /* Record current blockOffset. This might be changed inside\n          * flushBuffer() where a partial checksum chunk might be flushed.\n          * After the flush, reset the bytesCurBlock back to its previous value,\n          * any partial checksum chunk will be sent now and in next packet.\n          */\n         long saveOffset \u003d bytesCurBlock;\n         Packet oldCurrentPacket \u003d currentPacket;\n         // flush checksum buffer, but keep checksum buffer intact\n         flushBuffer(true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\n             \"DFSClient flush() : saveOffset \" + saveOffset +  \n             \" bytesCurBlock \" + bytesCurBlock +\n             \" lastFlushOffset \" + lastFlushOffset);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n-          waitAndQueueCurrentPacket();\n+          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n+            // Nothing to send right now,\n+            // but sync was requested.\n+            // Send an empty packet\n+            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n+                bytesCurBlock);\n+          }\n         } else {\n           // We already flushed up to this offset.\n           // This means that we haven\u0027t written anything since the last flush\n           // (or the beginning of the file). Hence, we should not have any\n           // packet queued prior to this call, since the last flush set\n           // currentPacket \u003d null.\n           assert oldCurrentPacket \u003d\u003d null :\n             \"Empty flush should not occur with a currentPacket\";\n \n-          // just discard the current packet since it is already been sent.\n-          currentPacket \u003d null;\n+          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n+            // Nothing to send right now,\n+            // and the block was partially written,\n+            // and sync was requested.\n+            // So send an empty sync packet.\n+            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n+                bytesCurBlock);\n+          } else {\n+            // just discard the current packet since it is already been sent.\n+            currentPacket \u003d null;\n+          }\n+        }\n+        if (currentPacket !\u003d null) {\n+          currentPacket.syncBlock \u003d isSync;\n+          waitAndQueueCurrentPacket();          \n         }\n         // Restore state of stream. Record the last flush offset \n         // of the last full chunk that was flushed.\n         //\n         bytesCurBlock \u003d saveOffset;\n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n \n       // If any new blocks were allocated since the last flush, \n       // then persist block locations on namenode. \n       //\n       if (persistBlocks.getAndSet(false)) {\n         try {\n           dfsClient.namenode.fsync(src, dfsClient.clientName);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           isClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!closed) {\n           lastException \u003d new IOException(\"IOException flush:\" + e);\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void flushOrSync(boolean isSync) throws IOException {\n    dfsClient.checkOpen();\n    isClosed();\n    try {\n      long toWaitFor;\n      synchronized (this) {\n        /* Record current blockOffset. This might be changed inside\n         * flushBuffer() where a partial checksum chunk might be flushed.\n         * After the flush, reset the bytesCurBlock back to its previous value,\n         * any partial checksum chunk will be sent now and in next packet.\n         */\n        long saveOffset \u003d bytesCurBlock;\n        Packet oldCurrentPacket \u003d currentPacket;\n        // flush checksum buffer, but keep checksum buffer intact\n        flushBuffer(true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() : saveOffset \" + saveOffset +  \n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock);\n          }\n        } else {\n          // We already flushed up to this offset.\n          // This means that we haven\u0027t written anything since the last flush\n          // (or the beginning of the file). Hence, we should not have any\n          // packet queued prior to this call, since the last flush set\n          // currentPacket \u003d null.\n          assert oldCurrentPacket \u003d\u003d null :\n            \"Empty flush should not occur with a currentPacket\";\n\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet.\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock);\n          } else {\n            // just discard the current packet since it is already been sent.\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.syncBlock \u003d isSync;\n          waitAndQueueCurrentPacket();          \n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock \u003d saveOffset;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n\n      // If any new blocks were allocated since the last flush, \n      // then persist block locations on namenode. \n      //\n      if (persistBlocks.getAndSet(false)) {\n        try {\n          dfsClient.namenode.fsync(src, dfsClient.clientName);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          isClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!closed) {\n          lastException \u003d new IOException(\"IOException flush:\" + e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[isSync-boolean]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-744. Support hsync in HDFS. Contributed by Lars Hofhans\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1344419 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/05/12 12:10 PM",
          "commitName": "83cf475050dba27e72b4e399491638c670621175",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "29/05/12 12:37 PM",
          "commitNameOld": "47a29c63291f1f9f09b89ce6f3305c0a2ef27b3f",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.98,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,89 +1,108 @@\n-  public void hflush() throws IOException {\n+  private void flushOrSync(boolean isSync) throws IOException {\n     dfsClient.checkOpen();\n     isClosed();\n     try {\n       long toWaitFor;\n       synchronized (this) {\n         /* Record current blockOffset. This might be changed inside\n          * flushBuffer() where a partial checksum chunk might be flushed.\n          * After the flush, reset the bytesCurBlock back to its previous value,\n          * any partial checksum chunk will be sent now and in next packet.\n          */\n         long saveOffset \u003d bytesCurBlock;\n         Packet oldCurrentPacket \u003d currentPacket;\n         // flush checksum buffer, but keep checksum buffer intact\n         flushBuffer(true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\n             \"DFSClient flush() : saveOffset \" + saveOffset +  \n             \" bytesCurBlock \" + bytesCurBlock +\n             \" lastFlushOffset \" + lastFlushOffset);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n-          waitAndQueueCurrentPacket();\n+          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n+            // Nothing to send right now,\n+            // but sync was requested.\n+            // Send an empty packet\n+            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n+                bytesCurBlock);\n+          }\n         } else {\n           // We already flushed up to this offset.\n           // This means that we haven\u0027t written anything since the last flush\n           // (or the beginning of the file). Hence, we should not have any\n           // packet queued prior to this call, since the last flush set\n           // currentPacket \u003d null.\n           assert oldCurrentPacket \u003d\u003d null :\n             \"Empty flush should not occur with a currentPacket\";\n \n-          // just discard the current packet since it is already been sent.\n-          currentPacket \u003d null;\n+          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n+            // Nothing to send right now,\n+            // and the block was partially written,\n+            // and sync was requested.\n+            // So send an empty sync packet.\n+            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n+                bytesCurBlock);\n+          } else {\n+            // just discard the current packet since it is already been sent.\n+            currentPacket \u003d null;\n+          }\n+        }\n+        if (currentPacket !\u003d null) {\n+          currentPacket.syncBlock \u003d isSync;\n+          waitAndQueueCurrentPacket();          \n         }\n         // Restore state of stream. Record the last flush offset \n         // of the last full chunk that was flushed.\n         //\n         bytesCurBlock \u003d saveOffset;\n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n \n       // If any new blocks were allocated since the last flush, \n       // then persist block locations on namenode. \n       //\n       if (persistBlocks.getAndSet(false)) {\n         try {\n           dfsClient.namenode.fsync(src, dfsClient.clientName);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           isClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!closed) {\n           lastException \u003d new IOException(\"IOException flush:\" + e);\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void flushOrSync(boolean isSync) throws IOException {\n    dfsClient.checkOpen();\n    isClosed();\n    try {\n      long toWaitFor;\n      synchronized (this) {\n        /* Record current blockOffset. This might be changed inside\n         * flushBuffer() where a partial checksum chunk might be flushed.\n         * After the flush, reset the bytesCurBlock back to its previous value,\n         * any partial checksum chunk will be sent now and in next packet.\n         */\n        long saveOffset \u003d bytesCurBlock;\n        Packet oldCurrentPacket \u003d currentPacket;\n        // flush checksum buffer, but keep checksum buffer intact\n        flushBuffer(true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() : saveOffset \" + saveOffset +  \n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock);\n          }\n        } else {\n          // We already flushed up to this offset.\n          // This means that we haven\u0027t written anything since the last flush\n          // (or the beginning of the file). Hence, we should not have any\n          // packet queued prior to this call, since the last flush set\n          // currentPacket \u003d null.\n          assert oldCurrentPacket \u003d\u003d null :\n            \"Empty flush should not occur with a currentPacket\";\n\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet.\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock);\n          } else {\n            // just discard the current packet since it is already been sent.\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.syncBlock \u003d isSync;\n          waitAndQueueCurrentPacket();          \n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock \u003d saveOffset;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n\n      // If any new blocks were allocated since the last flush, \n      // then persist block locations on namenode. \n      //\n      if (persistBlocks.getAndSet(false)) {\n        try {\n          dfsClient.namenode.fsync(src, dfsClient.clientName);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          isClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!closed) {\n          lastException \u003d new IOException(\"IOException flush:\" + e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-744. Support hsync in HDFS. Contributed by Lars Hofhans\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1344419 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/05/12 12:10 PM",
          "commitName": "83cf475050dba27e72b4e399491638c670621175",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "29/05/12 12:37 PM",
          "commitNameOld": "47a29c63291f1f9f09b89ce6f3305c0a2ef27b3f",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.98,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,89 +1,108 @@\n-  public void hflush() throws IOException {\n+  private void flushOrSync(boolean isSync) throws IOException {\n     dfsClient.checkOpen();\n     isClosed();\n     try {\n       long toWaitFor;\n       synchronized (this) {\n         /* Record current blockOffset. This might be changed inside\n          * flushBuffer() where a partial checksum chunk might be flushed.\n          * After the flush, reset the bytesCurBlock back to its previous value,\n          * any partial checksum chunk will be sent now and in next packet.\n          */\n         long saveOffset \u003d bytesCurBlock;\n         Packet oldCurrentPacket \u003d currentPacket;\n         // flush checksum buffer, but keep checksum buffer intact\n         flushBuffer(true);\n         // bytesCurBlock potentially incremented if there was buffered data\n \n         if (DFSClient.LOG.isDebugEnabled()) {\n           DFSClient.LOG.debug(\n             \"DFSClient flush() : saveOffset \" + saveOffset +  \n             \" bytesCurBlock \" + bytesCurBlock +\n             \" lastFlushOffset \" + lastFlushOffset);\n         }\n         // Flush only if we haven\u0027t already flushed till this offset.\n         if (lastFlushOffset !\u003d bytesCurBlock) {\n           assert bytesCurBlock \u003e lastFlushOffset;\n           // record the valid offset of this flush\n           lastFlushOffset \u003d bytesCurBlock;\n-          waitAndQueueCurrentPacket();\n+          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n+            // Nothing to send right now,\n+            // but sync was requested.\n+            // Send an empty packet\n+            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n+                bytesCurBlock);\n+          }\n         } else {\n           // We already flushed up to this offset.\n           // This means that we haven\u0027t written anything since the last flush\n           // (or the beginning of the file). Hence, we should not have any\n           // packet queued prior to this call, since the last flush set\n           // currentPacket \u003d null.\n           assert oldCurrentPacket \u003d\u003d null :\n             \"Empty flush should not occur with a currentPacket\";\n \n-          // just discard the current packet since it is already been sent.\n-          currentPacket \u003d null;\n+          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n+            // Nothing to send right now,\n+            // and the block was partially written,\n+            // and sync was requested.\n+            // So send an empty sync packet.\n+            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n+                bytesCurBlock);\n+          } else {\n+            // just discard the current packet since it is already been sent.\n+            currentPacket \u003d null;\n+          }\n+        }\n+        if (currentPacket !\u003d null) {\n+          currentPacket.syncBlock \u003d isSync;\n+          waitAndQueueCurrentPacket();          \n         }\n         // Restore state of stream. Record the last flush offset \n         // of the last full chunk that was flushed.\n         //\n         bytesCurBlock \u003d saveOffset;\n         toWaitFor \u003d lastQueuedSeqno;\n       } // end synchronized\n \n       waitForAckedSeqno(toWaitFor);\n \n       // If any new blocks were allocated since the last flush, \n       // then persist block locations on namenode. \n       //\n       if (persistBlocks.getAndSet(false)) {\n         try {\n           dfsClient.namenode.fsync(src, dfsClient.clientName);\n         } catch (IOException ioe) {\n           DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n           // If we got an error here, it might be because some other thread called\n           // close before our hflush completed. In that case, we should throw an\n           // exception that the stream is closed.\n           isClosed();\n           // If we aren\u0027t closed but failed to sync, we should expose that to the\n           // caller.\n           throw ioe;\n         }\n       }\n \n       synchronized(this) {\n         if (streamer !\u003d null) {\n           streamer.setHflush();\n         }\n       }\n     } catch (InterruptedIOException interrupt) {\n       // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n       // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n       // but instead just propagate the error\n       throw interrupt;\n     } catch (IOException e) {\n       DFSClient.LOG.warn(\"Error while syncing\", e);\n       synchronized (this) {\n         if (!closed) {\n           lastException \u003d new IOException(\"IOException flush:\" + e);\n           closeThreads(true);\n         }\n       }\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void flushOrSync(boolean isSync) throws IOException {\n    dfsClient.checkOpen();\n    isClosed();\n    try {\n      long toWaitFor;\n      synchronized (this) {\n        /* Record current blockOffset. This might be changed inside\n         * flushBuffer() where a partial checksum chunk might be flushed.\n         * After the flush, reset the bytesCurBlock back to its previous value,\n         * any partial checksum chunk will be sent now and in next packet.\n         */\n        long saveOffset \u003d bytesCurBlock;\n        Packet oldCurrentPacket \u003d currentPacket;\n        // flush checksum buffer, but keep checksum buffer intact\n        flushBuffer(true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() : saveOffset \" + saveOffset +  \n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          if (isSync \u0026\u0026 currentPacket \u003d\u003d null) {\n            // Nothing to send right now,\n            // but sync was requested.\n            // Send an empty packet\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock);\n          }\n        } else {\n          // We already flushed up to this offset.\n          // This means that we haven\u0027t written anything since the last flush\n          // (or the beginning of the file). Hence, we should not have any\n          // packet queued prior to this call, since the last flush set\n          // currentPacket \u003d null.\n          assert oldCurrentPacket \u003d\u003d null :\n            \"Empty flush should not occur with a currentPacket\";\n\n          if (isSync \u0026\u0026 bytesCurBlock \u003e 0) {\n            // Nothing to send right now,\n            // and the block was partially written,\n            // and sync was requested.\n            // So send an empty sync packet.\n            currentPacket \u003d new Packet(packetSize, chunksPerPacket,\n                bytesCurBlock);\n          } else {\n            // just discard the current packet since it is already been sent.\n            currentPacket \u003d null;\n          }\n        }\n        if (currentPacket !\u003d null) {\n          currentPacket.syncBlock \u003d isSync;\n          waitAndQueueCurrentPacket();          \n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock \u003d saveOffset;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n\n      // If any new blocks were allocated since the last flush, \n      // then persist block locations on namenode. \n      //\n      if (persistBlocks.getAndSet(false)) {\n        try {\n          dfsClient.namenode.fsync(src, dfsClient.clientName);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          isClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!closed) {\n          lastException \u003d new IOException(\"IOException flush:\" + e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void hflush() throws IOException {\n    dfsClient.checkOpen();\n    isClosed();\n    try {\n      long toWaitFor;\n      synchronized (this) {\n        /* Record current blockOffset. This might be changed inside\n         * flushBuffer() where a partial checksum chunk might be flushed.\n         * After the flush, reset the bytesCurBlock back to its previous value,\n         * any partial checksum chunk will be sent now and in next packet.\n         */\n        long saveOffset \u003d bytesCurBlock;\n        Packet oldCurrentPacket \u003d currentPacket;\n        // flush checksum buffer, but keep checksum buffer intact\n        flushBuffer(true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() : saveOffset \" + saveOffset +  \n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          waitAndQueueCurrentPacket();\n        } else {\n          // We already flushed up to this offset.\n          // This means that we haven\u0027t written anything since the last flush\n          // (or the beginning of the file). Hence, we should not have any\n          // packet queued prior to this call, since the last flush set\n          // currentPacket \u003d null.\n          assert oldCurrentPacket \u003d\u003d null :\n            \"Empty flush should not occur with a currentPacket\";\n\n          // just discard the current packet since it is already been sent.\n          currentPacket \u003d null;\n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock \u003d saveOffset;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n\n      // If any new blocks were allocated since the last flush, \n      // then persist block locations on namenode. \n      //\n      if (persistBlocks.getAndSet(false)) {\n        try {\n          dfsClient.namenode.fsync(src, dfsClient.clientName);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          isClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!closed) {\n          lastException \u003d new IOException(\"IOException flush:\" + e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void hflush() throws IOException {\n    dfsClient.checkOpen();\n    isClosed();\n    try {\n      long toWaitFor;\n      synchronized (this) {\n        /* Record current blockOffset. This might be changed inside\n         * flushBuffer() where a partial checksum chunk might be flushed.\n         * After the flush, reset the bytesCurBlock back to its previous value,\n         * any partial checksum chunk will be sent now and in next packet.\n         */\n        long saveOffset \u003d bytesCurBlock;\n        Packet oldCurrentPacket \u003d currentPacket;\n        // flush checksum buffer, but keep checksum buffer intact\n        flushBuffer(true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() : saveOffset \" + saveOffset +  \n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          waitAndQueueCurrentPacket();\n        } else {\n          // We already flushed up to this offset.\n          // This means that we haven\u0027t written anything since the last flush\n          // (or the beginning of the file). Hence, we should not have any\n          // packet queued prior to this call, since the last flush set\n          // currentPacket \u003d null.\n          assert oldCurrentPacket \u003d\u003d null :\n            \"Empty flush should not occur with a currentPacket\";\n\n          // just discard the current packet since it is already been sent.\n          currentPacket \u003d null;\n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock \u003d saveOffset;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n\n      // If any new blocks were allocated since the last flush, \n      // then persist block locations on namenode. \n      //\n      if (persistBlocks.getAndSet(false)) {\n        try {\n          dfsClient.namenode.fsync(src, dfsClient.clientName);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          isClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!closed) {\n          lastException \u003d new IOException(\"IOException flush:\" + e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,89 @@\n+  public void hflush() throws IOException {\n+    dfsClient.checkOpen();\n+    isClosed();\n+    try {\n+      long toWaitFor;\n+      synchronized (this) {\n+        /* Record current blockOffset. This might be changed inside\n+         * flushBuffer() where a partial checksum chunk might be flushed.\n+         * After the flush, reset the bytesCurBlock back to its previous value,\n+         * any partial checksum chunk will be sent now and in next packet.\n+         */\n+        long saveOffset \u003d bytesCurBlock;\n+        Packet oldCurrentPacket \u003d currentPacket;\n+        // flush checksum buffer, but keep checksum buffer intact\n+        flushBuffer(true);\n+        // bytesCurBlock potentially incremented if there was buffered data\n+\n+        if (DFSClient.LOG.isDebugEnabled()) {\n+          DFSClient.LOG.debug(\n+            \"DFSClient flush() : saveOffset \" + saveOffset +  \n+            \" bytesCurBlock \" + bytesCurBlock +\n+            \" lastFlushOffset \" + lastFlushOffset);\n+        }\n+        // Flush only if we haven\u0027t already flushed till this offset.\n+        if (lastFlushOffset !\u003d bytesCurBlock) {\n+          assert bytesCurBlock \u003e lastFlushOffset;\n+          // record the valid offset of this flush\n+          lastFlushOffset \u003d bytesCurBlock;\n+          waitAndQueueCurrentPacket();\n+        } else {\n+          // We already flushed up to this offset.\n+          // This means that we haven\u0027t written anything since the last flush\n+          // (or the beginning of the file). Hence, we should not have any\n+          // packet queued prior to this call, since the last flush set\n+          // currentPacket \u003d null.\n+          assert oldCurrentPacket \u003d\u003d null :\n+            \"Empty flush should not occur with a currentPacket\";\n+\n+          // just discard the current packet since it is already been sent.\n+          currentPacket \u003d null;\n+        }\n+        // Restore state of stream. Record the last flush offset \n+        // of the last full chunk that was flushed.\n+        //\n+        bytesCurBlock \u003d saveOffset;\n+        toWaitFor \u003d lastQueuedSeqno;\n+      } // end synchronized\n+\n+      waitForAckedSeqno(toWaitFor);\n+\n+      // If any new blocks were allocated since the last flush, \n+      // then persist block locations on namenode. \n+      //\n+      if (persistBlocks.getAndSet(false)) {\n+        try {\n+          dfsClient.namenode.fsync(src, dfsClient.clientName);\n+        } catch (IOException ioe) {\n+          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n+          // If we got an error here, it might be because some other thread called\n+          // close before our hflush completed. In that case, we should throw an\n+          // exception that the stream is closed.\n+          isClosed();\n+          // If we aren\u0027t closed but failed to sync, we should expose that to the\n+          // caller.\n+          throw ioe;\n+        }\n+      }\n+\n+      synchronized(this) {\n+        if (streamer !\u003d null) {\n+          streamer.setHflush();\n+        }\n+      }\n+    } catch (InterruptedIOException interrupt) {\n+      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n+      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n+      // but instead just propagate the error\n+      throw interrupt;\n+    } catch (IOException e) {\n+      DFSClient.LOG.warn(\"Error while syncing\", e);\n+      synchronized (this) {\n+        if (!closed) {\n+          lastException \u003d new IOException(\"IOException flush:\" + e);\n+          closeThreads(true);\n+        }\n+      }\n+      throw e;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void hflush() throws IOException {\n    dfsClient.checkOpen();\n    isClosed();\n    try {\n      long toWaitFor;\n      synchronized (this) {\n        /* Record current blockOffset. This might be changed inside\n         * flushBuffer() where a partial checksum chunk might be flushed.\n         * After the flush, reset the bytesCurBlock back to its previous value,\n         * any partial checksum chunk will be sent now and in next packet.\n         */\n        long saveOffset \u003d bytesCurBlock;\n        Packet oldCurrentPacket \u003d currentPacket;\n        // flush checksum buffer, but keep checksum buffer intact\n        flushBuffer(true);\n        // bytesCurBlock potentially incremented if there was buffered data\n\n        if (DFSClient.LOG.isDebugEnabled()) {\n          DFSClient.LOG.debug(\n            \"DFSClient flush() : saveOffset \" + saveOffset +  \n            \" bytesCurBlock \" + bytesCurBlock +\n            \" lastFlushOffset \" + lastFlushOffset);\n        }\n        // Flush only if we haven\u0027t already flushed till this offset.\n        if (lastFlushOffset !\u003d bytesCurBlock) {\n          assert bytesCurBlock \u003e lastFlushOffset;\n          // record the valid offset of this flush\n          lastFlushOffset \u003d bytesCurBlock;\n          waitAndQueueCurrentPacket();\n        } else {\n          // We already flushed up to this offset.\n          // This means that we haven\u0027t written anything since the last flush\n          // (or the beginning of the file). Hence, we should not have any\n          // packet queued prior to this call, since the last flush set\n          // currentPacket \u003d null.\n          assert oldCurrentPacket \u003d\u003d null :\n            \"Empty flush should not occur with a currentPacket\";\n\n          // just discard the current packet since it is already been sent.\n          currentPacket \u003d null;\n        }\n        // Restore state of stream. Record the last flush offset \n        // of the last full chunk that was flushed.\n        //\n        bytesCurBlock \u003d saveOffset;\n        toWaitFor \u003d lastQueuedSeqno;\n      } // end synchronized\n\n      waitForAckedSeqno(toWaitFor);\n\n      // If any new blocks were allocated since the last flush, \n      // then persist block locations on namenode. \n      //\n      if (persistBlocks.getAndSet(false)) {\n        try {\n          dfsClient.namenode.fsync(src, dfsClient.clientName);\n        } catch (IOException ioe) {\n          DFSClient.LOG.warn(\"Unable to persist blocks in hflush for \" + src, ioe);\n          // If we got an error here, it might be because some other thread called\n          // close before our hflush completed. In that case, we should throw an\n          // exception that the stream is closed.\n          isClosed();\n          // If we aren\u0027t closed but failed to sync, we should expose that to the\n          // caller.\n          throw ioe;\n        }\n      }\n\n      synchronized(this) {\n        if (streamer !\u003d null) {\n          streamer.setHflush();\n        }\n      }\n    } catch (InterruptedIOException interrupt) {\n      // This kind of error doesn\u0027t mean that the stream itself is broken - just the\n      // flushing thread got interrupted. So, we shouldn\u0027t close down the writer,\n      // but instead just propagate the error\n      throw interrupt;\n    } catch (IOException e) {\n      DFSClient.LOG.warn(\"Error while syncing\", e);\n      synchronized (this) {\n        if (!closed) {\n          lastException \u003d new IOException(\"IOException flush:\" + e);\n          closeThreads(true);\n        }\n      }\n      throw e;\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/DFSOutputStream.java"
    }
  }
}