{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AMOptions.java",
  "functionName": "initFromParser",
  "functionId": "initFromParser___cliParser-CommandLine",
  "sourceFilePath": "hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-infra/src/main/java/org/apache/hadoop/tools/dynamometer/AMOptions.java",
  "functionStartLine": 276,
  "functionEndLine": 315,
  "numCommitsSeen": 2,
  "timeTaken": 464,
  "changeHistory": [
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91"
  ],
  "changeHistoryShort": {
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91": "Yintroduced"
  },
  "changeHistoryDetails": {
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-12345 Add Dynamometer to hadoop-tools, a tool for scale testing the HDFS NameNode with real metadata and workloads. Contributed by Erik Krogen.\n",
      "commitDate": "25/06/19 8:07 AM",
      "commitName": "ab0b180ddb5d0775a2452d5eeb7badd252aadb91",
      "commitAuthor": "Erik Krogen",
      "diff": "@@ -0,0 +1,40 @@\n+  static AMOptions initFromParser(CommandLine cliParser) {\n+    Map\u003cString, String\u003e originalShellEnv \u003d new HashMap\u003c\u003e();\n+    if (cliParser.hasOption(SHELL_ENV_ARG)) {\n+      for (String env : cliParser.getOptionValues(SHELL_ENV_ARG)) {\n+        String trimmed \u003d env.trim();\n+        int index \u003d trimmed.indexOf(\u0027\u003d\u0027);\n+        if (index \u003d\u003d -1) {\n+          originalShellEnv.put(trimmed, \"\");\n+          continue;\n+        }\n+        String key \u003d trimmed.substring(0, index);\n+        String val \u003d \"\";\n+        if (index \u003c (trimmed.length() - 1)) {\n+          val \u003d trimmed.substring(index + 1);\n+        }\n+        originalShellEnv.put(key, val);\n+      }\n+    }\n+    return new AMOptions(\n+        Integer.parseInt(cliParser.getOptionValue(DATANODE_MEMORY_MB_ARG,\n+            DATANODE_MEMORY_MB_DEFAULT)),\n+        Integer.parseInt(cliParser.getOptionValue(DATANODE_VCORES_ARG,\n+            DATANODE_VCORES_DEFAULT)),\n+        cliParser.getOptionValue(DATANODE_ARGS_ARG, \"\"),\n+        cliParser.getOptionValue(DATANODE_NODELABEL_ARG, \"\"),\n+        Integer.parseInt(cliParser.getOptionValue(DATANODES_PER_CLUSTER_ARG,\n+            DATANODES_PER_CLUSTER_DEFAULT)),\n+        cliParser.getOptionValue(DATANODE_LAUNCH_DELAY_ARG,\n+            DATANODE_LAUNCH_DELAY_DEFAULT),\n+        Integer.parseInt(cliParser.getOptionValue(NAMENODE_MEMORY_MB_ARG,\n+            NAMENODE_MEMORY_MB_DEFAULT)),\n+        Integer.parseInt(cliParser.getOptionValue(NAMENODE_VCORES_ARG,\n+            NAMENODE_VCORES_DEFAULT)),\n+        cliParser.getOptionValue(NAMENODE_ARGS_ARG, \"\"),\n+        cliParser.getOptionValue(NAMENODE_NODELABEL_ARG, \"\"),\n+        Integer.parseInt(cliParser.getOptionValue(NAMENODE_METRICS_PERIOD_ARG,\n+            NAMENODE_METRICS_PERIOD_DEFAULT)),\n+        cliParser.getOptionValue(NAMENODE_NAME_DIR_ARG, \"\"),\n+        cliParser.getOptionValue(NAMENODE_EDITS_DIR_ARG, \"\"), originalShellEnv);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static AMOptions initFromParser(CommandLine cliParser) {\n    Map\u003cString, String\u003e originalShellEnv \u003d new HashMap\u003c\u003e();\n    if (cliParser.hasOption(SHELL_ENV_ARG)) {\n      for (String env : cliParser.getOptionValues(SHELL_ENV_ARG)) {\n        String trimmed \u003d env.trim();\n        int index \u003d trimmed.indexOf(\u0027\u003d\u0027);\n        if (index \u003d\u003d -1) {\n          originalShellEnv.put(trimmed, \"\");\n          continue;\n        }\n        String key \u003d trimmed.substring(0, index);\n        String val \u003d \"\";\n        if (index \u003c (trimmed.length() - 1)) {\n          val \u003d trimmed.substring(index + 1);\n        }\n        originalShellEnv.put(key, val);\n      }\n    }\n    return new AMOptions(\n        Integer.parseInt(cliParser.getOptionValue(DATANODE_MEMORY_MB_ARG,\n            DATANODE_MEMORY_MB_DEFAULT)),\n        Integer.parseInt(cliParser.getOptionValue(DATANODE_VCORES_ARG,\n            DATANODE_VCORES_DEFAULT)),\n        cliParser.getOptionValue(DATANODE_ARGS_ARG, \"\"),\n        cliParser.getOptionValue(DATANODE_NODELABEL_ARG, \"\"),\n        Integer.parseInt(cliParser.getOptionValue(DATANODES_PER_CLUSTER_ARG,\n            DATANODES_PER_CLUSTER_DEFAULT)),\n        cliParser.getOptionValue(DATANODE_LAUNCH_DELAY_ARG,\n            DATANODE_LAUNCH_DELAY_DEFAULT),\n        Integer.parseInt(cliParser.getOptionValue(NAMENODE_MEMORY_MB_ARG,\n            NAMENODE_MEMORY_MB_DEFAULT)),\n        Integer.parseInt(cliParser.getOptionValue(NAMENODE_VCORES_ARG,\n            NAMENODE_VCORES_DEFAULT)),\n        cliParser.getOptionValue(NAMENODE_ARGS_ARG, \"\"),\n        cliParser.getOptionValue(NAMENODE_NODELABEL_ARG, \"\"),\n        Integer.parseInt(cliParser.getOptionValue(NAMENODE_METRICS_PERIOD_ARG,\n            NAMENODE_METRICS_PERIOD_DEFAULT)),\n        cliParser.getOptionValue(NAMENODE_NAME_DIR_ARG, \"\"),\n        cliParser.getOptionValue(NAMENODE_EDITS_DIR_ARG, \"\"), originalShellEnv);\n  }",
      "path": "hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-infra/src/main/java/org/apache/hadoop/tools/dynamometer/AMOptions.java"
    }
  }
}