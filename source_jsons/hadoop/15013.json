{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PBImageXmlWriter.java",
  "functionName": "dumpINodeSection",
  "functionId": "dumpINodeSection___in-InputStream",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageXmlWriter.java",
  "functionStartLine": 615,
  "functionEndLine": 627,
  "numCommitsSeen": 27,
  "timeTaken": 2375,
  "changeHistory": [
    "680716f31e120f4d3ee70b095e4db46c05b891d9",
    "700b0e4019cf483f7532609711812150b8c44742",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305"
  ],
  "changeHistoryShort": {
    "680716f31e120f4d3ee70b095e4db46c05b891d9": "Ybodychange",
    "700b0e4019cf483f7532609711812150b8c44742": "Ybodychange",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": "Yintroduced"
  },
  "changeHistoryDetails": {
    "680716f31e120f4d3ee70b095e4db46c05b891d9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9951. Use string constants for XML tags in OfflineImageReconstructor (Lin Yiqun via cmccabe)\n",
      "commitDate": "21/03/16 11:40 AM",
      "commitName": "680716f31e120f4d3ee70b095e4db46c05b891d9",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "02/03/16 5:56 PM",
      "commitNameOld": "700b0e4019cf483f7532609711812150b8c44742",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 18.7,
      "commitsBetweenForRepo": 94,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   private void dumpINodeSection(InputStream in) throws IOException {\n     INodeSection s \u003d INodeSection.parseDelimitedFrom(in);\n-    out.print(\"\u003cINodeSection\u003e\");\n-    o(\"lastInodeId\", s.getLastInodeId());\n-    o(\"numInodes\", s.getNumInodes());\n+    out.print(\"\u003c\" + INODE_SECTION_NAME + \"\u003e\");\n+    o(INODE_SECTION_LAST_INODE_ID, s.getLastInodeId());\n+    o(INODE_SECTION_NUM_INODES, s.getNumInodes());\n     for (int i \u003d 0; i \u003c s.getNumInodes(); ++i) {\n       INodeSection.INode p \u003d INodeSection.INode.parseDelimitedFrom(in);\n-      out.print(\"\u003cinode\u003e\");\n+      out.print(\"\u003c\" + INODE_SECTION_INODE + \"\u003e\");\n       dumpINodeFields(p);\n-      out.print(\"\u003c/inode\u003e\\n\");\n+      out.print(\"\u003c/\" + INODE_SECTION_INODE + \"\u003e\\n\");\n     }\n-    out.print(\"\u003c/INodeSection\u003e\\n\");\n+    out.print(\"\u003c/\" + INODE_SECTION_NAME + \"\u003e\\n\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void dumpINodeSection(InputStream in) throws IOException {\n    INodeSection s \u003d INodeSection.parseDelimitedFrom(in);\n    out.print(\"\u003c\" + INODE_SECTION_NAME + \"\u003e\");\n    o(INODE_SECTION_LAST_INODE_ID, s.getLastInodeId());\n    o(INODE_SECTION_NUM_INODES, s.getNumInodes());\n    for (int i \u003d 0; i \u003c s.getNumInodes(); ++i) {\n      INodeSection.INode p \u003d INodeSection.INode.parseDelimitedFrom(in);\n      out.print(\"\u003c\" + INODE_SECTION_INODE + \"\u003e\");\n      dumpINodeFields(p);\n      out.print(\"\u003c/\" + INODE_SECTION_INODE + \"\u003e\\n\");\n    }\n    out.print(\"\u003c/\" + INODE_SECTION_NAME + \"\u003e\\n\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageXmlWriter.java",
      "extendedDetails": {}
    },
    "700b0e4019cf483f7532609711812150b8c44742": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9835. OIV: add ReverseXML processor which reconstructs an fsimage from an XML file (cmccabe)\n",
      "commitDate": "02/03/16 5:56 PM",
      "commitName": "700b0e4019cf483f7532609711812150b8c44742",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "21/10/15 2:58 PM",
      "commitNameOld": "a24c6e84205c684ef864b0fc5301dc07b3578351",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 133.17,
      "commitsBetweenForRepo": 905,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,13 @@\n   private void dumpINodeSection(InputStream in) throws IOException {\n     INodeSection s \u003d INodeSection.parseDelimitedFrom(in);\n     out.print(\"\u003cINodeSection\u003e\");\n     o(\"lastInodeId\", s.getLastInodeId());\n+    o(\"numInodes\", s.getNumInodes());\n     for (int i \u003d 0; i \u003c s.getNumInodes(); ++i) {\n       INodeSection.INode p \u003d INodeSection.INode.parseDelimitedFrom(in);\n       out.print(\"\u003cinode\u003e\");\n-      o(\"id\", p.getId()).o(\"type\", p.getType()).o(\"name\",\n-          p.getName().toStringUtf8());\n-\n-      if (p.hasFile()) {\n-        dumpINodeFile(p.getFile());\n-      } else if (p.hasDirectory()) {\n-        dumpINodeDirectory(p.getDirectory());\n-      } else if (p.hasSymlink()) {\n-        dumpINodeSymlink(p.getSymlink());\n-      }\n-\n+      dumpINodeFields(p);\n       out.print(\"\u003c/inode\u003e\\n\");\n     }\n     out.print(\"\u003c/INodeSection\u003e\\n\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void dumpINodeSection(InputStream in) throws IOException {\n    INodeSection s \u003d INodeSection.parseDelimitedFrom(in);\n    out.print(\"\u003cINodeSection\u003e\");\n    o(\"lastInodeId\", s.getLastInodeId());\n    o(\"numInodes\", s.getNumInodes());\n    for (int i \u003d 0; i \u003c s.getNumInodes(); ++i) {\n      INodeSection.INode p \u003d INodeSection.INode.parseDelimitedFrom(in);\n      out.print(\"\u003cinode\u003e\");\n      dumpINodeFields(p);\n      out.print(\"\u003c/inode\u003e\\n\");\n    }\n    out.print(\"\u003c/INodeSection\u003e\\n\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageXmlWriter.java",
      "extendedDetails": {}
    },
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5698. Use protobuf to serialize / deserialize FSImage. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1566359 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/02/14 11:18 AM",
      "commitName": "a2edb11b68ae01a44092cb14ac2717a6aad93305",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,22 @@\n+  private void dumpINodeSection(InputStream in) throws IOException {\n+    INodeSection s \u003d INodeSection.parseDelimitedFrom(in);\n+    out.print(\"\u003cINodeSection\u003e\");\n+    o(\"lastInodeId\", s.getLastInodeId());\n+    for (int i \u003d 0; i \u003c s.getNumInodes(); ++i) {\n+      INodeSection.INode p \u003d INodeSection.INode.parseDelimitedFrom(in);\n+      out.print(\"\u003cinode\u003e\");\n+      o(\"id\", p.getId()).o(\"type\", p.getType()).o(\"name\",\n+          p.getName().toStringUtf8());\n+\n+      if (p.hasFile()) {\n+        dumpINodeFile(p.getFile());\n+      } else if (p.hasDirectory()) {\n+        dumpINodeDirectory(p.getDirectory());\n+      } else if (p.hasSymlink()) {\n+        dumpINodeSymlink(p.getSymlink());\n+      }\n+\n+      out.print(\"\u003c/inode\u003e\\n\");\n+    }\n+    out.print(\"\u003c/INodeSection\u003e\\n\");\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void dumpINodeSection(InputStream in) throws IOException {\n    INodeSection s \u003d INodeSection.parseDelimitedFrom(in);\n    out.print(\"\u003cINodeSection\u003e\");\n    o(\"lastInodeId\", s.getLastInodeId());\n    for (int i \u003d 0; i \u003c s.getNumInodes(); ++i) {\n      INodeSection.INode p \u003d INodeSection.INode.parseDelimitedFrom(in);\n      out.print(\"\u003cinode\u003e\");\n      o(\"id\", p.getId()).o(\"type\", p.getType()).o(\"name\",\n          p.getName().toStringUtf8());\n\n      if (p.hasFile()) {\n        dumpINodeFile(p.getFile());\n      } else if (p.hasDirectory()) {\n        dumpINodeDirectory(p.getDirectory());\n      } else if (p.hasSymlink()) {\n        dumpINodeSymlink(p.getSymlink());\n      }\n\n      out.print(\"\u003c/inode\u003e\\n\");\n    }\n    out.print(\"\u003c/INodeSection\u003e\\n\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageXmlWriter.java"
    }
  }
}