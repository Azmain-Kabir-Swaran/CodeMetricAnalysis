{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FixedBlockResolver.java",
  "functionName": "blockLengths",
  "functionId": "blockLengths___s-FileStatus",
  "sourceFilePath": "hadoop-tools/hadoop-fs2img/src/main/java/org/apache/hadoop/hdfs/server/namenode/FixedBlockResolver.java",
  "functionStartLine": 60,
  "functionEndLine": 77,
  "numCommitsSeen": 3,
  "timeTaken": 174,
  "changeHistory": [
    "8da3a6e314609f9124bd9979cd09cddbc2a10d36"
  ],
  "changeHistoryShort": {
    "8da3a6e314609f9124bd9979cd09cddbc2a10d36": "Yintroduced"
  },
  "changeHistoryDetails": {
    "8da3a6e314609f9124bd9979cd09cddbc2a10d36": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-10706. [READ] Add tool generating FSImage from external store\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "8da3a6e314609f9124bd9979cd09cddbc2a10d36",
      "commitAuthor": "Virajith Jalaparti",
      "diff": "@@ -0,0 +1,18 @@\n+  protected List\u003cLong\u003e blockLengths(FileStatus s) {\n+    ArrayList\u003cLong\u003e ret \u003d new ArrayList\u003c\u003e();\n+    if (!s.isFile()) {\n+      return ret;\n+    }\n+    if (0 \u003d\u003d s.getLen()) {\n+      // the file has length 0; so we will have one block of size 0\n+      ret.add(0L);\n+      return ret;\n+    }\n+    int nblocks \u003d (int)((s.getLen() - 1) / blocksize) + 1;\n+    for (int i \u003d 0; i \u003c nblocks - 1; ++i) {\n+      ret.add(blocksize);\n+    }\n+    long rem \u003d s.getLen() % blocksize;\n+    ret.add(0 \u003d\u003d (rem % blocksize) ? blocksize : rem);\n+    return ret;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected List\u003cLong\u003e blockLengths(FileStatus s) {\n    ArrayList\u003cLong\u003e ret \u003d new ArrayList\u003c\u003e();\n    if (!s.isFile()) {\n      return ret;\n    }\n    if (0 \u003d\u003d s.getLen()) {\n      // the file has length 0; so we will have one block of size 0\n      ret.add(0L);\n      return ret;\n    }\n    int nblocks \u003d (int)((s.getLen() - 1) / blocksize) + 1;\n    for (int i \u003d 0; i \u003c nblocks - 1; ++i) {\n      ret.add(blocksize);\n    }\n    long rem \u003d s.getLen() % blocksize;\n    ret.add(0 \u003d\u003d (rem % blocksize) ? blocksize : rem);\n    return ret;\n  }",
      "path": "hadoop-tools/hadoop-fs2img/src/main/java/org/apache/hadoop/hdfs/server/namenode/FixedBlockResolver.java"
    }
  }
}