{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ContainerTokenIdentifier.java",
  "functionName": "readFields",
  "functionId": "readFields___in-DataInput",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
  "functionStartLine": 334,
  "functionEndLine": 343,
  "numCommitsSeen": 40,
  "timeTaken": 10855,
  "changeHistory": [
    "3e5f7ea986600e084fcac723b0423e7de1b3bb8a",
    "ea26cc0b4ac02b8af686dfda80f540e5aa70c358",
    "5391919b09ce9549d13c897aa89bb0a0536760fe",
    "c86674a3a4d99aa56bb8ed3f6df51e3fef215eba",
    "f4886111aa573ec928de69e8ca9328d480bf673e",
    "e285b98f0fe8637b574c52498035f7f11fb4e962",
    "d33534c4fb35cb82ff8d56abeeb63a949e72a031",
    "b16c5638b5190c56f9d854d873589cb5c11c8b32",
    "453926397182078c65a4428eb5de5a90d6af6448",
    "40062e1aaa09628c6f45d20298fd66d799fd1f3f",
    "ffd2e01604be814fa3db1dded7cd7cff26a79b1e",
    "e1fdf62123625e4ba399af02f8aad500637d29d1",
    "3bfb26ad3b5ac46f992a632541c97ca2bc897638",
    "7f4dc277572df6ba25fa961073b99a5bdb086c00",
    "6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1",
    "f2b91a8367a762091482074505618b570a520b19",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "3e5f7ea986600e084fcac723b0423e7de1b3bb8a": "Ybodychange",
    "ea26cc0b4ac02b8af686dfda80f540e5aa70c358": "Ybodychange",
    "5391919b09ce9549d13c897aa89bb0a0536760fe": "Ybodychange",
    "c86674a3a4d99aa56bb8ed3f6df51e3fef215eba": "Ybodychange",
    "f4886111aa573ec928de69e8ca9328d480bf673e": "Ybodychange",
    "e285b98f0fe8637b574c52498035f7f11fb4e962": "Ybodychange",
    "d33534c4fb35cb82ff8d56abeeb63a949e72a031": "Ybodychange",
    "b16c5638b5190c56f9d854d873589cb5c11c8b32": "Ybodychange",
    "453926397182078c65a4428eb5de5a90d6af6448": "Ybodychange",
    "40062e1aaa09628c6f45d20298fd66d799fd1f3f": "Ybodychange",
    "ffd2e01604be814fa3db1dded7cd7cff26a79b1e": "Ybodychange",
    "e1fdf62123625e4ba399af02f8aad500637d29d1": "Yfilerename",
    "3bfb26ad3b5ac46f992a632541c97ca2bc897638": "Ybodychange",
    "7f4dc277572df6ba25fa961073b99a5bdb086c00": "Ybodychange",
    "6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1": "Ybodychange",
    "f2b91a8367a762091482074505618b570a520b19": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Ymultichange(Ymovefromfile,Ybodychange)",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "3e5f7ea986600e084fcac723b0423e7de1b3bb8a": {
      "type": "Ybodychange",
      "commitMessage": "YARN-8310. Handle old NMTokenIdentifier, AMRMTokenIdentifier, and ContainerTokenIdentifier formats. Contributed by Robert Kanter.\n",
      "commitDate": "22/05/18 6:10 PM",
      "commitName": "3e5f7ea986600e084fcac723b0423e7de1b3bb8a",
      "commitAuthor": "Miklos Szegedi",
      "commitDateOld": "18/02/18 5:19 AM",
      "commitNameOld": "4d4dde5112e9ee6b37cbdea17104c5a4c6870bd5",
      "commitAuthorOld": "fang zhenyi",
      "daysBetweenCommits": 93.49,
      "commitsBetweenForRepo": 1283,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,10 @@\n   public void readFields(DataInput in) throws IOException {\n-    proto \u003d ContainerTokenIdentifierProto.parseFrom((DataInputStream)in);\n+    byte[] data \u003d IOUtils.readFullyToByteArray(in);\n+    try {\n+      proto \u003d ContainerTokenIdentifierProto.parseFrom(data);\n+    } catch (InvalidProtocolBufferException e) {\n+      LOG.warn(\"Recovering old formatted token\");\n+      readFieldsInOldFormat(\n+          new DataInputStream(new ByteArrayInputStream(data)));\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    byte[] data \u003d IOUtils.readFullyToByteArray(in);\n    try {\n      proto \u003d ContainerTokenIdentifierProto.parseFrom(data);\n    } catch (InvalidProtocolBufferException e) {\n      LOG.warn(\"Recovering old formatted token\");\n      readFieldsInOldFormat(\n          new DataInputStream(new ByteArrayInputStream(data)));\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "ea26cc0b4ac02b8af686dfda80f540e5aa70c358": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2615. Changed ClientToAMTokenIdentifier/RM(Timeline)DelegationTokenIdentifier to use protobuf as payload. Contributed by Junping Du\n",
      "commitDate": "06/10/14 10:47 AM",
      "commitName": "ea26cc0b4ac02b8af686dfda80f540e5aa70c358",
      "commitAuthor": "Jian He",
      "commitDateOld": "26/09/14 5:48 PM",
      "commitNameOld": "5391919b09ce9549d13c897aa89bb0a0536760fe",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 9.71,
      "commitsBetweenForRepo": 88,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,3 @@\n   public void readFields(DataInput in) throws IOException {\n-    DataInputStream dis \u003d (DataInputStream)in;\n-    byte[] buffer \u003d IOUtils.toByteArray(dis);\n-    proto \u003d ContainerTokenIdentifierProto.parseFrom(buffer);\n+    proto \u003d ContainerTokenIdentifierProto.parseFrom((DataInputStream)in);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    proto \u003d ContainerTokenIdentifierProto.parseFrom((DataInputStream)in);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "5391919b09ce9549d13c897aa89bb0a0536760fe": {
      "type": "Ybodychange",
      "commitMessage": "YARN-668. Changed NMTokenIdentifier/AMRMTokenIdentifier/ContainerTokenIdentifier to use protobuf object as the payload. Contributed by Junping Du.\n",
      "commitDate": "26/09/14 5:48 PM",
      "commitName": "5391919b09ce9549d13c897aa89bb0a0536760fe",
      "commitAuthor": "Jian He",
      "commitDateOld": "24/09/14 5:50 PM",
      "commitNameOld": "c86674a3a4d99aa56bb8ed3f6df51e3fef215eba",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 2.0,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,5 @@\n   public void readFields(DataInput in) throws IOException {\n-    ApplicationId applicationId \u003d\n-        ApplicationId.newInstance(in.readLong(), in.readInt());\n-    ApplicationAttemptId applicationAttemptId \u003d\n-        ApplicationAttemptId.newInstance(applicationId, in.readInt());\n-    this.containerId \u003d\n-        ContainerId.newInstance(applicationAttemptId, in.readLong());\n-    this.nmHostAddr \u003d in.readUTF();\n-    this.appSubmitter \u003d in.readUTF();\n-    int memory \u003d in.readInt();\n-    int vCores \u003d in.readInt();\n-    this.resource \u003d Resource.newInstance(memory, vCores);\n-    this.expiryTimeStamp \u003d in.readLong();\n-    this.masterKeyId \u003d in.readInt();\n-    this.rmIdentifier \u003d in.readLong();\n-    this.priority \u003d Priority.newInstance(in.readInt());\n-    this.creationTime \u003d in.readLong();\n-    int size \u003d in.readInt();\n-    if (size !\u003d -1) {\n-      byte[] bytes \u003d new byte[size];\n-      in.readFully(bytes);\n-      this.logAggregationContext \u003d\n-          new LogAggregationContextPBImpl(\n-            LogAggregationContextProto.parseFrom(bytes));\n-    }\n+    DataInputStream dis \u003d (DataInputStream)in;\n+    byte[] buffer \u003d IOUtils.toByteArray(dis);\n+    proto \u003d ContainerTokenIdentifierProto.parseFrom(buffer);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    DataInputStream dis \u003d (DataInputStream)in;\n    byte[] buffer \u003d IOUtils.toByteArray(dis);\n    proto \u003d ContainerTokenIdentifierProto.parseFrom(buffer);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "c86674a3a4d99aa56bb8ed3f6df51e3fef215eba": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2581. Passed LogAggregationContext to NM via ContainerTokenIdentifier. Contributed by Xuan Gong.\n",
      "commitDate": "24/09/14 5:50 PM",
      "commitName": "c86674a3a4d99aa56bb8ed3f6df51e3fef215eba",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "17/09/14 3:13 PM",
      "commitNameOld": "f4886111aa573ec928de69e8ca9328d480bf673e",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 7.11,
      "commitsBetweenForRepo": 81,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,26 @@\n   public void readFields(DataInput in) throws IOException {\n     ApplicationId applicationId \u003d\n         ApplicationId.newInstance(in.readLong(), in.readInt());\n     ApplicationAttemptId applicationAttemptId \u003d\n         ApplicationAttemptId.newInstance(applicationId, in.readInt());\n     this.containerId \u003d\n         ContainerId.newInstance(applicationAttemptId, in.readLong());\n     this.nmHostAddr \u003d in.readUTF();\n     this.appSubmitter \u003d in.readUTF();\n     int memory \u003d in.readInt();\n     int vCores \u003d in.readInt();\n     this.resource \u003d Resource.newInstance(memory, vCores);\n     this.expiryTimeStamp \u003d in.readLong();\n     this.masterKeyId \u003d in.readInt();\n     this.rmIdentifier \u003d in.readLong();\n     this.priority \u003d Priority.newInstance(in.readInt());\n     this.creationTime \u003d in.readLong();\n+    int size \u003d in.readInt();\n+    if (size !\u003d -1) {\n+      byte[] bytes \u003d new byte[size];\n+      in.readFully(bytes);\n+      this.logAggregationContext \u003d\n+          new LogAggregationContextPBImpl(\n+            LogAggregationContextProto.parseFrom(bytes));\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    ApplicationId applicationId \u003d\n        ApplicationId.newInstance(in.readLong(), in.readInt());\n    ApplicationAttemptId applicationAttemptId \u003d\n        ApplicationAttemptId.newInstance(applicationId, in.readInt());\n    this.containerId \u003d\n        ContainerId.newInstance(applicationAttemptId, in.readLong());\n    this.nmHostAddr \u003d in.readUTF();\n    this.appSubmitter \u003d in.readUTF();\n    int memory \u003d in.readInt();\n    int vCores \u003d in.readInt();\n    this.resource \u003d Resource.newInstance(memory, vCores);\n    this.expiryTimeStamp \u003d in.readLong();\n    this.masterKeyId \u003d in.readInt();\n    this.rmIdentifier \u003d in.readLong();\n    this.priority \u003d Priority.newInstance(in.readInt());\n    this.creationTime \u003d in.readLong();\n    int size \u003d in.readInt();\n    if (size !\u003d -1) {\n      byte[] bytes \u003d new byte[size];\n      in.readFully(bytes);\n      this.logAggregationContext \u003d\n          new LogAggregationContextPBImpl(\n            LogAggregationContextProto.parseFrom(bytes));\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "f4886111aa573ec928de69e8ca9328d480bf673e": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2558. Updated ContainerTokenIdentifier#read/write to use ContainerId#getContainerId. Contributed by Tsuyoshi OZAWA.\n",
      "commitDate": "17/09/14 3:13 PM",
      "commitName": "f4886111aa573ec928de69e8ca9328d480bf673e",
      "commitAuthor": "Jian He",
      "commitDateOld": "24/06/14 2:43 PM",
      "commitNameOld": "e285b98f0fe8637b574c52498035f7f11fb4e962",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 85.02,
      "commitsBetweenForRepo": 707,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   public void readFields(DataInput in) throws IOException {\n     ApplicationId applicationId \u003d\n         ApplicationId.newInstance(in.readLong(), in.readInt());\n     ApplicationAttemptId applicationAttemptId \u003d\n         ApplicationAttemptId.newInstance(applicationId, in.readInt());\n     this.containerId \u003d\n-        ContainerId.newInstance(applicationAttemptId, in.readInt());\n+        ContainerId.newInstance(applicationAttemptId, in.readLong());\n     this.nmHostAddr \u003d in.readUTF();\n     this.appSubmitter \u003d in.readUTF();\n     int memory \u003d in.readInt();\n     int vCores \u003d in.readInt();\n     this.resource \u003d Resource.newInstance(memory, vCores);\n     this.expiryTimeStamp \u003d in.readLong();\n     this.masterKeyId \u003d in.readInt();\n     this.rmIdentifier \u003d in.readLong();\n     this.priority \u003d Priority.newInstance(in.readInt());\n     this.creationTime \u003d in.readLong();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    ApplicationId applicationId \u003d\n        ApplicationId.newInstance(in.readLong(), in.readInt());\n    ApplicationAttemptId applicationAttemptId \u003d\n        ApplicationAttemptId.newInstance(applicationId, in.readInt());\n    this.containerId \u003d\n        ContainerId.newInstance(applicationAttemptId, in.readLong());\n    this.nmHostAddr \u003d in.readUTF();\n    this.appSubmitter \u003d in.readUTF();\n    int memory \u003d in.readInt();\n    int vCores \u003d in.readInt();\n    this.resource \u003d Resource.newInstance(memory, vCores);\n    this.expiryTimeStamp \u003d in.readLong();\n    this.masterKeyId \u003d in.readInt();\n    this.rmIdentifier \u003d in.readLong();\n    this.priority \u003d Priority.newInstance(in.readInt());\n    this.creationTime \u003d in.readLong();\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "e285b98f0fe8637b574c52498035f7f11fb4e962": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2152. Added missing information into ContainerTokenIdentifier so that NodeManagers can report the same to RM when RM restarts. Contributed Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1605205 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/06/14 2:43 PM",
      "commitName": "e285b98f0fe8637b574c52498035f7f11fb4e962",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "16/06/13 8:32 PM",
      "commitNameOld": "f5f8f3bca4eeaedeff8181812452ec363c4db744",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 372.76,
      "commitsBetweenForRepo": 2453,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,18 @@\n   public void readFields(DataInput in) throws IOException {\n     ApplicationId applicationId \u003d\n         ApplicationId.newInstance(in.readLong(), in.readInt());\n     ApplicationAttemptId applicationAttemptId \u003d\n         ApplicationAttemptId.newInstance(applicationId, in.readInt());\n     this.containerId \u003d\n         ContainerId.newInstance(applicationAttemptId, in.readInt());\n     this.nmHostAddr \u003d in.readUTF();\n     this.appSubmitter \u003d in.readUTF();\n     int memory \u003d in.readInt();\n     int vCores \u003d in.readInt();\n     this.resource \u003d Resource.newInstance(memory, vCores);\n     this.expiryTimeStamp \u003d in.readLong();\n     this.masterKeyId \u003d in.readInt();\n     this.rmIdentifier \u003d in.readLong();\n+    this.priority \u003d Priority.newInstance(in.readInt());\n+    this.creationTime \u003d in.readLong();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    ApplicationId applicationId \u003d\n        ApplicationId.newInstance(in.readLong(), in.readInt());\n    ApplicationAttemptId applicationAttemptId \u003d\n        ApplicationAttemptId.newInstance(applicationId, in.readInt());\n    this.containerId \u003d\n        ContainerId.newInstance(applicationAttemptId, in.readInt());\n    this.nmHostAddr \u003d in.readUTF();\n    this.appSubmitter \u003d in.readUTF();\n    int memory \u003d in.readInt();\n    int vCores \u003d in.readInt();\n    this.resource \u003d Resource.newInstance(memory, vCores);\n    this.expiryTimeStamp \u003d in.readLong();\n    this.masterKeyId \u003d in.readInt();\n    this.rmIdentifier \u003d in.readLong();\n    this.priority \u003d Priority.newInstance(in.readInt());\n    this.creationTime \u003d in.readLong();\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "d33534c4fb35cb82ff8d56abeeb63a949e72a031": {
      "type": "Ybodychange",
      "commitMessage": "YARN-748. Moved BuilderUtils from yarn-common to yarn-server-common for eventual retirement. Contributed by Jian He.\nMAPREDUCE-5297. Updated MR App since BuilderUtils is no longer public after YARN-748. Contributed by Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1489257 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/06/13 5:34 PM",
      "commitName": "d33534c4fb35cb82ff8d56abeeb63a949e72a031",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "29/05/13 9:59 PM",
      "commitNameOld": "b16c5638b5190c56f9d854d873589cb5c11c8b32",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 4.82,
      "commitsBetweenForRepo": 47,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n   public void readFields(DataInput in) throws IOException {\n-    ApplicationId applicationId \u003d BuilderUtils.newApplicationId(\n-        in.readLong(), in.readInt());\n-    ApplicationAttemptId applicationAttemptId \u003d BuilderUtils\n-        .newApplicationAttemptId(applicationId, in.readInt());\n-    this.containerId \u003d BuilderUtils.newContainerId(applicationAttemptId, in\n-        .readInt());\n+    ApplicationId applicationId \u003d\n+        ApplicationId.newInstance(in.readLong(), in.readInt());\n+    ApplicationAttemptId applicationAttemptId \u003d\n+        ApplicationAttemptId.newInstance(applicationId, in.readInt());\n+    this.containerId \u003d\n+        ContainerId.newInstance(applicationAttemptId, in.readInt());\n     this.nmHostAddr \u003d in.readUTF();\n     this.appSubmitter \u003d in.readUTF();\n     int memory \u003d in.readInt();\n     int vCores \u003d in.readInt();\n-    this.resource \u003d BuilderUtils.newResource(memory, vCores);\n+    this.resource \u003d Resource.newInstance(memory, vCores);\n     this.expiryTimeStamp \u003d in.readLong();\n     this.masterKeyId \u003d in.readInt();\n     this.rmIdentifier \u003d in.readLong();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    ApplicationId applicationId \u003d\n        ApplicationId.newInstance(in.readLong(), in.readInt());\n    ApplicationAttemptId applicationAttemptId \u003d\n        ApplicationAttemptId.newInstance(applicationId, in.readInt());\n    this.containerId \u003d\n        ContainerId.newInstance(applicationAttemptId, in.readInt());\n    this.nmHostAddr \u003d in.readUTF();\n    this.appSubmitter \u003d in.readUTF();\n    int memory \u003d in.readInt();\n    int vCores \u003d in.readInt();\n    this.resource \u003d Resource.newInstance(memory, vCores);\n    this.expiryTimeStamp \u003d in.readLong();\n    this.masterKeyId \u003d in.readInt();\n    this.rmIdentifier \u003d in.readLong();\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "b16c5638b5190c56f9d854d873589cb5c11c8b32": {
      "type": "Ybodychange",
      "commitMessage": "YARN-719. Move RMIdentifier from Container to ContainerTokenIdentifier. Contributed by Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1487741 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/05/13 9:59 PM",
      "commitName": "b16c5638b5190c56f9d854d873589cb5c11c8b32",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "08/01/13 9:08 PM",
      "commitNameOld": "453926397182078c65a4428eb5de5a90d6af6448",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 140.99,
      "commitsBetweenForRepo": 816,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,16 @@\n   public void readFields(DataInput in) throws IOException {\n     ApplicationId applicationId \u003d BuilderUtils.newApplicationId(\n         in.readLong(), in.readInt());\n     ApplicationAttemptId applicationAttemptId \u003d BuilderUtils\n         .newApplicationAttemptId(applicationId, in.readInt());\n     this.containerId \u003d BuilderUtils.newContainerId(applicationAttemptId, in\n         .readInt());\n     this.nmHostAddr \u003d in.readUTF();\n     this.appSubmitter \u003d in.readUTF();\n     int memory \u003d in.readInt();\n     int vCores \u003d in.readInt();\n     this.resource \u003d BuilderUtils.newResource(memory, vCores);\n     this.expiryTimeStamp \u003d in.readLong();\n     this.masterKeyId \u003d in.readInt();\n+    this.rmIdentifier \u003d in.readLong();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    ApplicationId applicationId \u003d BuilderUtils.newApplicationId(\n        in.readLong(), in.readInt());\n    ApplicationAttemptId applicationAttemptId \u003d BuilderUtils\n        .newApplicationAttemptId(applicationId, in.readInt());\n    this.containerId \u003d BuilderUtils.newContainerId(applicationAttemptId, in\n        .readInt());\n    this.nmHostAddr \u003d in.readUTF();\n    this.appSubmitter \u003d in.readUTF();\n    int memory \u003d in.readInt();\n    int vCores \u003d in.readInt();\n    this.resource \u003d BuilderUtils.newResource(memory, vCores);\n    this.expiryTimeStamp \u003d in.readLong();\n    this.masterKeyId \u003d in.readInt();\n    this.rmIdentifier \u003d in.readLong();\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "453926397182078c65a4428eb5de5a90d6af6448": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2. Enhanced CapacityScheduler to account for CPU alongwith memory for multi-dimensional resource scheduling. Contributed by Arun C. Murthy.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1430682 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/01/13 9:08 PM",
      "commitName": "453926397182078c65a4428eb5de5a90d6af6448",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "26/09/12 8:43 PM",
      "commitNameOld": "40062e1aaa09628c6f45d20298fd66d799fd1f3f",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 104.06,
      "commitsBetweenForRepo": 490,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,15 @@\n   public void readFields(DataInput in) throws IOException {\n     ApplicationId applicationId \u003d BuilderUtils.newApplicationId(\n         in.readLong(), in.readInt());\n     ApplicationAttemptId applicationAttemptId \u003d BuilderUtils\n         .newApplicationAttemptId(applicationId, in.readInt());\n     this.containerId \u003d BuilderUtils.newContainerId(applicationAttemptId, in\n         .readInt());\n     this.nmHostAddr \u003d in.readUTF();\n     this.appSubmitter \u003d in.readUTF();\n-    this.resource \u003d BuilderUtils.newResource(in.readInt());\n+    int memory \u003d in.readInt();\n+    int vCores \u003d in.readInt();\n+    this.resource \u003d BuilderUtils.newResource(memory, vCores);\n     this.expiryTimeStamp \u003d in.readLong();\n     this.masterKeyId \u003d in.readInt();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    ApplicationId applicationId \u003d BuilderUtils.newApplicationId(\n        in.readLong(), in.readInt());\n    ApplicationAttemptId applicationAttemptId \u003d BuilderUtils\n        .newApplicationAttemptId(applicationId, in.readInt());\n    this.containerId \u003d BuilderUtils.newContainerId(applicationAttemptId, in\n        .readInt());\n    this.nmHostAddr \u003d in.readUTF();\n    this.appSubmitter \u003d in.readUTF();\n    int memory \u003d in.readInt();\n    int vCores \u003d in.readInt();\n    this.resource \u003d BuilderUtils.newResource(memory, vCores);\n    this.expiryTimeStamp \u003d in.readLong();\n    this.masterKeyId \u003d in.readInt();\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "40062e1aaa09628c6f45d20298fd66d799fd1f3f": {
      "type": "Ybodychange",
      "commitMessage": "Fix NodeManager to verify the application\u0027s user-name.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1390825 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/09/12 8:43 PM",
      "commitName": "40062e1aaa09628c6f45d20298fd66d799fd1f3f",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "24/08/12 7:18 PM",
      "commitNameOld": "ffd2e01604be814fa3db1dded7cd7cff26a79b1e",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 33.06,
      "commitsBetweenForRepo": 173,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,13 @@\n   public void readFields(DataInput in) throws IOException {\n     ApplicationId applicationId \u003d BuilderUtils.newApplicationId(\n         in.readLong(), in.readInt());\n     ApplicationAttemptId applicationAttemptId \u003d BuilderUtils\n         .newApplicationAttemptId(applicationId, in.readInt());\n     this.containerId \u003d BuilderUtils.newContainerId(applicationAttemptId, in\n         .readInt());\n     this.nmHostAddr \u003d in.readUTF();\n+    this.appSubmitter \u003d in.readUTF();\n     this.resource \u003d BuilderUtils.newResource(in.readInt());\n     this.expiryTimeStamp \u003d in.readLong();\n     this.masterKeyId \u003d in.readInt();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    ApplicationId applicationId \u003d BuilderUtils.newApplicationId(\n        in.readLong(), in.readInt());\n    ApplicationAttemptId applicationAttemptId \u003d BuilderUtils\n        .newApplicationAttemptId(applicationId, in.readInt());\n    this.containerId \u003d BuilderUtils.newContainerId(applicationAttemptId, in\n        .readInt());\n    this.nmHostAddr \u003d in.readUTF();\n    this.appSubmitter \u003d in.readUTF();\n    this.resource \u003d BuilderUtils.newResource(in.readInt());\n    this.expiryTimeStamp \u003d in.readLong();\n    this.masterKeyId \u003d in.readInt();\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "ffd2e01604be814fa3db1dded7cd7cff26a79b1e": {
      "type": "Ybodychange",
      "commitMessage": "YARN-39. RM-NM secret-keys should be randomly generated and rolled every so often. (Contributed by Vinod Kumar Vavilapalli and Siddharth Seth)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1377180 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/12 7:18 PM",
      "commitName": "ffd2e01604be814fa3db1dded7cd7cff26a79b1e",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "07/08/12 10:22 PM",
      "commitNameOld": "e1fdf62123625e4ba399af02f8aad500637d29d1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 16.87,
      "commitsBetweenForRepo": 114,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,12 @@\n   public void readFields(DataInput in) throws IOException {\n     ApplicationId applicationId \u003d BuilderUtils.newApplicationId(\n         in.readLong(), in.readInt());\n     ApplicationAttemptId applicationAttemptId \u003d BuilderUtils\n         .newApplicationAttemptId(applicationId, in.readInt());\n     this.containerId \u003d BuilderUtils.newContainerId(applicationAttemptId, in\n         .readInt());\n     this.nmHostAddr \u003d in.readUTF();\n     this.resource \u003d BuilderUtils.newResource(in.readInt());\n     this.expiryTimeStamp \u003d in.readLong();\n+    this.masterKeyId \u003d in.readInt();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    ApplicationId applicationId \u003d BuilderUtils.newApplicationId(\n        in.readLong(), in.readInt());\n    ApplicationAttemptId applicationAttemptId \u003d BuilderUtils\n        .newApplicationAttemptId(applicationId, in.readInt());\n    this.containerId \u003d BuilderUtils.newContainerId(applicationAttemptId, in\n        .readInt());\n    this.nmHostAddr \u003d in.readUTF();\n    this.resource \u003d BuilderUtils.newResource(in.readInt());\n    this.expiryTimeStamp \u003d in.readLong();\n    this.masterKeyId \u003d in.readInt();\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "e1fdf62123625e4ba399af02f8aad500637d29d1": {
      "type": "Yfilerename",
      "commitMessage": "YARN-1. Promote YARN to be a sub-project of Apache Hadoop.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370666 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/12 10:22 PM",
      "commitName": "e1fdf62123625e4ba399af02f8aad500637d29d1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "07/08/12 7:53 PM",
      "commitNameOld": "34554d1e11ee1d5b564d7d9ed3e6d55931d72749",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    ApplicationId applicationId \u003d BuilderUtils.newApplicationId(\n        in.readLong(), in.readInt());\n    ApplicationAttemptId applicationAttemptId \u003d BuilderUtils\n        .newApplicationAttemptId(applicationId, in.readInt());\n    this.containerId \u003d BuilderUtils.newContainerId(applicationAttemptId, in\n        .readInt());\n    this.nmHostAddr \u003d in.readUTF();\n    this.resource \u003d BuilderUtils.newResource(in.readInt());\n    this.expiryTimeStamp \u003d in.readLong();\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java"
      }
    },
    "3bfb26ad3b5ac46f992a632541c97ca2bc897638": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3940. ContainerTokens should have an expiry interval. Contributed by Siddharth Seth and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1359910 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/07/12 2:26 PM",
      "commitName": "3bfb26ad3b5ac46f992a632541c97ca2bc897638",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "29/10/11 2:35 AM",
      "commitNameOld": "7f4dc277572df6ba25fa961073b99a5bdb086c00",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 255.49,
      "commitsBetweenForRepo": 1664,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,11 @@\n   public void readFields(DataInput in) throws IOException {\n     ApplicationId applicationId \u003d BuilderUtils.newApplicationId(\n         in.readLong(), in.readInt());\n     ApplicationAttemptId applicationAttemptId \u003d BuilderUtils\n         .newApplicationAttemptId(applicationId, in.readInt());\n     this.containerId \u003d BuilderUtils.newContainerId(applicationAttemptId, in\n         .readInt());\n     this.nmHostAddr \u003d in.readUTF();\n     this.resource \u003d BuilderUtils.newResource(in.readInt());\n+    this.expiryTimeStamp \u003d in.readLong();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    ApplicationId applicationId \u003d BuilderUtils.newApplicationId(\n        in.readLong(), in.readInt());\n    ApplicationAttemptId applicationAttemptId \u003d BuilderUtils\n        .newApplicationAttemptId(applicationId, in.readInt());\n    this.containerId \u003d BuilderUtils.newContainerId(applicationAttemptId, in\n        .readInt());\n    this.nmHostAddr \u003d in.readUTF();\n    this.resource \u003d BuilderUtils.newResource(in.readInt());\n    this.expiryTimeStamp \u003d in.readLong();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "7f4dc277572df6ba25fa961073b99a5bdb086c00": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3256. Added authorization checks for the protocol between NodeManager and ApplicationMaster. Contributed by Vinod K V.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1194850 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/10/11 2:35 AM",
      "commitName": "7f4dc277572df6ba25fa961073b99a5bdb086c00",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "13/10/11 6:24 PM",
      "commitNameOld": "002dd6968b89ded6a77858ccb50c9b2df074c226",
      "commitAuthorOld": "Jitendra Nath Pandey",
      "daysBetweenCommits": 15.34,
      "commitsBetweenForRepo": 154,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,10 @@\n   public void readFields(DataInput in) throws IOException {\n-    this.containerId \u003d \n-        RecordFactoryProvider.getRecordFactory(null).newRecordInstance(\n-            ContainerId.class);\n-    ApplicationAttemptId applicationAttemptId \u003d\n-        RecordFactoryProvider.getRecordFactory(null).newRecordInstance(\n-            ApplicationAttemptId.class);\n-    ApplicationId applicationId \u003d\n-        RecordFactoryProvider.getRecordFactory(null).newRecordInstance(\n-            ApplicationId.class);\n-    applicationId.setClusterTimestamp(in.readLong());\n-    applicationId.setId(in.readInt());\n-    applicationAttemptId.setApplicationId(applicationId);\n-    applicationAttemptId.setAttemptId(in.readInt());\n-    this.containerId.setApplicationAttemptId(applicationAttemptId);\n-    this.containerId.setId(in.readInt());\n-    this.nmHostName \u003d in.readUTF();\n-    this.resource \u003d \n-        RecordFactoryProvider.getRecordFactory(null).newRecordInstance(\n-            Resource.class);\n-    this.resource.setMemory(in.readInt());\n+    ApplicationId applicationId \u003d BuilderUtils.newApplicationId(\n+        in.readLong(), in.readInt());\n+    ApplicationAttemptId applicationAttemptId \u003d BuilderUtils\n+        .newApplicationAttemptId(applicationId, in.readInt());\n+    this.containerId \u003d BuilderUtils.newContainerId(applicationAttemptId, in\n+        .readInt());\n+    this.nmHostAddr \u003d in.readUTF();\n+    this.resource \u003d BuilderUtils.newResource(in.readInt());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    ApplicationId applicationId \u003d BuilderUtils.newApplicationId(\n        in.readLong(), in.readInt());\n    ApplicationAttemptId applicationAttemptId \u003d BuilderUtils\n        .newApplicationAttemptId(applicationId, in.readInt());\n    this.containerId \u003d BuilderUtils.newContainerId(applicationAttemptId, in\n        .readInt());\n    this.nmHostAddr \u003d in.readUTF();\n    this.resource \u003d BuilderUtils.newResource(in.readInt());\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2896. Simplify all apis to in org.apache.hadoop.yarn.api.records.* to be get/set only. Added javadocs to all public records.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1169980 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/09/11 5:05 PM",
      "commitName": "6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 11:35 PM",
      "commitNameOld": "f2b91a8367a762091482074505618b570a520b19",
      "commitAuthorOld": "Sharad Agarwal",
      "daysBetweenCommits": 18.73,
      "commitsBetweenForRepo": 109,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,22 @@\n   public void readFields(DataInput in) throws IOException {\n-    this.containerId \u003d RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ContainerId.class);\n-    this.containerId.setAppId(RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ApplicationId.class));\n-    this.containerId.setAppAttemptId(RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ApplicationAttemptId.class));\n-    this.containerId.getAppId().setId(in.readInt());\n-    this.containerId.getAppAttemptId().setApplicationId(this.containerId.getAppId());\n-    this.containerId.getAppAttemptId().setAttemptId(in.readInt());\n+    this.containerId \u003d \n+        RecordFactoryProvider.getRecordFactory(null).newRecordInstance(\n+            ContainerId.class);\n+    ApplicationAttemptId applicationAttemptId \u003d\n+        RecordFactoryProvider.getRecordFactory(null).newRecordInstance(\n+            ApplicationAttemptId.class);\n+    ApplicationId applicationId \u003d\n+        RecordFactoryProvider.getRecordFactory(null).newRecordInstance(\n+            ApplicationId.class);\n+    applicationId.setClusterTimestamp(in.readLong());\n+    applicationId.setId(in.readInt());\n+    applicationAttemptId.setApplicationId(applicationId);\n+    applicationAttemptId.setAttemptId(in.readInt());\n+    this.containerId.setApplicationAttemptId(applicationAttemptId);\n     this.containerId.setId(in.readInt());\n     this.nmHostName \u003d in.readUTF();\n-    this.resource \u003d RecordFactoryProvider.getRecordFactory(null).newRecordInstance(Resource.class);\n-    this.resource.setMemory(in.readInt()); // TODO: more resources.\n+    this.resource \u003d \n+        RecordFactoryProvider.getRecordFactory(null).newRecordInstance(\n+            Resource.class);\n+    this.resource.setMemory(in.readInt());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    this.containerId \u003d \n        RecordFactoryProvider.getRecordFactory(null).newRecordInstance(\n            ContainerId.class);\n    ApplicationAttemptId applicationAttemptId \u003d\n        RecordFactoryProvider.getRecordFactory(null).newRecordInstance(\n            ApplicationAttemptId.class);\n    ApplicationId applicationId \u003d\n        RecordFactoryProvider.getRecordFactory(null).newRecordInstance(\n            ApplicationId.class);\n    applicationId.setClusterTimestamp(in.readLong());\n    applicationId.setId(in.readInt());\n    applicationAttemptId.setApplicationId(applicationId);\n    applicationAttemptId.setAttemptId(in.readInt());\n    this.containerId.setApplicationAttemptId(applicationAttemptId);\n    this.containerId.setId(in.readInt());\n    this.nmHostName \u003d in.readUTF();\n    this.resource \u003d \n        RecordFactoryProvider.getRecordFactory(null).newRecordInstance(\n            Resource.class);\n    this.resource.setMemory(in.readInt());\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "f2b91a8367a762091482074505618b570a520b19": {
      "type": "Ybodychange",
      "commitMessage": " MAPREDUCE-2807. Fix AM restart and client redirection. Contributed by Sharad Agarwal.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161408 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 11:35 PM",
      "commitName": "f2b91a8367a762091482074505618b570a520b19",
      "commitAuthor": "Sharad Agarwal",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.26,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,12 @@\n   public void readFields(DataInput in) throws IOException {\n     this.containerId \u003d RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ContainerId.class);\n     this.containerId.setAppId(RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ApplicationId.class));\n+    this.containerId.setAppAttemptId(RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ApplicationAttemptId.class));\n     this.containerId.getAppId().setId(in.readInt());\n+    this.containerId.getAppAttemptId().setApplicationId(this.containerId.getAppId());\n+    this.containerId.getAppAttemptId().setAttemptId(in.readInt());\n     this.containerId.setId(in.readInt());\n     this.nmHostName \u003d in.readUTF();\n     this.resource \u003d RecordFactoryProvider.getRecordFactory(null).newRecordInstance(Resource.class);\n     this.resource.setMemory(in.readInt()); // TODO: more resources.\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    this.containerId \u003d RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ContainerId.class);\n    this.containerId.setAppId(RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ApplicationId.class));\n    this.containerId.setAppAttemptId(RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ApplicationAttemptId.class));\n    this.containerId.getAppId().setId(in.readInt());\n    this.containerId.getAppAttemptId().setApplicationId(this.containerId.getAppId());\n    this.containerId.getAppAttemptId().setAttemptId(in.readInt());\n    this.containerId.setId(in.readInt());\n    this.nmHostName \u003d in.readUTF();\n    this.resource \u003d RecordFactoryProvider.getRecordFactory(null).newRecordInstance(Resource.class);\n    this.resource.setMemory(in.readInt()); // TODO: more resources.\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    this.containerId \u003d RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ContainerId.class);\n    this.containerId.setAppId(RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ApplicationId.class));\n    this.containerId.getAppId().setId(in.readInt());\n    this.containerId.setId(in.readInt());\n    this.nmHostName \u003d in.readUTF();\n    this.resource \u003d RecordFactoryProvider.getRecordFactory(null).newRecordInstance(Resource.class);\n    this.resource.setMemory(in.readInt()); // TODO: more resources.\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
        "newPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,9 @@\n   public void readFields(DataInput in) throws IOException {\n-    jobFile \u003d Text.readString(in);\n-    taskId \u003d TaskAttemptID.read(in);\n-    partition \u003d in.readInt();\n-    numSlotsRequired \u003d in.readInt();\n-    taskStatus.readFields(in);\n-    skipRanges.readFields(in);\n-    currentRecIndexIterator \u003d skipRanges.skipRangeIterator();\n-    currentRecStartIndex \u003d currentRecIndexIterator.next();\n-    skipping \u003d in.readBoolean();\n-    jobCleanup \u003d in.readBoolean();\n-    if (jobCleanup) {\n-      jobRunStateForCleanup \u003d \n-        WritableUtils.readEnum(in, JobStatus.State.class);\n-    }\n-    jobSetup \u003d in.readBoolean();\n-    writeSkipRecs \u003d in.readBoolean();\n-    taskCleanup \u003d in.readBoolean();\n-    if (taskCleanup) {\n-      setPhase(TaskStatus.Phase.CLEANUP);\n-    }\n-    user \u003d Text.readString(in);\n-    extraData.readFields(in);\n+    this.containerId \u003d RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ContainerId.class);\n+    this.containerId.setAppId(RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ApplicationId.class));\n+    this.containerId.getAppId().setId(in.readInt());\n+    this.containerId.setId(in.readInt());\n+    this.nmHostName \u003d in.readUTF();\n+    this.resource \u003d RecordFactoryProvider.getRecordFactory(null).newRecordInstance(Resource.class);\n+    this.resource.setMemory(in.readInt()); // TODO: more resources.\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void readFields(DataInput in) throws IOException {\n    this.containerId \u003d RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ContainerId.class);\n    this.containerId.setAppId(RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ApplicationId.class));\n    this.containerId.getAppId().setId(in.readInt());\n    this.containerId.setId(in.readInt());\n    this.nmHostName \u003d in.readUTF();\n    this.resource \u003d RecordFactoryProvider.getRecordFactory(null).newRecordInstance(Resource.class);\n    this.resource.setMemory(in.readInt()); // TODO: more resources.\n  }",
          "path": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
          "extendedDetails": {
            "oldPath": "mapreduce/src/java/org/apache/hadoop/mapred/Task.java",
            "newPath": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
            "oldMethodName": "readFields",
            "newMethodName": "readFields"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,9 @@\n   public void readFields(DataInput in) throws IOException {\n-    jobFile \u003d Text.readString(in);\n-    taskId \u003d TaskAttemptID.read(in);\n-    partition \u003d in.readInt();\n-    numSlotsRequired \u003d in.readInt();\n-    taskStatus.readFields(in);\n-    skipRanges.readFields(in);\n-    currentRecIndexIterator \u003d skipRanges.skipRangeIterator();\n-    currentRecStartIndex \u003d currentRecIndexIterator.next();\n-    skipping \u003d in.readBoolean();\n-    jobCleanup \u003d in.readBoolean();\n-    if (jobCleanup) {\n-      jobRunStateForCleanup \u003d \n-        WritableUtils.readEnum(in, JobStatus.State.class);\n-    }\n-    jobSetup \u003d in.readBoolean();\n-    writeSkipRecs \u003d in.readBoolean();\n-    taskCleanup \u003d in.readBoolean();\n-    if (taskCleanup) {\n-      setPhase(TaskStatus.Phase.CLEANUP);\n-    }\n-    user \u003d Text.readString(in);\n-    extraData.readFields(in);\n+    this.containerId \u003d RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ContainerId.class);\n+    this.containerId.setAppId(RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ApplicationId.class));\n+    this.containerId.getAppId().setId(in.readInt());\n+    this.containerId.setId(in.readInt());\n+    this.nmHostName \u003d in.readUTF();\n+    this.resource \u003d RecordFactoryProvider.getRecordFactory(null).newRecordInstance(Resource.class);\n+    this.resource.setMemory(in.readInt()); // TODO: more resources.\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void readFields(DataInput in) throws IOException {\n    this.containerId \u003d RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ContainerId.class);\n    this.containerId.setAppId(RecordFactoryProvider.getRecordFactory(null).newRecordInstance(ApplicationId.class));\n    this.containerId.getAppId().setId(in.readInt());\n    this.containerId.setId(in.readInt());\n    this.nmHostName \u003d in.readUTF();\n    this.resource \u003d RecordFactoryProvider.getRecordFactory(null).newRecordInstance(Resource.class);\n    this.resource.setMemory(in.readInt()); // TODO: more resources.\n  }",
          "path": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
          "extendedDetails": {}
        }
      ]
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,24 @@\n+  public void readFields(DataInput in) throws IOException {\n+    jobFile \u003d Text.readString(in);\n+    taskId \u003d TaskAttemptID.read(in);\n+    partition \u003d in.readInt();\n+    numSlotsRequired \u003d in.readInt();\n+    taskStatus.readFields(in);\n+    skipRanges.readFields(in);\n+    currentRecIndexIterator \u003d skipRanges.skipRangeIterator();\n+    currentRecStartIndex \u003d currentRecIndexIterator.next();\n+    skipping \u003d in.readBoolean();\n+    jobCleanup \u003d in.readBoolean();\n+    if (jobCleanup) {\n+      jobRunStateForCleanup \u003d \n+        WritableUtils.readEnum(in, JobStatus.State.class);\n+    }\n+    jobSetup \u003d in.readBoolean();\n+    writeSkipRecs \u003d in.readBoolean();\n+    taskCleanup \u003d in.readBoolean();\n+    if (taskCleanup) {\n+      setPhase(TaskStatus.Phase.CLEANUP);\n+    }\n+    user \u003d Text.readString(in);\n+    extraData.readFields(in);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void readFields(DataInput in) throws IOException {\n    jobFile \u003d Text.readString(in);\n    taskId \u003d TaskAttemptID.read(in);\n    partition \u003d in.readInt();\n    numSlotsRequired \u003d in.readInt();\n    taskStatus.readFields(in);\n    skipRanges.readFields(in);\n    currentRecIndexIterator \u003d skipRanges.skipRangeIterator();\n    currentRecStartIndex \u003d currentRecIndexIterator.next();\n    skipping \u003d in.readBoolean();\n    jobCleanup \u003d in.readBoolean();\n    if (jobCleanup) {\n      jobRunStateForCleanup \u003d \n        WritableUtils.readEnum(in, JobStatus.State.class);\n    }\n    jobSetup \u003d in.readBoolean();\n    writeSkipRecs \u003d in.readBoolean();\n    taskCleanup \u003d in.readBoolean();\n    if (taskCleanup) {\n      setPhase(TaskStatus.Phase.CLEANUP);\n    }\n    user \u003d Text.readString(in);\n    extraData.readFields(in);\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapred/Task.java"
    }
  }
}