{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "removeBlocksAssociatedTo",
  "functionId": "removeBlocksAssociatedTo___storageInfo-DatanodeStorageInfo(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 1695,
  "functionEndLine": 1713,
  "numCommitsSeen": 477,
  "timeTaken": 14435,
  "changeHistory": [
    "51b671ef1844069888f976cd16f66c88f9bbc7de",
    "391ce535a739dc92cb90017d759217265a4fd969",
    "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a",
    "a49cc74b4c72195dee1dfb6f9548e5e411dff553",
    "663eba0ab1c73b45f98e46ffc87ad8fd91584046",
    "5956d23b645e272748e2edca4c30231e729b96a9",
    "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5",
    "abf833a7b228fff2bca4f69cd9df99d532380038",
    "41980c56d3c01d7a0ddc7deea2d89b7f28026722"
  ],
  "changeHistoryShort": {
    "51b671ef1844069888f976cd16f66c88f9bbc7de": "Ybodychange",
    "391ce535a739dc92cb90017d759217265a4fd969": "Ybodychange",
    "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a": "Ybodychange",
    "a49cc74b4c72195dee1dfb6f9548e5e411dff553": "Ybodychange",
    "663eba0ab1c73b45f98e46ffc87ad8fd91584046": "Ybodychange",
    "5956d23b645e272748e2edca4c30231e729b96a9": "Ybodychange",
    "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5": "Ybodychange",
    "abf833a7b228fff2bca4f69cd9df99d532380038": "Ybodychange",
    "41980c56d3c01d7a0ddc7deea2d89b7f28026722": "Yintroduced"
  },
  "changeHistoryDetails": {
    "51b671ef1844069888f976cd16f66c88f9bbc7de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11681. DatanodeStorageInfo#getBlockIterator() should return an iterator to an unmodifiable set Contributed by Virajith Jalaparti\n",
      "commitDate": "10/05/17 10:25 PM",
      "commitName": "51b671ef1844069888f976cd16f66c88f9bbc7de",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "10/05/17 12:15 PM",
      "commitNameOld": "ad1e3e4d9f105fac246ce1bdae80e92e013b8ba5",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.42,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n   void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n     assert namesystem.hasWriteLock();\n     final Iterator\u003cBlockInfo\u003e it \u003d storageInfo.getBlockIterator();\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n-    while(it.hasNext()) {\n-      BlockInfo block \u003d it.next();\n-      // DatanodeStorageInfo must be removed using the iterator to avoid\n-      // ConcurrentModificationException in the underlying storage\n-      it.remove();\n+    Collection\u003cBlockInfo\u003e toRemove \u003d new ArrayList\u003c\u003e();\n+    while (it.hasNext()) {\n+      toRemove.add(it.next());\n+    }\n+    for (BlockInfo block : toRemove) {\n       removeStoredBlock(block, node);\n       final Block b \u003d getBlockOnStorage(block, storageInfo);\n       if (b !\u003d null) {\n         invalidateBlocks.remove(node, b);\n       }\n     }\n     checkSafeMode();\n     LOG.info(\"Removed blocks associated with storage {} from DataNode {}\",\n         storageInfo, node);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n    assert namesystem.hasWriteLock();\n    final Iterator\u003cBlockInfo\u003e it \u003d storageInfo.getBlockIterator();\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    Collection\u003cBlockInfo\u003e toRemove \u003d new ArrayList\u003c\u003e();\n    while (it.hasNext()) {\n      toRemove.add(it.next());\n    }\n    for (BlockInfo block : toRemove) {\n      removeStoredBlock(block, node);\n      final Block b \u003d getBlockOnStorage(block, storageInfo);\n      if (b !\u003d null) {\n        invalidateBlocks.remove(node, b);\n      }\n    }\n    checkSafeMode();\n    LOG.info(\"Removed blocks associated with storage {} from DataNode {}\",\n        storageInfo, node);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "391ce535a739dc92cb90017d759217265a4fd969": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10301. Remove FBR tracking state to fix false zombie storage detection for interleaving block reports. Contributed by Vinitha Gankidi.",
      "commitDate": "14/10/16 6:13 PM",
      "commitName": "391ce535a739dc92cb90017d759217265a4fd969",
      "commitAuthor": "Vinitha Reddy Gankidi",
      "commitDateOld": "07/10/16 10:44 PM",
      "commitNameOld": "4d106213c0f4835b723c9a50bd8080a9017122d7",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 6.81,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,19 @@\n   void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n     assert namesystem.hasWriteLock();\n     final Iterator\u003cBlockInfo\u003e it \u003d storageInfo.getBlockIterator();\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     while(it.hasNext()) {\n       BlockInfo block \u003d it.next();\n       // DatanodeStorageInfo must be removed using the iterator to avoid\n       // ConcurrentModificationException in the underlying storage\n       it.remove();\n       removeStoredBlock(block, node);\n       final Block b \u003d getBlockOnStorage(block, storageInfo);\n       if (b !\u003d null) {\n         invalidateBlocks.remove(node, b);\n       }\n     }\n     checkSafeMode();\n+    LOG.info(\"Removed blocks associated with storage {} from DataNode {}\",\n+        storageInfo, node);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n    assert namesystem.hasWriteLock();\n    final Iterator\u003cBlockInfo\u003e it \u003d storageInfo.getBlockIterator();\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    while(it.hasNext()) {\n      BlockInfo block \u003d it.next();\n      // DatanodeStorageInfo must be removed using the iterator to avoid\n      // ConcurrentModificationException in the underlying storage\n      it.remove();\n      removeStoredBlock(block, node);\n      final Block b \u003d getBlockOnStorage(block, storageInfo);\n      if (b !\u003d null) {\n        invalidateBlocks.remove(node, b);\n      }\n    }\n    checkSafeMode();\n    LOG.info(\"Removed blocks associated with storage {} from DataNode {}\",\n        storageInfo, node);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9260. Improve the performance and GC friendliness of NameNode startup and full block reports (Staffan Friberg via cmccabe)\n",
      "commitDate": "02/02/16 11:23 AM",
      "commitName": "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "31/01/16 11:54 PM",
      "commitNameOld": "e418bd1fb0568ce7ae22f588fea2dd9c95567383",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 1.48,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,17 @@\n   void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n     assert namesystem.hasWriteLock();\n     final Iterator\u003cBlockInfo\u003e it \u003d storageInfo.getBlockIterator();\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     while(it.hasNext()) {\n       BlockInfo block \u003d it.next();\n+      // DatanodeStorageInfo must be removed using the iterator to avoid\n+      // ConcurrentModificationException in the underlying storage\n+      it.remove();\n       removeStoredBlock(block, node);\n       final Block b \u003d getBlockOnStorage(block, storageInfo);\n       if (b !\u003d null) {\n         invalidateBlocks.remove(node, b);\n       }\n     }\n     checkSafeMode();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n    assert namesystem.hasWriteLock();\n    final Iterator\u003cBlockInfo\u003e it \u003d storageInfo.getBlockIterator();\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    while(it.hasNext()) {\n      BlockInfo block \u003d it.next();\n      // DatanodeStorageInfo must be removed using the iterator to avoid\n      // ConcurrentModificationException in the underlying storage\n      it.remove();\n      removeStoredBlock(block, node);\n      final Block b \u003d getBlockOnStorage(block, storageInfo);\n      if (b !\u003d null) {\n        invalidateBlocks.remove(node, b);\n      }\n    }\n    checkSafeMode();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "a49cc74b4c72195dee1dfb6f9548e5e411dff553": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9129. Move the safemode block count into BlockManager. Contributed by Mingliang Liu.\n",
      "commitDate": "01/12/15 4:09 PM",
      "commitName": "a49cc74b4c72195dee1dfb6f9548e5e411dff553",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "01/12/15 1:05 PM",
      "commitNameOld": "830eb252aaa4fec7ef2ec38cb66f669e8e1ecaa5",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.13,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n     assert namesystem.hasWriteLock();\n     final Iterator\u003cBlockInfo\u003e it \u003d storageInfo.getBlockIterator();\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     while(it.hasNext()) {\n       BlockInfo block \u003d it.next();\n       removeStoredBlock(block, node);\n       final Block b \u003d getBlockOnStorage(block, storageInfo);\n       if (b !\u003d null) {\n         invalidateBlocks.remove(node, b);\n       }\n     }\n-    namesystem.checkSafeMode();\n+    checkSafeMode();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n    assert namesystem.hasWriteLock();\n    final Iterator\u003cBlockInfo\u003e it \u003d storageInfo.getBlockIterator();\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    while(it.hasNext()) {\n      BlockInfo block \u003d it.next();\n      removeStoredBlock(block, node);\n      final Block b \u003d getBlockOnStorage(block, storageInfo);\n      if (b !\u003d null) {\n        invalidateBlocks.remove(node, b);\n      }\n    }\n    checkSafeMode();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "663eba0ab1c73b45f98e46ffc87ad8fd91584046": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-8623. Refactor NameNode handling of invalid, corrupt, and under-recovery blocks. Contributed by Zhe Zhang.\"\n\nThis reverts commit de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5.\n",
      "commitDate": "06/08/15 10:21 AM",
      "commitName": "663eba0ab1c73b45f98e46ffc87ad8fd91584046",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "31/07/15 4:15 PM",
      "commitNameOld": "d311a38a6b32bbb210bd8748cfb65463e9c0740e",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 5.75,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n   void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n     assert namesystem.hasWriteLock();\n-    final Iterator\u003cBlockInfo\u003e it \u003d storageInfo.getBlockIterator();\n+    final Iterator\u003c? extends Block\u003e it \u003d storageInfo.getBlockIterator();\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     while(it.hasNext()) {\n-      BlockInfo block \u003d it.next();\n+      Block block \u003d it.next();\n       removeStoredBlock(block, node);\n       invalidateBlocks.remove(node, block);\n     }\n     namesystem.checkSafeMode();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n    assert namesystem.hasWriteLock();\n    final Iterator\u003c? extends Block\u003e it \u003d storageInfo.getBlockIterator();\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    while(it.hasNext()) {\n      Block block \u003d it.next();\n      removeStoredBlock(block, node);\n      invalidateBlocks.remove(node, block);\n    }\n    namesystem.checkSafeMode();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "5956d23b645e272748e2edca4c30231e729b96a9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8781. Erasure Coding: Correctly handle BlockManager#InvalidateBlocks for striped block. Contributed by Yi Liu.\n",
      "commitDate": "21/07/15 5:00 PM",
      "commitName": "5956d23b645e272748e2edca4c30231e729b96a9",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "19/07/15 7:18 PM",
      "commitNameOld": "06394e37601186d2bcff49ccea00712fda9b3579",
      "commitAuthorOld": "Walter Su",
      "daysBetweenCommits": 1.9,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,14 @@\n   void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n     assert namesystem.hasWriteLock();\n     final Iterator\u003cBlockInfo\u003e it \u003d storageInfo.getBlockIterator();\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     while(it.hasNext()) {\n       BlockInfo block \u003d it.next();\n       removeStoredBlock(block, node);\n-      invalidateBlocks.remove(node, block);\n+      final Block b \u003d getBlockOnStorage(block, storageInfo);\n+      if (b !\u003d null) {\n+        invalidateBlocks.remove(node, b);\n+      }\n     }\n     namesystem.checkSafeMode();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n    assert namesystem.hasWriteLock();\n    final Iterator\u003cBlockInfo\u003e it \u003d storageInfo.getBlockIterator();\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    while(it.hasNext()) {\n      BlockInfo block \u003d it.next();\n      removeStoredBlock(block, node);\n      final Block b \u003d getBlockOnStorage(block, storageInfo);\n      if (b !\u003d null) {\n        invalidateBlocks.remove(node, b);\n      }\n    }\n    namesystem.checkSafeMode();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8623. Refactor NameNode handling of invalid, corrupt, and under-recovery blocks. Contributed by Zhe Zhang.\n",
      "commitDate": "26/06/15 10:49 AM",
      "commitName": "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "24/06/15 2:42 PM",
      "commitNameOld": "afe9ea3c12e1f5a71922400eadb642960bc87ca1",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 1.84,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n   void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n     assert namesystem.hasWriteLock();\n-    final Iterator\u003c? extends Block\u003e it \u003d storageInfo.getBlockIterator();\n+    final Iterator\u003cBlockInfo\u003e it \u003d storageInfo.getBlockIterator();\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     while(it.hasNext()) {\n-      Block block \u003d it.next();\n+      BlockInfo block \u003d it.next();\n       removeStoredBlock(block, node);\n       invalidateBlocks.remove(node, block);\n     }\n     namesystem.checkSafeMode();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n    assert namesystem.hasWriteLock();\n    final Iterator\u003cBlockInfo\u003e it \u003d storageInfo.getBlockIterator();\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    while(it.hasNext()) {\n      BlockInfo block \u003d it.next();\n      removeStoredBlock(block, node);\n      invalidateBlocks.remove(node, block);\n    }\n    namesystem.checkSafeMode();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "abf833a7b228fff2bca4f69cd9df99d532380038": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7907. Erasure Coding: track invalid, corrupt, and under-recovery striped blocks in NameNode. Contributed by Jing Zhao.\n",
      "commitDate": "26/05/15 11:43 AM",
      "commitName": "abf833a7b228fff2bca4f69cd9df99d532380038",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "26/05/15 11:43 AM",
      "commitNameOld": "ea2e60fbcc79c65ec571224bd3f57c262a5d9114",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n   void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n     assert namesystem.hasWriteLock();\n-    final Iterator\u003c? extends Block\u003e it \u003d storageInfo.getBlockIterator();\n+    final Iterator\u003cBlockInfo\u003e it \u003d storageInfo.getBlockIterator();\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     while(it.hasNext()) {\n-      Block block \u003d it.next();\n+      BlockInfo block \u003d it.next();\n       removeStoredBlock(block, node);\n       invalidateBlocks.remove(node, block);\n     }\n     namesystem.checkSafeMode();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n    assert namesystem.hasWriteLock();\n    final Iterator\u003cBlockInfo\u003e it \u003d storageInfo.getBlockIterator();\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    while(it.hasNext()) {\n      BlockInfo block \u003d it.next();\n      removeStoredBlock(block, node);\n      invalidateBlocks.remove(node, block);\n    }\n    namesystem.checkSafeMode();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "41980c56d3c01d7a0ddc7deea2d89b7f28026722": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7208. NN doesn\u0027t schedule replication when a DN storage fails.  Contributed by Ming Ma\n",
      "commitDate": "15/10/14 8:44 PM",
      "commitName": "41980c56d3c01d7a0ddc7deea2d89b7f28026722",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "diff": "@@ -0,0 +1,11 @@\n+  void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n+    assert namesystem.hasWriteLock();\n+    final Iterator\u003c? extends Block\u003e it \u003d storageInfo.getBlockIterator();\n+    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n+    while(it.hasNext()) {\n+      Block block \u003d it.next();\n+      removeStoredBlock(block, node);\n+      invalidateBlocks.remove(node, block);\n+    }\n+    namesystem.checkSafeMode();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void removeBlocksAssociatedTo(final DatanodeStorageInfo storageInfo) {\n    assert namesystem.hasWriteLock();\n    final Iterator\u003c? extends Block\u003e it \u003d storageInfo.getBlockIterator();\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    while(it.hasNext()) {\n      Block block \u003d it.next();\n      removeStoredBlock(block, node);\n      invalidateBlocks.remove(node, block);\n    }\n    namesystem.checkSafeMode();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
    }
  }
}