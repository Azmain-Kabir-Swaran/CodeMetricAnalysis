{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LoadTypedBytes.java",
  "functionName": "printUsage",
  "functionId": "printUsage",
  "sourceFilePath": "hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/LoadTypedBytes.java",
  "functionStartLine": 91,
  "functionEndLine": 96,
  "numCommitsSeen": 6,
  "timeTaken": 4743,
  "changeHistory": [
    "730bc746f9ac6e045e94dc2bc622b16de0159b4b",
    "0a74610d1c7c7f183d2b2d0b7a775add53cf6c94",
    "26447229ba2c3d43db978c1b3ce95613669182ee",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "730bc746f9ac6e045e94dc2bc622b16de0159b4b": "Ybodychange",
    "0a74610d1c7c7f183d2b2d0b7a775add53cf6c94": "Ybodychange",
    "26447229ba2c3d43db978c1b3ce95613669182ee": "Yfilerename",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "730bc746f9ac6e045e94dc2bc622b16de0159b4b": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12930. Dynamic subcommands for hadoop shell scripts (aw)\n\nThis commit contains the following JIRA issues:\n\n    HADOOP-12931. bin/hadoop work for dynamic subcommands\n    HADOOP-12932. bin/yarn work for dynamic subcommands\n    HADOOP-12933. bin/hdfs work for dynamic subcommands\n    HADOOP-12934. bin/mapred work for dynamic subcommands\n    HADOOP-12935. API documentation for dynamic subcommands\n    HADOOP-12936. modify hadoop-tools to take advantage of dynamic subcommands\n    HADOOP-13086. enable daemonization of dynamic commands\n    HADOOP-13087. env var doc update for dynamic commands\n    HADOOP-13088. fix shellprofiles in hadoop-tools to allow replacement\n    HADOOP-13089. hadoop distcp adds client opts twice when dynamic\n    HADOOP-13094. hadoop-common unit tests for dynamic commands\n    HADOOP-13095. hadoop-hdfs unit tests for dynamic commands\n    HADOOP-13107. clean up how rumen is executed\n    HADOOP-13108. dynamic subcommands need a way to manipulate arguments\n    HADOOP-13110. add a streaming subcommand to mapred\n    HADOOP-13111. convert hadoop gridmix to be dynamic\n    HADOOP-13115. dynamic subcommand docs should talk about exit vs. continue program flow\n    HADOOP-13117. clarify daemonization and security vars for dynamic commands\n    HADOOP-13120. add a --debug message when dynamic commands have been used\n    HADOOP-13121. rename sub-project shellprofiles to match the rest of Hadoop\n    HADOOP-13129. fix typo in dynamic subcommand docs\n    HADOOP-13151. Underscores should be escaped in dynamic subcommands document\n    HADOOP-13153. fix typo in debug statement for dynamic subcommands\n",
      "commitDate": "16/05/16 5:54 PM",
      "commitName": "730bc746f9ac6e045e94dc2bc622b16de0159b4b",
      "commitAuthor": "Allen Wittenauer",
      "commitDateOld": "31/03/16 7:51 AM",
      "commitNameOld": "0a74610d1c7c7f183d2b2d0b7a775add53cf6c94",
      "commitAuthorOld": "Allen Wittenauer",
      "daysBetweenCommits": 46.42,
      "commitsBetweenForRepo": 287,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,6 @@\n   private void printUsage() {\n-    System.out.println(\"Usage: $HADOOP_HOME/bin/hadoop jar hadoop-streaming.jar\"\n-        + \" loadtb \u003cpath\u003e\");\n+    System.out.println(\"Usage: mapred streaming loadtb \u003cpath\u003e\");\n     System.out.println(\"  Reads typed bytes from standard input\" +\n     \" and stores them in a sequence file in\");\n     System.out.println(\"  the specified path\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void printUsage() {\n    System.out.println(\"Usage: mapred streaming loadtb \u003cpath\u003e\");\n    System.out.println(\"  Reads typed bytes from standard input\" +\n    \" and stores them in a sequence file in\");\n    System.out.println(\"  the specified path\");\n  }",
      "path": "hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/LoadTypedBytes.java",
      "extendedDetails": {}
    },
    "0a74610d1c7c7f183d2b2d0b7a775add53cf6c94": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11393. Revert HADOOP_PREFIX, go back to HADOOP_HOME (aw)\n",
      "commitDate": "31/03/16 7:51 AM",
      "commitName": "0a74610d1c7c7f183d2b2d0b7a775add53cf6c94",
      "commitAuthor": "Allen Wittenauer",
      "commitDateOld": "18/11/11 5:24 PM",
      "commitNameOld": "26447229ba2c3d43db978c1b3ce95613669182ee",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 1594.56,
      "commitsBetweenForRepo": 11193,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n   private void printUsage() {\n-    System.out.println(\"Usage: $HADOOP_PREFIX/bin/hadoop jar hadoop-streaming.jar\"\n+    System.out.println(\"Usage: $HADOOP_HOME/bin/hadoop jar hadoop-streaming.jar\"\n         + \" loadtb \u003cpath\u003e\");\n     System.out.println(\"  Reads typed bytes from standard input\" +\n     \" and stores them in a sequence file in\");\n     System.out.println(\"  the specified path\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void printUsage() {\n    System.out.println(\"Usage: $HADOOP_HOME/bin/hadoop jar hadoop-streaming.jar\"\n        + \" loadtb \u003cpath\u003e\");\n    System.out.println(\"  Reads typed bytes from standard input\" +\n    \" and stores them in a sequence file in\");\n    System.out.println(\"  the specified path\");\n  }",
      "path": "hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/LoadTypedBytes.java",
      "extendedDetails": {}
    },
    "26447229ba2c3d43db978c1b3ce95613669182ee": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7590. Mavenize streaming and MR examples. (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1203941 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/11/11 5:24 PM",
      "commitName": "26447229ba2c3d43db978c1b3ce95613669182ee",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "18/11/11 1:04 AM",
      "commitNameOld": "905a127850d5e0cba85c2e075f989fa0f5cf129a",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.68,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void printUsage() {\n    System.out.println(\"Usage: $HADOOP_PREFIX/bin/hadoop jar hadoop-streaming.jar\"\n        + \" loadtb \u003cpath\u003e\");\n    System.out.println(\"  Reads typed bytes from standard input\" +\n    \" and stores them in a sequence file in\");\n    System.out.println(\"  the specified path\");\n  }",
      "path": "hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/LoadTypedBytes.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/src/contrib/streaming/src/java/org/apache/hadoop/streaming/LoadTypedBytes.java",
        "newPath": "hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/LoadTypedBytes.java"
      }
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void printUsage() {\n    System.out.println(\"Usage: $HADOOP_PREFIX/bin/hadoop jar hadoop-streaming.jar\"\n        + \" loadtb \u003cpath\u003e\");\n    System.out.println(\"  Reads typed bytes from standard input\" +\n    \" and stores them in a sequence file in\");\n    System.out.println(\"  the specified path\");\n  }",
      "path": "hadoop-mapreduce-project/src/contrib/streaming/src/java/org/apache/hadoop/streaming/LoadTypedBytes.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/src/contrib/streaming/src/java/org/apache/hadoop/streaming/LoadTypedBytes.java",
        "newPath": "hadoop-mapreduce-project/src/contrib/streaming/src/java/org/apache/hadoop/streaming/LoadTypedBytes.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void printUsage() {\n    System.out.println(\"Usage: $HADOOP_PREFIX/bin/hadoop jar hadoop-streaming.jar\"\n        + \" loadtb \u003cpath\u003e\");\n    System.out.println(\"  Reads typed bytes from standard input\" +\n    \" and stores them in a sequence file in\");\n    System.out.println(\"  the specified path\");\n  }",
      "path": "hadoop-mapreduce/src/contrib/streaming/src/java/org/apache/hadoop/streaming/LoadTypedBytes.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/contrib/streaming/src/java/org/apache/hadoop/streaming/LoadTypedBytes.java",
        "newPath": "hadoop-mapreduce/src/contrib/streaming/src/java/org/apache/hadoop/streaming/LoadTypedBytes.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,7 @@\n+  private void printUsage() {\n+    System.out.println(\"Usage: $HADOOP_PREFIX/bin/hadoop jar hadoop-streaming.jar\"\n+        + \" loadtb \u003cpath\u003e\");\n+    System.out.println(\"  Reads typed bytes from standard input\" +\n+    \" and stores them in a sequence file in\");\n+    System.out.println(\"  the specified path\");\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void printUsage() {\n    System.out.println(\"Usage: $HADOOP_PREFIX/bin/hadoop jar hadoop-streaming.jar\"\n        + \" loadtb \u003cpath\u003e\");\n    System.out.println(\"  Reads typed bytes from standard input\" +\n    \" and stores them in a sequence file in\");\n    System.out.println(\"  the specified path\");\n  }",
      "path": "mapreduce/src/contrib/streaming/src/java/org/apache/hadoop/streaming/LoadTypedBytes.java"
    }
  }
}