{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RollingLevelDBTimelineStore.java",
  "functionName": "getEntityByTime",
  "functionId": "getEntityByTime___base-byte[]__entityType-String__limit-Long__starttime-Long__endtime-Long__fromId-String__fromTs-Long__secondaryFilters-Collection__NameValuePair____fields-EnumSet__Field____checkAcl-CheckAcl__usingPrimaryFilter-boolean",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/RollingLevelDBTimelineStore.java",
  "functionStartLine": 675,
  "functionEndLine": 839,
  "numCommitsSeen": 12,
  "timeTaken": 1872,
  "changeHistory": [
    "b4097b96a39bad6214b01989e7f2fb37dad70793",
    "01aca54a22c8586d232a8f79fe9977aeb8d09b83",
    "daf3e4ef8bf73cbe4a799d51b4765809cd81089f"
  ],
  "changeHistoryShort": {
    "b4097b96a39bad6214b01989e7f2fb37dad70793": "Ybodychange",
    "01aca54a22c8586d232a8f79fe9977aeb8d09b83": "Ybodychange",
    "daf3e4ef8bf73cbe4a799d51b4765809cd81089f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b4097b96a39bad6214b01989e7f2fb37dad70793": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9744. RollingLevelDBTimelineStore.getEntityByTime fails with NPE. Contributed by Prabhu Joseph.\n",
      "commitDate": "13/08/19 6:34 AM",
      "commitName": "b4097b96a39bad6214b01989e7f2fb37dad70793",
      "commitAuthor": "Abhishek Modi",
      "commitDateOld": "15/03/19 4:20 PM",
      "commitNameOld": "2064ca015d1584263aac0cc20c60b925a3aff612",
      "commitAuthorOld": "Eric Yang",
      "daysBetweenCommits": 150.59,
      "commitsBetweenForRepo": 1079,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,162 +1,165 @@\n   private TimelineEntities getEntityByTime(byte[] base, String entityType,\n       Long limit, Long starttime, Long endtime, String fromId, Long fromTs,\n       Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields,\n       CheckAcl checkAcl, boolean usingPrimaryFilter) throws IOException {\n     KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n     // only db keys matching the prefix (base + entity type) will be parsed\n     byte[] prefix \u003d kb.getBytesForLookup();\n     if (endtime \u003d\u003d null) {\n       // if end time is null, place no restriction on end time\n       endtime \u003d Long.MAX_VALUE;\n     }\n \n     // Sanitize the fields parameter\n     if (fields \u003d\u003d null) {\n       fields \u003d EnumSet.allOf(Field.class);\n     }\n \n     // construct a first key that will be seeked to using end time or fromId\n     long firstStartTime \u003d Long.MAX_VALUE;\n     byte[] first \u003d null;\n     if (fromId !\u003d null) {\n       Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n       if (fromIdStartTime \u003d\u003d null) {\n         // no start time for provided id, so return empty entities\n         return new TimelineEntities();\n       }\n       if (fromIdStartTime \u003c\u003d endtime) {\n         // if provided id\u0027s start time falls before the end of the window,\n         // use it to construct the seek key\n         firstStartTime \u003d fromIdStartTime;\n         first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime)).add(fromId)\n             .getBytesForLookup();\n       }\n     }\n     // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n     if (first \u003d\u003d null) {\n       firstStartTime \u003d endtime;\n       first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n     }\n     byte[] last \u003d null;\n     if (starttime !\u003d null) {\n       // if start time is not null, set a last key that will not be\n       // iterated past\n       last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n           .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n     }\n     if (limit \u003d\u003d null) {\n       // if limit is not specified, use the default\n       limit \u003d DEFAULT_LIMIT;\n     }\n \n     TimelineEntities entities \u003d new TimelineEntities();\n     RollingLevelDB rollingdb \u003d null;\n     if (usingPrimaryFilter) {\n       rollingdb \u003d indexdb;\n     } else {\n       rollingdb \u003d entitydb;\n     }\n \n     DB db \u003d rollingdb.getDBForStartTime(firstStartTime);\n     while (entities.getEntities().size() \u003c limit \u0026\u0026 db !\u003d null) {\n       try (DBIterator iterator \u003d db.iterator()) {\n         iterator.seek(first);\n \n         // iterate until one of the following conditions is met: limit is\n         // reached, there are no more keys, the key prefix no longer matches,\n         // or a start time has been specified and reached/exceeded\n         while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n           byte[] key \u003d iterator.peekNext().getKey();\n           if (!prefixMatches(prefix, prefix.length, key)\n               || (last !\u003d null \u0026\u0026 WritableComparator.compareBytes(key, 0,\n               key.length, last, 0, last.length) \u003e 0)) {\n             break;\n           }\n           // read the start time and entity id from the current key\n           KeyParser kp \u003d new KeyParser(key, prefix.length);\n           Long startTime \u003d kp.getNextLong();\n           String entityId \u003d kp.getNextString();\n \n           if (fromTs !\u003d null) {\n             long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n                 .getValue(), 0);\n             if (insertTime \u003e fromTs) {\n               byte[] firstKey \u003d key;\n               while (iterator.hasNext()) {\n                 key \u003d iterator.peekNext().getKey();\n                 iterator.next();\n                 if (!prefixMatches(firstKey, kp.getOffset(), key)) {\n                   break;\n                 }\n               }\n               continue;\n             }\n           }\n           // Even if other info and primary filter fields are not included, we\n           // still need to load them to match secondary filters when they are\n           // non-empty\n           EnumSet\u003cField\u003e queryFields \u003d EnumSet.copyOf(fields);\n           boolean addPrimaryFilters \u003d false;\n           boolean addOtherInfo \u003d false;\n           if (secondaryFilters !\u003d null \u0026\u0026 secondaryFilters.size() \u003e 0) {\n             if (!queryFields.contains(Field.PRIMARY_FILTERS)) {\n               queryFields.add(Field.PRIMARY_FILTERS);\n               addPrimaryFilters \u003d true;\n             }\n             if (!queryFields.contains(Field.OTHER_INFO)) {\n               queryFields.add(Field.OTHER_INFO);\n               addOtherInfo \u003d true;\n             }\n           }\n \n           // parse the entity that owns this key, iterating over all keys for\n           // the entity\n           TimelineEntity entity \u003d null;\n           if (usingPrimaryFilter) {\n             entity \u003d getEntity(entityId, entityType, queryFields);\n             iterator.next();\n           } else {\n             entity \u003d getEntity(entityId, entityType, startTime, queryFields,\n                 iterator, key, kp.getOffset());\n           }\n-          // determine if the retrieved entity matches the provided secondary\n-          // filters, and if so add it to the list of entities to return\n-          boolean filterPassed \u003d true;\n-          if (secondaryFilters !\u003d null) {\n-            for (NameValuePair filter : secondaryFilters) {\n-              Object v \u003d entity.getOtherInfo().get(filter.getName());\n-              if (v \u003d\u003d null) {\n-                Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n-                    .get(filter.getName());\n-                if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n+\n+          if (entity !\u003d null) {\n+            // determine if the retrieved entity matches the provided secondary\n+            // filters, and if so add it to the list of entities to return\n+            boolean filterPassed \u003d true;\n+            if (secondaryFilters !\u003d null) {\n+              for (NameValuePair filter : secondaryFilters) {\n+                Object v \u003d entity.getOtherInfo().get(filter.getName());\n+                if (v \u003d\u003d null) {\n+                  Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n+                          .get(filter.getName());\n+                  if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n+                    filterPassed \u003d false;\n+                    break;\n+                  }\n+                } else if (!v.equals(filter.getValue())) {\n                   filterPassed \u003d false;\n                   break;\n                 }\n-              } else if (!v.equals(filter.getValue())) {\n-                filterPassed \u003d false;\n-                break;\n               }\n             }\n-          }\n-          if (filterPassed) {\n-            if (entity.getDomainId() \u003d\u003d null) {\n-              entity.setDomainId(DEFAULT_DOMAIN_ID);\n-            }\n-            if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n-              // Remove primary filter and other info if they are added for\n-              // matching secondary filters\n-              if (addPrimaryFilters) {\n-                entity.setPrimaryFilters(null);\n+            if (filterPassed) {\n+              if (entity.getDomainId() \u003d\u003d null) {\n+                entity.setDomainId(DEFAULT_DOMAIN_ID);\n               }\n-              if (addOtherInfo) {\n-                entity.setOtherInfo(null);\n+              if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n+                // Remove primary filter and other info if they are added for\n+                // matching secondary filters\n+                if (addPrimaryFilters) {\n+                  entity.setPrimaryFilters(null);\n+                }\n+                if (addOtherInfo) {\n+                  entity.setOtherInfo(null);\n+                }\n+                entities.addEntity(entity);\n               }\n-              entities.addEntity(entity);\n             }\n           }\n         }\n         db \u003d rollingdb.getPreviousDB(db);\n       }\n     }\n     return entities;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private TimelineEntities getEntityByTime(byte[] base, String entityType,\n      Long limit, Long starttime, Long endtime, String fromId, Long fromTs,\n      Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields,\n      CheckAcl checkAcl, boolean usingPrimaryFilter) throws IOException {\n    KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n    // only db keys matching the prefix (base + entity type) will be parsed\n    byte[] prefix \u003d kb.getBytesForLookup();\n    if (endtime \u003d\u003d null) {\n      // if end time is null, place no restriction on end time\n      endtime \u003d Long.MAX_VALUE;\n    }\n\n    // Sanitize the fields parameter\n    if (fields \u003d\u003d null) {\n      fields \u003d EnumSet.allOf(Field.class);\n    }\n\n    // construct a first key that will be seeked to using end time or fromId\n    long firstStartTime \u003d Long.MAX_VALUE;\n    byte[] first \u003d null;\n    if (fromId !\u003d null) {\n      Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n      if (fromIdStartTime \u003d\u003d null) {\n        // no start time for provided id, so return empty entities\n        return new TimelineEntities();\n      }\n      if (fromIdStartTime \u003c\u003d endtime) {\n        // if provided id\u0027s start time falls before the end of the window,\n        // use it to construct the seek key\n        firstStartTime \u003d fromIdStartTime;\n        first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime)).add(fromId)\n            .getBytesForLookup();\n      }\n    }\n    // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n    if (first \u003d\u003d null) {\n      firstStartTime \u003d endtime;\n      first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n    }\n    byte[] last \u003d null;\n    if (starttime !\u003d null) {\n      // if start time is not null, set a last key that will not be\n      // iterated past\n      last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n          .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n    }\n    if (limit \u003d\u003d null) {\n      // if limit is not specified, use the default\n      limit \u003d DEFAULT_LIMIT;\n    }\n\n    TimelineEntities entities \u003d new TimelineEntities();\n    RollingLevelDB rollingdb \u003d null;\n    if (usingPrimaryFilter) {\n      rollingdb \u003d indexdb;\n    } else {\n      rollingdb \u003d entitydb;\n    }\n\n    DB db \u003d rollingdb.getDBForStartTime(firstStartTime);\n    while (entities.getEntities().size() \u003c limit \u0026\u0026 db !\u003d null) {\n      try (DBIterator iterator \u003d db.iterator()) {\n        iterator.seek(first);\n\n        // iterate until one of the following conditions is met: limit is\n        // reached, there are no more keys, the key prefix no longer matches,\n        // or a start time has been specified and reached/exceeded\n        while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n          byte[] key \u003d iterator.peekNext().getKey();\n          if (!prefixMatches(prefix, prefix.length, key)\n              || (last !\u003d null \u0026\u0026 WritableComparator.compareBytes(key, 0,\n              key.length, last, 0, last.length) \u003e 0)) {\n            break;\n          }\n          // read the start time and entity id from the current key\n          KeyParser kp \u003d new KeyParser(key, prefix.length);\n          Long startTime \u003d kp.getNextLong();\n          String entityId \u003d kp.getNextString();\n\n          if (fromTs !\u003d null) {\n            long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n                .getValue(), 0);\n            if (insertTime \u003e fromTs) {\n              byte[] firstKey \u003d key;\n              while (iterator.hasNext()) {\n                key \u003d iterator.peekNext().getKey();\n                iterator.next();\n                if (!prefixMatches(firstKey, kp.getOffset(), key)) {\n                  break;\n                }\n              }\n              continue;\n            }\n          }\n          // Even if other info and primary filter fields are not included, we\n          // still need to load them to match secondary filters when they are\n          // non-empty\n          EnumSet\u003cField\u003e queryFields \u003d EnumSet.copyOf(fields);\n          boolean addPrimaryFilters \u003d false;\n          boolean addOtherInfo \u003d false;\n          if (secondaryFilters !\u003d null \u0026\u0026 secondaryFilters.size() \u003e 0) {\n            if (!queryFields.contains(Field.PRIMARY_FILTERS)) {\n              queryFields.add(Field.PRIMARY_FILTERS);\n              addPrimaryFilters \u003d true;\n            }\n            if (!queryFields.contains(Field.OTHER_INFO)) {\n              queryFields.add(Field.OTHER_INFO);\n              addOtherInfo \u003d true;\n            }\n          }\n\n          // parse the entity that owns this key, iterating over all keys for\n          // the entity\n          TimelineEntity entity \u003d null;\n          if (usingPrimaryFilter) {\n            entity \u003d getEntity(entityId, entityType, queryFields);\n            iterator.next();\n          } else {\n            entity \u003d getEntity(entityId, entityType, startTime, queryFields,\n                iterator, key, kp.getOffset());\n          }\n\n          if (entity !\u003d null) {\n            // determine if the retrieved entity matches the provided secondary\n            // filters, and if so add it to the list of entities to return\n            boolean filterPassed \u003d true;\n            if (secondaryFilters !\u003d null) {\n              for (NameValuePair filter : secondaryFilters) {\n                Object v \u003d entity.getOtherInfo().get(filter.getName());\n                if (v \u003d\u003d null) {\n                  Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                          .get(filter.getName());\n                  if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                    filterPassed \u003d false;\n                    break;\n                  }\n                } else if (!v.equals(filter.getValue())) {\n                  filterPassed \u003d false;\n                  break;\n                }\n              }\n            }\n            if (filterPassed) {\n              if (entity.getDomainId() \u003d\u003d null) {\n                entity.setDomainId(DEFAULT_DOMAIN_ID);\n              }\n              if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n                // Remove primary filter and other info if they are added for\n                // matching secondary filters\n                if (addPrimaryFilters) {\n                  entity.setPrimaryFilters(null);\n                }\n                if (addOtherInfo) {\n                  entity.setOtherInfo(null);\n                }\n                entities.addEntity(entity);\n              }\n            }\n          }\n        }\n        db \u003d rollingdb.getPreviousDB(db);\n      }\n    }\n    return entities;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/RollingLevelDBTimelineStore.java",
      "extendedDetails": {}
    },
    "01aca54a22c8586d232a8f79fe9977aeb8d09b83": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5368. Memory leak in timeline server (Jonathan Eagles via Varun Saxena)\n",
      "commitDate": "28/03/17 1:23 PM",
      "commitName": "01aca54a22c8586d232a8f79fe9977aeb8d09b83",
      "commitAuthor": "Varun Saxena",
      "commitDateOld": "20/07/16 8:36 AM",
      "commitNameOld": "1c9d2ab503ea5a3f16757351af9603041059b390",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 251.2,
      "commitsBetweenForRepo": 1583,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,166 +1,162 @@\n   private TimelineEntities getEntityByTime(byte[] base, String entityType,\n       Long limit, Long starttime, Long endtime, String fromId, Long fromTs,\n       Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields,\n       CheckAcl checkAcl, boolean usingPrimaryFilter) throws IOException {\n-    DBIterator iterator \u003d null;\n-    try {\n-      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n-      // only db keys matching the prefix (base + entity type) will be parsed\n-      byte[] prefix \u003d kb.getBytesForLookup();\n-      if (endtime \u003d\u003d null) {\n-        // if end time is null, place no restriction on end time\n-        endtime \u003d Long.MAX_VALUE;\n-      }\n+    KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n+    // only db keys matching the prefix (base + entity type) will be parsed\n+    byte[] prefix \u003d kb.getBytesForLookup();\n+    if (endtime \u003d\u003d null) {\n+      // if end time is null, place no restriction on end time\n+      endtime \u003d Long.MAX_VALUE;\n+    }\n \n-      // Sanitize the fields parameter\n-      if (fields \u003d\u003d null) {\n-        fields \u003d EnumSet.allOf(Field.class);\n-      }\n+    // Sanitize the fields parameter\n+    if (fields \u003d\u003d null) {\n+      fields \u003d EnumSet.allOf(Field.class);\n+    }\n \n-      // construct a first key that will be seeked to using end time or fromId\n-      long firstStartTime \u003d Long.MAX_VALUE;\n-      byte[] first \u003d null;\n-      if (fromId !\u003d null) {\n-        Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n-        if (fromIdStartTime \u003d\u003d null) {\n-          // no start time for provided id, so return empty entities\n-          return new TimelineEntities();\n-        }\n-        if (fromIdStartTime \u003c\u003d endtime) {\n-          // if provided id\u0027s start time falls before the end of the window,\n-          // use it to construct the seek key\n-          firstStartTime \u003d fromIdStartTime;\n-          first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime)).add(fromId)\n-              .getBytesForLookup();\n-        }\n+    // construct a first key that will be seeked to using end time or fromId\n+    long firstStartTime \u003d Long.MAX_VALUE;\n+    byte[] first \u003d null;\n+    if (fromId !\u003d null) {\n+      Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n+      if (fromIdStartTime \u003d\u003d null) {\n+        // no start time for provided id, so return empty entities\n+        return new TimelineEntities();\n       }\n-      // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n-      if (first \u003d\u003d null) {\n-        firstStartTime \u003d endtime;\n-        first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n+      if (fromIdStartTime \u003c\u003d endtime) {\n+        // if provided id\u0027s start time falls before the end of the window,\n+        // use it to construct the seek key\n+        firstStartTime \u003d fromIdStartTime;\n+        first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime)).add(fromId)\n+            .getBytesForLookup();\n       }\n-      byte[] last \u003d null;\n-      if (starttime !\u003d null) {\n-        // if start time is not null, set a last key that will not be\n-        // iterated past\n-        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n-            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n-      }\n-      if (limit \u003d\u003d null) {\n-        // if limit is not specified, use the default\n-        limit \u003d DEFAULT_LIMIT;\n-      }\n+    }\n+    // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n+    if (first \u003d\u003d null) {\n+      firstStartTime \u003d endtime;\n+      first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n+    }\n+    byte[] last \u003d null;\n+    if (starttime !\u003d null) {\n+      // if start time is not null, set a last key that will not be\n+      // iterated past\n+      last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n+          .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n+    }\n+    if (limit \u003d\u003d null) {\n+      // if limit is not specified, use the default\n+      limit \u003d DEFAULT_LIMIT;\n+    }\n \n-      TimelineEntities entities \u003d new TimelineEntities();\n-      RollingLevelDB rollingdb \u003d null;\n-      if (usingPrimaryFilter) {\n-        rollingdb \u003d indexdb;\n-      } else {\n-        rollingdb \u003d entitydb;\n-      }\n+    TimelineEntities entities \u003d new TimelineEntities();\n+    RollingLevelDB rollingdb \u003d null;\n+    if (usingPrimaryFilter) {\n+      rollingdb \u003d indexdb;\n+    } else {\n+      rollingdb \u003d entitydb;\n+    }\n \n-      DB db \u003d rollingdb.getDBForStartTime(firstStartTime);\n-      while (entities.getEntities().size() \u003c limit \u0026\u0026 db !\u003d null) {\n-        iterator \u003d db.iterator();\n+    DB db \u003d rollingdb.getDBForStartTime(firstStartTime);\n+    while (entities.getEntities().size() \u003c limit \u0026\u0026 db !\u003d null) {\n+      try (DBIterator iterator \u003d db.iterator()) {\n         iterator.seek(first);\n \n         // iterate until one of the following conditions is met: limit is\n         // reached, there are no more keys, the key prefix no longer matches,\n         // or a start time has been specified and reached/exceeded\n         while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n           byte[] key \u003d iterator.peekNext().getKey();\n           if (!prefixMatches(prefix, prefix.length, key)\n               || (last !\u003d null \u0026\u0026 WritableComparator.compareBytes(key, 0,\n-                  key.length, last, 0, last.length) \u003e 0)) {\n+              key.length, last, 0, last.length) \u003e 0)) {\n             break;\n           }\n           // read the start time and entity id from the current key\n           KeyParser kp \u003d new KeyParser(key, prefix.length);\n           Long startTime \u003d kp.getNextLong();\n           String entityId \u003d kp.getNextString();\n \n           if (fromTs !\u003d null) {\n             long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n                 .getValue(), 0);\n             if (insertTime \u003e fromTs) {\n               byte[] firstKey \u003d key;\n               while (iterator.hasNext()) {\n                 key \u003d iterator.peekNext().getKey();\n                 iterator.next();\n                 if (!prefixMatches(firstKey, kp.getOffset(), key)) {\n                   break;\n                 }\n               }\n               continue;\n             }\n           }\n           // Even if other info and primary filter fields are not included, we\n           // still need to load them to match secondary filters when they are\n           // non-empty\n           EnumSet\u003cField\u003e queryFields \u003d EnumSet.copyOf(fields);\n           boolean addPrimaryFilters \u003d false;\n           boolean addOtherInfo \u003d false;\n           if (secondaryFilters !\u003d null \u0026\u0026 secondaryFilters.size() \u003e 0) {\n             if (!queryFields.contains(Field.PRIMARY_FILTERS)) {\n               queryFields.add(Field.PRIMARY_FILTERS);\n               addPrimaryFilters \u003d true;\n             }\n             if (!queryFields.contains(Field.OTHER_INFO)) {\n               queryFields.add(Field.OTHER_INFO);\n               addOtherInfo \u003d true;\n             }\n           }\n \n           // parse the entity that owns this key, iterating over all keys for\n           // the entity\n           TimelineEntity entity \u003d null;\n           if (usingPrimaryFilter) {\n             entity \u003d getEntity(entityId, entityType, queryFields);\n             iterator.next();\n           } else {\n             entity \u003d getEntity(entityId, entityType, startTime, queryFields,\n                 iterator, key, kp.getOffset());\n           }\n           // determine if the retrieved entity matches the provided secondary\n           // filters, and if so add it to the list of entities to return\n           boolean filterPassed \u003d true;\n           if (secondaryFilters !\u003d null) {\n             for (NameValuePair filter : secondaryFilters) {\n               Object v \u003d entity.getOtherInfo().get(filter.getName());\n               if (v \u003d\u003d null) {\n                 Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                     .get(filter.getName());\n                 if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                   filterPassed \u003d false;\n                   break;\n                 }\n               } else if (!v.equals(filter.getValue())) {\n                 filterPassed \u003d false;\n                 break;\n               }\n             }\n           }\n           if (filterPassed) {\n             if (entity.getDomainId() \u003d\u003d null) {\n               entity.setDomainId(DEFAULT_DOMAIN_ID);\n             }\n             if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n               // Remove primary filter and other info if they are added for\n               // matching secondary filters\n               if (addPrimaryFilters) {\n                 entity.setPrimaryFilters(null);\n               }\n               if (addOtherInfo) {\n                 entity.setOtherInfo(null);\n               }\n               entities.addEntity(entity);\n             }\n           }\n         }\n         db \u003d rollingdb.getPreviousDB(db);\n       }\n-      return entities;\n-    } finally {\n-      IOUtils.cleanup(LOG, iterator);\n     }\n+    return entities;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private TimelineEntities getEntityByTime(byte[] base, String entityType,\n      Long limit, Long starttime, Long endtime, String fromId, Long fromTs,\n      Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields,\n      CheckAcl checkAcl, boolean usingPrimaryFilter) throws IOException {\n    KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n    // only db keys matching the prefix (base + entity type) will be parsed\n    byte[] prefix \u003d kb.getBytesForLookup();\n    if (endtime \u003d\u003d null) {\n      // if end time is null, place no restriction on end time\n      endtime \u003d Long.MAX_VALUE;\n    }\n\n    // Sanitize the fields parameter\n    if (fields \u003d\u003d null) {\n      fields \u003d EnumSet.allOf(Field.class);\n    }\n\n    // construct a first key that will be seeked to using end time or fromId\n    long firstStartTime \u003d Long.MAX_VALUE;\n    byte[] first \u003d null;\n    if (fromId !\u003d null) {\n      Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n      if (fromIdStartTime \u003d\u003d null) {\n        // no start time for provided id, so return empty entities\n        return new TimelineEntities();\n      }\n      if (fromIdStartTime \u003c\u003d endtime) {\n        // if provided id\u0027s start time falls before the end of the window,\n        // use it to construct the seek key\n        firstStartTime \u003d fromIdStartTime;\n        first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime)).add(fromId)\n            .getBytesForLookup();\n      }\n    }\n    // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n    if (first \u003d\u003d null) {\n      firstStartTime \u003d endtime;\n      first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n    }\n    byte[] last \u003d null;\n    if (starttime !\u003d null) {\n      // if start time is not null, set a last key that will not be\n      // iterated past\n      last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n          .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n    }\n    if (limit \u003d\u003d null) {\n      // if limit is not specified, use the default\n      limit \u003d DEFAULT_LIMIT;\n    }\n\n    TimelineEntities entities \u003d new TimelineEntities();\n    RollingLevelDB rollingdb \u003d null;\n    if (usingPrimaryFilter) {\n      rollingdb \u003d indexdb;\n    } else {\n      rollingdb \u003d entitydb;\n    }\n\n    DB db \u003d rollingdb.getDBForStartTime(firstStartTime);\n    while (entities.getEntities().size() \u003c limit \u0026\u0026 db !\u003d null) {\n      try (DBIterator iterator \u003d db.iterator()) {\n        iterator.seek(first);\n\n        // iterate until one of the following conditions is met: limit is\n        // reached, there are no more keys, the key prefix no longer matches,\n        // or a start time has been specified and reached/exceeded\n        while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n          byte[] key \u003d iterator.peekNext().getKey();\n          if (!prefixMatches(prefix, prefix.length, key)\n              || (last !\u003d null \u0026\u0026 WritableComparator.compareBytes(key, 0,\n              key.length, last, 0, last.length) \u003e 0)) {\n            break;\n          }\n          // read the start time and entity id from the current key\n          KeyParser kp \u003d new KeyParser(key, prefix.length);\n          Long startTime \u003d kp.getNextLong();\n          String entityId \u003d kp.getNextString();\n\n          if (fromTs !\u003d null) {\n            long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n                .getValue(), 0);\n            if (insertTime \u003e fromTs) {\n              byte[] firstKey \u003d key;\n              while (iterator.hasNext()) {\n                key \u003d iterator.peekNext().getKey();\n                iterator.next();\n                if (!prefixMatches(firstKey, kp.getOffset(), key)) {\n                  break;\n                }\n              }\n              continue;\n            }\n          }\n          // Even if other info and primary filter fields are not included, we\n          // still need to load them to match secondary filters when they are\n          // non-empty\n          EnumSet\u003cField\u003e queryFields \u003d EnumSet.copyOf(fields);\n          boolean addPrimaryFilters \u003d false;\n          boolean addOtherInfo \u003d false;\n          if (secondaryFilters !\u003d null \u0026\u0026 secondaryFilters.size() \u003e 0) {\n            if (!queryFields.contains(Field.PRIMARY_FILTERS)) {\n              queryFields.add(Field.PRIMARY_FILTERS);\n              addPrimaryFilters \u003d true;\n            }\n            if (!queryFields.contains(Field.OTHER_INFO)) {\n              queryFields.add(Field.OTHER_INFO);\n              addOtherInfo \u003d true;\n            }\n          }\n\n          // parse the entity that owns this key, iterating over all keys for\n          // the entity\n          TimelineEntity entity \u003d null;\n          if (usingPrimaryFilter) {\n            entity \u003d getEntity(entityId, entityType, queryFields);\n            iterator.next();\n          } else {\n            entity \u003d getEntity(entityId, entityType, startTime, queryFields,\n                iterator, key, kp.getOffset());\n          }\n          // determine if the retrieved entity matches the provided secondary\n          // filters, and if so add it to the list of entities to return\n          boolean filterPassed \u003d true;\n          if (secondaryFilters !\u003d null) {\n            for (NameValuePair filter : secondaryFilters) {\n              Object v \u003d entity.getOtherInfo().get(filter.getName());\n              if (v \u003d\u003d null) {\n                Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                    .get(filter.getName());\n                if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                  filterPassed \u003d false;\n                  break;\n                }\n              } else if (!v.equals(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            }\n          }\n          if (filterPassed) {\n            if (entity.getDomainId() \u003d\u003d null) {\n              entity.setDomainId(DEFAULT_DOMAIN_ID);\n            }\n            if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n              // Remove primary filter and other info if they are added for\n              // matching secondary filters\n              if (addPrimaryFilters) {\n                entity.setPrimaryFilters(null);\n              }\n              if (addOtherInfo) {\n                entity.setOtherInfo(null);\n              }\n              entities.addEntity(entity);\n            }\n          }\n        }\n        db \u003d rollingdb.getPreviousDB(db);\n      }\n    }\n    return entities;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/RollingLevelDBTimelineStore.java",
      "extendedDetails": {}
    },
    "daf3e4ef8bf73cbe4a799d51b4765809cd81089f": {
      "type": "Yintroduced",
      "commitMessage": "YARN-3448. Added a rolling time-to-live LevelDB timeline store implementation. Contributed by Jonathan Eagles.\n",
      "commitDate": "07/05/15 10:01 AM",
      "commitName": "daf3e4ef8bf73cbe4a799d51b4765809cd81089f",
      "commitAuthor": "Zhijie Shen",
      "diff": "@@ -0,0 +1,166 @@\n+  private TimelineEntities getEntityByTime(byte[] base, String entityType,\n+      Long limit, Long starttime, Long endtime, String fromId, Long fromTs,\n+      Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields,\n+      CheckAcl checkAcl, boolean usingPrimaryFilter) throws IOException {\n+    DBIterator iterator \u003d null;\n+    try {\n+      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n+      // only db keys matching the prefix (base + entity type) will be parsed\n+      byte[] prefix \u003d kb.getBytesForLookup();\n+      if (endtime \u003d\u003d null) {\n+        // if end time is null, place no restriction on end time\n+        endtime \u003d Long.MAX_VALUE;\n+      }\n+\n+      // Sanitize the fields parameter\n+      if (fields \u003d\u003d null) {\n+        fields \u003d EnumSet.allOf(Field.class);\n+      }\n+\n+      // construct a first key that will be seeked to using end time or fromId\n+      long firstStartTime \u003d Long.MAX_VALUE;\n+      byte[] first \u003d null;\n+      if (fromId !\u003d null) {\n+        Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n+        if (fromIdStartTime \u003d\u003d null) {\n+          // no start time for provided id, so return empty entities\n+          return new TimelineEntities();\n+        }\n+        if (fromIdStartTime \u003c\u003d endtime) {\n+          // if provided id\u0027s start time falls before the end of the window,\n+          // use it to construct the seek key\n+          firstStartTime \u003d fromIdStartTime;\n+          first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime)).add(fromId)\n+              .getBytesForLookup();\n+        }\n+      }\n+      // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n+      if (first \u003d\u003d null) {\n+        firstStartTime \u003d endtime;\n+        first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n+      }\n+      byte[] last \u003d null;\n+      if (starttime !\u003d null) {\n+        // if start time is not null, set a last key that will not be\n+        // iterated past\n+        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n+            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n+      }\n+      if (limit \u003d\u003d null) {\n+        // if limit is not specified, use the default\n+        limit \u003d DEFAULT_LIMIT;\n+      }\n+\n+      TimelineEntities entities \u003d new TimelineEntities();\n+      RollingLevelDB rollingdb \u003d null;\n+      if (usingPrimaryFilter) {\n+        rollingdb \u003d indexdb;\n+      } else {\n+        rollingdb \u003d entitydb;\n+      }\n+\n+      DB db \u003d rollingdb.getDBForStartTime(firstStartTime);\n+      while (entities.getEntities().size() \u003c limit \u0026\u0026 db !\u003d null) {\n+        iterator \u003d db.iterator();\n+        iterator.seek(first);\n+\n+        // iterate until one of the following conditions is met: limit is\n+        // reached, there are no more keys, the key prefix no longer matches,\n+        // or a start time has been specified and reached/exceeded\n+        while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n+          byte[] key \u003d iterator.peekNext().getKey();\n+          if (!prefixMatches(prefix, prefix.length, key)\n+              || (last !\u003d null \u0026\u0026 WritableComparator.compareBytes(key, 0,\n+                  key.length, last, 0, last.length) \u003e 0)) {\n+            break;\n+          }\n+          // read the start time and entity id from the current key\n+          KeyParser kp \u003d new KeyParser(key, prefix.length);\n+          Long startTime \u003d kp.getNextLong();\n+          String entityId \u003d kp.getNextString();\n+\n+          if (fromTs !\u003d null) {\n+            long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n+                .getValue(), 0);\n+            if (insertTime \u003e fromTs) {\n+              byte[] firstKey \u003d key;\n+              while (iterator.hasNext()) {\n+                key \u003d iterator.peekNext().getKey();\n+                iterator.next();\n+                if (!prefixMatches(firstKey, kp.getOffset(), key)) {\n+                  break;\n+                }\n+              }\n+              continue;\n+            }\n+          }\n+          // Even if other info and primary filter fields are not included, we\n+          // still need to load them to match secondary filters when they are\n+          // non-empty\n+          EnumSet\u003cField\u003e queryFields \u003d EnumSet.copyOf(fields);\n+          boolean addPrimaryFilters \u003d false;\n+          boolean addOtherInfo \u003d false;\n+          if (secondaryFilters !\u003d null \u0026\u0026 secondaryFilters.size() \u003e 0) {\n+            if (!queryFields.contains(Field.PRIMARY_FILTERS)) {\n+              queryFields.add(Field.PRIMARY_FILTERS);\n+              addPrimaryFilters \u003d true;\n+            }\n+            if (!queryFields.contains(Field.OTHER_INFO)) {\n+              queryFields.add(Field.OTHER_INFO);\n+              addOtherInfo \u003d true;\n+            }\n+          }\n+\n+          // parse the entity that owns this key, iterating over all keys for\n+          // the entity\n+          TimelineEntity entity \u003d null;\n+          if (usingPrimaryFilter) {\n+            entity \u003d getEntity(entityId, entityType, queryFields);\n+            iterator.next();\n+          } else {\n+            entity \u003d getEntity(entityId, entityType, startTime, queryFields,\n+                iterator, key, kp.getOffset());\n+          }\n+          // determine if the retrieved entity matches the provided secondary\n+          // filters, and if so add it to the list of entities to return\n+          boolean filterPassed \u003d true;\n+          if (secondaryFilters !\u003d null) {\n+            for (NameValuePair filter : secondaryFilters) {\n+              Object v \u003d entity.getOtherInfo().get(filter.getName());\n+              if (v \u003d\u003d null) {\n+                Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n+                    .get(filter.getName());\n+                if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n+                  filterPassed \u003d false;\n+                  break;\n+                }\n+              } else if (!v.equals(filter.getValue())) {\n+                filterPassed \u003d false;\n+                break;\n+              }\n+            }\n+          }\n+          if (filterPassed) {\n+            if (entity.getDomainId() \u003d\u003d null) {\n+              entity.setDomainId(DEFAULT_DOMAIN_ID);\n+            }\n+            if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n+              // Remove primary filter and other info if they are added for\n+              // matching secondary filters\n+              if (addPrimaryFilters) {\n+                entity.setPrimaryFilters(null);\n+              }\n+              if (addOtherInfo) {\n+                entity.setOtherInfo(null);\n+              }\n+              entities.addEntity(entity);\n+            }\n+          }\n+        }\n+        db \u003d rollingdb.getPreviousDB(db);\n+      }\n+      return entities;\n+    } finally {\n+      IOUtils.cleanup(LOG, iterator);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private TimelineEntities getEntityByTime(byte[] base, String entityType,\n      Long limit, Long starttime, Long endtime, String fromId, Long fromTs,\n      Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields,\n      CheckAcl checkAcl, boolean usingPrimaryFilter) throws IOException {\n    DBIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n\n      // Sanitize the fields parameter\n      if (fields \u003d\u003d null) {\n        fields \u003d EnumSet.allOf(Field.class);\n      }\n\n      // construct a first key that will be seeked to using end time or fromId\n      long firstStartTime \u003d Long.MAX_VALUE;\n      byte[] first \u003d null;\n      if (fromId !\u003d null) {\n        Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n        if (fromIdStartTime \u003d\u003d null) {\n          // no start time for provided id, so return empty entities\n          return new TimelineEntities();\n        }\n        if (fromIdStartTime \u003c\u003d endtime) {\n          // if provided id\u0027s start time falls before the end of the window,\n          // use it to construct the seek key\n          firstStartTime \u003d fromIdStartTime;\n          first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime)).add(fromId)\n              .getBytesForLookup();\n        }\n      }\n      // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n      if (first \u003d\u003d null) {\n        firstStartTime \u003d endtime;\n        first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n      }\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      TimelineEntities entities \u003d new TimelineEntities();\n      RollingLevelDB rollingdb \u003d null;\n      if (usingPrimaryFilter) {\n        rollingdb \u003d indexdb;\n      } else {\n        rollingdb \u003d entitydb;\n      }\n\n      DB db \u003d rollingdb.getDBForStartTime(firstStartTime);\n      while (entities.getEntities().size() \u003c limit \u0026\u0026 db !\u003d null) {\n        iterator \u003d db.iterator();\n        iterator.seek(first);\n\n        // iterate until one of the following conditions is met: limit is\n        // reached, there are no more keys, the key prefix no longer matches,\n        // or a start time has been specified and reached/exceeded\n        while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n          byte[] key \u003d iterator.peekNext().getKey();\n          if (!prefixMatches(prefix, prefix.length, key)\n              || (last !\u003d null \u0026\u0026 WritableComparator.compareBytes(key, 0,\n                  key.length, last, 0, last.length) \u003e 0)) {\n            break;\n          }\n          // read the start time and entity id from the current key\n          KeyParser kp \u003d new KeyParser(key, prefix.length);\n          Long startTime \u003d kp.getNextLong();\n          String entityId \u003d kp.getNextString();\n\n          if (fromTs !\u003d null) {\n            long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n                .getValue(), 0);\n            if (insertTime \u003e fromTs) {\n              byte[] firstKey \u003d key;\n              while (iterator.hasNext()) {\n                key \u003d iterator.peekNext().getKey();\n                iterator.next();\n                if (!prefixMatches(firstKey, kp.getOffset(), key)) {\n                  break;\n                }\n              }\n              continue;\n            }\n          }\n          // Even if other info and primary filter fields are not included, we\n          // still need to load them to match secondary filters when they are\n          // non-empty\n          EnumSet\u003cField\u003e queryFields \u003d EnumSet.copyOf(fields);\n          boolean addPrimaryFilters \u003d false;\n          boolean addOtherInfo \u003d false;\n          if (secondaryFilters !\u003d null \u0026\u0026 secondaryFilters.size() \u003e 0) {\n            if (!queryFields.contains(Field.PRIMARY_FILTERS)) {\n              queryFields.add(Field.PRIMARY_FILTERS);\n              addPrimaryFilters \u003d true;\n            }\n            if (!queryFields.contains(Field.OTHER_INFO)) {\n              queryFields.add(Field.OTHER_INFO);\n              addOtherInfo \u003d true;\n            }\n          }\n\n          // parse the entity that owns this key, iterating over all keys for\n          // the entity\n          TimelineEntity entity \u003d null;\n          if (usingPrimaryFilter) {\n            entity \u003d getEntity(entityId, entityType, queryFields);\n            iterator.next();\n          } else {\n            entity \u003d getEntity(entityId, entityType, startTime, queryFields,\n                iterator, key, kp.getOffset());\n          }\n          // determine if the retrieved entity matches the provided secondary\n          // filters, and if so add it to the list of entities to return\n          boolean filterPassed \u003d true;\n          if (secondaryFilters !\u003d null) {\n            for (NameValuePair filter : secondaryFilters) {\n              Object v \u003d entity.getOtherInfo().get(filter.getName());\n              if (v \u003d\u003d null) {\n                Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                    .get(filter.getName());\n                if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                  filterPassed \u003d false;\n                  break;\n                }\n              } else if (!v.equals(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            }\n          }\n          if (filterPassed) {\n            if (entity.getDomainId() \u003d\u003d null) {\n              entity.setDomainId(DEFAULT_DOMAIN_ID);\n            }\n            if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n              // Remove primary filter and other info if they are added for\n              // matching secondary filters\n              if (addPrimaryFilters) {\n                entity.setPrimaryFilters(null);\n              }\n              if (addOtherInfo) {\n                entity.setOtherInfo(null);\n              }\n              entities.addEntity(entity);\n            }\n          }\n        }\n        db \u003d rollingdb.getPreviousDB(db);\n      }\n      return entities;\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/RollingLevelDBTimelineStore.java"
    }
  }
}