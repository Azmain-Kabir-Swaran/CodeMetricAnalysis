{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSDirSatisfyStoragePolicyOp.java",
  "functionName": "satisfyStoragePolicy",
  "functionId": "satisfyStoragePolicy___fsd-FSDirectory__bm-BlockManager__src-String__logRetryCache-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
  "functionStartLine": 65,
  "functionEndLine": 116,
  "numCommitsSeen": 79,
  "timeTaken": 8151,
  "changeHistory": [
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
    "d638a7dc0363dbe07deb8c389116132814267b10",
    "5ce332dc9a072f8850ab71ba16898faf8e866c06",
    "6215e35bb633706753a464ad3e8633366e6a10b2",
    "5179d99b7e1faeac1ce041967480115913d9f795",
    "b67ae6d9d741e79ccf2bd6f08a37fce070e6ad77"
  ],
  "changeHistoryShort": {
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": "Ybodychange",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": "Ybodychange",
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064": "Ybodychange",
    "d638a7dc0363dbe07deb8c389116132814267b10": "Ybodychange",
    "5ce332dc9a072f8850ab71ba16898faf8e866c06": "Ymultichange(Ymovefromfile,Ybodychange)",
    "6215e35bb633706753a464ad3e8633366e6a10b2": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
    "5179d99b7e1faeac1ce041967480115913d9f795": "Ybodychange",
    "b67ae6d9d741e79ccf2bd6f08a37fce070e6ad77": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,52 @@\n   static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n       String src, boolean logRetryCache) throws IOException {\n \n     assert fsd.getFSNamesystem().hasWriteLock();\n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n     INodesInPath iip;\n     fsd.writeLock();\n     try {\n \n       // check operation permission.\n       iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n       INode inode \u003d FSDirectory.resolveLastINode(iip);\n       if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() \u003d\u003d 0) {\n         if (NameNode.LOG.isInfoEnabled()) {\n           NameNode.LOG.info(\n               \"Skipping satisfy storage policy on path:{} as \"\n                   + \"this file doesn\u0027t have any blocks!\",\n               inode.getFullPathName());\n         }\n       } else if (inodeHasSatisfyXAttr(inode)) {\n         NameNode.LOG\n             .warn(\"Cannot request to call satisfy storage policy on path: \"\n                 + inode.getFullPathName()\n                 + \", as this file/dir was already called for satisfying \"\n                 + \"storage policy.\");\n       } else {\n         XAttr satisfyXAttr \u003d XAttrHelper\n             .buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n         List\u003cXAttr\u003e xAttrs \u003d Arrays.asList(satisfyXAttr);\n         List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(inode);\n         List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(fsd, existingXAttrs,\n             xAttrs, EnumSet.of(XAttrSetFlag.CREATE));\n         XAttrStorage.updateINodeXAttrs(inode, newXAttrs,\n             iip.getLatestSnapshotId());\n         fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n \n         // Adding directory in the pending queue, so FileInodeIdCollector\n         // process directory child in batch and recursively\n-        fsd.getBlockManager().getSPSManager().addPathId(inode.getId());\n+        StoragePolicySatisfyManager spsManager \u003d\n+            fsd.getBlockManager().getSPSManager();\n+        if (spsManager !\u003d null) {\n+          spsManager.addPathId(inode.getId());\n+        }\n       }\n     } finally {\n       fsd.writeUnlock();\n     }\n     return fsd.getAuditFileInfo(iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n      String src, boolean logRetryCache) throws IOException {\n\n    assert fsd.getFSNamesystem().hasWriteLock();\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    INodesInPath iip;\n    fsd.writeLock();\n    try {\n\n      // check operation permission.\n      iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INode inode \u003d FSDirectory.resolveLastINode(iip);\n      if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() \u003d\u003d 0) {\n        if (NameNode.LOG.isInfoEnabled()) {\n          NameNode.LOG.info(\n              \"Skipping satisfy storage policy on path:{} as \"\n                  + \"this file doesn\u0027t have any blocks!\",\n              inode.getFullPathName());\n        }\n      } else if (inodeHasSatisfyXAttr(inode)) {\n        NameNode.LOG\n            .warn(\"Cannot request to call satisfy storage policy on path: \"\n                + inode.getFullPathName()\n                + \", as this file/dir was already called for satisfying \"\n                + \"storage policy.\");\n      } else {\n        XAttr satisfyXAttr \u003d XAttrHelper\n            .buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n        List\u003cXAttr\u003e xAttrs \u003d Arrays.asList(satisfyXAttr);\n        List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(inode);\n        List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(fsd, existingXAttrs,\n            xAttrs, EnumSet.of(XAttrSetFlag.CREATE));\n        XAttrStorage.updateINodeXAttrs(inode, newXAttrs,\n            iip.getLatestSnapshotId());\n        fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n\n        // Adding directory in the pending queue, so FileInodeIdCollector\n        // process directory child in batch and recursively\n        StoragePolicySatisfyManager spsManager \u003d\n            fsd.getBlockManager().getSPSManager();\n        if (spsManager !\u003d null) {\n          spsManager.addPathId(inode.getId());\n        }\n      }\n    } finally {\n      fsd.writeUnlock();\n    }\n    return fsd.getAuditFileInfo(iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
      "extendedDetails": {}
    },
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13097: [SPS]: Fix the branch review comments(Part1). Contributed by Surendra Singh.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "d3de4fb2a084cbadab8ef91f11aa7732d3b0f308",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,48 @@\n   static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n       String src, boolean logRetryCache) throws IOException {\n \n     assert fsd.getFSNamesystem().hasWriteLock();\n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n     INodesInPath iip;\n     fsd.writeLock();\n     try {\n \n       // check operation permission.\n       iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n       INode inode \u003d FSDirectory.resolveLastINode(iip);\n-      if (inodeHasSatisfyXAttr(inode)) {\n-        throw new IOException(\n-            \"Cannot request to call satisfy storage policy on path \"\n+      if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() \u003d\u003d 0) {\n+        if (NameNode.LOG.isInfoEnabled()) {\n+          NameNode.LOG.info(\n+              \"Skipping satisfy storage policy on path:{} as \"\n+                  + \"this file doesn\u0027t have any blocks!\",\n+              inode.getFullPathName());\n+        }\n+      } else if (inodeHasSatisfyXAttr(inode)) {\n+        NameNode.LOG\n+            .warn(\"Cannot request to call satisfy storage policy on path: \"\n                 + inode.getFullPathName()\n                 + \", as this file/dir was already called for satisfying \"\n                 + \"storage policy.\");\n-      }\n-      if (unprotectedSatisfyStoragePolicy(inode, fsd)) {\n+      } else {\n         XAttr satisfyXAttr \u003d XAttrHelper\n             .buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n-        List\u003cXAttr\u003e xAttrs \u003d Lists.newArrayListWithCapacity(1);\n-        xAttrs.add(satisfyXAttr);\n+        List\u003cXAttr\u003e xAttrs \u003d Arrays.asList(satisfyXAttr);\n         List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(inode);\n         List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(fsd, existingXAttrs,\n             xAttrs, EnumSet.of(XAttrSetFlag.CREATE));\n         XAttrStorage.updateINodeXAttrs(inode, newXAttrs,\n             iip.getLatestSnapshotId());\n         fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n+\n+        // Adding directory in the pending queue, so FileInodeIdCollector\n+        // process directory child in batch and recursively\n+        fsd.getBlockManager().getSPSManager().addPathId(inode.getId());\n       }\n     } finally {\n       fsd.writeUnlock();\n     }\n     return fsd.getAuditFileInfo(iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n      String src, boolean logRetryCache) throws IOException {\n\n    assert fsd.getFSNamesystem().hasWriteLock();\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    INodesInPath iip;\n    fsd.writeLock();\n    try {\n\n      // check operation permission.\n      iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INode inode \u003d FSDirectory.resolveLastINode(iip);\n      if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() \u003d\u003d 0) {\n        if (NameNode.LOG.isInfoEnabled()) {\n          NameNode.LOG.info(\n              \"Skipping satisfy storage policy on path:{} as \"\n                  + \"this file doesn\u0027t have any blocks!\",\n              inode.getFullPathName());\n        }\n      } else if (inodeHasSatisfyXAttr(inode)) {\n        NameNode.LOG\n            .warn(\"Cannot request to call satisfy storage policy on path: \"\n                + inode.getFullPathName()\n                + \", as this file/dir was already called for satisfying \"\n                + \"storage policy.\");\n      } else {\n        XAttr satisfyXAttr \u003d XAttrHelper\n            .buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n        List\u003cXAttr\u003e xAttrs \u003d Arrays.asList(satisfyXAttr);\n        List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(inode);\n        List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(fsd, existingXAttrs,\n            xAttrs, EnumSet.of(XAttrSetFlag.CREATE));\n        XAttrStorage.updateINodeXAttrs(inode, newXAttrs,\n            iip.getLatestSnapshotId());\n        fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n\n        // Adding directory in the pending queue, so FileInodeIdCollector\n        // process directory child in batch and recursively\n        fsd.getBlockManager().getSPSManager().addPathId(inode.getId());\n      }\n    } finally {\n      fsd.writeUnlock();\n    }\n    return fsd.getAuditFileInfo(iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
      "extendedDetails": {}
    },
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12225: [SPS]: Optimize extended attributes for tracking SPS movements. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "d638a7dc0363dbe07deb8c389116132814267b10",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,39 @@\n   static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n       String src, boolean logRetryCache) throws IOException {\n \n     assert fsd.getFSNamesystem().hasWriteLock();\n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n     INodesInPath iip;\n     fsd.writeLock();\n     try {\n \n       // check operation permission.\n       iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n-      XAttr satisfyXAttr \u003d unprotectedSatisfyStoragePolicy(iip, bm, fsd);\n-      if (satisfyXAttr !\u003d null) {\n+      INode inode \u003d FSDirectory.resolveLastINode(iip);\n+      if (inodeHasSatisfyXAttr(inode)) {\n+        throw new IOException(\n+            \"Cannot request to call satisfy storage policy on path \"\n+                + inode.getFullPathName()\n+                + \", as this file/dir was already called for satisfying \"\n+                + \"storage policy.\");\n+      }\n+      if (unprotectedSatisfyStoragePolicy(inode, fsd)) {\n+        XAttr satisfyXAttr \u003d XAttrHelper\n+            .buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n         List\u003cXAttr\u003e xAttrs \u003d Lists.newArrayListWithCapacity(1);\n         xAttrs.add(satisfyXAttr);\n+        List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(inode);\n+        List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(fsd, existingXAttrs,\n+            xAttrs, EnumSet.of(XAttrSetFlag.CREATE));\n+        XAttrStorage.updateINodeXAttrs(inode, newXAttrs,\n+            iip.getLatestSnapshotId());\n         fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n       }\n     } finally {\n       fsd.writeUnlock();\n     }\n     return fsd.getAuditFileInfo(iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n      String src, boolean logRetryCache) throws IOException {\n\n    assert fsd.getFSNamesystem().hasWriteLock();\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    INodesInPath iip;\n    fsd.writeLock();\n    try {\n\n      // check operation permission.\n      iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      INode inode \u003d FSDirectory.resolveLastINode(iip);\n      if (inodeHasSatisfyXAttr(inode)) {\n        throw new IOException(\n            \"Cannot request to call satisfy storage policy on path \"\n                + inode.getFullPathName()\n                + \", as this file/dir was already called for satisfying \"\n                + \"storage policy.\");\n      }\n      if (unprotectedSatisfyStoragePolicy(inode, fsd)) {\n        XAttr satisfyXAttr \u003d XAttrHelper\n            .buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n        List\u003cXAttr\u003e xAttrs \u003d Lists.newArrayListWithCapacity(1);\n        xAttrs.add(satisfyXAttr);\n        List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(inode);\n        List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(fsd, existingXAttrs,\n            xAttrs, EnumSet.of(XAttrSetFlag.CREATE));\n        XAttrStorage.updateINodeXAttrs(inode, newXAttrs,\n            iip.getLatestSnapshotId());\n        fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n      }\n    } finally {\n      fsd.writeUnlock();\n    }\n    return fsd.getAuditFileInfo(iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
      "extendedDetails": {}
    },
    "d638a7dc0363dbe07deb8c389116132814267b10": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11762. [SPS]: Empty files should be ignored in StoragePolicySatisfier. Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "d638a7dc0363dbe07deb8c389116132814267b10",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "5ce332dc9a072f8850ab71ba16898faf8e866c06",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,25 @@\n   static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n       String src, boolean logRetryCache) throws IOException {\n \n     assert fsd.getFSNamesystem().hasWriteLock();\n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n-    List\u003cXAttr\u003e xAttrs \u003d Lists.newArrayListWithCapacity(1);\n     INodesInPath iip;\n     fsd.writeLock();\n     try {\n \n       // check operation permission.\n       iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n       XAttr satisfyXAttr \u003d unprotectedSatisfyStoragePolicy(iip, bm, fsd);\n-      xAttrs.add(satisfyXAttr);\n-      fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n+      if (satisfyXAttr !\u003d null) {\n+        List\u003cXAttr\u003e xAttrs \u003d Lists.newArrayListWithCapacity(1);\n+        xAttrs.add(satisfyXAttr);\n+        fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n+      }\n     } finally {\n       fsd.writeUnlock();\n     }\n     return fsd.getAuditFileInfo(iip);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n      String src, boolean logRetryCache) throws IOException {\n\n    assert fsd.getFSNamesystem().hasWriteLock();\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    INodesInPath iip;\n    fsd.writeLock();\n    try {\n\n      // check operation permission.\n      iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      XAttr satisfyXAttr \u003d unprotectedSatisfyStoragePolicy(iip, bm, fsd);\n      if (satisfyXAttr !\u003d null) {\n        List\u003cXAttr\u003e xAttrs \u003d Lists.newArrayListWithCapacity(1);\n        xAttrs.add(satisfyXAttr);\n        fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n      }\n    } finally {\n      fsd.writeUnlock();\n    }\n    return fsd.getAuditFileInfo(iip);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
      "extendedDetails": {}
    },
    "5ce332dc9a072f8850ab71ba16898faf8e866c06": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-11695: [SPS]: Namenode failed to start while loading SPS xAttrs from the edits log. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "5ce332dc9a072f8850ab71ba16898faf8e866c06",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-11695: [SPS]: Namenode failed to start while loading SPS xAttrs from the edits log. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "12/08/18 3:05 AM",
          "commitName": "5ce332dc9a072f8850ab71ba16898faf8e866c06",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "6fe6c549e8226b4893f502186f52452dcd9408a2",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,23 @@\n   static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n       String src, boolean logRetryCache) throws IOException {\n \n+    assert fsd.getFSNamesystem().hasWriteLock();\n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n     List\u003cXAttr\u003e xAttrs \u003d Lists.newArrayListWithCapacity(1);\n     INodesInPath iip;\n     fsd.writeLock();\n     try {\n \n       // check operation permission.\n       iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n       XAttr satisfyXAttr \u003d unprotectedSatisfyStoragePolicy(iip, bm, fsd);\n       xAttrs.add(satisfyXAttr);\n+      fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n     } finally {\n       fsd.writeUnlock();\n     }\n-    fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n     return fsd.getAuditFileInfo(iip);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n      String src, boolean logRetryCache) throws IOException {\n\n    assert fsd.getFSNamesystem().hasWriteLock();\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    List\u003cXAttr\u003e xAttrs \u003d Lists.newArrayListWithCapacity(1);\n    INodesInPath iip;\n    fsd.writeLock();\n    try {\n\n      // check operation permission.\n      iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      XAttr satisfyXAttr \u003d unprotectedSatisfyStoragePolicy(iip, bm, fsd);\n      xAttrs.add(satisfyXAttr);\n      fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n    } finally {\n      fsd.writeUnlock();\n    }\n    return fsd.getAuditFileInfo(iip);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirAttrOp.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
            "oldMethodName": "satisfyStoragePolicy",
            "newMethodName": "satisfyStoragePolicy"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-11695: [SPS]: Namenode failed to start while loading SPS xAttrs from the edits log. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "12/08/18 3:05 AM",
          "commitName": "5ce332dc9a072f8850ab71ba16898faf8e866c06",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "6fe6c549e8226b4893f502186f52452dcd9408a2",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,23 @@\n   static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n       String src, boolean logRetryCache) throws IOException {\n \n+    assert fsd.getFSNamesystem().hasWriteLock();\n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n     List\u003cXAttr\u003e xAttrs \u003d Lists.newArrayListWithCapacity(1);\n     INodesInPath iip;\n     fsd.writeLock();\n     try {\n \n       // check operation permission.\n       iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n       XAttr satisfyXAttr \u003d unprotectedSatisfyStoragePolicy(iip, bm, fsd);\n       xAttrs.add(satisfyXAttr);\n+      fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n     } finally {\n       fsd.writeUnlock();\n     }\n-    fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n     return fsd.getAuditFileInfo(iip);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n      String src, boolean logRetryCache) throws IOException {\n\n    assert fsd.getFSNamesystem().hasWriteLock();\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    List\u003cXAttr\u003e xAttrs \u003d Lists.newArrayListWithCapacity(1);\n    INodesInPath iip;\n    fsd.writeLock();\n    try {\n\n      // check operation permission.\n      iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      XAttr satisfyXAttr \u003d unprotectedSatisfyStoragePolicy(iip, bm, fsd);\n      xAttrs.add(satisfyXAttr);\n      fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n    } finally {\n      fsd.writeUnlock();\n    }\n    return fsd.getAuditFileInfo(iip);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
          "extendedDetails": {}
        }
      ]
    },
    "6215e35bb633706753a464ad3e8633366e6a10b2": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-11150: [SPS]: Provide persistence when satisfying storage policy. Contributed by Yuanbo Liu\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "6215e35bb633706753a464ad3e8633366e6a10b2",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-11150: [SPS]: Provide persistence when satisfying storage policy. Contributed by Yuanbo Liu\n",
          "commitDate": "12/08/18 3:05 AM",
          "commitName": "6215e35bb633706753a464ad3e8633366e6a10b2",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "5179d99b7e1faeac1ce041967480115913d9f795",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,22 @@\n-  static void satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n-      String src) throws IOException {\n+  static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n+      String src, boolean logRetryCache) throws IOException {\n \n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n+    List\u003cXAttr\u003e xAttrs \u003d Lists.newArrayListWithCapacity(1);\n     INodesInPath iip;\n     fsd.writeLock();\n     try {\n \n       // check operation permission.\n       iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n-      unprotectedSatisfyStoragePolicy(bm, iip);\n+      XAttr satisfyXAttr \u003d unprotectedSatisfyStoragePolicy(iip, bm, fsd);\n+      xAttrs.add(satisfyXAttr);\n     } finally {\n       fsd.writeUnlock();\n     }\n+    fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n+    return fsd.getAuditFileInfo(iip);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n      String src, boolean logRetryCache) throws IOException {\n\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    List\u003cXAttr\u003e xAttrs \u003d Lists.newArrayListWithCapacity(1);\n    INodesInPath iip;\n    fsd.writeLock();\n    try {\n\n      // check operation permission.\n      iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      XAttr satisfyXAttr \u003d unprotectedSatisfyStoragePolicy(iip, bm, fsd);\n      xAttrs.add(satisfyXAttr);\n    } finally {\n      fsd.writeUnlock();\n    }\n    fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n    return fsd.getAuditFileInfo(iip);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirAttrOp.java",
          "extendedDetails": {
            "oldValue": "[fsd-FSDirectory, bm-BlockManager, src-String]",
            "newValue": "[fsd-FSDirectory, bm-BlockManager, src-String, logRetryCache-boolean]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-11150: [SPS]: Provide persistence when satisfying storage policy. Contributed by Yuanbo Liu\n",
          "commitDate": "12/08/18 3:05 AM",
          "commitName": "6215e35bb633706753a464ad3e8633366e6a10b2",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "5179d99b7e1faeac1ce041967480115913d9f795",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,22 @@\n-  static void satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n-      String src) throws IOException {\n+  static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n+      String src, boolean logRetryCache) throws IOException {\n \n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n+    List\u003cXAttr\u003e xAttrs \u003d Lists.newArrayListWithCapacity(1);\n     INodesInPath iip;\n     fsd.writeLock();\n     try {\n \n       // check operation permission.\n       iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n-      unprotectedSatisfyStoragePolicy(bm, iip);\n+      XAttr satisfyXAttr \u003d unprotectedSatisfyStoragePolicy(iip, bm, fsd);\n+      xAttrs.add(satisfyXAttr);\n     } finally {\n       fsd.writeUnlock();\n     }\n+    fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n+    return fsd.getAuditFileInfo(iip);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n      String src, boolean logRetryCache) throws IOException {\n\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    List\u003cXAttr\u003e xAttrs \u003d Lists.newArrayListWithCapacity(1);\n    INodesInPath iip;\n    fsd.writeLock();\n    try {\n\n      // check operation permission.\n      iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      XAttr satisfyXAttr \u003d unprotectedSatisfyStoragePolicy(iip, bm, fsd);\n      xAttrs.add(satisfyXAttr);\n    } finally {\n      fsd.writeUnlock();\n    }\n    fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n    return fsd.getAuditFileInfo(iip);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirAttrOp.java",
          "extendedDetails": {
            "oldValue": "void",
            "newValue": "FileStatus"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-11150: [SPS]: Provide persistence when satisfying storage policy. Contributed by Yuanbo Liu\n",
          "commitDate": "12/08/18 3:05 AM",
          "commitName": "6215e35bb633706753a464ad3e8633366e6a10b2",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "5179d99b7e1faeac1ce041967480115913d9f795",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,22 @@\n-  static void satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n-      String src) throws IOException {\n+  static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n+      String src, boolean logRetryCache) throws IOException {\n \n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n+    List\u003cXAttr\u003e xAttrs \u003d Lists.newArrayListWithCapacity(1);\n     INodesInPath iip;\n     fsd.writeLock();\n     try {\n \n       // check operation permission.\n       iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n-      unprotectedSatisfyStoragePolicy(bm, iip);\n+      XAttr satisfyXAttr \u003d unprotectedSatisfyStoragePolicy(iip, bm, fsd);\n+      xAttrs.add(satisfyXAttr);\n     } finally {\n       fsd.writeUnlock();\n     }\n+    fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n+    return fsd.getAuditFileInfo(iip);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static FileStatus satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n      String src, boolean logRetryCache) throws IOException {\n\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    List\u003cXAttr\u003e xAttrs \u003d Lists.newArrayListWithCapacity(1);\n    INodesInPath iip;\n    fsd.writeLock();\n    try {\n\n      // check operation permission.\n      iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      XAttr satisfyXAttr \u003d unprotectedSatisfyStoragePolicy(iip, bm, fsd);\n      xAttrs.add(satisfyXAttr);\n    } finally {\n      fsd.writeUnlock();\n    }\n    fsd.getEditLog().logSetXAttrs(src, xAttrs, logRetryCache);\n    return fsd.getAuditFileInfo(iip);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirAttrOp.java",
          "extendedDetails": {}
        }
      ]
    },
    "5179d99b7e1faeac1ce041967480115913d9f795": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11123. [SPS] Make storage policy satisfier daemon work on/off dynamically. Contributed by Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "5179d99b7e1faeac1ce041967480115913d9f795",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "b67ae6d9d741e79ccf2bd6f08a37fce070e6ad77",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,18 @@\n   static void satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n       String src) throws IOException {\n \n-    // make sure storage policy is enabled, otherwise\n-    // there is no need to satisfy storage policy.\n-    if (!fsd.isStoragePolicyEnabled()) {\n-      throw new IOException(String.format(\n-          \"Failed to satisfy storage policy since %s is set to false.\",\n-          DFS_STORAGE_POLICY_ENABLED_KEY));\n-    }\n-\n     FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n     INodesInPath iip;\n     fsd.writeLock();\n     try {\n \n       // check operation permission.\n       iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n       if (fsd.isPermissionEnabled()) {\n         fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n       }\n       unprotectedSatisfyStoragePolicy(bm, iip);\n     } finally {\n       fsd.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static void satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n      String src) throws IOException {\n\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    INodesInPath iip;\n    fsd.writeLock();\n    try {\n\n      // check operation permission.\n      iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      unprotectedSatisfyStoragePolicy(bm, iip);\n    } finally {\n      fsd.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirAttrOp.java",
      "extendedDetails": {}
    },
    "b67ae6d9d741e79ccf2bd6f08a37fce070e6ad77": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-10802. [SPS]: Add satisfyStoragePolicy API in HdfsAdmin. Contributed by Yuanbo Liu\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "b67ae6d9d741e79ccf2bd6f08a37fce070e6ad77",
      "commitAuthor": "Rakesh Radhakrishnan",
      "diff": "@@ -0,0 +1,26 @@\n+  static void satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n+      String src) throws IOException {\n+\n+    // make sure storage policy is enabled, otherwise\n+    // there is no need to satisfy storage policy.\n+    if (!fsd.isStoragePolicyEnabled()) {\n+      throw new IOException(String.format(\n+          \"Failed to satisfy storage policy since %s is set to false.\",\n+          DFS_STORAGE_POLICY_ENABLED_KEY));\n+    }\n+\n+    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n+    INodesInPath iip;\n+    fsd.writeLock();\n+    try {\n+\n+      // check operation permission.\n+      iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n+      if (fsd.isPermissionEnabled()) {\n+        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n+      }\n+      unprotectedSatisfyStoragePolicy(bm, iip);\n+    } finally {\n+      fsd.writeUnlock();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static void satisfyStoragePolicy(FSDirectory fsd, BlockManager bm,\n      String src) throws IOException {\n\n    // make sure storage policy is enabled, otherwise\n    // there is no need to satisfy storage policy.\n    if (!fsd.isStoragePolicyEnabled()) {\n      throw new IOException(String.format(\n          \"Failed to satisfy storage policy since %s is set to false.\",\n          DFS_STORAGE_POLICY_ENABLED_KEY));\n    }\n\n    FSPermissionChecker pc \u003d fsd.getPermissionChecker();\n    INodesInPath iip;\n    fsd.writeLock();\n    try {\n\n      // check operation permission.\n      iip \u003d fsd.resolvePath(pc, src, DirOp.WRITE);\n      if (fsd.isPermissionEnabled()) {\n        fsd.checkPathAccess(pc, iip, FsAction.WRITE);\n      }\n      unprotectedSatisfyStoragePolicy(bm, iip);\n    } finally {\n      fsd.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirAttrOp.java"
    }
  }
}