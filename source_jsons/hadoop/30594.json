{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LeveldbTimelineStore.java",
  "functionName": "getEntityByTime",
  "functionId": "getEntityByTime___base-byte[]__entityType-String__limit-Long__starttime-Long__endtime-Long__fromId-String__fromTs-Long__secondaryFilters-Collection__NameValuePair____fields-EnumSet__Field____checkAcl-CheckAcl",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
  "functionStartLine": 616,
  "functionEndLine": 757,
  "numCommitsSeen": 40,
  "timeTaken": 5089,
  "changeHistory": [
    "839e077faf4019d6efdcd89d95930023cd0b0a08",
    "a4aa1cb40504299d3401008fdabc795eafb28713",
    "1a78c0ff016097930edf68e8278f826b637e918c",
    "7f07c4d81023e3bf4bf8980e64cc9420ec31cf55",
    "8180e676abb2bb500a48b3a0c0809d2a807ab235",
    "57db50cbe3ce42618ad6d6869ae337d15b261f4e",
    "1ce4d33c2dc86d711b227a04d2f9a2ab696a24a1",
    "001078e0677e39b962ca1da81fc34d7ac9a7e65c",
    "0f1eda6bbf895a1239b25cdf8b17fabd3759e806",
    "b3ea4aebff42131642af0393748dc751cb3fc31e",
    "84425fb435cb603fd8adcc2f76631c0244175310",
    "e06226126cd89d0cf8b4ef80a88659b248579231",
    "23b2e43f5d678517e33590d15dec73225b9c5682"
  ],
  "changeHistoryShort": {
    "839e077faf4019d6efdcd89d95930023cd0b0a08": "Ybodychange",
    "a4aa1cb40504299d3401008fdabc795eafb28713": "Ybodychange",
    "1a78c0ff016097930edf68e8278f826b637e918c": "Ybodychange",
    "7f07c4d81023e3bf4bf8980e64cc9420ec31cf55": "Ybodychange",
    "8180e676abb2bb500a48b3a0c0809d2a807ab235": "Ymultichange(Yparameterchange,Ybodychange)",
    "57db50cbe3ce42618ad6d6869ae337d15b261f4e": "Ybodychange",
    "1ce4d33c2dc86d711b227a04d2f9a2ab696a24a1": "Ybodychange",
    "001078e0677e39b962ca1da81fc34d7ac9a7e65c": "Yfilerename",
    "0f1eda6bbf895a1239b25cdf8b17fabd3759e806": "Ymultichange(Yparameterchange,Ybodychange)",
    "b3ea4aebff42131642af0393748dc751cb3fc31e": "Ybodychange",
    "84425fb435cb603fd8adcc2f76631c0244175310": "Ymultichange(Yfilerename,Yreturntypechange,Ybodychange)",
    "e06226126cd89d0cf8b4ef80a88659b248579231": "Ybodychange",
    "23b2e43f5d678517e33590d15dec73225b9c5682": "Yintroduced"
  },
  "changeHistoryDetails": {
    "839e077faf4019d6efdcd89d95930023cd0b0a08": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6873. Moving logging APIs over to slf4j in hadoop-yarn-server-applicationhistoryservice. Contributed by Yeliang Cang.\n",
      "commitDate": "07/08/17 2:56 AM",
      "commitName": "839e077faf4019d6efdcd89d95930023cd0b0a08",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "31/07/17 8:15 PM",
      "commitNameOld": "a4aa1cb40504299d3401008fdabc795eafb28713",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 6.28,
      "commitsBetweenForRepo": 91,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,142 +1,142 @@\n   private TimelineEntities getEntityByTime(byte[] base,\n       String entityType, Long limit, Long starttime, Long endtime,\n       String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n       EnumSet\u003cField\u003e fields, CheckAcl checkAcl) throws IOException {\n     // Even if other info and primary filter fields are not included, we\n     // still need to load them to match secondary filters when they are\n     // non-empty\n     if (fields \u003d\u003d null) {\n       fields \u003d EnumSet.allOf(Field.class);\n     }\n     boolean addPrimaryFilters \u003d false;\n     boolean addOtherInfo \u003d false;\n     if (secondaryFilters !\u003d null \u0026\u0026 secondaryFilters.size() \u003e 0) {\n       if (!fields.contains(Field.PRIMARY_FILTERS)) {\n         fields.add(Field.PRIMARY_FILTERS);\n         addPrimaryFilters \u003d true;\n       }\n       if (!fields.contains(Field.OTHER_INFO)) {\n         fields.add(Field.OTHER_INFO);\n         addOtherInfo \u003d true;\n       }\n     }\n \n     LeveldbIterator iterator \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n       // only db keys matching the prefix (base + entity type) will be parsed\n       byte[] prefix \u003d kb.getBytesForLookup();\n       if (endtime \u003d\u003d null) {\n         // if end time is null, place no restriction on end time\n         endtime \u003d Long.MAX_VALUE;\n       }\n       // construct a first key that will be seeked to using end time or fromId\n       byte[] first \u003d null;\n       if (fromId !\u003d null) {\n         Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n         if (fromIdStartTime \u003d\u003d null) {\n           // no start time for provided id, so return empty entities\n           return new TimelineEntities();\n         }\n         if (fromIdStartTime \u003c\u003d endtime) {\n           // if provided id\u0027s start time falls before the end of the window,\n           // use it to construct the seek key\n           first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n               .add(fromId).getBytesForLookup();\n         }\n       }\n       // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n       if (first \u003d\u003d null) {\n         first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n       }\n       byte[] last \u003d null;\n       if (starttime !\u003d null) {\n         // if start time is not null, set a last key that will not be\n         // iterated past\n         last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n             .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n       }\n       if (limit \u003d\u003d null) {\n         // if limit is not specified, use the default\n         limit \u003d DEFAULT_LIMIT;\n       }\n \n       TimelineEntities entities \u003d new TimelineEntities();\n       iterator \u003d new LeveldbIterator(db);\n       iterator.seek(first);\n       // iterate until one of the following conditions is met: limit is\n       // reached, there are no more keys, the key prefix no longer matches,\n       // or a start time has been specified and reached/exceeded\n       while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n             WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                 last.length) \u003e 0)) {\n           break;\n         }\n         // read the start time and entity id from the current key\n         KeyParser kp \u003d new KeyParser(key, prefix.length);\n         Long startTime \u003d kp.getNextLong();\n         String entityId \u003d kp.getNextString();\n \n         if (fromTs !\u003d null) {\n           long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n               .getValue(), 0);\n           if (insertTime \u003e fromTs) {\n             byte[] firstKey \u003d key;\n             while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                 kp.getOffset(), key)) {\n               iterator.next();\n               key \u003d iterator.peekNext().getKey();\n             }\n             continue;\n           }\n         }\n \n         // parse the entity that owns this key, iterating over all keys for\n         // the entity\n         TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n             fields, iterator, key, kp.getOffset());\n         // determine if the retrieved entity matches the provided secondary\n         // filters, and if so add it to the list of entities to return\n         boolean filterPassed \u003d true;\n         if (secondaryFilters !\u003d null) {\n           for (NameValuePair filter : secondaryFilters) {\n             Object v \u003d entity.getOtherInfo().get(filter.getName());\n             if (v \u003d\u003d null) {\n               Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                   .get(filter.getName());\n               if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                 filterPassed \u003d false;\n                 break;\n               }\n             } else if (!v.equals(filter.getValue())) {\n               filterPassed \u003d false;\n               break;\n             }\n           }\n         }\n         if (filterPassed) {\n           if (entity.getDomainId() \u003d\u003d null) {\n             entity.setDomainId(DEFAULT_DOMAIN_ID);\n           }\n           if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n             // Remove primary filter and other info if they are added for\n             // matching secondary filters\n             if (addPrimaryFilters) {\n               entity.setPrimaryFilters(null);\n             }\n             if (addOtherInfo) {\n               entity.setOtherInfo(null);\n             }\n             entities.addEntity(entity);\n           }\n         }\n       }\n       return entities;\n     } catch(DBException e) {\n       throw new IOException(e);   \t\n     } finally {\n-      IOUtils.cleanup(LOG, iterator);\n+      IOUtils.cleanupWithLogger(LOG, iterator);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private TimelineEntities getEntityByTime(byte[] base,\n      String entityType, Long limit, Long starttime, Long endtime,\n      String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n      EnumSet\u003cField\u003e fields, CheckAcl checkAcl) throws IOException {\n    // Even if other info and primary filter fields are not included, we\n    // still need to load them to match secondary filters when they are\n    // non-empty\n    if (fields \u003d\u003d null) {\n      fields \u003d EnumSet.allOf(Field.class);\n    }\n    boolean addPrimaryFilters \u003d false;\n    boolean addOtherInfo \u003d false;\n    if (secondaryFilters !\u003d null \u0026\u0026 secondaryFilters.size() \u003e 0) {\n      if (!fields.contains(Field.PRIMARY_FILTERS)) {\n        fields.add(Field.PRIMARY_FILTERS);\n        addPrimaryFilters \u003d true;\n      }\n      if (!fields.contains(Field.OTHER_INFO)) {\n        fields.add(Field.OTHER_INFO);\n        addOtherInfo \u003d true;\n      }\n    }\n\n    LeveldbIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n      // construct a first key that will be seeked to using end time or fromId\n      byte[] first \u003d null;\n      if (fromId !\u003d null) {\n        Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n        if (fromIdStartTime \u003d\u003d null) {\n          // no start time for provided id, so return empty entities\n          return new TimelineEntities();\n        }\n        if (fromIdStartTime \u003c\u003d endtime) {\n          // if provided id\u0027s start time falls before the end of the window,\n          // use it to construct the seek key\n          first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n              .add(fromId).getBytesForLookup();\n        }\n      }\n      // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n      if (first \u003d\u003d null) {\n        first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n      }\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      TimelineEntities entities \u003d new TimelineEntities();\n      iterator \u003d new LeveldbIterator(db);\n      iterator.seek(first);\n      // iterate until one of the following conditions is met: limit is\n      // reached, there are no more keys, the key prefix no longer matches,\n      // or a start time has been specified and reached/exceeded\n      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                last.length) \u003e 0)) {\n          break;\n        }\n        // read the start time and entity id from the current key\n        KeyParser kp \u003d new KeyParser(key, prefix.length);\n        Long startTime \u003d kp.getNextLong();\n        String entityId \u003d kp.getNextString();\n\n        if (fromTs !\u003d null) {\n          long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n              .getValue(), 0);\n          if (insertTime \u003e fromTs) {\n            byte[] firstKey \u003d key;\n            while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                kp.getOffset(), key)) {\n              iterator.next();\n              key \u003d iterator.peekNext().getKey();\n            }\n            continue;\n          }\n        }\n\n        // parse the entity that owns this key, iterating over all keys for\n        // the entity\n        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n            fields, iterator, key, kp.getOffset());\n        // determine if the retrieved entity matches the provided secondary\n        // filters, and if so add it to the list of entities to return\n        boolean filterPassed \u003d true;\n        if (secondaryFilters !\u003d null) {\n          for (NameValuePair filter : secondaryFilters) {\n            Object v \u003d entity.getOtherInfo().get(filter.getName());\n            if (v \u003d\u003d null) {\n              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                  .get(filter.getName());\n              if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            } else if (!v.equals(filter.getValue())) {\n              filterPassed \u003d false;\n              break;\n            }\n          }\n        }\n        if (filterPassed) {\n          if (entity.getDomainId() \u003d\u003d null) {\n            entity.setDomainId(DEFAULT_DOMAIN_ID);\n          }\n          if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n            // Remove primary filter and other info if they are added for\n            // matching secondary filters\n            if (addPrimaryFilters) {\n              entity.setPrimaryFilters(null);\n            }\n            if (addOtherInfo) {\n              entity.setOtherInfo(null);\n            }\n            entities.addEntity(entity);\n          }\n        }\n      }\n      return entities;\n    } catch(DBException e) {\n      throw new IOException(e);   \t\n    } finally {\n      IOUtils.cleanupWithLogger(LOG, iterator);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {}
    },
    "a4aa1cb40504299d3401008fdabc795eafb28713": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"YARN-6873. Moving logging APIs over to slf4j in hadoop-yarn-server-applicationhistoryservice. Contributed by Yeliang Cang.\"\n\nThis reverts commit 1a78c0ff016097930edf68e8278f826b637e918c.\n",
      "commitDate": "31/07/17 8:15 PM",
      "commitName": "a4aa1cb40504299d3401008fdabc795eafb28713",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "31/07/17 6:53 PM",
      "commitNameOld": "1a78c0ff016097930edf68e8278f826b637e918c",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 0.06,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,142 +1,142 @@\n   private TimelineEntities getEntityByTime(byte[] base,\n       String entityType, Long limit, Long starttime, Long endtime,\n       String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n       EnumSet\u003cField\u003e fields, CheckAcl checkAcl) throws IOException {\n     // Even if other info and primary filter fields are not included, we\n     // still need to load them to match secondary filters when they are\n     // non-empty\n     if (fields \u003d\u003d null) {\n       fields \u003d EnumSet.allOf(Field.class);\n     }\n     boolean addPrimaryFilters \u003d false;\n     boolean addOtherInfo \u003d false;\n     if (secondaryFilters !\u003d null \u0026\u0026 secondaryFilters.size() \u003e 0) {\n       if (!fields.contains(Field.PRIMARY_FILTERS)) {\n         fields.add(Field.PRIMARY_FILTERS);\n         addPrimaryFilters \u003d true;\n       }\n       if (!fields.contains(Field.OTHER_INFO)) {\n         fields.add(Field.OTHER_INFO);\n         addOtherInfo \u003d true;\n       }\n     }\n \n     LeveldbIterator iterator \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n       // only db keys matching the prefix (base + entity type) will be parsed\n       byte[] prefix \u003d kb.getBytesForLookup();\n       if (endtime \u003d\u003d null) {\n         // if end time is null, place no restriction on end time\n         endtime \u003d Long.MAX_VALUE;\n       }\n       // construct a first key that will be seeked to using end time or fromId\n       byte[] first \u003d null;\n       if (fromId !\u003d null) {\n         Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n         if (fromIdStartTime \u003d\u003d null) {\n           // no start time for provided id, so return empty entities\n           return new TimelineEntities();\n         }\n         if (fromIdStartTime \u003c\u003d endtime) {\n           // if provided id\u0027s start time falls before the end of the window,\n           // use it to construct the seek key\n           first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n               .add(fromId).getBytesForLookup();\n         }\n       }\n       // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n       if (first \u003d\u003d null) {\n         first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n       }\n       byte[] last \u003d null;\n       if (starttime !\u003d null) {\n         // if start time is not null, set a last key that will not be\n         // iterated past\n         last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n             .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n       }\n       if (limit \u003d\u003d null) {\n         // if limit is not specified, use the default\n         limit \u003d DEFAULT_LIMIT;\n       }\n \n       TimelineEntities entities \u003d new TimelineEntities();\n       iterator \u003d new LeveldbIterator(db);\n       iterator.seek(first);\n       // iterate until one of the following conditions is met: limit is\n       // reached, there are no more keys, the key prefix no longer matches,\n       // or a start time has been specified and reached/exceeded\n       while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n             WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                 last.length) \u003e 0)) {\n           break;\n         }\n         // read the start time and entity id from the current key\n         KeyParser kp \u003d new KeyParser(key, prefix.length);\n         Long startTime \u003d kp.getNextLong();\n         String entityId \u003d kp.getNextString();\n \n         if (fromTs !\u003d null) {\n           long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n               .getValue(), 0);\n           if (insertTime \u003e fromTs) {\n             byte[] firstKey \u003d key;\n             while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                 kp.getOffset(), key)) {\n               iterator.next();\n               key \u003d iterator.peekNext().getKey();\n             }\n             continue;\n           }\n         }\n \n         // parse the entity that owns this key, iterating over all keys for\n         // the entity\n         TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n             fields, iterator, key, kp.getOffset());\n         // determine if the retrieved entity matches the provided secondary\n         // filters, and if so add it to the list of entities to return\n         boolean filterPassed \u003d true;\n         if (secondaryFilters !\u003d null) {\n           for (NameValuePair filter : secondaryFilters) {\n             Object v \u003d entity.getOtherInfo().get(filter.getName());\n             if (v \u003d\u003d null) {\n               Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                   .get(filter.getName());\n               if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                 filterPassed \u003d false;\n                 break;\n               }\n             } else if (!v.equals(filter.getValue())) {\n               filterPassed \u003d false;\n               break;\n             }\n           }\n         }\n         if (filterPassed) {\n           if (entity.getDomainId() \u003d\u003d null) {\n             entity.setDomainId(DEFAULT_DOMAIN_ID);\n           }\n           if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n             // Remove primary filter and other info if they are added for\n             // matching secondary filters\n             if (addPrimaryFilters) {\n               entity.setPrimaryFilters(null);\n             }\n             if (addOtherInfo) {\n               entity.setOtherInfo(null);\n             }\n             entities.addEntity(entity);\n           }\n         }\n       }\n       return entities;\n     } catch(DBException e) {\n       throw new IOException(e);   \t\n     } finally {\n-      IOUtils.cleanupWithLogger(LOG, iterator);\n+      IOUtils.cleanup(LOG, iterator);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private TimelineEntities getEntityByTime(byte[] base,\n      String entityType, Long limit, Long starttime, Long endtime,\n      String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n      EnumSet\u003cField\u003e fields, CheckAcl checkAcl) throws IOException {\n    // Even if other info and primary filter fields are not included, we\n    // still need to load them to match secondary filters when they are\n    // non-empty\n    if (fields \u003d\u003d null) {\n      fields \u003d EnumSet.allOf(Field.class);\n    }\n    boolean addPrimaryFilters \u003d false;\n    boolean addOtherInfo \u003d false;\n    if (secondaryFilters !\u003d null \u0026\u0026 secondaryFilters.size() \u003e 0) {\n      if (!fields.contains(Field.PRIMARY_FILTERS)) {\n        fields.add(Field.PRIMARY_FILTERS);\n        addPrimaryFilters \u003d true;\n      }\n      if (!fields.contains(Field.OTHER_INFO)) {\n        fields.add(Field.OTHER_INFO);\n        addOtherInfo \u003d true;\n      }\n    }\n\n    LeveldbIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n      // construct a first key that will be seeked to using end time or fromId\n      byte[] first \u003d null;\n      if (fromId !\u003d null) {\n        Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n        if (fromIdStartTime \u003d\u003d null) {\n          // no start time for provided id, so return empty entities\n          return new TimelineEntities();\n        }\n        if (fromIdStartTime \u003c\u003d endtime) {\n          // if provided id\u0027s start time falls before the end of the window,\n          // use it to construct the seek key\n          first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n              .add(fromId).getBytesForLookup();\n        }\n      }\n      // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n      if (first \u003d\u003d null) {\n        first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n      }\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      TimelineEntities entities \u003d new TimelineEntities();\n      iterator \u003d new LeveldbIterator(db);\n      iterator.seek(first);\n      // iterate until one of the following conditions is met: limit is\n      // reached, there are no more keys, the key prefix no longer matches,\n      // or a start time has been specified and reached/exceeded\n      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                last.length) \u003e 0)) {\n          break;\n        }\n        // read the start time and entity id from the current key\n        KeyParser kp \u003d new KeyParser(key, prefix.length);\n        Long startTime \u003d kp.getNextLong();\n        String entityId \u003d kp.getNextString();\n\n        if (fromTs !\u003d null) {\n          long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n              .getValue(), 0);\n          if (insertTime \u003e fromTs) {\n            byte[] firstKey \u003d key;\n            while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                kp.getOffset(), key)) {\n              iterator.next();\n              key \u003d iterator.peekNext().getKey();\n            }\n            continue;\n          }\n        }\n\n        // parse the entity that owns this key, iterating over all keys for\n        // the entity\n        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n            fields, iterator, key, kp.getOffset());\n        // determine if the retrieved entity matches the provided secondary\n        // filters, and if so add it to the list of entities to return\n        boolean filterPassed \u003d true;\n        if (secondaryFilters !\u003d null) {\n          for (NameValuePair filter : secondaryFilters) {\n            Object v \u003d entity.getOtherInfo().get(filter.getName());\n            if (v \u003d\u003d null) {\n              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                  .get(filter.getName());\n              if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            } else if (!v.equals(filter.getValue())) {\n              filterPassed \u003d false;\n              break;\n            }\n          }\n        }\n        if (filterPassed) {\n          if (entity.getDomainId() \u003d\u003d null) {\n            entity.setDomainId(DEFAULT_DOMAIN_ID);\n          }\n          if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n            // Remove primary filter and other info if they are added for\n            // matching secondary filters\n            if (addPrimaryFilters) {\n              entity.setPrimaryFilters(null);\n            }\n            if (addOtherInfo) {\n              entity.setOtherInfo(null);\n            }\n            entities.addEntity(entity);\n          }\n        }\n      }\n      return entities;\n    } catch(DBException e) {\n      throw new IOException(e);   \t\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {}
    },
    "1a78c0ff016097930edf68e8278f826b637e918c": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6873. Moving logging APIs over to slf4j in hadoop-yarn-server-applicationhistoryservice. Contributed by Yeliang Cang.\n",
      "commitDate": "31/07/17 6:53 PM",
      "commitName": "1a78c0ff016097930edf68e8278f826b637e918c",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "10/01/17 2:24 AM",
      "commitNameOld": "4c431a694059e40e78365b02a1497a6c7e479a70",
      "commitAuthorOld": "Naganarasimha",
      "daysBetweenCommits": 202.65,
      "commitsBetweenForRepo": 1063,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,142 +1,142 @@\n   private TimelineEntities getEntityByTime(byte[] base,\n       String entityType, Long limit, Long starttime, Long endtime,\n       String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n       EnumSet\u003cField\u003e fields, CheckAcl checkAcl) throws IOException {\n     // Even if other info and primary filter fields are not included, we\n     // still need to load them to match secondary filters when they are\n     // non-empty\n     if (fields \u003d\u003d null) {\n       fields \u003d EnumSet.allOf(Field.class);\n     }\n     boolean addPrimaryFilters \u003d false;\n     boolean addOtherInfo \u003d false;\n     if (secondaryFilters !\u003d null \u0026\u0026 secondaryFilters.size() \u003e 0) {\n       if (!fields.contains(Field.PRIMARY_FILTERS)) {\n         fields.add(Field.PRIMARY_FILTERS);\n         addPrimaryFilters \u003d true;\n       }\n       if (!fields.contains(Field.OTHER_INFO)) {\n         fields.add(Field.OTHER_INFO);\n         addOtherInfo \u003d true;\n       }\n     }\n \n     LeveldbIterator iterator \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n       // only db keys matching the prefix (base + entity type) will be parsed\n       byte[] prefix \u003d kb.getBytesForLookup();\n       if (endtime \u003d\u003d null) {\n         // if end time is null, place no restriction on end time\n         endtime \u003d Long.MAX_VALUE;\n       }\n       // construct a first key that will be seeked to using end time or fromId\n       byte[] first \u003d null;\n       if (fromId !\u003d null) {\n         Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n         if (fromIdStartTime \u003d\u003d null) {\n           // no start time for provided id, so return empty entities\n           return new TimelineEntities();\n         }\n         if (fromIdStartTime \u003c\u003d endtime) {\n           // if provided id\u0027s start time falls before the end of the window,\n           // use it to construct the seek key\n           first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n               .add(fromId).getBytesForLookup();\n         }\n       }\n       // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n       if (first \u003d\u003d null) {\n         first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n       }\n       byte[] last \u003d null;\n       if (starttime !\u003d null) {\n         // if start time is not null, set a last key that will not be\n         // iterated past\n         last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n             .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n       }\n       if (limit \u003d\u003d null) {\n         // if limit is not specified, use the default\n         limit \u003d DEFAULT_LIMIT;\n       }\n \n       TimelineEntities entities \u003d new TimelineEntities();\n       iterator \u003d new LeveldbIterator(db);\n       iterator.seek(first);\n       // iterate until one of the following conditions is met: limit is\n       // reached, there are no more keys, the key prefix no longer matches,\n       // or a start time has been specified and reached/exceeded\n       while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n             WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                 last.length) \u003e 0)) {\n           break;\n         }\n         // read the start time and entity id from the current key\n         KeyParser kp \u003d new KeyParser(key, prefix.length);\n         Long startTime \u003d kp.getNextLong();\n         String entityId \u003d kp.getNextString();\n \n         if (fromTs !\u003d null) {\n           long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n               .getValue(), 0);\n           if (insertTime \u003e fromTs) {\n             byte[] firstKey \u003d key;\n             while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                 kp.getOffset(), key)) {\n               iterator.next();\n               key \u003d iterator.peekNext().getKey();\n             }\n             continue;\n           }\n         }\n \n         // parse the entity that owns this key, iterating over all keys for\n         // the entity\n         TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n             fields, iterator, key, kp.getOffset());\n         // determine if the retrieved entity matches the provided secondary\n         // filters, and if so add it to the list of entities to return\n         boolean filterPassed \u003d true;\n         if (secondaryFilters !\u003d null) {\n           for (NameValuePair filter : secondaryFilters) {\n             Object v \u003d entity.getOtherInfo().get(filter.getName());\n             if (v \u003d\u003d null) {\n               Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                   .get(filter.getName());\n               if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                 filterPassed \u003d false;\n                 break;\n               }\n             } else if (!v.equals(filter.getValue())) {\n               filterPassed \u003d false;\n               break;\n             }\n           }\n         }\n         if (filterPassed) {\n           if (entity.getDomainId() \u003d\u003d null) {\n             entity.setDomainId(DEFAULT_DOMAIN_ID);\n           }\n           if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n             // Remove primary filter and other info if they are added for\n             // matching secondary filters\n             if (addPrimaryFilters) {\n               entity.setPrimaryFilters(null);\n             }\n             if (addOtherInfo) {\n               entity.setOtherInfo(null);\n             }\n             entities.addEntity(entity);\n           }\n         }\n       }\n       return entities;\n     } catch(DBException e) {\n       throw new IOException(e);   \t\n     } finally {\n-      IOUtils.cleanup(LOG, iterator);\n+      IOUtils.cleanupWithLogger(LOG, iterator);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private TimelineEntities getEntityByTime(byte[] base,\n      String entityType, Long limit, Long starttime, Long endtime,\n      String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n      EnumSet\u003cField\u003e fields, CheckAcl checkAcl) throws IOException {\n    // Even if other info and primary filter fields are not included, we\n    // still need to load them to match secondary filters when they are\n    // non-empty\n    if (fields \u003d\u003d null) {\n      fields \u003d EnumSet.allOf(Field.class);\n    }\n    boolean addPrimaryFilters \u003d false;\n    boolean addOtherInfo \u003d false;\n    if (secondaryFilters !\u003d null \u0026\u0026 secondaryFilters.size() \u003e 0) {\n      if (!fields.contains(Field.PRIMARY_FILTERS)) {\n        fields.add(Field.PRIMARY_FILTERS);\n        addPrimaryFilters \u003d true;\n      }\n      if (!fields.contains(Field.OTHER_INFO)) {\n        fields.add(Field.OTHER_INFO);\n        addOtherInfo \u003d true;\n      }\n    }\n\n    LeveldbIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n      // construct a first key that will be seeked to using end time or fromId\n      byte[] first \u003d null;\n      if (fromId !\u003d null) {\n        Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n        if (fromIdStartTime \u003d\u003d null) {\n          // no start time for provided id, so return empty entities\n          return new TimelineEntities();\n        }\n        if (fromIdStartTime \u003c\u003d endtime) {\n          // if provided id\u0027s start time falls before the end of the window,\n          // use it to construct the seek key\n          first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n              .add(fromId).getBytesForLookup();\n        }\n      }\n      // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n      if (first \u003d\u003d null) {\n        first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n      }\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      TimelineEntities entities \u003d new TimelineEntities();\n      iterator \u003d new LeveldbIterator(db);\n      iterator.seek(first);\n      // iterate until one of the following conditions is met: limit is\n      // reached, there are no more keys, the key prefix no longer matches,\n      // or a start time has been specified and reached/exceeded\n      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                last.length) \u003e 0)) {\n          break;\n        }\n        // read the start time and entity id from the current key\n        KeyParser kp \u003d new KeyParser(key, prefix.length);\n        Long startTime \u003d kp.getNextLong();\n        String entityId \u003d kp.getNextString();\n\n        if (fromTs !\u003d null) {\n          long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n              .getValue(), 0);\n          if (insertTime \u003e fromTs) {\n            byte[] firstKey \u003d key;\n            while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                kp.getOffset(), key)) {\n              iterator.next();\n              key \u003d iterator.peekNext().getKey();\n            }\n            continue;\n          }\n        }\n\n        // parse the entity that owns this key, iterating over all keys for\n        // the entity\n        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n            fields, iterator, key, kp.getOffset());\n        // determine if the retrieved entity matches the provided secondary\n        // filters, and if so add it to the list of entities to return\n        boolean filterPassed \u003d true;\n        if (secondaryFilters !\u003d null) {\n          for (NameValuePair filter : secondaryFilters) {\n            Object v \u003d entity.getOtherInfo().get(filter.getName());\n            if (v \u003d\u003d null) {\n              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                  .get(filter.getName());\n              if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            } else if (!v.equals(filter.getValue())) {\n              filterPassed \u003d false;\n              break;\n            }\n          }\n        }\n        if (filterPassed) {\n          if (entity.getDomainId() \u003d\u003d null) {\n            entity.setDomainId(DEFAULT_DOMAIN_ID);\n          }\n          if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n            // Remove primary filter and other info if they are added for\n            // matching secondary filters\n            if (addPrimaryFilters) {\n              entity.setPrimaryFilters(null);\n            }\n            if (addOtherInfo) {\n              entity.setOtherInfo(null);\n            }\n            entities.addEntity(entity);\n          }\n        }\n      }\n      return entities;\n    } catch(DBException e) {\n      throw new IOException(e);   \t\n    } finally {\n      IOUtils.cleanupWithLogger(LOG, iterator);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {}
    },
    "7f07c4d81023e3bf4bf8980e64cc9420ec31cf55": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3530. ATS throws exception on trying to filter results without\notherinfo. Contributed by zhijie shen\n",
      "commitDate": "27/04/15 10:36 AM",
      "commitName": "7f07c4d81023e3bf4bf8980e64cc9420ec31cf55",
      "commitAuthor": "Xuan",
      "commitDateOld": "13/03/15 10:04 AM",
      "commitNameOld": "8180e676abb2bb500a48b3a0c0809d2a807ab235",
      "commitAuthorOld": "Jonathan Eagles",
      "daysBetweenCommits": 45.02,
      "commitsBetweenForRepo": 407,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,115 +1,142 @@\n   private TimelineEntities getEntityByTime(byte[] base,\n       String entityType, Long limit, Long starttime, Long endtime,\n       String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n       EnumSet\u003cField\u003e fields, CheckAcl checkAcl) throws IOException {\n+    // Even if other info and primary filter fields are not included, we\n+    // still need to load them to match secondary filters when they are\n+    // non-empty\n+    if (fields \u003d\u003d null) {\n+      fields \u003d EnumSet.allOf(Field.class);\n+    }\n+    boolean addPrimaryFilters \u003d false;\n+    boolean addOtherInfo \u003d false;\n+    if (secondaryFilters !\u003d null \u0026\u0026 secondaryFilters.size() \u003e 0) {\n+      if (!fields.contains(Field.PRIMARY_FILTERS)) {\n+        fields.add(Field.PRIMARY_FILTERS);\n+        addPrimaryFilters \u003d true;\n+      }\n+      if (!fields.contains(Field.OTHER_INFO)) {\n+        fields.add(Field.OTHER_INFO);\n+        addOtherInfo \u003d true;\n+      }\n+    }\n+\n     LeveldbIterator iterator \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n       // only db keys matching the prefix (base + entity type) will be parsed\n       byte[] prefix \u003d kb.getBytesForLookup();\n       if (endtime \u003d\u003d null) {\n         // if end time is null, place no restriction on end time\n         endtime \u003d Long.MAX_VALUE;\n       }\n       // construct a first key that will be seeked to using end time or fromId\n       byte[] first \u003d null;\n       if (fromId !\u003d null) {\n         Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n         if (fromIdStartTime \u003d\u003d null) {\n           // no start time for provided id, so return empty entities\n           return new TimelineEntities();\n         }\n         if (fromIdStartTime \u003c\u003d endtime) {\n           // if provided id\u0027s start time falls before the end of the window,\n           // use it to construct the seek key\n           first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n               .add(fromId).getBytesForLookup();\n         }\n       }\n       // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n       if (first \u003d\u003d null) {\n         first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n       }\n       byte[] last \u003d null;\n       if (starttime !\u003d null) {\n         // if start time is not null, set a last key that will not be\n         // iterated past\n         last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n             .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n       }\n       if (limit \u003d\u003d null) {\n         // if limit is not specified, use the default\n         limit \u003d DEFAULT_LIMIT;\n       }\n \n       TimelineEntities entities \u003d new TimelineEntities();\n       iterator \u003d new LeveldbIterator(db);\n       iterator.seek(first);\n       // iterate until one of the following conditions is met: limit is\n       // reached, there are no more keys, the key prefix no longer matches,\n       // or a start time has been specified and reached/exceeded\n       while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n             WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                 last.length) \u003e 0)) {\n           break;\n         }\n         // read the start time and entity id from the current key\n         KeyParser kp \u003d new KeyParser(key, prefix.length);\n         Long startTime \u003d kp.getNextLong();\n         String entityId \u003d kp.getNextString();\n \n         if (fromTs !\u003d null) {\n           long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n               .getValue(), 0);\n           if (insertTime \u003e fromTs) {\n             byte[] firstKey \u003d key;\n             while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                 kp.getOffset(), key)) {\n               iterator.next();\n               key \u003d iterator.peekNext().getKey();\n             }\n             continue;\n           }\n         }\n \n         // parse the entity that owns this key, iterating over all keys for\n         // the entity\n         TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n             fields, iterator, key, kp.getOffset());\n         // determine if the retrieved entity matches the provided secondary\n         // filters, and if so add it to the list of entities to return\n         boolean filterPassed \u003d true;\n         if (secondaryFilters !\u003d null) {\n           for (NameValuePair filter : secondaryFilters) {\n             Object v \u003d entity.getOtherInfo().get(filter.getName());\n             if (v \u003d\u003d null) {\n               Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                   .get(filter.getName());\n               if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                 filterPassed \u003d false;\n                 break;\n               }\n             } else if (!v.equals(filter.getValue())) {\n               filterPassed \u003d false;\n               break;\n             }\n           }\n         }\n         if (filterPassed) {\n           if (entity.getDomainId() \u003d\u003d null) {\n             entity.setDomainId(DEFAULT_DOMAIN_ID);\n           }\n           if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n+            // Remove primary filter and other info if they are added for\n+            // matching secondary filters\n+            if (addPrimaryFilters) {\n+              entity.setPrimaryFilters(null);\n+            }\n+            if (addOtherInfo) {\n+              entity.setOtherInfo(null);\n+            }\n             entities.addEntity(entity);\n           }\n         }\n       }\n       return entities;\n     } catch(DBException e) {\n       throw new IOException(e);   \t\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private TimelineEntities getEntityByTime(byte[] base,\n      String entityType, Long limit, Long starttime, Long endtime,\n      String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n      EnumSet\u003cField\u003e fields, CheckAcl checkAcl) throws IOException {\n    // Even if other info and primary filter fields are not included, we\n    // still need to load them to match secondary filters when they are\n    // non-empty\n    if (fields \u003d\u003d null) {\n      fields \u003d EnumSet.allOf(Field.class);\n    }\n    boolean addPrimaryFilters \u003d false;\n    boolean addOtherInfo \u003d false;\n    if (secondaryFilters !\u003d null \u0026\u0026 secondaryFilters.size() \u003e 0) {\n      if (!fields.contains(Field.PRIMARY_FILTERS)) {\n        fields.add(Field.PRIMARY_FILTERS);\n        addPrimaryFilters \u003d true;\n      }\n      if (!fields.contains(Field.OTHER_INFO)) {\n        fields.add(Field.OTHER_INFO);\n        addOtherInfo \u003d true;\n      }\n    }\n\n    LeveldbIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n      // construct a first key that will be seeked to using end time or fromId\n      byte[] first \u003d null;\n      if (fromId !\u003d null) {\n        Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n        if (fromIdStartTime \u003d\u003d null) {\n          // no start time for provided id, so return empty entities\n          return new TimelineEntities();\n        }\n        if (fromIdStartTime \u003c\u003d endtime) {\n          // if provided id\u0027s start time falls before the end of the window,\n          // use it to construct the seek key\n          first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n              .add(fromId).getBytesForLookup();\n        }\n      }\n      // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n      if (first \u003d\u003d null) {\n        first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n      }\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      TimelineEntities entities \u003d new TimelineEntities();\n      iterator \u003d new LeveldbIterator(db);\n      iterator.seek(first);\n      // iterate until one of the following conditions is met: limit is\n      // reached, there are no more keys, the key prefix no longer matches,\n      // or a start time has been specified and reached/exceeded\n      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                last.length) \u003e 0)) {\n          break;\n        }\n        // read the start time and entity id from the current key\n        KeyParser kp \u003d new KeyParser(key, prefix.length);\n        Long startTime \u003d kp.getNextLong();\n        String entityId \u003d kp.getNextString();\n\n        if (fromTs !\u003d null) {\n          long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n              .getValue(), 0);\n          if (insertTime \u003e fromTs) {\n            byte[] firstKey \u003d key;\n            while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                kp.getOffset(), key)) {\n              iterator.next();\n              key \u003d iterator.peekNext().getKey();\n            }\n            continue;\n          }\n        }\n\n        // parse the entity that owns this key, iterating over all keys for\n        // the entity\n        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n            fields, iterator, key, kp.getOffset());\n        // determine if the retrieved entity matches the provided secondary\n        // filters, and if so add it to the list of entities to return\n        boolean filterPassed \u003d true;\n        if (secondaryFilters !\u003d null) {\n          for (NameValuePair filter : secondaryFilters) {\n            Object v \u003d entity.getOtherInfo().get(filter.getName());\n            if (v \u003d\u003d null) {\n              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                  .get(filter.getName());\n              if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            } else if (!v.equals(filter.getValue())) {\n              filterPassed \u003d false;\n              break;\n            }\n          }\n        }\n        if (filterPassed) {\n          if (entity.getDomainId() \u003d\u003d null) {\n            entity.setDomainId(DEFAULT_DOMAIN_ID);\n          }\n          if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n            // Remove primary filter and other info if they are added for\n            // matching secondary filters\n            if (addPrimaryFilters) {\n              entity.setPrimaryFilters(null);\n            }\n            if (addOtherInfo) {\n              entity.setOtherInfo(null);\n            }\n            entities.addEntity(entity);\n          }\n        }\n      }\n      return entities;\n    } catch(DBException e) {\n      throw new IOException(e);   \t\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {}
    },
    "8180e676abb2bb500a48b3a0c0809d2a807ab235": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-3267. Timelineserver applies the ACL rules after applying the limit on the number of records (Chang Li via jeagles)\n",
      "commitDate": "13/03/15 10:04 AM",
      "commitName": "8180e676abb2bb500a48b3a0c0809d2a807ab235",
      "commitAuthor": "Jonathan Eagles",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-3267. Timelineserver applies the ACL rules after applying the limit on the number of records (Chang Li via jeagles)\n",
          "commitDate": "13/03/15 10:04 AM",
          "commitName": "8180e676abb2bb500a48b3a0c0809d2a807ab235",
          "commitAuthor": "Jonathan Eagles",
          "commitDateOld": "17/02/15 6:17 PM",
          "commitNameOld": "57db50cbe3ce42618ad6d6869ae337d15b261f4e",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 23.62,
          "commitsBetweenForRepo": 182,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,110 +1,115 @@\n   private TimelineEntities getEntityByTime(byte[] base,\n       String entityType, Long limit, Long starttime, Long endtime,\n       String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n-      EnumSet\u003cField\u003e fields) throws IOException {\n+      EnumSet\u003cField\u003e fields, CheckAcl checkAcl) throws IOException {\n     LeveldbIterator iterator \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n       // only db keys matching the prefix (base + entity type) will be parsed\n       byte[] prefix \u003d kb.getBytesForLookup();\n       if (endtime \u003d\u003d null) {\n         // if end time is null, place no restriction on end time\n         endtime \u003d Long.MAX_VALUE;\n       }\n       // construct a first key that will be seeked to using end time or fromId\n       byte[] first \u003d null;\n       if (fromId !\u003d null) {\n         Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n         if (fromIdStartTime \u003d\u003d null) {\n           // no start time for provided id, so return empty entities\n           return new TimelineEntities();\n         }\n         if (fromIdStartTime \u003c\u003d endtime) {\n           // if provided id\u0027s start time falls before the end of the window,\n           // use it to construct the seek key\n           first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n               .add(fromId).getBytesForLookup();\n         }\n       }\n       // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n       if (first \u003d\u003d null) {\n         first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n       }\n       byte[] last \u003d null;\n       if (starttime !\u003d null) {\n         // if start time is not null, set a last key that will not be\n         // iterated past\n         last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n             .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n       }\n       if (limit \u003d\u003d null) {\n         // if limit is not specified, use the default\n         limit \u003d DEFAULT_LIMIT;\n       }\n \n       TimelineEntities entities \u003d new TimelineEntities();\n       iterator \u003d new LeveldbIterator(db);\n       iterator.seek(first);\n       // iterate until one of the following conditions is met: limit is\n       // reached, there are no more keys, the key prefix no longer matches,\n       // or a start time has been specified and reached/exceeded\n       while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n             WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                 last.length) \u003e 0)) {\n           break;\n         }\n         // read the start time and entity id from the current key\n         KeyParser kp \u003d new KeyParser(key, prefix.length);\n         Long startTime \u003d kp.getNextLong();\n         String entityId \u003d kp.getNextString();\n \n         if (fromTs !\u003d null) {\n           long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n               .getValue(), 0);\n           if (insertTime \u003e fromTs) {\n             byte[] firstKey \u003d key;\n             while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                 kp.getOffset(), key)) {\n               iterator.next();\n               key \u003d iterator.peekNext().getKey();\n             }\n             continue;\n           }\n         }\n \n         // parse the entity that owns this key, iterating over all keys for\n         // the entity\n         TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n             fields, iterator, key, kp.getOffset());\n         // determine if the retrieved entity matches the provided secondary\n         // filters, and if so add it to the list of entities to return\n         boolean filterPassed \u003d true;\n         if (secondaryFilters !\u003d null) {\n           for (NameValuePair filter : secondaryFilters) {\n             Object v \u003d entity.getOtherInfo().get(filter.getName());\n             if (v \u003d\u003d null) {\n               Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                   .get(filter.getName());\n               if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                 filterPassed \u003d false;\n                 break;\n               }\n             } else if (!v.equals(filter.getValue())) {\n               filterPassed \u003d false;\n               break;\n             }\n           }\n         }\n         if (filterPassed) {\n-          entities.addEntity(entity);\n+          if (entity.getDomainId() \u003d\u003d null) {\n+            entity.setDomainId(DEFAULT_DOMAIN_ID);\n+          }\n+          if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n+            entities.addEntity(entity);\n+          }\n         }\n       }\n       return entities;\n     } catch(DBException e) {\n       throw new IOException(e);   \t\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private TimelineEntities getEntityByTime(byte[] base,\n      String entityType, Long limit, Long starttime, Long endtime,\n      String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n      EnumSet\u003cField\u003e fields, CheckAcl checkAcl) throws IOException {\n    LeveldbIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n      // construct a first key that will be seeked to using end time or fromId\n      byte[] first \u003d null;\n      if (fromId !\u003d null) {\n        Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n        if (fromIdStartTime \u003d\u003d null) {\n          // no start time for provided id, so return empty entities\n          return new TimelineEntities();\n        }\n        if (fromIdStartTime \u003c\u003d endtime) {\n          // if provided id\u0027s start time falls before the end of the window,\n          // use it to construct the seek key\n          first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n              .add(fromId).getBytesForLookup();\n        }\n      }\n      // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n      if (first \u003d\u003d null) {\n        first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n      }\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      TimelineEntities entities \u003d new TimelineEntities();\n      iterator \u003d new LeveldbIterator(db);\n      iterator.seek(first);\n      // iterate until one of the following conditions is met: limit is\n      // reached, there are no more keys, the key prefix no longer matches,\n      // or a start time has been specified and reached/exceeded\n      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                last.length) \u003e 0)) {\n          break;\n        }\n        // read the start time and entity id from the current key\n        KeyParser kp \u003d new KeyParser(key, prefix.length);\n        Long startTime \u003d kp.getNextLong();\n        String entityId \u003d kp.getNextString();\n\n        if (fromTs !\u003d null) {\n          long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n              .getValue(), 0);\n          if (insertTime \u003e fromTs) {\n            byte[] firstKey \u003d key;\n            while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                kp.getOffset(), key)) {\n              iterator.next();\n              key \u003d iterator.peekNext().getKey();\n            }\n            continue;\n          }\n        }\n\n        // parse the entity that owns this key, iterating over all keys for\n        // the entity\n        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n            fields, iterator, key, kp.getOffset());\n        // determine if the retrieved entity matches the provided secondary\n        // filters, and if so add it to the list of entities to return\n        boolean filterPassed \u003d true;\n        if (secondaryFilters !\u003d null) {\n          for (NameValuePair filter : secondaryFilters) {\n            Object v \u003d entity.getOtherInfo().get(filter.getName());\n            if (v \u003d\u003d null) {\n              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                  .get(filter.getName());\n              if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            } else if (!v.equals(filter.getValue())) {\n              filterPassed \u003d false;\n              break;\n            }\n          }\n        }\n        if (filterPassed) {\n          if (entity.getDomainId() \u003d\u003d null) {\n            entity.setDomainId(DEFAULT_DOMAIN_ID);\n          }\n          if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n            entities.addEntity(entity);\n          }\n        }\n      }\n      return entities;\n    } catch(DBException e) {\n      throw new IOException(e);   \t\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
          "extendedDetails": {
            "oldValue": "[base-byte[], entityType-String, limit-Long, starttime-Long, endtime-Long, fromId-String, fromTs-Long, secondaryFilters-Collection\u003cNameValuePair\u003e, fields-EnumSet\u003cField\u003e]",
            "newValue": "[base-byte[], entityType-String, limit-Long, starttime-Long, endtime-Long, fromId-String, fromTs-Long, secondaryFilters-Collection\u003cNameValuePair\u003e, fields-EnumSet\u003cField\u003e, checkAcl-CheckAcl]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-3267. Timelineserver applies the ACL rules after applying the limit on the number of records (Chang Li via jeagles)\n",
          "commitDate": "13/03/15 10:04 AM",
          "commitName": "8180e676abb2bb500a48b3a0c0809d2a807ab235",
          "commitAuthor": "Jonathan Eagles",
          "commitDateOld": "17/02/15 6:17 PM",
          "commitNameOld": "57db50cbe3ce42618ad6d6869ae337d15b261f4e",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 23.62,
          "commitsBetweenForRepo": 182,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,110 +1,115 @@\n   private TimelineEntities getEntityByTime(byte[] base,\n       String entityType, Long limit, Long starttime, Long endtime,\n       String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n-      EnumSet\u003cField\u003e fields) throws IOException {\n+      EnumSet\u003cField\u003e fields, CheckAcl checkAcl) throws IOException {\n     LeveldbIterator iterator \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n       // only db keys matching the prefix (base + entity type) will be parsed\n       byte[] prefix \u003d kb.getBytesForLookup();\n       if (endtime \u003d\u003d null) {\n         // if end time is null, place no restriction on end time\n         endtime \u003d Long.MAX_VALUE;\n       }\n       // construct a first key that will be seeked to using end time or fromId\n       byte[] first \u003d null;\n       if (fromId !\u003d null) {\n         Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n         if (fromIdStartTime \u003d\u003d null) {\n           // no start time for provided id, so return empty entities\n           return new TimelineEntities();\n         }\n         if (fromIdStartTime \u003c\u003d endtime) {\n           // if provided id\u0027s start time falls before the end of the window,\n           // use it to construct the seek key\n           first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n               .add(fromId).getBytesForLookup();\n         }\n       }\n       // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n       if (first \u003d\u003d null) {\n         first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n       }\n       byte[] last \u003d null;\n       if (starttime !\u003d null) {\n         // if start time is not null, set a last key that will not be\n         // iterated past\n         last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n             .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n       }\n       if (limit \u003d\u003d null) {\n         // if limit is not specified, use the default\n         limit \u003d DEFAULT_LIMIT;\n       }\n \n       TimelineEntities entities \u003d new TimelineEntities();\n       iterator \u003d new LeveldbIterator(db);\n       iterator.seek(first);\n       // iterate until one of the following conditions is met: limit is\n       // reached, there are no more keys, the key prefix no longer matches,\n       // or a start time has been specified and reached/exceeded\n       while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n             WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                 last.length) \u003e 0)) {\n           break;\n         }\n         // read the start time and entity id from the current key\n         KeyParser kp \u003d new KeyParser(key, prefix.length);\n         Long startTime \u003d kp.getNextLong();\n         String entityId \u003d kp.getNextString();\n \n         if (fromTs !\u003d null) {\n           long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n               .getValue(), 0);\n           if (insertTime \u003e fromTs) {\n             byte[] firstKey \u003d key;\n             while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                 kp.getOffset(), key)) {\n               iterator.next();\n               key \u003d iterator.peekNext().getKey();\n             }\n             continue;\n           }\n         }\n \n         // parse the entity that owns this key, iterating over all keys for\n         // the entity\n         TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n             fields, iterator, key, kp.getOffset());\n         // determine if the retrieved entity matches the provided secondary\n         // filters, and if so add it to the list of entities to return\n         boolean filterPassed \u003d true;\n         if (secondaryFilters !\u003d null) {\n           for (NameValuePair filter : secondaryFilters) {\n             Object v \u003d entity.getOtherInfo().get(filter.getName());\n             if (v \u003d\u003d null) {\n               Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                   .get(filter.getName());\n               if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                 filterPassed \u003d false;\n                 break;\n               }\n             } else if (!v.equals(filter.getValue())) {\n               filterPassed \u003d false;\n               break;\n             }\n           }\n         }\n         if (filterPassed) {\n-          entities.addEntity(entity);\n+          if (entity.getDomainId() \u003d\u003d null) {\n+            entity.setDomainId(DEFAULT_DOMAIN_ID);\n+          }\n+          if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n+            entities.addEntity(entity);\n+          }\n         }\n       }\n       return entities;\n     } catch(DBException e) {\n       throw new IOException(e);   \t\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private TimelineEntities getEntityByTime(byte[] base,\n      String entityType, Long limit, Long starttime, Long endtime,\n      String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n      EnumSet\u003cField\u003e fields, CheckAcl checkAcl) throws IOException {\n    LeveldbIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n      // construct a first key that will be seeked to using end time or fromId\n      byte[] first \u003d null;\n      if (fromId !\u003d null) {\n        Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n        if (fromIdStartTime \u003d\u003d null) {\n          // no start time for provided id, so return empty entities\n          return new TimelineEntities();\n        }\n        if (fromIdStartTime \u003c\u003d endtime) {\n          // if provided id\u0027s start time falls before the end of the window,\n          // use it to construct the seek key\n          first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n              .add(fromId).getBytesForLookup();\n        }\n      }\n      // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n      if (first \u003d\u003d null) {\n        first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n      }\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      TimelineEntities entities \u003d new TimelineEntities();\n      iterator \u003d new LeveldbIterator(db);\n      iterator.seek(first);\n      // iterate until one of the following conditions is met: limit is\n      // reached, there are no more keys, the key prefix no longer matches,\n      // or a start time has been specified and reached/exceeded\n      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                last.length) \u003e 0)) {\n          break;\n        }\n        // read the start time and entity id from the current key\n        KeyParser kp \u003d new KeyParser(key, prefix.length);\n        Long startTime \u003d kp.getNextLong();\n        String entityId \u003d kp.getNextString();\n\n        if (fromTs !\u003d null) {\n          long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n              .getValue(), 0);\n          if (insertTime \u003e fromTs) {\n            byte[] firstKey \u003d key;\n            while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                kp.getOffset(), key)) {\n              iterator.next();\n              key \u003d iterator.peekNext().getKey();\n            }\n            continue;\n          }\n        }\n\n        // parse the entity that owns this key, iterating over all keys for\n        // the entity\n        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n            fields, iterator, key, kp.getOffset());\n        // determine if the retrieved entity matches the provided secondary\n        // filters, and if so add it to the list of entities to return\n        boolean filterPassed \u003d true;\n        if (secondaryFilters !\u003d null) {\n          for (NameValuePair filter : secondaryFilters) {\n            Object v \u003d entity.getOtherInfo().get(filter.getName());\n            if (v \u003d\u003d null) {\n              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                  .get(filter.getName());\n              if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            } else if (!v.equals(filter.getValue())) {\n              filterPassed \u003d false;\n              break;\n            }\n          }\n        }\n        if (filterPassed) {\n          if (entity.getDomainId() \u003d\u003d null) {\n            entity.setDomainId(DEFAULT_DOMAIN_ID);\n          }\n          if (checkAcl \u003d\u003d null || checkAcl.check(entity)) {\n            entities.addEntity(entity);\n          }\n        }\n      }\n      return entities;\n    } catch(DBException e) {\n      throw new IOException(e);   \t\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
          "extendedDetails": {}
        }
      ]
    },
    "57db50cbe3ce42618ad6d6869ae337d15b261f4e": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3207. Secondary filter matches entites which do not have the key\nbeing filtered for. Contributed by Zhijie Shen\n",
      "commitDate": "17/02/15 6:17 PM",
      "commitName": "57db50cbe3ce42618ad6d6869ae337d15b261f4e",
      "commitAuthor": "Xuan",
      "commitDateOld": "29/12/14 9:59 AM",
      "commitNameOld": "241d3b3a50c6af92f023d8b2c24598f4813f4674",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 50.35,
      "commitsBetweenForRepo": 411,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,110 +1,110 @@\n   private TimelineEntities getEntityByTime(byte[] base,\n       String entityType, Long limit, Long starttime, Long endtime,\n       String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n       EnumSet\u003cField\u003e fields) throws IOException {\n     LeveldbIterator iterator \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n       // only db keys matching the prefix (base + entity type) will be parsed\n       byte[] prefix \u003d kb.getBytesForLookup();\n       if (endtime \u003d\u003d null) {\n         // if end time is null, place no restriction on end time\n         endtime \u003d Long.MAX_VALUE;\n       }\n       // construct a first key that will be seeked to using end time or fromId\n       byte[] first \u003d null;\n       if (fromId !\u003d null) {\n         Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n         if (fromIdStartTime \u003d\u003d null) {\n           // no start time for provided id, so return empty entities\n           return new TimelineEntities();\n         }\n         if (fromIdStartTime \u003c\u003d endtime) {\n           // if provided id\u0027s start time falls before the end of the window,\n           // use it to construct the seek key\n           first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n               .add(fromId).getBytesForLookup();\n         }\n       }\n       // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n       if (first \u003d\u003d null) {\n         first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n       }\n       byte[] last \u003d null;\n       if (starttime !\u003d null) {\n         // if start time is not null, set a last key that will not be\n         // iterated past\n         last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n             .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n       }\n       if (limit \u003d\u003d null) {\n         // if limit is not specified, use the default\n         limit \u003d DEFAULT_LIMIT;\n       }\n \n       TimelineEntities entities \u003d new TimelineEntities();\n       iterator \u003d new LeveldbIterator(db);\n       iterator.seek(first);\n       // iterate until one of the following conditions is met: limit is\n       // reached, there are no more keys, the key prefix no longer matches,\n       // or a start time has been specified and reached/exceeded\n       while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n             WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                 last.length) \u003e 0)) {\n           break;\n         }\n         // read the start time and entity id from the current key\n         KeyParser kp \u003d new KeyParser(key, prefix.length);\n         Long startTime \u003d kp.getNextLong();\n         String entityId \u003d kp.getNextString();\n \n         if (fromTs !\u003d null) {\n           long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n               .getValue(), 0);\n           if (insertTime \u003e fromTs) {\n             byte[] firstKey \u003d key;\n             while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                 kp.getOffset(), key)) {\n               iterator.next();\n               key \u003d iterator.peekNext().getKey();\n             }\n             continue;\n           }\n         }\n \n         // parse the entity that owns this key, iterating over all keys for\n         // the entity\n         TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n             fields, iterator, key, kp.getOffset());\n         // determine if the retrieved entity matches the provided secondary\n         // filters, and if so add it to the list of entities to return\n         boolean filterPassed \u003d true;\n         if (secondaryFilters !\u003d null) {\n           for (NameValuePair filter : secondaryFilters) {\n             Object v \u003d entity.getOtherInfo().get(filter.getName());\n             if (v \u003d\u003d null) {\n               Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                   .get(filter.getName());\n-              if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n+              if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                 filterPassed \u003d false;\n                 break;\n               }\n             } else if (!v.equals(filter.getValue())) {\n               filterPassed \u003d false;\n               break;\n             }\n           }\n         }\n         if (filterPassed) {\n           entities.addEntity(entity);\n         }\n       }\n       return entities;\n     } catch(DBException e) {\n       throw new IOException(e);   \t\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private TimelineEntities getEntityByTime(byte[] base,\n      String entityType, Long limit, Long starttime, Long endtime,\n      String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n      EnumSet\u003cField\u003e fields) throws IOException {\n    LeveldbIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n      // construct a first key that will be seeked to using end time or fromId\n      byte[] first \u003d null;\n      if (fromId !\u003d null) {\n        Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n        if (fromIdStartTime \u003d\u003d null) {\n          // no start time for provided id, so return empty entities\n          return new TimelineEntities();\n        }\n        if (fromIdStartTime \u003c\u003d endtime) {\n          // if provided id\u0027s start time falls before the end of the window,\n          // use it to construct the seek key\n          first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n              .add(fromId).getBytesForLookup();\n        }\n      }\n      // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n      if (first \u003d\u003d null) {\n        first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n      }\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      TimelineEntities entities \u003d new TimelineEntities();\n      iterator \u003d new LeveldbIterator(db);\n      iterator.seek(first);\n      // iterate until one of the following conditions is met: limit is\n      // reached, there are no more keys, the key prefix no longer matches,\n      // or a start time has been specified and reached/exceeded\n      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                last.length) \u003e 0)) {\n          break;\n        }\n        // read the start time and entity id from the current key\n        KeyParser kp \u003d new KeyParser(key, prefix.length);\n        Long startTime \u003d kp.getNextLong();\n        String entityId \u003d kp.getNextString();\n\n        if (fromTs !\u003d null) {\n          long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n              .getValue(), 0);\n          if (insertTime \u003e fromTs) {\n            byte[] firstKey \u003d key;\n            while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                kp.getOffset(), key)) {\n              iterator.next();\n              key \u003d iterator.peekNext().getKey();\n            }\n            continue;\n          }\n        }\n\n        // parse the entity that owns this key, iterating over all keys for\n        // the entity\n        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n            fields, iterator, key, kp.getOffset());\n        // determine if the retrieved entity matches the provided secondary\n        // filters, and if so add it to the list of entities to return\n        boolean filterPassed \u003d true;\n        if (secondaryFilters !\u003d null) {\n          for (NameValuePair filter : secondaryFilters) {\n            Object v \u003d entity.getOtherInfo().get(filter.getName());\n            if (v \u003d\u003d null) {\n              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                  .get(filter.getName());\n              if (vs \u003d\u003d null || !vs.contains(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            } else if (!v.equals(filter.getValue())) {\n              filterPassed \u003d false;\n              break;\n            }\n          }\n        }\n        if (filterPassed) {\n          entities.addEntity(entity);\n        }\n      }\n      return entities;\n    } catch(DBException e) {\n      throw new IOException(e);   \t\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {}
    },
    "1ce4d33c2dc86d711b227a04d2f9a2ab696a24a1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1984. LeveldbTimelineStore does not handle db exceptions properly. Contributed by Varun Saxena\n",
      "commitDate": "24/11/14 2:36 PM",
      "commitName": "1ce4d33c2dc86d711b227a04d2f9a2ab696a24a1",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "07/11/14 4:11 PM",
      "commitNameOld": "4a114dd67aae83e5bb2d65470166de954acf36a2",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 16.93,
      "commitsBetweenForRepo": 118,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,108 +1,110 @@\n   private TimelineEntities getEntityByTime(byte[] base,\n       String entityType, Long limit, Long starttime, Long endtime,\n       String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n       EnumSet\u003cField\u003e fields) throws IOException {\n-    DBIterator iterator \u003d null;\n+    LeveldbIterator iterator \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n       // only db keys matching the prefix (base + entity type) will be parsed\n       byte[] prefix \u003d kb.getBytesForLookup();\n       if (endtime \u003d\u003d null) {\n         // if end time is null, place no restriction on end time\n         endtime \u003d Long.MAX_VALUE;\n       }\n       // construct a first key that will be seeked to using end time or fromId\n       byte[] first \u003d null;\n       if (fromId !\u003d null) {\n         Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n         if (fromIdStartTime \u003d\u003d null) {\n           // no start time for provided id, so return empty entities\n           return new TimelineEntities();\n         }\n         if (fromIdStartTime \u003c\u003d endtime) {\n           // if provided id\u0027s start time falls before the end of the window,\n           // use it to construct the seek key\n           first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n               .add(fromId).getBytesForLookup();\n         }\n       }\n       // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n       if (first \u003d\u003d null) {\n         first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n       }\n       byte[] last \u003d null;\n       if (starttime !\u003d null) {\n         // if start time is not null, set a last key that will not be\n         // iterated past\n         last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n             .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n       }\n       if (limit \u003d\u003d null) {\n         // if limit is not specified, use the default\n         limit \u003d DEFAULT_LIMIT;\n       }\n \n       TimelineEntities entities \u003d new TimelineEntities();\n-      iterator \u003d db.iterator();\n+      iterator \u003d new LeveldbIterator(db);\n       iterator.seek(first);\n       // iterate until one of the following conditions is met: limit is\n       // reached, there are no more keys, the key prefix no longer matches,\n       // or a start time has been specified and reached/exceeded\n       while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n             WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                 last.length) \u003e 0)) {\n           break;\n         }\n         // read the start time and entity id from the current key\n         KeyParser kp \u003d new KeyParser(key, prefix.length);\n         Long startTime \u003d kp.getNextLong();\n         String entityId \u003d kp.getNextString();\n \n         if (fromTs !\u003d null) {\n           long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n               .getValue(), 0);\n           if (insertTime \u003e fromTs) {\n             byte[] firstKey \u003d key;\n             while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                 kp.getOffset(), key)) {\n               iterator.next();\n               key \u003d iterator.peekNext().getKey();\n             }\n             continue;\n           }\n         }\n \n         // parse the entity that owns this key, iterating over all keys for\n         // the entity\n         TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n             fields, iterator, key, kp.getOffset());\n         // determine if the retrieved entity matches the provided secondary\n         // filters, and if so add it to the list of entities to return\n         boolean filterPassed \u003d true;\n         if (secondaryFilters !\u003d null) {\n           for (NameValuePair filter : secondaryFilters) {\n             Object v \u003d entity.getOtherInfo().get(filter.getName());\n             if (v \u003d\u003d null) {\n               Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                   .get(filter.getName());\n               if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n                 filterPassed \u003d false;\n                 break;\n               }\n             } else if (!v.equals(filter.getValue())) {\n               filterPassed \u003d false;\n               break;\n             }\n           }\n         }\n         if (filterPassed) {\n           entities.addEntity(entity);\n         }\n       }\n       return entities;\n+    } catch(DBException e) {\n+      throw new IOException(e);   \t\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private TimelineEntities getEntityByTime(byte[] base,\n      String entityType, Long limit, Long starttime, Long endtime,\n      String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n      EnumSet\u003cField\u003e fields) throws IOException {\n    LeveldbIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n      // construct a first key that will be seeked to using end time or fromId\n      byte[] first \u003d null;\n      if (fromId !\u003d null) {\n        Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n        if (fromIdStartTime \u003d\u003d null) {\n          // no start time for provided id, so return empty entities\n          return new TimelineEntities();\n        }\n        if (fromIdStartTime \u003c\u003d endtime) {\n          // if provided id\u0027s start time falls before the end of the window,\n          // use it to construct the seek key\n          first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n              .add(fromId).getBytesForLookup();\n        }\n      }\n      // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n      if (first \u003d\u003d null) {\n        first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n      }\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      TimelineEntities entities \u003d new TimelineEntities();\n      iterator \u003d new LeveldbIterator(db);\n      iterator.seek(first);\n      // iterate until one of the following conditions is met: limit is\n      // reached, there are no more keys, the key prefix no longer matches,\n      // or a start time has been specified and reached/exceeded\n      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                last.length) \u003e 0)) {\n          break;\n        }\n        // read the start time and entity id from the current key\n        KeyParser kp \u003d new KeyParser(key, prefix.length);\n        Long startTime \u003d kp.getNextLong();\n        String entityId \u003d kp.getNextString();\n\n        if (fromTs !\u003d null) {\n          long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n              .getValue(), 0);\n          if (insertTime \u003e fromTs) {\n            byte[] firstKey \u003d key;\n            while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                kp.getOffset(), key)) {\n              iterator.next();\n              key \u003d iterator.peekNext().getKey();\n            }\n            continue;\n          }\n        }\n\n        // parse the entity that owns this key, iterating over all keys for\n        // the entity\n        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n            fields, iterator, key, kp.getOffset());\n        // determine if the retrieved entity matches the provided secondary\n        // filters, and if so add it to the list of entities to return\n        boolean filterPassed \u003d true;\n        if (secondaryFilters !\u003d null) {\n          for (NameValuePair filter : secondaryFilters) {\n            Object v \u003d entity.getOtherInfo().get(filter.getName());\n            if (v \u003d\u003d null) {\n              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                  .get(filter.getName());\n              if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            } else if (!v.equals(filter.getValue())) {\n              filterPassed \u003d false;\n              break;\n            }\n          }\n        }\n        if (filterPassed) {\n          entities.addEntity(entity);\n        }\n      }\n      return entities;\n    } catch(DBException e) {\n      throw new IOException(e);   \t\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {}
    },
    "001078e0677e39b962ca1da81fc34d7ac9a7e65c": {
      "type": "Yfilerename",
      "commitMessage": "YARN-2107. Refactored timeline classes into o.a.h.y.s.timeline package. Contributed by Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1598094 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/05/14 11:09 AM",
      "commitName": "001078e0677e39b962ca1da81fc34d7ac9a7e65c",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "28/05/14 10:44 AM",
      "commitNameOld": "cfd8647d0f20c08761f908be1f5b718c1c372498",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private TimelineEntities getEntityByTime(byte[] base,\n      String entityType, Long limit, Long starttime, Long endtime,\n      String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n      EnumSet\u003cField\u003e fields) throws IOException {\n    DBIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n      // construct a first key that will be seeked to using end time or fromId\n      byte[] first \u003d null;\n      if (fromId !\u003d null) {\n        Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n        if (fromIdStartTime \u003d\u003d null) {\n          // no start time for provided id, so return empty entities\n          return new TimelineEntities();\n        }\n        if (fromIdStartTime \u003c\u003d endtime) {\n          // if provided id\u0027s start time falls before the end of the window,\n          // use it to construct the seek key\n          first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n              .add(fromId).getBytesForLookup();\n        }\n      }\n      // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n      if (first \u003d\u003d null) {\n        first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n      }\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      TimelineEntities entities \u003d new TimelineEntities();\n      iterator \u003d db.iterator();\n      iterator.seek(first);\n      // iterate until one of the following conditions is met: limit is\n      // reached, there are no more keys, the key prefix no longer matches,\n      // or a start time has been specified and reached/exceeded\n      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                last.length) \u003e 0)) {\n          break;\n        }\n        // read the start time and entity id from the current key\n        KeyParser kp \u003d new KeyParser(key, prefix.length);\n        Long startTime \u003d kp.getNextLong();\n        String entityId \u003d kp.getNextString();\n\n        if (fromTs !\u003d null) {\n          long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n              .getValue(), 0);\n          if (insertTime \u003e fromTs) {\n            byte[] firstKey \u003d key;\n            while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                kp.getOffset(), key)) {\n              iterator.next();\n              key \u003d iterator.peekNext().getKey();\n            }\n            continue;\n          }\n        }\n\n        // parse the entity that owns this key, iterating over all keys for\n        // the entity\n        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n            fields, iterator, key, kp.getOffset());\n        // determine if the retrieved entity matches the provided secondary\n        // filters, and if so add it to the list of entities to return\n        boolean filterPassed \u003d true;\n        if (secondaryFilters !\u003d null) {\n          for (NameValuePair filter : secondaryFilters) {\n            Object v \u003d entity.getOtherInfo().get(filter.getName());\n            if (v \u003d\u003d null) {\n              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                  .get(filter.getName());\n              if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            } else if (!v.equals(filter.getValue())) {\n              filterPassed \u003d false;\n              break;\n            }\n          }\n        }\n        if (filterPassed) {\n          entities.addEntity(entity);\n        }\n      }\n      return entities;\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/LeveldbTimelineStore.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java"
      }
    },
    "0f1eda6bbf895a1239b25cdf8b17fabd3759e806": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-1838. Enhanced timeline service getEntities API to get entities from a given entity ID or insertion timestamp. Contributed by Billie Rinaldi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1580960 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/03/14 11:14 AM",
      "commitName": "0f1eda6bbf895a1239b25cdf8b17fabd3759e806",
      "commitAuthor": "Zhijie Shen",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-1838. Enhanced timeline service getEntities API to get entities from a given entity ID or insertion timestamp. Contributed by Billie Rinaldi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1580960 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/03/14 11:14 AM",
          "commitName": "0f1eda6bbf895a1239b25cdf8b17fabd3759e806",
          "commitAuthor": "Zhijie Shen",
          "commitDateOld": "14/03/14 1:35 PM",
          "commitNameOld": "b3ea4aebff42131642af0393748dc751cb3fc31e",
          "commitAuthorOld": "Zhijie Shen",
          "daysBetweenCommits": 9.9,
          "commitsBetweenForRepo": 64,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,78 +1,108 @@\n   private TimelineEntities getEntityByTime(byte[] base,\n       String entityType, Long limit, Long starttime, Long endtime,\n-      Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields)\n-      throws IOException {\n+      String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n+      EnumSet\u003cField\u003e fields) throws IOException {\n     DBIterator iterator \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n       // only db keys matching the prefix (base + entity type) will be parsed\n       byte[] prefix \u003d kb.getBytesForLookup();\n       if (endtime \u003d\u003d null) {\n         // if end time is null, place no restriction on end time\n         endtime \u003d Long.MAX_VALUE;\n       }\n-      // using end time, construct a first key that will be seeked to\n-      byte[] revts \u003d writeReverseOrderedLong(endtime);\n-      kb.add(revts);\n-      byte[] first \u003d kb.getBytesForLookup();\n+      // construct a first key that will be seeked to using end time or fromId\n+      byte[] first \u003d null;\n+      if (fromId !\u003d null) {\n+        Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n+        if (fromIdStartTime \u003d\u003d null) {\n+          // no start time for provided id, so return empty entities\n+          return new TimelineEntities();\n+        }\n+        if (fromIdStartTime \u003c\u003d endtime) {\n+          // if provided id\u0027s start time falls before the end of the window,\n+          // use it to construct the seek key\n+          first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n+              .add(fromId).getBytesForLookup();\n+        }\n+      }\n+      // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n+      if (first \u003d\u003d null) {\n+        first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n+      }\n       byte[] last \u003d null;\n       if (starttime !\u003d null) {\n         // if start time is not null, set a last key that will not be\n         // iterated past\n         last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n             .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n       }\n       if (limit \u003d\u003d null) {\n         // if limit is not specified, use the default\n         limit \u003d DEFAULT_LIMIT;\n       }\n \n       TimelineEntities entities \u003d new TimelineEntities();\n       iterator \u003d db.iterator();\n       iterator.seek(first);\n       // iterate until one of the following conditions is met: limit is\n       // reached, there are no more keys, the key prefix no longer matches,\n       // or a start time has been specified and reached/exceeded\n       while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n             WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                 last.length) \u003e 0)) {\n           break;\n         }\n         // read the start time and entity id from the current key\n         KeyParser kp \u003d new KeyParser(key, prefix.length);\n         Long startTime \u003d kp.getNextLong();\n         String entityId \u003d kp.getNextString();\n+\n+        if (fromTs !\u003d null) {\n+          long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n+              .getValue(), 0);\n+          if (insertTime \u003e fromTs) {\n+            byte[] firstKey \u003d key;\n+            while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n+                kp.getOffset(), key)) {\n+              iterator.next();\n+              key \u003d iterator.peekNext().getKey();\n+            }\n+            continue;\n+          }\n+        }\n+\n         // parse the entity that owns this key, iterating over all keys for\n         // the entity\n         TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n             fields, iterator, key, kp.getOffset());\n         // determine if the retrieved entity matches the provided secondary\n         // filters, and if so add it to the list of entities to return\n         boolean filterPassed \u003d true;\n         if (secondaryFilters !\u003d null) {\n           for (NameValuePair filter : secondaryFilters) {\n             Object v \u003d entity.getOtherInfo().get(filter.getName());\n             if (v \u003d\u003d null) {\n               Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                   .get(filter.getName());\n               if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n                 filterPassed \u003d false;\n                 break;\n               }\n             } else if (!v.equals(filter.getValue())) {\n               filterPassed \u003d false;\n               break;\n             }\n           }\n         }\n         if (filterPassed) {\n           entities.addEntity(entity);\n         }\n       }\n       return entities;\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private TimelineEntities getEntityByTime(byte[] base,\n      String entityType, Long limit, Long starttime, Long endtime,\n      String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n      EnumSet\u003cField\u003e fields) throws IOException {\n    DBIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n      // construct a first key that will be seeked to using end time or fromId\n      byte[] first \u003d null;\n      if (fromId !\u003d null) {\n        Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n        if (fromIdStartTime \u003d\u003d null) {\n          // no start time for provided id, so return empty entities\n          return new TimelineEntities();\n        }\n        if (fromIdStartTime \u003c\u003d endtime) {\n          // if provided id\u0027s start time falls before the end of the window,\n          // use it to construct the seek key\n          first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n              .add(fromId).getBytesForLookup();\n        }\n      }\n      // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n      if (first \u003d\u003d null) {\n        first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n      }\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      TimelineEntities entities \u003d new TimelineEntities();\n      iterator \u003d db.iterator();\n      iterator.seek(first);\n      // iterate until one of the following conditions is met: limit is\n      // reached, there are no more keys, the key prefix no longer matches,\n      // or a start time has been specified and reached/exceeded\n      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                last.length) \u003e 0)) {\n          break;\n        }\n        // read the start time and entity id from the current key\n        KeyParser kp \u003d new KeyParser(key, prefix.length);\n        Long startTime \u003d kp.getNextLong();\n        String entityId \u003d kp.getNextString();\n\n        if (fromTs !\u003d null) {\n          long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n              .getValue(), 0);\n          if (insertTime \u003e fromTs) {\n            byte[] firstKey \u003d key;\n            while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                kp.getOffset(), key)) {\n              iterator.next();\n              key \u003d iterator.peekNext().getKey();\n            }\n            continue;\n          }\n        }\n\n        // parse the entity that owns this key, iterating over all keys for\n        // the entity\n        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n            fields, iterator, key, kp.getOffset());\n        // determine if the retrieved entity matches the provided secondary\n        // filters, and if so add it to the list of entities to return\n        boolean filterPassed \u003d true;\n        if (secondaryFilters !\u003d null) {\n          for (NameValuePair filter : secondaryFilters) {\n            Object v \u003d entity.getOtherInfo().get(filter.getName());\n            if (v \u003d\u003d null) {\n              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                  .get(filter.getName());\n              if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            } else if (!v.equals(filter.getValue())) {\n              filterPassed \u003d false;\n              break;\n            }\n          }\n        }\n        if (filterPassed) {\n          entities.addEntity(entity);\n        }\n      }\n      return entities;\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/LeveldbTimelineStore.java",
          "extendedDetails": {
            "oldValue": "[base-byte[], entityType-String, limit-Long, starttime-Long, endtime-Long, secondaryFilters-Collection\u003cNameValuePair\u003e, fields-EnumSet\u003cField\u003e]",
            "newValue": "[base-byte[], entityType-String, limit-Long, starttime-Long, endtime-Long, fromId-String, fromTs-Long, secondaryFilters-Collection\u003cNameValuePair\u003e, fields-EnumSet\u003cField\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-1838. Enhanced timeline service getEntities API to get entities from a given entity ID or insertion timestamp. Contributed by Billie Rinaldi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1580960 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/03/14 11:14 AM",
          "commitName": "0f1eda6bbf895a1239b25cdf8b17fabd3759e806",
          "commitAuthor": "Zhijie Shen",
          "commitDateOld": "14/03/14 1:35 PM",
          "commitNameOld": "b3ea4aebff42131642af0393748dc751cb3fc31e",
          "commitAuthorOld": "Zhijie Shen",
          "daysBetweenCommits": 9.9,
          "commitsBetweenForRepo": 64,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,78 +1,108 @@\n   private TimelineEntities getEntityByTime(byte[] base,\n       String entityType, Long limit, Long starttime, Long endtime,\n-      Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields)\n-      throws IOException {\n+      String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n+      EnumSet\u003cField\u003e fields) throws IOException {\n     DBIterator iterator \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n       // only db keys matching the prefix (base + entity type) will be parsed\n       byte[] prefix \u003d kb.getBytesForLookup();\n       if (endtime \u003d\u003d null) {\n         // if end time is null, place no restriction on end time\n         endtime \u003d Long.MAX_VALUE;\n       }\n-      // using end time, construct a first key that will be seeked to\n-      byte[] revts \u003d writeReverseOrderedLong(endtime);\n-      kb.add(revts);\n-      byte[] first \u003d kb.getBytesForLookup();\n+      // construct a first key that will be seeked to using end time or fromId\n+      byte[] first \u003d null;\n+      if (fromId !\u003d null) {\n+        Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n+        if (fromIdStartTime \u003d\u003d null) {\n+          // no start time for provided id, so return empty entities\n+          return new TimelineEntities();\n+        }\n+        if (fromIdStartTime \u003c\u003d endtime) {\n+          // if provided id\u0027s start time falls before the end of the window,\n+          // use it to construct the seek key\n+          first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n+              .add(fromId).getBytesForLookup();\n+        }\n+      }\n+      // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n+      if (first \u003d\u003d null) {\n+        first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n+      }\n       byte[] last \u003d null;\n       if (starttime !\u003d null) {\n         // if start time is not null, set a last key that will not be\n         // iterated past\n         last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n             .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n       }\n       if (limit \u003d\u003d null) {\n         // if limit is not specified, use the default\n         limit \u003d DEFAULT_LIMIT;\n       }\n \n       TimelineEntities entities \u003d new TimelineEntities();\n       iterator \u003d db.iterator();\n       iterator.seek(first);\n       // iterate until one of the following conditions is met: limit is\n       // reached, there are no more keys, the key prefix no longer matches,\n       // or a start time has been specified and reached/exceeded\n       while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n             WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                 last.length) \u003e 0)) {\n           break;\n         }\n         // read the start time and entity id from the current key\n         KeyParser kp \u003d new KeyParser(key, prefix.length);\n         Long startTime \u003d kp.getNextLong();\n         String entityId \u003d kp.getNextString();\n+\n+        if (fromTs !\u003d null) {\n+          long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n+              .getValue(), 0);\n+          if (insertTime \u003e fromTs) {\n+            byte[] firstKey \u003d key;\n+            while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n+                kp.getOffset(), key)) {\n+              iterator.next();\n+              key \u003d iterator.peekNext().getKey();\n+            }\n+            continue;\n+          }\n+        }\n+\n         // parse the entity that owns this key, iterating over all keys for\n         // the entity\n         TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n             fields, iterator, key, kp.getOffset());\n         // determine if the retrieved entity matches the provided secondary\n         // filters, and if so add it to the list of entities to return\n         boolean filterPassed \u003d true;\n         if (secondaryFilters !\u003d null) {\n           for (NameValuePair filter : secondaryFilters) {\n             Object v \u003d entity.getOtherInfo().get(filter.getName());\n             if (v \u003d\u003d null) {\n               Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                   .get(filter.getName());\n               if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n                 filterPassed \u003d false;\n                 break;\n               }\n             } else if (!v.equals(filter.getValue())) {\n               filterPassed \u003d false;\n               break;\n             }\n           }\n         }\n         if (filterPassed) {\n           entities.addEntity(entity);\n         }\n       }\n       return entities;\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private TimelineEntities getEntityByTime(byte[] base,\n      String entityType, Long limit, Long starttime, Long endtime,\n      String fromId, Long fromTs, Collection\u003cNameValuePair\u003e secondaryFilters,\n      EnumSet\u003cField\u003e fields) throws IOException {\n    DBIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n      // construct a first key that will be seeked to using end time or fromId\n      byte[] first \u003d null;\n      if (fromId !\u003d null) {\n        Long fromIdStartTime \u003d getStartTimeLong(fromId, entityType);\n        if (fromIdStartTime \u003d\u003d null) {\n          // no start time for provided id, so return empty entities\n          return new TimelineEntities();\n        }\n        if (fromIdStartTime \u003c\u003d endtime) {\n          // if provided id\u0027s start time falls before the end of the window,\n          // use it to construct the seek key\n          first \u003d kb.add(writeReverseOrderedLong(fromIdStartTime))\n              .add(fromId).getBytesForLookup();\n        }\n      }\n      // if seek key wasn\u0027t constructed using fromId, construct it using end ts\n      if (first \u003d\u003d null) {\n        first \u003d kb.add(writeReverseOrderedLong(endtime)).getBytesForLookup();\n      }\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      TimelineEntities entities \u003d new TimelineEntities();\n      iterator \u003d db.iterator();\n      iterator.seek(first);\n      // iterate until one of the following conditions is met: limit is\n      // reached, there are no more keys, the key prefix no longer matches,\n      // or a start time has been specified and reached/exceeded\n      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                last.length) \u003e 0)) {\n          break;\n        }\n        // read the start time and entity id from the current key\n        KeyParser kp \u003d new KeyParser(key, prefix.length);\n        Long startTime \u003d kp.getNextLong();\n        String entityId \u003d kp.getNextString();\n\n        if (fromTs !\u003d null) {\n          long insertTime \u003d readReverseOrderedLong(iterator.peekNext()\n              .getValue(), 0);\n          if (insertTime \u003e fromTs) {\n            byte[] firstKey \u003d key;\n            while (iterator.hasNext() \u0026\u0026 prefixMatches(firstKey,\n                kp.getOffset(), key)) {\n              iterator.next();\n              key \u003d iterator.peekNext().getKey();\n            }\n            continue;\n          }\n        }\n\n        // parse the entity that owns this key, iterating over all keys for\n        // the entity\n        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n            fields, iterator, key, kp.getOffset());\n        // determine if the retrieved entity matches the provided secondary\n        // filters, and if so add it to the list of entities to return\n        boolean filterPassed \u003d true;\n        if (secondaryFilters !\u003d null) {\n          for (NameValuePair filter : secondaryFilters) {\n            Object v \u003d entity.getOtherInfo().get(filter.getName());\n            if (v \u003d\u003d null) {\n              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                  .get(filter.getName());\n              if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            } else if (!v.equals(filter.getValue())) {\n              filterPassed \u003d false;\n              break;\n            }\n          }\n        }\n        if (filterPassed) {\n          entities.addEntity(entity);\n        }\n      }\n      return entities;\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/LeveldbTimelineStore.java",
          "extendedDetails": {}
        }
      ]
    },
    "b3ea4aebff42131642af0393748dc751cb3fc31e": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1717. Enabled periodically discarding old data in LeveldbTimelineStore. Contributed by Billie Rinaldi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1577693 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/03/14 1:35 PM",
      "commitName": "b3ea4aebff42131642af0393748dc751cb3fc31e",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "04/03/14 9:32 AM",
      "commitNameOld": "40464fba22bac99d0e5b79674152aa5dfba99483",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 10.13,
      "commitsBetweenForRepo": 99,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,78 @@\n   private TimelineEntities getEntityByTime(byte[] base,\n       String entityType, Long limit, Long starttime, Long endtime,\n       Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields)\n       throws IOException {\n     DBIterator iterator \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n       // only db keys matching the prefix (base + entity type) will be parsed\n       byte[] prefix \u003d kb.getBytesForLookup();\n       if (endtime \u003d\u003d null) {\n         // if end time is null, place no restriction on end time\n         endtime \u003d Long.MAX_VALUE;\n       }\n       // using end time, construct a first key that will be seeked to\n       byte[] revts \u003d writeReverseOrderedLong(endtime);\n       kb.add(revts);\n       byte[] first \u003d kb.getBytesForLookup();\n       byte[] last \u003d null;\n       if (starttime !\u003d null) {\n         // if start time is not null, set a last key that will not be\n         // iterated past\n         last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n             .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n       }\n       if (limit \u003d\u003d null) {\n         // if limit is not specified, use the default\n         limit \u003d DEFAULT_LIMIT;\n       }\n \n       TimelineEntities entities \u003d new TimelineEntities();\n       iterator \u003d db.iterator();\n       iterator.seek(first);\n       // iterate until one of the following conditions is met: limit is\n       // reached, there are no more keys, the key prefix no longer matches,\n       // or a start time has been specified and reached/exceeded\n       while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n             WritableComparator.compareBytes(key, 0, key.length, last, 0,\n-                last.length) \u003e 0))\n+                last.length) \u003e 0)) {\n           break;\n-        // read the start time and entityId from the current key\n+        }\n+        // read the start time and entity id from the current key\n         KeyParser kp \u003d new KeyParser(key, prefix.length);\n         Long startTime \u003d kp.getNextLong();\n         String entityId \u003d kp.getNextString();\n         // parse the entity that owns this key, iterating over all keys for\n         // the entity\n         TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n             fields, iterator, key, kp.getOffset());\n-        if (entity \u003d\u003d null)\n-          continue;\n         // determine if the retrieved entity matches the provided secondary\n         // filters, and if so add it to the list of entities to return\n         boolean filterPassed \u003d true;\n         if (secondaryFilters !\u003d null) {\n           for (NameValuePair filter : secondaryFilters) {\n             Object v \u003d entity.getOtherInfo().get(filter.getName());\n             if (v \u003d\u003d null) {\n               Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                   .get(filter.getName());\n               if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n                 filterPassed \u003d false;\n                 break;\n               }\n             } else if (!v.equals(filter.getValue())) {\n               filterPassed \u003d false;\n               break;\n             }\n           }\n         }\n-        if (filterPassed)\n+        if (filterPassed) {\n           entities.addEntity(entity);\n+        }\n       }\n       return entities;\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private TimelineEntities getEntityByTime(byte[] base,\n      String entityType, Long limit, Long starttime, Long endtime,\n      Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields)\n      throws IOException {\n    DBIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n      // using end time, construct a first key that will be seeked to\n      byte[] revts \u003d writeReverseOrderedLong(endtime);\n      kb.add(revts);\n      byte[] first \u003d kb.getBytesForLookup();\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      TimelineEntities entities \u003d new TimelineEntities();\n      iterator \u003d db.iterator();\n      iterator.seek(first);\n      // iterate until one of the following conditions is met: limit is\n      // reached, there are no more keys, the key prefix no longer matches,\n      // or a start time has been specified and reached/exceeded\n      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                last.length) \u003e 0)) {\n          break;\n        }\n        // read the start time and entity id from the current key\n        KeyParser kp \u003d new KeyParser(key, prefix.length);\n        Long startTime \u003d kp.getNextLong();\n        String entityId \u003d kp.getNextString();\n        // parse the entity that owns this key, iterating over all keys for\n        // the entity\n        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n            fields, iterator, key, kp.getOffset());\n        // determine if the retrieved entity matches the provided secondary\n        // filters, and if so add it to the list of entities to return\n        boolean filterPassed \u003d true;\n        if (secondaryFilters !\u003d null) {\n          for (NameValuePair filter : secondaryFilters) {\n            Object v \u003d entity.getOtherInfo().get(filter.getName());\n            if (v \u003d\u003d null) {\n              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                  .get(filter.getName());\n              if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            } else if (!v.equals(filter.getValue())) {\n              filterPassed \u003d false;\n              break;\n            }\n          }\n        }\n        if (filterPassed) {\n          entities.addEntity(entity);\n        }\n      }\n      return entities;\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {}
    },
    "84425fb435cb603fd8adcc2f76631c0244175310": {
      "type": "Ymultichange(Yfilerename,Yreturntypechange,Ybodychange)",
      "commitMessage": "YARN-1687. Renamed user-facing records for the timeline-service to be simply named after \u0027timeline\u0027 instead of \u0027apptimeline\u0027. Contributed by Zhijie Shen.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1570922 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/02/14 12:55 PM",
      "commitName": "84425fb435cb603fd8adcc2f76631c0244175310",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "YARN-1687. Renamed user-facing records for the timeline-service to be simply named after \u0027timeline\u0027 instead of \u0027apptimeline\u0027. Contributed by Zhijie Shen.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1570922 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/02/14 12:55 PM",
          "commitName": "84425fb435cb603fd8adcc2f76631c0244175310",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "22/02/14 12:46 PM",
          "commitNameOld": "e06226126cd89d0cf8b4ef80a88659b248579231",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,78 +1,78 @@\n-  private ATSEntities getEntityByTime(byte[] base,\n+  private TimelineEntities getEntityByTime(byte[] base,\n       String entityType, Long limit, Long starttime, Long endtime,\n       Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields)\n       throws IOException {\n     DBIterator iterator \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n       // only db keys matching the prefix (base + entity type) will be parsed\n       byte[] prefix \u003d kb.getBytesForLookup();\n       if (endtime \u003d\u003d null) {\n         // if end time is null, place no restriction on end time\n         endtime \u003d Long.MAX_VALUE;\n       }\n       // using end time, construct a first key that will be seeked to\n       byte[] revts \u003d writeReverseOrderedLong(endtime);\n       kb.add(revts);\n       byte[] first \u003d kb.getBytesForLookup();\n       byte[] last \u003d null;\n       if (starttime !\u003d null) {\n         // if start time is not null, set a last key that will not be\n         // iterated past\n         last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n             .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n       }\n       if (limit \u003d\u003d null) {\n         // if limit is not specified, use the default\n         limit \u003d DEFAULT_LIMIT;\n       }\n \n-      ATSEntities atsEntities \u003d new ATSEntities();\n+      TimelineEntities entities \u003d new TimelineEntities();\n       iterator \u003d db.iterator();\n       iterator.seek(first);\n       // iterate until one of the following conditions is met: limit is\n       // reached, there are no more keys, the key prefix no longer matches,\n       // or a start time has been specified and reached/exceeded\n-      while (atsEntities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n+      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n             WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                 last.length) \u003e 0))\n           break;\n-        // read the start time and entity from the current key\n+        // read the start time and entityId from the current key\n         KeyParser kp \u003d new KeyParser(key, prefix.length);\n         Long startTime \u003d kp.getNextLong();\n-        String entity \u003d kp.getNextString();\n+        String entityId \u003d kp.getNextString();\n         // parse the entity that owns this key, iterating over all keys for\n         // the entity\n-        ATSEntity atsEntity \u003d getEntity(entity, entityType, startTime,\n+        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n             fields, iterator, key, kp.getOffset());\n-        if (atsEntity \u003d\u003d null)\n+        if (entity \u003d\u003d null)\n           continue;\n         // determine if the retrieved entity matches the provided secondary\n         // filters, and if so add it to the list of entities to return\n         boolean filterPassed \u003d true;\n         if (secondaryFilters !\u003d null) {\n           for (NameValuePair filter : secondaryFilters) {\n-            Object v \u003d atsEntity.getOtherInfo().get(filter.getName());\n+            Object v \u003d entity.getOtherInfo().get(filter.getName());\n             if (v \u003d\u003d null) {\n-              Set\u003cObject\u003e vs \u003d atsEntity.getPrimaryFilters()\n+              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                   .get(filter.getName());\n               if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n                 filterPassed \u003d false;\n                 break;\n               }\n             } else if (!v.equals(filter.getValue())) {\n               filterPassed \u003d false;\n               break;\n             }\n           }\n         }\n         if (filterPassed)\n-          atsEntities.addEntity(atsEntity);\n+          entities.addEntity(entity);\n       }\n-      return atsEntities;\n+      return entities;\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private TimelineEntities getEntityByTime(byte[] base,\n      String entityType, Long limit, Long starttime, Long endtime,\n      Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields)\n      throws IOException {\n    DBIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n      // using end time, construct a first key that will be seeked to\n      byte[] revts \u003d writeReverseOrderedLong(endtime);\n      kb.add(revts);\n      byte[] first \u003d kb.getBytesForLookup();\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      TimelineEntities entities \u003d new TimelineEntities();\n      iterator \u003d db.iterator();\n      iterator.seek(first);\n      // iterate until one of the following conditions is met: limit is\n      // reached, there are no more keys, the key prefix no longer matches,\n      // or a start time has been specified and reached/exceeded\n      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                last.length) \u003e 0))\n          break;\n        // read the start time and entityId from the current key\n        KeyParser kp \u003d new KeyParser(key, prefix.length);\n        Long startTime \u003d kp.getNextLong();\n        String entityId \u003d kp.getNextString();\n        // parse the entity that owns this key, iterating over all keys for\n        // the entity\n        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n            fields, iterator, key, kp.getOffset());\n        if (entity \u003d\u003d null)\n          continue;\n        // determine if the retrieved entity matches the provided secondary\n        // filters, and if so add it to the list of entities to return\n        boolean filterPassed \u003d true;\n        if (secondaryFilters !\u003d null) {\n          for (NameValuePair filter : secondaryFilters) {\n            Object v \u003d entity.getOtherInfo().get(filter.getName());\n            if (v \u003d\u003d null) {\n              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                  .get(filter.getName());\n              if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            } else if (!v.equals(filter.getValue())) {\n              filterPassed \u003d false;\n              break;\n            }\n          }\n        }\n        if (filterPassed)\n          entities.addEntity(entity);\n      }\n      return entities;\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/LeveldbTimelineStore.java",
          "extendedDetails": {
            "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/apptimeline/LeveldbApplicationTimelineStore.java",
            "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/LeveldbTimelineStore.java"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "YARN-1687. Renamed user-facing records for the timeline-service to be simply named after \u0027timeline\u0027 instead of \u0027apptimeline\u0027. Contributed by Zhijie Shen.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1570922 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/02/14 12:55 PM",
          "commitName": "84425fb435cb603fd8adcc2f76631c0244175310",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "22/02/14 12:46 PM",
          "commitNameOld": "e06226126cd89d0cf8b4ef80a88659b248579231",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,78 +1,78 @@\n-  private ATSEntities getEntityByTime(byte[] base,\n+  private TimelineEntities getEntityByTime(byte[] base,\n       String entityType, Long limit, Long starttime, Long endtime,\n       Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields)\n       throws IOException {\n     DBIterator iterator \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n       // only db keys matching the prefix (base + entity type) will be parsed\n       byte[] prefix \u003d kb.getBytesForLookup();\n       if (endtime \u003d\u003d null) {\n         // if end time is null, place no restriction on end time\n         endtime \u003d Long.MAX_VALUE;\n       }\n       // using end time, construct a first key that will be seeked to\n       byte[] revts \u003d writeReverseOrderedLong(endtime);\n       kb.add(revts);\n       byte[] first \u003d kb.getBytesForLookup();\n       byte[] last \u003d null;\n       if (starttime !\u003d null) {\n         // if start time is not null, set a last key that will not be\n         // iterated past\n         last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n             .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n       }\n       if (limit \u003d\u003d null) {\n         // if limit is not specified, use the default\n         limit \u003d DEFAULT_LIMIT;\n       }\n \n-      ATSEntities atsEntities \u003d new ATSEntities();\n+      TimelineEntities entities \u003d new TimelineEntities();\n       iterator \u003d db.iterator();\n       iterator.seek(first);\n       // iterate until one of the following conditions is met: limit is\n       // reached, there are no more keys, the key prefix no longer matches,\n       // or a start time has been specified and reached/exceeded\n-      while (atsEntities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n+      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n             WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                 last.length) \u003e 0))\n           break;\n-        // read the start time and entity from the current key\n+        // read the start time and entityId from the current key\n         KeyParser kp \u003d new KeyParser(key, prefix.length);\n         Long startTime \u003d kp.getNextLong();\n-        String entity \u003d kp.getNextString();\n+        String entityId \u003d kp.getNextString();\n         // parse the entity that owns this key, iterating over all keys for\n         // the entity\n-        ATSEntity atsEntity \u003d getEntity(entity, entityType, startTime,\n+        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n             fields, iterator, key, kp.getOffset());\n-        if (atsEntity \u003d\u003d null)\n+        if (entity \u003d\u003d null)\n           continue;\n         // determine if the retrieved entity matches the provided secondary\n         // filters, and if so add it to the list of entities to return\n         boolean filterPassed \u003d true;\n         if (secondaryFilters !\u003d null) {\n           for (NameValuePair filter : secondaryFilters) {\n-            Object v \u003d atsEntity.getOtherInfo().get(filter.getName());\n+            Object v \u003d entity.getOtherInfo().get(filter.getName());\n             if (v \u003d\u003d null) {\n-              Set\u003cObject\u003e vs \u003d atsEntity.getPrimaryFilters()\n+              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                   .get(filter.getName());\n               if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n                 filterPassed \u003d false;\n                 break;\n               }\n             } else if (!v.equals(filter.getValue())) {\n               filterPassed \u003d false;\n               break;\n             }\n           }\n         }\n         if (filterPassed)\n-          atsEntities.addEntity(atsEntity);\n+          entities.addEntity(entity);\n       }\n-      return atsEntities;\n+      return entities;\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private TimelineEntities getEntityByTime(byte[] base,\n      String entityType, Long limit, Long starttime, Long endtime,\n      Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields)\n      throws IOException {\n    DBIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n      // using end time, construct a first key that will be seeked to\n      byte[] revts \u003d writeReverseOrderedLong(endtime);\n      kb.add(revts);\n      byte[] first \u003d kb.getBytesForLookup();\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      TimelineEntities entities \u003d new TimelineEntities();\n      iterator \u003d db.iterator();\n      iterator.seek(first);\n      // iterate until one of the following conditions is met: limit is\n      // reached, there are no more keys, the key prefix no longer matches,\n      // or a start time has been specified and reached/exceeded\n      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                last.length) \u003e 0))\n          break;\n        // read the start time and entityId from the current key\n        KeyParser kp \u003d new KeyParser(key, prefix.length);\n        Long startTime \u003d kp.getNextLong();\n        String entityId \u003d kp.getNextString();\n        // parse the entity that owns this key, iterating over all keys for\n        // the entity\n        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n            fields, iterator, key, kp.getOffset());\n        if (entity \u003d\u003d null)\n          continue;\n        // determine if the retrieved entity matches the provided secondary\n        // filters, and if so add it to the list of entities to return\n        boolean filterPassed \u003d true;\n        if (secondaryFilters !\u003d null) {\n          for (NameValuePair filter : secondaryFilters) {\n            Object v \u003d entity.getOtherInfo().get(filter.getName());\n            if (v \u003d\u003d null) {\n              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                  .get(filter.getName());\n              if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            } else if (!v.equals(filter.getValue())) {\n              filterPassed \u003d false;\n              break;\n            }\n          }\n        }\n        if (filterPassed)\n          entities.addEntity(entity);\n      }\n      return entities;\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/LeveldbTimelineStore.java",
          "extendedDetails": {
            "oldValue": "ATSEntities",
            "newValue": "TimelineEntities"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-1687. Renamed user-facing records for the timeline-service to be simply named after \u0027timeline\u0027 instead of \u0027apptimeline\u0027. Contributed by Zhijie Shen.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1570922 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/02/14 12:55 PM",
          "commitName": "84425fb435cb603fd8adcc2f76631c0244175310",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "22/02/14 12:46 PM",
          "commitNameOld": "e06226126cd89d0cf8b4ef80a88659b248579231",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,78 +1,78 @@\n-  private ATSEntities getEntityByTime(byte[] base,\n+  private TimelineEntities getEntityByTime(byte[] base,\n       String entityType, Long limit, Long starttime, Long endtime,\n       Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields)\n       throws IOException {\n     DBIterator iterator \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n       // only db keys matching the prefix (base + entity type) will be parsed\n       byte[] prefix \u003d kb.getBytesForLookup();\n       if (endtime \u003d\u003d null) {\n         // if end time is null, place no restriction on end time\n         endtime \u003d Long.MAX_VALUE;\n       }\n       // using end time, construct a first key that will be seeked to\n       byte[] revts \u003d writeReverseOrderedLong(endtime);\n       kb.add(revts);\n       byte[] first \u003d kb.getBytesForLookup();\n       byte[] last \u003d null;\n       if (starttime !\u003d null) {\n         // if start time is not null, set a last key that will not be\n         // iterated past\n         last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n             .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n       }\n       if (limit \u003d\u003d null) {\n         // if limit is not specified, use the default\n         limit \u003d DEFAULT_LIMIT;\n       }\n \n-      ATSEntities atsEntities \u003d new ATSEntities();\n+      TimelineEntities entities \u003d new TimelineEntities();\n       iterator \u003d db.iterator();\n       iterator.seek(first);\n       // iterate until one of the following conditions is met: limit is\n       // reached, there are no more keys, the key prefix no longer matches,\n       // or a start time has been specified and reached/exceeded\n-      while (atsEntities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n+      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n             WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                 last.length) \u003e 0))\n           break;\n-        // read the start time and entity from the current key\n+        // read the start time and entityId from the current key\n         KeyParser kp \u003d new KeyParser(key, prefix.length);\n         Long startTime \u003d kp.getNextLong();\n-        String entity \u003d kp.getNextString();\n+        String entityId \u003d kp.getNextString();\n         // parse the entity that owns this key, iterating over all keys for\n         // the entity\n-        ATSEntity atsEntity \u003d getEntity(entity, entityType, startTime,\n+        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n             fields, iterator, key, kp.getOffset());\n-        if (atsEntity \u003d\u003d null)\n+        if (entity \u003d\u003d null)\n           continue;\n         // determine if the retrieved entity matches the provided secondary\n         // filters, and if so add it to the list of entities to return\n         boolean filterPassed \u003d true;\n         if (secondaryFilters !\u003d null) {\n           for (NameValuePair filter : secondaryFilters) {\n-            Object v \u003d atsEntity.getOtherInfo().get(filter.getName());\n+            Object v \u003d entity.getOtherInfo().get(filter.getName());\n             if (v \u003d\u003d null) {\n-              Set\u003cObject\u003e vs \u003d atsEntity.getPrimaryFilters()\n+              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                   .get(filter.getName());\n               if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n                 filterPassed \u003d false;\n                 break;\n               }\n             } else if (!v.equals(filter.getValue())) {\n               filterPassed \u003d false;\n               break;\n             }\n           }\n         }\n         if (filterPassed)\n-          atsEntities.addEntity(atsEntity);\n+          entities.addEntity(entity);\n       }\n-      return atsEntities;\n+      return entities;\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private TimelineEntities getEntityByTime(byte[] base,\n      String entityType, Long limit, Long starttime, Long endtime,\n      Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields)\n      throws IOException {\n    DBIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n      // using end time, construct a first key that will be seeked to\n      byte[] revts \u003d writeReverseOrderedLong(endtime);\n      kb.add(revts);\n      byte[] first \u003d kb.getBytesForLookup();\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      TimelineEntities entities \u003d new TimelineEntities();\n      iterator \u003d db.iterator();\n      iterator.seek(first);\n      // iterate until one of the following conditions is met: limit is\n      // reached, there are no more keys, the key prefix no longer matches,\n      // or a start time has been specified and reached/exceeded\n      while (entities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                last.length) \u003e 0))\n          break;\n        // read the start time and entityId from the current key\n        KeyParser kp \u003d new KeyParser(key, prefix.length);\n        Long startTime \u003d kp.getNextLong();\n        String entityId \u003d kp.getNextString();\n        // parse the entity that owns this key, iterating over all keys for\n        // the entity\n        TimelineEntity entity \u003d getEntity(entityId, entityType, startTime,\n            fields, iterator, key, kp.getOffset());\n        if (entity \u003d\u003d null)\n          continue;\n        // determine if the retrieved entity matches the provided secondary\n        // filters, and if so add it to the list of entities to return\n        boolean filterPassed \u003d true;\n        if (secondaryFilters !\u003d null) {\n          for (NameValuePair filter : secondaryFilters) {\n            Object v \u003d entity.getOtherInfo().get(filter.getName());\n            if (v \u003d\u003d null) {\n              Set\u003cObject\u003e vs \u003d entity.getPrimaryFilters()\n                  .get(filter.getName());\n              if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            } else if (!v.equals(filter.getValue())) {\n              filterPassed \u003d false;\n              break;\n            }\n          }\n        }\n        if (filterPassed)\n          entities.addEntity(entity);\n      }\n      return entities;\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/LeveldbTimelineStore.java",
          "extendedDetails": {}
        }
      ]
    },
    "e06226126cd89d0cf8b4ef80a88659b248579231": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1732. Changed types of related-entities and primary-filters in the timeline-service to be sets instead of maps. Contributed by Billie Rinaldi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1570914 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/02/14 12:46 PM",
      "commitName": "e06226126cd89d0cf8b4ef80a88659b248579231",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "07/02/14 6:15 PM",
      "commitNameOld": "23b2e43f5d678517e33590d15dec73225b9c5682",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 14.77,
      "commitsBetweenForRepo": 121,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,73 +1,78 @@\n   private ATSEntities getEntityByTime(byte[] base,\n       String entityType, Long limit, Long starttime, Long endtime,\n       Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields)\n       throws IOException {\n     DBIterator iterator \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n       // only db keys matching the prefix (base + entity type) will be parsed\n       byte[] prefix \u003d kb.getBytesForLookup();\n       if (endtime \u003d\u003d null) {\n         // if end time is null, place no restriction on end time\n         endtime \u003d Long.MAX_VALUE;\n       }\n       // using end time, construct a first key that will be seeked to\n       byte[] revts \u003d writeReverseOrderedLong(endtime);\n       kb.add(revts);\n       byte[] first \u003d kb.getBytesForLookup();\n       byte[] last \u003d null;\n       if (starttime !\u003d null) {\n         // if start time is not null, set a last key that will not be\n         // iterated past\n         last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n             .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n       }\n       if (limit \u003d\u003d null) {\n         // if limit is not specified, use the default\n         limit \u003d DEFAULT_LIMIT;\n       }\n \n       ATSEntities atsEntities \u003d new ATSEntities();\n       iterator \u003d db.iterator();\n       iterator.seek(first);\n       // iterate until one of the following conditions is met: limit is\n       // reached, there are no more keys, the key prefix no longer matches,\n       // or a start time has been specified and reached/exceeded\n       while (atsEntities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n             WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                 last.length) \u003e 0))\n           break;\n         // read the start time and entity from the current key\n         KeyParser kp \u003d new KeyParser(key, prefix.length);\n         Long startTime \u003d kp.getNextLong();\n         String entity \u003d kp.getNextString();\n         // parse the entity that owns this key, iterating over all keys for\n         // the entity\n         ATSEntity atsEntity \u003d getEntity(entity, entityType, startTime,\n             fields, iterator, key, kp.getOffset());\n         if (atsEntity \u003d\u003d null)\n           continue;\n         // determine if the retrieved entity matches the provided secondary\n         // filters, and if so add it to the list of entities to return\n         boolean filterPassed \u003d true;\n         if (secondaryFilters !\u003d null) {\n           for (NameValuePair filter : secondaryFilters) {\n             Object v \u003d atsEntity.getOtherInfo().get(filter.getName());\n-            if (v \u003d\u003d null)\n-              v \u003d atsEntity.getPrimaryFilters().get(filter.getName());\n-            if (v \u003d\u003d null || !v.equals(filter.getValue())) {\n+            if (v \u003d\u003d null) {\n+              Set\u003cObject\u003e vs \u003d atsEntity.getPrimaryFilters()\n+                  .get(filter.getName());\n+              if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n+                filterPassed \u003d false;\n+                break;\n+              }\n+            } else if (!v.equals(filter.getValue())) {\n               filterPassed \u003d false;\n               break;\n             }\n           }\n         }\n         if (filterPassed)\n           atsEntities.addEntity(atsEntity);\n       }\n       return atsEntities;\n     } finally {\n       IOUtils.cleanup(LOG, iterator);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private ATSEntities getEntityByTime(byte[] base,\n      String entityType, Long limit, Long starttime, Long endtime,\n      Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields)\n      throws IOException {\n    DBIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n      // using end time, construct a first key that will be seeked to\n      byte[] revts \u003d writeReverseOrderedLong(endtime);\n      kb.add(revts);\n      byte[] first \u003d kb.getBytesForLookup();\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      ATSEntities atsEntities \u003d new ATSEntities();\n      iterator \u003d db.iterator();\n      iterator.seek(first);\n      // iterate until one of the following conditions is met: limit is\n      // reached, there are no more keys, the key prefix no longer matches,\n      // or a start time has been specified and reached/exceeded\n      while (atsEntities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                last.length) \u003e 0))\n          break;\n        // read the start time and entity from the current key\n        KeyParser kp \u003d new KeyParser(key, prefix.length);\n        Long startTime \u003d kp.getNextLong();\n        String entity \u003d kp.getNextString();\n        // parse the entity that owns this key, iterating over all keys for\n        // the entity\n        ATSEntity atsEntity \u003d getEntity(entity, entityType, startTime,\n            fields, iterator, key, kp.getOffset());\n        if (atsEntity \u003d\u003d null)\n          continue;\n        // determine if the retrieved entity matches the provided secondary\n        // filters, and if so add it to the list of entities to return\n        boolean filterPassed \u003d true;\n        if (secondaryFilters !\u003d null) {\n          for (NameValuePair filter : secondaryFilters) {\n            Object v \u003d atsEntity.getOtherInfo().get(filter.getName());\n            if (v \u003d\u003d null) {\n              Set\u003cObject\u003e vs \u003d atsEntity.getPrimaryFilters()\n                  .get(filter.getName());\n              if (vs !\u003d null \u0026\u0026 !vs.contains(filter.getValue())) {\n                filterPassed \u003d false;\n                break;\n              }\n            } else if (!v.equals(filter.getValue())) {\n              filterPassed \u003d false;\n              break;\n            }\n          }\n        }\n        if (filterPassed)\n          atsEntities.addEntity(atsEntity);\n      }\n      return atsEntities;\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/apptimeline/LeveldbApplicationTimelineStore.java",
      "extendedDetails": {}
    },
    "23b2e43f5d678517e33590d15dec73225b9c5682": {
      "type": "Yintroduced",
      "commitMessage": "YARN-1635. Implemented a Leveldb based ApplicationTimelineStore. Contributed by Billie Rinaldi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1565868 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/02/14 6:15 PM",
      "commitName": "23b2e43f5d678517e33590d15dec73225b9c5682",
      "commitAuthor": "Zhijie Shen",
      "diff": "@@ -0,0 +1,73 @@\n+  private ATSEntities getEntityByTime(byte[] base,\n+      String entityType, Long limit, Long starttime, Long endtime,\n+      Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields)\n+      throws IOException {\n+    DBIterator iterator \u003d null;\n+    try {\n+      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n+      // only db keys matching the prefix (base + entity type) will be parsed\n+      byte[] prefix \u003d kb.getBytesForLookup();\n+      if (endtime \u003d\u003d null) {\n+        // if end time is null, place no restriction on end time\n+        endtime \u003d Long.MAX_VALUE;\n+      }\n+      // using end time, construct a first key that will be seeked to\n+      byte[] revts \u003d writeReverseOrderedLong(endtime);\n+      kb.add(revts);\n+      byte[] first \u003d kb.getBytesForLookup();\n+      byte[] last \u003d null;\n+      if (starttime !\u003d null) {\n+        // if start time is not null, set a last key that will not be\n+        // iterated past\n+        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n+            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n+      }\n+      if (limit \u003d\u003d null) {\n+        // if limit is not specified, use the default\n+        limit \u003d DEFAULT_LIMIT;\n+      }\n+\n+      ATSEntities atsEntities \u003d new ATSEntities();\n+      iterator \u003d db.iterator();\n+      iterator.seek(first);\n+      // iterate until one of the following conditions is met: limit is\n+      // reached, there are no more keys, the key prefix no longer matches,\n+      // or a start time has been specified and reached/exceeded\n+      while (atsEntities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n+        byte[] key \u003d iterator.peekNext().getKey();\n+        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n+            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n+                last.length) \u003e 0))\n+          break;\n+        // read the start time and entity from the current key\n+        KeyParser kp \u003d new KeyParser(key, prefix.length);\n+        Long startTime \u003d kp.getNextLong();\n+        String entity \u003d kp.getNextString();\n+        // parse the entity that owns this key, iterating over all keys for\n+        // the entity\n+        ATSEntity atsEntity \u003d getEntity(entity, entityType, startTime,\n+            fields, iterator, key, kp.getOffset());\n+        if (atsEntity \u003d\u003d null)\n+          continue;\n+        // determine if the retrieved entity matches the provided secondary\n+        // filters, and if so add it to the list of entities to return\n+        boolean filterPassed \u003d true;\n+        if (secondaryFilters !\u003d null) {\n+          for (NameValuePair filter : secondaryFilters) {\n+            Object v \u003d atsEntity.getOtherInfo().get(filter.getName());\n+            if (v \u003d\u003d null)\n+              v \u003d atsEntity.getPrimaryFilters().get(filter.getName());\n+            if (v \u003d\u003d null || !v.equals(filter.getValue())) {\n+              filterPassed \u003d false;\n+              break;\n+            }\n+          }\n+        }\n+        if (filterPassed)\n+          atsEntities.addEntity(atsEntity);\n+      }\n+      return atsEntities;\n+    } finally {\n+      IOUtils.cleanup(LOG, iterator);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private ATSEntities getEntityByTime(byte[] base,\n      String entityType, Long limit, Long starttime, Long endtime,\n      Collection\u003cNameValuePair\u003e secondaryFilters, EnumSet\u003cField\u003e fields)\n      throws IOException {\n    DBIterator iterator \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(base).add(entityType);\n      // only db keys matching the prefix (base + entity type) will be parsed\n      byte[] prefix \u003d kb.getBytesForLookup();\n      if (endtime \u003d\u003d null) {\n        // if end time is null, place no restriction on end time\n        endtime \u003d Long.MAX_VALUE;\n      }\n      // using end time, construct a first key that will be seeked to\n      byte[] revts \u003d writeReverseOrderedLong(endtime);\n      kb.add(revts);\n      byte[] first \u003d kb.getBytesForLookup();\n      byte[] last \u003d null;\n      if (starttime !\u003d null) {\n        // if start time is not null, set a last key that will not be\n        // iterated past\n        last \u003d KeyBuilder.newInstance().add(base).add(entityType)\n            .add(writeReverseOrderedLong(starttime)).getBytesForLookup();\n      }\n      if (limit \u003d\u003d null) {\n        // if limit is not specified, use the default\n        limit \u003d DEFAULT_LIMIT;\n      }\n\n      ATSEntities atsEntities \u003d new ATSEntities();\n      iterator \u003d db.iterator();\n      iterator.seek(first);\n      // iterate until one of the following conditions is met: limit is\n      // reached, there are no more keys, the key prefix no longer matches,\n      // or a start time has been specified and reached/exceeded\n      while (atsEntities.getEntities().size() \u003c limit \u0026\u0026 iterator.hasNext()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(prefix, prefix.length, key) || (last !\u003d null \u0026\u0026\n            WritableComparator.compareBytes(key, 0, key.length, last, 0,\n                last.length) \u003e 0))\n          break;\n        // read the start time and entity from the current key\n        KeyParser kp \u003d new KeyParser(key, prefix.length);\n        Long startTime \u003d kp.getNextLong();\n        String entity \u003d kp.getNextString();\n        // parse the entity that owns this key, iterating over all keys for\n        // the entity\n        ATSEntity atsEntity \u003d getEntity(entity, entityType, startTime,\n            fields, iterator, key, kp.getOffset());\n        if (atsEntity \u003d\u003d null)\n          continue;\n        // determine if the retrieved entity matches the provided secondary\n        // filters, and if so add it to the list of entities to return\n        boolean filterPassed \u003d true;\n        if (secondaryFilters !\u003d null) {\n          for (NameValuePair filter : secondaryFilters) {\n            Object v \u003d atsEntity.getOtherInfo().get(filter.getName());\n            if (v \u003d\u003d null)\n              v \u003d atsEntity.getPrimaryFilters().get(filter.getName());\n            if (v \u003d\u003d null || !v.equals(filter.getValue())) {\n              filterPassed \u003d false;\n              break;\n            }\n          }\n        }\n        if (filterPassed)\n          atsEntities.addEntity(atsEntity);\n      }\n      return atsEntities;\n    } finally {\n      IOUtils.cleanup(LOG, iterator);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/apptimeline/LeveldbApplicationTimelineStore.java"
    }
  }
}