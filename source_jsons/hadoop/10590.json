{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockRecoveryWorker.java",
  "functionName": "recover",
  "functionId": "recover",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockRecoveryWorker.java",
  "functionStartLine": 118,
  "functionEndLine": 189,
  "numCommitsSeen": 264,
  "timeTaken": 12964,
  "changeHistory": [
    "810783d443cce4dd560acfc3e652a912d57d6a77",
    "099cbb427ad535c3369d9ac3fda6463502fc1c54",
    "023b941e3b83f32bc785240dbb1bfce11a987941",
    "61ab0440f7eaff0f631cbae0378403912f88d7ad",
    "2fda45b9dc9c0bf9bb1380134c80836e89d50471",
    "b64242c0d2cabd225a8fb7d25fed449d252e4fa1",
    "e287e7d14b838a866ba03d895fa35819999d7c09",
    "6c0ccb5989c2053f5a1ebab0dd9fdb7b4019fda8",
    "f98d8eb291be364102b5c3011ce72e8f43eab389",
    "905a127850d5e0cba85c2e075f989fa0f5cf129a",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "810783d443cce4dd560acfc3e652a912d57d6a77": "Ybodychange",
    "099cbb427ad535c3369d9ac3fda6463502fc1c54": "Ybodychange",
    "023b941e3b83f32bc785240dbb1bfce11a987941": "Ybodychange",
    "61ab0440f7eaff0f631cbae0378403912f88d7ad": "Ybodychange",
    "2fda45b9dc9c0bf9bb1380134c80836e89d50471": "Ybodychange",
    "b64242c0d2cabd225a8fb7d25fed449d252e4fa1": "Ybodychange",
    "e287e7d14b838a866ba03d895fa35819999d7c09": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yrename,Yparameterchange)",
    "6c0ccb5989c2053f5a1ebab0dd9fdb7b4019fda8": "Ybodychange",
    "f98d8eb291be364102b5c3011ce72e8f43eab389": "Ybodychange",
    "905a127850d5e0cba85c2e075f989fa0f5cf129a": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "810783d443cce4dd560acfc3e652a912d57d6a77": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15135. EC : ArrayIndexOutOfBoundsException in BlockRecoveryWorker#RecoveryTaskStriped. Contributed by Ravuri Sushma sree.\n",
      "commitDate": "15/02/20 10:45 PM",
      "commitName": "810783d443cce4dd560acfc3e652a912d57d6a77",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "30/10/18 10:43 PM",
      "commitNameOld": "fac9f91b2944cee641049fffcafa6b65e0cf68f2",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 473.04,
      "commitsBetweenForRepo": 3043,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,87 @@\n     protected void recover() throws IOException {\n       checkLocations(locs.length);\n \n       Map\u003cLong, BlockRecord\u003e syncBlocks \u003d new HashMap\u003c\u003e(locs.length);\n       final int dataBlkNum \u003d ecPolicy.getNumDataUnits();\n       final int totalBlkNum \u003d dataBlkNum + ecPolicy.getNumParityUnits();\n       //check generation stamps\n       for (int i \u003d 0; i \u003c locs.length; i++) {\n         DatanodeID id \u003d locs[i];\n         try {\n           DatanodeID bpReg \u003d getDatanodeID(bpid);\n           InterDatanodeProtocol proxyDN \u003d bpReg.equals(id) ?\n               datanode : DataNode.createInterDataNodeProtocolProxy(id, conf,\n               dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n           ExtendedBlock internalBlk \u003d new ExtendedBlock(block);\n           final long blockId \u003d block.getBlockId() + blockIndices[i];\n           internalBlk.setBlockId(blockId);\n           ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN,\n               new RecoveringBlock(internalBlk, null, recoveryId));\n \n           if (info !\u003d null \u0026\u0026\n               info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n               info.getNumBytes() \u003e 0) {\n             final BlockRecord existing \u003d syncBlocks.get(blockId);\n             if (existing \u003d\u003d null ||\n                 info.getNumBytes() \u003e existing.rInfo.getNumBytes()) {\n               // if we have \u003e1 replicas for the same internal block, we\n               // simply choose the one with larger length.\n               // TODO: better usage of redundant replicas\n               syncBlocks.put(blockId, new BlockRecord(id, proxyDN, info));\n             }\n           }\n         } catch (RecoveryInProgressException ripE) {\n           InterDatanodeProtocol.LOG.warn(\n               \"Recovery for replica \" + block + \" on data-node \" + id\n                   + \" is already in progress. Recovery id \u003d \"\n                   + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n           return;\n         } catch (IOException e) {\n           InterDatanodeProtocol.LOG.warn(\"Failed to recover block (block\u003d\"\n               + block + \", datanode\u003d\" + id + \")\", e);\n         }\n       }\n       checkLocations(syncBlocks.size());\n \n       final long safeLength \u003d getSafeLength(syncBlocks);\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Recovering block \" + block\n             + \", length\u003d\" + block.getNumBytes() + \", safeLength\u003d\" + safeLength\n             + \", syncList\u003d\" + syncBlocks);\n       }\n \n       // If some internal blocks reach the safe length, convert them to RUR\n       List\u003cBlockRecord\u003e rurList \u003d new ArrayList\u003c\u003e(locs.length);\n       for (BlockRecord r : syncBlocks.values()) {\n         int blockIndex \u003d (int) (r.rInfo.getBlockId() \u0026 BLOCK_GROUP_INDEX_MASK);\n         long newSize \u003d getInternalBlockLength(safeLength, ecPolicy.getCellSize(),\n             dataBlkNum, blockIndex);\n         if (r.rInfo.getNumBytes() \u003e\u003d newSize) {\n           rurList.add(r);\n         }\n       }\n       assert rurList.size() \u003e\u003d dataBlkNum : \"incorrect safe length\";\n \n       // Recovery the striped block by truncating internal blocks to the safe\n       // length. Abort if there is any failure in this step.\n       truncatePartialBlock(rurList, safeLength);\n \n       // notify Namenode the new size and locations\n       final DatanodeID[] newLocs \u003d new DatanodeID[totalBlkNum];\n       final String[] newStorages \u003d new String[totalBlkNum];\n-      for (int i \u003d 0; i \u003c totalBlkNum; i++) {\n+      for (int i \u003d 0; i \u003c blockIndices.length; i++) {\n         newLocs[blockIndices[i]] \u003d DatanodeID.EMPTY_DATANODE_ID;\n         newStorages[blockIndices[i]] \u003d \"\";\n       }\n       for (BlockRecord r : rurList) {\n         int index \u003d (int) (r.rInfo.getBlockId() \u0026\n             HdfsServerConstants.BLOCK_GROUP_INDEX_MASK);\n         newLocs[index] \u003d r.id;\n         newStorages[index] \u003d r.storageID;\n       }\n       ExtendedBlock newBlock \u003d new ExtendedBlock(bpid, block.getBlockId(),\n           safeLength, recoveryId);\n       DatanodeProtocolClientSideTranslatorPB nn \u003d getActiveNamenodeForBP(bpid);\n       nn.commitBlockSynchronization(block, newBlock.getGenerationStamp(),\n           newBlock.getNumBytes(), true, false, newLocs, newStorages);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected void recover() throws IOException {\n      checkLocations(locs.length);\n\n      Map\u003cLong, BlockRecord\u003e syncBlocks \u003d new HashMap\u003c\u003e(locs.length);\n      final int dataBlkNum \u003d ecPolicy.getNumDataUnits();\n      final int totalBlkNum \u003d dataBlkNum + ecPolicy.getNumParityUnits();\n      //check generation stamps\n      for (int i \u003d 0; i \u003c locs.length; i++) {\n        DatanodeID id \u003d locs[i];\n        try {\n          DatanodeID bpReg \u003d getDatanodeID(bpid);\n          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id) ?\n              datanode : DataNode.createInterDataNodeProtocolProxy(id, conf,\n              dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n          ExtendedBlock internalBlk \u003d new ExtendedBlock(block);\n          final long blockId \u003d block.getBlockId() + blockIndices[i];\n          internalBlk.setBlockId(blockId);\n          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN,\n              new RecoveringBlock(internalBlk, null, recoveryId));\n\n          if (info !\u003d null \u0026\u0026\n              info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n              info.getNumBytes() \u003e 0) {\n            final BlockRecord existing \u003d syncBlocks.get(blockId);\n            if (existing \u003d\u003d null ||\n                info.getNumBytes() \u003e existing.rInfo.getNumBytes()) {\n              // if we have \u003e1 replicas for the same internal block, we\n              // simply choose the one with larger length.\n              // TODO: better usage of redundant replicas\n              syncBlocks.put(blockId, new BlockRecord(id, proxyDN, info));\n            }\n          }\n        } catch (RecoveryInProgressException ripE) {\n          InterDatanodeProtocol.LOG.warn(\n              \"Recovery for replica \" + block + \" on data-node \" + id\n                  + \" is already in progress. Recovery id \u003d \"\n                  + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n          return;\n        } catch (IOException e) {\n          InterDatanodeProtocol.LOG.warn(\"Failed to recover block (block\u003d\"\n              + block + \", datanode\u003d\" + id + \")\", e);\n        }\n      }\n      checkLocations(syncBlocks.size());\n\n      final long safeLength \u003d getSafeLength(syncBlocks);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Recovering block \" + block\n            + \", length\u003d\" + block.getNumBytes() + \", safeLength\u003d\" + safeLength\n            + \", syncList\u003d\" + syncBlocks);\n      }\n\n      // If some internal blocks reach the safe length, convert them to RUR\n      List\u003cBlockRecord\u003e rurList \u003d new ArrayList\u003c\u003e(locs.length);\n      for (BlockRecord r : syncBlocks.values()) {\n        int blockIndex \u003d (int) (r.rInfo.getBlockId() \u0026 BLOCK_GROUP_INDEX_MASK);\n        long newSize \u003d getInternalBlockLength(safeLength, ecPolicy.getCellSize(),\n            dataBlkNum, blockIndex);\n        if (r.rInfo.getNumBytes() \u003e\u003d newSize) {\n          rurList.add(r);\n        }\n      }\n      assert rurList.size() \u003e\u003d dataBlkNum : \"incorrect safe length\";\n\n      // Recovery the striped block by truncating internal blocks to the safe\n      // length. Abort if there is any failure in this step.\n      truncatePartialBlock(rurList, safeLength);\n\n      // notify Namenode the new size and locations\n      final DatanodeID[] newLocs \u003d new DatanodeID[totalBlkNum];\n      final String[] newStorages \u003d new String[totalBlkNum];\n      for (int i \u003d 0; i \u003c blockIndices.length; i++) {\n        newLocs[blockIndices[i]] \u003d DatanodeID.EMPTY_DATANODE_ID;\n        newStorages[blockIndices[i]] \u003d \"\";\n      }\n      for (BlockRecord r : rurList) {\n        int index \u003d (int) (r.rInfo.getBlockId() \u0026\n            HdfsServerConstants.BLOCK_GROUP_INDEX_MASK);\n        newLocs[index] \u003d r.id;\n        newStorages[index] \u003d r.storageID;\n      }\n      ExtendedBlock newBlock \u003d new ExtendedBlock(bpid, block.getBlockId(),\n          safeLength, recoveryId);\n      DatanodeProtocolClientSideTranslatorPB nn \u003d getActiveNamenodeForBP(bpid);\n      nn.commitBlockSynchronization(block, newBlock.getGenerationStamp(),\n          newBlock.getNumBytes(), true, false, newLocs, newStorages);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockRecoveryWorker.java",
      "extendedDetails": {}
    },
    "099cbb427ad535c3369d9ac3fda6463502fc1c54": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11890. Handle NPE in BlockRecoveryWorker when DN is getting shoutdown. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "19/06/17 8:03 PM",
      "commitName": "099cbb427ad535c3369d9ac3fda6463502fc1c54",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "14/03/17 2:49 AM",
      "commitNameOld": "023b941e3b83f32bc785240dbb1bfce11a987941",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 97.72,
      "commitsBetweenForRepo": 520,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,88 +1,87 @@\n     protected void recover() throws IOException {\n       checkLocations(locs.length);\n \n       Map\u003cLong, BlockRecord\u003e syncBlocks \u003d new HashMap\u003c\u003e(locs.length);\n       final int dataBlkNum \u003d ecPolicy.getNumDataUnits();\n       final int totalBlkNum \u003d dataBlkNum + ecPolicy.getNumParityUnits();\n       //check generation stamps\n       for (int i \u003d 0; i \u003c locs.length; i++) {\n         DatanodeID id \u003d locs[i];\n         try {\n-          DatanodeID bpReg \u003d new DatanodeID(\n-              datanode.getBPOfferService(bpid).bpRegistration);\n+          DatanodeID bpReg \u003d getDatanodeID(bpid);\n           InterDatanodeProtocol proxyDN \u003d bpReg.equals(id) ?\n               datanode : DataNode.createInterDataNodeProtocolProxy(id, conf,\n               dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n           ExtendedBlock internalBlk \u003d new ExtendedBlock(block);\n           final long blockId \u003d block.getBlockId() + blockIndices[i];\n           internalBlk.setBlockId(blockId);\n           ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN,\n               new RecoveringBlock(internalBlk, null, recoveryId));\n \n           if (info !\u003d null \u0026\u0026\n               info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n               info.getNumBytes() \u003e 0) {\n             final BlockRecord existing \u003d syncBlocks.get(blockId);\n             if (existing \u003d\u003d null ||\n                 info.getNumBytes() \u003e existing.rInfo.getNumBytes()) {\n               // if we have \u003e1 replicas for the same internal block, we\n               // simply choose the one with larger length.\n               // TODO: better usage of redundant replicas\n               syncBlocks.put(blockId, new BlockRecord(id, proxyDN, info));\n             }\n           }\n         } catch (RecoveryInProgressException ripE) {\n           InterDatanodeProtocol.LOG.warn(\n               \"Recovery for replica \" + block + \" on data-node \" + id\n                   + \" is already in progress. Recovery id \u003d \"\n                   + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n           return;\n         } catch (IOException e) {\n           InterDatanodeProtocol.LOG.warn(\"Failed to recover block (block\u003d\"\n               + block + \", datanode\u003d\" + id + \")\", e);\n         }\n       }\n       checkLocations(syncBlocks.size());\n \n       final long safeLength \u003d getSafeLength(syncBlocks);\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Recovering block \" + block\n             + \", length\u003d\" + block.getNumBytes() + \", safeLength\u003d\" + safeLength\n             + \", syncList\u003d\" + syncBlocks);\n       }\n \n       // If some internal blocks reach the safe length, convert them to RUR\n       List\u003cBlockRecord\u003e rurList \u003d new ArrayList\u003c\u003e(locs.length);\n       for (BlockRecord r : syncBlocks.values()) {\n         int blockIndex \u003d (int) (r.rInfo.getBlockId() \u0026 BLOCK_GROUP_INDEX_MASK);\n         long newSize \u003d getInternalBlockLength(safeLength, ecPolicy.getCellSize(),\n             dataBlkNum, blockIndex);\n         if (r.rInfo.getNumBytes() \u003e\u003d newSize) {\n           rurList.add(r);\n         }\n       }\n       assert rurList.size() \u003e\u003d dataBlkNum : \"incorrect safe length\";\n \n       // Recovery the striped block by truncating internal blocks to the safe\n       // length. Abort if there is any failure in this step.\n       truncatePartialBlock(rurList, safeLength);\n \n       // notify Namenode the new size and locations\n       final DatanodeID[] newLocs \u003d new DatanodeID[totalBlkNum];\n       final String[] newStorages \u003d new String[totalBlkNum];\n       for (int i \u003d 0; i \u003c totalBlkNum; i++) {\n         newLocs[blockIndices[i]] \u003d DatanodeID.EMPTY_DATANODE_ID;\n         newStorages[blockIndices[i]] \u003d \"\";\n       }\n       for (BlockRecord r : rurList) {\n         int index \u003d (int) (r.rInfo.getBlockId() \u0026\n             HdfsServerConstants.BLOCK_GROUP_INDEX_MASK);\n         newLocs[index] \u003d r.id;\n         newStorages[index] \u003d r.storageID;\n       }\n       ExtendedBlock newBlock \u003d new ExtendedBlock(bpid, block.getBlockId(),\n           safeLength, recoveryId);\n       DatanodeProtocolClientSideTranslatorPB nn \u003d getActiveNamenodeForBP(bpid);\n       nn.commitBlockSynchronization(block, newBlock.getGenerationStamp(),\n           newBlock.getNumBytes(), true, false, newLocs, newStorages);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected void recover() throws IOException {\n      checkLocations(locs.length);\n\n      Map\u003cLong, BlockRecord\u003e syncBlocks \u003d new HashMap\u003c\u003e(locs.length);\n      final int dataBlkNum \u003d ecPolicy.getNumDataUnits();\n      final int totalBlkNum \u003d dataBlkNum + ecPolicy.getNumParityUnits();\n      //check generation stamps\n      for (int i \u003d 0; i \u003c locs.length; i++) {\n        DatanodeID id \u003d locs[i];\n        try {\n          DatanodeID bpReg \u003d getDatanodeID(bpid);\n          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id) ?\n              datanode : DataNode.createInterDataNodeProtocolProxy(id, conf,\n              dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n          ExtendedBlock internalBlk \u003d new ExtendedBlock(block);\n          final long blockId \u003d block.getBlockId() + blockIndices[i];\n          internalBlk.setBlockId(blockId);\n          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN,\n              new RecoveringBlock(internalBlk, null, recoveryId));\n\n          if (info !\u003d null \u0026\u0026\n              info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n              info.getNumBytes() \u003e 0) {\n            final BlockRecord existing \u003d syncBlocks.get(blockId);\n            if (existing \u003d\u003d null ||\n                info.getNumBytes() \u003e existing.rInfo.getNumBytes()) {\n              // if we have \u003e1 replicas for the same internal block, we\n              // simply choose the one with larger length.\n              // TODO: better usage of redundant replicas\n              syncBlocks.put(blockId, new BlockRecord(id, proxyDN, info));\n            }\n          }\n        } catch (RecoveryInProgressException ripE) {\n          InterDatanodeProtocol.LOG.warn(\n              \"Recovery for replica \" + block + \" on data-node \" + id\n                  + \" is already in progress. Recovery id \u003d \"\n                  + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n          return;\n        } catch (IOException e) {\n          InterDatanodeProtocol.LOG.warn(\"Failed to recover block (block\u003d\"\n              + block + \", datanode\u003d\" + id + \")\", e);\n        }\n      }\n      checkLocations(syncBlocks.size());\n\n      final long safeLength \u003d getSafeLength(syncBlocks);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Recovering block \" + block\n            + \", length\u003d\" + block.getNumBytes() + \", safeLength\u003d\" + safeLength\n            + \", syncList\u003d\" + syncBlocks);\n      }\n\n      // If some internal blocks reach the safe length, convert them to RUR\n      List\u003cBlockRecord\u003e rurList \u003d new ArrayList\u003c\u003e(locs.length);\n      for (BlockRecord r : syncBlocks.values()) {\n        int blockIndex \u003d (int) (r.rInfo.getBlockId() \u0026 BLOCK_GROUP_INDEX_MASK);\n        long newSize \u003d getInternalBlockLength(safeLength, ecPolicy.getCellSize(),\n            dataBlkNum, blockIndex);\n        if (r.rInfo.getNumBytes() \u003e\u003d newSize) {\n          rurList.add(r);\n        }\n      }\n      assert rurList.size() \u003e\u003d dataBlkNum : \"incorrect safe length\";\n\n      // Recovery the striped block by truncating internal blocks to the safe\n      // length. Abort if there is any failure in this step.\n      truncatePartialBlock(rurList, safeLength);\n\n      // notify Namenode the new size and locations\n      final DatanodeID[] newLocs \u003d new DatanodeID[totalBlkNum];\n      final String[] newStorages \u003d new String[totalBlkNum];\n      for (int i \u003d 0; i \u003c totalBlkNum; i++) {\n        newLocs[blockIndices[i]] \u003d DatanodeID.EMPTY_DATANODE_ID;\n        newStorages[blockIndices[i]] \u003d \"\";\n      }\n      for (BlockRecord r : rurList) {\n        int index \u003d (int) (r.rInfo.getBlockId() \u0026\n            HdfsServerConstants.BLOCK_GROUP_INDEX_MASK);\n        newLocs[index] \u003d r.id;\n        newStorages[index] \u003d r.storageID;\n      }\n      ExtendedBlock newBlock \u003d new ExtendedBlock(bpid, block.getBlockId(),\n          safeLength, recoveryId);\n      DatanodeProtocolClientSideTranslatorPB nn \u003d getActiveNamenodeForBP(bpid);\n      nn.commitBlockSynchronization(block, newBlock.getGenerationStamp(),\n          newBlock.getNumBytes(), true, false, newLocs, newStorages);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockRecoveryWorker.java",
      "extendedDetails": {}
    },
    "023b941e3b83f32bc785240dbb1bfce11a987941": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11526. Fix confusing block recovery message. Contributed by Yiqun Lin.\n",
      "commitDate": "14/03/17 2:49 AM",
      "commitName": "023b941e3b83f32bc785240dbb1bfce11a987941",
      "commitAuthor": "Yiqun Lin",
      "commitDateOld": "23/02/16 2:05 PM",
      "commitNameOld": "def754ec064c8502fbd736efae738bcbdc735f0a",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 384.49,
      "commitsBetweenForRepo": 2569,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,89 +1,88 @@\n     protected void recover() throws IOException {\n       checkLocations(locs.length);\n \n       Map\u003cLong, BlockRecord\u003e syncBlocks \u003d new HashMap\u003c\u003e(locs.length);\n       final int dataBlkNum \u003d ecPolicy.getNumDataUnits();\n       final int totalBlkNum \u003d dataBlkNum + ecPolicy.getNumParityUnits();\n       //check generation stamps\n       for (int i \u003d 0; i \u003c locs.length; i++) {\n         DatanodeID id \u003d locs[i];\n         try {\n           DatanodeID bpReg \u003d new DatanodeID(\n               datanode.getBPOfferService(bpid).bpRegistration);\n           InterDatanodeProtocol proxyDN \u003d bpReg.equals(id) ?\n               datanode : DataNode.createInterDataNodeProtocolProxy(id, conf,\n               dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n           ExtendedBlock internalBlk \u003d new ExtendedBlock(block);\n           final long blockId \u003d block.getBlockId() + blockIndices[i];\n           internalBlk.setBlockId(blockId);\n           ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN,\n               new RecoveringBlock(internalBlk, null, recoveryId));\n \n           if (info !\u003d null \u0026\u0026\n               info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n               info.getNumBytes() \u003e 0) {\n             final BlockRecord existing \u003d syncBlocks.get(blockId);\n             if (existing \u003d\u003d null ||\n                 info.getNumBytes() \u003e existing.rInfo.getNumBytes()) {\n               // if we have \u003e1 replicas for the same internal block, we\n               // simply choose the one with larger length.\n               // TODO: better usage of redundant replicas\n               syncBlocks.put(blockId, new BlockRecord(id, proxyDN, info));\n             }\n           }\n         } catch (RecoveryInProgressException ripE) {\n           InterDatanodeProtocol.LOG.warn(\n               \"Recovery for replica \" + block + \" on data-node \" + id\n                   + \" is already in progress. Recovery id \u003d \"\n                   + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n           return;\n         } catch (IOException e) {\n-          InterDatanodeProtocol.LOG.warn(\n-              \"Failed to obtain replica info for block (\u003d\" + block\n-                  + \") from datanode (\u003d\" + id + \")\", e);\n+          InterDatanodeProtocol.LOG.warn(\"Failed to recover block (block\u003d\"\n+              + block + \", datanode\u003d\" + id + \")\", e);\n         }\n       }\n       checkLocations(syncBlocks.size());\n \n       final long safeLength \u003d getSafeLength(syncBlocks);\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Recovering block \" + block\n             + \", length\u003d\" + block.getNumBytes() + \", safeLength\u003d\" + safeLength\n             + \", syncList\u003d\" + syncBlocks);\n       }\n \n       // If some internal blocks reach the safe length, convert them to RUR\n       List\u003cBlockRecord\u003e rurList \u003d new ArrayList\u003c\u003e(locs.length);\n       for (BlockRecord r : syncBlocks.values()) {\n         int blockIndex \u003d (int) (r.rInfo.getBlockId() \u0026 BLOCK_GROUP_INDEX_MASK);\n         long newSize \u003d getInternalBlockLength(safeLength, ecPolicy.getCellSize(),\n             dataBlkNum, blockIndex);\n         if (r.rInfo.getNumBytes() \u003e\u003d newSize) {\n           rurList.add(r);\n         }\n       }\n       assert rurList.size() \u003e\u003d dataBlkNum : \"incorrect safe length\";\n \n       // Recovery the striped block by truncating internal blocks to the safe\n       // length. Abort if there is any failure in this step.\n       truncatePartialBlock(rurList, safeLength);\n \n       // notify Namenode the new size and locations\n       final DatanodeID[] newLocs \u003d new DatanodeID[totalBlkNum];\n       final String[] newStorages \u003d new String[totalBlkNum];\n       for (int i \u003d 0; i \u003c totalBlkNum; i++) {\n         newLocs[blockIndices[i]] \u003d DatanodeID.EMPTY_DATANODE_ID;\n         newStorages[blockIndices[i]] \u003d \"\";\n       }\n       for (BlockRecord r : rurList) {\n         int index \u003d (int) (r.rInfo.getBlockId() \u0026\n             HdfsServerConstants.BLOCK_GROUP_INDEX_MASK);\n         newLocs[index] \u003d r.id;\n         newStorages[index] \u003d r.storageID;\n       }\n       ExtendedBlock newBlock \u003d new ExtendedBlock(bpid, block.getBlockId(),\n           safeLength, recoveryId);\n       DatanodeProtocolClientSideTranslatorPB nn \u003d getActiveNamenodeForBP(bpid);\n       nn.commitBlockSynchronization(block, newBlock.getGenerationStamp(),\n           newBlock.getNumBytes(), true, false, newLocs, newStorages);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected void recover() throws IOException {\n      checkLocations(locs.length);\n\n      Map\u003cLong, BlockRecord\u003e syncBlocks \u003d new HashMap\u003c\u003e(locs.length);\n      final int dataBlkNum \u003d ecPolicy.getNumDataUnits();\n      final int totalBlkNum \u003d dataBlkNum + ecPolicy.getNumParityUnits();\n      //check generation stamps\n      for (int i \u003d 0; i \u003c locs.length; i++) {\n        DatanodeID id \u003d locs[i];\n        try {\n          DatanodeID bpReg \u003d new DatanodeID(\n              datanode.getBPOfferService(bpid).bpRegistration);\n          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id) ?\n              datanode : DataNode.createInterDataNodeProtocolProxy(id, conf,\n              dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n          ExtendedBlock internalBlk \u003d new ExtendedBlock(block);\n          final long blockId \u003d block.getBlockId() + blockIndices[i];\n          internalBlk.setBlockId(blockId);\n          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN,\n              new RecoveringBlock(internalBlk, null, recoveryId));\n\n          if (info !\u003d null \u0026\u0026\n              info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n              info.getNumBytes() \u003e 0) {\n            final BlockRecord existing \u003d syncBlocks.get(blockId);\n            if (existing \u003d\u003d null ||\n                info.getNumBytes() \u003e existing.rInfo.getNumBytes()) {\n              // if we have \u003e1 replicas for the same internal block, we\n              // simply choose the one with larger length.\n              // TODO: better usage of redundant replicas\n              syncBlocks.put(blockId, new BlockRecord(id, proxyDN, info));\n            }\n          }\n        } catch (RecoveryInProgressException ripE) {\n          InterDatanodeProtocol.LOG.warn(\n              \"Recovery for replica \" + block + \" on data-node \" + id\n                  + \" is already in progress. Recovery id \u003d \"\n                  + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n          return;\n        } catch (IOException e) {\n          InterDatanodeProtocol.LOG.warn(\"Failed to recover block (block\u003d\"\n              + block + \", datanode\u003d\" + id + \")\", e);\n        }\n      }\n      checkLocations(syncBlocks.size());\n\n      final long safeLength \u003d getSafeLength(syncBlocks);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Recovering block \" + block\n            + \", length\u003d\" + block.getNumBytes() + \", safeLength\u003d\" + safeLength\n            + \", syncList\u003d\" + syncBlocks);\n      }\n\n      // If some internal blocks reach the safe length, convert them to RUR\n      List\u003cBlockRecord\u003e rurList \u003d new ArrayList\u003c\u003e(locs.length);\n      for (BlockRecord r : syncBlocks.values()) {\n        int blockIndex \u003d (int) (r.rInfo.getBlockId() \u0026 BLOCK_GROUP_INDEX_MASK);\n        long newSize \u003d getInternalBlockLength(safeLength, ecPolicy.getCellSize(),\n            dataBlkNum, blockIndex);\n        if (r.rInfo.getNumBytes() \u003e\u003d newSize) {\n          rurList.add(r);\n        }\n      }\n      assert rurList.size() \u003e\u003d dataBlkNum : \"incorrect safe length\";\n\n      // Recovery the striped block by truncating internal blocks to the safe\n      // length. Abort if there is any failure in this step.\n      truncatePartialBlock(rurList, safeLength);\n\n      // notify Namenode the new size and locations\n      final DatanodeID[] newLocs \u003d new DatanodeID[totalBlkNum];\n      final String[] newStorages \u003d new String[totalBlkNum];\n      for (int i \u003d 0; i \u003c totalBlkNum; i++) {\n        newLocs[blockIndices[i]] \u003d DatanodeID.EMPTY_DATANODE_ID;\n        newStorages[blockIndices[i]] \u003d \"\";\n      }\n      for (BlockRecord r : rurList) {\n        int index \u003d (int) (r.rInfo.getBlockId() \u0026\n            HdfsServerConstants.BLOCK_GROUP_INDEX_MASK);\n        newLocs[index] \u003d r.id;\n        newStorages[index] \u003d r.storageID;\n      }\n      ExtendedBlock newBlock \u003d new ExtendedBlock(bpid, block.getBlockId(),\n          safeLength, recoveryId);\n      DatanodeProtocolClientSideTranslatorPB nn \u003d getActiveNamenodeForBP(bpid);\n      nn.commitBlockSynchronization(block, newBlock.getGenerationStamp(),\n          newBlock.getNumBytes(), true, false, newLocs, newStorages);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockRecoveryWorker.java",
      "extendedDetails": {}
    },
    "61ab0440f7eaff0f631cbae0378403912f88d7ad": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9173. Erasure Coding: Lease recovery for striped file. Contributed by Walter Su and Jing Zhao.\n\nChange-Id: I51703a61c9d8454f883028f3f6acb5729fde1b15\n",
      "commitDate": "18/12/15 3:57 PM",
      "commitName": "61ab0440f7eaff0f631cbae0378403912f88d7ad",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "22/11/15 3:54 PM",
      "commitNameOld": "176ff5ce90f2cbcd8342016d0f5570337d2ff79f",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 26.0,
      "commitsBetweenForRepo": 196,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,74 +1,89 @@\n     protected void recover() throws IOException {\n-      List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003c\u003e(locs.length);\n-      int errorCount \u003d 0;\n-      int candidateReplicaCnt \u003d 0;\n+      checkLocations(locs.length);\n \n-      // Check generation stamps, replica size and state. Replica must satisfy\n-      // the following criteria to be included in syncList for recovery:\n-      // - Valid generation stamp\n-      // - Non-zero length\n-      // - Original state is RWR or better\n-      for(DatanodeID id : locs) {\n+      Map\u003cLong, BlockRecord\u003e syncBlocks \u003d new HashMap\u003c\u003e(locs.length);\n+      final int dataBlkNum \u003d ecPolicy.getNumDataUnits();\n+      final int totalBlkNum \u003d dataBlkNum + ecPolicy.getNumParityUnits();\n+      //check generation stamps\n+      for (int i \u003d 0; i \u003c locs.length; i++) {\n+        DatanodeID id \u003d locs[i];\n         try {\n           DatanodeID bpReg \u003d new DatanodeID(\n               datanode.getBPOfferService(bpid).bpRegistration);\n-          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id)?\n-              datanode: DataNode.createInterDataNodeProtocolProxy(id, conf,\n+          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id) ?\n+              datanode : DataNode.createInterDataNodeProtocolProxy(id, conf,\n               dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n-          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN, rBlock);\n+          ExtendedBlock internalBlk \u003d new ExtendedBlock(block);\n+          final long blockId \u003d block.getBlockId() + blockIndices[i];\n+          internalBlk.setBlockId(blockId);\n+          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN,\n+              new RecoveringBlock(internalBlk, null, recoveryId));\n+\n           if (info !\u003d null \u0026\u0026\n               info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n               info.getNumBytes() \u003e 0) {\n-            // Count the number of candidate replicas received.\n-            ++candidateReplicaCnt;\n-            if (info.getOriginalReplicaState().getValue() \u003c\u003d\n-                ReplicaState.RWR.getValue()) {\n-              syncList.add(new BlockRecord(id, proxyDN, info));\n-            } else {\n-              if (LOG.isDebugEnabled()) {\n-                LOG.debug(\"Block recovery: Ignored replica with invalid \" +\n-                    \"original state: \" + info + \" from DataNode: \" + id);\n-              }\n-            }\n-          } else {\n-            if (LOG.isDebugEnabled()) {\n-              if (info \u003d\u003d null) {\n-                LOG.debug(\"Block recovery: DataNode: \" + id + \" does not have \"\n-                    + \"replica for block: \" + block);\n-              } else {\n-                LOG.debug(\"Block recovery: Ignored replica with invalid \"\n-                    + \"generation stamp or length: \" + info + \" from \" +\n-                    \"DataNode: \" + id);\n-              }\n+            final BlockRecord existing \u003d syncBlocks.get(blockId);\n+            if (existing \u003d\u003d null ||\n+                info.getNumBytes() \u003e existing.rInfo.getNumBytes()) {\n+              // if we have \u003e1 replicas for the same internal block, we\n+              // simply choose the one with larger length.\n+              // TODO: better usage of redundant replicas\n+              syncBlocks.put(blockId, new BlockRecord(id, proxyDN, info));\n             }\n           }\n         } catch (RecoveryInProgressException ripE) {\n           InterDatanodeProtocol.LOG.warn(\n               \"Recovery for replica \" + block + \" on data-node \" + id\n                   + \" is already in progress. Recovery id \u003d \"\n                   + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n           return;\n         } catch (IOException e) {\n-          ++errorCount;\n           InterDatanodeProtocol.LOG.warn(\n               \"Failed to obtain replica info for block (\u003d\" + block\n                   + \") from datanode (\u003d\" + id + \")\", e);\n         }\n       }\n+      checkLocations(syncBlocks.size());\n \n-      if (errorCount \u003d\u003d locs.length) {\n-        throw new IOException(\"All datanodes failed: block\u003d\" + block\n-            + \", datanodeids\u003d\" + Arrays.asList(locs));\n+      final long safeLength \u003d getSafeLength(syncBlocks);\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Recovering block \" + block\n+            + \", length\u003d\" + block.getNumBytes() + \", safeLength\u003d\" + safeLength\n+            + \", syncList\u003d\" + syncBlocks);\n       }\n \n-      // None of the replicas reported by DataNodes has the required original\n-      // state, report the error.\n-      if (candidateReplicaCnt \u003e 0 \u0026\u0026 syncList.isEmpty()) {\n-        throw new IOException(\"Found \" + candidateReplicaCnt +\n-            \" replica(s) for block \" + block + \" but none is in \" +\n-            ReplicaState.RWR.name() + \" or better state. datanodeids\u003d\" +\n-            Arrays.asList(locs));\n+      // If some internal blocks reach the safe length, convert them to RUR\n+      List\u003cBlockRecord\u003e rurList \u003d new ArrayList\u003c\u003e(locs.length);\n+      for (BlockRecord r : syncBlocks.values()) {\n+        int blockIndex \u003d (int) (r.rInfo.getBlockId() \u0026 BLOCK_GROUP_INDEX_MASK);\n+        long newSize \u003d getInternalBlockLength(safeLength, ecPolicy.getCellSize(),\n+            dataBlkNum, blockIndex);\n+        if (r.rInfo.getNumBytes() \u003e\u003d newSize) {\n+          rurList.add(r);\n+        }\n       }\n+      assert rurList.size() \u003e\u003d dataBlkNum : \"incorrect safe length\";\n \n-      syncBlock(syncList);\n+      // Recovery the striped block by truncating internal blocks to the safe\n+      // length. Abort if there is any failure in this step.\n+      truncatePartialBlock(rurList, safeLength);\n+\n+      // notify Namenode the new size and locations\n+      final DatanodeID[] newLocs \u003d new DatanodeID[totalBlkNum];\n+      final String[] newStorages \u003d new String[totalBlkNum];\n+      for (int i \u003d 0; i \u003c totalBlkNum; i++) {\n+        newLocs[blockIndices[i]] \u003d DatanodeID.EMPTY_DATANODE_ID;\n+        newStorages[blockIndices[i]] \u003d \"\";\n+      }\n+      for (BlockRecord r : rurList) {\n+        int index \u003d (int) (r.rInfo.getBlockId() \u0026\n+            HdfsServerConstants.BLOCK_GROUP_INDEX_MASK);\n+        newLocs[index] \u003d r.id;\n+        newStorages[index] \u003d r.storageID;\n+      }\n+      ExtendedBlock newBlock \u003d new ExtendedBlock(bpid, block.getBlockId(),\n+          safeLength, recoveryId);\n+      DatanodeProtocolClientSideTranslatorPB nn \u003d getActiveNamenodeForBP(bpid);\n+      nn.commitBlockSynchronization(block, newBlock.getGenerationStamp(),\n+          newBlock.getNumBytes(), true, false, newLocs, newStorages);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected void recover() throws IOException {\n      checkLocations(locs.length);\n\n      Map\u003cLong, BlockRecord\u003e syncBlocks \u003d new HashMap\u003c\u003e(locs.length);\n      final int dataBlkNum \u003d ecPolicy.getNumDataUnits();\n      final int totalBlkNum \u003d dataBlkNum + ecPolicy.getNumParityUnits();\n      //check generation stamps\n      for (int i \u003d 0; i \u003c locs.length; i++) {\n        DatanodeID id \u003d locs[i];\n        try {\n          DatanodeID bpReg \u003d new DatanodeID(\n              datanode.getBPOfferService(bpid).bpRegistration);\n          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id) ?\n              datanode : DataNode.createInterDataNodeProtocolProxy(id, conf,\n              dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n          ExtendedBlock internalBlk \u003d new ExtendedBlock(block);\n          final long blockId \u003d block.getBlockId() + blockIndices[i];\n          internalBlk.setBlockId(blockId);\n          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN,\n              new RecoveringBlock(internalBlk, null, recoveryId));\n\n          if (info !\u003d null \u0026\u0026\n              info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n              info.getNumBytes() \u003e 0) {\n            final BlockRecord existing \u003d syncBlocks.get(blockId);\n            if (existing \u003d\u003d null ||\n                info.getNumBytes() \u003e existing.rInfo.getNumBytes()) {\n              // if we have \u003e1 replicas for the same internal block, we\n              // simply choose the one with larger length.\n              // TODO: better usage of redundant replicas\n              syncBlocks.put(blockId, new BlockRecord(id, proxyDN, info));\n            }\n          }\n        } catch (RecoveryInProgressException ripE) {\n          InterDatanodeProtocol.LOG.warn(\n              \"Recovery for replica \" + block + \" on data-node \" + id\n                  + \" is already in progress. Recovery id \u003d \"\n                  + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n          return;\n        } catch (IOException e) {\n          InterDatanodeProtocol.LOG.warn(\n              \"Failed to obtain replica info for block (\u003d\" + block\n                  + \") from datanode (\u003d\" + id + \")\", e);\n        }\n      }\n      checkLocations(syncBlocks.size());\n\n      final long safeLength \u003d getSafeLength(syncBlocks);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Recovering block \" + block\n            + \", length\u003d\" + block.getNumBytes() + \", safeLength\u003d\" + safeLength\n            + \", syncList\u003d\" + syncBlocks);\n      }\n\n      // If some internal blocks reach the safe length, convert them to RUR\n      List\u003cBlockRecord\u003e rurList \u003d new ArrayList\u003c\u003e(locs.length);\n      for (BlockRecord r : syncBlocks.values()) {\n        int blockIndex \u003d (int) (r.rInfo.getBlockId() \u0026 BLOCK_GROUP_INDEX_MASK);\n        long newSize \u003d getInternalBlockLength(safeLength, ecPolicy.getCellSize(),\n            dataBlkNum, blockIndex);\n        if (r.rInfo.getNumBytes() \u003e\u003d newSize) {\n          rurList.add(r);\n        }\n      }\n      assert rurList.size() \u003e\u003d dataBlkNum : \"incorrect safe length\";\n\n      // Recovery the striped block by truncating internal blocks to the safe\n      // length. Abort if there is any failure in this step.\n      truncatePartialBlock(rurList, safeLength);\n\n      // notify Namenode the new size and locations\n      final DatanodeID[] newLocs \u003d new DatanodeID[totalBlkNum];\n      final String[] newStorages \u003d new String[totalBlkNum];\n      for (int i \u003d 0; i \u003c totalBlkNum; i++) {\n        newLocs[blockIndices[i]] \u003d DatanodeID.EMPTY_DATANODE_ID;\n        newStorages[blockIndices[i]] \u003d \"\";\n      }\n      for (BlockRecord r : rurList) {\n        int index \u003d (int) (r.rInfo.getBlockId() \u0026\n            HdfsServerConstants.BLOCK_GROUP_INDEX_MASK);\n        newLocs[index] \u003d r.id;\n        newStorages[index] \u003d r.storageID;\n      }\n      ExtendedBlock newBlock \u003d new ExtendedBlock(bpid, block.getBlockId(),\n          safeLength, recoveryId);\n      DatanodeProtocolClientSideTranslatorPB nn \u003d getActiveNamenodeForBP(bpid);\n      nn.commitBlockSynchronization(block, newBlock.getGenerationStamp(),\n          newBlock.getNumBytes(), true, false, newLocs, newStorages);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockRecoveryWorker.java",
      "extendedDetails": {}
    },
    "2fda45b9dc9c0bf9bb1380134c80836e89d50471": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9401. Fix findbugs warnings in BlockRecoveryWorker. Contributed by Brahma Reddy Battula.\n",
      "commitDate": "09/11/15 10:48 PM",
      "commitName": "2fda45b9dc9c0bf9bb1380134c80836e89d50471",
      "commitAuthor": "Walter Su",
      "commitDateOld": "06/11/15 11:15 AM",
      "commitNameOld": "b64242c0d2cabd225a8fb7d25fed449d252e4fa1",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 3.48,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,73 +1,74 @@\n     protected void recover() throws IOException {\n       List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003c\u003e(locs.length);\n       int errorCount \u003d 0;\n       int candidateReplicaCnt \u003d 0;\n \n       // Check generation stamps, replica size and state. Replica must satisfy\n       // the following criteria to be included in syncList for recovery:\n       // - Valid generation stamp\n       // - Non-zero length\n       // - Original state is RWR or better\n       for(DatanodeID id : locs) {\n         try {\n-          DatanodeID bpReg \u003ddatanode.getBPOfferService(bpid).bpRegistration;\n+          DatanodeID bpReg \u003d new DatanodeID(\n+              datanode.getBPOfferService(bpid).bpRegistration);\n           InterDatanodeProtocol proxyDN \u003d bpReg.equals(id)?\n               datanode: DataNode.createInterDataNodeProtocolProxy(id, conf,\n               dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n           ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN, rBlock);\n           if (info !\u003d null \u0026\u0026\n               info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n               info.getNumBytes() \u003e 0) {\n             // Count the number of candidate replicas received.\n             ++candidateReplicaCnt;\n             if (info.getOriginalReplicaState().getValue() \u003c\u003d\n                 ReplicaState.RWR.getValue()) {\n               syncList.add(new BlockRecord(id, proxyDN, info));\n             } else {\n               if (LOG.isDebugEnabled()) {\n                 LOG.debug(\"Block recovery: Ignored replica with invalid \" +\n                     \"original state: \" + info + \" from DataNode: \" + id);\n               }\n             }\n           } else {\n             if (LOG.isDebugEnabled()) {\n               if (info \u003d\u003d null) {\n                 LOG.debug(\"Block recovery: DataNode: \" + id + \" does not have \"\n                     + \"replica for block: \" + block);\n               } else {\n                 LOG.debug(\"Block recovery: Ignored replica with invalid \"\n                     + \"generation stamp or length: \" + info + \" from \" +\n                     \"DataNode: \" + id);\n               }\n             }\n           }\n         } catch (RecoveryInProgressException ripE) {\n           InterDatanodeProtocol.LOG.warn(\n               \"Recovery for replica \" + block + \" on data-node \" + id\n                   + \" is already in progress. Recovery id \u003d \"\n                   + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n           return;\n         } catch (IOException e) {\n           ++errorCount;\n           InterDatanodeProtocol.LOG.warn(\n               \"Failed to obtain replica info for block (\u003d\" + block\n                   + \") from datanode (\u003d\" + id + \")\", e);\n         }\n       }\n \n       if (errorCount \u003d\u003d locs.length) {\n         throw new IOException(\"All datanodes failed: block\u003d\" + block\n             + \", datanodeids\u003d\" + Arrays.asList(locs));\n       }\n \n       // None of the replicas reported by DataNodes has the required original\n       // state, report the error.\n       if (candidateReplicaCnt \u003e 0 \u0026\u0026 syncList.isEmpty()) {\n         throw new IOException(\"Found \" + candidateReplicaCnt +\n             \" replica(s) for block \" + block + \" but none is in \" +\n             ReplicaState.RWR.name() + \" or better state. datanodeids\u003d\" +\n             Arrays.asList(locs));\n       }\n \n       syncBlock(syncList);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected void recover() throws IOException {\n      List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003c\u003e(locs.length);\n      int errorCount \u003d 0;\n      int candidateReplicaCnt \u003d 0;\n\n      // Check generation stamps, replica size and state. Replica must satisfy\n      // the following criteria to be included in syncList for recovery:\n      // - Valid generation stamp\n      // - Non-zero length\n      // - Original state is RWR or better\n      for(DatanodeID id : locs) {\n        try {\n          DatanodeID bpReg \u003d new DatanodeID(\n              datanode.getBPOfferService(bpid).bpRegistration);\n          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id)?\n              datanode: DataNode.createInterDataNodeProtocolProxy(id, conf,\n              dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN, rBlock);\n          if (info !\u003d null \u0026\u0026\n              info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n              info.getNumBytes() \u003e 0) {\n            // Count the number of candidate replicas received.\n            ++candidateReplicaCnt;\n            if (info.getOriginalReplicaState().getValue() \u003c\u003d\n                ReplicaState.RWR.getValue()) {\n              syncList.add(new BlockRecord(id, proxyDN, info));\n            } else {\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(\"Block recovery: Ignored replica with invalid \" +\n                    \"original state: \" + info + \" from DataNode: \" + id);\n              }\n            }\n          } else {\n            if (LOG.isDebugEnabled()) {\n              if (info \u003d\u003d null) {\n                LOG.debug(\"Block recovery: DataNode: \" + id + \" does not have \"\n                    + \"replica for block: \" + block);\n              } else {\n                LOG.debug(\"Block recovery: Ignored replica with invalid \"\n                    + \"generation stamp or length: \" + info + \" from \" +\n                    \"DataNode: \" + id);\n              }\n            }\n          }\n        } catch (RecoveryInProgressException ripE) {\n          InterDatanodeProtocol.LOG.warn(\n              \"Recovery for replica \" + block + \" on data-node \" + id\n                  + \" is already in progress. Recovery id \u003d \"\n                  + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n          return;\n        } catch (IOException e) {\n          ++errorCount;\n          InterDatanodeProtocol.LOG.warn(\n              \"Failed to obtain replica info for block (\u003d\" + block\n                  + \") from datanode (\u003d\" + id + \")\", e);\n        }\n      }\n\n      if (errorCount \u003d\u003d locs.length) {\n        throw new IOException(\"All datanodes failed: block\u003d\" + block\n            + \", datanodeids\u003d\" + Arrays.asList(locs));\n      }\n\n      // None of the replicas reported by DataNodes has the required original\n      // state, report the error.\n      if (candidateReplicaCnt \u003e 0 \u0026\u0026 syncList.isEmpty()) {\n        throw new IOException(\"Found \" + candidateReplicaCnt +\n            \" replica(s) for block \" + block + \" but none is in \" +\n            ReplicaState.RWR.name() + \" or better state. datanodeids\u003d\" +\n            Arrays.asList(locs));\n      }\n\n      syncBlock(syncList);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockRecoveryWorker.java",
      "extendedDetails": {}
    },
    "b64242c0d2cabd225a8fb7d25fed449d252e4fa1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9236. Missing sanity check for block size during block recovery. (Tony Wu via Yongjun Zhang)\n",
      "commitDate": "06/11/15 11:15 AM",
      "commitName": "b64242c0d2cabd225a8fb7d25fed449d252e4fa1",
      "commitAuthor": "Yongjun Zhang",
      "commitDateOld": "28/10/15 7:34 AM",
      "commitNameOld": "e287e7d14b838a866ba03d895fa35819999d7c09",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 9.2,
      "commitsBetweenForRepo": 83,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,73 @@\n     protected void recover() throws IOException {\n       List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003c\u003e(locs.length);\n       int errorCount \u003d 0;\n+      int candidateReplicaCnt \u003d 0;\n \n-      //check generation stamps\n+      // Check generation stamps, replica size and state. Replica must satisfy\n+      // the following criteria to be included in syncList for recovery:\n+      // - Valid generation stamp\n+      // - Non-zero length\n+      // - Original state is RWR or better\n       for(DatanodeID id : locs) {\n         try {\n           DatanodeID bpReg \u003ddatanode.getBPOfferService(bpid).bpRegistration;\n           InterDatanodeProtocol proxyDN \u003d bpReg.equals(id)?\n               datanode: DataNode.createInterDataNodeProtocolProxy(id, conf,\n               dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n           ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN, rBlock);\n           if (info !\u003d null \u0026\u0026\n               info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n               info.getNumBytes() \u003e 0) {\n-            syncList.add(new BlockRecord(id, proxyDN, info));\n+            // Count the number of candidate replicas received.\n+            ++candidateReplicaCnt;\n+            if (info.getOriginalReplicaState().getValue() \u003c\u003d\n+                ReplicaState.RWR.getValue()) {\n+              syncList.add(new BlockRecord(id, proxyDN, info));\n+            } else {\n+              if (LOG.isDebugEnabled()) {\n+                LOG.debug(\"Block recovery: Ignored replica with invalid \" +\n+                    \"original state: \" + info + \" from DataNode: \" + id);\n+              }\n+            }\n+          } else {\n+            if (LOG.isDebugEnabled()) {\n+              if (info \u003d\u003d null) {\n+                LOG.debug(\"Block recovery: DataNode: \" + id + \" does not have \"\n+                    + \"replica for block: \" + block);\n+              } else {\n+                LOG.debug(\"Block recovery: Ignored replica with invalid \"\n+                    + \"generation stamp or length: \" + info + \" from \" +\n+                    \"DataNode: \" + id);\n+              }\n+            }\n           }\n         } catch (RecoveryInProgressException ripE) {\n           InterDatanodeProtocol.LOG.warn(\n               \"Recovery for replica \" + block + \" on data-node \" + id\n                   + \" is already in progress. Recovery id \u003d \"\n                   + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n           return;\n         } catch (IOException e) {\n           ++errorCount;\n           InterDatanodeProtocol.LOG.warn(\n               \"Failed to obtain replica info for block (\u003d\" + block\n                   + \") from datanode (\u003d\" + id + \")\", e);\n         }\n       }\n \n       if (errorCount \u003d\u003d locs.length) {\n         throw new IOException(\"All datanodes failed: block\u003d\" + block\n             + \", datanodeids\u003d\" + Arrays.asList(locs));\n       }\n \n+      // None of the replicas reported by DataNodes has the required original\n+      // state, report the error.\n+      if (candidateReplicaCnt \u003e 0 \u0026\u0026 syncList.isEmpty()) {\n+        throw new IOException(\"Found \" + candidateReplicaCnt +\n+            \" replica(s) for block \" + block + \" but none is in \" +\n+            ReplicaState.RWR.name() + \" or better state. datanodeids\u003d\" +\n+            Arrays.asList(locs));\n+      }\n+\n       syncBlock(syncList);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    protected void recover() throws IOException {\n      List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003c\u003e(locs.length);\n      int errorCount \u003d 0;\n      int candidateReplicaCnt \u003d 0;\n\n      // Check generation stamps, replica size and state. Replica must satisfy\n      // the following criteria to be included in syncList for recovery:\n      // - Valid generation stamp\n      // - Non-zero length\n      // - Original state is RWR or better\n      for(DatanodeID id : locs) {\n        try {\n          DatanodeID bpReg \u003ddatanode.getBPOfferService(bpid).bpRegistration;\n          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id)?\n              datanode: DataNode.createInterDataNodeProtocolProxy(id, conf,\n              dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN, rBlock);\n          if (info !\u003d null \u0026\u0026\n              info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n              info.getNumBytes() \u003e 0) {\n            // Count the number of candidate replicas received.\n            ++candidateReplicaCnt;\n            if (info.getOriginalReplicaState().getValue() \u003c\u003d\n                ReplicaState.RWR.getValue()) {\n              syncList.add(new BlockRecord(id, proxyDN, info));\n            } else {\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(\"Block recovery: Ignored replica with invalid \" +\n                    \"original state: \" + info + \" from DataNode: \" + id);\n              }\n            }\n          } else {\n            if (LOG.isDebugEnabled()) {\n              if (info \u003d\u003d null) {\n                LOG.debug(\"Block recovery: DataNode: \" + id + \" does not have \"\n                    + \"replica for block: \" + block);\n              } else {\n                LOG.debug(\"Block recovery: Ignored replica with invalid \"\n                    + \"generation stamp or length: \" + info + \" from \" +\n                    \"DataNode: \" + id);\n              }\n            }\n          }\n        } catch (RecoveryInProgressException ripE) {\n          InterDatanodeProtocol.LOG.warn(\n              \"Recovery for replica \" + block + \" on data-node \" + id\n                  + \" is already in progress. Recovery id \u003d \"\n                  + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n          return;\n        } catch (IOException e) {\n          ++errorCount;\n          InterDatanodeProtocol.LOG.warn(\n              \"Failed to obtain replica info for block (\u003d\" + block\n                  + \") from datanode (\u003d\" + id + \")\", e);\n        }\n      }\n\n      if (errorCount \u003d\u003d locs.length) {\n        throw new IOException(\"All datanodes failed: block\u003d\" + block\n            + \", datanodeids\u003d\" + Arrays.asList(locs));\n      }\n\n      // None of the replicas reported by DataNodes has the required original\n      // state, report the error.\n      if (candidateReplicaCnt \u003e 0 \u0026\u0026 syncList.isEmpty()) {\n        throw new IOException(\"Found \" + candidateReplicaCnt +\n            \" replica(s) for block \" + block + \" but none is in \" +\n            ReplicaState.RWR.name() + \" or better state. datanodeids\u003d\" +\n            Arrays.asList(locs));\n      }\n\n      syncBlock(syncList);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockRecoveryWorker.java",
      "extendedDetails": {}
    },
    "e287e7d14b838a866ba03d895fa35819999d7c09": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yrename,Yparameterchange)",
      "commitMessage": "HDFS-9255. Consolidate block recovery related implementation into a single class. Contributed by Walter Su.\n\nChange-Id: I7a1c03f50123d79ac0a78c981d9721617e3229d1\n",
      "commitDate": "28/10/15 7:34 AM",
      "commitName": "e287e7d14b838a866ba03d895fa35819999d7c09",
      "commitAuthor": "Zhe Zhang",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-9255. Consolidate block recovery related implementation into a single class. Contributed by Walter Su.\n\nChange-Id: I7a1c03f50123d79ac0a78c981d9721617e3229d1\n",
          "commitDate": "28/10/15 7:34 AM",
          "commitName": "e287e7d14b838a866ba03d895fa35819999d7c09",
          "commitAuthor": "Zhe Zhang",
          "commitDateOld": "28/10/15 3:36 AM",
          "commitNameOld": "a04b16970b0dbe903ac9a3a2a3080cf6de181bc2",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 0.16,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,42 +1,38 @@\n-  private void recoverBlock(RecoveringBlock rBlock) throws IOException {\n-    ExtendedBlock block \u003d rBlock.getBlock();\n-    String blookPoolId \u003d block.getBlockPoolId();\n-    DatanodeID[] datanodeids \u003d rBlock.getLocations();\n-    List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003cBlockRecord\u003e(datanodeids.length);\n-    int errorCount \u003d 0;\n+    protected void recover() throws IOException {\n+      List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003c\u003e(locs.length);\n+      int errorCount \u003d 0;\n \n-    //check generation stamps\n-    for(DatanodeID id : datanodeids) {\n-      try {\n-        BPOfferService bpos \u003d blockPoolManager.get(blookPoolId);\n-        DatanodeRegistration bpReg \u003d bpos.bpRegistration;\n-        InterDatanodeProtocol datanode \u003d bpReg.equals(id)?\n-            this: DataNode.createInterDataNodeProtocolProxy(id, getConf(),\n-                dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n-        ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(datanode, rBlock);\n-        if (info !\u003d null \u0026\u0026\n-            info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n-            info.getNumBytes() \u003e 0) {\n-          syncList.add(new BlockRecord(id, datanode, info));\n+      //check generation stamps\n+      for(DatanodeID id : locs) {\n+        try {\n+          DatanodeID bpReg \u003ddatanode.getBPOfferService(bpid).bpRegistration;\n+          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id)?\n+              datanode: DataNode.createInterDataNodeProtocolProxy(id, conf,\n+              dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n+          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN, rBlock);\n+          if (info !\u003d null \u0026\u0026\n+              info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n+              info.getNumBytes() \u003e 0) {\n+            syncList.add(new BlockRecord(id, proxyDN, info));\n+          }\n+        } catch (RecoveryInProgressException ripE) {\n+          InterDatanodeProtocol.LOG.warn(\n+              \"Recovery for replica \" + block + \" on data-node \" + id\n+                  + \" is already in progress. Recovery id \u003d \"\n+                  + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n+          return;\n+        } catch (IOException e) {\n+          ++errorCount;\n+          InterDatanodeProtocol.LOG.warn(\n+              \"Failed to obtain replica info for block (\u003d\" + block\n+                  + \") from datanode (\u003d\" + id + \")\", e);\n         }\n-      } catch (RecoveryInProgressException ripE) {\n-        InterDatanodeProtocol.LOG.warn(\n-            \"Recovery for replica \" + block + \" on data-node \" + id\n-            + \" is already in progress. Recovery id \u003d \"\n-            + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n-        return;\n-      } catch (IOException e) {\n-        ++errorCount;\n-        InterDatanodeProtocol.LOG.warn(\n-            \"Failed to obtain replica info for block (\u003d\" + block \n-            + \") from datanode (\u003d\" + id + \")\", e);\n       }\n-    }\n \n-    if (errorCount \u003d\u003d datanodeids.length) {\n-      throw new IOException(\"All datanodes failed: block\u003d\" + block\n-          + \", datanodeids\u003d\" + Arrays.asList(datanodeids));\n-    }\n+      if (errorCount \u003d\u003d locs.length) {\n+        throw new IOException(\"All datanodes failed: block\u003d\" + block\n+            + \", datanodeids\u003d\" + Arrays.asList(locs));\n+      }\n \n-    syncBlock(rBlock, syncList);\n-  }\n\\ No newline at end of file\n+      syncBlock(syncList);\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    protected void recover() throws IOException {\n      List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003c\u003e(locs.length);\n      int errorCount \u003d 0;\n\n      //check generation stamps\n      for(DatanodeID id : locs) {\n        try {\n          DatanodeID bpReg \u003ddatanode.getBPOfferService(bpid).bpRegistration;\n          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id)?\n              datanode: DataNode.createInterDataNodeProtocolProxy(id, conf,\n              dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN, rBlock);\n          if (info !\u003d null \u0026\u0026\n              info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n              info.getNumBytes() \u003e 0) {\n            syncList.add(new BlockRecord(id, proxyDN, info));\n          }\n        } catch (RecoveryInProgressException ripE) {\n          InterDatanodeProtocol.LOG.warn(\n              \"Recovery for replica \" + block + \" on data-node \" + id\n                  + \" is already in progress. Recovery id \u003d \"\n                  + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n          return;\n        } catch (IOException e) {\n          ++errorCount;\n          InterDatanodeProtocol.LOG.warn(\n              \"Failed to obtain replica info for block (\u003d\" + block\n                  + \") from datanode (\u003d\" + id + \")\", e);\n        }\n      }\n\n      if (errorCount \u003d\u003d locs.length) {\n        throw new IOException(\"All datanodes failed: block\u003d\" + block\n            + \", datanodeids\u003d\" + Arrays.asList(locs));\n      }\n\n      syncBlock(syncList);\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockRecoveryWorker.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockRecoveryWorker.java",
            "oldMethodName": "recoverBlock",
            "newMethodName": "recover"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-9255. Consolidate block recovery related implementation into a single class. Contributed by Walter Su.\n\nChange-Id: I7a1c03f50123d79ac0a78c981d9721617e3229d1\n",
          "commitDate": "28/10/15 7:34 AM",
          "commitName": "e287e7d14b838a866ba03d895fa35819999d7c09",
          "commitAuthor": "Zhe Zhang",
          "commitDateOld": "28/10/15 3:36 AM",
          "commitNameOld": "a04b16970b0dbe903ac9a3a2a3080cf6de181bc2",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 0.16,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,42 +1,38 @@\n-  private void recoverBlock(RecoveringBlock rBlock) throws IOException {\n-    ExtendedBlock block \u003d rBlock.getBlock();\n-    String blookPoolId \u003d block.getBlockPoolId();\n-    DatanodeID[] datanodeids \u003d rBlock.getLocations();\n-    List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003cBlockRecord\u003e(datanodeids.length);\n-    int errorCount \u003d 0;\n+    protected void recover() throws IOException {\n+      List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003c\u003e(locs.length);\n+      int errorCount \u003d 0;\n \n-    //check generation stamps\n-    for(DatanodeID id : datanodeids) {\n-      try {\n-        BPOfferService bpos \u003d blockPoolManager.get(blookPoolId);\n-        DatanodeRegistration bpReg \u003d bpos.bpRegistration;\n-        InterDatanodeProtocol datanode \u003d bpReg.equals(id)?\n-            this: DataNode.createInterDataNodeProtocolProxy(id, getConf(),\n-                dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n-        ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(datanode, rBlock);\n-        if (info !\u003d null \u0026\u0026\n-            info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n-            info.getNumBytes() \u003e 0) {\n-          syncList.add(new BlockRecord(id, datanode, info));\n+      //check generation stamps\n+      for(DatanodeID id : locs) {\n+        try {\n+          DatanodeID bpReg \u003ddatanode.getBPOfferService(bpid).bpRegistration;\n+          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id)?\n+              datanode: DataNode.createInterDataNodeProtocolProxy(id, conf,\n+              dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n+          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN, rBlock);\n+          if (info !\u003d null \u0026\u0026\n+              info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n+              info.getNumBytes() \u003e 0) {\n+            syncList.add(new BlockRecord(id, proxyDN, info));\n+          }\n+        } catch (RecoveryInProgressException ripE) {\n+          InterDatanodeProtocol.LOG.warn(\n+              \"Recovery for replica \" + block + \" on data-node \" + id\n+                  + \" is already in progress. Recovery id \u003d \"\n+                  + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n+          return;\n+        } catch (IOException e) {\n+          ++errorCount;\n+          InterDatanodeProtocol.LOG.warn(\n+              \"Failed to obtain replica info for block (\u003d\" + block\n+                  + \") from datanode (\u003d\" + id + \")\", e);\n         }\n-      } catch (RecoveryInProgressException ripE) {\n-        InterDatanodeProtocol.LOG.warn(\n-            \"Recovery for replica \" + block + \" on data-node \" + id\n-            + \" is already in progress. Recovery id \u003d \"\n-            + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n-        return;\n-      } catch (IOException e) {\n-        ++errorCount;\n-        InterDatanodeProtocol.LOG.warn(\n-            \"Failed to obtain replica info for block (\u003d\" + block \n-            + \") from datanode (\u003d\" + id + \")\", e);\n       }\n-    }\n \n-    if (errorCount \u003d\u003d datanodeids.length) {\n-      throw new IOException(\"All datanodes failed: block\u003d\" + block\n-          + \", datanodeids\u003d\" + Arrays.asList(datanodeids));\n-    }\n+      if (errorCount \u003d\u003d locs.length) {\n+        throw new IOException(\"All datanodes failed: block\u003d\" + block\n+            + \", datanodeids\u003d\" + Arrays.asList(locs));\n+      }\n \n-    syncBlock(rBlock, syncList);\n-  }\n\\ No newline at end of file\n+      syncBlock(syncList);\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    protected void recover() throws IOException {\n      List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003c\u003e(locs.length);\n      int errorCount \u003d 0;\n\n      //check generation stamps\n      for(DatanodeID id : locs) {\n        try {\n          DatanodeID bpReg \u003ddatanode.getBPOfferService(bpid).bpRegistration;\n          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id)?\n              datanode: DataNode.createInterDataNodeProtocolProxy(id, conf,\n              dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN, rBlock);\n          if (info !\u003d null \u0026\u0026\n              info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n              info.getNumBytes() \u003e 0) {\n            syncList.add(new BlockRecord(id, proxyDN, info));\n          }\n        } catch (RecoveryInProgressException ripE) {\n          InterDatanodeProtocol.LOG.warn(\n              \"Recovery for replica \" + block + \" on data-node \" + id\n                  + \" is already in progress. Recovery id \u003d \"\n                  + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n          return;\n        } catch (IOException e) {\n          ++errorCount;\n          InterDatanodeProtocol.LOG.warn(\n              \"Failed to obtain replica info for block (\u003d\" + block\n                  + \") from datanode (\u003d\" + id + \")\", e);\n        }\n      }\n\n      if (errorCount \u003d\u003d locs.length) {\n        throw new IOException(\"All datanodes failed: block\u003d\" + block\n            + \", datanodeids\u003d\" + Arrays.asList(locs));\n      }\n\n      syncBlock(syncList);\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockRecoveryWorker.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[protected]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9255. Consolidate block recovery related implementation into a single class. Contributed by Walter Su.\n\nChange-Id: I7a1c03f50123d79ac0a78c981d9721617e3229d1\n",
          "commitDate": "28/10/15 7:34 AM",
          "commitName": "e287e7d14b838a866ba03d895fa35819999d7c09",
          "commitAuthor": "Zhe Zhang",
          "commitDateOld": "28/10/15 3:36 AM",
          "commitNameOld": "a04b16970b0dbe903ac9a3a2a3080cf6de181bc2",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 0.16,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,42 +1,38 @@\n-  private void recoverBlock(RecoveringBlock rBlock) throws IOException {\n-    ExtendedBlock block \u003d rBlock.getBlock();\n-    String blookPoolId \u003d block.getBlockPoolId();\n-    DatanodeID[] datanodeids \u003d rBlock.getLocations();\n-    List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003cBlockRecord\u003e(datanodeids.length);\n-    int errorCount \u003d 0;\n+    protected void recover() throws IOException {\n+      List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003c\u003e(locs.length);\n+      int errorCount \u003d 0;\n \n-    //check generation stamps\n-    for(DatanodeID id : datanodeids) {\n-      try {\n-        BPOfferService bpos \u003d blockPoolManager.get(blookPoolId);\n-        DatanodeRegistration bpReg \u003d bpos.bpRegistration;\n-        InterDatanodeProtocol datanode \u003d bpReg.equals(id)?\n-            this: DataNode.createInterDataNodeProtocolProxy(id, getConf(),\n-                dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n-        ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(datanode, rBlock);\n-        if (info !\u003d null \u0026\u0026\n-            info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n-            info.getNumBytes() \u003e 0) {\n-          syncList.add(new BlockRecord(id, datanode, info));\n+      //check generation stamps\n+      for(DatanodeID id : locs) {\n+        try {\n+          DatanodeID bpReg \u003ddatanode.getBPOfferService(bpid).bpRegistration;\n+          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id)?\n+              datanode: DataNode.createInterDataNodeProtocolProxy(id, conf,\n+              dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n+          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN, rBlock);\n+          if (info !\u003d null \u0026\u0026\n+              info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n+              info.getNumBytes() \u003e 0) {\n+            syncList.add(new BlockRecord(id, proxyDN, info));\n+          }\n+        } catch (RecoveryInProgressException ripE) {\n+          InterDatanodeProtocol.LOG.warn(\n+              \"Recovery for replica \" + block + \" on data-node \" + id\n+                  + \" is already in progress. Recovery id \u003d \"\n+                  + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n+          return;\n+        } catch (IOException e) {\n+          ++errorCount;\n+          InterDatanodeProtocol.LOG.warn(\n+              \"Failed to obtain replica info for block (\u003d\" + block\n+                  + \") from datanode (\u003d\" + id + \")\", e);\n         }\n-      } catch (RecoveryInProgressException ripE) {\n-        InterDatanodeProtocol.LOG.warn(\n-            \"Recovery for replica \" + block + \" on data-node \" + id\n-            + \" is already in progress. Recovery id \u003d \"\n-            + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n-        return;\n-      } catch (IOException e) {\n-        ++errorCount;\n-        InterDatanodeProtocol.LOG.warn(\n-            \"Failed to obtain replica info for block (\u003d\" + block \n-            + \") from datanode (\u003d\" + id + \")\", e);\n       }\n-    }\n \n-    if (errorCount \u003d\u003d datanodeids.length) {\n-      throw new IOException(\"All datanodes failed: block\u003d\" + block\n-          + \", datanodeids\u003d\" + Arrays.asList(datanodeids));\n-    }\n+      if (errorCount \u003d\u003d locs.length) {\n+        throw new IOException(\"All datanodes failed: block\u003d\" + block\n+            + \", datanodeids\u003d\" + Arrays.asList(locs));\n+      }\n \n-    syncBlock(rBlock, syncList);\n-  }\n\\ No newline at end of file\n+      syncBlock(syncList);\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    protected void recover() throws IOException {\n      List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003c\u003e(locs.length);\n      int errorCount \u003d 0;\n\n      //check generation stamps\n      for(DatanodeID id : locs) {\n        try {\n          DatanodeID bpReg \u003ddatanode.getBPOfferService(bpid).bpRegistration;\n          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id)?\n              datanode: DataNode.createInterDataNodeProtocolProxy(id, conf,\n              dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN, rBlock);\n          if (info !\u003d null \u0026\u0026\n              info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n              info.getNumBytes() \u003e 0) {\n            syncList.add(new BlockRecord(id, proxyDN, info));\n          }\n        } catch (RecoveryInProgressException ripE) {\n          InterDatanodeProtocol.LOG.warn(\n              \"Recovery for replica \" + block + \" on data-node \" + id\n                  + \" is already in progress. Recovery id \u003d \"\n                  + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n          return;\n        } catch (IOException e) {\n          ++errorCount;\n          InterDatanodeProtocol.LOG.warn(\n              \"Failed to obtain replica info for block (\u003d\" + block\n                  + \") from datanode (\u003d\" + id + \")\", e);\n        }\n      }\n\n      if (errorCount \u003d\u003d locs.length) {\n        throw new IOException(\"All datanodes failed: block\u003d\" + block\n            + \", datanodeids\u003d\" + Arrays.asList(locs));\n      }\n\n      syncBlock(syncList);\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockRecoveryWorker.java",
          "extendedDetails": {}
        },
        {
          "type": "Yrename",
          "commitMessage": "HDFS-9255. Consolidate block recovery related implementation into a single class. Contributed by Walter Su.\n\nChange-Id: I7a1c03f50123d79ac0a78c981d9721617e3229d1\n",
          "commitDate": "28/10/15 7:34 AM",
          "commitName": "e287e7d14b838a866ba03d895fa35819999d7c09",
          "commitAuthor": "Zhe Zhang",
          "commitDateOld": "28/10/15 3:36 AM",
          "commitNameOld": "a04b16970b0dbe903ac9a3a2a3080cf6de181bc2",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 0.16,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,42 +1,38 @@\n-  private void recoverBlock(RecoveringBlock rBlock) throws IOException {\n-    ExtendedBlock block \u003d rBlock.getBlock();\n-    String blookPoolId \u003d block.getBlockPoolId();\n-    DatanodeID[] datanodeids \u003d rBlock.getLocations();\n-    List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003cBlockRecord\u003e(datanodeids.length);\n-    int errorCount \u003d 0;\n+    protected void recover() throws IOException {\n+      List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003c\u003e(locs.length);\n+      int errorCount \u003d 0;\n \n-    //check generation stamps\n-    for(DatanodeID id : datanodeids) {\n-      try {\n-        BPOfferService bpos \u003d blockPoolManager.get(blookPoolId);\n-        DatanodeRegistration bpReg \u003d bpos.bpRegistration;\n-        InterDatanodeProtocol datanode \u003d bpReg.equals(id)?\n-            this: DataNode.createInterDataNodeProtocolProxy(id, getConf(),\n-                dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n-        ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(datanode, rBlock);\n-        if (info !\u003d null \u0026\u0026\n-            info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n-            info.getNumBytes() \u003e 0) {\n-          syncList.add(new BlockRecord(id, datanode, info));\n+      //check generation stamps\n+      for(DatanodeID id : locs) {\n+        try {\n+          DatanodeID bpReg \u003ddatanode.getBPOfferService(bpid).bpRegistration;\n+          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id)?\n+              datanode: DataNode.createInterDataNodeProtocolProxy(id, conf,\n+              dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n+          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN, rBlock);\n+          if (info !\u003d null \u0026\u0026\n+              info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n+              info.getNumBytes() \u003e 0) {\n+            syncList.add(new BlockRecord(id, proxyDN, info));\n+          }\n+        } catch (RecoveryInProgressException ripE) {\n+          InterDatanodeProtocol.LOG.warn(\n+              \"Recovery for replica \" + block + \" on data-node \" + id\n+                  + \" is already in progress. Recovery id \u003d \"\n+                  + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n+          return;\n+        } catch (IOException e) {\n+          ++errorCount;\n+          InterDatanodeProtocol.LOG.warn(\n+              \"Failed to obtain replica info for block (\u003d\" + block\n+                  + \") from datanode (\u003d\" + id + \")\", e);\n         }\n-      } catch (RecoveryInProgressException ripE) {\n-        InterDatanodeProtocol.LOG.warn(\n-            \"Recovery for replica \" + block + \" on data-node \" + id\n-            + \" is already in progress. Recovery id \u003d \"\n-            + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n-        return;\n-      } catch (IOException e) {\n-        ++errorCount;\n-        InterDatanodeProtocol.LOG.warn(\n-            \"Failed to obtain replica info for block (\u003d\" + block \n-            + \") from datanode (\u003d\" + id + \")\", e);\n       }\n-    }\n \n-    if (errorCount \u003d\u003d datanodeids.length) {\n-      throw new IOException(\"All datanodes failed: block\u003d\" + block\n-          + \", datanodeids\u003d\" + Arrays.asList(datanodeids));\n-    }\n+      if (errorCount \u003d\u003d locs.length) {\n+        throw new IOException(\"All datanodes failed: block\u003d\" + block\n+            + \", datanodeids\u003d\" + Arrays.asList(locs));\n+      }\n \n-    syncBlock(rBlock, syncList);\n-  }\n\\ No newline at end of file\n+      syncBlock(syncList);\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    protected void recover() throws IOException {\n      List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003c\u003e(locs.length);\n      int errorCount \u003d 0;\n\n      //check generation stamps\n      for(DatanodeID id : locs) {\n        try {\n          DatanodeID bpReg \u003ddatanode.getBPOfferService(bpid).bpRegistration;\n          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id)?\n              datanode: DataNode.createInterDataNodeProtocolProxy(id, conf,\n              dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN, rBlock);\n          if (info !\u003d null \u0026\u0026\n              info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n              info.getNumBytes() \u003e 0) {\n            syncList.add(new BlockRecord(id, proxyDN, info));\n          }\n        } catch (RecoveryInProgressException ripE) {\n          InterDatanodeProtocol.LOG.warn(\n              \"Recovery for replica \" + block + \" on data-node \" + id\n                  + \" is already in progress. Recovery id \u003d \"\n                  + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n          return;\n        } catch (IOException e) {\n          ++errorCount;\n          InterDatanodeProtocol.LOG.warn(\n              \"Failed to obtain replica info for block (\u003d\" + block\n                  + \") from datanode (\u003d\" + id + \")\", e);\n        }\n      }\n\n      if (errorCount \u003d\u003d locs.length) {\n        throw new IOException(\"All datanodes failed: block\u003d\" + block\n            + \", datanodeids\u003d\" + Arrays.asList(locs));\n      }\n\n      syncBlock(syncList);\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockRecoveryWorker.java",
          "extendedDetails": {
            "oldValue": "recoverBlock",
            "newValue": "recover"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9255. Consolidate block recovery related implementation into a single class. Contributed by Walter Su.\n\nChange-Id: I7a1c03f50123d79ac0a78c981d9721617e3229d1\n",
          "commitDate": "28/10/15 7:34 AM",
          "commitName": "e287e7d14b838a866ba03d895fa35819999d7c09",
          "commitAuthor": "Zhe Zhang",
          "commitDateOld": "28/10/15 3:36 AM",
          "commitNameOld": "a04b16970b0dbe903ac9a3a2a3080cf6de181bc2",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 0.16,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,42 +1,38 @@\n-  private void recoverBlock(RecoveringBlock rBlock) throws IOException {\n-    ExtendedBlock block \u003d rBlock.getBlock();\n-    String blookPoolId \u003d block.getBlockPoolId();\n-    DatanodeID[] datanodeids \u003d rBlock.getLocations();\n-    List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003cBlockRecord\u003e(datanodeids.length);\n-    int errorCount \u003d 0;\n+    protected void recover() throws IOException {\n+      List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003c\u003e(locs.length);\n+      int errorCount \u003d 0;\n \n-    //check generation stamps\n-    for(DatanodeID id : datanodeids) {\n-      try {\n-        BPOfferService bpos \u003d blockPoolManager.get(blookPoolId);\n-        DatanodeRegistration bpReg \u003d bpos.bpRegistration;\n-        InterDatanodeProtocol datanode \u003d bpReg.equals(id)?\n-            this: DataNode.createInterDataNodeProtocolProxy(id, getConf(),\n-                dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n-        ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(datanode, rBlock);\n-        if (info !\u003d null \u0026\u0026\n-            info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n-            info.getNumBytes() \u003e 0) {\n-          syncList.add(new BlockRecord(id, datanode, info));\n+      //check generation stamps\n+      for(DatanodeID id : locs) {\n+        try {\n+          DatanodeID bpReg \u003ddatanode.getBPOfferService(bpid).bpRegistration;\n+          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id)?\n+              datanode: DataNode.createInterDataNodeProtocolProxy(id, conf,\n+              dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n+          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN, rBlock);\n+          if (info !\u003d null \u0026\u0026\n+              info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n+              info.getNumBytes() \u003e 0) {\n+            syncList.add(new BlockRecord(id, proxyDN, info));\n+          }\n+        } catch (RecoveryInProgressException ripE) {\n+          InterDatanodeProtocol.LOG.warn(\n+              \"Recovery for replica \" + block + \" on data-node \" + id\n+                  + \" is already in progress. Recovery id \u003d \"\n+                  + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n+          return;\n+        } catch (IOException e) {\n+          ++errorCount;\n+          InterDatanodeProtocol.LOG.warn(\n+              \"Failed to obtain replica info for block (\u003d\" + block\n+                  + \") from datanode (\u003d\" + id + \")\", e);\n         }\n-      } catch (RecoveryInProgressException ripE) {\n-        InterDatanodeProtocol.LOG.warn(\n-            \"Recovery for replica \" + block + \" on data-node \" + id\n-            + \" is already in progress. Recovery id \u003d \"\n-            + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n-        return;\n-      } catch (IOException e) {\n-        ++errorCount;\n-        InterDatanodeProtocol.LOG.warn(\n-            \"Failed to obtain replica info for block (\u003d\" + block \n-            + \") from datanode (\u003d\" + id + \")\", e);\n       }\n-    }\n \n-    if (errorCount \u003d\u003d datanodeids.length) {\n-      throw new IOException(\"All datanodes failed: block\u003d\" + block\n-          + \", datanodeids\u003d\" + Arrays.asList(datanodeids));\n-    }\n+      if (errorCount \u003d\u003d locs.length) {\n+        throw new IOException(\"All datanodes failed: block\u003d\" + block\n+            + \", datanodeids\u003d\" + Arrays.asList(locs));\n+      }\n \n-    syncBlock(rBlock, syncList);\n-  }\n\\ No newline at end of file\n+      syncBlock(syncList);\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    protected void recover() throws IOException {\n      List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003c\u003e(locs.length);\n      int errorCount \u003d 0;\n\n      //check generation stamps\n      for(DatanodeID id : locs) {\n        try {\n          DatanodeID bpReg \u003ddatanode.getBPOfferService(bpid).bpRegistration;\n          InterDatanodeProtocol proxyDN \u003d bpReg.equals(id)?\n              datanode: DataNode.createInterDataNodeProtocolProxy(id, conf,\n              dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n          ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(proxyDN, rBlock);\n          if (info !\u003d null \u0026\u0026\n              info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n              info.getNumBytes() \u003e 0) {\n            syncList.add(new BlockRecord(id, proxyDN, info));\n          }\n        } catch (RecoveryInProgressException ripE) {\n          InterDatanodeProtocol.LOG.warn(\n              \"Recovery for replica \" + block + \" on data-node \" + id\n                  + \" is already in progress. Recovery id \u003d \"\n                  + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n          return;\n        } catch (IOException e) {\n          ++errorCount;\n          InterDatanodeProtocol.LOG.warn(\n              \"Failed to obtain replica info for block (\u003d\" + block\n                  + \") from datanode (\u003d\" + id + \")\", e);\n        }\n      }\n\n      if (errorCount \u003d\u003d locs.length) {\n        throw new IOException(\"All datanodes failed: block\u003d\" + block\n            + \", datanodeids\u003d\" + Arrays.asList(locs));\n      }\n\n      syncBlock(syncList);\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockRecoveryWorker.java",
          "extendedDetails": {
            "oldValue": "[rBlock-RecoveringBlock]",
            "newValue": "[]"
          }
        }
      ]
    },
    "6c0ccb5989c2053f5a1ebab0dd9fdb7b4019fda8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2686. Remove DistributedUpgrade related code. Contributed by Suresh Srinivas\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1375800 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/08/12 2:18 PM",
      "commitName": "6c0ccb5989c2053f5a1ebab0dd9fdb7b4019fda8",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "17/08/12 9:52 AM",
      "commitNameOld": "fccace6116713c85cd59a808c565ea39fb5d6944",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 4.19,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,42 @@\n   private void recoverBlock(RecoveringBlock rBlock) throws IOException {\n     ExtendedBlock block \u003d rBlock.getBlock();\n     String blookPoolId \u003d block.getBlockPoolId();\n-    DatanodeInfo[] targets \u003d rBlock.getLocations();\n-    DatanodeID[] datanodeids \u003d (DatanodeID[])targets;\n+    DatanodeID[] datanodeids \u003d rBlock.getLocations();\n     List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003cBlockRecord\u003e(datanodeids.length);\n     int errorCount \u003d 0;\n \n     //check generation stamps\n     for(DatanodeID id : datanodeids) {\n       try {\n         BPOfferService bpos \u003d blockPoolManager.get(blookPoolId);\n         DatanodeRegistration bpReg \u003d bpos.bpRegistration;\n         InterDatanodeProtocol datanode \u003d bpReg.equals(id)?\n             this: DataNode.createInterDataNodeProtocolProxy(id, getConf(),\n                 dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n         ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(datanode, rBlock);\n         if (info !\u003d null \u0026\u0026\n             info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n             info.getNumBytes() \u003e 0) {\n           syncList.add(new BlockRecord(id, datanode, info));\n         }\n       } catch (RecoveryInProgressException ripE) {\n         InterDatanodeProtocol.LOG.warn(\n             \"Recovery for replica \" + block + \" on data-node \" + id\n             + \" is already in progress. Recovery id \u003d \"\n             + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n         return;\n       } catch (IOException e) {\n         ++errorCount;\n         InterDatanodeProtocol.LOG.warn(\n             \"Failed to obtain replica info for block (\u003d\" + block \n             + \") from datanode (\u003d\" + id + \")\", e);\n       }\n     }\n \n     if (errorCount \u003d\u003d datanodeids.length) {\n       throw new IOException(\"All datanodes failed: block\u003d\" + block\n           + \", datanodeids\u003d\" + Arrays.asList(datanodeids));\n     }\n \n     syncBlock(rBlock, syncList);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void recoverBlock(RecoveringBlock rBlock) throws IOException {\n    ExtendedBlock block \u003d rBlock.getBlock();\n    String blookPoolId \u003d block.getBlockPoolId();\n    DatanodeID[] datanodeids \u003d rBlock.getLocations();\n    List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003cBlockRecord\u003e(datanodeids.length);\n    int errorCount \u003d 0;\n\n    //check generation stamps\n    for(DatanodeID id : datanodeids) {\n      try {\n        BPOfferService bpos \u003d blockPoolManager.get(blookPoolId);\n        DatanodeRegistration bpReg \u003d bpos.bpRegistration;\n        InterDatanodeProtocol datanode \u003d bpReg.equals(id)?\n            this: DataNode.createInterDataNodeProtocolProxy(id, getConf(),\n                dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n        ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(datanode, rBlock);\n        if (info !\u003d null \u0026\u0026\n            info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n            info.getNumBytes() \u003e 0) {\n          syncList.add(new BlockRecord(id, datanode, info));\n        }\n      } catch (RecoveryInProgressException ripE) {\n        InterDatanodeProtocol.LOG.warn(\n            \"Recovery for replica \" + block + \" on data-node \" + id\n            + \" is already in progress. Recovery id \u003d \"\n            + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n        return;\n      } catch (IOException e) {\n        ++errorCount;\n        InterDatanodeProtocol.LOG.warn(\n            \"Failed to obtain replica info for block (\u003d\" + block \n            + \") from datanode (\u003d\" + id + \")\", e);\n      }\n    }\n\n    if (errorCount \u003d\u003d datanodeids.length) {\n      throw new IOException(\"All datanodes failed: block\u003d\" + block\n          + \", datanodeids\u003d\" + Arrays.asList(datanodeids));\n    }\n\n    syncBlock(rBlock, syncList);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
      "extendedDetails": {}
    },
    "f98d8eb291be364102b5c3011ce72e8f43eab389": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3150. Add option for clients to contact DNs via hostname. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1373094 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/08/12 1:59 PM",
      "commitName": "f98d8eb291be364102b5c3011ce72e8f43eab389",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "14/08/12 1:56 PM",
      "commitNameOld": "f46b6ea55c91fa7db87f4defed3d36e68b51ed1f",
      "commitAuthorOld": "Daryn Sharp",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,43 @@\n   private void recoverBlock(RecoveringBlock rBlock) throws IOException {\n     ExtendedBlock block \u003d rBlock.getBlock();\n     String blookPoolId \u003d block.getBlockPoolId();\n     DatanodeInfo[] targets \u003d rBlock.getLocations();\n     DatanodeID[] datanodeids \u003d (DatanodeID[])targets;\n     List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003cBlockRecord\u003e(datanodeids.length);\n     int errorCount \u003d 0;\n \n     //check generation stamps\n     for(DatanodeID id : datanodeids) {\n       try {\n         BPOfferService bpos \u003d blockPoolManager.get(blookPoolId);\n         DatanodeRegistration bpReg \u003d bpos.bpRegistration;\n         InterDatanodeProtocol datanode \u003d bpReg.equals(id)?\n             this: DataNode.createInterDataNodeProtocolProxy(id, getConf(),\n-                dnConf.socketTimeout);\n+                dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n         ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(datanode, rBlock);\n         if (info !\u003d null \u0026\u0026\n             info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n             info.getNumBytes() \u003e 0) {\n           syncList.add(new BlockRecord(id, datanode, info));\n         }\n       } catch (RecoveryInProgressException ripE) {\n         InterDatanodeProtocol.LOG.warn(\n             \"Recovery for replica \" + block + \" on data-node \" + id\n             + \" is already in progress. Recovery id \u003d \"\n             + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n         return;\n       } catch (IOException e) {\n         ++errorCount;\n         InterDatanodeProtocol.LOG.warn(\n             \"Failed to obtain replica info for block (\u003d\" + block \n             + \") from datanode (\u003d\" + id + \")\", e);\n       }\n     }\n \n     if (errorCount \u003d\u003d datanodeids.length) {\n       throw new IOException(\"All datanodes failed: block\u003d\" + block\n           + \", datanodeids\u003d\" + Arrays.asList(datanodeids));\n     }\n \n     syncBlock(rBlock, syncList);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void recoverBlock(RecoveringBlock rBlock) throws IOException {\n    ExtendedBlock block \u003d rBlock.getBlock();\n    String blookPoolId \u003d block.getBlockPoolId();\n    DatanodeInfo[] targets \u003d rBlock.getLocations();\n    DatanodeID[] datanodeids \u003d (DatanodeID[])targets;\n    List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003cBlockRecord\u003e(datanodeids.length);\n    int errorCount \u003d 0;\n\n    //check generation stamps\n    for(DatanodeID id : datanodeids) {\n      try {\n        BPOfferService bpos \u003d blockPoolManager.get(blookPoolId);\n        DatanodeRegistration bpReg \u003d bpos.bpRegistration;\n        InterDatanodeProtocol datanode \u003d bpReg.equals(id)?\n            this: DataNode.createInterDataNodeProtocolProxy(id, getConf(),\n                dnConf.socketTimeout, dnConf.connectToDnViaHostname);\n        ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(datanode, rBlock);\n        if (info !\u003d null \u0026\u0026\n            info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n            info.getNumBytes() \u003e 0) {\n          syncList.add(new BlockRecord(id, datanode, info));\n        }\n      } catch (RecoveryInProgressException ripE) {\n        InterDatanodeProtocol.LOG.warn(\n            \"Recovery for replica \" + block + \" on data-node \" + id\n            + \" is already in progress. Recovery id \u003d \"\n            + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n        return;\n      } catch (IOException e) {\n        ++errorCount;\n        InterDatanodeProtocol.LOG.warn(\n            \"Failed to obtain replica info for block (\u003d\" + block \n            + \") from datanode (\u003d\" + id + \")\", e);\n      }\n    }\n\n    if (errorCount \u003d\u003d datanodeids.length) {\n      throw new IOException(\"All datanodes failed: block\u003d\" + block\n          + \", datanodeids\u003d\" + Arrays.asList(datanodeids));\n    }\n\n    syncBlock(rBlock, syncList);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
      "extendedDetails": {}
    },
    "905a127850d5e0cba85c2e075f989fa0f5cf129a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2562. Refactor DN configuration variables out of DataNode class. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1203543 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/11/11 1:04 AM",
      "commitName": "905a127850d5e0cba85c2e075f989fa0f5cf129a",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "17/11/11 4:45 PM",
      "commitNameOld": "0864ef19089f703232107d8aa26c4a7571ff132e",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.35,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,43 @@\n   private void recoverBlock(RecoveringBlock rBlock) throws IOException {\n     ExtendedBlock block \u003d rBlock.getBlock();\n     String blookPoolId \u003d block.getBlockPoolId();\n     DatanodeInfo[] targets \u003d rBlock.getLocations();\n     DatanodeID[] datanodeids \u003d (DatanodeID[])targets;\n     List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003cBlockRecord\u003e(datanodeids.length);\n     int errorCount \u003d 0;\n \n     //check generation stamps\n     for(DatanodeID id : datanodeids) {\n       try {\n         BPOfferService bpos \u003d blockPoolManager.get(blookPoolId);\n         DatanodeRegistration bpReg \u003d bpos.bpRegistration;\n         InterDatanodeProtocol datanode \u003d bpReg.equals(id)?\n             this: DataNode.createInterDataNodeProtocolProxy(id, getConf(),\n-                socketTimeout);\n+                dnConf.socketTimeout);\n         ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(datanode, rBlock);\n         if (info !\u003d null \u0026\u0026\n             info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n             info.getNumBytes() \u003e 0) {\n           syncList.add(new BlockRecord(id, datanode, info));\n         }\n       } catch (RecoveryInProgressException ripE) {\n         InterDatanodeProtocol.LOG.warn(\n             \"Recovery for replica \" + block + \" on data-node \" + id\n             + \" is already in progress. Recovery id \u003d \"\n             + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n         return;\n       } catch (IOException e) {\n         ++errorCount;\n         InterDatanodeProtocol.LOG.warn(\n             \"Failed to obtain replica info for block (\u003d\" + block \n             + \") from datanode (\u003d\" + id + \")\", e);\n       }\n     }\n \n     if (errorCount \u003d\u003d datanodeids.length) {\n       throw new IOException(\"All datanodes failed: block\u003d\" + block\n           + \", datanodeids\u003d\" + Arrays.asList(datanodeids));\n     }\n \n     syncBlock(rBlock, syncList);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void recoverBlock(RecoveringBlock rBlock) throws IOException {\n    ExtendedBlock block \u003d rBlock.getBlock();\n    String blookPoolId \u003d block.getBlockPoolId();\n    DatanodeInfo[] targets \u003d rBlock.getLocations();\n    DatanodeID[] datanodeids \u003d (DatanodeID[])targets;\n    List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003cBlockRecord\u003e(datanodeids.length);\n    int errorCount \u003d 0;\n\n    //check generation stamps\n    for(DatanodeID id : datanodeids) {\n      try {\n        BPOfferService bpos \u003d blockPoolManager.get(blookPoolId);\n        DatanodeRegistration bpReg \u003d bpos.bpRegistration;\n        InterDatanodeProtocol datanode \u003d bpReg.equals(id)?\n            this: DataNode.createInterDataNodeProtocolProxy(id, getConf(),\n                dnConf.socketTimeout);\n        ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(datanode, rBlock);\n        if (info !\u003d null \u0026\u0026\n            info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n            info.getNumBytes() \u003e 0) {\n          syncList.add(new BlockRecord(id, datanode, info));\n        }\n      } catch (RecoveryInProgressException ripE) {\n        InterDatanodeProtocol.LOG.warn(\n            \"Recovery for replica \" + block + \" on data-node \" + id\n            + \" is already in progress. Recovery id \u003d \"\n            + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n        return;\n      } catch (IOException e) {\n        ++errorCount;\n        InterDatanodeProtocol.LOG.warn(\n            \"Failed to obtain replica info for block (\u003d\" + block \n            + \") from datanode (\u003d\" + id + \")\", e);\n      }\n    }\n\n    if (errorCount \u003d\u003d datanodeids.length) {\n      throw new IOException(\"All datanodes failed: block\u003d\" + block\n          + \", datanodeids\u003d\" + Arrays.asList(datanodeids));\n    }\n\n    syncBlock(rBlock, syncList);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void recoverBlock(RecoveringBlock rBlock) throws IOException {\n    ExtendedBlock block \u003d rBlock.getBlock();\n    String blookPoolId \u003d block.getBlockPoolId();\n    DatanodeInfo[] targets \u003d rBlock.getLocations();\n    DatanodeID[] datanodeids \u003d (DatanodeID[])targets;\n    List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003cBlockRecord\u003e(datanodeids.length);\n    int errorCount \u003d 0;\n\n    //check generation stamps\n    for(DatanodeID id : datanodeids) {\n      try {\n        BPOfferService bpos \u003d blockPoolManager.get(blookPoolId);\n        DatanodeRegistration bpReg \u003d bpos.bpRegistration;\n        InterDatanodeProtocol datanode \u003d bpReg.equals(id)?\n            this: DataNode.createInterDataNodeProtocolProxy(id, getConf(),\n                socketTimeout);\n        ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(datanode, rBlock);\n        if (info !\u003d null \u0026\u0026\n            info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n            info.getNumBytes() \u003e 0) {\n          syncList.add(new BlockRecord(id, datanode, info));\n        }\n      } catch (RecoveryInProgressException ripE) {\n        InterDatanodeProtocol.LOG.warn(\n            \"Recovery for replica \" + block + \" on data-node \" + id\n            + \" is already in progress. Recovery id \u003d \"\n            + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n        return;\n      } catch (IOException e) {\n        ++errorCount;\n        InterDatanodeProtocol.LOG.warn(\n            \"Failed to obtain replica info for block (\u003d\" + block \n            + \") from datanode (\u003d\" + id + \")\", e);\n      }\n    }\n\n    if (errorCount \u003d\u003d datanodeids.length) {\n      throw new IOException(\"All datanodes failed: block\u003d\" + block\n          + \", datanodeids\u003d\" + Arrays.asList(datanodeids));\n    }\n\n    syncBlock(rBlock, syncList);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void recoverBlock(RecoveringBlock rBlock) throws IOException {\n    ExtendedBlock block \u003d rBlock.getBlock();\n    String blookPoolId \u003d block.getBlockPoolId();\n    DatanodeInfo[] targets \u003d rBlock.getLocations();\n    DatanodeID[] datanodeids \u003d (DatanodeID[])targets;\n    List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003cBlockRecord\u003e(datanodeids.length);\n    int errorCount \u003d 0;\n\n    //check generation stamps\n    for(DatanodeID id : datanodeids) {\n      try {\n        BPOfferService bpos \u003d blockPoolManager.get(blookPoolId);\n        DatanodeRegistration bpReg \u003d bpos.bpRegistration;\n        InterDatanodeProtocol datanode \u003d bpReg.equals(id)?\n            this: DataNode.createInterDataNodeProtocolProxy(id, getConf(),\n                socketTimeout);\n        ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(datanode, rBlock);\n        if (info !\u003d null \u0026\u0026\n            info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n            info.getNumBytes() \u003e 0) {\n          syncList.add(new BlockRecord(id, datanode, info));\n        }\n      } catch (RecoveryInProgressException ripE) {\n        InterDatanodeProtocol.LOG.warn(\n            \"Recovery for replica \" + block + \" on data-node \" + id\n            + \" is already in progress. Recovery id \u003d \"\n            + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n        return;\n      } catch (IOException e) {\n        ++errorCount;\n        InterDatanodeProtocol.LOG.warn(\n            \"Failed to obtain replica info for block (\u003d\" + block \n            + \") from datanode (\u003d\" + id + \")\", e);\n      }\n    }\n\n    if (errorCount \u003d\u003d datanodeids.length) {\n      throw new IOException(\"All datanodes failed: block\u003d\" + block\n          + \", datanodeids\u003d\" + Arrays.asList(datanodeids));\n    }\n\n    syncBlock(rBlock, syncList);\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,43 @@\n+  private void recoverBlock(RecoveringBlock rBlock) throws IOException {\n+    ExtendedBlock block \u003d rBlock.getBlock();\n+    String blookPoolId \u003d block.getBlockPoolId();\n+    DatanodeInfo[] targets \u003d rBlock.getLocations();\n+    DatanodeID[] datanodeids \u003d (DatanodeID[])targets;\n+    List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003cBlockRecord\u003e(datanodeids.length);\n+    int errorCount \u003d 0;\n+\n+    //check generation stamps\n+    for(DatanodeID id : datanodeids) {\n+      try {\n+        BPOfferService bpos \u003d blockPoolManager.get(blookPoolId);\n+        DatanodeRegistration bpReg \u003d bpos.bpRegistration;\n+        InterDatanodeProtocol datanode \u003d bpReg.equals(id)?\n+            this: DataNode.createInterDataNodeProtocolProxy(id, getConf(),\n+                socketTimeout);\n+        ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(datanode, rBlock);\n+        if (info !\u003d null \u0026\u0026\n+            info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n+            info.getNumBytes() \u003e 0) {\n+          syncList.add(new BlockRecord(id, datanode, info));\n+        }\n+      } catch (RecoveryInProgressException ripE) {\n+        InterDatanodeProtocol.LOG.warn(\n+            \"Recovery for replica \" + block + \" on data-node \" + id\n+            + \" is already in progress. Recovery id \u003d \"\n+            + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n+        return;\n+      } catch (IOException e) {\n+        ++errorCount;\n+        InterDatanodeProtocol.LOG.warn(\n+            \"Failed to obtain replica info for block (\u003d\" + block \n+            + \") from datanode (\u003d\" + id + \")\", e);\n+      }\n+    }\n+\n+    if (errorCount \u003d\u003d datanodeids.length) {\n+      throw new IOException(\"All datanodes failed: block\u003d\" + block\n+          + \", datanodeids\u003d\" + Arrays.asList(datanodeids));\n+    }\n+\n+    syncBlock(rBlock, syncList);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void recoverBlock(RecoveringBlock rBlock) throws IOException {\n    ExtendedBlock block \u003d rBlock.getBlock();\n    String blookPoolId \u003d block.getBlockPoolId();\n    DatanodeInfo[] targets \u003d rBlock.getLocations();\n    DatanodeID[] datanodeids \u003d (DatanodeID[])targets;\n    List\u003cBlockRecord\u003e syncList \u003d new ArrayList\u003cBlockRecord\u003e(datanodeids.length);\n    int errorCount \u003d 0;\n\n    //check generation stamps\n    for(DatanodeID id : datanodeids) {\n      try {\n        BPOfferService bpos \u003d blockPoolManager.get(blookPoolId);\n        DatanodeRegistration bpReg \u003d bpos.bpRegistration;\n        InterDatanodeProtocol datanode \u003d bpReg.equals(id)?\n            this: DataNode.createInterDataNodeProtocolProxy(id, getConf(),\n                socketTimeout);\n        ReplicaRecoveryInfo info \u003d callInitReplicaRecovery(datanode, rBlock);\n        if (info !\u003d null \u0026\u0026\n            info.getGenerationStamp() \u003e\u003d block.getGenerationStamp() \u0026\u0026\n            info.getNumBytes() \u003e 0) {\n          syncList.add(new BlockRecord(id, datanode, info));\n        }\n      } catch (RecoveryInProgressException ripE) {\n        InterDatanodeProtocol.LOG.warn(\n            \"Recovery for replica \" + block + \" on data-node \" + id\n            + \" is already in progress. Recovery id \u003d \"\n            + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n        return;\n      } catch (IOException e) {\n        ++errorCount;\n        InterDatanodeProtocol.LOG.warn(\n            \"Failed to obtain replica info for block (\u003d\" + block \n            + \") from datanode (\u003d\" + id + \")\", e);\n      }\n    }\n\n    if (errorCount \u003d\u003d datanodeids.length) {\n      throw new IOException(\"All datanodes failed: block\u003d\" + block\n          + \", datanodeids\u003d\" + Arrays.asList(datanodeids));\n    }\n\n    syncBlock(rBlock, syncList);\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java"
    }
  }
}