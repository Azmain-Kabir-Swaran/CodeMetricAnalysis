{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPlacementPolicy.java",
  "functionName": "adjustSetsWithChosenReplica",
  "functionId": "adjustSetsWithChosenReplica___rackMap-Map__String,List__DatanodeStorageInfo____(modifiers-final)__moreThanOne-List__DatanodeStorageInfo__(modifiers-final)__exactlyOne-List__DatanodeStorageInfo__(modifiers-final)__cur-DatanodeStorageInfo(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicy.java",
  "functionStartLine": 184,
  "functionEndLine": 205,
  "numCommitsSeen": 43,
  "timeTaken": 1855,
  "changeHistory": [
    "08466eaa0045658fa7919a634e48f2d0669f8414",
    "bbab35e6d87aeebbc1848d7072c59af780536425"
  ],
  "changeHistoryShort": {
    "08466eaa0045658fa7919a634e48f2d0669f8414": "Ymultichange(Yparameterchange,Ybodychange)",
    "bbab35e6d87aeebbc1848d7072c59af780536425": "Yintroduced"
  },
  "changeHistoryDetails": {
    "08466eaa0045658fa7919a634e48f2d0669f8414": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6700. BlockPlacementPolicy shoud choose storage but not datanode for deletion.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1611731 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/07/14 10:40 AM",
      "commitName": "08466eaa0045658fa7919a634e48f2d0669f8414",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6700. BlockPlacementPolicy shoud choose storage but not datanode for deletion.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1611731 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/07/14 10:40 AM",
          "commitName": "08466eaa0045658fa7919a634e48f2d0669f8414",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "03/05/14 4:02 AM",
          "commitNameOld": "b2f65c276da2c4420a0974a7e2d75e081abf5d63",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 76.28,
          "commitsBetweenForRepo": 475,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,22 @@\n-  public void adjustSetsWithChosenReplica(final Map\u003cString, \n-      List\u003cDatanodeDescriptor\u003e\u003e rackMap,\n-      final List\u003cDatanodeDescriptor\u003e moreThanOne,\n-      final List\u003cDatanodeDescriptor\u003e exactlyOne, final DatanodeInfo cur) {\n+  public void adjustSetsWithChosenReplica(\n+      final Map\u003cString, List\u003cDatanodeStorageInfo\u003e\u003e rackMap,\n+      final List\u003cDatanodeStorageInfo\u003e moreThanOne,\n+      final List\u003cDatanodeStorageInfo\u003e exactlyOne,\n+      final DatanodeStorageInfo cur) {\n     \n-    String rack \u003d getRack(cur);\n-    final List\u003cDatanodeDescriptor\u003e datanodes \u003d rackMap.get(rack);\n-    datanodes.remove(cur);\n-    if (datanodes.isEmpty()) {\n+    final String rack \u003d getRack(cur.getDatanodeDescriptor());\n+    final List\u003cDatanodeStorageInfo\u003e storages \u003d rackMap.get(rack);\n+    storages.remove(cur);\n+    if (storages.isEmpty()) {\n       rackMap.remove(rack);\n     }\n     if (moreThanOne.remove(cur)) {\n-      if (datanodes.size() \u003d\u003d 1) {\n-        moreThanOne.remove(datanodes.get(0));\n-        exactlyOne.add(datanodes.get(0));\n+      if (storages.size() \u003d\u003d 1) {\n+        final DatanodeStorageInfo remaining \u003d storages.get(0);\n+        moreThanOne.remove(remaining);\n+        exactlyOne.add(remaining);\n       }\n     } else {\n       exactlyOne.remove(cur);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void adjustSetsWithChosenReplica(\n      final Map\u003cString, List\u003cDatanodeStorageInfo\u003e\u003e rackMap,\n      final List\u003cDatanodeStorageInfo\u003e moreThanOne,\n      final List\u003cDatanodeStorageInfo\u003e exactlyOne,\n      final DatanodeStorageInfo cur) {\n    \n    final String rack \u003d getRack(cur.getDatanodeDescriptor());\n    final List\u003cDatanodeStorageInfo\u003e storages \u003d rackMap.get(rack);\n    storages.remove(cur);\n    if (storages.isEmpty()) {\n      rackMap.remove(rack);\n    }\n    if (moreThanOne.remove(cur)) {\n      if (storages.size() \u003d\u003d 1) {\n        final DatanodeStorageInfo remaining \u003d storages.get(0);\n        moreThanOne.remove(remaining);\n        exactlyOne.add(remaining);\n      }\n    } else {\n      exactlyOne.remove(cur);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicy.java",
          "extendedDetails": {
            "oldValue": "[rackMap-Map\u003cString,List\u003cDatanodeDescriptor\u003e\u003e(modifiers-final), moreThanOne-List\u003cDatanodeDescriptor\u003e(modifiers-final), exactlyOne-List\u003cDatanodeDescriptor\u003e(modifiers-final), cur-DatanodeInfo(modifiers-final)]",
            "newValue": "[rackMap-Map\u003cString,List\u003cDatanodeStorageInfo\u003e\u003e(modifiers-final), moreThanOne-List\u003cDatanodeStorageInfo\u003e(modifiers-final), exactlyOne-List\u003cDatanodeStorageInfo\u003e(modifiers-final), cur-DatanodeStorageInfo(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6700. BlockPlacementPolicy shoud choose storage but not datanode for deletion.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1611731 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/07/14 10:40 AM",
          "commitName": "08466eaa0045658fa7919a634e48f2d0669f8414",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "03/05/14 4:02 AM",
          "commitNameOld": "b2f65c276da2c4420a0974a7e2d75e081abf5d63",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 76.28,
          "commitsBetweenForRepo": 475,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,22 @@\n-  public void adjustSetsWithChosenReplica(final Map\u003cString, \n-      List\u003cDatanodeDescriptor\u003e\u003e rackMap,\n-      final List\u003cDatanodeDescriptor\u003e moreThanOne,\n-      final List\u003cDatanodeDescriptor\u003e exactlyOne, final DatanodeInfo cur) {\n+  public void adjustSetsWithChosenReplica(\n+      final Map\u003cString, List\u003cDatanodeStorageInfo\u003e\u003e rackMap,\n+      final List\u003cDatanodeStorageInfo\u003e moreThanOne,\n+      final List\u003cDatanodeStorageInfo\u003e exactlyOne,\n+      final DatanodeStorageInfo cur) {\n     \n-    String rack \u003d getRack(cur);\n-    final List\u003cDatanodeDescriptor\u003e datanodes \u003d rackMap.get(rack);\n-    datanodes.remove(cur);\n-    if (datanodes.isEmpty()) {\n+    final String rack \u003d getRack(cur.getDatanodeDescriptor());\n+    final List\u003cDatanodeStorageInfo\u003e storages \u003d rackMap.get(rack);\n+    storages.remove(cur);\n+    if (storages.isEmpty()) {\n       rackMap.remove(rack);\n     }\n     if (moreThanOne.remove(cur)) {\n-      if (datanodes.size() \u003d\u003d 1) {\n-        moreThanOne.remove(datanodes.get(0));\n-        exactlyOne.add(datanodes.get(0));\n+      if (storages.size() \u003d\u003d 1) {\n+        final DatanodeStorageInfo remaining \u003d storages.get(0);\n+        moreThanOne.remove(remaining);\n+        exactlyOne.add(remaining);\n       }\n     } else {\n       exactlyOne.remove(cur);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void adjustSetsWithChosenReplica(\n      final Map\u003cString, List\u003cDatanodeStorageInfo\u003e\u003e rackMap,\n      final List\u003cDatanodeStorageInfo\u003e moreThanOne,\n      final List\u003cDatanodeStorageInfo\u003e exactlyOne,\n      final DatanodeStorageInfo cur) {\n    \n    final String rack \u003d getRack(cur.getDatanodeDescriptor());\n    final List\u003cDatanodeStorageInfo\u003e storages \u003d rackMap.get(rack);\n    storages.remove(cur);\n    if (storages.isEmpty()) {\n      rackMap.remove(rack);\n    }\n    if (moreThanOne.remove(cur)) {\n      if (storages.size() \u003d\u003d 1) {\n        final DatanodeStorageInfo remaining \u003d storages.get(0);\n        moreThanOne.remove(remaining);\n        exactlyOne.add(remaining);\n      }\n    } else {\n      exactlyOne.remove(cur);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicy.java",
          "extendedDetails": {}
        }
      ]
    },
    "bbab35e6d87aeebbc1848d7072c59af780536425": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3498. Support replica removal in BlockPlacementPolicy and make BlockPlacementPolicyDefault extensible for reusing code in subclasses.  Contributed by Junping Du\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1353807 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/06/12 8:25 PM",
      "commitName": "bbab35e6d87aeebbc1848d7072c59af780536425",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,20 @@\n+  public void adjustSetsWithChosenReplica(final Map\u003cString, \n+      List\u003cDatanodeDescriptor\u003e\u003e rackMap,\n+      final List\u003cDatanodeDescriptor\u003e moreThanOne,\n+      final List\u003cDatanodeDescriptor\u003e exactlyOne, final DatanodeInfo cur) {\n+    \n+    String rack \u003d getRack(cur);\n+    final List\u003cDatanodeDescriptor\u003e datanodes \u003d rackMap.get(rack);\n+    datanodes.remove(cur);\n+    if (datanodes.isEmpty()) {\n+      rackMap.remove(rack);\n+    }\n+    if (moreThanOne.remove(cur)) {\n+      if (datanodes.size() \u003d\u003d 1) {\n+        moreThanOne.remove(datanodes.get(0));\n+        exactlyOne.add(datanodes.get(0));\n+      }\n+    } else {\n+      exactlyOne.remove(cur);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void adjustSetsWithChosenReplica(final Map\u003cString, \n      List\u003cDatanodeDescriptor\u003e\u003e rackMap,\n      final List\u003cDatanodeDescriptor\u003e moreThanOne,\n      final List\u003cDatanodeDescriptor\u003e exactlyOne, final DatanodeInfo cur) {\n    \n    String rack \u003d getRack(cur);\n    final List\u003cDatanodeDescriptor\u003e datanodes \u003d rackMap.get(rack);\n    datanodes.remove(cur);\n    if (datanodes.isEmpty()) {\n      rackMap.remove(rack);\n    }\n    if (moreThanOne.remove(cur)) {\n      if (datanodes.size() \u003d\u003d 1) {\n        moreThanOne.remove(datanodes.get(0));\n        exactlyOne.add(datanodes.get(0));\n      }\n    } else {\n      exactlyOne.remove(cur);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicy.java"
    }
  }
}