{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImageFormatProtobuf.java",
  "functionName": "loadStringTableSection",
  "functionId": "loadStringTableSection___in-InputStream",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java",
  "functionStartLine": 511,
  "functionEndLine": 520,
  "numCommitsSeen": 38,
  "timeTaken": 2762,
  "changeHistory": [
    "b60ca37914b22550e3630fa02742d40697decb31",
    "5c978a43c3052cc1466b23653c354399186b4e10",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305"
  ],
  "changeHistoryShort": {
    "b60ca37914b22550e3630fa02742d40697decb31": "Ybodychange",
    "5c978a43c3052cc1466b23653c354399186b4e10": "Ybodychange",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b60ca37914b22550e3630fa02742d40697decb31": {
      "type": "Ybodychange",
      "commitMessage": "Fix potential FSImage corruption. Contributed by Daryn Sharp.\n",
      "commitDate": "15/10/18 3:18 AM",
      "commitName": "b60ca37914b22550e3630fa02742d40697decb31",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "13/08/18 4:12 PM",
      "commitNameOld": "23854443efa62aa70a1c30c32c3816750e5d7a5b",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 62.46,
      "commitsBetweenForRepo": 561,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,10 @@\n     private void loadStringTableSection(InputStream in) throws IOException {\n       StringTableSection s \u003d StringTableSection.parseDelimitedFrom(in);\n-      ctx.stringTable \u003d new String[s.getNumEntry() + 1];\n+      ctx.stringTable \u003d\n+          SerialNumberManager.newStringTable(s.getNumEntry(), s.getMaskBits());\n       for (int i \u003d 0; i \u003c s.getNumEntry(); ++i) {\n         StringTableSection.Entry e \u003d StringTableSection.Entry\n             .parseDelimitedFrom(in);\n-        ctx.stringTable[e.getId()] \u003d e.getStr();\n+        ctx.stringTable.put(e.getId(), e.getStr());\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void loadStringTableSection(InputStream in) throws IOException {\n      StringTableSection s \u003d StringTableSection.parseDelimitedFrom(in);\n      ctx.stringTable \u003d\n          SerialNumberManager.newStringTable(s.getNumEntry(), s.getMaskBits());\n      for (int i \u003d 0; i \u003c s.getNumEntry(); ++i) {\n        StringTableSection.Entry e \u003d StringTableSection.Entry\n            .parseDelimitedFrom(in);\n        ctx.stringTable.put(e.getId(), e.getStr());\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java",
      "extendedDetails": {}
    },
    "5c978a43c3052cc1466b23653c354399186b4e10": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5915. Refactor FSImageFormatProtobuf to simplify cross section reads. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1566824 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/02/14 3:13 PM",
      "commitName": "5c978a43c3052cc1466b23653c354399186b4e10",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "09/02/14 11:18 AM",
      "commitNameOld": "a2edb11b68ae01a44092cb14ac2717a6aad93305",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 1.16,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,9 @@\n     private void loadStringTableSection(InputStream in) throws IOException {\n       StringTableSection s \u003d StringTableSection.parseDelimitedFrom(in);\n-      stringTable \u003d new String[s.getNumEntry() + 1];\n+      ctx.stringTable \u003d new String[s.getNumEntry() + 1];\n       for (int i \u003d 0; i \u003c s.getNumEntry(); ++i) {\n         StringTableSection.Entry e \u003d StringTableSection.Entry\n             .parseDelimitedFrom(in);\n-        stringTable[e.getId()] \u003d e.getStr();\n+        ctx.stringTable[e.getId()] \u003d e.getStr();\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void loadStringTableSection(InputStream in) throws IOException {\n      StringTableSection s \u003d StringTableSection.parseDelimitedFrom(in);\n      ctx.stringTable \u003d new String[s.getNumEntry() + 1];\n      for (int i \u003d 0; i \u003c s.getNumEntry(); ++i) {\n        StringTableSection.Entry e \u003d StringTableSection.Entry\n            .parseDelimitedFrom(in);\n        ctx.stringTable[e.getId()] \u003d e.getStr();\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java",
      "extendedDetails": {}
    },
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5698. Use protobuf to serialize / deserialize FSImage. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1566359 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/02/14 11:18 AM",
      "commitName": "a2edb11b68ae01a44092cb14ac2717a6aad93305",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,9 @@\n+    private void loadStringTableSection(InputStream in) throws IOException {\n+      StringTableSection s \u003d StringTableSection.parseDelimitedFrom(in);\n+      stringTable \u003d new String[s.getNumEntry() + 1];\n+      for (int i \u003d 0; i \u003c s.getNumEntry(); ++i) {\n+        StringTableSection.Entry e \u003d StringTableSection.Entry\n+            .parseDelimitedFrom(in);\n+        stringTable[e.getId()] \u003d e.getStr();\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private void loadStringTableSection(InputStream in) throws IOException {\n      StringTableSection s \u003d StringTableSection.parseDelimitedFrom(in);\n      stringTable \u003d new String[s.getNumEntry() + 1];\n      for (int i \u003d 0; i \u003c s.getNumEntry(); ++i) {\n        StringTableSection.Entry e \u003d StringTableSection.Entry\n            .parseDelimitedFrom(in);\n        stringTable[e.getId()] \u003d e.getStr();\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java"
    }
  }
}