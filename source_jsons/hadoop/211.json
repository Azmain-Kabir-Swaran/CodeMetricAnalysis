{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "OpenFileCtx.java",
  "functionName": "offerNextToWrite",
  "functionId": "offerNextToWrite",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
  "functionStartLine": 965,
  "functionEndLine": 1017,
  "numCommitsSeen": 36,
  "timeTaken": 2080,
  "changeHistory": [
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
    "151fca5032719e561226ef278e002739073c23ec",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f",
    "08a9ac7098cb4ae684f40cf2513e3137110cc7e4",
    "5c02d2f6225144772dcb975d3144b057b71d6476",
    "28e3d09230971b32f74284311931525cb7ad1b7c"
  ],
  "changeHistoryShort": {
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": "Ybodychange",
    "151fca5032719e561226ef278e002739073c23ec": "Ybodychange",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": "Ybodychange",
    "08a9ac7098cb4ae684f40cf2513e3137110cc7e4": "Ybodychange",
    "5c02d2f6225144772dcb975d3144b057b71d6476": "Ybodychange",
    "28e3d09230971b32f74284311931525cb7ad1b7c": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10571. Use Log.*(Object, Throwable) overload to log exceptions.\nContributed by Andras Bokor.\n",
      "commitDate": "14/02/18 8:20 AM",
      "commitName": "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "10/10/17 10:38 AM",
      "commitNameOld": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
      "commitAuthorOld": "Jitendra Pandey",
      "daysBetweenCommits": 126.95,
      "commitsBetweenForRepo": 833,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,53 @@\n   private synchronized WriteCtx offerNextToWrite() {\n     if (pendingWrites.isEmpty()) {\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"The async write task has no pending writes, fileId: \"\n-            + latestAttr.getFileId());\n-      }\n+      LOG.debug(\"The async write task has no pending writes, fileId: {}\",\n+          latestAttr.getFileId());\n       // process pending commit again to handle this race: a commit is added\n       // to pendingCommits map just after the last doSingleWrite returns.\n       // There is no pending write and the commit should be handled by the\n       // last doSingleWrite. Due to the race, the commit is left along and\n       // can\u0027t be processed until cleanup. Therefore, we should do another\n       // processCommits to fix the race issue.\n       processCommits(nextOffset.get()); // nextOffset has same value as\n                                         // flushedOffset\n       this.asyncStatus \u003d false;\n       return null;\n     } \n \n     Entry\u003cOffsetRange, WriteCtx\u003e lastEntry \u003d pendingWrites.lastEntry();\n     OffsetRange range \u003d lastEntry.getKey();\n     WriteCtx toWrite \u003d lastEntry.getValue();\n \n-    if (LOG.isTraceEnabled()) {\n-      LOG.trace(\"range.getMin()\u003d\" + range.getMin() + \" nextOffset\u003d\"\n-          + nextOffset);\n-    }\n+    LOG.trace(\"range.getMin()\u003d{} nextOffset\u003d{}\",\n+        range.getMin(), nextOffset);\n \n     long offset \u003d nextOffset.get();\n     if (range.getMin() \u003e offset) {\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"The next sequential write has not arrived yet\");\n-      }\n+      LOG.debug(\"The next sequential write has not arrived yet\");\n       processCommits(nextOffset.get()); // handle race\n       this.asyncStatus \u003d false;\n     } else if (range.getMax() \u003c\u003d offset) {\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Remove write \" + range.toString()\n-            + \" which is already written from the list\");\n-      }\n+      LOG.debug(\"Remove write {} which is already written from the list\",\n+          range);\n       // remove the WriteCtx from cache\n       pendingWrites.remove(range);\n     } else if (range.getMin() \u003c offset \u0026\u0026 range.getMax() \u003e offset) {\n-      LOG.warn(\"Got an overlapping write \" + range.toString()\n-          + \", nextOffset\u003d\" + offset\n-          + \". Remove and trim it\");\n+      LOG.warn(\"Got an overlapping write {}, nextOffset\u003d{}. \" +\n+          \"Remove and trim it\", range, offset);\n       pendingWrites.remove(range);\n       trimWriteRequest(toWrite, offset);\n       // update nextOffset\n       nextOffset.addAndGet(toWrite.getCount());\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Change nextOffset (after trim) to \" + nextOffset.get());\n-      }\n+      LOG.debug(\"Change nextOffset (after trim) to {}\", nextOffset.get());\n       return toWrite;\n     } else {\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Remove write \" + range.toString()\n-            + \" from the list\");\n-      }\n+      LOG.debug(\"Remove write {} from the list\", range);\n       // after writing, remove the WriteCtx from cache\n       pendingWrites.remove(range);\n       // update nextOffset\n       nextOffset.addAndGet(toWrite.getCount());\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Change nextOffset to \" + nextOffset.get());\n-      }\n+      LOG.debug(\"Change nextOffset to {}\", nextOffset.get());\n       return toWrite;\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized WriteCtx offerNextToWrite() {\n    if (pendingWrites.isEmpty()) {\n      LOG.debug(\"The async write task has no pending writes, fileId: {}\",\n          latestAttr.getFileId());\n      // process pending commit again to handle this race: a commit is added\n      // to pendingCommits map just after the last doSingleWrite returns.\n      // There is no pending write and the commit should be handled by the\n      // last doSingleWrite. Due to the race, the commit is left along and\n      // can\u0027t be processed until cleanup. Therefore, we should do another\n      // processCommits to fix the race issue.\n      processCommits(nextOffset.get()); // nextOffset has same value as\n                                        // flushedOffset\n      this.asyncStatus \u003d false;\n      return null;\n    } \n\n    Entry\u003cOffsetRange, WriteCtx\u003e lastEntry \u003d pendingWrites.lastEntry();\n    OffsetRange range \u003d lastEntry.getKey();\n    WriteCtx toWrite \u003d lastEntry.getValue();\n\n    LOG.trace(\"range.getMin()\u003d{} nextOffset\u003d{}\",\n        range.getMin(), nextOffset);\n\n    long offset \u003d nextOffset.get();\n    if (range.getMin() \u003e offset) {\n      LOG.debug(\"The next sequential write has not arrived yet\");\n      processCommits(nextOffset.get()); // handle race\n      this.asyncStatus \u003d false;\n    } else if (range.getMax() \u003c\u003d offset) {\n      LOG.debug(\"Remove write {} which is already written from the list\",\n          range);\n      // remove the WriteCtx from cache\n      pendingWrites.remove(range);\n    } else if (range.getMin() \u003c offset \u0026\u0026 range.getMax() \u003e offset) {\n      LOG.warn(\"Got an overlapping write {}, nextOffset\u003d{}. \" +\n          \"Remove and trim it\", range, offset);\n      pendingWrites.remove(range);\n      trimWriteRequest(toWrite, offset);\n      // update nextOffset\n      nextOffset.addAndGet(toWrite.getCount());\n      LOG.debug(\"Change nextOffset (after trim) to {}\", nextOffset.get());\n      return toWrite;\n    } else {\n      LOG.debug(\"Remove write {} from the list\", range);\n      // after writing, remove the WriteCtx from cache\n      pendingWrites.remove(range);\n      // update nextOffset\n      nextOffset.addAndGet(toWrite.getCount());\n      LOG.debug(\"Change nextOffset to {}\", nextOffset.get());\n      return toWrite;\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "151fca5032719e561226ef278e002739073c23ec": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9092. Nfs silently drops overlapping write requests and causes data copying to fail. Contributed by Yongjun Zhang.\n",
      "commitDate": "28/09/15 6:45 PM",
      "commitName": "151fca5032719e561226ef278e002739073c23ec",
      "commitAuthor": "Yongjun Zhang",
      "commitDateOld": "28/01/15 12:56 PM",
      "commitNameOld": "f37849188b05a6251584de1aed5e66d5dfa7da4f",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 243.2,
      "commitsBetweenForRepo": 1923,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,58 +1,69 @@\n   private synchronized WriteCtx offerNextToWrite() {\n     if (pendingWrites.isEmpty()) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"The async write task has no pending writes, fileId: \"\n             + latestAttr.getFileId());\n       }\n       // process pending commit again to handle this race: a commit is added\n       // to pendingCommits map just after the last doSingleWrite returns.\n       // There is no pending write and the commit should be handled by the\n       // last doSingleWrite. Due to the race, the commit is left along and\n       // can\u0027t be processed until cleanup. Therefore, we should do another\n       // processCommits to fix the race issue.\n       processCommits(nextOffset.get()); // nextOffset has same value as\n                                         // flushedOffset\n       this.asyncStatus \u003d false;\n       return null;\n     } \n-    \n-      Entry\u003cOffsetRange, WriteCtx\u003e lastEntry \u003d pendingWrites.lastEntry();\n-      OffsetRange range \u003d lastEntry.getKey();\n-      WriteCtx toWrite \u003d lastEntry.getValue();\n-      \n-      if (LOG.isTraceEnabled()) {\n-        LOG.trace(\"range.getMin()\u003d\" + range.getMin() + \" nextOffset\u003d\"\n-            + nextOffset);\n+\n+    Entry\u003cOffsetRange, WriteCtx\u003e lastEntry \u003d pendingWrites.lastEntry();\n+    OffsetRange range \u003d lastEntry.getKey();\n+    WriteCtx toWrite \u003d lastEntry.getValue();\n+\n+    if (LOG.isTraceEnabled()) {\n+      LOG.trace(\"range.getMin()\u003d\" + range.getMin() + \" nextOffset\u003d\"\n+          + nextOffset);\n+    }\n+\n+    long offset \u003d nextOffset.get();\n+    if (range.getMin() \u003e offset) {\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"The next sequential write has not arrived yet\");\n       }\n-      \n-      long offset \u003d nextOffset.get();\n-      if (range.getMin() \u003e offset) {\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"The next sequential write has not arrived yet\");\n-        }\n-        processCommits(nextOffset.get()); // handle race\n-        this.asyncStatus \u003d false;\n-      } else if (range.getMin() \u003c offset \u0026\u0026 range.getMax() \u003e offset) {\n-        // shouldn\u0027t happen since we do sync for overlapped concurrent writers\n-        LOG.warn(\"Got an overlapping write (\" + range.getMin() + \", \"\n-            + range.getMax() + \"), nextOffset\u003d\" + offset\n-            + \". Silently drop it now\");\n-        pendingWrites.remove(range);\n-        processCommits(nextOffset.get()); // handle race\n-      } else {\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"Remove write(\" + range.getMin() + \"-\" + range.getMax()\n-              + \") from the list\");\n-        }\n-        // after writing, remove the WriteCtx from cache \n-        pendingWrites.remove(range);\n-        // update nextOffset\n-        nextOffset.addAndGet(toWrite.getCount());\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"Change nextOffset to \" + nextOffset.get());\n-        }\n-        return toWrite;\n+      processCommits(nextOffset.get()); // handle race\n+      this.asyncStatus \u003d false;\n+    } else if (range.getMax() \u003c\u003d offset) {\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Remove write \" + range.toString()\n+            + \" which is already written from the list\");\n       }\n-    \n+      // remove the WriteCtx from cache\n+      pendingWrites.remove(range);\n+    } else if (range.getMin() \u003c offset \u0026\u0026 range.getMax() \u003e offset) {\n+      LOG.warn(\"Got an overlapping write \" + range.toString()\n+          + \", nextOffset\u003d\" + offset\n+          + \". Remove and trim it\");\n+      pendingWrites.remove(range);\n+      trimWriteRequest(toWrite, offset);\n+      // update nextOffset\n+      nextOffset.addAndGet(toWrite.getCount());\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Change nextOffset (after trim) to \" + nextOffset.get());\n+      }\n+      return toWrite;\n+    } else {\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Remove write \" + range.toString()\n+            + \" from the list\");\n+      }\n+      // after writing, remove the WriteCtx from cache\n+      pendingWrites.remove(range);\n+      // update nextOffset\n+      nextOffset.addAndGet(toWrite.getCount());\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Change nextOffset to \" + nextOffset.get());\n+      }\n+      return toWrite;\n+    }\n     return null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized WriteCtx offerNextToWrite() {\n    if (pendingWrites.isEmpty()) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"The async write task has no pending writes, fileId: \"\n            + latestAttr.getFileId());\n      }\n      // process pending commit again to handle this race: a commit is added\n      // to pendingCommits map just after the last doSingleWrite returns.\n      // There is no pending write and the commit should be handled by the\n      // last doSingleWrite. Due to the race, the commit is left along and\n      // can\u0027t be processed until cleanup. Therefore, we should do another\n      // processCommits to fix the race issue.\n      processCommits(nextOffset.get()); // nextOffset has same value as\n                                        // flushedOffset\n      this.asyncStatus \u003d false;\n      return null;\n    } \n\n    Entry\u003cOffsetRange, WriteCtx\u003e lastEntry \u003d pendingWrites.lastEntry();\n    OffsetRange range \u003d lastEntry.getKey();\n    WriteCtx toWrite \u003d lastEntry.getValue();\n\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"range.getMin()\u003d\" + range.getMin() + \" nextOffset\u003d\"\n          + nextOffset);\n    }\n\n    long offset \u003d nextOffset.get();\n    if (range.getMin() \u003e offset) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"The next sequential write has not arrived yet\");\n      }\n      processCommits(nextOffset.get()); // handle race\n      this.asyncStatus \u003d false;\n    } else if (range.getMax() \u003c\u003d offset) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Remove write \" + range.toString()\n            + \" which is already written from the list\");\n      }\n      // remove the WriteCtx from cache\n      pendingWrites.remove(range);\n    } else if (range.getMin() \u003c offset \u0026\u0026 range.getMax() \u003e offset) {\n      LOG.warn(\"Got an overlapping write \" + range.toString()\n          + \", nextOffset\u003d\" + offset\n          + \". Remove and trim it\");\n      pendingWrites.remove(range);\n      trimWriteRequest(toWrite, offset);\n      // update nextOffset\n      nextOffset.addAndGet(toWrite.getCount());\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Change nextOffset (after trim) to \" + nextOffset.get());\n      }\n      return toWrite;\n    } else {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Remove write \" + range.toString()\n            + \" from the list\");\n      }\n      // after writing, remove the WriteCtx from cache\n      pendingWrites.remove(range);\n      // update nextOffset\n      nextOffset.addAndGet(toWrite.getCount());\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Change nextOffset to \" + nextOffset.get());\n      }\n      return toWrite;\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7423. various typos and message formatting fixes in nfs daemon and doc. (Charles Lamb via yliu)\n",
      "commitDate": "28/01/15 12:56 PM",
      "commitName": "f37849188b05a6251584de1aed5e66d5dfa7da4f",
      "commitAuthor": "yliu",
      "commitDateOld": "11/12/14 3:40 PM",
      "commitNameOld": "f6f2a3f1c73266bfedd802eacde60d8b19b81015",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 47.89,
      "commitsBetweenForRepo": 279,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,58 +1,58 @@\n   private synchronized WriteCtx offerNextToWrite() {\n     if (pendingWrites.isEmpty()) {\n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"The asyn write task has no pending writes, fileId: \"\n+        LOG.debug(\"The async write task has no pending writes, fileId: \"\n             + latestAttr.getFileId());\n       }\n       // process pending commit again to handle this race: a commit is added\n       // to pendingCommits map just after the last doSingleWrite returns.\n       // There is no pending write and the commit should be handled by the\n       // last doSingleWrite. Due to the race, the commit is left along and\n       // can\u0027t be processed until cleanup. Therefore, we should do another\n       // processCommits to fix the race issue.\n       processCommits(nextOffset.get()); // nextOffset has same value as\n                                         // flushedOffset\n       this.asyncStatus \u003d false;\n       return null;\n     } \n     \n       Entry\u003cOffsetRange, WriteCtx\u003e lastEntry \u003d pendingWrites.lastEntry();\n       OffsetRange range \u003d lastEntry.getKey();\n       WriteCtx toWrite \u003d lastEntry.getValue();\n       \n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"range.getMin()\u003d\" + range.getMin() + \" nextOffset\u003d\"\n             + nextOffset);\n       }\n       \n       long offset \u003d nextOffset.get();\n       if (range.getMin() \u003e offset) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"The next sequential write has not arrived yet\");\n         }\n         processCommits(nextOffset.get()); // handle race\n         this.asyncStatus \u003d false;\n       } else if (range.getMin() \u003c offset \u0026\u0026 range.getMax() \u003e offset) {\n         // shouldn\u0027t happen since we do sync for overlapped concurrent writers\n-        LOG.warn(\"Got a overlapping write (\" + range.getMin() + \",\"\n+        LOG.warn(\"Got an overlapping write (\" + range.getMin() + \", \"\n             + range.getMax() + \"), nextOffset\u003d\" + offset\n             + \". Silently drop it now\");\n         pendingWrites.remove(range);\n         processCommits(nextOffset.get()); // handle race\n       } else {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Remove write(\" + range.getMin() + \"-\" + range.getMax()\n               + \") from the list\");\n         }\n         // after writing, remove the WriteCtx from cache \n         pendingWrites.remove(range);\n         // update nextOffset\n         nextOffset.addAndGet(toWrite.getCount());\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Change nextOffset to \" + nextOffset.get());\n         }\n         return toWrite;\n       }\n     \n     return null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized WriteCtx offerNextToWrite() {\n    if (pendingWrites.isEmpty()) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"The async write task has no pending writes, fileId: \"\n            + latestAttr.getFileId());\n      }\n      // process pending commit again to handle this race: a commit is added\n      // to pendingCommits map just after the last doSingleWrite returns.\n      // There is no pending write and the commit should be handled by the\n      // last doSingleWrite. Due to the race, the commit is left along and\n      // can\u0027t be processed until cleanup. Therefore, we should do another\n      // processCommits to fix the race issue.\n      processCommits(nextOffset.get()); // nextOffset has same value as\n                                        // flushedOffset\n      this.asyncStatus \u003d false;\n      return null;\n    } \n    \n      Entry\u003cOffsetRange, WriteCtx\u003e lastEntry \u003d pendingWrites.lastEntry();\n      OffsetRange range \u003d lastEntry.getKey();\n      WriteCtx toWrite \u003d lastEntry.getValue();\n      \n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"range.getMin()\u003d\" + range.getMin() + \" nextOffset\u003d\"\n            + nextOffset);\n      }\n      \n      long offset \u003d nextOffset.get();\n      if (range.getMin() \u003e offset) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"The next sequential write has not arrived yet\");\n        }\n        processCommits(nextOffset.get()); // handle race\n        this.asyncStatus \u003d false;\n      } else if (range.getMin() \u003c offset \u0026\u0026 range.getMax() \u003e offset) {\n        // shouldn\u0027t happen since we do sync for overlapped concurrent writers\n        LOG.warn(\"Got an overlapping write (\" + range.getMin() + \", \"\n            + range.getMax() + \"), nextOffset\u003d\" + offset\n            + \". Silently drop it now\");\n        pendingWrites.remove(range);\n        processCommits(nextOffset.get()); // handle race\n      } else {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Remove write(\" + range.getMin() + \"-\" + range.getMax()\n              + \") from the list\");\n        }\n        // after writing, remove the WriteCtx from cache \n        pendingWrites.remove(range);\n        // update nextOffset\n        nextOffset.addAndGet(toWrite.getCount());\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Change nextOffset to \" + nextOffset.get());\n        }\n        return toWrite;\n      }\n    \n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "08a9ac7098cb4ae684f40cf2513e3137110cc7e4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6942. Fix typos in log messages. Contributed by Ray Chiang.\n",
      "commitDate": "02/09/14 4:22 PM",
      "commitName": "08a9ac7098cb4ae684f40cf2513e3137110cc7e4",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "19/06/14 12:39 PM",
      "commitNameOld": "9ff3836a367737d6dfcb12f50c8bd2f1b2233e37",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 75.15,
      "commitsBetweenForRepo": 587,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,58 +1,58 @@\n   private synchronized WriteCtx offerNextToWrite() {\n     if (pendingWrites.isEmpty()) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"The asyn write task has no pending writes, fileId: \"\n             + latestAttr.getFileId());\n       }\n       // process pending commit again to handle this race: a commit is added\n       // to pendingCommits map just after the last doSingleWrite returns.\n       // There is no pending write and the commit should be handled by the\n       // last doSingleWrite. Due to the race, the commit is left along and\n       // can\u0027t be processed until cleanup. Therefore, we should do another\n       // processCommits to fix the race issue.\n       processCommits(nextOffset.get()); // nextOffset has same value as\n                                         // flushedOffset\n       this.asyncStatus \u003d false;\n       return null;\n     } \n     \n       Entry\u003cOffsetRange, WriteCtx\u003e lastEntry \u003d pendingWrites.lastEntry();\n       OffsetRange range \u003d lastEntry.getKey();\n       WriteCtx toWrite \u003d lastEntry.getValue();\n       \n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"range.getMin()\u003d\" + range.getMin() + \" nextOffset\u003d\"\n             + nextOffset);\n       }\n       \n       long offset \u003d nextOffset.get();\n       if (range.getMin() \u003e offset) {\n         if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"The next sequencial write has not arrived yet\");\n+          LOG.debug(\"The next sequential write has not arrived yet\");\n         }\n         processCommits(nextOffset.get()); // handle race\n         this.asyncStatus \u003d false;\n       } else if (range.getMin() \u003c offset \u0026\u0026 range.getMax() \u003e offset) {\n         // shouldn\u0027t happen since we do sync for overlapped concurrent writers\n         LOG.warn(\"Got a overlapping write (\" + range.getMin() + \",\"\n             + range.getMax() + \"), nextOffset\u003d\" + offset\n             + \". Silently drop it now\");\n         pendingWrites.remove(range);\n         processCommits(nextOffset.get()); // handle race\n       } else {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Remove write(\" + range.getMin() + \"-\" + range.getMax()\n               + \") from the list\");\n         }\n         // after writing, remove the WriteCtx from cache \n         pendingWrites.remove(range);\n         // update nextOffset\n         nextOffset.addAndGet(toWrite.getCount());\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Change nextOffset to \" + nextOffset.get());\n         }\n         return toWrite;\n       }\n     \n     return null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized WriteCtx offerNextToWrite() {\n    if (pendingWrites.isEmpty()) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"The asyn write task has no pending writes, fileId: \"\n            + latestAttr.getFileId());\n      }\n      // process pending commit again to handle this race: a commit is added\n      // to pendingCommits map just after the last doSingleWrite returns.\n      // There is no pending write and the commit should be handled by the\n      // last doSingleWrite. Due to the race, the commit is left along and\n      // can\u0027t be processed until cleanup. Therefore, we should do another\n      // processCommits to fix the race issue.\n      processCommits(nextOffset.get()); // nextOffset has same value as\n                                        // flushedOffset\n      this.asyncStatus \u003d false;\n      return null;\n    } \n    \n      Entry\u003cOffsetRange, WriteCtx\u003e lastEntry \u003d pendingWrites.lastEntry();\n      OffsetRange range \u003d lastEntry.getKey();\n      WriteCtx toWrite \u003d lastEntry.getValue();\n      \n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"range.getMin()\u003d\" + range.getMin() + \" nextOffset\u003d\"\n            + nextOffset);\n      }\n      \n      long offset \u003d nextOffset.get();\n      if (range.getMin() \u003e offset) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"The next sequential write has not arrived yet\");\n        }\n        processCommits(nextOffset.get()); // handle race\n        this.asyncStatus \u003d false;\n      } else if (range.getMin() \u003c offset \u0026\u0026 range.getMax() \u003e offset) {\n        // shouldn\u0027t happen since we do sync for overlapped concurrent writers\n        LOG.warn(\"Got a overlapping write (\" + range.getMin() + \",\"\n            + range.getMax() + \"), nextOffset\u003d\" + offset\n            + \". Silently drop it now\");\n        pendingWrites.remove(range);\n        processCommits(nextOffset.get()); // handle race\n      } else {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Remove write(\" + range.getMin() + \"-\" + range.getMax()\n              + \") from the list\");\n        }\n        // after writing, remove the WriteCtx from cache \n        pendingWrites.remove(range);\n        // update nextOffset\n        nextOffset.addAndGet(toWrite.getCount());\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Change nextOffset to \" + nextOffset.get());\n        }\n        return toWrite;\n      }\n    \n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "5c02d2f6225144772dcb975d3144b057b71d6476": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5281. COMMIT request should not block. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1530461 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/10/13 4:40 PM",
      "commitName": "5c02d2f6225144772dcb975d3144b057b71d6476",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "06/10/13 7:57 PM",
      "commitNameOld": "caa4abd30cfc4361c7bc9f212a9092840d7c3b53",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 1.86,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,58 @@\n   private synchronized WriteCtx offerNextToWrite() {\n     if (pendingWrites.isEmpty()) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"The asyn write task has no pending writes, fileId: \"\n             + latestAttr.getFileId());\n       }\n+      // process pending commit again to handle this race: a commit is added\n+      // to pendingCommits map just after the last doSingleWrite returns.\n+      // There is no pending write and the commit should be handled by the\n+      // last doSingleWrite. Due to the race, the commit is left along and\n+      // can\u0027t be processed until cleanup. Therefore, we should do another\n+      // processCommits to fix the race issue.\n+      processCommits(nextOffset.get()); // nextOffset has same value as\n+                                        // flushedOffset\n       this.asyncStatus \u003d false;\n-    } else {\n+      return null;\n+    } \n+    \n       Entry\u003cOffsetRange, WriteCtx\u003e lastEntry \u003d pendingWrites.lastEntry();\n       OffsetRange range \u003d lastEntry.getKey();\n       WriteCtx toWrite \u003d lastEntry.getValue();\n       \n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"range.getMin()\u003d\" + range.getMin() + \" nextOffset\u003d\"\n             + nextOffset);\n       }\n       \n       long offset \u003d nextOffset.get();\n       if (range.getMin() \u003e offset) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"The next sequencial write has not arrived yet\");\n         }\n+        processCommits(nextOffset.get()); // handle race\n         this.asyncStatus \u003d false;\n       } else if (range.getMin() \u003c offset \u0026\u0026 range.getMax() \u003e offset) {\n         // shouldn\u0027t happen since we do sync for overlapped concurrent writers\n         LOG.warn(\"Got a overlapping write (\" + range.getMin() + \",\"\n             + range.getMax() + \"), nextOffset\u003d\" + offset\n             + \". Silently drop it now\");\n         pendingWrites.remove(range);\n+        processCommits(nextOffset.get()); // handle race\n       } else {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Remove write(\" + range.getMin() + \"-\" + range.getMax()\n               + \") from the list\");\n         }\n         // after writing, remove the WriteCtx from cache \n         pendingWrites.remove(range);\n         // update nextOffset\n         nextOffset.addAndGet(toWrite.getCount());\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Change nextOffset to \" + nextOffset.get());\n         }\n         return toWrite;\n       }\n-    }\n+    \n     return null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized WriteCtx offerNextToWrite() {\n    if (pendingWrites.isEmpty()) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"The asyn write task has no pending writes, fileId: \"\n            + latestAttr.getFileId());\n      }\n      // process pending commit again to handle this race: a commit is added\n      // to pendingCommits map just after the last doSingleWrite returns.\n      // There is no pending write and the commit should be handled by the\n      // last doSingleWrite. Due to the race, the commit is left along and\n      // can\u0027t be processed until cleanup. Therefore, we should do another\n      // processCommits to fix the race issue.\n      processCommits(nextOffset.get()); // nextOffset has same value as\n                                        // flushedOffset\n      this.asyncStatus \u003d false;\n      return null;\n    } \n    \n      Entry\u003cOffsetRange, WriteCtx\u003e lastEntry \u003d pendingWrites.lastEntry();\n      OffsetRange range \u003d lastEntry.getKey();\n      WriteCtx toWrite \u003d lastEntry.getValue();\n      \n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"range.getMin()\u003d\" + range.getMin() + \" nextOffset\u003d\"\n            + nextOffset);\n      }\n      \n      long offset \u003d nextOffset.get();\n      if (range.getMin() \u003e offset) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"The next sequencial write has not arrived yet\");\n        }\n        processCommits(nextOffset.get()); // handle race\n        this.asyncStatus \u003d false;\n      } else if (range.getMin() \u003c offset \u0026\u0026 range.getMax() \u003e offset) {\n        // shouldn\u0027t happen since we do sync for overlapped concurrent writers\n        LOG.warn(\"Got a overlapping write (\" + range.getMin() + \",\"\n            + range.getMax() + \"), nextOffset\u003d\" + offset\n            + \". Silently drop it now\");\n        pendingWrites.remove(range);\n        processCommits(nextOffset.get()); // handle race\n      } else {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Remove write(\" + range.getMin() + \"-\" + range.getMax()\n              + \") from the list\");\n        }\n        // after writing, remove the WriteCtx from cache \n        pendingWrites.remove(range);\n        // update nextOffset\n        nextOffset.addAndGet(toWrite.getCount());\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Change nextOffset to \" + nextOffset.get());\n        }\n        return toWrite;\n      }\n    \n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "28e3d09230971b32f74284311931525cb7ad1b7c": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4971. Move IO operations out of locking in OpenFileCtx. Contributed by Jing Zhao and Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1525681 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/09/13 1:02 PM",
      "commitName": "28e3d09230971b32f74284311931525cb7ad1b7c",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,46 @@\n+  private synchronized WriteCtx offerNextToWrite() {\n+    if (pendingWrites.isEmpty()) {\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"The asyn write task has no pending writes, fileId: \"\n+            + latestAttr.getFileId());\n+      }\n+      this.asyncStatus \u003d false;\n+    } else {\n+      Entry\u003cOffsetRange, WriteCtx\u003e lastEntry \u003d pendingWrites.lastEntry();\n+      OffsetRange range \u003d lastEntry.getKey();\n+      WriteCtx toWrite \u003d lastEntry.getValue();\n+      \n+      if (LOG.isTraceEnabled()) {\n+        LOG.trace(\"range.getMin()\u003d\" + range.getMin() + \" nextOffset\u003d\"\n+            + nextOffset);\n+      }\n+      \n+      long offset \u003d nextOffset.get();\n+      if (range.getMin() \u003e offset) {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"The next sequencial write has not arrived yet\");\n+        }\n+        this.asyncStatus \u003d false;\n+      } else if (range.getMin() \u003c offset \u0026\u0026 range.getMax() \u003e offset) {\n+        // shouldn\u0027t happen since we do sync for overlapped concurrent writers\n+        LOG.warn(\"Got a overlapping write (\" + range.getMin() + \",\"\n+            + range.getMax() + \"), nextOffset\u003d\" + offset\n+            + \". Silently drop it now\");\n+        pendingWrites.remove(range);\n+      } else {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Remove write(\" + range.getMin() + \"-\" + range.getMax()\n+              + \") from the list\");\n+        }\n+        // after writing, remove the WriteCtx from cache \n+        pendingWrites.remove(range);\n+        // update nextOffset\n+        nextOffset.addAndGet(toWrite.getCount());\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Change nextOffset to \" + nextOffset.get());\n+        }\n+        return toWrite;\n+      }\n+    }\n+    return null;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized WriteCtx offerNextToWrite() {\n    if (pendingWrites.isEmpty()) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"The asyn write task has no pending writes, fileId: \"\n            + latestAttr.getFileId());\n      }\n      this.asyncStatus \u003d false;\n    } else {\n      Entry\u003cOffsetRange, WriteCtx\u003e lastEntry \u003d pendingWrites.lastEntry();\n      OffsetRange range \u003d lastEntry.getKey();\n      WriteCtx toWrite \u003d lastEntry.getValue();\n      \n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"range.getMin()\u003d\" + range.getMin() + \" nextOffset\u003d\"\n            + nextOffset);\n      }\n      \n      long offset \u003d nextOffset.get();\n      if (range.getMin() \u003e offset) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"The next sequencial write has not arrived yet\");\n        }\n        this.asyncStatus \u003d false;\n      } else if (range.getMin() \u003c offset \u0026\u0026 range.getMax() \u003e offset) {\n        // shouldn\u0027t happen since we do sync for overlapped concurrent writers\n        LOG.warn(\"Got a overlapping write (\" + range.getMin() + \",\"\n            + range.getMax() + \"), nextOffset\u003d\" + offset\n            + \". Silently drop it now\");\n        pendingWrites.remove(range);\n      } else {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Remove write(\" + range.getMin() + \"-\" + range.getMax()\n              + \") from the list\");\n        }\n        // after writing, remove the WriteCtx from cache \n        pendingWrites.remove(range);\n        // update nextOffset\n        nextOffset.addAndGet(toWrite.getCount());\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Change nextOffset to \" + nextOffset.get());\n        }\n        return toWrite;\n      }\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java"
    }
  }
}