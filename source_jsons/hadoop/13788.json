{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "addExpectedReplicasToPending",
  "functionId": "addExpectedReplicasToPending___blk-BlockInfo",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 1163,
  "functionEndLine": 1179,
  "numCommitsSeen": 794,
  "timeTaken": 10497,
  "changeHistory": [
    "a98352ced18e51003b443e1a652d19ec00b2f2d2",
    "5865fe2bf01284993572ea60b3ec3bf8b4492818",
    "972782d9568e0849484c027f27c1638ba50ec56e",
    "2a987243423eb5c7e191de2ba969b7591a441c70"
  ],
  "changeHistoryShort": {
    "a98352ced18e51003b443e1a652d19ec00b2f2d2": "Ybodychange",
    "5865fe2bf01284993572ea60b3ec3bf8b4492818": "Ybodychange",
    "972782d9568e0849484c027f27c1638ba50ec56e": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
    "2a987243423eb5c7e191de2ba969b7591a441c70": "Yintroduced"
  },
  "changeHistoryDetails": {
    "a98352ced18e51003b443e1a652d19ec00b2f2d2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15086. Block scheduled counter never get decremet if the block got deleted before replication. Contributed by hemanthboyina.\n",
      "commitDate": "13/02/20 3:27 AM",
      "commitName": "a98352ced18e51003b443e1a652d19ec00b2f2d2",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "06/11/19 9:56 AM",
      "commitNameOld": "dd900259c421d6edd0b89a535a1fe08ada91735f",
      "commitAuthorOld": "Chen Liang",
      "daysBetweenCommits": 98.73,
      "commitsBetweenForRepo": 341,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   public void addExpectedReplicasToPending(BlockInfo blk) {\n     if (!blk.isStriped()) {\n       DatanodeStorageInfo[] expectedStorages \u003d\n           blk.getUnderConstructionFeature().getExpectedStorageLocations();\n       if (expectedStorages.length - blk.numNodes() \u003e 0) {\n-        ArrayList\u003cDatanodeDescriptor\u003e pendingNodes \u003d new ArrayList\u003c\u003e();\n+        ArrayList\u003cDatanodeStorageInfo\u003e pendingNodes \u003d new ArrayList\u003c\u003e();\n         for (DatanodeStorageInfo storage : expectedStorages) {\n           DatanodeDescriptor dnd \u003d storage.getDatanodeDescriptor();\n           if (blk.findStorageInfo(dnd) \u003d\u003d null) {\n-            pendingNodes.add(dnd);\n+            pendingNodes.add(storage);\n           }\n         }\n         pendingReconstruction.increment(blk,\n-            pendingNodes.toArray(new DatanodeDescriptor[pendingNodes.size()]));\n+            pendingNodes.toArray(new DatanodeStorageInfo[pendingNodes.size()]));\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void addExpectedReplicasToPending(BlockInfo blk) {\n    if (!blk.isStriped()) {\n      DatanodeStorageInfo[] expectedStorages \u003d\n          blk.getUnderConstructionFeature().getExpectedStorageLocations();\n      if (expectedStorages.length - blk.numNodes() \u003e 0) {\n        ArrayList\u003cDatanodeStorageInfo\u003e pendingNodes \u003d new ArrayList\u003c\u003e();\n        for (DatanodeStorageInfo storage : expectedStorages) {\n          DatanodeDescriptor dnd \u003d storage.getDatanodeDescriptor();\n          if (blk.findStorageInfo(dnd) \u003d\u003d null) {\n            pendingNodes.add(storage);\n          }\n        }\n        pendingReconstruction.increment(blk,\n            pendingNodes.toArray(new DatanodeStorageInfo[pendingNodes.size()]));\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "5865fe2bf01284993572ea60b3ec3bf8b4492818": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9869. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-2]. Contributed by Rakesh R.\n",
      "commitDate": "25/04/16 10:01 PM",
      "commitName": "5865fe2bf01284993572ea60b3ec3bf8b4492818",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "17/04/16 6:28 PM",
      "commitNameOld": "67523ffcf491f4f2db5335899c00a174d0caaa9b",
      "commitAuthorOld": "Walter Su",
      "daysBetweenCommits": 8.15,
      "commitsBetweenForRepo": 47,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   public void addExpectedReplicasToPending(BlockInfo blk) {\n     if (!blk.isStriped()) {\n       DatanodeStorageInfo[] expectedStorages \u003d\n           blk.getUnderConstructionFeature().getExpectedStorageLocations();\n       if (expectedStorages.length - blk.numNodes() \u003e 0) {\n         ArrayList\u003cDatanodeDescriptor\u003e pendingNodes \u003d new ArrayList\u003c\u003e();\n         for (DatanodeStorageInfo storage : expectedStorages) {\n           DatanodeDescriptor dnd \u003d storage.getDatanodeDescriptor();\n           if (blk.findStorageInfo(dnd) \u003d\u003d null) {\n             pendingNodes.add(dnd);\n           }\n         }\n-        pendingReplications.increment(blk,\n+        pendingReconstruction.increment(blk,\n             pendingNodes.toArray(new DatanodeDescriptor[pendingNodes.size()]));\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void addExpectedReplicasToPending(BlockInfo blk) {\n    if (!blk.isStriped()) {\n      DatanodeStorageInfo[] expectedStorages \u003d\n          blk.getUnderConstructionFeature().getExpectedStorageLocations();\n      if (expectedStorages.length - blk.numNodes() \u003e 0) {\n        ArrayList\u003cDatanodeDescriptor\u003e pendingNodes \u003d new ArrayList\u003c\u003e();\n        for (DatanodeStorageInfo storage : expectedStorages) {\n          DatanodeDescriptor dnd \u003d storage.getDatanodeDescriptor();\n          if (blk.findStorageInfo(dnd) \u003d\u003d null) {\n            pendingNodes.add(dnd);\n          }\n        }\n        pendingReconstruction.increment(blk,\n            pendingNodes.toArray(new DatanodeDescriptor[pendingNodes.size()]));\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "972782d9568e0849484c027f27c1638ba50ec56e": {
      "type": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-9754. Avoid unnecessary getBlockCollection calls in BlockManager. Contributed by Jing Zhao.\n",
      "commitDate": "12/02/16 11:07 AM",
      "commitName": "972782d9568e0849484c027f27c1638ba50ec56e",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9754. Avoid unnecessary getBlockCollection calls in BlockManager. Contributed by Jing Zhao.\n",
          "commitDate": "12/02/16 11:07 AM",
          "commitName": "972782d9568e0849484c027f27c1638ba50ec56e",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "10/02/16 9:24 PM",
          "commitNameOld": "19adb2bc641999b83e25ff0e107ba8c6edbad399",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 1.57,
          "commitsBetweenForRepo": 17,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,17 @@\n-  private void addExpectedReplicasToPending(BlockInfo lastBlock) {\n-    DatanodeStorageInfo[] expectedStorages \u003d\n-        lastBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n-    if (expectedStorages.length - lastBlock.numNodes() \u003e 0) {\n-      ArrayList\u003cDatanodeDescriptor\u003e pendingNodes \u003d\n-          new ArrayList\u003cDatanodeDescriptor\u003e();\n-      for (DatanodeStorageInfo storage : expectedStorages) {\n-        DatanodeDescriptor dnd \u003d storage.getDatanodeDescriptor();\n-        if (lastBlock.findStorageInfo(dnd) \u003d\u003d null) {\n-          pendingNodes.add(dnd);\n+  public void addExpectedReplicasToPending(BlockInfo blk) {\n+    if (!blk.isStriped()) {\n+      DatanodeStorageInfo[] expectedStorages \u003d\n+          blk.getUnderConstructionFeature().getExpectedStorageLocations();\n+      if (expectedStorages.length - blk.numNodes() \u003e 0) {\n+        ArrayList\u003cDatanodeDescriptor\u003e pendingNodes \u003d new ArrayList\u003c\u003e();\n+        for (DatanodeStorageInfo storage : expectedStorages) {\n+          DatanodeDescriptor dnd \u003d storage.getDatanodeDescriptor();\n+          if (blk.findStorageInfo(dnd) \u003d\u003d null) {\n+            pendingNodes.add(dnd);\n+          }\n         }\n+        pendingReplications.increment(blk,\n+            pendingNodes.toArray(new DatanodeDescriptor[pendingNodes.size()]));\n       }\n-      pendingReplications.increment(lastBlock,\n-          pendingNodes.toArray(new DatanodeDescriptor[pendingNodes.size()]));\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void addExpectedReplicasToPending(BlockInfo blk) {\n    if (!blk.isStriped()) {\n      DatanodeStorageInfo[] expectedStorages \u003d\n          blk.getUnderConstructionFeature().getExpectedStorageLocations();\n      if (expectedStorages.length - blk.numNodes() \u003e 0) {\n        ArrayList\u003cDatanodeDescriptor\u003e pendingNodes \u003d new ArrayList\u003c\u003e();\n        for (DatanodeStorageInfo storage : expectedStorages) {\n          DatanodeDescriptor dnd \u003d storage.getDatanodeDescriptor();\n          if (blk.findStorageInfo(dnd) \u003d\u003d null) {\n            pendingNodes.add(dnd);\n          }\n        }\n        pendingReplications.increment(blk,\n            pendingNodes.toArray(new DatanodeDescriptor[pendingNodes.size()]));\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "[lastBlock-BlockInfo]",
            "newValue": "[blk-BlockInfo]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-9754. Avoid unnecessary getBlockCollection calls in BlockManager. Contributed by Jing Zhao.\n",
          "commitDate": "12/02/16 11:07 AM",
          "commitName": "972782d9568e0849484c027f27c1638ba50ec56e",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "10/02/16 9:24 PM",
          "commitNameOld": "19adb2bc641999b83e25ff0e107ba8c6edbad399",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 1.57,
          "commitsBetweenForRepo": 17,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,17 @@\n-  private void addExpectedReplicasToPending(BlockInfo lastBlock) {\n-    DatanodeStorageInfo[] expectedStorages \u003d\n-        lastBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n-    if (expectedStorages.length - lastBlock.numNodes() \u003e 0) {\n-      ArrayList\u003cDatanodeDescriptor\u003e pendingNodes \u003d\n-          new ArrayList\u003cDatanodeDescriptor\u003e();\n-      for (DatanodeStorageInfo storage : expectedStorages) {\n-        DatanodeDescriptor dnd \u003d storage.getDatanodeDescriptor();\n-        if (lastBlock.findStorageInfo(dnd) \u003d\u003d null) {\n-          pendingNodes.add(dnd);\n+  public void addExpectedReplicasToPending(BlockInfo blk) {\n+    if (!blk.isStriped()) {\n+      DatanodeStorageInfo[] expectedStorages \u003d\n+          blk.getUnderConstructionFeature().getExpectedStorageLocations();\n+      if (expectedStorages.length - blk.numNodes() \u003e 0) {\n+        ArrayList\u003cDatanodeDescriptor\u003e pendingNodes \u003d new ArrayList\u003c\u003e();\n+        for (DatanodeStorageInfo storage : expectedStorages) {\n+          DatanodeDescriptor dnd \u003d storage.getDatanodeDescriptor();\n+          if (blk.findStorageInfo(dnd) \u003d\u003d null) {\n+            pendingNodes.add(dnd);\n+          }\n         }\n+        pendingReplications.increment(blk,\n+            pendingNodes.toArray(new DatanodeDescriptor[pendingNodes.size()]));\n       }\n-      pendingReplications.increment(lastBlock,\n-          pendingNodes.toArray(new DatanodeDescriptor[pendingNodes.size()]));\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void addExpectedReplicasToPending(BlockInfo blk) {\n    if (!blk.isStriped()) {\n      DatanodeStorageInfo[] expectedStorages \u003d\n          blk.getUnderConstructionFeature().getExpectedStorageLocations();\n      if (expectedStorages.length - blk.numNodes() \u003e 0) {\n        ArrayList\u003cDatanodeDescriptor\u003e pendingNodes \u003d new ArrayList\u003c\u003e();\n        for (DatanodeStorageInfo storage : expectedStorages) {\n          DatanodeDescriptor dnd \u003d storage.getDatanodeDescriptor();\n          if (blk.findStorageInfo(dnd) \u003d\u003d null) {\n            pendingNodes.add(dnd);\n          }\n        }\n        pendingReplications.increment(blk,\n            pendingNodes.toArray(new DatanodeDescriptor[pendingNodes.size()]));\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9754. Avoid unnecessary getBlockCollection calls in BlockManager. Contributed by Jing Zhao.\n",
          "commitDate": "12/02/16 11:07 AM",
          "commitName": "972782d9568e0849484c027f27c1638ba50ec56e",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "10/02/16 9:24 PM",
          "commitNameOld": "19adb2bc641999b83e25ff0e107ba8c6edbad399",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 1.57,
          "commitsBetweenForRepo": 17,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,17 @@\n-  private void addExpectedReplicasToPending(BlockInfo lastBlock) {\n-    DatanodeStorageInfo[] expectedStorages \u003d\n-        lastBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n-    if (expectedStorages.length - lastBlock.numNodes() \u003e 0) {\n-      ArrayList\u003cDatanodeDescriptor\u003e pendingNodes \u003d\n-          new ArrayList\u003cDatanodeDescriptor\u003e();\n-      for (DatanodeStorageInfo storage : expectedStorages) {\n-        DatanodeDescriptor dnd \u003d storage.getDatanodeDescriptor();\n-        if (lastBlock.findStorageInfo(dnd) \u003d\u003d null) {\n-          pendingNodes.add(dnd);\n+  public void addExpectedReplicasToPending(BlockInfo blk) {\n+    if (!blk.isStriped()) {\n+      DatanodeStorageInfo[] expectedStorages \u003d\n+          blk.getUnderConstructionFeature().getExpectedStorageLocations();\n+      if (expectedStorages.length - blk.numNodes() \u003e 0) {\n+        ArrayList\u003cDatanodeDescriptor\u003e pendingNodes \u003d new ArrayList\u003c\u003e();\n+        for (DatanodeStorageInfo storage : expectedStorages) {\n+          DatanodeDescriptor dnd \u003d storage.getDatanodeDescriptor();\n+          if (blk.findStorageInfo(dnd) \u003d\u003d null) {\n+            pendingNodes.add(dnd);\n+          }\n         }\n+        pendingReplications.increment(blk,\n+            pendingNodes.toArray(new DatanodeDescriptor[pendingNodes.size()]));\n       }\n-      pendingReplications.increment(lastBlock,\n-          pendingNodes.toArray(new DatanodeDescriptor[pendingNodes.size()]));\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void addExpectedReplicasToPending(BlockInfo blk) {\n    if (!blk.isStriped()) {\n      DatanodeStorageInfo[] expectedStorages \u003d\n          blk.getUnderConstructionFeature().getExpectedStorageLocations();\n      if (expectedStorages.length - blk.numNodes() \u003e 0) {\n        ArrayList\u003cDatanodeDescriptor\u003e pendingNodes \u003d new ArrayList\u003c\u003e();\n        for (DatanodeStorageInfo storage : expectedStorages) {\n          DatanodeDescriptor dnd \u003d storage.getDatanodeDescriptor();\n          if (blk.findStorageInfo(dnd) \u003d\u003d null) {\n            pendingNodes.add(dnd);\n          }\n        }\n        pendingReplications.increment(blk,\n            pendingNodes.toArray(new DatanodeDescriptor[pendingNodes.size()]));\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "2a987243423eb5c7e191de2ba969b7591a441c70": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-1172. Blocks in newly completed files are considered under-replicated too quickly. Contributed by Masatake Iwasaki.\n",
      "commitDate": "13/10/15 11:00 PM",
      "commitName": "2a987243423eb5c7e191de2ba969b7591a441c70",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,16 @@\n+  private void addExpectedReplicasToPending(BlockInfo lastBlock) {\n+    DatanodeStorageInfo[] expectedStorages \u003d\n+        lastBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n+    if (expectedStorages.length - lastBlock.numNodes() \u003e 0) {\n+      ArrayList\u003cDatanodeDescriptor\u003e pendingNodes \u003d\n+          new ArrayList\u003cDatanodeDescriptor\u003e();\n+      for (DatanodeStorageInfo storage : expectedStorages) {\n+        DatanodeDescriptor dnd \u003d storage.getDatanodeDescriptor();\n+        if (lastBlock.findStorageInfo(dnd) \u003d\u003d null) {\n+          pendingNodes.add(dnd);\n+        }\n+      }\n+      pendingReplications.increment(lastBlock,\n+          pendingNodes.toArray(new DatanodeDescriptor[pendingNodes.size()]));\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void addExpectedReplicasToPending(BlockInfo lastBlock) {\n    DatanodeStorageInfo[] expectedStorages \u003d\n        lastBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n    if (expectedStorages.length - lastBlock.numNodes() \u003e 0) {\n      ArrayList\u003cDatanodeDescriptor\u003e pendingNodes \u003d\n          new ArrayList\u003cDatanodeDescriptor\u003e();\n      for (DatanodeStorageInfo storage : expectedStorages) {\n        DatanodeDescriptor dnd \u003d storage.getDatanodeDescriptor();\n        if (lastBlock.findStorageInfo(dnd) \u003d\u003d null) {\n          pendingNodes.add(dnd);\n        }\n      }\n      pendingReplications.increment(lastBlock,\n          pendingNodes.toArray(new DatanodeDescriptor[pendingNodes.size()]));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
    }
  }
}