{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "isSufficientlyReplicated",
  "functionId": "isSufficientlyReplicated___b-BlockInfo",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 1613,
  "functionEndLine": 1622,
  "numCommitsSeen": 477,
  "timeTaken": 9146,
  "changeHistory": [
    "ff06ef0631cb8a0f67bbc39b5b5a1b0a81ca3b3c"
  ],
  "changeHistoryShort": {
    "ff06ef0631cb8a0f67bbc39b5b5a1b0a81ca3b3c": "Ybodychange"
  },
  "changeHistoryDetails": {
    "ff06ef0631cb8a0f67bbc39b5b5a1b0a81ca3b3c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14366. Improve HDFS append performance. Contributed by Chao Sun.\n",
      "commitDate": "15/03/19 11:06 AM",
      "commitName": "ff06ef0631cb8a0f67bbc39b5b5a1b0a81ca3b3c",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "13/03/19 1:15 PM",
      "commitNameOld": "66357574ae1da09ced735da36bf7d80a40c3fa1b",
      "commitAuthorOld": "Erik Krogen",
      "daysBetweenCommits": 1.91,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,10 @@\n   public boolean isSufficientlyReplicated(BlockInfo b) {\n     // Compare against the lesser of the minReplication and number of live DNs.\n-    final int replication \u003d\n-        Math.min(minReplication, getDatanodeManager().getNumLiveDataNodes());\n-    return countNodes(b).liveReplicas() \u003e\u003d replication;\n+    final int liveReplicas \u003d countNodes(b).liveReplicas();\n+    if (liveReplicas \u003e\u003d minReplication) {\n+      return true;\n+    }\n+    // getNumLiveDataNodes() is very expensive and we minimize its use by\n+    // comparing with minReplication first.\n+    return liveReplicas \u003e\u003d getDatanodeManager().getNumLiveDataNodes();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean isSufficientlyReplicated(BlockInfo b) {\n    // Compare against the lesser of the minReplication and number of live DNs.\n    final int liveReplicas \u003d countNodes(b).liveReplicas();\n    if (liveReplicas \u003e\u003d minReplication) {\n      return true;\n    }\n    // getNumLiveDataNodes() is very expensive and we minimize its use by\n    // comparing with minReplication first.\n    return liveReplicas \u003e\u003d getDatanodeManager().getNumLiveDataNodes();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    }
  }
}