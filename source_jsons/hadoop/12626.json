{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ExternalSPSContext.java",
  "functionName": "getNumLiveDataNodes",
  "functionId": "getNumLiveDataNodes",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/sps/ExternalSPSContext.java",
  "functionStartLine": 137,
  "functionEndLine": 145,
  "numCommitsSeen": 8,
  "timeTaken": 1846,
  "changeHistory": [
    "5845c36c16c423107183287cce3be9357dad7564",
    "99594b48b8e040ab5a0939d7c3dbcfb34400e6fc"
  ],
  "changeHistoryShort": {
    "5845c36c16c423107183287cce3be9357dad7564": "Ybodychange",
    "99594b48b8e040ab5a0939d7c3dbcfb34400e6fc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "5845c36c16c423107183287cce3be9357dad7564": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13050: [SPS]: Create start/stop script to start external SPS process. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "5845c36c16c423107183287cce3be9357dad7564",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "99594b48b8e040ab5a0939d7c3dbcfb34400e6fc",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,9 @@\n   public int getNumLiveDataNodes() {\n-    initializeNamenodeConnector();\n     try {\n       return nnc.getDistributedFileSystem()\n           .getDataNodeStats(DatanodeReportType.LIVE).length;\n     } catch (IOException e) {\n       LOG.warn(\"Exception while getting number of live datanodes.\", e);\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int getNumLiveDataNodes() {\n    try {\n      return nnc.getDistributedFileSystem()\n          .getDataNodeStats(DatanodeReportType.LIVE).length;\n    } catch (IOException e) {\n      LOG.warn(\"Exception while getting number of live datanodes.\", e);\n    }\n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/sps/ExternalSPSContext.java",
      "extendedDetails": {}
    },
    "99594b48b8e040ab5a0939d7c3dbcfb34400e6fc": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13075. [SPS]: Provide External Context implementation. Contributed by Uma Maheswara Rao G.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "99594b48b8e040ab5a0939d7c3dbcfb34400e6fc",
      "commitAuthor": "Surendra Singh Lilhore",
      "diff": "@@ -0,0 +1,10 @@\n+  public int getNumLiveDataNodes() {\n+    initializeNamenodeConnector();\n+    try {\n+      return nnc.getDistributedFileSystem()\n+          .getDataNodeStats(DatanodeReportType.LIVE).length;\n+    } catch (IOException e) {\n+      LOG.warn(\"Exception while getting number of live datanodes.\", e);\n+    }\n+    return 0;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public int getNumLiveDataNodes() {\n    initializeNamenodeConnector();\n    try {\n      return nnc.getDistributedFileSystem()\n          .getDataNodeStats(DatanodeReportType.LIVE).length;\n    } catch (IOException e) {\n      LOG.warn(\"Exception while getting number of live datanodes.\", e);\n    }\n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/sps/ExternalSPSContext.java"
    }
  }
}