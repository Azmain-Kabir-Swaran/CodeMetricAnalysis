{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HostFileManager.java",
  "functionName": "refresh",
  "functionId": "refresh___includeFile-String__excludeFile-String",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HostFileManager.java",
  "functionStartLine": 154,
  "functionEndLine": 160,
  "numCommitsSeen": 8,
  "timeTaken": 1940,
  "changeHistory": [
    "fde8ac5d8514f5146f438f8d0794116aaef20416",
    "b94b56806d3d6e04984e229b479f7ac15b62bbfa",
    "05af0ff4be871ddbb4c4cb4f0b5b506ecee36fb8",
    "88209ce181b5ecc55c0ae2bceff4893ab4817e88",
    "2002dc63c9409de733a374d810c529e95895df44"
  ],
  "changeHistoryShort": {
    "fde8ac5d8514f5146f438f8d0794116aaef20416": "Ymodifierchange",
    "b94b56806d3d6e04984e229b479f7ac15b62bbfa": "Ybodychange",
    "05af0ff4be871ddbb4c4cb4f0b5b506ecee36fb8": "Ybodychange",
    "88209ce181b5ecc55c0ae2bceff4893ab4817e88": "Ybodychange",
    "2002dc63c9409de733a374d810c529e95895df44": "Yintroduced"
  },
  "changeHistoryDetails": {
    "fde8ac5d8514f5146f438f8d0794116aaef20416": {
      "type": "Ymodifierchange",
      "commitMessage": "Add missing files from HDFS-9005. (lei)\n",
      "commitDate": "25/03/16 5:11 PM",
      "commitName": "fde8ac5d8514f5146f438f8d0794116aaef20416",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "28/08/15 2:21 PM",
      "commitNameOld": "b94b56806d3d6e04984e229b479f7ac15b62bbfa",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 210.12,
      "commitsBetweenForRepo": 1414,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,7 @@\n-  void refresh(String includeFile, String excludeFile) throws IOException {\n+  private void refresh(String includeFile, String excludeFile)\n+      throws IOException {\n     HostSet newIncludes \u003d readFile(\"included\", includeFile);\n     HostSet newExcludes \u003d readFile(\"excluded\", excludeFile);\n \n     refresh(newIncludes, newExcludes);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void refresh(String includeFile, String excludeFile)\n      throws IOException {\n    HostSet newIncludes \u003d readFile(\"included\", includeFile);\n    HostSet newExcludes \u003d readFile(\"excluded\", excludeFile);\n\n    refresh(newIncludes, newExcludes);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HostFileManager.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[private]"
      }
    },
    "b94b56806d3d6e04984e229b479f7ac15b62bbfa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8950. NameNode refresh doesn\u0027t remove DataNodes that are no longer in the allowed list (Daniel Templeton)\n",
      "commitDate": "28/08/15 2:21 PM",
      "commitName": "b94b56806d3d6e04984e229b479f7ac15b62bbfa",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "09/09/14 5:30 PM",
      "commitNameOld": "05af0ff4be871ddbb4c4cb4f0b5b506ecee36fb8",
      "commitAuthorOld": "Konstantin V Shvachko",
      "daysBetweenCommits": 352.87,
      "commitsBetweenForRepo": 2859,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,6 @@\n   void refresh(String includeFile, String excludeFile) throws IOException {\n     HostSet newIncludes \u003d readFile(\"included\", includeFile);\n     HostSet newExcludes \u003d readFile(\"excluded\", excludeFile);\n-    synchronized (this) {\n-      includes \u003d newIncludes;\n-      excludes \u003d newExcludes;\n-    }\n+\n+    refresh(newIncludes, newExcludes);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void refresh(String includeFile, String excludeFile) throws IOException {\n    HostSet newIncludes \u003d readFile(\"included\", includeFile);\n    HostSet newExcludes \u003d readFile(\"excluded\", excludeFile);\n\n    refresh(newIncludes, newExcludes);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HostFileManager.java",
      "extendedDetails": {}
    },
    "05af0ff4be871ddbb4c4cb4f0b5b506ecee36fb8": {
      "type": "Ybodychange",
      "commitMessage": "Revert HDFS-6940.",
      "commitDate": "09/09/14 5:30 PM",
      "commitName": "05af0ff4be871ddbb4c4cb4f0b5b506ecee36fb8",
      "commitAuthor": "Konstantin V Shvachko",
      "commitDateOld": "06/09/14 12:07 PM",
      "commitNameOld": "88209ce181b5ecc55c0ae2bceff4893ab4817e88",
      "commitAuthorOld": "Konstantin V Shvachko",
      "daysBetweenCommits": 3.22,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,8 @@\n   void refresh(String includeFile, String excludeFile) throws IOException {\n     HostSet newIncludes \u003d readFile(\"included\", includeFile);\n     HostSet newExcludes \u003d readFile(\"excluded\", excludeFile);\n-    setHosts(newIncludes, newExcludes);\n+    synchronized (this) {\n+      includes \u003d newIncludes;\n+      excludes \u003d newExcludes;\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void refresh(String includeFile, String excludeFile) throws IOException {\n    HostSet newIncludes \u003d readFile(\"included\", includeFile);\n    HostSet newExcludes \u003d readFile(\"excluded\", excludeFile);\n    synchronized (this) {\n      includes \u003d newIncludes;\n      excludes \u003d newExcludes;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HostFileManager.java",
      "extendedDetails": {}
    },
    "88209ce181b5ecc55c0ae2bceff4893ab4817e88": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6940. Refactoring to allow ConsensusNode implementation.\nContributed by Konstantin Shvachko.",
      "commitDate": "06/09/14 12:07 PM",
      "commitName": "88209ce181b5ecc55c0ae2bceff4893ab4817e88",
      "commitAuthor": "Konstantin V Shvachko",
      "commitDateOld": "07/04/14 4:55 PM",
      "commitNameOld": "2002dc63c9409de733a374d810c529e95895df44",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 151.8,
      "commitsBetweenForRepo": 1074,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,5 @@\n   void refresh(String includeFile, String excludeFile) throws IOException {\n     HostSet newIncludes \u003d readFile(\"included\", includeFile);\n     HostSet newExcludes \u003d readFile(\"excluded\", excludeFile);\n-    synchronized (this) {\n-      includes \u003d newIncludes;\n-      excludes \u003d newExcludes;\n-    }\n+    setHosts(newIncludes, newExcludes);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void refresh(String includeFile, String excludeFile) throws IOException {\n    HostSet newIncludes \u003d readFile(\"included\", includeFile);\n    HostSet newExcludes \u003d readFile(\"excluded\", excludeFile);\n    setHosts(newIncludes, newExcludes);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HostFileManager.java",
      "extendedDetails": {}
    },
    "2002dc63c9409de733a374d810c529e95895df44": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6180. Dead node count / listing is very broken in JMX and old GUI. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1585625 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/04/14 4:55 PM",
      "commitName": "2002dc63c9409de733a374d810c529e95895df44",
      "commitAuthor": "Haohui Mai",
      "diff": "@@ -0,0 +1,8 @@\n+  void refresh(String includeFile, String excludeFile) throws IOException {\n+    HostSet newIncludes \u003d readFile(\"included\", includeFile);\n+    HostSet newExcludes \u003d readFile(\"excluded\", excludeFile);\n+    synchronized (this) {\n+      includes \u003d newIncludes;\n+      excludes \u003d newExcludes;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void refresh(String includeFile, String excludeFile) throws IOException {\n    HostSet newIncludes \u003d readFile(\"included\", includeFile);\n    HostSet newExcludes \u003d readFile(\"excluded\", excludeFile);\n    synchronized (this) {\n      includes \u003d newIncludes;\n      excludes \u003d newExcludes;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HostFileManager.java"
    }
  }
}