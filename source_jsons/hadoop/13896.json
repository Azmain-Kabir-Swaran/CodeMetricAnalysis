{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "countLiveNodes",
  "functionId": "countLiveNodes___b-BlockInfo",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 4467,
  "functionEndLine": 4470,
  "numCommitsSeen": 898,
  "timeTaken": 20560,
  "changeHistory": [
    "47b92f2b6f2dafc129a41b247f35e77c8e47ffba",
    "e418bd1fb0568ce7ae22f588fea2dd9c95567383",
    "4928f5473394981829e5ffd4b16ea0801baf5c45",
    "ba9371492036983a9899398907ab41fe548f29b3",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
    "2f341414dd4a052bee3907ff4a6db283a15f9d53",
    "3f070e83b1f4e0211ece8c0ab508a61188ad352a",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "09b6f98de431628c80bc8a6faf0070eeaf72ff2a",
    "97b6ca4dd7d1233e8f8c90b1c01e47228c044e13",
    "1bcfe45e47775b98cce5541f328c4fd46e5eb13d",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "47b92f2b6f2dafc129a41b247f35e77c8e47ffba": "Ybodychange",
    "e418bd1fb0568ce7ae22f588fea2dd9c95567383": "Ybodychange",
    "4928f5473394981829e5ffd4b16ea0801baf5c45": "Yparameterchange",
    "ba9371492036983a9899398907ab41fe548f29b3": "Yparameterchange",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": "Yparameterchange",
    "2f341414dd4a052bee3907ff4a6db283a15f9d53": "Ybodychange",
    "3f070e83b1f4e0211ece8c0ab508a61188ad352a": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "09b6f98de431628c80bc8a6faf0070eeaf72ff2a": "Yfilerename",
    "97b6ca4dd7d1233e8f8c90b1c01e47228c044e13": "Yfilerename",
    "1bcfe45e47775b98cce5541f328c4fd46e5eb13d": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "47b92f2b6f2dafc129a41b247f35e77c8e47ffba": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9837. BlockManager#countNodes should be able to detect duplicated internal blocks. Contributed by Jing Zhao.\n",
      "commitDate": "24/02/16 3:13 PM",
      "commitName": "47b92f2b6f2dafc129a41b247f35e77c8e47ffba",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "20/02/16 11:19 PM",
      "commitNameOld": "d5abd293a890a8a1da48a166a291ae1c5644ad57",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 3.66,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,4 @@\n   int countLiveNodes(BlockInfo b) {\n-    if (!namesystem.isInStartupSafeMode()) {\n-      return countNodes(b).liveReplicas();\n-    }\n-    // else proceed with fast case\n-    int live \u003d 0;\n-    Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n-    for (DatanodeStorageInfo storage : blocksMap.getStorages(b)) {\n-      if (storage.getState() !\u003d State.NORMAL) {\n-        continue;\n-      }\n-      final DatanodeDescriptor node \u003d storage.getDatanodeDescriptor();\n-      if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n-        live++;\n-    }\n-    return live;\n+    final boolean inStartupSafeMode \u003d namesystem.isInStartupSafeMode();\n+    return countNodes(b, inStartupSafeMode).liveReplicas();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  int countLiveNodes(BlockInfo b) {\n    final boolean inStartupSafeMode \u003d namesystem.isInStartupSafeMode();\n    return countNodes(b, inStartupSafeMode).liveReplicas();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "e418bd1fb0568ce7ae22f588fea2dd9c95567383": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9566. Remove expensive \u0027BlocksMap#getStorages(Block b, final DatanodeStorage.State state)\u0027 method (Contributed by Daryn Sharp)\n",
      "commitDate": "31/01/16 11:54 PM",
      "commitName": "e418bd1fb0568ce7ae22f588fea2dd9c95567383",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "27/01/16 4:31 PM",
      "commitNameOld": "3a9571308e99cc374681bbc451a517d41a150aa0",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 4.31,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,17 @@\n   int countLiveNodes(BlockInfo b) {\n     if (!namesystem.isInStartupSafeMode()) {\n       return countNodes(b).liveReplicas();\n     }\n     // else proceed with fast case\n     int live \u003d 0;\n     Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n-    for(DatanodeStorageInfo storage : blocksMap.getStorages(b, State.NORMAL)) {\n+    for (DatanodeStorageInfo storage : blocksMap.getStorages(b)) {\n+      if (storage.getState() !\u003d State.NORMAL) {\n+        continue;\n+      }\n       final DatanodeDescriptor node \u003d storage.getDatanodeDescriptor();\n       if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n         live++;\n     }\n     return live;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  int countLiveNodes(BlockInfo b) {\n    if (!namesystem.isInStartupSafeMode()) {\n      return countNodes(b).liveReplicas();\n    }\n    // else proceed with fast case\n    int live \u003d 0;\n    Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n    for (DatanodeStorageInfo storage : blocksMap.getStorages(b)) {\n      if (storage.getState() !\u003d State.NORMAL) {\n        continue;\n      }\n      final DatanodeDescriptor node \u003d storage.getDatanodeDescriptor();\n      if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n        live++;\n    }\n    return live;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "4928f5473394981829e5ffd4b16ea0801baf5c45": {
      "type": "Yparameterchange",
      "commitMessage": "HDFS-8482. Rename BlockInfoContiguous to BlockInfo. Contributed by Zhe Zhang.\n",
      "commitDate": "27/05/15 3:42 PM",
      "commitName": "4928f5473394981829e5ffd4b16ea0801baf5c45",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "19/05/15 11:05 AM",
      "commitNameOld": "8860e352c394372e4eb3ebdf82ea899567f34e4e",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 8.19,
      "commitsBetweenForRepo": 52,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n-  int countLiveNodes(BlockInfoContiguous b) {\n+  int countLiveNodes(BlockInfo b) {\n     if (!namesystem.isInStartupSafeMode()) {\n       return countNodes(b).liveReplicas();\n     }\n     // else proceed with fast case\n     int live \u003d 0;\n     Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n     for(DatanodeStorageInfo storage : blocksMap.getStorages(b, State.NORMAL)) {\n       final DatanodeDescriptor node \u003d storage.getDatanodeDescriptor();\n       if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n         live++;\n     }\n     return live;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  int countLiveNodes(BlockInfo b) {\n    if (!namesystem.isInStartupSafeMode()) {\n      return countNodes(b).liveReplicas();\n    }\n    // else proceed with fast case\n    int live \u003d 0;\n    Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n    for(DatanodeStorageInfo storage : blocksMap.getStorages(b, State.NORMAL)) {\n      final DatanodeDescriptor node \u003d storage.getDatanodeDescriptor();\n      if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n        live++;\n    }\n    return live;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {
        "oldValue": "[b-BlockInfoContiguous]",
        "newValue": "[b-BlockInfo]"
      }
    },
    "ba9371492036983a9899398907ab41fe548f29b3": {
      "type": "Yparameterchange",
      "commitMessage": "HDFS-7716. Erasure Coding: extend BlockInfo to handle EC info. Contributed by Jing Zhao.\n",
      "commitDate": "26/05/15 11:07 AM",
      "commitName": "ba9371492036983a9899398907ab41fe548f29b3",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "26/05/15 11:03 AM",
      "commitNameOld": "0c1da5a0300f015a7e39f2b40a73fb06c65a78c8",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n-  int countLiveNodes(BlockInfoContiguous b) {\n+  int countLiveNodes(BlockInfo b) {\n     if (!namesystem.isInStartupSafeMode()) {\n       return countNodes(b).liveReplicas();\n     }\n     // else proceed with fast case\n     int live \u003d 0;\n     Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n     for(DatanodeStorageInfo storage : blocksMap.getStorages(b, State.NORMAL)) {\n       final DatanodeDescriptor node \u003d storage.getDatanodeDescriptor();\n       if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n         live++;\n     }\n     return live;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  int countLiveNodes(BlockInfo b) {\n    if (!namesystem.isInStartupSafeMode()) {\n      return countNodes(b).liveReplicas();\n    }\n    // else proceed with fast case\n    int live \u003d 0;\n    Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n    for(DatanodeStorageInfo storage : blocksMap.getStorages(b, State.NORMAL)) {\n      final DatanodeDescriptor node \u003d storage.getDatanodeDescriptor();\n      if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n        live++;\n    }\n    return live;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {
        "oldValue": "[b-BlockInfoContiguous]",
        "newValue": "[b-BlockInfo]"
      }
    },
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": {
      "type": "Yparameterchange",
      "commitMessage": "HDFS-7743. Code cleanup of BlockInfo and rename BlockInfo to BlockInfoContiguous. Contributed by Jing Zhao.\n",
      "commitDate": "08/02/15 11:51 AM",
      "commitName": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "04/02/15 11:31 AM",
      "commitNameOld": "9175105eeaecf0a1d60b57989b73ce45cee4689b",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 4.01,
      "commitsBetweenForRepo": 50,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n-  int countLiveNodes(BlockInfo b) {\n+  int countLiveNodes(BlockInfoContiguous b) {\n     if (!namesystem.isInStartupSafeMode()) {\n       return countNodes(b).liveReplicas();\n     }\n     // else proceed with fast case\n     int live \u003d 0;\n     Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n     for(DatanodeStorageInfo storage : blocksMap.getStorages(b, State.NORMAL)) {\n       final DatanodeDescriptor node \u003d storage.getDatanodeDescriptor();\n       if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n         live++;\n     }\n     return live;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  int countLiveNodes(BlockInfoContiguous b) {\n    if (!namesystem.isInStartupSafeMode()) {\n      return countNodes(b).liveReplicas();\n    }\n    // else proceed with fast case\n    int live \u003d 0;\n    Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n    for(DatanodeStorageInfo storage : blocksMap.getStorages(b, State.NORMAL)) {\n      final DatanodeDescriptor node \u003d storage.getDatanodeDescriptor();\n      if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n        live++;\n    }\n    return live;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {
        "oldValue": "[b-BlockInfo]",
        "newValue": "[b-BlockInfoContiguous]"
      }
    },
    "2f341414dd4a052bee3907ff4a6db283a15f9d53": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5318. Support read-only and read-write paths to shared replicas. (Contributed by Eric Sirianni)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1569951 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/02/14 2:59 PM",
      "commitName": "2f341414dd4a052bee3907ff4a6db283a15f9d53",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "31/01/14 1:00 PM",
      "commitNameOld": "5beeb3016954a3ee0c1fb10a2083ffd540cd2c14",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 19.08,
      "commitsBetweenForRepo": 153,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   int countLiveNodes(BlockInfo b) {\n     if (!namesystem.isInStartupSafeMode()) {\n       return countNodes(b).liveReplicas();\n     }\n     // else proceed with fast case\n     int live \u003d 0;\n     Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n-    for(DatanodeStorageInfo storage : blocksMap.getStorages(b)) {\n+    for(DatanodeStorageInfo storage : blocksMap.getStorages(b, State.NORMAL)) {\n       final DatanodeDescriptor node \u003d storage.getDatanodeDescriptor();\n       if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n         live++;\n     }\n     return live;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  int countLiveNodes(BlockInfo b) {\n    if (!namesystem.isInStartupSafeMode()) {\n      return countNodes(b).liveReplicas();\n    }\n    // else proceed with fast case\n    int live \u003d 0;\n    Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n    for(DatanodeStorageInfo storage : blocksMap.getStorages(b, State.NORMAL)) {\n      final DatanodeDescriptor node \u003d storage.getDatanodeDescriptor();\n      if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n        live++;\n    }\n    return live;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "3f070e83b1f4e0211ece8c0ab508a61188ad352a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5009. Include storage information in the LocatedBlock.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1519691 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/09/13 7:03 AM",
      "commitName": "3f070e83b1f4e0211ece8c0ab508a61188ad352a",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "27/08/13 11:30 PM",
      "commitNameOld": "5d9d702607913685eab0d8ad077040ddc82bf085",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 6.31,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,14 @@\n   int countLiveNodes(BlockInfo b) {\n     if (!namesystem.isInStartupSafeMode()) {\n       return countNodes(b).liveReplicas();\n     }\n     // else proceed with fast case\n     int live \u003d 0;\n-    Iterator\u003cDatanodeDescriptor\u003e nodeIter \u003d blocksMap.nodeIterator(b);\n     Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n-    while (nodeIter.hasNext()) {\n-      DatanodeDescriptor node \u003d nodeIter.next();\n+    for(DatanodeStorageInfo storage : blocksMap.getStorages(b)) {\n+      final DatanodeDescriptor node \u003d storage.getDatanodeDescriptor();\n       if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n         live++;\n     }\n     return live;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  int countLiveNodes(BlockInfo b) {\n    if (!namesystem.isInStartupSafeMode()) {\n      return countNodes(b).liveReplicas();\n    }\n    // else proceed with fast case\n    int live \u003d 0;\n    Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n    for(DatanodeStorageInfo storage : blocksMap.getStorages(b)) {\n      final DatanodeDescriptor node \u003d storage.getDatanodeDescriptor();\n      if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n        live++;\n    }\n    return live;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  int countLiveNodes(BlockInfo b) {\n    if (!namesystem.isInStartupSafeMode()) {\n      return countNodes(b).liveReplicas();\n    }\n    // else proceed with fast case\n    int live \u003d 0;\n    Iterator\u003cDatanodeDescriptor\u003e nodeIter \u003d blocksMap.nodeIterator(b);\n    Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n    while (nodeIter.hasNext()) {\n      DatanodeDescriptor node \u003d nodeIter.next();\n      if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n        live++;\n    }\n    return live;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  int countLiveNodes(BlockInfo b) {\n    if (!namesystem.isInStartupSafeMode()) {\n      return countNodes(b).liveReplicas();\n    }\n    // else proceed with fast case\n    int live \u003d 0;\n    Iterator\u003cDatanodeDescriptor\u003e nodeIter \u003d blocksMap.nodeIterator(b);\n    Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n    while (nodeIter.hasNext()) {\n      DatanodeDescriptor node \u003d nodeIter.next();\n      if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n        live++;\n    }\n    return live;\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
      }
    },
    "09b6f98de431628c80bc8a6faf0070eeaf72ff2a": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2107. Move block management code from o.a.h.h.s.namenode to a new package o.a.h.h.s.blockmanagement.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1140939 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/06/11 6:31 PM",
      "commitName": "09b6f98de431628c80bc8a6faf0070eeaf72ff2a",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "28/06/11 5:26 PM",
      "commitNameOld": "97b6ca4dd7d1233e8f8c90b1c01e47228c044e13",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  int countLiveNodes(BlockInfo b) {\n    if (!namesystem.isInStartupSafeMode()) {\n      return countNodes(b).liveReplicas();\n    }\n    // else proceed with fast case\n    int live \u003d 0;\n    Iterator\u003cDatanodeDescriptor\u003e nodeIter \u003d blocksMap.nodeIterator(b);\n    Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n    while (nodeIter.hasNext()) {\n      DatanodeDescriptor node \u003d nodeIter.next();\n      if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n        live++;\n    }\n    return live;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/BlockManager.java",
        "newPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
      }
    },
    "97b6ca4dd7d1233e8f8c90b1c01e47228c044e13": {
      "type": "Yfilerename",
      "commitMessage": "Revert 1140913 and 1140909 for HDFS-2107.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1140920 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/06/11 5:26 PM",
      "commitName": "97b6ca4dd7d1233e8f8c90b1c01e47228c044e13",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "28/06/11 4:57 PM",
      "commitNameOld": "d58e3efe9269efe00c309ed0e9726d2f94bcd03a",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  int countLiveNodes(BlockInfo b) {\n    if (!namesystem.isInStartupSafeMode()) {\n      return countNodes(b).liveReplicas();\n    }\n    // else proceed with fast case\n    int live \u003d 0;\n    Iterator\u003cDatanodeDescriptor\u003e nodeIter \u003d blocksMap.nodeIterator(b);\n    Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n    while (nodeIter.hasNext()) {\n      DatanodeDescriptor node \u003d nodeIter.next();\n      if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n        live++;\n    }\n    return live;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/BlockManager.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
        "newPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/BlockManager.java"
      }
    },
    "1bcfe45e47775b98cce5541f328c4fd46e5eb13d": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2106. Move block management code from o.a.h.h.s.namenode to a new package o.a.h.h.s.blockmanagement.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1140909 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/06/11 4:43 PM",
      "commitName": "1bcfe45e47775b98cce5541f328c4fd46e5eb13d",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "28/06/11 9:21 AM",
      "commitNameOld": "1834fb99f516b2f2cd5e0ab1f89d407f98a7237a",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.31,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  int countLiveNodes(BlockInfo b) {\n    if (!namesystem.isInStartupSafeMode()) {\n      return countNodes(b).liveReplicas();\n    }\n    // else proceed with fast case\n    int live \u003d 0;\n    Iterator\u003cDatanodeDescriptor\u003e nodeIter \u003d blocksMap.nodeIterator(b);\n    Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n    while (nodeIter.hasNext()) {\n      DatanodeDescriptor node \u003d nodeIter.next();\n      if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n        live++;\n    }\n    return live;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/BlockManager.java",
        "newPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,15 @@\n+  int countLiveNodes(BlockInfo b) {\n+    if (!namesystem.isInStartupSafeMode()) {\n+      return countNodes(b).liveReplicas();\n+    }\n+    // else proceed with fast case\n+    int live \u003d 0;\n+    Iterator\u003cDatanodeDescriptor\u003e nodeIter \u003d blocksMap.nodeIterator(b);\n+    Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n+    while (nodeIter.hasNext()) {\n+      DatanodeDescriptor node \u003d nodeIter.next();\n+      if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n+        live++;\n+    }\n+    return live;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  int countLiveNodes(BlockInfo b) {\n    if (!namesystem.isInStartupSafeMode()) {\n      return countNodes(b).liveReplicas();\n    }\n    // else proceed with fast case\n    int live \u003d 0;\n    Iterator\u003cDatanodeDescriptor\u003e nodeIter \u003d blocksMap.nodeIterator(b);\n    Collection\u003cDatanodeDescriptor\u003e nodesCorrupt \u003d corruptReplicas.getNodes(b);\n    while (nodeIter.hasNext()) {\n      DatanodeDescriptor node \u003d nodeIter.next();\n      if ((nodesCorrupt \u003d\u003d null) || (!nodesCorrupt.contains(node)))\n        live++;\n    }\n    return live;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/BlockManager.java"
    }
  }
}