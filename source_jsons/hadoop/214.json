{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "OpenFileCtx.java",
  "functionName": "doSingleWrite",
  "functionId": "doSingleWrite___writeCtx-WriteCtx(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
  "functionStartLine": 1123,
  "functionEndLine": 1216,
  "numCommitsSeen": 36,
  "timeTaken": 3764,
  "changeHistory": [
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
    "7b1fa5693efc687492776d43ab482601cbb30dfd",
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
    "d6602b5f39833611b4afa4581552f6c4c37e23a8",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f",
    "f6f2a3f1c73266bfedd802eacde60d8b19b81015",
    "875aa797caee96572162ff59bc50cf97d1195348",
    "3bfd18c6b0483ae27eff6d53bda934e67dda5464",
    "3fccdec6e0a8e9305fc75921211c3745eddb9c45",
    "16c6755554cc5ecd9d4e0ba74b75b10c74bb0ab4",
    "5c02d2f6225144772dcb975d3144b057b71d6476",
    "caa4abd30cfc4361c7bc9f212a9092840d7c3b53",
    "28e3d09230971b32f74284311931525cb7ad1b7c",
    "5e18410e06dd63113c49029894007e0878312903",
    "a56a4b6ef06602312144783b7507bf2b82821e4f",
    "30b8ef91a32ddf1fe3756bae6d7dc538a150bdc4",
    "58d75576c4d2a03d4954174bc223ed0334b34fee",
    "37f587563a943a827fbff865f5302bac6d202415"
  ],
  "changeHistoryShort": {
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568": "Ybodychange",
    "7b1fa5693efc687492776d43ab482601cbb30dfd": "Ybodychange",
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": "Ybodychange",
    "d6602b5f39833611b4afa4581552f6c4c37e23a8": "Ybodychange",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": "Ybodychange",
    "f6f2a3f1c73266bfedd802eacde60d8b19b81015": "Ybodychange",
    "875aa797caee96572162ff59bc50cf97d1195348": "Ybodychange",
    "3bfd18c6b0483ae27eff6d53bda934e67dda5464": "Ybodychange",
    "3fccdec6e0a8e9305fc75921211c3745eddb9c45": "Ybodychange",
    "16c6755554cc5ecd9d4e0ba74b75b10c74bb0ab4": "Ybodychange",
    "5c02d2f6225144772dcb975d3144b057b71d6476": "Ybodychange",
    "caa4abd30cfc4361c7bc9f212a9092840d7c3b53": "Ybodychange",
    "28e3d09230971b32f74284311931525cb7ad1b7c": "Ybodychange",
    "5e18410e06dd63113c49029894007e0878312903": "Ybodychange",
    "a56a4b6ef06602312144783b7507bf2b82821e4f": "Ybodychange",
    "30b8ef91a32ddf1fe3756bae6d7dc538a150bdc4": "Ybodychange",
    "58d75576c4d2a03d4954174bc223ed0334b34fee": "Ybodychange",
    "37f587563a943a827fbff865f5302bac6d202415": "Yintroduced"
  },
  "changeHistoryDetails": {
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13695. Move logging to slf4j in HDFS package. Contributed by Ian Pickering.\n",
      "commitDate": "06/09/18 2:48 PM",
      "commitName": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "27/08/18 10:18 AM",
      "commitNameOld": "7b1fa5693efc687492776d43ab482601cbb30dfd",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 10.19,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,94 @@\n   private void doSingleWrite(final WriteCtx writeCtx) {\n     Channel channel \u003d writeCtx.getChannel();\n     int xid \u003d writeCtx.getXid();\n \n     long offset \u003d writeCtx.getOffset();\n     int count \u003d writeCtx.getCount();\n     WriteStableHow stableHow \u003d writeCtx.getStableHow();\n     \n     FileHandle handle \u003d writeCtx.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"do write, fileHandle {} offset: {} length: {} stableHow: {}\",\n           handle.dumpFileHandle(), offset, count, stableHow.name());\n     }\n \n     try {\n       // The write is not protected by lock. asyncState is used to make sure\n       // there is one thread doing write back at any time    \n       writeCtx.writeData(fos);\n       RpcProgramNfs3.metrics.incrBytesWritten(writeCtx.getCount());\n       \n       long flushedOffset \u003d getFlushedOffset();\n       if (flushedOffset !\u003d (offset + count)) {\n         throw new IOException(\"output stream is out of sync, pos\u003d\"\n             + flushedOffset + \" and nextOffset should be\"\n             + (offset + count));\n       }\n       \n \n       // Reduce memory occupation size if request was allowed dumped\n       if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n         synchronized (writeCtx) {\n           if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n             writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n             updateNonSequentialWriteInMemory(-count);\n             if (LOG.isDebugEnabled()) {\n               LOG.debug(\"After writing {} at offset {}, \" +\n                       \"updated the memory count, new value: {}\",\n                   handle.dumpFileHandle(), offset,\n                   nonSequentialWriteInMemory.get());\n             }\n           }\n         }\n       }\n       \n       if (!writeCtx.getReplied()) {\n         if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n           LOG.info(\"Do sync for stable write: {}\", writeCtx);\n           try {\n             if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n               fos.hsync();\n             } else {\n               Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                   \"Unknown WriteStableHow: \" + stableHow);\n               // Sync file data and length\n               fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n             }\n           } catch (IOException e) {\n             LOG.error(\"hsync failed with writeCtx: {}\", writeCtx, e);\n             throw e;\n           }\n         }\n         \n         WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n           LOG.warn(\"Return original count: {} instead of real data count: {}\",\n               writeCtx.getOriginalCount(), count);\n           count \u003d writeCtx.getOriginalCount();\n         }\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n         RpcProgramNfs3.metrics.addWrite(Nfs3Utils.getElapsedTime(writeCtx.startTime));\n         Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n       }\n       \n       // Handle the waiting commits without holding any lock\n       processCommits(writeCtx.getOffset() + writeCtx.getCount());\n      \n     } catch (IOException e) {\n       LOG.error(\"Error writing to fileHandle {} at offset {} and length {}\",\n           handle.dumpFileHandle(), offset, count, e);\n       if (!writeCtx.getReplied()) {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n         Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n         // Keep stream open. Either client retries or SteamMonitor closes it.\n       }\n \n       LOG.info(\"Clean up open file context for fileId: {}\",\n           latestAttr.getFileId());\n-      cleanupWithLogger();\n+      cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    \n    FileHandle handle \u003d writeCtx.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"do write, fileHandle {} offset: {} length: {} stableHow: {}\",\n          handle.dumpFileHandle(), offset, count, stableHow.name());\n    }\n\n    try {\n      // The write is not protected by lock. asyncState is used to make sure\n      // there is one thread doing write back at any time    \n      writeCtx.writeData(fos);\n      RpcProgramNfs3.metrics.incrBytesWritten(writeCtx.getCount());\n      \n      long flushedOffset \u003d getFlushedOffset();\n      if (flushedOffset !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + flushedOffset + \" and nextOffset should be\"\n            + (offset + count));\n      }\n      \n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n        synchronized (writeCtx) {\n          if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n            writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n            updateNonSequentialWriteInMemory(-count);\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"After writing {} at offset {}, \" +\n                      \"updated the memory count, new value: {}\",\n                  handle.dumpFileHandle(), offset,\n                  nonSequentialWriteInMemory.get());\n            }\n          }\n        }\n      }\n      \n      if (!writeCtx.getReplied()) {\n        if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n          LOG.info(\"Do sync for stable write: {}\", writeCtx);\n          try {\n            if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n              fos.hsync();\n            } else {\n              Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                  \"Unknown WriteStableHow: \" + stableHow);\n              // Sync file data and length\n              fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n            }\n          } catch (IOException e) {\n            LOG.error(\"hsync failed with writeCtx: {}\", writeCtx, e);\n            throw e;\n          }\n        }\n        \n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n          LOG.warn(\"Return original count: {} instead of real data count: {}\",\n              writeCtx.getOriginalCount(), count);\n          count \u003d writeCtx.getOriginalCount();\n        }\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        RpcProgramNfs3.metrics.addWrite(Nfs3Utils.getElapsedTime(writeCtx.startTime));\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n      }\n      \n      // Handle the waiting commits without holding any lock\n      processCommits(writeCtx.getOffset() + writeCtx.getCount());\n     \n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileHandle {} at offset {} and length {}\",\n          handle.dumpFileHandle(), offset, count, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: {}\",\n          latestAttr.getFileId());\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "7b1fa5693efc687492776d43ab482601cbb30dfd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13849. Migrate logging to slf4j in hadoop-hdfs-httpfs, hadoop-hdfs-nfs, hadoop-hdfs-rbf, hadoop-hdfs-native-client. Contributed by Ian Pickering.\n",
      "commitDate": "27/08/18 10:18 AM",
      "commitName": "7b1fa5693efc687492776d43ab482601cbb30dfd",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "14/02/18 8:20 AM",
      "commitNameOld": "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 194.04,
      "commitsBetweenForRepo": 2013,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,94 @@\n   private void doSingleWrite(final WriteCtx writeCtx) {\n     Channel channel \u003d writeCtx.getChannel();\n     int xid \u003d writeCtx.getXid();\n \n     long offset \u003d writeCtx.getOffset();\n     int count \u003d writeCtx.getCount();\n     WriteStableHow stableHow \u003d writeCtx.getStableHow();\n     \n     FileHandle handle \u003d writeCtx.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"do write, fileHandle {} offset: {} length: {} stableHow: {}\",\n           handle.dumpFileHandle(), offset, count, stableHow.name());\n     }\n \n     try {\n       // The write is not protected by lock. asyncState is used to make sure\n       // there is one thread doing write back at any time    \n       writeCtx.writeData(fos);\n       RpcProgramNfs3.metrics.incrBytesWritten(writeCtx.getCount());\n       \n       long flushedOffset \u003d getFlushedOffset();\n       if (flushedOffset !\u003d (offset + count)) {\n         throw new IOException(\"output stream is out of sync, pos\u003d\"\n             + flushedOffset + \" and nextOffset should be\"\n             + (offset + count));\n       }\n       \n \n       // Reduce memory occupation size if request was allowed dumped\n       if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n         synchronized (writeCtx) {\n           if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n             writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n             updateNonSequentialWriteInMemory(-count);\n             if (LOG.isDebugEnabled()) {\n               LOG.debug(\"After writing {} at offset {}, \" +\n                       \"updated the memory count, new value: {}\",\n                   handle.dumpFileHandle(), offset,\n                   nonSequentialWriteInMemory.get());\n             }\n           }\n         }\n       }\n       \n       if (!writeCtx.getReplied()) {\n         if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n           LOG.info(\"Do sync for stable write: {}\", writeCtx);\n           try {\n             if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n               fos.hsync();\n             } else {\n               Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                   \"Unknown WriteStableHow: \" + stableHow);\n               // Sync file data and length\n               fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n             }\n           } catch (IOException e) {\n             LOG.error(\"hsync failed with writeCtx: {}\", writeCtx, e);\n             throw e;\n           }\n         }\n         \n         WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n           LOG.warn(\"Return original count: {} instead of real data count: {}\",\n               writeCtx.getOriginalCount(), count);\n           count \u003d writeCtx.getOriginalCount();\n         }\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n         RpcProgramNfs3.metrics.addWrite(Nfs3Utils.getElapsedTime(writeCtx.startTime));\n         Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n       }\n       \n       // Handle the waiting commits without holding any lock\n       processCommits(writeCtx.getOffset() + writeCtx.getCount());\n      \n     } catch (IOException e) {\n       LOG.error(\"Error writing to fileHandle {} at offset {} and length {}\",\n           handle.dumpFileHandle(), offset, count, e);\n       if (!writeCtx.getReplied()) {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n         Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n         // Keep stream open. Either client retries or SteamMonitor closes it.\n       }\n \n       LOG.info(\"Clean up open file context for fileId: {}\",\n           latestAttr.getFileId());\n-      cleanup();\n+      cleanupWithLogger();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    \n    FileHandle handle \u003d writeCtx.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"do write, fileHandle {} offset: {} length: {} stableHow: {}\",\n          handle.dumpFileHandle(), offset, count, stableHow.name());\n    }\n\n    try {\n      // The write is not protected by lock. asyncState is used to make sure\n      // there is one thread doing write back at any time    \n      writeCtx.writeData(fos);\n      RpcProgramNfs3.metrics.incrBytesWritten(writeCtx.getCount());\n      \n      long flushedOffset \u003d getFlushedOffset();\n      if (flushedOffset !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + flushedOffset + \" and nextOffset should be\"\n            + (offset + count));\n      }\n      \n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n        synchronized (writeCtx) {\n          if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n            writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n            updateNonSequentialWriteInMemory(-count);\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"After writing {} at offset {}, \" +\n                      \"updated the memory count, new value: {}\",\n                  handle.dumpFileHandle(), offset,\n                  nonSequentialWriteInMemory.get());\n            }\n          }\n        }\n      }\n      \n      if (!writeCtx.getReplied()) {\n        if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n          LOG.info(\"Do sync for stable write: {}\", writeCtx);\n          try {\n            if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n              fos.hsync();\n            } else {\n              Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                  \"Unknown WriteStableHow: \" + stableHow);\n              // Sync file data and length\n              fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n            }\n          } catch (IOException e) {\n            LOG.error(\"hsync failed with writeCtx: {}\", writeCtx, e);\n            throw e;\n          }\n        }\n        \n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n          LOG.warn(\"Return original count: {} instead of real data count: {}\",\n              writeCtx.getOriginalCount(), count);\n          count \u003d writeCtx.getOriginalCount();\n        }\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        RpcProgramNfs3.metrics.addWrite(Nfs3Utils.getElapsedTime(writeCtx.startTime));\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n      }\n      \n      // Handle the waiting commits without holding any lock\n      processCommits(writeCtx.getOffset() + writeCtx.getCount());\n     \n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileHandle {} at offset {} and length {}\",\n          handle.dumpFileHandle(), offset, count, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: {}\",\n          latestAttr.getFileId());\n      cleanupWithLogger();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10571. Use Log.*(Object, Throwable) overload to log exceptions.\nContributed by Andras Bokor.\n",
      "commitDate": "14/02/18 8:20 AM",
      "commitName": "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "10/10/17 10:38 AM",
      "commitNameOld": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
      "commitAuthorOld": "Jitendra Pandey",
      "daysBetweenCommits": 126.95,
      "commitsBetweenForRepo": 833,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,94 @@\n   private void doSingleWrite(final WriteCtx writeCtx) {\n     Channel channel \u003d writeCtx.getChannel();\n     int xid \u003d writeCtx.getXid();\n \n     long offset \u003d writeCtx.getOffset();\n     int count \u003d writeCtx.getCount();\n     WriteStableHow stableHow \u003d writeCtx.getStableHow();\n     \n     FileHandle handle \u003d writeCtx.getHandle();\n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"do write, fileHandle \" + handle.dumpFileHandle() + \" offset: \"\n-          + offset + \" length: \" + count + \" stableHow: \" + stableHow.name());\n+      LOG.debug(\"do write, fileHandle {} offset: {} length: {} stableHow: {}\",\n+          handle.dumpFileHandle(), offset, count, stableHow.name());\n     }\n \n     try {\n       // The write is not protected by lock. asyncState is used to make sure\n       // there is one thread doing write back at any time    \n       writeCtx.writeData(fos);\n       RpcProgramNfs3.metrics.incrBytesWritten(writeCtx.getCount());\n       \n       long flushedOffset \u003d getFlushedOffset();\n       if (flushedOffset !\u003d (offset + count)) {\n         throw new IOException(\"output stream is out of sync, pos\u003d\"\n             + flushedOffset + \" and nextOffset should be\"\n             + (offset + count));\n       }\n       \n \n       // Reduce memory occupation size if request was allowed dumped\n       if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n         synchronized (writeCtx) {\n           if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n             writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n             updateNonSequentialWriteInMemory(-count);\n             if (LOG.isDebugEnabled()) {\n-              LOG.debug(\"After writing \" + handle.dumpFileHandle()\n-                  + \" at offset \" + offset\n-                  + \", updated the memory count, new value: \"\n-                  + nonSequentialWriteInMemory.get());\n+              LOG.debug(\"After writing {} at offset {}, \" +\n+                      \"updated the memory count, new value: {}\",\n+                  handle.dumpFileHandle(), offset,\n+                  nonSequentialWriteInMemory.get());\n             }\n           }\n         }\n       }\n       \n       if (!writeCtx.getReplied()) {\n         if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n-          LOG.info(\"Do sync for stable write: \" + writeCtx);\n+          LOG.info(\"Do sync for stable write: {}\", writeCtx);\n           try {\n             if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n               fos.hsync();\n             } else {\n               Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                   \"Unknown WriteStableHow: \" + stableHow);\n               // Sync file data and length\n               fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n             }\n           } catch (IOException e) {\n-            LOG.error(\"hsync failed with writeCtx: \" + writeCtx, e);\n+            LOG.error(\"hsync failed with writeCtx: {}\", writeCtx, e);\n             throw e;\n           }\n         }\n         \n         WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n-          LOG.warn(\"Return original count: \" + writeCtx.getOriginalCount()\n-              + \" instead of real data count: \" + count);\n+          LOG.warn(\"Return original count: {} instead of real data count: {}\",\n+              writeCtx.getOriginalCount(), count);\n           count \u003d writeCtx.getOriginalCount();\n         }\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n         RpcProgramNfs3.metrics.addWrite(Nfs3Utils.getElapsedTime(writeCtx.startTime));\n         Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n       }\n       \n       // Handle the waiting commits without holding any lock\n       processCommits(writeCtx.getOffset() + writeCtx.getCount());\n      \n     } catch (IOException e) {\n-      LOG.error(\"Error writing to fileHandle \" + handle.dumpFileHandle()\n-          + \" at offset \" + offset + \" and length \" + count, e);\n+      LOG.error(\"Error writing to fileHandle {} at offset {} and length {}\",\n+          handle.dumpFileHandle(), offset, count, e);\n       if (!writeCtx.getReplied()) {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n         Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n         // Keep stream open. Either client retries or SteamMonitor closes it.\n       }\n \n-      LOG.info(\"Clean up open file context for fileId: \"\n-          + latestAttr.getFileId());\n+      LOG.info(\"Clean up open file context for fileId: {}\",\n+          latestAttr.getFileId());\n       cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    \n    FileHandle handle \u003d writeCtx.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"do write, fileHandle {} offset: {} length: {} stableHow: {}\",\n          handle.dumpFileHandle(), offset, count, stableHow.name());\n    }\n\n    try {\n      // The write is not protected by lock. asyncState is used to make sure\n      // there is one thread doing write back at any time    \n      writeCtx.writeData(fos);\n      RpcProgramNfs3.metrics.incrBytesWritten(writeCtx.getCount());\n      \n      long flushedOffset \u003d getFlushedOffset();\n      if (flushedOffset !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + flushedOffset + \" and nextOffset should be\"\n            + (offset + count));\n      }\n      \n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n        synchronized (writeCtx) {\n          if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n            writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n            updateNonSequentialWriteInMemory(-count);\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"After writing {} at offset {}, \" +\n                      \"updated the memory count, new value: {}\",\n                  handle.dumpFileHandle(), offset,\n                  nonSequentialWriteInMemory.get());\n            }\n          }\n        }\n      }\n      \n      if (!writeCtx.getReplied()) {\n        if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n          LOG.info(\"Do sync for stable write: {}\", writeCtx);\n          try {\n            if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n              fos.hsync();\n            } else {\n              Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                  \"Unknown WriteStableHow: \" + stableHow);\n              // Sync file data and length\n              fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n            }\n          } catch (IOException e) {\n            LOG.error(\"hsync failed with writeCtx: {}\", writeCtx, e);\n            throw e;\n          }\n        }\n        \n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n          LOG.warn(\"Return original count: {} instead of real data count: {}\",\n              writeCtx.getOriginalCount(), count);\n          count \u003d writeCtx.getOriginalCount();\n        }\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        RpcProgramNfs3.metrics.addWrite(Nfs3Utils.getElapsedTime(writeCtx.startTime));\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n      }\n      \n      // Handle the waiting commits without holding any lock\n      processCommits(writeCtx.getOffset() + writeCtx.getCount());\n     \n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileHandle {} at offset {} and length {}\",\n          handle.dumpFileHandle(), offset, count, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: {}\",\n          latestAttr.getFileId());\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "d6602b5f39833611b4afa4581552f6c4c37e23a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11575. Supporting HDFS NFS gateway with Federated HDFS. Contributed by Mukul Kumar Singh.\n",
      "commitDate": "10/10/17 10:38 AM",
      "commitName": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
      "commitAuthor": "Jitendra Pandey",
      "commitDateOld": "31/05/17 8:09 AM",
      "commitNameOld": "13de636b4079b077890ad10389ff350dcf8086a2",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 132.1,
      "commitsBetweenForRepo": 969,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,93 +1,94 @@\n   private void doSingleWrite(final WriteCtx writeCtx) {\n     Channel channel \u003d writeCtx.getChannel();\n     int xid \u003d writeCtx.getXid();\n \n     long offset \u003d writeCtx.getOffset();\n     int count \u003d writeCtx.getCount();\n     WriteStableHow stableHow \u003d writeCtx.getStableHow();\n     \n     FileHandle handle \u003d writeCtx.getHandle();\n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n+      LOG.debug(\"do write, fileHandle \" + handle.dumpFileHandle() + \" offset: \"\n           + offset + \" length: \" + count + \" stableHow: \" + stableHow.name());\n     }\n \n     try {\n       // The write is not protected by lock. asyncState is used to make sure\n       // there is one thread doing write back at any time    \n       writeCtx.writeData(fos);\n       RpcProgramNfs3.metrics.incrBytesWritten(writeCtx.getCount());\n       \n       long flushedOffset \u003d getFlushedOffset();\n       if (flushedOffset !\u003d (offset + count)) {\n         throw new IOException(\"output stream is out of sync, pos\u003d\"\n             + flushedOffset + \" and nextOffset should be\"\n             + (offset + count));\n       }\n       \n \n       // Reduce memory occupation size if request was allowed dumped\n       if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n         synchronized (writeCtx) {\n           if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n             writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n             updateNonSequentialWriteInMemory(-count);\n             if (LOG.isDebugEnabled()) {\n-              LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n-                  + offset + \", updated the memory count, new value: \"\n+              LOG.debug(\"After writing \" + handle.dumpFileHandle()\n+                  + \" at offset \" + offset\n+                  + \", updated the memory count, new value: \"\n                   + nonSequentialWriteInMemory.get());\n             }\n           }\n         }\n       }\n       \n       if (!writeCtx.getReplied()) {\n         if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n           LOG.info(\"Do sync for stable write: \" + writeCtx);\n           try {\n             if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n               fos.hsync();\n             } else {\n               Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                   \"Unknown WriteStableHow: \" + stableHow);\n               // Sync file data and length\n               fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n             }\n           } catch (IOException e) {\n             LOG.error(\"hsync failed with writeCtx: \" + writeCtx, e);\n             throw e;\n           }\n         }\n         \n         WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n           LOG.warn(\"Return original count: \" + writeCtx.getOriginalCount()\n               + \" instead of real data count: \" + count);\n           count \u003d writeCtx.getOriginalCount();\n         }\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n         RpcProgramNfs3.metrics.addWrite(Nfs3Utils.getElapsedTime(writeCtx.startTime));\n         Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n       }\n       \n       // Handle the waiting commits without holding any lock\n       processCommits(writeCtx.getOffset() + writeCtx.getCount());\n      \n     } catch (IOException e) {\n-      LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n-          + offset + \" and length \" + count, e);\n+      LOG.error(\"Error writing to fileHandle \" + handle.dumpFileHandle()\n+          + \" at offset \" + offset + \" and length \" + count, e);\n       if (!writeCtx.getReplied()) {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n         Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n         // Keep stream open. Either client retries or SteamMonitor closes it.\n       }\n \n       LOG.info(\"Clean up open file context for fileId: \"\n           + latestAttr.getFileId());\n       cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    \n    FileHandle handle \u003d writeCtx.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"do write, fileHandle \" + handle.dumpFileHandle() + \" offset: \"\n          + offset + \" length: \" + count + \" stableHow: \" + stableHow.name());\n    }\n\n    try {\n      // The write is not protected by lock. asyncState is used to make sure\n      // there is one thread doing write back at any time    \n      writeCtx.writeData(fos);\n      RpcProgramNfs3.metrics.incrBytesWritten(writeCtx.getCount());\n      \n      long flushedOffset \u003d getFlushedOffset();\n      if (flushedOffset !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + flushedOffset + \" and nextOffset should be\"\n            + (offset + count));\n      }\n      \n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n        synchronized (writeCtx) {\n          if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n            writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n            updateNonSequentialWriteInMemory(-count);\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"After writing \" + handle.dumpFileHandle()\n                  + \" at offset \" + offset\n                  + \", updated the memory count, new value: \"\n                  + nonSequentialWriteInMemory.get());\n            }\n          }\n        }\n      }\n      \n      if (!writeCtx.getReplied()) {\n        if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n          LOG.info(\"Do sync for stable write: \" + writeCtx);\n          try {\n            if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n              fos.hsync();\n            } else {\n              Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                  \"Unknown WriteStableHow: \" + stableHow);\n              // Sync file data and length\n              fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n            }\n          } catch (IOException e) {\n            LOG.error(\"hsync failed with writeCtx: \" + writeCtx, e);\n            throw e;\n          }\n        }\n        \n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n          LOG.warn(\"Return original count: \" + writeCtx.getOriginalCount()\n              + \" instead of real data count: \" + count);\n          count \u003d writeCtx.getOriginalCount();\n        }\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        RpcProgramNfs3.metrics.addWrite(Nfs3Utils.getElapsedTime(writeCtx.startTime));\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n      }\n      \n      // Handle the waiting commits without holding any lock\n      processCommits(writeCtx.getOffset() + writeCtx.getCount());\n     \n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileHandle \" + handle.dumpFileHandle()\n          + \" at offset \" + offset + \" and length \" + count, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: \"\n          + latestAttr.getFileId());\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7423. various typos and message formatting fixes in nfs daemon and doc. (Charles Lamb via yliu)\n",
      "commitDate": "28/01/15 12:56 PM",
      "commitName": "f37849188b05a6251584de1aed5e66d5dfa7da4f",
      "commitAuthor": "yliu",
      "commitDateOld": "11/12/14 3:40 PM",
      "commitNameOld": "f6f2a3f1c73266bfedd802eacde60d8b19b81015",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 47.89,
      "commitsBetweenForRepo": 279,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,93 +1,93 @@\n   private void doSingleWrite(final WriteCtx writeCtx) {\n     Channel channel \u003d writeCtx.getChannel();\n     int xid \u003d writeCtx.getXid();\n \n     long offset \u003d writeCtx.getOffset();\n     int count \u003d writeCtx.getCount();\n     WriteStableHow stableHow \u003d writeCtx.getStableHow();\n     \n     FileHandle handle \u003d writeCtx.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n-          + offset + \" length:\" + count + \" stableHow:\" + stableHow.name());\n+          + offset + \" length: \" + count + \" stableHow: \" + stableHow.name());\n     }\n \n     try {\n       // The write is not protected by lock. asyncState is used to make sure\n       // there is one thread doing write back at any time    \n       writeCtx.writeData(fos);\n       RpcProgramNfs3.metrics.incrBytesWritten(writeCtx.getCount());\n       \n       long flushedOffset \u003d getFlushedOffset();\n       if (flushedOffset !\u003d (offset + count)) {\n         throw new IOException(\"output stream is out of sync, pos\u003d\"\n             + flushedOffset + \" and nextOffset should be\"\n             + (offset + count));\n       }\n       \n \n       // Reduce memory occupation size if request was allowed dumped\n       if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n         synchronized (writeCtx) {\n           if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n             writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n             updateNonSequentialWriteInMemory(-count);\n             if (LOG.isDebugEnabled()) {\n               LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n-                  + offset + \", updated the memory count, new value:\"\n+                  + offset + \", updated the memory count, new value: \"\n                   + nonSequentialWriteInMemory.get());\n             }\n           }\n         }\n       }\n       \n       if (!writeCtx.getReplied()) {\n         if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n-          LOG.info(\"Do sync for stable write:\" + writeCtx);\n+          LOG.info(\"Do sync for stable write: \" + writeCtx);\n           try {\n             if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n               fos.hsync();\n             } else {\n               Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n-                  \"Unknown WriteStableHow:\" + stableHow);\n+                  \"Unknown WriteStableHow: \" + stableHow);\n               // Sync file data and length\n               fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n             }\n           } catch (IOException e) {\n-            LOG.error(\"hsync failed with writeCtx:\" + writeCtx, e);\n+            LOG.error(\"hsync failed with writeCtx: \" + writeCtx, e);\n             throw e;\n           }\n         }\n         \n         WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n-          LOG.warn(\"Return original count:\" + writeCtx.getOriginalCount()\n-              + \" instead of real data count:\" + count);\n+          LOG.warn(\"Return original count: \" + writeCtx.getOriginalCount()\n+              + \" instead of real data count: \" + count);\n           count \u003d writeCtx.getOriginalCount();\n         }\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n         RpcProgramNfs3.metrics.addWrite(Nfs3Utils.getElapsedTime(writeCtx.startTime));\n         Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n       }\n       \n       // Handle the waiting commits without holding any lock\n       processCommits(writeCtx.getOffset() + writeCtx.getCount());\n      \n     } catch (IOException e) {\n       LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n           + offset + \" and length \" + count, e);\n       if (!writeCtx.getReplied()) {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n         Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n         // Keep stream open. Either client retries or SteamMonitor closes it.\n       }\n \n       LOG.info(\"Clean up open file context for fileId: \"\n           + latestAttr.getFileId());\n       cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    \n    FileHandle handle \u003d writeCtx.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n          + offset + \" length: \" + count + \" stableHow: \" + stableHow.name());\n    }\n\n    try {\n      // The write is not protected by lock. asyncState is used to make sure\n      // there is one thread doing write back at any time    \n      writeCtx.writeData(fos);\n      RpcProgramNfs3.metrics.incrBytesWritten(writeCtx.getCount());\n      \n      long flushedOffset \u003d getFlushedOffset();\n      if (flushedOffset !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + flushedOffset + \" and nextOffset should be\"\n            + (offset + count));\n      }\n      \n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n        synchronized (writeCtx) {\n          if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n            writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n            updateNonSequentialWriteInMemory(-count);\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n                  + offset + \", updated the memory count, new value: \"\n                  + nonSequentialWriteInMemory.get());\n            }\n          }\n        }\n      }\n      \n      if (!writeCtx.getReplied()) {\n        if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n          LOG.info(\"Do sync for stable write: \" + writeCtx);\n          try {\n            if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n              fos.hsync();\n            } else {\n              Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                  \"Unknown WriteStableHow: \" + stableHow);\n              // Sync file data and length\n              fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n            }\n          } catch (IOException e) {\n            LOG.error(\"hsync failed with writeCtx: \" + writeCtx, e);\n            throw e;\n          }\n        }\n        \n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n          LOG.warn(\"Return original count: \" + writeCtx.getOriginalCount()\n              + \" instead of real data count: \" + count);\n          count \u003d writeCtx.getOriginalCount();\n        }\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        RpcProgramNfs3.metrics.addWrite(Nfs3Utils.getElapsedTime(writeCtx.startTime));\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n      }\n      \n      // Handle the waiting commits without holding any lock\n      processCommits(writeCtx.getOffset() + writeCtx.getCount());\n     \n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n          + offset + \" and length \" + count, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: \"\n          + latestAttr.getFileId());\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "f6f2a3f1c73266bfedd802eacde60d8b19b81015": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7449. Add metrics to NFS gateway. Contributed by Brandon Li\n",
      "commitDate": "11/12/14 3:40 PM",
      "commitName": "f6f2a3f1c73266bfedd802eacde60d8b19b81015",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "11/11/14 1:03 PM",
      "commitNameOld": "99d9d0c2d19b9f161b765947f3fb64619ea58090",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 30.11,
      "commitsBetweenForRepo": 214,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,91 +1,93 @@\n   private void doSingleWrite(final WriteCtx writeCtx) {\n     Channel channel \u003d writeCtx.getChannel();\n     int xid \u003d writeCtx.getXid();\n \n     long offset \u003d writeCtx.getOffset();\n     int count \u003d writeCtx.getCount();\n     WriteStableHow stableHow \u003d writeCtx.getStableHow();\n     \n     FileHandle handle \u003d writeCtx.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n           + offset + \" length:\" + count + \" stableHow:\" + stableHow.name());\n     }\n \n     try {\n       // The write is not protected by lock. asyncState is used to make sure\n       // there is one thread doing write back at any time    \n       writeCtx.writeData(fos);\n+      RpcProgramNfs3.metrics.incrBytesWritten(writeCtx.getCount());\n       \n       long flushedOffset \u003d getFlushedOffset();\n       if (flushedOffset !\u003d (offset + count)) {\n         throw new IOException(\"output stream is out of sync, pos\u003d\"\n             + flushedOffset + \" and nextOffset should be\"\n             + (offset + count));\n       }\n       \n \n       // Reduce memory occupation size if request was allowed dumped\n       if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n         synchronized (writeCtx) {\n           if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n             writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n             updateNonSequentialWriteInMemory(-count);\n             if (LOG.isDebugEnabled()) {\n               LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n                   + offset + \", updated the memory count, new value:\"\n                   + nonSequentialWriteInMemory.get());\n             }\n           }\n         }\n       }\n       \n       if (!writeCtx.getReplied()) {\n         if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n           LOG.info(\"Do sync for stable write:\" + writeCtx);\n           try {\n             if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n               fos.hsync();\n             } else {\n               Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                   \"Unknown WriteStableHow:\" + stableHow);\n               // Sync file data and length\n               fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n             }\n           } catch (IOException e) {\n             LOG.error(\"hsync failed with writeCtx:\" + writeCtx, e);\n             throw e;\n           }\n         }\n         \n         WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n           LOG.warn(\"Return original count:\" + writeCtx.getOriginalCount()\n               + \" instead of real data count:\" + count);\n           count \u003d writeCtx.getOriginalCount();\n         }\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n+        RpcProgramNfs3.metrics.addWrite(Nfs3Utils.getElapsedTime(writeCtx.startTime));\n         Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n       }\n       \n       // Handle the waiting commits without holding any lock\n       processCommits(writeCtx.getOffset() + writeCtx.getCount());\n      \n     } catch (IOException e) {\n       LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n           + offset + \" and length \" + count, e);\n       if (!writeCtx.getReplied()) {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n         Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n         // Keep stream open. Either client retries or SteamMonitor closes it.\n       }\n \n       LOG.info(\"Clean up open file context for fileId: \"\n           + latestAttr.getFileId());\n       cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    \n    FileHandle handle \u003d writeCtx.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n          + offset + \" length:\" + count + \" stableHow:\" + stableHow.name());\n    }\n\n    try {\n      // The write is not protected by lock. asyncState is used to make sure\n      // there is one thread doing write back at any time    \n      writeCtx.writeData(fos);\n      RpcProgramNfs3.metrics.incrBytesWritten(writeCtx.getCount());\n      \n      long flushedOffset \u003d getFlushedOffset();\n      if (flushedOffset !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + flushedOffset + \" and nextOffset should be\"\n            + (offset + count));\n      }\n      \n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n        synchronized (writeCtx) {\n          if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n            writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n            updateNonSequentialWriteInMemory(-count);\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n                  + offset + \", updated the memory count, new value:\"\n                  + nonSequentialWriteInMemory.get());\n            }\n          }\n        }\n      }\n      \n      if (!writeCtx.getReplied()) {\n        if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n          LOG.info(\"Do sync for stable write:\" + writeCtx);\n          try {\n            if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n              fos.hsync();\n            } else {\n              Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                  \"Unknown WriteStableHow:\" + stableHow);\n              // Sync file data and length\n              fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n            }\n          } catch (IOException e) {\n            LOG.error(\"hsync failed with writeCtx:\" + writeCtx, e);\n            throw e;\n          }\n        }\n        \n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n          LOG.warn(\"Return original count:\" + writeCtx.getOriginalCount()\n              + \" instead of real data count:\" + count);\n          count \u003d writeCtx.getOriginalCount();\n        }\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        RpcProgramNfs3.metrics.addWrite(Nfs3Utils.getElapsedTime(writeCtx.startTime));\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n      }\n      \n      // Handle the waiting commits without holding any lock\n      processCommits(writeCtx.getOffset() + writeCtx.getCount());\n     \n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n          + offset + \" and length \" + count, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: \"\n          + latestAttr.getFileId());\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "875aa797caee96572162ff59bc50cf97d1195348": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6894. Add XDR parser method for each NFS response. Contributed by Brandon Li.\n",
      "commitDate": "01/10/14 1:18 PM",
      "commitName": "875aa797caee96572162ff59bc50cf97d1195348",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "18/09/14 2:57 PM",
      "commitNameOld": "70be56d093022de9953e14a92dfa1a146bd9a290",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 12.93,
      "commitsBetweenForRepo": 154,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,91 +1,91 @@\n   private void doSingleWrite(final WriteCtx writeCtx) {\n     Channel channel \u003d writeCtx.getChannel();\n     int xid \u003d writeCtx.getXid();\n \n     long offset \u003d writeCtx.getOffset();\n     int count \u003d writeCtx.getCount();\n     WriteStableHow stableHow \u003d writeCtx.getStableHow();\n     \n     FileHandle handle \u003d writeCtx.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n           + offset + \" length:\" + count + \" stableHow:\" + stableHow.name());\n     }\n \n     try {\n       // The write is not protected by lock. asyncState is used to make sure\n       // there is one thread doing write back at any time    \n       writeCtx.writeData(fos);\n       \n       long flushedOffset \u003d getFlushedOffset();\n       if (flushedOffset !\u003d (offset + count)) {\n         throw new IOException(\"output stream is out of sync, pos\u003d\"\n             + flushedOffset + \" and nextOffset should be\"\n             + (offset + count));\n       }\n       \n \n       // Reduce memory occupation size if request was allowed dumped\n       if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n         synchronized (writeCtx) {\n           if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n             writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n             updateNonSequentialWriteInMemory(-count);\n             if (LOG.isDebugEnabled()) {\n               LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n                   + offset + \", updated the memory count, new value:\"\n                   + nonSequentialWriteInMemory.get());\n             }\n           }\n         }\n       }\n       \n       if (!writeCtx.getReplied()) {\n         if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n           LOG.info(\"Do sync for stable write:\" + writeCtx);\n           try {\n             if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n               fos.hsync();\n             } else {\n               Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                   \"Unknown WriteStableHow:\" + stableHow);\n               // Sync file data and length\n               fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n             }\n           } catch (IOException e) {\n             LOG.error(\"hsync failed with writeCtx:\" + writeCtx, e);\n             throw e;\n           }\n         }\n         \n         WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n           LOG.warn(\"Return original count:\" + writeCtx.getOriginalCount()\n               + \" instead of real data count:\" + count);\n           count \u003d writeCtx.getOriginalCount();\n         }\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n-        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n+        Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n       }\n       \n       // Handle the waiting commits without holding any lock\n       processCommits(writeCtx.getOffset() + writeCtx.getCount());\n      \n     } catch (IOException e) {\n       LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n           + offset + \" and length \" + count, e);\n       if (!writeCtx.getReplied()) {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n-        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n+        Nfs3Utils.writeChannel(channel, response.serialize(\n             new XDR(), xid, new VerifierNone()), xid);\n         // Keep stream open. Either client retries or SteamMonitor closes it.\n       }\n \n       LOG.info(\"Clean up open file context for fileId: \"\n           + latestAttr.getFileId());\n       cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    \n    FileHandle handle \u003d writeCtx.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n          + offset + \" length:\" + count + \" stableHow:\" + stableHow.name());\n    }\n\n    try {\n      // The write is not protected by lock. asyncState is used to make sure\n      // there is one thread doing write back at any time    \n      writeCtx.writeData(fos);\n      \n      long flushedOffset \u003d getFlushedOffset();\n      if (flushedOffset !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + flushedOffset + \" and nextOffset should be\"\n            + (offset + count));\n      }\n      \n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n        synchronized (writeCtx) {\n          if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n            writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n            updateNonSequentialWriteInMemory(-count);\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n                  + offset + \", updated the memory count, new value:\"\n                  + nonSequentialWriteInMemory.get());\n            }\n          }\n        }\n      }\n      \n      if (!writeCtx.getReplied()) {\n        if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n          LOG.info(\"Do sync for stable write:\" + writeCtx);\n          try {\n            if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n              fos.hsync();\n            } else {\n              Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                  \"Unknown WriteStableHow:\" + stableHow);\n              // Sync file data and length\n              fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n            }\n          } catch (IOException e) {\n            LOG.error(\"hsync failed with writeCtx:\" + writeCtx, e);\n            throw e;\n          }\n        }\n        \n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n          LOG.warn(\"Return original count:\" + writeCtx.getOriginalCount()\n              + \" instead of real data count:\" + count);\n          count \u003d writeCtx.getOriginalCount();\n        }\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n      }\n      \n      // Handle the waiting commits without holding any lock\n      processCommits(writeCtx.getOffset() + writeCtx.getCount());\n     \n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n          + offset + \" and length \" + count, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.serialize(\n            new XDR(), xid, new VerifierNone()), xid);\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: \"\n          + latestAttr.getFileId());\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "3bfd18c6b0483ae27eff6d53bda934e67dda5464": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6050. NFS does not handle exceptions correctly in a few places. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1581055 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/03/14 1:49 PM",
      "commitName": "3bfd18c6b0483ae27eff6d53bda934e67dda5464",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "17/12/13 12:40 PM",
      "commitNameOld": "5792d59da390842caec86ccaa8472d5be7933837",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 97.01,
      "commitsBetweenForRepo": 719,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,91 +1,91 @@\n   private void doSingleWrite(final WriteCtx writeCtx) {\n     Channel channel \u003d writeCtx.getChannel();\n     int xid \u003d writeCtx.getXid();\n \n     long offset \u003d writeCtx.getOffset();\n     int count \u003d writeCtx.getCount();\n     WriteStableHow stableHow \u003d writeCtx.getStableHow();\n     \n     FileHandle handle \u003d writeCtx.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n           + offset + \" length:\" + count + \" stableHow:\" + stableHow.name());\n     }\n \n     try {\n       // The write is not protected by lock. asyncState is used to make sure\n       // there is one thread doing write back at any time    \n       writeCtx.writeData(fos);\n       \n       long flushedOffset \u003d getFlushedOffset();\n       if (flushedOffset !\u003d (offset + count)) {\n         throw new IOException(\"output stream is out of sync, pos\u003d\"\n             + flushedOffset + \" and nextOffset should be\"\n             + (offset + count));\n       }\n       \n \n       // Reduce memory occupation size if request was allowed dumped\n       if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n         synchronized (writeCtx) {\n           if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n             writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n             updateNonSequentialWriteInMemory(-count);\n             if (LOG.isDebugEnabled()) {\n               LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n                   + offset + \", updated the memory count, new value:\"\n                   + nonSequentialWriteInMemory.get());\n             }\n           }\n         }\n       }\n       \n       if (!writeCtx.getReplied()) {\n         if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n           LOG.info(\"Do sync for stable write:\" + writeCtx);\n           try {\n             if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n               fos.hsync();\n             } else {\n               Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                   \"Unknown WriteStableHow:\" + stableHow);\n               // Sync file data and length\n               fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n             }\n           } catch (IOException e) {\n-            LOG.error(\"hsync failed with writeCtx:\" + writeCtx + \" error:\" + e);\n+            LOG.error(\"hsync failed with writeCtx:\" + writeCtx, e);\n             throw e;\n           }\n         }\n         \n         WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n           LOG.warn(\"Return original count:\" + writeCtx.getOriginalCount()\n               + \" instead of real data count:\" + count);\n           count \u003d writeCtx.getOriginalCount();\n         }\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n             new XDR(), xid, new VerifierNone()), xid);\n       }\n       \n       // Handle the waiting commits without holding any lock\n       processCommits(writeCtx.getOffset() + writeCtx.getCount());\n      \n     } catch (IOException e) {\n       LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n           + offset + \" and length \" + count, e);\n       if (!writeCtx.getReplied()) {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n         Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n             new XDR(), xid, new VerifierNone()), xid);\n         // Keep stream open. Either client retries or SteamMonitor closes it.\n       }\n \n       LOG.info(\"Clean up open file context for fileId: \"\n-          + latestAttr.getFileid());\n+          + latestAttr.getFileId());\n       cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    \n    FileHandle handle \u003d writeCtx.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n          + offset + \" length:\" + count + \" stableHow:\" + stableHow.name());\n    }\n\n    try {\n      // The write is not protected by lock. asyncState is used to make sure\n      // there is one thread doing write back at any time    \n      writeCtx.writeData(fos);\n      \n      long flushedOffset \u003d getFlushedOffset();\n      if (flushedOffset !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + flushedOffset + \" and nextOffset should be\"\n            + (offset + count));\n      }\n      \n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n        synchronized (writeCtx) {\n          if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n            writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n            updateNonSequentialWriteInMemory(-count);\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n                  + offset + \", updated the memory count, new value:\"\n                  + nonSequentialWriteInMemory.get());\n            }\n          }\n        }\n      }\n      \n      if (!writeCtx.getReplied()) {\n        if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n          LOG.info(\"Do sync for stable write:\" + writeCtx);\n          try {\n            if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n              fos.hsync();\n            } else {\n              Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                  \"Unknown WriteStableHow:\" + stableHow);\n              // Sync file data and length\n              fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n            }\n          } catch (IOException e) {\n            LOG.error(\"hsync failed with writeCtx:\" + writeCtx, e);\n            throw e;\n          }\n        }\n        \n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n          LOG.warn(\"Return original count:\" + writeCtx.getOriginalCount()\n              + \" instead of real data count:\" + count);\n          count \u003d writeCtx.getOriginalCount();\n        }\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n      }\n      \n      // Handle the waiting commits without holding any lock\n      processCommits(writeCtx.getOffset() + writeCtx.getCount());\n     \n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n          + offset + \" and length \" + count, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: \"\n          + latestAttr.getFileId());\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "3fccdec6e0a8e9305fc75921211c3745eddb9c45": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5364. Add OpenFileCtx cache. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1539834 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/11/13 1:49 PM",
      "commitName": "3fccdec6e0a8e9305fc75921211c3745eddb9c45",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "07/11/13 10:02 AM",
      "commitNameOld": "16c6755554cc5ecd9d4e0ba74b75b10c74bb0ab4",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 0.16,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,91 +1,91 @@\n   private void doSingleWrite(final WriteCtx writeCtx) {\n     Channel channel \u003d writeCtx.getChannel();\n     int xid \u003d writeCtx.getXid();\n \n     long offset \u003d writeCtx.getOffset();\n     int count \u003d writeCtx.getCount();\n     WriteStableHow stableHow \u003d writeCtx.getStableHow();\n     \n     FileHandle handle \u003d writeCtx.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n-          + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n+          + offset + \" length:\" + count + \" stableHow:\" + stableHow.name());\n     }\n \n     try {\n       // The write is not protected by lock. asyncState is used to make sure\n       // there is one thread doing write back at any time    \n       writeCtx.writeData(fos);\n       \n       long flushedOffset \u003d getFlushedOffset();\n       if (flushedOffset !\u003d (offset + count)) {\n         throw new IOException(\"output stream is out of sync, pos\u003d\"\n             + flushedOffset + \" and nextOffset should be\"\n             + (offset + count));\n       }\n       \n \n       // Reduce memory occupation size if request was allowed dumped\n       if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n         synchronized (writeCtx) {\n           if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n             writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n             updateNonSequentialWriteInMemory(-count);\n             if (LOG.isDebugEnabled()) {\n               LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n                   + offset + \", updated the memory count, new value:\"\n                   + nonSequentialWriteInMemory.get());\n             }\n           }\n         }\n       }\n       \n       if (!writeCtx.getReplied()) {\n         if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n           LOG.info(\"Do sync for stable write:\" + writeCtx);\n           try {\n             if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n               fos.hsync();\n             } else {\n               Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                   \"Unknown WriteStableHow:\" + stableHow);\n               // Sync file data and length\n               fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n             }\n           } catch (IOException e) {\n             LOG.error(\"hsync failed with writeCtx:\" + writeCtx + \" error:\" + e);\n             throw e;\n           }\n         }\n         \n         WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n           LOG.warn(\"Return original count:\" + writeCtx.getOriginalCount()\n               + \" instead of real data count:\" + count);\n           count \u003d writeCtx.getOriginalCount();\n         }\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n             new XDR(), xid, new VerifierNone()), xid);\n       }\n       \n       // Handle the waiting commits without holding any lock\n       processCommits(writeCtx.getOffset() + writeCtx.getCount());\n      \n     } catch (IOException e) {\n       LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n           + offset + \" and length \" + count, e);\n       if (!writeCtx.getReplied()) {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n         Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n             new XDR(), xid, new VerifierNone()), xid);\n         // Keep stream open. Either client retries or SteamMonitor closes it.\n       }\n \n       LOG.info(\"Clean up open file context for fileId: \"\n           + latestAttr.getFileid());\n       cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    \n    FileHandle handle \u003d writeCtx.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n          + offset + \" length:\" + count + \" stableHow:\" + stableHow.name());\n    }\n\n    try {\n      // The write is not protected by lock. asyncState is used to make sure\n      // there is one thread doing write back at any time    \n      writeCtx.writeData(fos);\n      \n      long flushedOffset \u003d getFlushedOffset();\n      if (flushedOffset !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + flushedOffset + \" and nextOffset should be\"\n            + (offset + count));\n      }\n      \n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n        synchronized (writeCtx) {\n          if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n            writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n            updateNonSequentialWriteInMemory(-count);\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n                  + offset + \", updated the memory count, new value:\"\n                  + nonSequentialWriteInMemory.get());\n            }\n          }\n        }\n      }\n      \n      if (!writeCtx.getReplied()) {\n        if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n          LOG.info(\"Do sync for stable write:\" + writeCtx);\n          try {\n            if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n              fos.hsync();\n            } else {\n              Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                  \"Unknown WriteStableHow:\" + stableHow);\n              // Sync file data and length\n              fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n            }\n          } catch (IOException e) {\n            LOG.error(\"hsync failed with writeCtx:\" + writeCtx + \" error:\" + e);\n            throw e;\n          }\n        }\n        \n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n          LOG.warn(\"Return original count:\" + writeCtx.getOriginalCount()\n              + \" instead of real data count:\" + count);\n          count \u003d writeCtx.getOriginalCount();\n        }\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n      }\n      \n      // Handle the waiting commits without holding any lock\n      processCommits(writeCtx.getOffset() + writeCtx.getCount());\n     \n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n          + offset + \" and length \" + count, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: \"\n          + latestAttr.getFileid());\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "16c6755554cc5ecd9d4e0ba74b75b10c74bb0ab4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5252. Stable write is not handled correctly in someplace. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1539740 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/11/13 10:02 AM",
      "commitName": "16c6755554cc5ecd9d4e0ba74b75b10c74bb0ab4",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "09/10/13 5:52 PM",
      "commitNameOld": "7429debd866b3ebf41b9aae4a602b240a8387b2b",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 28.72,
      "commitsBetweenForRepo": 151,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,74 +1,91 @@\n   private void doSingleWrite(final WriteCtx writeCtx) {\n     Channel channel \u003d writeCtx.getChannel();\n     int xid \u003d writeCtx.getXid();\n \n     long offset \u003d writeCtx.getOffset();\n     int count \u003d writeCtx.getCount();\n     WriteStableHow stableHow \u003d writeCtx.getStableHow();\n     \n     FileHandle handle \u003d writeCtx.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n           + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n     }\n \n     try {\n       // The write is not protected by lock. asyncState is used to make sure\n       // there is one thread doing write back at any time    \n       writeCtx.writeData(fos);\n       \n       long flushedOffset \u003d getFlushedOffset();\n       if (flushedOffset !\u003d (offset + count)) {\n         throw new IOException(\"output stream is out of sync, pos\u003d\"\n             + flushedOffset + \" and nextOffset should be\"\n             + (offset + count));\n       }\n       \n \n       // Reduce memory occupation size if request was allowed dumped\n       if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n         synchronized (writeCtx) {\n           if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n             writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n             updateNonSequentialWriteInMemory(-count);\n             if (LOG.isDebugEnabled()) {\n               LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n                   + offset + \", updated the memory count, new value:\"\n                   + nonSequentialWriteInMemory.get());\n             }\n           }\n         }\n       }\n       \n       if (!writeCtx.getReplied()) {\n+        if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n+          LOG.info(\"Do sync for stable write:\" + writeCtx);\n+          try {\n+            if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n+              fos.hsync();\n+            } else {\n+              Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n+                  \"Unknown WriteStableHow:\" + stableHow);\n+              // Sync file data and length\n+              fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n+            }\n+          } catch (IOException e) {\n+            LOG.error(\"hsync failed with writeCtx:\" + writeCtx + \" error:\" + e);\n+            throw e;\n+          }\n+        }\n+        \n         WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n           LOG.warn(\"Return original count:\" + writeCtx.getOriginalCount()\n               + \" instead of real data count:\" + count);\n           count \u003d writeCtx.getOriginalCount();\n         }\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n             new XDR(), xid, new VerifierNone()), xid);\n       }\n       \n       // Handle the waiting commits without holding any lock\n       processCommits(writeCtx.getOffset() + writeCtx.getCount());\n      \n     } catch (IOException e) {\n       LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n           + offset + \" and length \" + count, e);\n       if (!writeCtx.getReplied()) {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n         Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n             new XDR(), xid, new VerifierNone()), xid);\n         // Keep stream open. Either client retries or SteamMonitor closes it.\n       }\n \n       LOG.info(\"Clean up open file context for fileId: \"\n           + latestAttr.getFileid());\n       cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    \n    FileHandle handle \u003d writeCtx.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n          + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n    }\n\n    try {\n      // The write is not protected by lock. asyncState is used to make sure\n      // there is one thread doing write back at any time    \n      writeCtx.writeData(fos);\n      \n      long flushedOffset \u003d getFlushedOffset();\n      if (flushedOffset !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + flushedOffset + \" and nextOffset should be\"\n            + (offset + count));\n      }\n      \n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n        synchronized (writeCtx) {\n          if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n            writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n            updateNonSequentialWriteInMemory(-count);\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n                  + offset + \", updated the memory count, new value:\"\n                  + nonSequentialWriteInMemory.get());\n            }\n          }\n        }\n      }\n      \n      if (!writeCtx.getReplied()) {\n        if (stableHow !\u003d WriteStableHow.UNSTABLE) {\n          LOG.info(\"Do sync for stable write:\" + writeCtx);\n          try {\n            if (stableHow \u003d\u003d WriteStableHow.DATA_SYNC) {\n              fos.hsync();\n            } else {\n              Preconditions.checkState(stableHow \u003d\u003d WriteStableHow.FILE_SYNC,\n                  \"Unknown WriteStableHow:\" + stableHow);\n              // Sync file data and length\n              fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n            }\n          } catch (IOException e) {\n            LOG.error(\"hsync failed with writeCtx:\" + writeCtx + \" error:\" + e);\n            throw e;\n          }\n        }\n        \n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n          LOG.warn(\"Return original count:\" + writeCtx.getOriginalCount()\n              + \" instead of real data count:\" + count);\n          count \u003d writeCtx.getOriginalCount();\n        }\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n      }\n      \n      // Handle the waiting commits without holding any lock\n      processCommits(writeCtx.getOffset() + writeCtx.getCount());\n     \n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n          + offset + \" and length \" + count, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: \"\n          + latestAttr.getFileid());\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "5c02d2f6225144772dcb975d3144b057b71d6476": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5281. COMMIT request should not block. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1530461 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/10/13 4:40 PM",
      "commitName": "5c02d2f6225144772dcb975d3144b057b71d6476",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "06/10/13 7:57 PM",
      "commitNameOld": "caa4abd30cfc4361c7bc9f212a9092840d7c3b53",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 1.86,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,74 @@\n   private void doSingleWrite(final WriteCtx writeCtx) {\n     Channel channel \u003d writeCtx.getChannel();\n     int xid \u003d writeCtx.getXid();\n \n     long offset \u003d writeCtx.getOffset();\n     int count \u003d writeCtx.getCount();\n     WriteStableHow stableHow \u003d writeCtx.getStableHow();\n     \n     FileHandle handle \u003d writeCtx.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n           + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n     }\n \n     try {\n       // The write is not protected by lock. asyncState is used to make sure\n       // there is one thread doing write back at any time    \n       writeCtx.writeData(fos);\n       \n       long flushedOffset \u003d getFlushedOffset();\n       if (flushedOffset !\u003d (offset + count)) {\n         throw new IOException(\"output stream is out of sync, pos\u003d\"\n             + flushedOffset + \" and nextOffset should be\"\n             + (offset + count));\n       }\n       \n \n       // Reduce memory occupation size if request was allowed dumped\n       if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n         synchronized (writeCtx) {\n           if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n             writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n             updateNonSequentialWriteInMemory(-count);\n             if (LOG.isDebugEnabled()) {\n               LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n                   + offset + \", updated the memory count, new value:\"\n                   + nonSequentialWriteInMemory.get());\n             }\n           }\n         }\n       }\n       \n       if (!writeCtx.getReplied()) {\n         WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n           LOG.warn(\"Return original count:\" + writeCtx.getOriginalCount()\n               + \" instead of real data count:\" + count);\n           count \u003d writeCtx.getOriginalCount();\n         }\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n             new XDR(), xid, new VerifierNone()), xid);\n       }\n+      \n+      // Handle the waiting commits without holding any lock\n+      processCommits(writeCtx.getOffset() + writeCtx.getCount());\n+     \n     } catch (IOException e) {\n       LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n           + offset + \" and length \" + count, e);\n       if (!writeCtx.getReplied()) {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n         Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n             new XDR(), xid, new VerifierNone()), xid);\n         // Keep stream open. Either client retries or SteamMonitor closes it.\n       }\n \n       LOG.info(\"Clean up open file context for fileId: \"\n           + latestAttr.getFileid());\n       cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    \n    FileHandle handle \u003d writeCtx.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n          + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n    }\n\n    try {\n      // The write is not protected by lock. asyncState is used to make sure\n      // there is one thread doing write back at any time    \n      writeCtx.writeData(fos);\n      \n      long flushedOffset \u003d getFlushedOffset();\n      if (flushedOffset !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + flushedOffset + \" and nextOffset should be\"\n            + (offset + count));\n      }\n      \n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n        synchronized (writeCtx) {\n          if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n            writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n            updateNonSequentialWriteInMemory(-count);\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n                  + offset + \", updated the memory count, new value:\"\n                  + nonSequentialWriteInMemory.get());\n            }\n          }\n        }\n      }\n      \n      if (!writeCtx.getReplied()) {\n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n          LOG.warn(\"Return original count:\" + writeCtx.getOriginalCount()\n              + \" instead of real data count:\" + count);\n          count \u003d writeCtx.getOriginalCount();\n        }\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n      }\n      \n      // Handle the waiting commits without holding any lock\n      processCommits(writeCtx.getOffset() + writeCtx.getCount());\n     \n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n          + offset + \" and length \" + count, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: \"\n          + latestAttr.getFileid());\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "caa4abd30cfc4361c7bc9f212a9092840d7c3b53": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5259. Support client which combines appended data with old data before sends it to NFS server. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1529730 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/10/13 7:57 PM",
      "commitName": "caa4abd30cfc4361c7bc9f212a9092840d7c3b53",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "27/09/13 2:28 PM",
      "commitNameOld": "027419832c1125d707b45ce852032d704ab79d88",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 9.23,
      "commitsBetweenForRepo": 77,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,70 @@\n   private void doSingleWrite(final WriteCtx writeCtx) {\n     Channel channel \u003d writeCtx.getChannel();\n     int xid \u003d writeCtx.getXid();\n \n     long offset \u003d writeCtx.getOffset();\n     int count \u003d writeCtx.getCount();\n     WriteStableHow stableHow \u003d writeCtx.getStableHow();\n-    byte[] data \u003d null;\n-    try {\n-      data \u003d writeCtx.getData();\n-    } catch (Exception e1) {\n-      LOG.error(\"Failed to get request data offset:\" + offset + \" count:\"\n-          + count + \" error:\" + e1);\n-      // Cleanup everything\n-      cleanup();\n-      return;\n-    }\n     \n-    Preconditions.checkState(data.length \u003d\u003d count);\n-\n     FileHandle handle \u003d writeCtx.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n           + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n     }\n \n     try {\n       // The write is not protected by lock. asyncState is used to make sure\n-      // there is one thread doing write back at any time\n-      fos.write(data, 0, count);\n+      // there is one thread doing write back at any time    \n+      writeCtx.writeData(fos);\n       \n       long flushedOffset \u003d getFlushedOffset();\n       if (flushedOffset !\u003d (offset + count)) {\n         throw new IOException(\"output stream is out of sync, pos\u003d\"\n             + flushedOffset + \" and nextOffset should be\"\n             + (offset + count));\n       }\n       \n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n-            + offset + \", update the memory count.\");\n-      }\n \n       // Reduce memory occupation size if request was allowed dumped\n       if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n         synchronized (writeCtx) {\n           if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n             writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n             updateNonSequentialWriteInMemory(-count);\n+            if (LOG.isDebugEnabled()) {\n+              LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n+                  + offset + \", updated the memory count, new value:\"\n+                  + nonSequentialWriteInMemory.get());\n+            }\n           }\n         }\n       }\n       \n       if (!writeCtx.getReplied()) {\n         WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n+        if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n+          LOG.warn(\"Return original count:\" + writeCtx.getOriginalCount()\n+              + \" instead of real data count:\" + count);\n+          count \u003d writeCtx.getOriginalCount();\n+        }\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n             new XDR(), xid, new VerifierNone()), xid);\n       }\n     } catch (IOException e) {\n       LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n-          + offset + \" and length \" + data.length, e);\n+          + offset + \" and length \" + count, e);\n       if (!writeCtx.getReplied()) {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n         Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n             new XDR(), xid, new VerifierNone()), xid);\n         // Keep stream open. Either client retries or SteamMonitor closes it.\n       }\n \n       LOG.info(\"Clean up open file context for fileId: \"\n           + latestAttr.getFileid());\n       cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    \n    FileHandle handle \u003d writeCtx.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n          + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n    }\n\n    try {\n      // The write is not protected by lock. asyncState is used to make sure\n      // there is one thread doing write back at any time    \n      writeCtx.writeData(fos);\n      \n      long flushedOffset \u003d getFlushedOffset();\n      if (flushedOffset !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + flushedOffset + \" and nextOffset should be\"\n            + (offset + count));\n      }\n      \n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n        synchronized (writeCtx) {\n          if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n            writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n            updateNonSequentialWriteInMemory(-count);\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n                  + offset + \", updated the memory count, new value:\"\n                  + nonSequentialWriteInMemory.get());\n            }\n          }\n        }\n      }\n      \n      if (!writeCtx.getReplied()) {\n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        if (writeCtx.getOriginalCount() !\u003d WriteCtx.INVALID_ORIGINAL_COUNT) {\n          LOG.warn(\"Return original count:\" + writeCtx.getOriginalCount()\n              + \" instead of real data count:\" + count);\n          count \u003d writeCtx.getOriginalCount();\n        }\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n      }\n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n          + offset + \" and length \" + count, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: \"\n          + latestAttr.getFileid());\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "28e3d09230971b32f74284311931525cb7ad1b7c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4971. Move IO operations out of locking in OpenFileCtx. Contributed by Jing Zhao and Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1525681 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/09/13 1:02 PM",
      "commitName": "28e3d09230971b32f74284311931525cb7ad1b7c",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "17/09/13 11:08 PM",
      "commitNameOld": "5e18410e06dd63113c49029894007e0878312903",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 5.58,
      "commitsBetweenForRepo": 25,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,64 +1,76 @@\n   private void doSingleWrite(final WriteCtx writeCtx) {\n-    assert(ctxLock.isLocked());\n     Channel channel \u003d writeCtx.getChannel();\n     int xid \u003d writeCtx.getXid();\n \n     long offset \u003d writeCtx.getOffset();\n     int count \u003d writeCtx.getCount();\n     WriteStableHow stableHow \u003d writeCtx.getStableHow();\n     byte[] data \u003d null;\n     try {\n       data \u003d writeCtx.getData();\n-    } catch (IOException e1) {\n+    } catch (Exception e1) {\n       LOG.error(\"Failed to get request data offset:\" + offset + \" count:\"\n           + count + \" error:\" + e1);\n       // Cleanup everything\n       cleanup();\n       return;\n     }\n-    assert (data.length \u003d\u003d count);\n+    \n+    Preconditions.checkState(data.length \u003d\u003d count);\n \n     FileHandle handle \u003d writeCtx.getHandle();\n-    LOG.info(\"do write, fileId: \" + handle.getFileId() + \" offset: \" + offset\n-        + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n+          + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n+    }\n \n     try {\n+      // The write is not protected by lock. asyncState is used to make sure\n+      // there is one thread doing write back at any time\n       fos.write(data, 0, count);\n       \n       long flushedOffset \u003d getFlushedOffset();\n       if (flushedOffset !\u003d (offset + count)) {\n         throw new IOException(\"output stream is out of sync, pos\u003d\"\n             + flushedOffset + \" and nextOffset should be\"\n             + (offset + count));\n       }\n-      nextOffset \u003d flushedOffset;\n+      \n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n+            + offset + \", update the memory count.\");\n+      }\n \n       // Reduce memory occupation size if request was allowed dumped\n-      if (writeCtx.getDataState() \u003d\u003d DataState.ALLOW_DUMP) {\n-        updateNonSequentialWriteInMemory(-count);\n+      if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n+        synchronized (writeCtx) {\n+          if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n+            writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n+            updateNonSequentialWriteInMemory(-count);\n+          }\n+        }\n       }\n       \n       if (!writeCtx.getReplied()) {\n         WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n             new XDR(), xid, new VerifierNone()), xid);\n       }\n-\n     } catch (IOException e) {\n       LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n           + offset + \" and length \" + data.length, e);\n       if (!writeCtx.getReplied()) {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n         Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n             new XDR(), xid, new VerifierNone()), xid);\n         // Keep stream open. Either client retries or SteamMonitor closes it.\n       }\n \n       LOG.info(\"Clean up open file context for fileId: \"\n           + latestAttr.getFileid());\n       cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    byte[] data \u003d null;\n    try {\n      data \u003d writeCtx.getData();\n    } catch (Exception e1) {\n      LOG.error(\"Failed to get request data offset:\" + offset + \" count:\"\n          + count + \" error:\" + e1);\n      // Cleanup everything\n      cleanup();\n      return;\n    }\n    \n    Preconditions.checkState(data.length \u003d\u003d count);\n\n    FileHandle handle \u003d writeCtx.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"do write, fileId: \" + handle.getFileId() + \" offset: \"\n          + offset + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n    }\n\n    try {\n      // The write is not protected by lock. asyncState is used to make sure\n      // there is one thread doing write back at any time\n      fos.write(data, 0, count);\n      \n      long flushedOffset \u003d getFlushedOffset();\n      if (flushedOffset !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + flushedOffset + \" and nextOffset should be\"\n            + (offset + count));\n      }\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"After writing \" + handle.getFileId() + \" at offset \"\n            + offset + \", update the memory count.\");\n      }\n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n        synchronized (writeCtx) {\n          if (writeCtx.getDataState() \u003d\u003d WriteCtx.DataState.ALLOW_DUMP) {\n            writeCtx.setDataState(WriteCtx.DataState.NO_DUMP);\n            updateNonSequentialWriteInMemory(-count);\n          }\n        }\n      }\n      \n      if (!writeCtx.getReplied()) {\n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n      }\n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n          + offset + \" and length \" + data.length, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: \"\n          + latestAttr.getFileid());\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "5e18410e06dd63113c49029894007e0878312903": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5212. Refactor RpcMessage and NFS3Response to support different types of authentication information. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1524298 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/09/13 11:08 PM",
      "commitName": "5e18410e06dd63113c49029894007e0878312903",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "13/09/13 4:14 PM",
      "commitNameOld": "a56a4b6ef06602312144783b7507bf2b82821e4f",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 4.29,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,64 @@\n   private void doSingleWrite(final WriteCtx writeCtx) {\n     assert(ctxLock.isLocked());\n     Channel channel \u003d writeCtx.getChannel();\n     int xid \u003d writeCtx.getXid();\n \n     long offset \u003d writeCtx.getOffset();\n     int count \u003d writeCtx.getCount();\n     WriteStableHow stableHow \u003d writeCtx.getStableHow();\n     byte[] data \u003d null;\n     try {\n       data \u003d writeCtx.getData();\n     } catch (IOException e1) {\n       LOG.error(\"Failed to get request data offset:\" + offset + \" count:\"\n           + count + \" error:\" + e1);\n       // Cleanup everything\n       cleanup();\n       return;\n     }\n     assert (data.length \u003d\u003d count);\n \n     FileHandle handle \u003d writeCtx.getHandle();\n     LOG.info(\"do write, fileId: \" + handle.getFileId() + \" offset: \" + offset\n         + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n \n     try {\n       fos.write(data, 0, count);\n       \n       long flushedOffset \u003d getFlushedOffset();\n       if (flushedOffset !\u003d (offset + count)) {\n         throw new IOException(\"output stream is out of sync, pos\u003d\"\n             + flushedOffset + \" and nextOffset should be\"\n             + (offset + count));\n       }\n       nextOffset \u003d flushedOffset;\n \n       // Reduce memory occupation size if request was allowed dumped\n       if (writeCtx.getDataState() \u003d\u003d DataState.ALLOW_DUMP) {\n         updateNonSequentialWriteInMemory(-count);\n       }\n       \n       if (!writeCtx.getReplied()) {\n         WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n-        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n+        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n+            new XDR(), xid, new VerifierNone()), xid);\n       }\n \n     } catch (IOException e) {\n       LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n           + offset + \" and length \" + data.length, e);\n       if (!writeCtx.getReplied()) {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n-        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n+        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n+            new XDR(), xid, new VerifierNone()), xid);\n         // Keep stream open. Either client retries or SteamMonitor closes it.\n       }\n \n       LOG.info(\"Clean up open file context for fileId: \"\n           + latestAttr.getFileid());\n       cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    assert(ctxLock.isLocked());\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    byte[] data \u003d null;\n    try {\n      data \u003d writeCtx.getData();\n    } catch (IOException e1) {\n      LOG.error(\"Failed to get request data offset:\" + offset + \" count:\"\n          + count + \" error:\" + e1);\n      // Cleanup everything\n      cleanup();\n      return;\n    }\n    assert (data.length \u003d\u003d count);\n\n    FileHandle handle \u003d writeCtx.getHandle();\n    LOG.info(\"do write, fileId: \" + handle.getFileId() + \" offset: \" + offset\n        + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n\n    try {\n      fos.write(data, 0, count);\n      \n      long flushedOffset \u003d getFlushedOffset();\n      if (flushedOffset !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + flushedOffset + \" and nextOffset should be\"\n            + (offset + count));\n      }\n      nextOffset \u003d flushedOffset;\n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d DataState.ALLOW_DUMP) {\n        updateNonSequentialWriteInMemory(-count);\n      }\n      \n      if (!writeCtx.getReplied()) {\n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n      }\n\n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n          + offset + \" and length \" + data.length, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.writeHeaderAndResponse(\n            new XDR(), xid, new VerifierNone()), xid);\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: \"\n          + latestAttr.getFileid());\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "a56a4b6ef06602312144783b7507bf2b82821e4f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5199 Add more debug trace for NFS READ and WRITE. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1523140 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/09/13 4:14 PM",
      "commitName": "a56a4b6ef06602312144783b7507bf2b82821e4f",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "28/08/13 10:23 AM",
      "commitNameOld": "30b8ef91a32ddf1fe3756bae6d7dc538a150bdc4",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 16.24,
      "commitsBetweenForRepo": 77,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,62 @@\n   private void doSingleWrite(final WriteCtx writeCtx) {\n     assert(ctxLock.isLocked());\n     Channel channel \u003d writeCtx.getChannel();\n     int xid \u003d writeCtx.getXid();\n \n     long offset \u003d writeCtx.getOffset();\n     int count \u003d writeCtx.getCount();\n     WriteStableHow stableHow \u003d writeCtx.getStableHow();\n     byte[] data \u003d null;\n     try {\n       data \u003d writeCtx.getData();\n     } catch (IOException e1) {\n       LOG.error(\"Failed to get request data offset:\" + offset + \" count:\"\n           + count + \" error:\" + e1);\n       // Cleanup everything\n       cleanup();\n       return;\n     }\n     assert (data.length \u003d\u003d count);\n \n     FileHandle handle \u003d writeCtx.getHandle();\n     LOG.info(\"do write, fileId: \" + handle.getFileId() + \" offset: \" + offset\n         + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n \n     try {\n       fos.write(data, 0, count);\n       \n       long flushedOffset \u003d getFlushedOffset();\n       if (flushedOffset !\u003d (offset + count)) {\n         throw new IOException(\"output stream is out of sync, pos\u003d\"\n             + flushedOffset + \" and nextOffset should be\"\n             + (offset + count));\n       }\n       nextOffset \u003d flushedOffset;\n \n       // Reduce memory occupation size if request was allowed dumped\n       if (writeCtx.getDataState() \u003d\u003d DataState.ALLOW_DUMP) {\n         updateNonSequentialWriteInMemory(-count);\n       }\n       \n       if (!writeCtx.getReplied()) {\n         WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n-        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n+        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n       }\n \n     } catch (IOException e) {\n       LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n           + offset + \" and length \" + data.length, e);\n       if (!writeCtx.getReplied()) {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n-        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n+        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n         // Keep stream open. Either client retries or SteamMonitor closes it.\n       }\n \n       LOG.info(\"Clean up open file context for fileId: \"\n           + latestAttr.getFileid());\n       cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    assert(ctxLock.isLocked());\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    byte[] data \u003d null;\n    try {\n      data \u003d writeCtx.getData();\n    } catch (IOException e1) {\n      LOG.error(\"Failed to get request data offset:\" + offset + \" count:\"\n          + count + \" error:\" + e1);\n      // Cleanup everything\n      cleanup();\n      return;\n    }\n    assert (data.length \u003d\u003d count);\n\n    FileHandle handle \u003d writeCtx.getHandle();\n    LOG.info(\"do write, fileId: \" + handle.getFileId() + \" offset: \" + offset\n        + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n\n    try {\n      fos.write(data, 0, count);\n      \n      long flushedOffset \u003d getFlushedOffset();\n      if (flushedOffset !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + flushedOffset + \" and nextOffset should be\"\n            + (offset + count));\n      }\n      nextOffset \u003d flushedOffset;\n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d DataState.ALLOW_DUMP) {\n        updateNonSequentialWriteInMemory(-count);\n      }\n      \n      if (!writeCtx.getReplied()) {\n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n      }\n\n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n          + offset + \" and length \" + data.length, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid), xid);\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: \"\n          + latestAttr.getFileid());\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "30b8ef91a32ddf1fe3756bae6d7dc538a150bdc4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5078 Support file append in NFSv3 gateway to enable data streaming to HDFS. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1518292 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/08/13 10:23 AM",
      "commitName": "30b8ef91a32ddf1fe3756bae6d7dc538a150bdc4",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "19/08/13 2:54 PM",
      "commitNameOld": "c9b89de0eacf15f21faa3a7ba30d4773f571c9a4",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 8.81,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,60 +1,62 @@\n   private void doSingleWrite(final WriteCtx writeCtx) {\n     assert(ctxLock.isLocked());\n     Channel channel \u003d writeCtx.getChannel();\n     int xid \u003d writeCtx.getXid();\n \n     long offset \u003d writeCtx.getOffset();\n     int count \u003d writeCtx.getCount();\n     WriteStableHow stableHow \u003d writeCtx.getStableHow();\n     byte[] data \u003d null;\n     try {\n       data \u003d writeCtx.getData();\n     } catch (IOException e1) {\n       LOG.error(\"Failed to get request data offset:\" + offset + \" count:\"\n           + count + \" error:\" + e1);\n       // Cleanup everything\n       cleanup();\n       return;\n     }\n     assert (data.length \u003d\u003d count);\n \n     FileHandle handle \u003d writeCtx.getHandle();\n     LOG.info(\"do write, fileId: \" + handle.getFileId() + \" offset: \" + offset\n         + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n \n     try {\n       fos.write(data, 0, count);\n-\n-      if (fos.getPos() !\u003d (offset + count)) {\n+      \n+      long flushedOffset \u003d getFlushedOffset();\n+      if (flushedOffset !\u003d (offset + count)) {\n         throw new IOException(\"output stream is out of sync, pos\u003d\"\n-            + fos.getPos() + \" and nextOffset should be\" + (offset + count));\n+            + flushedOffset + \" and nextOffset should be\"\n+            + (offset + count));\n       }\n-      nextOffset \u003d fos.getPos();\n+      nextOffset \u003d flushedOffset;\n \n       // Reduce memory occupation size if request was allowed dumped\n       if (writeCtx.getDataState() \u003d\u003d DataState.ALLOW_DUMP) {\n         updateNonSequentialWriteInMemory(-count);\n       }\n       \n       if (!writeCtx.getReplied()) {\n         WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n       }\n \n     } catch (IOException e) {\n       LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n           + offset + \" and length \" + data.length, e);\n       if (!writeCtx.getReplied()) {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n         Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n         // Keep stream open. Either client retries or SteamMonitor closes it.\n       }\n \n       LOG.info(\"Clean up open file context for fileId: \"\n           + latestAttr.getFileid());\n       cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    assert(ctxLock.isLocked());\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    byte[] data \u003d null;\n    try {\n      data \u003d writeCtx.getData();\n    } catch (IOException e1) {\n      LOG.error(\"Failed to get request data offset:\" + offset + \" count:\"\n          + count + \" error:\" + e1);\n      // Cleanup everything\n      cleanup();\n      return;\n    }\n    assert (data.length \u003d\u003d count);\n\n    FileHandle handle \u003d writeCtx.getHandle();\n    LOG.info(\"do write, fileId: \" + handle.getFileId() + \" offset: \" + offset\n        + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n\n    try {\n      fos.write(data, 0, count);\n      \n      long flushedOffset \u003d getFlushedOffset();\n      if (flushedOffset !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + flushedOffset + \" and nextOffset should be\"\n            + (offset + count));\n      }\n      nextOffset \u003d flushedOffset;\n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d DataState.ALLOW_DUMP) {\n        updateNonSequentialWriteInMemory(-count);\n      }\n      \n      if (!writeCtx.getReplied()) {\n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n      }\n\n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n          + offset + \" and length \" + data.length, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: \"\n          + latestAttr.getFileid());\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "58d75576c4d2a03d4954174bc223ed0334b34fee": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4962. Use enum for nfs constants. Contributed by Tsz Wo (Nicholas) SZE.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1501851 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/07/13 10:01 AM",
      "commitName": "58d75576c4d2a03d4954174bc223ed0334b34fee",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "02/07/13 10:31 AM",
      "commitNameOld": "37f587563a943a827fbff865f5302bac6d202415",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 7.98,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,60 +1,60 @@\n   private void doSingleWrite(final WriteCtx writeCtx) {\n     assert(ctxLock.isLocked());\n     Channel channel \u003d writeCtx.getChannel();\n     int xid \u003d writeCtx.getXid();\n \n     long offset \u003d writeCtx.getOffset();\n     int count \u003d writeCtx.getCount();\n     WriteStableHow stableHow \u003d writeCtx.getStableHow();\n     byte[] data \u003d null;\n     try {\n       data \u003d writeCtx.getData();\n     } catch (IOException e1) {\n       LOG.error(\"Failed to get request data offset:\" + offset + \" count:\"\n           + count + \" error:\" + e1);\n       // Cleanup everything\n       cleanup();\n       return;\n     }\n     assert (data.length \u003d\u003d count);\n \n     FileHandle handle \u003d writeCtx.getHandle();\n     LOG.info(\"do write, fileId: \" + handle.getFileId() + \" offset: \" + offset\n         + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n \n     try {\n       fos.write(data, 0, count);\n \n       if (fos.getPos() !\u003d (offset + count)) {\n         throw new IOException(\"output stream is out of sync, pos\u003d\"\n             + fos.getPos() + \" and nextOffset should be\" + (offset + count));\n       }\n       nextOffset \u003d fos.getPos();\n \n       // Reduce memory occupation size if request was allowed dumped\n-      if (writeCtx.getDataState() \u003d\u003d WriteCtx.ALLOW_DUMP) {\n+      if (writeCtx.getDataState() \u003d\u003d DataState.ALLOW_DUMP) {\n         updateNonSequentialWriteInMemory(-count);\n       }\n       \n       if (!writeCtx.getReplied()) {\n         WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n             fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n       }\n \n     } catch (IOException e) {\n       LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n           + offset + \" and length \" + data.length, e);\n       if (!writeCtx.getReplied()) {\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n         Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n         // Keep stream open. Either client retries or SteamMonitor closes it.\n       }\n \n       LOG.info(\"Clean up open file context for fileId: \"\n           + latestAttr.getFileid());\n       cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    assert(ctxLock.isLocked());\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    byte[] data \u003d null;\n    try {\n      data \u003d writeCtx.getData();\n    } catch (IOException e1) {\n      LOG.error(\"Failed to get request data offset:\" + offset + \" count:\"\n          + count + \" error:\" + e1);\n      // Cleanup everything\n      cleanup();\n      return;\n    }\n    assert (data.length \u003d\u003d count);\n\n    FileHandle handle \u003d writeCtx.getHandle();\n    LOG.info(\"do write, fileId: \" + handle.getFileId() + \" offset: \" + offset\n        + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n\n    try {\n      fos.write(data, 0, count);\n\n      if (fos.getPos() !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + fos.getPos() + \" and nextOffset should be\" + (offset + count));\n      }\n      nextOffset \u003d fos.getPos();\n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d DataState.ALLOW_DUMP) {\n        updateNonSequentialWriteInMemory(-count);\n      }\n      \n      if (!writeCtx.getReplied()) {\n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n      }\n\n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n          + offset + \" and length \" + data.length, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: \"\n          + latestAttr.getFileid());\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "37f587563a943a827fbff865f5302bac6d202415": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4762 Provide HDFS based NFSv3 and Mountd implementation. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1499029 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/07/13 10:31 AM",
      "commitName": "37f587563a943a827fbff865f5302bac6d202415",
      "commitAuthor": "Brandon Li",
      "diff": "@@ -0,0 +1,60 @@\n+  private void doSingleWrite(final WriteCtx writeCtx) {\n+    assert(ctxLock.isLocked());\n+    Channel channel \u003d writeCtx.getChannel();\n+    int xid \u003d writeCtx.getXid();\n+\n+    long offset \u003d writeCtx.getOffset();\n+    int count \u003d writeCtx.getCount();\n+    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n+    byte[] data \u003d null;\n+    try {\n+      data \u003d writeCtx.getData();\n+    } catch (IOException e1) {\n+      LOG.error(\"Failed to get request data offset:\" + offset + \" count:\"\n+          + count + \" error:\" + e1);\n+      // Cleanup everything\n+      cleanup();\n+      return;\n+    }\n+    assert (data.length \u003d\u003d count);\n+\n+    FileHandle handle \u003d writeCtx.getHandle();\n+    LOG.info(\"do write, fileId: \" + handle.getFileId() + \" offset: \" + offset\n+        + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n+\n+    try {\n+      fos.write(data, 0, count);\n+\n+      if (fos.getPos() !\u003d (offset + count)) {\n+        throw new IOException(\"output stream is out of sync, pos\u003d\"\n+            + fos.getPos() + \" and nextOffset should be\" + (offset + count));\n+      }\n+      nextOffset \u003d fos.getPos();\n+\n+      // Reduce memory occupation size if request was allowed dumped\n+      if (writeCtx.getDataState() \u003d\u003d WriteCtx.ALLOW_DUMP) {\n+        updateNonSequentialWriteInMemory(-count);\n+      }\n+      \n+      if (!writeCtx.getReplied()) {\n+        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n+        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n+        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n+            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n+        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n+      }\n+\n+    } catch (IOException e) {\n+      LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n+          + offset + \" and length \" + data.length, e);\n+      if (!writeCtx.getReplied()) {\n+        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n+        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n+        // Keep stream open. Either client retries or SteamMonitor closes it.\n+      }\n+\n+      LOG.info(\"Clean up open file context for fileId: \"\n+          + latestAttr.getFileid());\n+      cleanup();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void doSingleWrite(final WriteCtx writeCtx) {\n    assert(ctxLock.isLocked());\n    Channel channel \u003d writeCtx.getChannel();\n    int xid \u003d writeCtx.getXid();\n\n    long offset \u003d writeCtx.getOffset();\n    int count \u003d writeCtx.getCount();\n    WriteStableHow stableHow \u003d writeCtx.getStableHow();\n    byte[] data \u003d null;\n    try {\n      data \u003d writeCtx.getData();\n    } catch (IOException e1) {\n      LOG.error(\"Failed to get request data offset:\" + offset + \" count:\"\n          + count + \" error:\" + e1);\n      // Cleanup everything\n      cleanup();\n      return;\n    }\n    assert (data.length \u003d\u003d count);\n\n    FileHandle handle \u003d writeCtx.getHandle();\n    LOG.info(\"do write, fileId: \" + handle.getFileId() + \" offset: \" + offset\n        + \" length:\" + count + \" stableHow:\" + stableHow.getValue());\n\n    try {\n      fos.write(data, 0, count);\n\n      if (fos.getPos() !\u003d (offset + count)) {\n        throw new IOException(\"output stream is out of sync, pos\u003d\"\n            + fos.getPos() + \" and nextOffset should be\" + (offset + count));\n      }\n      nextOffset \u003d fos.getPos();\n\n      // Reduce memory occupation size if request was allowed dumped\n      if (writeCtx.getDataState() \u003d\u003d WriteCtx.ALLOW_DUMP) {\n        updateNonSequentialWriteInMemory(-count);\n      }\n      \n      if (!writeCtx.getReplied()) {\n        WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3_OK,\n            fileWcc, count, stableHow, Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n      }\n\n    } catch (IOException e) {\n      LOG.error(\"Error writing to fileId \" + handle.getFileId() + \" at offset \"\n          + offset + \" and length \" + data.length, e);\n      if (!writeCtx.getReplied()) {\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO);\n        Nfs3Utils.writeChannel(channel, response.send(new XDR(), xid));\n        // Keep stream open. Either client retries or SteamMonitor closes it.\n      }\n\n      LOG.info(\"Clean up open file context for fileId: \"\n          + latestAttr.getFileid());\n      cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java"
    }
  }
}