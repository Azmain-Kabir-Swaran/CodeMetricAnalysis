{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CommandWithDestination.java",
  "functionName": "copyStreamToTarget",
  "functionId": "copyStreamToTarget___in-InputStream__target-PathData",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CommandWithDestination.java",
  "functionStartLine": 407,
  "functionEndLine": 423,
  "numCommitsSeen": 29,
  "timeTaken": 2470,
  "changeHistory": [
    "0dd8956f2e4bd7cd2315ef23703e4b2da1a0d073",
    "9221704f857e33a5f9e00c19d3705e46e94f427b",
    "090d26652c04916a1ede4ca55e7f2ca4fc5f6249",
    "bbaa7dc28db75d9b3700c6ff95222d8e1de29c15",
    "12d0e025919cfb375ecb1739fe99e92421beb56c",
    "7f7b05226e3ae1fdf3c440f8d26814f4d955f734",
    "8f9661da4823bfbb243e430252ec1bb5780ecbfc"
  ],
  "changeHistoryShort": {
    "0dd8956f2e4bd7cd2315ef23703e4b2da1a0d073": "Ybodychange",
    "9221704f857e33a5f9e00c19d3705e46e94f427b": "Ybodychange",
    "090d26652c04916a1ede4ca55e7f2ca4fc5f6249": "Ybodychange",
    "bbaa7dc28db75d9b3700c6ff95222d8e1de29c15": "Ybodychange",
    "12d0e025919cfb375ecb1739fe99e92421beb56c": "Ybodychange",
    "7f7b05226e3ae1fdf3c440f8d26814f4d955f734": "Ybodychange",
    "8f9661da4823bfbb243e430252ec1bb5780ecbfc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "0dd8956f2e4bd7cd2315ef23703e4b2da1a0d073": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16885. Encryption zone file copy failure leaks a temp file\n\n\r\nContributed by Xiaoyu Yao.\r\n\r\nContains HDFS-14892. Close the output stream if createWrappedOutputStream() fails\r\n\r\nCopying file through the FsShell command into an HDFS encryption zone where\r\nthe caller lacks permissions is leaks a temp ._COPYING file\r\nand potentially a wrapped stream unclosed.\r\n\r\nThis is a convergence of a fix for S3 meeting an issue in HDFS.\r\n\r\nS3: a HEAD against a file can cache a 404, \r\n -you must not do any existence checks, including deleteOnExit(),\r\n  until the file is written. \r\n\r\nHence: HADOOP-16490, only register files for deletion the create worked\r\nand the upload is not direct. \r\n\r\nHDFS-14892. HDFS doesn\u0027t close wrapped streams when IOEs are raised on\r\ncreate() failures. Which means that an entry is retained on the NN.\r\n-you need to register a file with deleteOnExit() even if the file wasn\u0027t\r\ncreated.\r\n\r\nThis patch:\r\n\r\n* Moves the deleteOnExit to ensure the created file get deleted cleanly.\r\n* Fixes HDFS to close the wrapped stream on failures.\r\n\r\n\r\n",
      "commitDate": "02/03/20 5:22 AM",
      "commitName": "0dd8956f2e4bd7cd2315ef23703e4b2da1a0d073",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "11/09/19 8:46 AM",
      "commitNameOld": "9221704f857e33a5f9e00c19d3705e46e94f427b",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 172.9,
      "commitsBetweenForRepo": 759,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,17 @@\n   protected void copyStreamToTarget(InputStream in, PathData target)\n   throws IOException {\n     if (target.exists \u0026\u0026 (target.stat.isDirectory() || !overwrite)) {\n       throw new PathExistsException(target.toString());\n     }\n     TargetFileSystem targetFs \u003d new TargetFileSystem(target.fs);\n     try {\n       PathData tempTarget \u003d direct ? target : target.suffix(\"._COPYING_\");\n       targetFs.setWriteChecksum(writeChecksum);\n       targetFs.writeStreamToFile(in, tempTarget, lazyPersist, direct);\n       if (!direct) {\n-        targetFs.deleteOnExit(tempTarget.path);\n         targetFs.rename(tempTarget, target);\n       }\n     } finally {\n       targetFs.close(); // last ditch effort to ensure temp file is removed\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void copyStreamToTarget(InputStream in, PathData target)\n  throws IOException {\n    if (target.exists \u0026\u0026 (target.stat.isDirectory() || !overwrite)) {\n      throw new PathExistsException(target.toString());\n    }\n    TargetFileSystem targetFs \u003d new TargetFileSystem(target.fs);\n    try {\n      PathData tempTarget \u003d direct ? target : target.suffix(\"._COPYING_\");\n      targetFs.setWriteChecksum(writeChecksum);\n      targetFs.writeStreamToFile(in, tempTarget, lazyPersist, direct);\n      if (!direct) {\n        targetFs.rename(tempTarget, target);\n      }\n    } finally {\n      targetFs.close(); // last ditch effort to ensure temp file is removed\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CommandWithDestination.java",
      "extendedDetails": {}
    },
    "9221704f857e33a5f9e00c19d3705e46e94f427b": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16490. Avoid/handle cached 404s during S3A file creation.\n\nContributed by Steve Loughran.\n\nThis patch avoids issuing any HEAD path request when creating a file with overwrite\u003dtrue,\nso 404s will not end up in the S3 load balancers unless someone calls getFileStatus/exists/isFile\nin their own code.\n\nThe Hadoop FsShell CommandWithDestination class is modified to not register uncreated files\nfor deleteOnExit(), because that calls exists() and so can place the 404 in the cache, even\nafter S3A is patched to not do it itself.\n\nBecause S3Guard knows when a file should be present, it adds a special FileNotFound retry policy\nindependently configurable from other retry policies; it is also exponential, but with\ndifferent parameters. This is because every HEAD request will refresh any 404 cached in\nthe S3 Load Balancers. It\u0027s not enough to retry: we have to have a suitable gap between\nattempts to (hopefully) ensure any cached entry wil be gone.\n\nThe options and values are:\n\nfs.s3a.s3guard.consistency.retry.interval: 2s\nfs.s3a.s3guard.consistency.retry.limit: 7\n\nThe S3A copy() method used during rename() raises a RemoteFileChangedException which is not caught\nso not downgraded to false. Thus: when a rename is unrecoverable, this fact is propagated.\n\nCopy operations without S3Guard lack the confidence that the file exists, so don\u0027t retry the same way:\nit will fail fast with a different error message. However, because create(path, overwrite\u003dfalse) no\nlonger does HEAD path, we can at least be confident that S3A itself is not creating those cached\n404 markers.\n\nChange-Id: Ia7807faad8b9a8546836cb19f816cccf17cca26d\n",
      "commitDate": "11/09/19 8:46 AM",
      "commitName": "9221704f857e33a5f9e00c19d3705e46e94f427b",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "29/01/19 4:45 PM",
      "commitNameOld": "b3bc94ebfd7cbf959bd33b8d85be80c4a8a46574",
      "commitAuthorOld": "Hanisha Koneru",
      "daysBetweenCommits": 224.63,
      "commitsBetweenForRepo": 1743,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,18 @@\n   protected void copyStreamToTarget(InputStream in, PathData target)\n   throws IOException {\n     if (target.exists \u0026\u0026 (target.stat.isDirectory() || !overwrite)) {\n       throw new PathExistsException(target.toString());\n     }\n     TargetFileSystem targetFs \u003d new TargetFileSystem(target.fs);\n     try {\n       PathData tempTarget \u003d direct ? target : target.suffix(\"._COPYING_\");\n       targetFs.setWriteChecksum(writeChecksum);\n       targetFs.writeStreamToFile(in, tempTarget, lazyPersist, direct);\n       if (!direct) {\n+        targetFs.deleteOnExit(tempTarget.path);\n         targetFs.rename(tempTarget, target);\n       }\n     } finally {\n       targetFs.close(); // last ditch effort to ensure temp file is removed\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void copyStreamToTarget(InputStream in, PathData target)\n  throws IOException {\n    if (target.exists \u0026\u0026 (target.stat.isDirectory() || !overwrite)) {\n      throw new PathExistsException(target.toString());\n    }\n    TargetFileSystem targetFs \u003d new TargetFileSystem(target.fs);\n    try {\n      PathData tempTarget \u003d direct ? target : target.suffix(\"._COPYING_\");\n      targetFs.setWriteChecksum(writeChecksum);\n      targetFs.writeStreamToFile(in, tempTarget, lazyPersist, direct);\n      if (!direct) {\n        targetFs.deleteOnExit(tempTarget.path);\n        targetFs.rename(tempTarget, target);\n      }\n    } finally {\n      targetFs.close(); // last ditch effort to ensure temp file is removed\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CommandWithDestination.java",
      "extendedDetails": {}
    },
    "090d26652c04916a1ede4ca55e7f2ca4fc5f6249": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12384. Add \u0027-direct\u0027 flag option for fs copy so that user can choose not to create \u0027._COPYING_\u0027 file (Contributed by J.Andreina)\n",
      "commitDate": "08/09/15 6:41 AM",
      "commitName": "090d26652c04916a1ede4ca55e7f2ca4fc5f6249",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "16/09/14 6:19 PM",
      "commitNameOld": "dcbc46730131a1bdf8416efeb4571794e5c8e369",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 356.51,
      "commitsBetweenForRepo": 2841,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,17 @@\n   protected void copyStreamToTarget(InputStream in, PathData target)\n   throws IOException {\n     if (target.exists \u0026\u0026 (target.stat.isDirectory() || !overwrite)) {\n       throw new PathExistsException(target.toString());\n     }\n     TargetFileSystem targetFs \u003d new TargetFileSystem(target.fs);\n     try {\n-      PathData tempTarget \u003d target.suffix(\"._COPYING_\");\n+      PathData tempTarget \u003d direct ? target : target.suffix(\"._COPYING_\");\n       targetFs.setWriteChecksum(writeChecksum);\n-      targetFs.writeStreamToFile(in, tempTarget, lazyPersist);\n-      targetFs.rename(tempTarget, target);\n+      targetFs.writeStreamToFile(in, tempTarget, lazyPersist, direct);\n+      if (!direct) {\n+        targetFs.rename(tempTarget, target);\n+      }\n     } finally {\n       targetFs.close(); // last ditch effort to ensure temp file is removed\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void copyStreamToTarget(InputStream in, PathData target)\n  throws IOException {\n    if (target.exists \u0026\u0026 (target.stat.isDirectory() || !overwrite)) {\n      throw new PathExistsException(target.toString());\n    }\n    TargetFileSystem targetFs \u003d new TargetFileSystem(target.fs);\n    try {\n      PathData tempTarget \u003d direct ? target : target.suffix(\"._COPYING_\");\n      targetFs.setWriteChecksum(writeChecksum);\n      targetFs.writeStreamToFile(in, tempTarget, lazyPersist, direct);\n      if (!direct) {\n        targetFs.rename(tempTarget, target);\n      }\n    } finally {\n      targetFs.close(); // last ditch effort to ensure temp file is removed\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CommandWithDestination.java",
      "extendedDetails": {}
    },
    "bbaa7dc28db75d9b3700c6ff95222d8e1de29c15": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6928. \u0027hdfs put\u0027 command should accept lazyPersist flag for testing. (Arpit Agarwal)\n",
      "commitDate": "28/08/14 3:53 PM",
      "commitName": "bbaa7dc28db75d9b3700c6ff95222d8e1de29c15",
      "commitAuthor": "arp",
      "commitDateOld": "19/08/14 1:43 PM",
      "commitNameOld": "a4ee77b65f31351b4eae76ba5df0681a0d2b856f",
      "commitAuthorOld": "Charles Lamb",
      "daysBetweenCommits": 9.09,
      "commitsBetweenForRepo": 58,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,15 @@\n   protected void copyStreamToTarget(InputStream in, PathData target)\n   throws IOException {\n     if (target.exists \u0026\u0026 (target.stat.isDirectory() || !overwrite)) {\n       throw new PathExistsException(target.toString());\n     }\n     TargetFileSystem targetFs \u003d new TargetFileSystem(target.fs);\n     try {\n       PathData tempTarget \u003d target.suffix(\"._COPYING_\");\n       targetFs.setWriteChecksum(writeChecksum);\n-      targetFs.writeStreamToFile(in, tempTarget);\n+      targetFs.writeStreamToFile(in, tempTarget, lazyPersist);\n       targetFs.rename(tempTarget, target);\n     } finally {\n       targetFs.close(); // last ditch effort to ensure temp file is removed\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void copyStreamToTarget(InputStream in, PathData target)\n  throws IOException {\n    if (target.exists \u0026\u0026 (target.stat.isDirectory() || !overwrite)) {\n      throw new PathExistsException(target.toString());\n    }\n    TargetFileSystem targetFs \u003d new TargetFileSystem(target.fs);\n    try {\n      PathData tempTarget \u003d target.suffix(\"._COPYING_\");\n      targetFs.setWriteChecksum(writeChecksum);\n      targetFs.writeStreamToFile(in, tempTarget, lazyPersist);\n      targetFs.rename(tempTarget, target);\n    } finally {\n      targetFs.close(); // last ditch effort to ensure temp file is removed\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CommandWithDestination.java",
      "extendedDetails": {}
    },
    "12d0e025919cfb375ecb1739fe99e92421beb56c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-8633. Interrupted FsShell copies may leave tmp files (Daryn Sharp via tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1368002 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/08/12 7:02 AM",
      "commitName": "12d0e025919cfb375ecb1739fe99e92421beb56c",
      "commitAuthor": "Thomas Graves",
      "commitDateOld": "16/03/12 9:08 AM",
      "commitNameOld": "af3163d1d1e144a55fc448110a6ba6cdca7204c0",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 137.91,
      "commitsBetweenForRepo": 846,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,15 @@\n   protected void copyStreamToTarget(InputStream in, PathData target)\n   throws IOException {\n     if (target.exists \u0026\u0026 (target.stat.isDirectory() || !overwrite)) {\n       throw new PathExistsException(target.toString());\n     }\n-    target.fs.setWriteChecksum(writeChecksum);\n-    PathData tempFile \u003d null;\n+    TargetFileSystem targetFs \u003d new TargetFileSystem(target.fs);\n     try {\n-      tempFile \u003d target.createTempFile(target+\"._COPYING_\");\n-      FSDataOutputStream out \u003d target.fs.create(tempFile.path, true);\n-      IOUtils.copyBytes(in, out, getConf(), true);\n-      // the rename method with an option to delete the target is deprecated\n-      if (target.exists \u0026\u0026 !target.fs.delete(target.path, false)) {\n-        // too bad we don\u0027t know why it failed\n-        PathIOException e \u003d new PathIOException(target.toString());\n-        e.setOperation(\"delete\");\n-        throw e;\n-      }\n-      if (!tempFile.fs.rename(tempFile.path, target.path)) {\n-        // too bad we don\u0027t know why it failed\n-        PathIOException e \u003d new PathIOException(tempFile.toString());\n-        e.setOperation(\"rename\");\n-        e.setTargetPath(target.toString());\n-        throw e;\n-      }\n-      tempFile \u003d null;\n+      PathData tempTarget \u003d target.suffix(\"._COPYING_\");\n+      targetFs.setWriteChecksum(writeChecksum);\n+      targetFs.writeStreamToFile(in, tempTarget);\n+      targetFs.rename(tempTarget, target);\n     } finally {\n-      if (tempFile !\u003d null) {\n-        tempFile.fs.delete(tempFile.path, false);\n-      }\n+      targetFs.close(); // last ditch effort to ensure temp file is removed\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void copyStreamToTarget(InputStream in, PathData target)\n  throws IOException {\n    if (target.exists \u0026\u0026 (target.stat.isDirectory() || !overwrite)) {\n      throw new PathExistsException(target.toString());\n    }\n    TargetFileSystem targetFs \u003d new TargetFileSystem(target.fs);\n    try {\n      PathData tempTarget \u003d target.suffix(\"._COPYING_\");\n      targetFs.setWriteChecksum(writeChecksum);\n      targetFs.writeStreamToFile(in, tempTarget);\n      targetFs.rename(tempTarget, target);\n    } finally {\n      targetFs.close(); // last ditch effort to ensure temp file is removed\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CommandWithDestination.java",
      "extendedDetails": {}
    },
    "7f7b05226e3ae1fdf3c440f8d26814f4d955f734": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-8042.  When copying a file out of HDFS, modifying it, and uploading it back into HDFS, the put fails due to a CRC mismatch (Daryn Sharp via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1242389 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/02/12 8:41 AM",
      "commitName": "7f7b05226e3ae1fdf3c440f8d26814f4d955f734",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "31/10/11 6:50 PM",
      "commitNameOld": "8f9661da4823bfbb243e430252ec1bb5780ecbfc",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 100.62,
      "commitsBetweenForRepo": 559,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,32 @@\n   protected void copyStreamToTarget(InputStream in, PathData target)\n   throws IOException {\n     if (target.exists \u0026\u0026 (target.stat.isDirectory() || !overwrite)) {\n       throw new PathExistsException(target.toString());\n     }\n+    target.fs.setWriteChecksum(writeChecksum);\n     PathData tempFile \u003d null;\n     try {\n       tempFile \u003d target.createTempFile(target+\"._COPYING_\");\n       FSDataOutputStream out \u003d target.fs.create(tempFile.path, true);\n       IOUtils.copyBytes(in, out, getConf(), true);\n       // the rename method with an option to delete the target is deprecated\n       if (target.exists \u0026\u0026 !target.fs.delete(target.path, false)) {\n         // too bad we don\u0027t know why it failed\n         PathIOException e \u003d new PathIOException(target.toString());\n         e.setOperation(\"delete\");\n         throw e;\n       }\n       if (!tempFile.fs.rename(tempFile.path, target.path)) {\n         // too bad we don\u0027t know why it failed\n         PathIOException e \u003d new PathIOException(tempFile.toString());\n         e.setOperation(\"rename\");\n         e.setTargetPath(target.toString());\n         throw e;\n       }\n       tempFile \u003d null;\n     } finally {\n       if (tempFile !\u003d null) {\n         tempFile.fs.delete(tempFile.path, false);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void copyStreamToTarget(InputStream in, PathData target)\n  throws IOException {\n    if (target.exists \u0026\u0026 (target.stat.isDirectory() || !overwrite)) {\n      throw new PathExistsException(target.toString());\n    }\n    target.fs.setWriteChecksum(writeChecksum);\n    PathData tempFile \u003d null;\n    try {\n      tempFile \u003d target.createTempFile(target+\"._COPYING_\");\n      FSDataOutputStream out \u003d target.fs.create(tempFile.path, true);\n      IOUtils.copyBytes(in, out, getConf(), true);\n      // the rename method with an option to delete the target is deprecated\n      if (target.exists \u0026\u0026 !target.fs.delete(target.path, false)) {\n        // too bad we don\u0027t know why it failed\n        PathIOException e \u003d new PathIOException(target.toString());\n        e.setOperation(\"delete\");\n        throw e;\n      }\n      if (!tempFile.fs.rename(tempFile.path, target.path)) {\n        // too bad we don\u0027t know why it failed\n        PathIOException e \u003d new PathIOException(tempFile.toString());\n        e.setOperation(\"rename\");\n        e.setTargetPath(target.toString());\n        throw e;\n      }\n      tempFile \u003d null;\n    } finally {\n      if (tempFile !\u003d null) {\n        tempFile.fs.delete(tempFile.path, false);\n      }\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CommandWithDestination.java",
      "extendedDetails": {}
    },
    "8f9661da4823bfbb243e430252ec1bb5780ecbfc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7771. FsShell -copyToLocal, -get, etc. commands throw NPE if the destination directory does not exist.  Contributed by John George and Daryn Sharp\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195760 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/10/11 6:50 PM",
      "commitName": "8f9661da4823bfbb243e430252ec1bb5780ecbfc",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,31 @@\n+  protected void copyStreamToTarget(InputStream in, PathData target)\n+  throws IOException {\n+    if (target.exists \u0026\u0026 (target.stat.isDirectory() || !overwrite)) {\n+      throw new PathExistsException(target.toString());\n+    }\n+    PathData tempFile \u003d null;\n+    try {\n+      tempFile \u003d target.createTempFile(target+\"._COPYING_\");\n+      FSDataOutputStream out \u003d target.fs.create(tempFile.path, true);\n+      IOUtils.copyBytes(in, out, getConf(), true);\n+      // the rename method with an option to delete the target is deprecated\n+      if (target.exists \u0026\u0026 !target.fs.delete(target.path, false)) {\n+        // too bad we don\u0027t know why it failed\n+        PathIOException e \u003d new PathIOException(target.toString());\n+        e.setOperation(\"delete\");\n+        throw e;\n+      }\n+      if (!tempFile.fs.rename(tempFile.path, target.path)) {\n+        // too bad we don\u0027t know why it failed\n+        PathIOException e \u003d new PathIOException(tempFile.toString());\n+        e.setOperation(\"rename\");\n+        e.setTargetPath(target.toString());\n+        throw e;\n+      }\n+      tempFile \u003d null;\n+    } finally {\n+      if (tempFile !\u003d null) {\n+        tempFile.fs.delete(tempFile.path, false);\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected void copyStreamToTarget(InputStream in, PathData target)\n  throws IOException {\n    if (target.exists \u0026\u0026 (target.stat.isDirectory() || !overwrite)) {\n      throw new PathExistsException(target.toString());\n    }\n    PathData tempFile \u003d null;\n    try {\n      tempFile \u003d target.createTempFile(target+\"._COPYING_\");\n      FSDataOutputStream out \u003d target.fs.create(tempFile.path, true);\n      IOUtils.copyBytes(in, out, getConf(), true);\n      // the rename method with an option to delete the target is deprecated\n      if (target.exists \u0026\u0026 !target.fs.delete(target.path, false)) {\n        // too bad we don\u0027t know why it failed\n        PathIOException e \u003d new PathIOException(target.toString());\n        e.setOperation(\"delete\");\n        throw e;\n      }\n      if (!tempFile.fs.rename(tempFile.path, target.path)) {\n        // too bad we don\u0027t know why it failed\n        PathIOException e \u003d new PathIOException(tempFile.toString());\n        e.setOperation(\"rename\");\n        e.setTargetPath(target.toString());\n        throw e;\n      }\n      tempFile \u003d null;\n    } finally {\n      if (tempFile !\u003d null) {\n        tempFile.fs.delete(tempFile.path, false);\n      }\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CommandWithDestination.java"
    }
  }
}