{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NNUpgradeUtil.java",
  "functionName": "doRollBack",
  "functionId": "doRollBack___sd-StorageDirectory",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNUpgradeUtil.java",
  "functionStartLine": 213,
  "functionEndLine": 236,
  "numCommitsSeen": 7,
  "timeTaken": 1916,
  "changeHistory": [
    "56205ca7d7f3b2a7e55f48b9cf444326e1d2b1a7",
    "edb6dc5f303093c2604cd07b0c0dacf12dbce5de"
  ],
  "changeHistoryShort": {
    "56205ca7d7f3b2a7e55f48b9cf444326e1d2b1a7": "Ybodychange",
    "edb6dc5f303093c2604cd07b0c0dacf12dbce5de": "Yintroduced"
  },
  "changeHistoryDetails": {
    "56205ca7d7f3b2a7e55f48b9cf444326e1d2b1a7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5840. Follow-up to HDFS-5138 to improve error handling during partial upgrade failures. Contributed by Aaron T. Myers, Suresh Srinivas, and Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1581260 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/03/14 11:48 PM",
      "commitName": "56205ca7d7f3b2a7e55f48b9cf444326e1d2b1a7",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "25/01/14 12:01 PM",
      "commitNameOld": "edb6dc5f303093c2604cd07b0c0dacf12dbce5de",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 58.45,
      "commitsBetweenForRepo": 537,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,24 @@\n   static void doRollBack(StorageDirectory sd)\n       throws IOException {\n     File prevDir \u003d sd.getPreviousDir();\n-    if (!prevDir.exists())\n+    if (!prevDir.exists()) {\n       return;\n+    }\n \n     File tmpDir \u003d sd.getRemovedTmp();\n-    assert !tmpDir.exists() : \"removed.tmp directory must not exist.\";\n+    Preconditions.checkState(!tmpDir.exists(),\n+        \"removed.tmp directory must not exist for rollback.\"\n+            + \"Consider restarting for recovery.\");\n     // rename current to tmp\n     File curDir \u003d sd.getCurrentDir();\n-    assert curDir.exists() : \"Current directory must exist.\";\n+    Preconditions.checkState(curDir.exists(),\n+        \"Current directory must exist for rollback.\");\n+\n     NNStorage.rename(curDir, tmpDir);\n     // rename previous to current\n     NNStorage.rename(prevDir, curDir);\n \n     // delete tmp dir\n     NNStorage.deleteDir(tmpDir);\n     LOG.info(\"Rollback of \" + sd.getRoot() + \" is complete.\");\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static void doRollBack(StorageDirectory sd)\n      throws IOException {\n    File prevDir \u003d sd.getPreviousDir();\n    if (!prevDir.exists()) {\n      return;\n    }\n\n    File tmpDir \u003d sd.getRemovedTmp();\n    Preconditions.checkState(!tmpDir.exists(),\n        \"removed.tmp directory must not exist for rollback.\"\n            + \"Consider restarting for recovery.\");\n    // rename current to tmp\n    File curDir \u003d sd.getCurrentDir();\n    Preconditions.checkState(curDir.exists(),\n        \"Current directory must exist for rollback.\");\n\n    NNStorage.rename(curDir, tmpDir);\n    // rename previous to current\n    NNStorage.rename(prevDir, curDir);\n\n    // delete tmp dir\n    NNStorage.deleteDir(tmpDir);\n    LOG.info(\"Rollback of \" + sd.getRoot() + \" is complete.\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNUpgradeUtil.java",
      "extendedDetails": {}
    },
    "edb6dc5f303093c2604cd07b0c0dacf12dbce5de": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5138. Support HDFS upgrade in HA. Contributed by Aaron T. Myers.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1561381 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/01/14 12:01 PM",
      "commitName": "edb6dc5f303093c2604cd07b0c0dacf12dbce5de",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,19 @@\n+  static void doRollBack(StorageDirectory sd)\n+      throws IOException {\n+    File prevDir \u003d sd.getPreviousDir();\n+    if (!prevDir.exists())\n+      return;\n+\n+    File tmpDir \u003d sd.getRemovedTmp();\n+    assert !tmpDir.exists() : \"removed.tmp directory must not exist.\";\n+    // rename current to tmp\n+    File curDir \u003d sd.getCurrentDir();\n+    assert curDir.exists() : \"Current directory must exist.\";\n+    NNStorage.rename(curDir, tmpDir);\n+    // rename previous to current\n+    NNStorage.rename(prevDir, curDir);\n+\n+    // delete tmp dir\n+    NNStorage.deleteDir(tmpDir);\n+    LOG.info(\"Rollback of \" + sd.getRoot() + \" is complete.\");\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static void doRollBack(StorageDirectory sd)\n      throws IOException {\n    File prevDir \u003d sd.getPreviousDir();\n    if (!prevDir.exists())\n      return;\n\n    File tmpDir \u003d sd.getRemovedTmp();\n    assert !tmpDir.exists() : \"removed.tmp directory must not exist.\";\n    // rename current to tmp\n    File curDir \u003d sd.getCurrentDir();\n    assert curDir.exists() : \"Current directory must exist.\";\n    NNStorage.rename(curDir, tmpDir);\n    // rename previous to current\n    NNStorage.rename(prevDir, curDir);\n\n    // delete tmp dir\n    NNStorage.deleteDir(tmpDir);\n    LOG.info(\"Rollback of \" + sd.getRoot() + \" is complete.\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNUpgradeUtil.java"
    }
  }
}