{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JobHistory.java",
  "functionName": "serviceInit",
  "functionId": "serviceInit___conf-Configuration",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
  "functionStartLine": 85,
  "functionEndLine": 112,
  "numCommitsSeen": 54,
  "timeTaken": 9240,
  "changeHistory": [
    "2fa7963c3d8cdfc65f90efabc6fe51a160be5c78",
    "8bb035509ea195ec03b8295a7abd11ce675a4d85",
    "8fa3ebd13451a243510eed5c2f3dd43cdf605a77",
    "0928502029ef141759008997335ea2cd836a7154",
    "a83fb61ac07c0468cbc7a38526e92683883dd932",
    "982753dc8e49ad51ad75698e0b30e2c75a4605a6",
    "7d04a96027ad75877b41b7cd8f67455dd13159d7",
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
    "7475e836dc2bdd29142eaf210262fba354b745ed",
    "68fa208b1cc991dec2577a07b3199a6935a71065",
    "fafe8cd28e726566509c679e19d7da622f29f90d",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "2fa7963c3d8cdfc65f90efabc6fe51a160be5c78": "Ybodychange",
    "8bb035509ea195ec03b8295a7abd11ce675a4d85": "Ybodychange",
    "8fa3ebd13451a243510eed5c2f3dd43cdf605a77": "Ybodychange",
    "0928502029ef141759008997335ea2cd836a7154": "Ymultichange(Yrename,Ymodifierchange,Yexceptionschange,Ybodychange)",
    "a83fb61ac07c0468cbc7a38526e92683883dd932": "Ymultichange(Yexceptionschange,Ybodychange)",
    "982753dc8e49ad51ad75698e0b30e2c75a4605a6": "Ybodychange",
    "7d04a96027ad75877b41b7cd8f67455dd13159d7": "Ybodychange",
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f": "Ybodychange",
    "7475e836dc2bdd29142eaf210262fba354b745ed": "Ybodychange",
    "68fa208b1cc991dec2577a07b3199a6935a71065": "Ybodychange",
    "fafe8cd28e726566509c679e19d7da622f29f90d": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2fa7963c3d8cdfc65f90efabc6fe51a160be5c78": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15254. Correct the wrong word spelling \u0027intialize\u0027. Contributed by fang zhenyi.\n",
      "commitDate": "24/02/18 2:41 PM",
      "commitName": "2fa7963c3d8cdfc65f90efabc6fe51a160be5c78",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "08/11/17 2:21 AM",
      "commitNameOld": "ffee10b68ef1f2d75c9d0df9140c2a605f826724",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 108.51,
      "commitsBetweenForRepo": 619,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n   protected void serviceInit(Configuration conf) throws Exception {\n     LOG.info(\"JobHistory Init\");\n     this.conf \u003d conf;\n     this.appID \u003d ApplicationId.newInstance(0, 0);\n     this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n         .newRecordInstance(ApplicationAttemptId.class);\n \n     moveThreadInterval \u003d conf.getLong(\n         JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n         JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n \n     hsManager \u003d createHistoryFileManager();\n     hsManager.init(conf);\n     try {\n       hsManager.initExisting();\n     } catch (IOException e) {\n-      throw new YarnRuntimeException(\"Failed to intialize existing directories\", e);\n+      throw new YarnRuntimeException(\"Failed to initialize existing directories\", e);\n     }\n \n     storage \u003d createHistoryStorage();\n     \n     if (storage instanceof Service) {\n       ((Service) storage).init(conf);\n     }\n     storage.setHistoryFileManager(hsManager);\n \n     super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    LOG.info(\"JobHistory Init\");\n    this.conf \u003d conf;\n    this.appID \u003d ApplicationId.newInstance(0, 0);\n    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationAttemptId.class);\n\n    moveThreadInterval \u003d conf.getLong(\n        JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n\n    hsManager \u003d createHistoryFileManager();\n    hsManager.init(conf);\n    try {\n      hsManager.initExisting();\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed to initialize existing directories\", e);\n    }\n\n    storage \u003d createHistoryStorage();\n    \n    if (storage instanceof Service) {\n      ((Service) storage).init(conf);\n    }\n    storage.setHistoryFileManager(hsManager);\n\n    super.serviceInit(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "8bb035509ea195ec03b8295a7abd11ce675a4d85": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5411. Refresh size of loaded job cache on history server. Contributed by Ashwin Shankar\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1508220 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/13 3:33 PM",
      "commitName": "8bb035509ea195ec03b8295a7abd11ce675a4d85",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "25/07/13 2:27 PM",
      "commitNameOld": "8fa3ebd13451a243510eed5c2f3dd43cdf605a77",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 4.05,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,28 @@\n   protected void serviceInit(Configuration conf) throws Exception {\n     LOG.info(\"JobHistory Init\");\n     this.conf \u003d conf;\n     this.appID \u003d ApplicationId.newInstance(0, 0);\n     this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n         .newRecordInstance(ApplicationAttemptId.class);\n \n     moveThreadInterval \u003d conf.getLong(\n         JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n         JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n \n     hsManager \u003d createHistoryFileManager();\n     hsManager.init(conf);\n     try {\n       hsManager.initExisting();\n     } catch (IOException e) {\n       throw new YarnRuntimeException(\"Failed to intialize existing directories\", e);\n     }\n \n-    storage \u003d ReflectionUtils.newInstance(conf.getClass(\n-        JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n-        HistoryStorage.class), conf);\n+    storage \u003d createHistoryStorage();\n+    \n     if (storage instanceof Service) {\n       ((Service) storage).init(conf);\n     }\n     storage.setHistoryFileManager(hsManager);\n \n     super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    LOG.info(\"JobHistory Init\");\n    this.conf \u003d conf;\n    this.appID \u003d ApplicationId.newInstance(0, 0);\n    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationAttemptId.class);\n\n    moveThreadInterval \u003d conf.getLong(\n        JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n\n    hsManager \u003d createHistoryFileManager();\n    hsManager.init(conf);\n    try {\n      hsManager.initExisting();\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed to intialize existing directories\", e);\n    }\n\n    storage \u003d createHistoryStorage();\n    \n    if (storage instanceof Service) {\n      ((Service) storage).init(conf);\n    }\n    storage.setHistoryFileManager(hsManager);\n\n    super.serviceInit(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "8fa3ebd13451a243510eed5c2f3dd43cdf605a77": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5386. Ability to refresh history server job retention and job cleaner settings. Contributed by Ashwin Shankar\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1507135 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/07/13 2:27 PM",
      "commitName": "8fa3ebd13451a243510eed5c2f3dd43cdf605a77",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "20/06/13 5:08 PM",
      "commitNameOld": "1a06175440eec7994d6b63b0e5ac8b6532870fb3",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 34.89,
      "commitsBetweenForRepo": 172,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,29 @@\n   protected void serviceInit(Configuration conf) throws Exception {\n     LOG.info(\"JobHistory Init\");\n     this.conf \u003d conf;\n     this.appID \u003d ApplicationId.newInstance(0, 0);\n     this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n         .newRecordInstance(ApplicationAttemptId.class);\n \n     moveThreadInterval \u003d conf.getLong(\n         JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n         JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n \n-    hsManager \u003d new HistoryFileManager();\n+    hsManager \u003d createHistoryFileManager();\n     hsManager.init(conf);\n     try {\n       hsManager.initExisting();\n     } catch (IOException e) {\n       throw new YarnRuntimeException(\"Failed to intialize existing directories\", e);\n     }\n \n     storage \u003d ReflectionUtils.newInstance(conf.getClass(\n         JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n         HistoryStorage.class), conf);\n     if (storage instanceof Service) {\n       ((Service) storage).init(conf);\n     }\n     storage.setHistoryFileManager(hsManager);\n \n     super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    LOG.info(\"JobHistory Init\");\n    this.conf \u003d conf;\n    this.appID \u003d ApplicationId.newInstance(0, 0);\n    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationAttemptId.class);\n\n    moveThreadInterval \u003d conf.getLong(\n        JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n\n    hsManager \u003d createHistoryFileManager();\n    hsManager.init(conf);\n    try {\n      hsManager.initExisting();\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed to intialize existing directories\", e);\n    }\n\n    storage \u003d ReflectionUtils.newInstance(conf.getClass(\n        JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n        HistoryStorage.class), conf);\n    if (storage instanceof Service) {\n      ((Service) storage).init(conf);\n    }\n    storage.setHistoryFileManager(hsManager);\n\n    super.serviceInit(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "0928502029ef141759008997335ea2cd836a7154": {
      "type": "Ymultichange(Yrename,Ymodifierchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/06/13 8:54 AM",
      "commitName": "0928502029ef141759008997335ea2cd836a7154",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,29 @@\n-  public void init(Configuration conf) throws YarnRuntimeException {\n+  protected void serviceInit(Configuration conf) throws Exception {\n     LOG.info(\"JobHistory Init\");\n     this.conf \u003d conf;\n     this.appID \u003d ApplicationId.newInstance(0, 0);\n     this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n         .newRecordInstance(ApplicationAttemptId.class);\n \n     moveThreadInterval \u003d conf.getLong(\n         JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n         JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n \n     hsManager \u003d new HistoryFileManager();\n     hsManager.init(conf);\n     try {\n       hsManager.initExisting();\n     } catch (IOException e) {\n       throw new YarnRuntimeException(\"Failed to intialize existing directories\", e);\n     }\n \n     storage \u003d ReflectionUtils.newInstance(conf.getClass(\n         JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n         HistoryStorage.class), conf);\n     if (storage instanceof Service) {\n       ((Service) storage).init(conf);\n     }\n     storage.setHistoryFileManager(hsManager);\n \n-    super.init(conf);\n+    super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    LOG.info(\"JobHistory Init\");\n    this.conf \u003d conf;\n    this.appID \u003d ApplicationId.newInstance(0, 0);\n    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationAttemptId.class);\n\n    moveThreadInterval \u003d conf.getLong(\n        JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n\n    hsManager \u003d new HistoryFileManager();\n    hsManager.init(conf);\n    try {\n      hsManager.initExisting();\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed to intialize existing directories\", e);\n    }\n\n    storage \u003d ReflectionUtils.newInstance(conf.getClass(\n        JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n        HistoryStorage.class), conf);\n    if (storage instanceof Service) {\n      ((Service) storage).init(conf);\n    }\n    storage.setHistoryFileManager(hsManager);\n\n    super.serviceInit(conf);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
          "extendedDetails": {
            "oldValue": "init",
            "newValue": "serviceInit"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,29 @@\n-  public void init(Configuration conf) throws YarnRuntimeException {\n+  protected void serviceInit(Configuration conf) throws Exception {\n     LOG.info(\"JobHistory Init\");\n     this.conf \u003d conf;\n     this.appID \u003d ApplicationId.newInstance(0, 0);\n     this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n         .newRecordInstance(ApplicationAttemptId.class);\n \n     moveThreadInterval \u003d conf.getLong(\n         JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n         JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n \n     hsManager \u003d new HistoryFileManager();\n     hsManager.init(conf);\n     try {\n       hsManager.initExisting();\n     } catch (IOException e) {\n       throw new YarnRuntimeException(\"Failed to intialize existing directories\", e);\n     }\n \n     storage \u003d ReflectionUtils.newInstance(conf.getClass(\n         JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n         HistoryStorage.class), conf);\n     if (storage instanceof Service) {\n       ((Service) storage).init(conf);\n     }\n     storage.setHistoryFileManager(hsManager);\n \n-    super.init(conf);\n+    super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    LOG.info(\"JobHistory Init\");\n    this.conf \u003d conf;\n    this.appID \u003d ApplicationId.newInstance(0, 0);\n    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationAttemptId.class);\n\n    moveThreadInterval \u003d conf.getLong(\n        JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n\n    hsManager \u003d new HistoryFileManager();\n    hsManager.init(conf);\n    try {\n      hsManager.initExisting();\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed to intialize existing directories\", e);\n    }\n\n    storage \u003d ReflectionUtils.newInstance(conf.getClass(\n        JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n        HistoryStorage.class), conf);\n    if (storage instanceof Service) {\n      ((Service) storage).init(conf);\n    }\n    storage.setHistoryFileManager(hsManager);\n\n    super.serviceInit(conf);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[protected]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,29 @@\n-  public void init(Configuration conf) throws YarnRuntimeException {\n+  protected void serviceInit(Configuration conf) throws Exception {\n     LOG.info(\"JobHistory Init\");\n     this.conf \u003d conf;\n     this.appID \u003d ApplicationId.newInstance(0, 0);\n     this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n         .newRecordInstance(ApplicationAttemptId.class);\n \n     moveThreadInterval \u003d conf.getLong(\n         JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n         JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n \n     hsManager \u003d new HistoryFileManager();\n     hsManager.init(conf);\n     try {\n       hsManager.initExisting();\n     } catch (IOException e) {\n       throw new YarnRuntimeException(\"Failed to intialize existing directories\", e);\n     }\n \n     storage \u003d ReflectionUtils.newInstance(conf.getClass(\n         JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n         HistoryStorage.class), conf);\n     if (storage instanceof Service) {\n       ((Service) storage).init(conf);\n     }\n     storage.setHistoryFileManager(hsManager);\n \n-    super.init(conf);\n+    super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    LOG.info(\"JobHistory Init\");\n    this.conf \u003d conf;\n    this.appID \u003d ApplicationId.newInstance(0, 0);\n    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationAttemptId.class);\n\n    moveThreadInterval \u003d conf.getLong(\n        JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n\n    hsManager \u003d new HistoryFileManager();\n    hsManager.init(conf);\n    try {\n      hsManager.initExisting();\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed to intialize existing directories\", e);\n    }\n\n    storage \u003d ReflectionUtils.newInstance(conf.getClass(\n        JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n        HistoryStorage.class), conf);\n    if (storage instanceof Service) {\n      ((Service) storage).init(conf);\n    }\n    storage.setHistoryFileManager(hsManager);\n\n    super.serviceInit(conf);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
          "extendedDetails": {
            "oldValue": "[YarnRuntimeException]",
            "newValue": "[Exception]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,29 @@\n-  public void init(Configuration conf) throws YarnRuntimeException {\n+  protected void serviceInit(Configuration conf) throws Exception {\n     LOG.info(\"JobHistory Init\");\n     this.conf \u003d conf;\n     this.appID \u003d ApplicationId.newInstance(0, 0);\n     this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n         .newRecordInstance(ApplicationAttemptId.class);\n \n     moveThreadInterval \u003d conf.getLong(\n         JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n         JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n \n     hsManager \u003d new HistoryFileManager();\n     hsManager.init(conf);\n     try {\n       hsManager.initExisting();\n     } catch (IOException e) {\n       throw new YarnRuntimeException(\"Failed to intialize existing directories\", e);\n     }\n \n     storage \u003d ReflectionUtils.newInstance(conf.getClass(\n         JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n         HistoryStorage.class), conf);\n     if (storage instanceof Service) {\n       ((Service) storage).init(conf);\n     }\n     storage.setHistoryFileManager(hsManager);\n \n-    super.init(conf);\n+    super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    LOG.info(\"JobHistory Init\");\n    this.conf \u003d conf;\n    this.appID \u003d ApplicationId.newInstance(0, 0);\n    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationAttemptId.class);\n\n    moveThreadInterval \u003d conf.getLong(\n        JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n\n    hsManager \u003d new HistoryFileManager();\n    hsManager.init(conf);\n    try {\n      hsManager.initExisting();\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed to intialize existing directories\", e);\n    }\n\n    storage \u003d ReflectionUtils.newInstance(conf.getClass(\n        JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n        HistoryStorage.class), conf);\n    if (storage instanceof Service) {\n      ((Service) storage).init(conf);\n    }\n    storage.setHistoryFileManager(hsManager);\n\n    super.serviceInit(conf);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
          "extendedDetails": {}
        }
      ]
    },
    "a83fb61ac07c0468cbc7a38526e92683883dd932": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "YARN-635. Renamed YarnRemoteException to YarnException. Contributed by Siddharth Seth.\nMAPREDUCE-5301. Updated MR code to work with YARN-635 changes of renaming YarnRemoteException to YarnException. Contributed by Siddharth Seth\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1489283 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/06/13 9:05 PM",
      "commitName": "a83fb61ac07c0468cbc7a38526e92683883dd932",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "YARN-635. Renamed YarnRemoteException to YarnException. Contributed by Siddharth Seth.\nMAPREDUCE-5301. Updated MR code to work with YARN-635 changes of renaming YarnRemoteException to YarnException. Contributed by Siddharth Seth\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1489283 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "03/06/13 9:05 PM",
          "commitName": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "30/05/13 1:18 PM",
          "commitNameOld": "982753dc8e49ad51ad75698e0b30e2c75a4605a6",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 4.32,
          "commitsBetweenForRepo": 48,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,29 @@\n-  public void init(Configuration conf) throws YarnException {\n+  public void init(Configuration conf) throws YarnRuntimeException {\n     LOG.info(\"JobHistory Init\");\n     this.conf \u003d conf;\n     this.appID \u003d ApplicationId.newInstance(0, 0);\n     this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n         .newRecordInstance(ApplicationAttemptId.class);\n \n     moveThreadInterval \u003d conf.getLong(\n         JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n         JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n \n     hsManager \u003d new HistoryFileManager();\n     hsManager.init(conf);\n     try {\n       hsManager.initExisting();\n     } catch (IOException e) {\n-      throw new YarnException(\"Failed to intialize existing directories\", e);\n+      throw new YarnRuntimeException(\"Failed to intialize existing directories\", e);\n     }\n \n     storage \u003d ReflectionUtils.newInstance(conf.getClass(\n         JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n         HistoryStorage.class), conf);\n     if (storage instanceof Service) {\n       ((Service) storage).init(conf);\n     }\n     storage.setHistoryFileManager(hsManager);\n \n     super.init(conf);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void init(Configuration conf) throws YarnRuntimeException {\n    LOG.info(\"JobHistory Init\");\n    this.conf \u003d conf;\n    this.appID \u003d ApplicationId.newInstance(0, 0);\n    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationAttemptId.class);\n\n    moveThreadInterval \u003d conf.getLong(\n        JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n\n    hsManager \u003d new HistoryFileManager();\n    hsManager.init(conf);\n    try {\n      hsManager.initExisting();\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed to intialize existing directories\", e);\n    }\n\n    storage \u003d ReflectionUtils.newInstance(conf.getClass(\n        JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n        HistoryStorage.class), conf);\n    if (storage instanceof Service) {\n      ((Service) storage).init(conf);\n    }\n    storage.setHistoryFileManager(hsManager);\n\n    super.init(conf);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
          "extendedDetails": {
            "oldValue": "[YarnException]",
            "newValue": "[YarnRuntimeException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-635. Renamed YarnRemoteException to YarnException. Contributed by Siddharth Seth.\nMAPREDUCE-5301. Updated MR code to work with YARN-635 changes of renaming YarnRemoteException to YarnException. Contributed by Siddharth Seth\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1489283 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "03/06/13 9:05 PM",
          "commitName": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "30/05/13 1:18 PM",
          "commitNameOld": "982753dc8e49ad51ad75698e0b30e2c75a4605a6",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 4.32,
          "commitsBetweenForRepo": 48,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,29 @@\n-  public void init(Configuration conf) throws YarnException {\n+  public void init(Configuration conf) throws YarnRuntimeException {\n     LOG.info(\"JobHistory Init\");\n     this.conf \u003d conf;\n     this.appID \u003d ApplicationId.newInstance(0, 0);\n     this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n         .newRecordInstance(ApplicationAttemptId.class);\n \n     moveThreadInterval \u003d conf.getLong(\n         JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n         JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n \n     hsManager \u003d new HistoryFileManager();\n     hsManager.init(conf);\n     try {\n       hsManager.initExisting();\n     } catch (IOException e) {\n-      throw new YarnException(\"Failed to intialize existing directories\", e);\n+      throw new YarnRuntimeException(\"Failed to intialize existing directories\", e);\n     }\n \n     storage \u003d ReflectionUtils.newInstance(conf.getClass(\n         JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n         HistoryStorage.class), conf);\n     if (storage instanceof Service) {\n       ((Service) storage).init(conf);\n     }\n     storage.setHistoryFileManager(hsManager);\n \n     super.init(conf);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void init(Configuration conf) throws YarnRuntimeException {\n    LOG.info(\"JobHistory Init\");\n    this.conf \u003d conf;\n    this.appID \u003d ApplicationId.newInstance(0, 0);\n    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationAttemptId.class);\n\n    moveThreadInterval \u003d conf.getLong(\n        JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n\n    hsManager \u003d new HistoryFileManager();\n    hsManager.init(conf);\n    try {\n      hsManager.initExisting();\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed to intialize existing directories\", e);\n    }\n\n    storage \u003d ReflectionUtils.newInstance(conf.getClass(\n        JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n        HistoryStorage.class), conf);\n    if (storage instanceof Service) {\n      ((Service) storage).init(conf);\n    }\n    storage.setHistoryFileManager(hsManager);\n\n    super.init(conf);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
          "extendedDetails": {}
        }
      ]
    },
    "982753dc8e49ad51ad75698e0b30e2c75a4605a6": {
      "type": "Ybodychange",
      "commitMessage": "YARN-716. Making ApplicationID immutable. Contributed by Siddharth Seth.\nMAPREDUCE-5282. Updating MR App to use immutable ApplicationID after YARN-716. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1487994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/05/13 1:18 PM",
      "commitName": "982753dc8e49ad51ad75698e0b30e2c75a4605a6",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/04/12 6:59 PM",
      "commitNameOld": "7d04a96027ad75877b41b7cd8f67455dd13159d7",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 407.76,
      "commitsBetweenForRepo": 2287,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,29 @@\n   public void init(Configuration conf) throws YarnException {\n     LOG.info(\"JobHistory Init\");\n     this.conf \u003d conf;\n-    this.appID \u003d RecordFactoryProvider.getRecordFactory(conf)\n-        .newRecordInstance(ApplicationId.class);\n+    this.appID \u003d ApplicationId.newInstance(0, 0);\n     this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n         .newRecordInstance(ApplicationAttemptId.class);\n \n     moveThreadInterval \u003d conf.getLong(\n         JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n         JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n \n     hsManager \u003d new HistoryFileManager();\n     hsManager.init(conf);\n     try {\n       hsManager.initExisting();\n     } catch (IOException e) {\n       throw new YarnException(\"Failed to intialize existing directories\", e);\n     }\n \n     storage \u003d ReflectionUtils.newInstance(conf.getClass(\n         JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n         HistoryStorage.class), conf);\n     if (storage instanceof Service) {\n       ((Service) storage).init(conf);\n     }\n     storage.setHistoryFileManager(hsManager);\n \n     super.init(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void init(Configuration conf) throws YarnException {\n    LOG.info(\"JobHistory Init\");\n    this.conf \u003d conf;\n    this.appID \u003d ApplicationId.newInstance(0, 0);\n    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationAttemptId.class);\n\n    moveThreadInterval \u003d conf.getLong(\n        JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n\n    hsManager \u003d new HistoryFileManager();\n    hsManager.init(conf);\n    try {\n      hsManager.initExisting();\n    } catch (IOException e) {\n      throw new YarnException(\"Failed to intialize existing directories\", e);\n    }\n\n    storage \u003d ReflectionUtils.newInstance(conf.getClass(\n        JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n        HistoryStorage.class), conf);\n    if (storage instanceof Service) {\n      ((Service) storage).init(conf);\n    }\n    storage.setHistoryFileManager(hsManager);\n\n    super.init(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "7d04a96027ad75877b41b7cd8f67455dd13159d7": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3972. Fix locking and exception issues in JobHistory server. (Contributed by Robert Joseph Evans)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1327354 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/04/12 6:59 PM",
      "commitName": "7d04a96027ad75877b41b7cd8f67455dd13159d7",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "10/04/12 11:11 AM",
      "commitNameOld": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
      "commitAuthorOld": "Thomas Graves",
      "daysBetweenCommits": 7.32,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,30 @@\n   public void init(Configuration conf) throws YarnException {\n     LOG.info(\"JobHistory Init\");\n     this.conf \u003d conf;\n     this.appID \u003d RecordFactoryProvider.getRecordFactory(conf)\n         .newRecordInstance(ApplicationId.class);\n     this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n         .newRecordInstance(ApplicationAttemptId.class);\n \n     moveThreadInterval \u003d conf.getLong(\n         JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n         JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n-    numMoveThreads \u003d conf.getInt(JHAdminConfig.MR_HISTORY_MOVE_THREAD_COUNT,\n-        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_THREAD_COUNT);\n \n     hsManager \u003d new HistoryFileManager();\n     hsManager.init(conf);\n     try {\n       hsManager.initExisting();\n     } catch (IOException e) {\n       throw new YarnException(\"Failed to intialize existing directories\", e);\n     }\n \n     storage \u003d ReflectionUtils.newInstance(conf.getClass(\n         JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n         HistoryStorage.class), conf);\n     if (storage instanceof Service) {\n       ((Service) storage).init(conf);\n     }\n     storage.setHistoryFileManager(hsManager);\n \n     super.init(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void init(Configuration conf) throws YarnException {\n    LOG.info(\"JobHistory Init\");\n    this.conf \u003d conf;\n    this.appID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationId.class);\n    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationAttemptId.class);\n\n    moveThreadInterval \u003d conf.getLong(\n        JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n\n    hsManager \u003d new HistoryFileManager();\n    hsManager.init(conf);\n    try {\n      hsManager.initExisting();\n    } catch (IOException e) {\n      throw new YarnException(\"Failed to intialize existing directories\", e);\n    }\n\n    storage \u003d ReflectionUtils.newInstance(conf.getClass(\n        JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n        HistoryStorage.class), conf);\n    if (storage instanceof Service) {\n      ((Service) storage).init(conf);\n    }\n    storage.setHistoryFileManager(hsManager);\n\n    super.init(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311896 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/04/12 11:11 AM",
      "commitName": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
      "commitAuthor": "Thomas Graves",
      "commitDateOld": "06/03/12 3:21 PM",
      "commitNameOld": "c3a4de0ec0389064f5468180d1b9024f64b00f40",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 34.78,
      "commitsBetweenForRepo": 243,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,73 +1,32 @@\n   public void init(Configuration conf) throws YarnException {\n     LOG.info(\"JobHistory Init\");\n     this.conf \u003d conf;\n     this.appID \u003d RecordFactoryProvider.getRecordFactory(conf)\n         .newRecordInstance(ApplicationId.class);\n     this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n-    .newRecordInstance(ApplicationAttemptId.class);\n+        .newRecordInstance(ApplicationAttemptId.class);\n \n-    debugMode \u003d conf.getBoolean(JHAdminConfig.MR_HISTORY_DEBUG_MODE, false);\n-    serialNumberLowDigits \u003d debugMode ? 1 : 3;\n-    serialNumberFormat \u003d (\"%0\"\n-        + (JobHistoryUtils.SERIAL_NUMBER_DIRECTORY_DIGITS \n-            + serialNumberLowDigits) + \"d\");\n-\n-    String doneDirPrefix \u003d null;\n-    doneDirPrefix \u003d JobHistoryUtils.getConfiguredHistoryServerDoneDirPrefix(conf);\n-    try {\n-      doneDirPrefixPath \u003d FileContext.getFileContext(conf).makeQualified(\n-          new Path(doneDirPrefix));\n-      doneDirFc \u003d FileContext.getFileContext(doneDirPrefixPath.toUri(), conf);\n-      mkdir(doneDirFc, doneDirPrefixPath, new FsPermission(\n-          JobHistoryUtils.HISTORY_DONE_DIR_PERMISSION));\n-    } catch (IOException e) {\n-      throw new YarnException(\"Error creating done directory: [\" +\n-          doneDirPrefixPath + \"]\", e);\n-    }\n-\n-    String intermediateDoneDirPrefix \u003d null;\n-    intermediateDoneDirPrefix \u003d JobHistoryUtils\n-        .getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n-    try {\n-      intermediateDoneDirPath \u003d FileContext.getFileContext(conf)\n-          .makeQualified(new Path(intermediateDoneDirPrefix));\n-      intermediateDoneDirFc \u003d FileContext.getFileContext(\n-          intermediateDoneDirPath.toUri(), conf);\n-      mkdir(intermediateDoneDirFc, intermediateDoneDirPath, new FsPermission(\n-          JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS.toShort()));\n-    } catch (IOException e) {\n-      LOG.info(\"error creating done directory on dfs \" + e);\n-      throw new YarnException(\"Error creating intermediate done directory: [\" \n-          + intermediateDoneDirPath + \"]\", e);\n-    }\n-    \n-    this.aclsMgr \u003d new JobACLsManager(conf);\n-    \n-    jobListCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_JOBLIST_CACHE_SIZE,\n-        DEFAULT_JOBLIST_CACHE_SIZE);\n-    loadedJobCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_LOADED_JOB_CACHE_SIZE,\n-        DEFAULT_LOADEDJOB_CACHE_SIZE);\n-    dateStringCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_DATESTRING_CACHE_SIZE,\n-        DEFAULT_DATESTRING_CACHE_SIZE);\n-    moveThreadInterval \u003d\n-        conf.getLong(JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n-            DEFAULT_MOVE_THREAD_INTERVAL);\n+    moveThreadInterval \u003d conf.getLong(\n+        JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n+        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n     numMoveThreads \u003d conf.getInt(JHAdminConfig.MR_HISTORY_MOVE_THREAD_COUNT,\n-        DEFAULT_MOVE_THREAD_COUNT);\n-    \n-    loadedJobCache \u003d\n-        Collections.synchronizedMap(new LinkedHashMap\u003cJobId, Job\u003e(\n-            loadedJobCacheSize + 1, 0.75f, true) {\n-          @Override\n-          public boolean removeEldestEntry(final Map.Entry\u003cJobId, Job\u003e eldest) {\n-            return super.size() \u003e loadedJobCacheSize;\n-          }\n-        });\n-    \n+        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_THREAD_COUNT);\n+\n+    hsManager \u003d new HistoryFileManager();\n+    hsManager.init(conf);\n     try {\n-      initExisting();\n+      hsManager.initExisting();\n     } catch (IOException e) {\n       throw new YarnException(\"Failed to intialize existing directories\", e);\n     }\n+\n+    storage \u003d ReflectionUtils.newInstance(conf.getClass(\n+        JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n+        HistoryStorage.class), conf);\n+    if (storage instanceof Service) {\n+      ((Service) storage).init(conf);\n+    }\n+    storage.setHistoryFileManager(hsManager);\n+\n     super.init(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void init(Configuration conf) throws YarnException {\n    LOG.info(\"JobHistory Init\");\n    this.conf \u003d conf;\n    this.appID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationId.class);\n    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationAttemptId.class);\n\n    moveThreadInterval \u003d conf.getLong(\n        JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_INTERVAL_MS);\n    numMoveThreads \u003d conf.getInt(JHAdminConfig.MR_HISTORY_MOVE_THREAD_COUNT,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_THREAD_COUNT);\n\n    hsManager \u003d new HistoryFileManager();\n    hsManager.init(conf);\n    try {\n      hsManager.initExisting();\n    } catch (IOException e) {\n      throw new YarnException(\"Failed to intialize existing directories\", e);\n    }\n\n    storage \u003d ReflectionUtils.newInstance(conf.getClass(\n        JHAdminConfig.MR_HISTORY_STORAGE, CachedHistoryStorage.class,\n        HistoryStorage.class), conf);\n    if (storage instanceof Service) {\n      ((Service) storage).init(conf);\n    }\n    storage.setHistoryFileManager(hsManager);\n\n    super.init(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "7475e836dc2bdd29142eaf210262fba354b745ed": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3901. Modified JobHistory records in YARN to lazily load job and task reports so as to improve UI response times. Contributed by Siddarth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1294417 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/02/12 4:32 PM",
      "commitName": "7475e836dc2bdd29142eaf210262fba354b745ed",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "18/01/12 2:10 PM",
      "commitNameOld": "10325d97329c214bb3899c8535df5a366bc86d2f",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 40.1,
      "commitsBetweenForRepo": 264,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,63 +1,73 @@\n   public void init(Configuration conf) throws YarnException {\n     LOG.info(\"JobHistory Init\");\n     this.conf \u003d conf;\n     this.appID \u003d RecordFactoryProvider.getRecordFactory(conf)\n         .newRecordInstance(ApplicationId.class);\n     this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n     .newRecordInstance(ApplicationAttemptId.class);\n \n     debugMode \u003d conf.getBoolean(JHAdminConfig.MR_HISTORY_DEBUG_MODE, false);\n     serialNumberLowDigits \u003d debugMode ? 1 : 3;\n     serialNumberFormat \u003d (\"%0\"\n         + (JobHistoryUtils.SERIAL_NUMBER_DIRECTORY_DIGITS \n             + serialNumberLowDigits) + \"d\");\n \n     String doneDirPrefix \u003d null;\n     doneDirPrefix \u003d JobHistoryUtils.getConfiguredHistoryServerDoneDirPrefix(conf);\n     try {\n       doneDirPrefixPath \u003d FileContext.getFileContext(conf).makeQualified(\n           new Path(doneDirPrefix));\n       doneDirFc \u003d FileContext.getFileContext(doneDirPrefixPath.toUri(), conf);\n       mkdir(doneDirFc, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_DONE_DIR_PERMISSION));\n     } catch (IOException e) {\n       throw new YarnException(\"Error creating done directory: [\" +\n           doneDirPrefixPath + \"]\", e);\n     }\n \n     String intermediateDoneDirPrefix \u003d null;\n     intermediateDoneDirPrefix \u003d JobHistoryUtils\n         .getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n     try {\n       intermediateDoneDirPath \u003d FileContext.getFileContext(conf)\n           .makeQualified(new Path(intermediateDoneDirPrefix));\n       intermediateDoneDirFc \u003d FileContext.getFileContext(\n           intermediateDoneDirPath.toUri(), conf);\n       mkdir(intermediateDoneDirFc, intermediateDoneDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS.toShort()));\n     } catch (IOException e) {\n       LOG.info(\"error creating done directory on dfs \" + e);\n       throw new YarnException(\"Error creating intermediate done directory: [\" \n           + intermediateDoneDirPath + \"]\", e);\n     }\n     \n     this.aclsMgr \u003d new JobACLsManager(conf);\n     \n     jobListCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_JOBLIST_CACHE_SIZE,\n         DEFAULT_JOBLIST_CACHE_SIZE);\n     loadedJobCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_LOADED_JOB_CACHE_SIZE,\n         DEFAULT_LOADEDJOB_CACHE_SIZE);\n     dateStringCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_DATESTRING_CACHE_SIZE,\n         DEFAULT_DATESTRING_CACHE_SIZE);\n     moveThreadInterval \u003d\n         conf.getLong(JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n             DEFAULT_MOVE_THREAD_INTERVAL);\n     numMoveThreads \u003d conf.getInt(JHAdminConfig.MR_HISTORY_MOVE_THREAD_COUNT,\n         DEFAULT_MOVE_THREAD_COUNT);\n+    \n+    loadedJobCache \u003d\n+        Collections.synchronizedMap(new LinkedHashMap\u003cJobId, Job\u003e(\n+            loadedJobCacheSize + 1, 0.75f, true) {\n+          @Override\n+          public boolean removeEldestEntry(final Map.Entry\u003cJobId, Job\u003e eldest) {\n+            return super.size() \u003e loadedJobCacheSize;\n+          }\n+        });\n+    \n     try {\n       initExisting();\n     } catch (IOException e) {\n       throw new YarnException(\"Failed to intialize existing directories\", e);\n     }\n     super.init(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void init(Configuration conf) throws YarnException {\n    LOG.info(\"JobHistory Init\");\n    this.conf \u003d conf;\n    this.appID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationId.class);\n    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n    .newRecordInstance(ApplicationAttemptId.class);\n\n    debugMode \u003d conf.getBoolean(JHAdminConfig.MR_HISTORY_DEBUG_MODE, false);\n    serialNumberLowDigits \u003d debugMode ? 1 : 3;\n    serialNumberFormat \u003d (\"%0\"\n        + (JobHistoryUtils.SERIAL_NUMBER_DIRECTORY_DIGITS \n            + serialNumberLowDigits) + \"d\");\n\n    String doneDirPrefix \u003d null;\n    doneDirPrefix \u003d JobHistoryUtils.getConfiguredHistoryServerDoneDirPrefix(conf);\n    try {\n      doneDirPrefixPath \u003d FileContext.getFileContext(conf).makeQualified(\n          new Path(doneDirPrefix));\n      doneDirFc \u003d FileContext.getFileContext(doneDirPrefixPath.toUri(), conf);\n      mkdir(doneDirFc, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_DONE_DIR_PERMISSION));\n    } catch (IOException e) {\n      throw new YarnException(\"Error creating done directory: [\" +\n          doneDirPrefixPath + \"]\", e);\n    }\n\n    String intermediateDoneDirPrefix \u003d null;\n    intermediateDoneDirPrefix \u003d JobHistoryUtils\n        .getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n    try {\n      intermediateDoneDirPath \u003d FileContext.getFileContext(conf)\n          .makeQualified(new Path(intermediateDoneDirPrefix));\n      intermediateDoneDirFc \u003d FileContext.getFileContext(\n          intermediateDoneDirPath.toUri(), conf);\n      mkdir(intermediateDoneDirFc, intermediateDoneDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS.toShort()));\n    } catch (IOException e) {\n      LOG.info(\"error creating done directory on dfs \" + e);\n      throw new YarnException(\"Error creating intermediate done directory: [\" \n          + intermediateDoneDirPath + \"]\", e);\n    }\n    \n    this.aclsMgr \u003d new JobACLsManager(conf);\n    \n    jobListCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_JOBLIST_CACHE_SIZE,\n        DEFAULT_JOBLIST_CACHE_SIZE);\n    loadedJobCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_LOADED_JOB_CACHE_SIZE,\n        DEFAULT_LOADEDJOB_CACHE_SIZE);\n    dateStringCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_DATESTRING_CACHE_SIZE,\n        DEFAULT_DATESTRING_CACHE_SIZE);\n    moveThreadInterval \u003d\n        conf.getLong(JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n            DEFAULT_MOVE_THREAD_INTERVAL);\n    numMoveThreads \u003d conf.getInt(JHAdminConfig.MR_HISTORY_MOVE_THREAD_COUNT,\n        DEFAULT_MOVE_THREAD_COUNT);\n    \n    loadedJobCache \u003d\n        Collections.synchronizedMap(new LinkedHashMap\u003cJobId, Job\u003e(\n            loadedJobCacheSize + 1, 0.75f, true) {\n          @Override\n          public boolean removeEldestEntry(final Map.Entry\u003cJobId, Job\u003e eldest) {\n            return super.size() \u003e loadedJobCacheSize;\n          }\n        });\n    \n    try {\n      initExisting();\n    } catch (IOException e) {\n      throw new YarnException(\"Failed to intialize existing directories\", e);\n    }\n    super.init(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "68fa208b1cc991dec2577a07b3199a6935a71065": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3103. Implement Job ACLs for MRAppMaster. (mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195761 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/10/11 6:51 PM",
      "commitName": "68fa208b1cc991dec2577a07b3199a6935a71065",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "16/10/11 12:27 PM",
      "commitNameOld": "68328ae92632afc9cdd6e75b7a8d832723ddbe3b",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 15.27,
      "commitsBetweenForRepo": 164,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,63 +1,63 @@\n   public void init(Configuration conf) throws YarnException {\n     LOG.info(\"JobHistory Init\");\n     this.conf \u003d conf;\n     this.appID \u003d RecordFactoryProvider.getRecordFactory(conf)\n         .newRecordInstance(ApplicationId.class);\n     this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n     .newRecordInstance(ApplicationAttemptId.class);\n \n     debugMode \u003d conf.getBoolean(JHAdminConfig.MR_HISTORY_DEBUG_MODE, false);\n     serialNumberLowDigits \u003d debugMode ? 1 : 3;\n     serialNumberFormat \u003d (\"%0\"\n         + (JobHistoryUtils.SERIAL_NUMBER_DIRECTORY_DIGITS \n             + serialNumberLowDigits) + \"d\");\n \n     String doneDirPrefix \u003d null;\n     doneDirPrefix \u003d JobHistoryUtils.getConfiguredHistoryServerDoneDirPrefix(conf);\n     try {\n       doneDirPrefixPath \u003d FileContext.getFileContext(conf).makeQualified(\n           new Path(doneDirPrefix));\n       doneDirFc \u003d FileContext.getFileContext(doneDirPrefixPath.toUri(), conf);\n       mkdir(doneDirFc, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_DONE_DIR_PERMISSION));\n     } catch (IOException e) {\n       throw new YarnException(\"Error creating done directory: [\" +\n           doneDirPrefixPath + \"]\", e);\n     }\n \n     String intermediateDoneDirPrefix \u003d null;\n     intermediateDoneDirPrefix \u003d JobHistoryUtils\n         .getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n     try {\n       intermediateDoneDirPath \u003d FileContext.getFileContext(conf)\n           .makeQualified(new Path(intermediateDoneDirPrefix));\n       intermediateDoneDirFc \u003d FileContext.getFileContext(\n           intermediateDoneDirPath.toUri(), conf);\n       mkdir(intermediateDoneDirFc, intermediateDoneDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS.toShort()));\n     } catch (IOException e) {\n       LOG.info(\"error creating done directory on dfs \" + e);\n       throw new YarnException(\"Error creating intermediate done directory: [\" \n           + intermediateDoneDirPath + \"]\", e);\n     }\n     \n-    \n+    this.aclsMgr \u003d new JobACLsManager(conf);\n     \n     jobListCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_JOBLIST_CACHE_SIZE,\n         DEFAULT_JOBLIST_CACHE_SIZE);\n     loadedJobCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_LOADED_JOB_CACHE_SIZE,\n         DEFAULT_LOADEDJOB_CACHE_SIZE);\n     dateStringCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_DATESTRING_CACHE_SIZE,\n         DEFAULT_DATESTRING_CACHE_SIZE);\n     moveThreadInterval \u003d\n         conf.getLong(JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n             DEFAULT_MOVE_THREAD_INTERVAL);\n     numMoveThreads \u003d conf.getInt(JHAdminConfig.MR_HISTORY_MOVE_THREAD_COUNT,\n         DEFAULT_MOVE_THREAD_COUNT);\n     try {\n       initExisting();\n     } catch (IOException e) {\n       throw new YarnException(\"Failed to intialize existing directories\", e);\n     }\n     super.init(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void init(Configuration conf) throws YarnException {\n    LOG.info(\"JobHistory Init\");\n    this.conf \u003d conf;\n    this.appID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationId.class);\n    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n    .newRecordInstance(ApplicationAttemptId.class);\n\n    debugMode \u003d conf.getBoolean(JHAdminConfig.MR_HISTORY_DEBUG_MODE, false);\n    serialNumberLowDigits \u003d debugMode ? 1 : 3;\n    serialNumberFormat \u003d (\"%0\"\n        + (JobHistoryUtils.SERIAL_NUMBER_DIRECTORY_DIGITS \n            + serialNumberLowDigits) + \"d\");\n\n    String doneDirPrefix \u003d null;\n    doneDirPrefix \u003d JobHistoryUtils.getConfiguredHistoryServerDoneDirPrefix(conf);\n    try {\n      doneDirPrefixPath \u003d FileContext.getFileContext(conf).makeQualified(\n          new Path(doneDirPrefix));\n      doneDirFc \u003d FileContext.getFileContext(doneDirPrefixPath.toUri(), conf);\n      mkdir(doneDirFc, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_DONE_DIR_PERMISSION));\n    } catch (IOException e) {\n      throw new YarnException(\"Error creating done directory: [\" +\n          doneDirPrefixPath + \"]\", e);\n    }\n\n    String intermediateDoneDirPrefix \u003d null;\n    intermediateDoneDirPrefix \u003d JobHistoryUtils\n        .getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n    try {\n      intermediateDoneDirPath \u003d FileContext.getFileContext(conf)\n          .makeQualified(new Path(intermediateDoneDirPrefix));\n      intermediateDoneDirFc \u003d FileContext.getFileContext(\n          intermediateDoneDirPath.toUri(), conf);\n      mkdir(intermediateDoneDirFc, intermediateDoneDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS.toShort()));\n    } catch (IOException e) {\n      LOG.info(\"error creating done directory on dfs \" + e);\n      throw new YarnException(\"Error creating intermediate done directory: [\" \n          + intermediateDoneDirPath + \"]\", e);\n    }\n    \n    this.aclsMgr \u003d new JobACLsManager(conf);\n    \n    jobListCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_JOBLIST_CACHE_SIZE,\n        DEFAULT_JOBLIST_CACHE_SIZE);\n    loadedJobCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_LOADED_JOB_CACHE_SIZE,\n        DEFAULT_LOADEDJOB_CACHE_SIZE);\n    dateStringCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_DATESTRING_CACHE_SIZE,\n        DEFAULT_DATESTRING_CACHE_SIZE);\n    moveThreadInterval \u003d\n        conf.getLong(JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n            DEFAULT_MOVE_THREAD_INTERVAL);\n    numMoveThreads \u003d conf.getInt(JHAdminConfig.MR_HISTORY_MOVE_THREAD_COUNT,\n        DEFAULT_MOVE_THREAD_COUNT);\n    try {\n      initExisting();\n    } catch (IOException e) {\n      throw new YarnException(\"Failed to intialize existing directories\", e);\n    }\n    super.init(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "fafe8cd28e726566509c679e19d7da622f29f90d": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2864. Normalize configuration variable names for YARN. Contributed by Robert Evans.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1166955 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/09/11 6:44 PM",
      "commitName": "fafe8cd28e726566509c679e19d7da622f29f90d",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 15.06,
      "commitsBetweenForRepo": 86,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,54 @@\n   public void init(Configuration conf) throws YarnException {\n     LOG.info(\"JobHistory Init\");\n     this.conf \u003d conf;\n     this.appID \u003d RecordFactoryProvider.getRecordFactory(conf)\n         .newRecordInstance(ApplicationId.class);\n     this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n     .newRecordInstance(ApplicationAttemptId.class);\n \n-    debugMode \u003d conf.getBoolean(JHConfig.HISTORY_DEBUG_MODE_KEY, false);\n+    debugMode \u003d conf.getBoolean(JHAdminConfig.MR_HISTORY_DEBUG_MODE, false);\n     serialNumberLowDigits \u003d debugMode ? 1 : 3;\n     serialNumberFormat \u003d (\"%0\"\n         + (JobHistoryUtils.SERIAL_NUMBER_DIRECTORY_DIGITS + serialNumberLowDigits) + \"d\");\n \n     String doneDirPrefix \u003d null;\n     doneDirPrefix \u003d JobHistoryUtils.getConfiguredHistoryServerDoneDirPrefix(conf);\n     try {\n       doneDirPrefixPath \u003d FileContext.getFileContext(conf).makeQualified(\n           new Path(doneDirPrefix));\n       doneDirFc \u003d FileContext.getFileContext(doneDirPrefixPath.toUri(), conf);\n       mkdir(doneDirFc, doneDirPrefixPath, new FsPermission(JobHistoryUtils.HISTORY_DONE_DIR_PERMISSION));\n     } catch (IOException e) {\n       throw new YarnException(\"Error creating done directory: [\" + doneDirPrefixPath + \"]\", e);\n     }\n \n     String intermediateDoneDirPrefix \u003d null;\n     intermediateDoneDirPrefix \u003d JobHistoryUtils\n         .getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n     try {\n       intermediateDoneDirPath \u003d FileContext.getFileContext(conf)\n           .makeQualified(new Path(intermediateDoneDirPrefix));\n       intermediateDoneDirFc \u003d FileContext.getFileContext(\n           intermediateDoneDirPath.toUri(), conf);\n       mkdir(intermediateDoneDirFc, intermediateDoneDirPath, new FsPermission(JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS.toShort()));\n     } catch (IOException e) {\n       LOG.info(\"error creating done directory on dfs \" + e);\n       throw new YarnException(\"Error creating intermediate done directory: [\" + intermediateDoneDirPath + \"]\", e);\n     }\n     \n     \n     \n-    jobListCacheSize \u003d conf.getInt(JHConfig.HISTORY_SERVER_JOBLIST_CACHE_SIZE_KEY, DEFAULT_JOBLIST_CACHE_SIZE);\n-    loadedJobCacheSize \u003d conf.getInt(JHConfig.HISTORY_SERVER_LOADED_JOB_CACHE_SIZE_KEY, DEFAULT_LOADEDJOB_CACHE_SIZE);\n-    dateStringCacheSize \u003d conf.getInt(JHConfig.HISTORY_SERVER_DATESTRING_CACHE_SIZE_KEY, DEFAULT_DATESTRING_CACHE_SIZE);\n+    jobListCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_JOBLIST_CACHE_SIZE, DEFAULT_JOBLIST_CACHE_SIZE);\n+    loadedJobCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_LOADED_JOB_CACHE_SIZE, DEFAULT_LOADEDJOB_CACHE_SIZE);\n+    dateStringCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_DATESTRING_CACHE_SIZE, DEFAULT_DATESTRING_CACHE_SIZE);\n     moveThreadInterval \u003d\n-        conf.getLong(JHConfig.HISTORY_SERVER_MOVE_THREAD_INTERVAL,\n+        conf.getLong(JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n             DEFAULT_MOVE_THREAD_INTERVAL);\n-    numMoveThreads \u003d conf.getInt(JHConfig.HISTORY_SERVER_NUM_MOVE_THREADS, DEFAULT_MOVE_THREAD_COUNT);\n+    numMoveThreads \u003d conf.getInt(JHAdminConfig.MR_HISTORY_MOVE_THREAD_COUNT, DEFAULT_MOVE_THREAD_COUNT);\n     try {\n     initExisting();\n     } catch (IOException e) {\n       throw new YarnException(\"Failed to intialize existing directories\", e);\n     }\n     super.init(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void init(Configuration conf) throws YarnException {\n    LOG.info(\"JobHistory Init\");\n    this.conf \u003d conf;\n    this.appID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationId.class);\n    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n    .newRecordInstance(ApplicationAttemptId.class);\n\n    debugMode \u003d conf.getBoolean(JHAdminConfig.MR_HISTORY_DEBUG_MODE, false);\n    serialNumberLowDigits \u003d debugMode ? 1 : 3;\n    serialNumberFormat \u003d (\"%0\"\n        + (JobHistoryUtils.SERIAL_NUMBER_DIRECTORY_DIGITS + serialNumberLowDigits) + \"d\");\n\n    String doneDirPrefix \u003d null;\n    doneDirPrefix \u003d JobHistoryUtils.getConfiguredHistoryServerDoneDirPrefix(conf);\n    try {\n      doneDirPrefixPath \u003d FileContext.getFileContext(conf).makeQualified(\n          new Path(doneDirPrefix));\n      doneDirFc \u003d FileContext.getFileContext(doneDirPrefixPath.toUri(), conf);\n      mkdir(doneDirFc, doneDirPrefixPath, new FsPermission(JobHistoryUtils.HISTORY_DONE_DIR_PERMISSION));\n    } catch (IOException e) {\n      throw new YarnException(\"Error creating done directory: [\" + doneDirPrefixPath + \"]\", e);\n    }\n\n    String intermediateDoneDirPrefix \u003d null;\n    intermediateDoneDirPrefix \u003d JobHistoryUtils\n        .getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n    try {\n      intermediateDoneDirPath \u003d FileContext.getFileContext(conf)\n          .makeQualified(new Path(intermediateDoneDirPrefix));\n      intermediateDoneDirFc \u003d FileContext.getFileContext(\n          intermediateDoneDirPath.toUri(), conf);\n      mkdir(intermediateDoneDirFc, intermediateDoneDirPath, new FsPermission(JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS.toShort()));\n    } catch (IOException e) {\n      LOG.info(\"error creating done directory on dfs \" + e);\n      throw new YarnException(\"Error creating intermediate done directory: [\" + intermediateDoneDirPath + \"]\", e);\n    }\n    \n    \n    \n    jobListCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_JOBLIST_CACHE_SIZE, DEFAULT_JOBLIST_CACHE_SIZE);\n    loadedJobCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_LOADED_JOB_CACHE_SIZE, DEFAULT_LOADEDJOB_CACHE_SIZE);\n    dateStringCacheSize \u003d conf.getInt(JHAdminConfig.MR_HISTORY_DATESTRING_CACHE_SIZE, DEFAULT_DATESTRING_CACHE_SIZE);\n    moveThreadInterval \u003d\n        conf.getLong(JHAdminConfig.MR_HISTORY_MOVE_INTERVAL_MS,\n            DEFAULT_MOVE_THREAD_INTERVAL);\n    numMoveThreads \u003d conf.getInt(JHAdminConfig.MR_HISTORY_MOVE_THREAD_COUNT, DEFAULT_MOVE_THREAD_COUNT);\n    try {\n    initExisting();\n    } catch (IOException e) {\n      throw new YarnException(\"Failed to intialize existing directories\", e);\n    }\n    super.init(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void init(Configuration conf) throws YarnException {\n    LOG.info(\"JobHistory Init\");\n    this.conf \u003d conf;\n    this.appID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationId.class);\n    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n    .newRecordInstance(ApplicationAttemptId.class);\n\n    debugMode \u003d conf.getBoolean(JHConfig.HISTORY_DEBUG_MODE_KEY, false);\n    serialNumberLowDigits \u003d debugMode ? 1 : 3;\n    serialNumberFormat \u003d (\"%0\"\n        + (JobHistoryUtils.SERIAL_NUMBER_DIRECTORY_DIGITS + serialNumberLowDigits) + \"d\");\n\n    String doneDirPrefix \u003d null;\n    doneDirPrefix \u003d JobHistoryUtils.getConfiguredHistoryServerDoneDirPrefix(conf);\n    try {\n      doneDirPrefixPath \u003d FileContext.getFileContext(conf).makeQualified(\n          new Path(doneDirPrefix));\n      doneDirFc \u003d FileContext.getFileContext(doneDirPrefixPath.toUri(), conf);\n      mkdir(doneDirFc, doneDirPrefixPath, new FsPermission(JobHistoryUtils.HISTORY_DONE_DIR_PERMISSION));\n    } catch (IOException e) {\n      throw new YarnException(\"Error creating done directory: [\" + doneDirPrefixPath + \"]\", e);\n    }\n\n    String intermediateDoneDirPrefix \u003d null;\n    intermediateDoneDirPrefix \u003d JobHistoryUtils\n        .getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n    try {\n      intermediateDoneDirPath \u003d FileContext.getFileContext(conf)\n          .makeQualified(new Path(intermediateDoneDirPrefix));\n      intermediateDoneDirFc \u003d FileContext.getFileContext(\n          intermediateDoneDirPath.toUri(), conf);\n      mkdir(intermediateDoneDirFc, intermediateDoneDirPath, new FsPermission(JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS.toShort()));\n    } catch (IOException e) {\n      LOG.info(\"error creating done directory on dfs \" + e);\n      throw new YarnException(\"Error creating intermediate done directory: [\" + intermediateDoneDirPath + \"]\", e);\n    }\n    \n    \n    \n    jobListCacheSize \u003d conf.getInt(JHConfig.HISTORY_SERVER_JOBLIST_CACHE_SIZE_KEY, DEFAULT_JOBLIST_CACHE_SIZE);\n    loadedJobCacheSize \u003d conf.getInt(JHConfig.HISTORY_SERVER_LOADED_JOB_CACHE_SIZE_KEY, DEFAULT_LOADEDJOB_CACHE_SIZE);\n    dateStringCacheSize \u003d conf.getInt(JHConfig.HISTORY_SERVER_DATESTRING_CACHE_SIZE_KEY, DEFAULT_DATESTRING_CACHE_SIZE);\n    moveThreadInterval \u003d\n        conf.getLong(JHConfig.HISTORY_SERVER_MOVE_THREAD_INTERVAL,\n            DEFAULT_MOVE_THREAD_INTERVAL);\n    numMoveThreads \u003d conf.getInt(JHConfig.HISTORY_SERVER_NUM_MOVE_THREADS, DEFAULT_MOVE_THREAD_COUNT);\n    try {\n    initExisting();\n    } catch (IOException e) {\n      throw new YarnException(\"Failed to intialize existing directories\", e);\n    }\n    super.init(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,54 @@\n+  public void init(Configuration conf) throws YarnException {\n+    LOG.info(\"JobHistory Init\");\n+    this.conf \u003d conf;\n+    this.appID \u003d RecordFactoryProvider.getRecordFactory(conf)\n+        .newRecordInstance(ApplicationId.class);\n+    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n+    .newRecordInstance(ApplicationAttemptId.class);\n+\n+    debugMode \u003d conf.getBoolean(JHConfig.HISTORY_DEBUG_MODE_KEY, false);\n+    serialNumberLowDigits \u003d debugMode ? 1 : 3;\n+    serialNumberFormat \u003d (\"%0\"\n+        + (JobHistoryUtils.SERIAL_NUMBER_DIRECTORY_DIGITS + serialNumberLowDigits) + \"d\");\n+\n+    String doneDirPrefix \u003d null;\n+    doneDirPrefix \u003d JobHistoryUtils.getConfiguredHistoryServerDoneDirPrefix(conf);\n+    try {\n+      doneDirPrefixPath \u003d FileContext.getFileContext(conf).makeQualified(\n+          new Path(doneDirPrefix));\n+      doneDirFc \u003d FileContext.getFileContext(doneDirPrefixPath.toUri(), conf);\n+      mkdir(doneDirFc, doneDirPrefixPath, new FsPermission(JobHistoryUtils.HISTORY_DONE_DIR_PERMISSION));\n+    } catch (IOException e) {\n+      throw new YarnException(\"Error creating done directory: [\" + doneDirPrefixPath + \"]\", e);\n+    }\n+\n+    String intermediateDoneDirPrefix \u003d null;\n+    intermediateDoneDirPrefix \u003d JobHistoryUtils\n+        .getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n+    try {\n+      intermediateDoneDirPath \u003d FileContext.getFileContext(conf)\n+          .makeQualified(new Path(intermediateDoneDirPrefix));\n+      intermediateDoneDirFc \u003d FileContext.getFileContext(\n+          intermediateDoneDirPath.toUri(), conf);\n+      mkdir(intermediateDoneDirFc, intermediateDoneDirPath, new FsPermission(JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS.toShort()));\n+    } catch (IOException e) {\n+      LOG.info(\"error creating done directory on dfs \" + e);\n+      throw new YarnException(\"Error creating intermediate done directory: [\" + intermediateDoneDirPath + \"]\", e);\n+    }\n+    \n+    \n+    \n+    jobListCacheSize \u003d conf.getInt(JHConfig.HISTORY_SERVER_JOBLIST_CACHE_SIZE_KEY, DEFAULT_JOBLIST_CACHE_SIZE);\n+    loadedJobCacheSize \u003d conf.getInt(JHConfig.HISTORY_SERVER_LOADED_JOB_CACHE_SIZE_KEY, DEFAULT_LOADEDJOB_CACHE_SIZE);\n+    dateStringCacheSize \u003d conf.getInt(JHConfig.HISTORY_SERVER_DATESTRING_CACHE_SIZE_KEY, DEFAULT_DATESTRING_CACHE_SIZE);\n+    moveThreadInterval \u003d\n+        conf.getLong(JHConfig.HISTORY_SERVER_MOVE_THREAD_INTERVAL,\n+            DEFAULT_MOVE_THREAD_INTERVAL);\n+    numMoveThreads \u003d conf.getInt(JHConfig.HISTORY_SERVER_NUM_MOVE_THREADS, DEFAULT_MOVE_THREAD_COUNT);\n+    try {\n+    initExisting();\n+    } catch (IOException e) {\n+      throw new YarnException(\"Failed to intialize existing directories\", e);\n+    }\n+    super.init(conf);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void init(Configuration conf) throws YarnException {\n    LOG.info(\"JobHistory Init\");\n    this.conf \u003d conf;\n    this.appID \u003d RecordFactoryProvider.getRecordFactory(conf)\n        .newRecordInstance(ApplicationId.class);\n    this.appAttemptID \u003d RecordFactoryProvider.getRecordFactory(conf)\n    .newRecordInstance(ApplicationAttemptId.class);\n\n    debugMode \u003d conf.getBoolean(JHConfig.HISTORY_DEBUG_MODE_KEY, false);\n    serialNumberLowDigits \u003d debugMode ? 1 : 3;\n    serialNumberFormat \u003d (\"%0\"\n        + (JobHistoryUtils.SERIAL_NUMBER_DIRECTORY_DIGITS + serialNumberLowDigits) + \"d\");\n\n    String doneDirPrefix \u003d null;\n    doneDirPrefix \u003d JobHistoryUtils.getConfiguredHistoryServerDoneDirPrefix(conf);\n    try {\n      doneDirPrefixPath \u003d FileContext.getFileContext(conf).makeQualified(\n          new Path(doneDirPrefix));\n      doneDirFc \u003d FileContext.getFileContext(doneDirPrefixPath.toUri(), conf);\n      mkdir(doneDirFc, doneDirPrefixPath, new FsPermission(JobHistoryUtils.HISTORY_DONE_DIR_PERMISSION));\n    } catch (IOException e) {\n      throw new YarnException(\"Error creating done directory: [\" + doneDirPrefixPath + \"]\", e);\n    }\n\n    String intermediateDoneDirPrefix \u003d null;\n    intermediateDoneDirPrefix \u003d JobHistoryUtils\n        .getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n    try {\n      intermediateDoneDirPath \u003d FileContext.getFileContext(conf)\n          .makeQualified(new Path(intermediateDoneDirPrefix));\n      intermediateDoneDirFc \u003d FileContext.getFileContext(\n          intermediateDoneDirPath.toUri(), conf);\n      mkdir(intermediateDoneDirFc, intermediateDoneDirPath, new FsPermission(JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS.toShort()));\n    } catch (IOException e) {\n      LOG.info(\"error creating done directory on dfs \" + e);\n      throw new YarnException(\"Error creating intermediate done directory: [\" + intermediateDoneDirPath + \"]\", e);\n    }\n    \n    \n    \n    jobListCacheSize \u003d conf.getInt(JHConfig.HISTORY_SERVER_JOBLIST_CACHE_SIZE_KEY, DEFAULT_JOBLIST_CACHE_SIZE);\n    loadedJobCacheSize \u003d conf.getInt(JHConfig.HISTORY_SERVER_LOADED_JOB_CACHE_SIZE_KEY, DEFAULT_LOADEDJOB_CACHE_SIZE);\n    dateStringCacheSize \u003d conf.getInt(JHConfig.HISTORY_SERVER_DATESTRING_CACHE_SIZE_KEY, DEFAULT_DATESTRING_CACHE_SIZE);\n    moveThreadInterval \u003d\n        conf.getLong(JHConfig.HISTORY_SERVER_MOVE_THREAD_INTERVAL,\n            DEFAULT_MOVE_THREAD_INTERVAL);\n    numMoveThreads \u003d conf.getInt(JHConfig.HISTORY_SERVER_NUM_MOVE_THREADS, DEFAULT_MOVE_THREAD_COUNT);\n    try {\n    initExisting();\n    } catch (IOException e) {\n      throw new YarnException(\"Failed to intialize existing directories\", e);\n    }\n    super.init(conf);\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java"
    }
  }
}