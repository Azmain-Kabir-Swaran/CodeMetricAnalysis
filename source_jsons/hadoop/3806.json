{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DistributedFileSystem.java",
  "functionName": "initialize",
  "functionId": "initialize___uri-URI__conf-Configuration",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
  "functionStartLine": 175,
  "functionEndLine": 196,
  "numCommitsSeen": 214,
  "timeTaken": 9290,
  "changeHistory": [
    "729cb3aefe71d7f728c7edea78ce7f268a1fdecb",
    "687233f20d24c29041929dd0a99d963cec54b6df",
    "1c030c6e58dc83152f933323bb7743ad47f5af27",
    "ead1b9e680201e8ad789b55c09b3c993cbf4827e",
    "f4caedfcbfeae7e2fe7c0e812ddbb087608a5ffd",
    "9eb8f4d267ca38c16e3ba191a3b754de7d167669",
    "8b4f497af85b49519da2e05e8269db6c4e9d621f",
    "8ae98a9d1ca4725e28783370517cb3a3ecda7324",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "729cb3aefe71d7f728c7edea78ce7f268a1fdecb": "Ybodychange",
    "687233f20d24c29041929dd0a99d963cec54b6df": "Ybodychange",
    "1c030c6e58dc83152f933323bb7743ad47f5af27": "Yfilerename",
    "ead1b9e680201e8ad789b55c09b3c993cbf4827e": "Ybodychange",
    "f4caedfcbfeae7e2fe7c0e812ddbb087608a5ffd": "Ybodychange",
    "9eb8f4d267ca38c16e3ba191a3b754de7d167669": "Ybodychange",
    "8b4f497af85b49519da2e05e8269db6c4e9d621f": "Ybodychange",
    "8ae98a9d1ca4725e28783370517cb3a3ecda7324": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "729cb3aefe71d7f728c7edea78ce7f268a1fdecb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12748. NameNode memory leak when accessing webhdfs GETHOMEDIRECTORY. Contributed by Weiwei Yang.\n",
      "commitDate": "03/07/19 6:37 PM",
      "commitName": "729cb3aefe71d7f728c7edea78ce7f268a1fdecb",
      "commitAuthor": "Weiwei Yang",
      "commitDateOld": "14/02/19 8:43 AM",
      "commitNameOld": "0d7a5ac5f526801367a9ec963e6d72783b637d55",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 139.37,
      "commitsBetweenForRepo": 1048,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,22 @@\n   public void initialize(URI uri, Configuration conf) throws IOException {\n     super.initialize(uri, conf);\n     setConf(conf);\n \n     String host \u003d uri.getHost();\n     if (host \u003d\u003d null) {\n       throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n     }\n-    homeDirPrefix \u003d conf.get(\n-        HdfsClientConfigKeys.DFS_USER_HOME_DIR_PREFIX_KEY,\n-        HdfsClientConfigKeys.DFS_USER_HOME_DIR_PREFIX_DEFAULT);\n \n     this.dfs \u003d new DFSClient(uri, conf, statistics);\n     this.uri \u003d URI.create(uri.getScheme()+\"://\"+uri.getAuthority());\n     this.workingDir \u003d getHomeDirectory();\n \n     storageStatistics \u003d (DFSOpsCountStatistics) GlobalStorageStatistics.INSTANCE\n         .put(DFSOpsCountStatistics.NAME,\n           new StorageStatisticsProvider() {\n             @Override\n             public StorageStatistics provide() {\n               return new DFSOpsCountStatistics();\n             }\n           });\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(URI uri, Configuration conf) throws IOException {\n    super.initialize(uri, conf);\n    setConf(conf);\n\n    String host \u003d uri.getHost();\n    if (host \u003d\u003d null) {\n      throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n    }\n\n    this.dfs \u003d new DFSClient(uri, conf, statistics);\n    this.uri \u003d URI.create(uri.getScheme()+\"://\"+uri.getAuthority());\n    this.workingDir \u003d getHomeDirectory();\n\n    storageStatistics \u003d (DFSOpsCountStatistics) GlobalStorageStatistics.INSTANCE\n        .put(DFSOpsCountStatistics.NAME,\n          new StorageStatisticsProvider() {\n            @Override\n            public StorageStatistics provide() {\n              return new DFSOpsCountStatistics();\n            }\n          });\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {}
    },
    "687233f20d24c29041929dd0a99d963cec54b6df": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13065. Add a new interface for retrieving FS and FC Statistics (Mingliang Liu via cmccabe)\n",
      "commitDate": "11/05/16 1:45 PM",
      "commitName": "687233f20d24c29041929dd0a99d963cec54b6df",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "02/05/16 7:30 PM",
      "commitNameOld": "45a753ccf79d334513c7bc8f2b81c89a4697075d",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 8.76,
      "commitsBetweenForRepo": 55,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,25 @@\n   public void initialize(URI uri, Configuration conf) throws IOException {\n     super.initialize(uri, conf);\n     setConf(conf);\n \n     String host \u003d uri.getHost();\n     if (host \u003d\u003d null) {\n       throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n     }\n     homeDirPrefix \u003d conf.get(\n         HdfsClientConfigKeys.DFS_USER_HOME_DIR_PREFIX_KEY,\n         HdfsClientConfigKeys.DFS_USER_HOME_DIR_PREFIX_DEFAULT);\n \n     this.dfs \u003d new DFSClient(uri, conf, statistics);\n     this.uri \u003d URI.create(uri.getScheme()+\"://\"+uri.getAuthority());\n     this.workingDir \u003d getHomeDirectory();\n+\n+    storageStatistics \u003d (DFSOpsCountStatistics) GlobalStorageStatistics.INSTANCE\n+        .put(DFSOpsCountStatistics.NAME,\n+          new StorageStatisticsProvider() {\n+            @Override\n+            public StorageStatistics provide() {\n+              return new DFSOpsCountStatistics();\n+            }\n+          });\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(URI uri, Configuration conf) throws IOException {\n    super.initialize(uri, conf);\n    setConf(conf);\n\n    String host \u003d uri.getHost();\n    if (host \u003d\u003d null) {\n      throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n    }\n    homeDirPrefix \u003d conf.get(\n        HdfsClientConfigKeys.DFS_USER_HOME_DIR_PREFIX_KEY,\n        HdfsClientConfigKeys.DFS_USER_HOME_DIR_PREFIX_DEFAULT);\n\n    this.dfs \u003d new DFSClient(uri, conf, statistics);\n    this.uri \u003d URI.create(uri.getScheme()+\"://\"+uri.getAuthority());\n    this.workingDir \u003d getHomeDirectory();\n\n    storageStatistics \u003d (DFSOpsCountStatistics) GlobalStorageStatistics.INSTANCE\n        .put(DFSOpsCountStatistics.NAME,\n          new StorageStatisticsProvider() {\n            @Override\n            public StorageStatistics provide() {\n              return new DFSOpsCountStatistics();\n            }\n          });\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {}
    },
    "1c030c6e58dc83152f933323bb7743ad47f5af27": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8740. Move DistributedFileSystem to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "27/09/15 10:54 AM",
      "commitName": "1c030c6e58dc83152f933323bb7743ad47f5af27",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "27/09/15 1:42 AM",
      "commitNameOld": "f0f984e4e63d0dbafe93062a122ee051330db301",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.38,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void initialize(URI uri, Configuration conf) throws IOException {\n    super.initialize(uri, conf);\n    setConf(conf);\n\n    String host \u003d uri.getHost();\n    if (host \u003d\u003d null) {\n      throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n    }\n    homeDirPrefix \u003d conf.get(\n        HdfsClientConfigKeys.DFS_USER_HOME_DIR_PREFIX_KEY,\n        HdfsClientConfigKeys.DFS_USER_HOME_DIR_PREFIX_DEFAULT);\n\n    this.dfs \u003d new DFSClient(uri, conf, statistics);\n    this.uri \u003d URI.create(uri.getScheme()+\"://\"+uri.getAuthority());\n    this.workingDir \u003d getHomeDirectory();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java"
      }
    },
    "ead1b9e680201e8ad789b55c09b3c993cbf4827e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9131. Move config keys used by hdfs-client to HdfsClientConfigKeys. Contributed by Mingliang Liu.\n",
      "commitDate": "24/09/15 12:30 AM",
      "commitName": "ead1b9e680201e8ad789b55c09b3c993cbf4827e",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "14/09/15 6:22 PM",
      "commitNameOld": "76957a485b526468498f93e443544131a88b5684",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 9.25,
      "commitsBetweenForRepo": 77,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n   public void initialize(URI uri, Configuration conf) throws IOException {\n     super.initialize(uri, conf);\n     setConf(conf);\n \n     String host \u003d uri.getHost();\n     if (host \u003d\u003d null) {\n       throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n     }\n     homeDirPrefix \u003d conf.get(\n-        DFSConfigKeys.DFS_USER_HOME_DIR_PREFIX_KEY,\n-        DFSConfigKeys.DFS_USER_HOME_DIR_PREFIX_DEFAULT);\n-    \n+        HdfsClientConfigKeys.DFS_USER_HOME_DIR_PREFIX_KEY,\n+        HdfsClientConfigKeys.DFS_USER_HOME_DIR_PREFIX_DEFAULT);\n+\n     this.dfs \u003d new DFSClient(uri, conf, statistics);\n     this.uri \u003d URI.create(uri.getScheme()+\"://\"+uri.getAuthority());\n     this.workingDir \u003d getHomeDirectory();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(URI uri, Configuration conf) throws IOException {\n    super.initialize(uri, conf);\n    setConf(conf);\n\n    String host \u003d uri.getHost();\n    if (host \u003d\u003d null) {\n      throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n    }\n    homeDirPrefix \u003d conf.get(\n        HdfsClientConfigKeys.DFS_USER_HOME_DIR_PREFIX_KEY,\n        HdfsClientConfigKeys.DFS_USER_HOME_DIR_PREFIX_DEFAULT);\n\n    this.dfs \u003d new DFSClient(uri, conf, statistics);\n    this.uri \u003d URI.create(uri.getScheme()+\"://\"+uri.getAuthority());\n    this.workingDir \u003d getHomeDirectory();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {}
    },
    "f4caedfcbfeae7e2fe7c0e812ddbb087608a5ffd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6959 Make the HDFS home directory location customizable.  Contributed by Yongjun Zhang\n",
      "commitDate": "03/09/14 7:30 PM",
      "commitName": "f4caedfcbfeae7e2fe7c0e812ddbb087608a5ffd",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "02/09/14 2:02 PM",
      "commitNameOld": "faa4455be512e070fa420084be8d1be5c72f3b08",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 1.23,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,16 @@\n   public void initialize(URI uri, Configuration conf) throws IOException {\n     super.initialize(uri, conf);\n     setConf(conf);\n \n     String host \u003d uri.getHost();\n     if (host \u003d\u003d null) {\n       throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n     }\n-\n+    homeDirPrefix \u003d conf.get(\n+        DFSConfigKeys.DFS_USER_HOME_DIR_PREFIX_KEY,\n+        DFSConfigKeys.DFS_USER_HOME_DIR_PREFIX_DEFAULT);\n+    \n     this.dfs \u003d new DFSClient(uri, conf, statistics);\n     this.uri \u003d URI.create(uri.getScheme()+\"://\"+uri.getAuthority());\n     this.workingDir \u003d getHomeDirectory();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(URI uri, Configuration conf) throws IOException {\n    super.initialize(uri, conf);\n    setConf(conf);\n\n    String host \u003d uri.getHost();\n    if (host \u003d\u003d null) {\n      throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n    }\n    homeDirPrefix \u003d conf.get(\n        DFSConfigKeys.DFS_USER_HOME_DIR_PREFIX_KEY,\n        DFSConfigKeys.DFS_USER_HOME_DIR_PREFIX_DEFAULT);\n    \n    this.dfs \u003d new DFSClient(uri, conf, statistics);\n    this.uri \u003d URI.create(uri.getScheme()+\"://\"+uri.getAuthority());\n    this.workingDir \u003d getHomeDirectory();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {}
    },
    "9eb8f4d267ca38c16e3ba191a3b754de7d167669": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2784. Update hftp and hdfs for host-based token support. Contributed by Kihwal Lee.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1239763 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/02/12 11:04 AM",
      "commitName": "9eb8f4d267ca38c16e3ba191a3b754de7d167669",
      "commitAuthor": "Jitendra Nath Pandey",
      "commitDateOld": "13/12/11 10:07 AM",
      "commitNameOld": "f2f4e9341387199e04679ebc8de5e05c0fdbd437",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 51.04,
      "commitsBetweenForRepo": 257,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   public void initialize(URI uri, Configuration conf) throws IOException {\n     super.initialize(uri, conf);\n     setConf(conf);\n \n     String host \u003d uri.getHost();\n     if (host \u003d\u003d null) {\n       throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n     }\n \n     InetSocketAddress namenode \u003d NameNode.getAddress(uri.getAuthority());\n     this.dfs \u003d new DFSClient(namenode, conf, statistics);\n-    this.uri \u003d URI.create(HdfsConstants.HDFS_URI_SCHEME + \"://\" + uri.getAuthority());\n+    this.uri \u003d URI.create(uri.getScheme()+\"://\"+uri.getAuthority());\n     this.workingDir \u003d getHomeDirectory();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(URI uri, Configuration conf) throws IOException {\n    super.initialize(uri, conf);\n    setConf(conf);\n\n    String host \u003d uri.getHost();\n    if (host \u003d\u003d null) {\n      throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n    }\n\n    InetSocketAddress namenode \u003d NameNode.getAddress(uri.getAuthority());\n    this.dfs \u003d new DFSClient(namenode, conf, statistics);\n    this.uri \u003d URI.create(uri.getScheme()+\"://\"+uri.getAuthority());\n    this.workingDir \u003d getHomeDirectory();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {}
    },
    "8b4f497af85b49519da2e05e8269db6c4e9d621f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1973. HA: HDFS clients must handle namenode failover and switch over to the new active namenode. (atm)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1179896 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/10/11 4:26 PM",
      "commitName": "8b4f497af85b49519da2e05e8269db6c4e9d621f",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "15/09/11 8:28 AM",
      "commitNameOld": "376a1a251123699806a3114511bdcc3d9f7bc6f4",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 21.33,
      "commitsBetweenForRepo": 151,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,13 @@\n   public void initialize(URI uri, Configuration conf) throws IOException {\n     super.initialize(uri, conf);\n     setConf(conf);\n \n     String host \u003d uri.getHost();\n     if (host \u003d\u003d null) {\n       throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n     }\n \n-    InetSocketAddress namenode \u003d NameNode.getAddress(uri.getAuthority());\n-    this.dfs \u003d new DFSClient(namenode, conf, statistics);\n+    this.dfs \u003d new DFSClient(uri, conf, statistics);\n     this.uri \u003d URI.create(HdfsConstants.HDFS_URI_SCHEME + \"://\" + uri.getAuthority());\n     this.workingDir \u003d getHomeDirectory();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(URI uri, Configuration conf) throws IOException {\n    super.initialize(uri, conf);\n    setConf(conf);\n\n    String host \u003d uri.getHost();\n    if (host \u003d\u003d null) {\n      throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n    }\n\n    this.dfs \u003d new DFSClient(uri, conf, statistics);\n    this.uri \u003d URI.create(HdfsConstants.HDFS_URI_SCHEME + \"://\" + uri.getAuthority());\n    this.workingDir \u003d getHomeDirectory();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {}
    },
    "8ae98a9d1ca4725e28783370517cb3a3ecda7324": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1620. Rename HdfsConstants -\u003e HdfsServerConstants, FSConstants -\u003e HdfsConstants. (Harsh J Chouraria via atm)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1165096 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/09/11 12:30 PM",
      "commitName": "8ae98a9d1ca4725e28783370517cb3a3ecda7324",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 10.8,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   public void initialize(URI uri, Configuration conf) throws IOException {\n     super.initialize(uri, conf);\n     setConf(conf);\n \n     String host \u003d uri.getHost();\n     if (host \u003d\u003d null) {\n       throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n     }\n \n     InetSocketAddress namenode \u003d NameNode.getAddress(uri.getAuthority());\n     this.dfs \u003d new DFSClient(namenode, conf, statistics);\n-    this.uri \u003d URI.create(FSConstants.HDFS_URI_SCHEME + \"://\" + uri.getAuthority());\n+    this.uri \u003d URI.create(HdfsConstants.HDFS_URI_SCHEME + \"://\" + uri.getAuthority());\n     this.workingDir \u003d getHomeDirectory();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(URI uri, Configuration conf) throws IOException {\n    super.initialize(uri, conf);\n    setConf(conf);\n\n    String host \u003d uri.getHost();\n    if (host \u003d\u003d null) {\n      throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n    }\n\n    InetSocketAddress namenode \u003d NameNode.getAddress(uri.getAuthority());\n    this.dfs \u003d new DFSClient(namenode, conf, statistics);\n    this.uri \u003d URI.create(HdfsConstants.HDFS_URI_SCHEME + \"://\" + uri.getAuthority());\n    this.workingDir \u003d getHomeDirectory();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void initialize(URI uri, Configuration conf) throws IOException {\n    super.initialize(uri, conf);\n    setConf(conf);\n\n    String host \u003d uri.getHost();\n    if (host \u003d\u003d null) {\n      throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n    }\n\n    InetSocketAddress namenode \u003d NameNode.getAddress(uri.getAuthority());\n    this.dfs \u003d new DFSClient(namenode, conf, statistics);\n    this.uri \u003d URI.create(FSConstants.HDFS_URI_SCHEME + \"://\" + uri.getAuthority());\n    this.workingDir \u003d getHomeDirectory();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void initialize(URI uri, Configuration conf) throws IOException {\n    super.initialize(uri, conf);\n    setConf(conf);\n\n    String host \u003d uri.getHost();\n    if (host \u003d\u003d null) {\n      throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n    }\n\n    InetSocketAddress namenode \u003d NameNode.getAddress(uri.getAuthority());\n    this.dfs \u003d new DFSClient(namenode, conf, statistics);\n    this.uri \u003d URI.create(FSConstants.HDFS_URI_SCHEME + \"://\" + uri.getAuthority());\n    this.workingDir \u003d getHomeDirectory();\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/DistributedFileSystem.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,14 @@\n+  public void initialize(URI uri, Configuration conf) throws IOException {\n+    super.initialize(uri, conf);\n+    setConf(conf);\n+\n+    String host \u003d uri.getHost();\n+    if (host \u003d\u003d null) {\n+      throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n+    }\n+\n+    InetSocketAddress namenode \u003d NameNode.getAddress(uri.getAuthority());\n+    this.dfs \u003d new DFSClient(namenode, conf, statistics);\n+    this.uri \u003d URI.create(FSConstants.HDFS_URI_SCHEME + \"://\" + uri.getAuthority());\n+    this.workingDir \u003d getHomeDirectory();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(URI uri, Configuration conf) throws IOException {\n    super.initialize(uri, conf);\n    setConf(conf);\n\n    String host \u003d uri.getHost();\n    if (host \u003d\u003d null) {\n      throw new IOException(\"Incomplete HDFS URI, no host: \"+ uri);\n    }\n\n    InetSocketAddress namenode \u003d NameNode.getAddress(uri.getAuthority());\n    this.dfs \u003d new DFSClient(namenode, conf, statistics);\n    this.uri \u003d URI.create(FSConstants.HDFS_URI_SCHEME + \"://\" + uri.getAuthority());\n    this.workingDir \u003d getHomeDirectory();\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/DistributedFileSystem.java"
    }
  }
}