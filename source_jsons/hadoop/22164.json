{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ShuffleSchedulerImpl.java",
  "functionName": "checkReducerHealth",
  "functionId": "checkReducerHealth",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java",
  "functionStartLine": 354,
  "functionEndLine": 399,
  "numCommitsSeen": 19,
  "timeTaken": 6351,
  "changeHistory": [
    "178751ed8c9d47038acf8616c226f1f52e884feb",
    "2c3da25fd718b3a9c1ed67f05b577975ae613f4e",
    "1a389305b27ac1efec4d7923b87de3e703bf70e1",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "178751ed8c9d47038acf8616c226f1f52e884feb": "Ybodychange",
    "2c3da25fd718b3a9c1ed67f05b577975ae613f4e": "Ybodychange",
    "1a389305b27ac1efec4d7923b87de3e703bf70e1": "Ymultichange(Ymovefromfile,Ybodychange)",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "178751ed8c9d47038acf8616c226f1f52e884feb": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6983. Moving logging APIs over to slf4j in hadoop-mapreduce-client-core. Contributed by Jinjiang Ling.\n",
      "commitDate": "02/11/17 1:43 AM",
      "commitName": "178751ed8c9d47038acf8616c226f1f52e884feb",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "13/09/17 3:21 PM",
      "commitNameOld": "4d98936eec1b5d196053426c70d455cf8f83f84f",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 49.43,
      "commitsBetweenForRepo": 372,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,46 @@\n   private void checkReducerHealth() {\n     final float MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT \u003d 0.5f;\n     final float MIN_REQUIRED_PROGRESS_PERCENT \u003d 0.5f;\n     final float MAX_ALLOWED_STALL_TIME_PERCENT \u003d 0.5f;\n \n     long totalFailures \u003d failedShuffleCounter.getValue();\n     int doneMaps \u003d totalMaps - remainingMaps;\n \n     boolean reducerHealthy \u003d\n       (((float)totalFailures / (totalFailures + doneMaps))\n           \u003c MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT);\n \n     // check if the reducer has progressed enough\n     boolean reducerProgressedEnough \u003d\n       (((float)doneMaps / totalMaps)\n           \u003e\u003d MIN_REQUIRED_PROGRESS_PERCENT);\n \n     // check if the reducer is stalled for a long time\n     // duration for which the reducer is stalled\n     int stallDuration \u003d\n       (int)(Time.monotonicNow() - lastProgressTime);\n \n     // duration for which the reducer ran with progress\n     int shuffleProgressDuration \u003d\n       (int)(lastProgressTime - startTime);\n \n     // min time the reducer should run without getting killed\n     int minShuffleRunDuration \u003d\n       Math.max(shuffleProgressDuration, maxMapRuntime);\n \n     boolean reducerStalled \u003d\n       (((float)stallDuration / minShuffleRunDuration)\n           \u003e\u003d MAX_ALLOWED_STALL_TIME_PERCENT);\n \n     // kill if not healthy and has insufficient progress\n     if ((failureCounts.size() \u003e\u003d maxFailedUniqueFetches ||\n         failureCounts.size() \u003d\u003d (totalMaps - doneMaps))\n         \u0026\u0026 !reducerHealthy\n         \u0026\u0026 (!reducerProgressedEnough || reducerStalled)) {\n-      LOG.fatal(\"Shuffle failed with too many fetch failures \" +\n+      LOG.error(\"Shuffle failed with too many fetch failures \" +\n       \"and insufficient progress!\");\n       String errorMsg \u003d \"Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.\";\n       reporter.reportException(new IOException(errorMsg));\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void checkReducerHealth() {\n    final float MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT \u003d 0.5f;\n    final float MIN_REQUIRED_PROGRESS_PERCENT \u003d 0.5f;\n    final float MAX_ALLOWED_STALL_TIME_PERCENT \u003d 0.5f;\n\n    long totalFailures \u003d failedShuffleCounter.getValue();\n    int doneMaps \u003d totalMaps - remainingMaps;\n\n    boolean reducerHealthy \u003d\n      (((float)totalFailures / (totalFailures + doneMaps))\n          \u003c MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT);\n\n    // check if the reducer has progressed enough\n    boolean reducerProgressedEnough \u003d\n      (((float)doneMaps / totalMaps)\n          \u003e\u003d MIN_REQUIRED_PROGRESS_PERCENT);\n\n    // check if the reducer is stalled for a long time\n    // duration for which the reducer is stalled\n    int stallDuration \u003d\n      (int)(Time.monotonicNow() - lastProgressTime);\n\n    // duration for which the reducer ran with progress\n    int shuffleProgressDuration \u003d\n      (int)(lastProgressTime - startTime);\n\n    // min time the reducer should run without getting killed\n    int minShuffleRunDuration \u003d\n      Math.max(shuffleProgressDuration, maxMapRuntime);\n\n    boolean reducerStalled \u003d\n      (((float)stallDuration / minShuffleRunDuration)\n          \u003e\u003d MAX_ALLOWED_STALL_TIME_PERCENT);\n\n    // kill if not healthy and has insufficient progress\n    if ((failureCounts.size() \u003e\u003d maxFailedUniqueFetches ||\n        failureCounts.size() \u003d\u003d (totalMaps - doneMaps))\n        \u0026\u0026 !reducerHealthy\n        \u0026\u0026 (!reducerProgressedEnough || reducerStalled)) {\n      LOG.error(\"Shuffle failed with too many fetch failures \" +\n      \"and insufficient progress!\");\n      String errorMsg \u003d \"Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.\";\n      reporter.reportException(new IOException(errorMsg));\n    }\n\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java",
      "extendedDetails": {}
    },
    "2c3da25fd718b3a9c1ed67f05b577975ae613f4e": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5891. Improved shuffle error handling across NM restarts. Contributed by Junping Du\n",
      "commitDate": "18/09/14 3:00 PM",
      "commitName": "2c3da25fd718b3a9c1ed67f05b577975ae613f4e",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "18/08/14 10:57 AM",
      "commitNameOld": "f8e871d01b851cd5d8c57dd7e364b3e787521765",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 31.17,
      "commitsBetweenForRepo": 264,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,46 @@\n   private void checkReducerHealth() {\n     final float MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT \u003d 0.5f;\n     final float MIN_REQUIRED_PROGRESS_PERCENT \u003d 0.5f;\n     final float MAX_ALLOWED_STALL_TIME_PERCENT \u003d 0.5f;\n \n     long totalFailures \u003d failedShuffleCounter.getValue();\n     int doneMaps \u003d totalMaps - remainingMaps;\n \n     boolean reducerHealthy \u003d\n       (((float)totalFailures / (totalFailures + doneMaps))\n           \u003c MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT);\n \n     // check if the reducer has progressed enough\n     boolean reducerProgressedEnough \u003d\n       (((float)doneMaps / totalMaps)\n           \u003e\u003d MIN_REQUIRED_PROGRESS_PERCENT);\n \n     // check if the reducer is stalled for a long time\n     // duration for which the reducer is stalled\n     int stallDuration \u003d\n-      (int)(System.currentTimeMillis() - lastProgressTime);\n+      (int)(Time.monotonicNow() - lastProgressTime);\n \n     // duration for which the reducer ran with progress\n     int shuffleProgressDuration \u003d\n       (int)(lastProgressTime - startTime);\n \n     // min time the reducer should run without getting killed\n     int minShuffleRunDuration \u003d\n       Math.max(shuffleProgressDuration, maxMapRuntime);\n \n     boolean reducerStalled \u003d\n       (((float)stallDuration / minShuffleRunDuration)\n           \u003e\u003d MAX_ALLOWED_STALL_TIME_PERCENT);\n \n     // kill if not healthy and has insufficient progress\n     if ((failureCounts.size() \u003e\u003d maxFailedUniqueFetches ||\n         failureCounts.size() \u003d\u003d (totalMaps - doneMaps))\n         \u0026\u0026 !reducerHealthy\n         \u0026\u0026 (!reducerProgressedEnough || reducerStalled)) {\n       LOG.fatal(\"Shuffle failed with too many fetch failures \" +\n       \"and insufficient progress!\");\n       String errorMsg \u003d \"Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.\";\n       reporter.reportException(new IOException(errorMsg));\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void checkReducerHealth() {\n    final float MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT \u003d 0.5f;\n    final float MIN_REQUIRED_PROGRESS_PERCENT \u003d 0.5f;\n    final float MAX_ALLOWED_STALL_TIME_PERCENT \u003d 0.5f;\n\n    long totalFailures \u003d failedShuffleCounter.getValue();\n    int doneMaps \u003d totalMaps - remainingMaps;\n\n    boolean reducerHealthy \u003d\n      (((float)totalFailures / (totalFailures + doneMaps))\n          \u003c MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT);\n\n    // check if the reducer has progressed enough\n    boolean reducerProgressedEnough \u003d\n      (((float)doneMaps / totalMaps)\n          \u003e\u003d MIN_REQUIRED_PROGRESS_PERCENT);\n\n    // check if the reducer is stalled for a long time\n    // duration for which the reducer is stalled\n    int stallDuration \u003d\n      (int)(Time.monotonicNow() - lastProgressTime);\n\n    // duration for which the reducer ran with progress\n    int shuffleProgressDuration \u003d\n      (int)(lastProgressTime - startTime);\n\n    // min time the reducer should run without getting killed\n    int minShuffleRunDuration \u003d\n      Math.max(shuffleProgressDuration, maxMapRuntime);\n\n    boolean reducerStalled \u003d\n      (((float)stallDuration / minShuffleRunDuration)\n          \u003e\u003d MAX_ALLOWED_STALL_TIME_PERCENT);\n\n    // kill if not healthy and has insufficient progress\n    if ((failureCounts.size() \u003e\u003d maxFailedUniqueFetches ||\n        failureCounts.size() \u003d\u003d (totalMaps - doneMaps))\n        \u0026\u0026 !reducerHealthy\n        \u0026\u0026 (!reducerProgressedEnough || reducerStalled)) {\n      LOG.fatal(\"Shuffle failed with too many fetch failures \" +\n      \"and insufficient progress!\");\n      String errorMsg \u003d \"Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.\";\n      reporter.reportException(new IOException(errorMsg));\n    }\n\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java",
      "extendedDetails": {}
    },
    "1a389305b27ac1efec4d7923b87de3e703bf70e1": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "MAPREDUCE-5192. Allow for alternate resolutions of TaskCompletionEvents. Contributed by Chris Douglas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1493445 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/06/13 8:07 PM",
      "commitName": "1a389305b27ac1efec4d7923b87de3e703bf70e1",
      "commitAuthor": "Arun Murthy",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "MAPREDUCE-5192. Allow for alternate resolutions of TaskCompletionEvents. Contributed by Chris Douglas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1493445 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "15/06/13 8:07 PM",
          "commitName": "1a389305b27ac1efec4d7923b87de3e703bf70e1",
          "commitAuthor": "Arun Murthy",
          "commitDateOld": "15/06/13 4:09 PM",
          "commitNameOld": "29a370872435ee558fbeb9f64bf70da87f8cd27a",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 0.17,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,48 +1,46 @@\n   private void checkReducerHealth() {\n     final float MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT \u003d 0.5f;\n     final float MIN_REQUIRED_PROGRESS_PERCENT \u003d 0.5f;\n     final float MAX_ALLOWED_STALL_TIME_PERCENT \u003d 0.5f;\n \n     long totalFailures \u003d failedShuffleCounter.getValue();\n     int doneMaps \u003d totalMaps - remainingMaps;\n-    \n+\n     boolean reducerHealthy \u003d\n       (((float)totalFailures / (totalFailures + doneMaps))\n           \u003c MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT);\n-    \n+\n     // check if the reducer has progressed enough\n     boolean reducerProgressedEnough \u003d\n       (((float)doneMaps / totalMaps)\n           \u003e\u003d MIN_REQUIRED_PROGRESS_PERCENT);\n \n     // check if the reducer is stalled for a long time\n     // duration for which the reducer is stalled\n     int stallDuration \u003d\n       (int)(System.currentTimeMillis() - lastProgressTime);\n-    \n+\n     // duration for which the reducer ran with progress\n     int shuffleProgressDuration \u003d\n       (int)(lastProgressTime - startTime);\n \n     // min time the reducer should run without getting killed\n     int minShuffleRunDuration \u003d\n-      (shuffleProgressDuration \u003e maxMapRuntime)\n-      ? shuffleProgressDuration\n-          : maxMapRuntime;\n-    \n+      Math.max(shuffleProgressDuration, maxMapRuntime);\n+\n     boolean reducerStalled \u003d\n       (((float)stallDuration / minShuffleRunDuration)\n           \u003e\u003d MAX_ALLOWED_STALL_TIME_PERCENT);\n \n     // kill if not healthy and has insufficient progress\n     if ((failureCounts.size() \u003e\u003d maxFailedUniqueFetches ||\n         failureCounts.size() \u003d\u003d (totalMaps - doneMaps))\n         \u0026\u0026 !reducerHealthy\n         \u0026\u0026 (!reducerProgressedEnough || reducerStalled)) {\n       LOG.fatal(\"Shuffle failed with too many fetch failures \" +\n       \"and insufficient progress!\");\n       String errorMsg \u003d \"Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.\";\n       reporter.reportException(new IOException(errorMsg));\n     }\n \n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void checkReducerHealth() {\n    final float MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT \u003d 0.5f;\n    final float MIN_REQUIRED_PROGRESS_PERCENT \u003d 0.5f;\n    final float MAX_ALLOWED_STALL_TIME_PERCENT \u003d 0.5f;\n\n    long totalFailures \u003d failedShuffleCounter.getValue();\n    int doneMaps \u003d totalMaps - remainingMaps;\n\n    boolean reducerHealthy \u003d\n      (((float)totalFailures / (totalFailures + doneMaps))\n          \u003c MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT);\n\n    // check if the reducer has progressed enough\n    boolean reducerProgressedEnough \u003d\n      (((float)doneMaps / totalMaps)\n          \u003e\u003d MIN_REQUIRED_PROGRESS_PERCENT);\n\n    // check if the reducer is stalled for a long time\n    // duration for which the reducer is stalled\n    int stallDuration \u003d\n      (int)(System.currentTimeMillis() - lastProgressTime);\n\n    // duration for which the reducer ran with progress\n    int shuffleProgressDuration \u003d\n      (int)(lastProgressTime - startTime);\n\n    // min time the reducer should run without getting killed\n    int minShuffleRunDuration \u003d\n      Math.max(shuffleProgressDuration, maxMapRuntime);\n\n    boolean reducerStalled \u003d\n      (((float)stallDuration / minShuffleRunDuration)\n          \u003e\u003d MAX_ALLOWED_STALL_TIME_PERCENT);\n\n    // kill if not healthy and has insufficient progress\n    if ((failureCounts.size() \u003e\u003d maxFailedUniqueFetches ||\n        failureCounts.size() \u003d\u003d (totalMaps - doneMaps))\n        \u0026\u0026 !reducerHealthy\n        \u0026\u0026 (!reducerProgressedEnough || reducerStalled)) {\n      LOG.fatal(\"Shuffle failed with too many fetch failures \" +\n      \"and insufficient progress!\");\n      String errorMsg \u003d \"Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.\";\n      reporter.reportException(new IOException(errorMsg));\n    }\n\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java",
          "extendedDetails": {
            "oldPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/ShuffleScheduler.java",
            "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java",
            "oldMethodName": "checkReducerHealth",
            "newMethodName": "checkReducerHealth"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-5192. Allow for alternate resolutions of TaskCompletionEvents. Contributed by Chris Douglas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1493445 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "15/06/13 8:07 PM",
          "commitName": "1a389305b27ac1efec4d7923b87de3e703bf70e1",
          "commitAuthor": "Arun Murthy",
          "commitDateOld": "15/06/13 4:09 PM",
          "commitNameOld": "29a370872435ee558fbeb9f64bf70da87f8cd27a",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 0.17,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,48 +1,46 @@\n   private void checkReducerHealth() {\n     final float MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT \u003d 0.5f;\n     final float MIN_REQUIRED_PROGRESS_PERCENT \u003d 0.5f;\n     final float MAX_ALLOWED_STALL_TIME_PERCENT \u003d 0.5f;\n \n     long totalFailures \u003d failedShuffleCounter.getValue();\n     int doneMaps \u003d totalMaps - remainingMaps;\n-    \n+\n     boolean reducerHealthy \u003d\n       (((float)totalFailures / (totalFailures + doneMaps))\n           \u003c MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT);\n-    \n+\n     // check if the reducer has progressed enough\n     boolean reducerProgressedEnough \u003d\n       (((float)doneMaps / totalMaps)\n           \u003e\u003d MIN_REQUIRED_PROGRESS_PERCENT);\n \n     // check if the reducer is stalled for a long time\n     // duration for which the reducer is stalled\n     int stallDuration \u003d\n       (int)(System.currentTimeMillis() - lastProgressTime);\n-    \n+\n     // duration for which the reducer ran with progress\n     int shuffleProgressDuration \u003d\n       (int)(lastProgressTime - startTime);\n \n     // min time the reducer should run without getting killed\n     int minShuffleRunDuration \u003d\n-      (shuffleProgressDuration \u003e maxMapRuntime)\n-      ? shuffleProgressDuration\n-          : maxMapRuntime;\n-    \n+      Math.max(shuffleProgressDuration, maxMapRuntime);\n+\n     boolean reducerStalled \u003d\n       (((float)stallDuration / minShuffleRunDuration)\n           \u003e\u003d MAX_ALLOWED_STALL_TIME_PERCENT);\n \n     // kill if not healthy and has insufficient progress\n     if ((failureCounts.size() \u003e\u003d maxFailedUniqueFetches ||\n         failureCounts.size() \u003d\u003d (totalMaps - doneMaps))\n         \u0026\u0026 !reducerHealthy\n         \u0026\u0026 (!reducerProgressedEnough || reducerStalled)) {\n       LOG.fatal(\"Shuffle failed with too many fetch failures \" +\n       \"and insufficient progress!\");\n       String errorMsg \u003d \"Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.\";\n       reporter.reportException(new IOException(errorMsg));\n     }\n \n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void checkReducerHealth() {\n    final float MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT \u003d 0.5f;\n    final float MIN_REQUIRED_PROGRESS_PERCENT \u003d 0.5f;\n    final float MAX_ALLOWED_STALL_TIME_PERCENT \u003d 0.5f;\n\n    long totalFailures \u003d failedShuffleCounter.getValue();\n    int doneMaps \u003d totalMaps - remainingMaps;\n\n    boolean reducerHealthy \u003d\n      (((float)totalFailures / (totalFailures + doneMaps))\n          \u003c MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT);\n\n    // check if the reducer has progressed enough\n    boolean reducerProgressedEnough \u003d\n      (((float)doneMaps / totalMaps)\n          \u003e\u003d MIN_REQUIRED_PROGRESS_PERCENT);\n\n    // check if the reducer is stalled for a long time\n    // duration for which the reducer is stalled\n    int stallDuration \u003d\n      (int)(System.currentTimeMillis() - lastProgressTime);\n\n    // duration for which the reducer ran with progress\n    int shuffleProgressDuration \u003d\n      (int)(lastProgressTime - startTime);\n\n    // min time the reducer should run without getting killed\n    int minShuffleRunDuration \u003d\n      Math.max(shuffleProgressDuration, maxMapRuntime);\n\n    boolean reducerStalled \u003d\n      (((float)stallDuration / minShuffleRunDuration)\n          \u003e\u003d MAX_ALLOWED_STALL_TIME_PERCENT);\n\n    // kill if not healthy and has insufficient progress\n    if ((failureCounts.size() \u003e\u003d maxFailedUniqueFetches ||\n        failureCounts.size() \u003d\u003d (totalMaps - doneMaps))\n        \u0026\u0026 !reducerHealthy\n        \u0026\u0026 (!reducerProgressedEnough || reducerStalled)) {\n      LOG.fatal(\"Shuffle failed with too many fetch failures \" +\n      \"and insufficient progress!\");\n      String errorMsg \u003d \"Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.\";\n      reporter.reportException(new IOException(errorMsg));\n    }\n\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void checkReducerHealth() {\n    final float MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT \u003d 0.5f;\n    final float MIN_REQUIRED_PROGRESS_PERCENT \u003d 0.5f;\n    final float MAX_ALLOWED_STALL_TIME_PERCENT \u003d 0.5f;\n\n    long totalFailures \u003d failedShuffleCounter.getValue();\n    int doneMaps \u003d totalMaps - remainingMaps;\n    \n    boolean reducerHealthy \u003d\n      (((float)totalFailures / (totalFailures + doneMaps))\n          \u003c MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT);\n    \n    // check if the reducer has progressed enough\n    boolean reducerProgressedEnough \u003d\n      (((float)doneMaps / totalMaps)\n          \u003e\u003d MIN_REQUIRED_PROGRESS_PERCENT);\n\n    // check if the reducer is stalled for a long time\n    // duration for which the reducer is stalled\n    int stallDuration \u003d\n      (int)(System.currentTimeMillis() - lastProgressTime);\n    \n    // duration for which the reducer ran with progress\n    int shuffleProgressDuration \u003d\n      (int)(lastProgressTime - startTime);\n\n    // min time the reducer should run without getting killed\n    int minShuffleRunDuration \u003d\n      (shuffleProgressDuration \u003e maxMapRuntime)\n      ? shuffleProgressDuration\n          : maxMapRuntime;\n    \n    boolean reducerStalled \u003d\n      (((float)stallDuration / minShuffleRunDuration)\n          \u003e\u003d MAX_ALLOWED_STALL_TIME_PERCENT);\n\n    // kill if not healthy and has insufficient progress\n    if ((failureCounts.size() \u003e\u003d maxFailedUniqueFetches ||\n        failureCounts.size() \u003d\u003d (totalMaps - doneMaps))\n        \u0026\u0026 !reducerHealthy\n        \u0026\u0026 (!reducerProgressedEnough || reducerStalled)) {\n      LOG.fatal(\"Shuffle failed with too many fetch failures \" +\n      \"and insufficient progress!\");\n      String errorMsg \u003d \"Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.\";\n      reporter.reportException(new IOException(errorMsg));\n    }\n\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/ShuffleScheduler.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/ShuffleScheduler.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/ShuffleScheduler.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void checkReducerHealth() {\n    final float MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT \u003d 0.5f;\n    final float MIN_REQUIRED_PROGRESS_PERCENT \u003d 0.5f;\n    final float MAX_ALLOWED_STALL_TIME_PERCENT \u003d 0.5f;\n\n    long totalFailures \u003d failedShuffleCounter.getValue();\n    int doneMaps \u003d totalMaps - remainingMaps;\n    \n    boolean reducerHealthy \u003d\n      (((float)totalFailures / (totalFailures + doneMaps))\n          \u003c MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT);\n    \n    // check if the reducer has progressed enough\n    boolean reducerProgressedEnough \u003d\n      (((float)doneMaps / totalMaps)\n          \u003e\u003d MIN_REQUIRED_PROGRESS_PERCENT);\n\n    // check if the reducer is stalled for a long time\n    // duration for which the reducer is stalled\n    int stallDuration \u003d\n      (int)(System.currentTimeMillis() - lastProgressTime);\n    \n    // duration for which the reducer ran with progress\n    int shuffleProgressDuration \u003d\n      (int)(lastProgressTime - startTime);\n\n    // min time the reducer should run without getting killed\n    int minShuffleRunDuration \u003d\n      (shuffleProgressDuration \u003e maxMapRuntime)\n      ? shuffleProgressDuration\n          : maxMapRuntime;\n    \n    boolean reducerStalled \u003d\n      (((float)stallDuration / minShuffleRunDuration)\n          \u003e\u003d MAX_ALLOWED_STALL_TIME_PERCENT);\n\n    // kill if not healthy and has insufficient progress\n    if ((failureCounts.size() \u003e\u003d maxFailedUniqueFetches ||\n        failureCounts.size() \u003d\u003d (totalMaps - doneMaps))\n        \u0026\u0026 !reducerHealthy\n        \u0026\u0026 (!reducerProgressedEnough || reducerStalled)) {\n      LOG.fatal(\"Shuffle failed with too many fetch failures \" +\n      \"and insufficient progress!\");\n      String errorMsg \u003d \"Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.\";\n      reporter.reportException(new IOException(errorMsg));\n    }\n\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/ShuffleScheduler.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/java/org/apache/hadoop/mapreduce/task/reduce/ShuffleScheduler.java",
        "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/ShuffleScheduler.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,48 @@\n+  private void checkReducerHealth() {\n+    final float MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT \u003d 0.5f;\n+    final float MIN_REQUIRED_PROGRESS_PERCENT \u003d 0.5f;\n+    final float MAX_ALLOWED_STALL_TIME_PERCENT \u003d 0.5f;\n+\n+    long totalFailures \u003d failedShuffleCounter.getValue();\n+    int doneMaps \u003d totalMaps - remainingMaps;\n+    \n+    boolean reducerHealthy \u003d\n+      (((float)totalFailures / (totalFailures + doneMaps))\n+          \u003c MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT);\n+    \n+    // check if the reducer has progressed enough\n+    boolean reducerProgressedEnough \u003d\n+      (((float)doneMaps / totalMaps)\n+          \u003e\u003d MIN_REQUIRED_PROGRESS_PERCENT);\n+\n+    // check if the reducer is stalled for a long time\n+    // duration for which the reducer is stalled\n+    int stallDuration \u003d\n+      (int)(System.currentTimeMillis() - lastProgressTime);\n+    \n+    // duration for which the reducer ran with progress\n+    int shuffleProgressDuration \u003d\n+      (int)(lastProgressTime - startTime);\n+\n+    // min time the reducer should run without getting killed\n+    int minShuffleRunDuration \u003d\n+      (shuffleProgressDuration \u003e maxMapRuntime)\n+      ? shuffleProgressDuration\n+          : maxMapRuntime;\n+    \n+    boolean reducerStalled \u003d\n+      (((float)stallDuration / minShuffleRunDuration)\n+          \u003e\u003d MAX_ALLOWED_STALL_TIME_PERCENT);\n+\n+    // kill if not healthy and has insufficient progress\n+    if ((failureCounts.size() \u003e\u003d maxFailedUniqueFetches ||\n+        failureCounts.size() \u003d\u003d (totalMaps - doneMaps))\n+        \u0026\u0026 !reducerHealthy\n+        \u0026\u0026 (!reducerProgressedEnough || reducerStalled)) {\n+      LOG.fatal(\"Shuffle failed with too many fetch failures \" +\n+      \"and insufficient progress!\");\n+      String errorMsg \u003d \"Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.\";\n+      reporter.reportException(new IOException(errorMsg));\n+    }\n+\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void checkReducerHealth() {\n    final float MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT \u003d 0.5f;\n    final float MIN_REQUIRED_PROGRESS_PERCENT \u003d 0.5f;\n    final float MAX_ALLOWED_STALL_TIME_PERCENT \u003d 0.5f;\n\n    long totalFailures \u003d failedShuffleCounter.getValue();\n    int doneMaps \u003d totalMaps - remainingMaps;\n    \n    boolean reducerHealthy \u003d\n      (((float)totalFailures / (totalFailures + doneMaps))\n          \u003c MAX_ALLOWED_FAILED_FETCH_ATTEMPT_PERCENT);\n    \n    // check if the reducer has progressed enough\n    boolean reducerProgressedEnough \u003d\n      (((float)doneMaps / totalMaps)\n          \u003e\u003d MIN_REQUIRED_PROGRESS_PERCENT);\n\n    // check if the reducer is stalled for a long time\n    // duration for which the reducer is stalled\n    int stallDuration \u003d\n      (int)(System.currentTimeMillis() - lastProgressTime);\n    \n    // duration for which the reducer ran with progress\n    int shuffleProgressDuration \u003d\n      (int)(lastProgressTime - startTime);\n\n    // min time the reducer should run without getting killed\n    int minShuffleRunDuration \u003d\n      (shuffleProgressDuration \u003e maxMapRuntime)\n      ? shuffleProgressDuration\n          : maxMapRuntime;\n    \n    boolean reducerStalled \u003d\n      (((float)stallDuration / minShuffleRunDuration)\n          \u003e\u003d MAX_ALLOWED_STALL_TIME_PERCENT);\n\n    // kill if not healthy and has insufficient progress\n    if ((failureCounts.size() \u003e\u003d maxFailedUniqueFetches ||\n        failureCounts.size() \u003d\u003d (totalMaps - doneMaps))\n        \u0026\u0026 !reducerHealthy\n        \u0026\u0026 (!reducerProgressedEnough || reducerStalled)) {\n      LOG.fatal(\"Shuffle failed with too many fetch failures \" +\n      \"and insufficient progress!\");\n      String errorMsg \u003d \"Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.\";\n      reporter.reportException(new IOException(errorMsg));\n    }\n\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapreduce/task/reduce/ShuffleScheduler.java"
    }
  }
}