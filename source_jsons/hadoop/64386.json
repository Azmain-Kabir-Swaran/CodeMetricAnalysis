{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3AInstrumentation.java",
  "functionName": "close",
  "functionId": "close",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInstrumentation.java",
  "functionStartLine": 1064,
  "functionEndLine": 1070,
  "numCommitsSeen": 27,
  "timeTaken": 1183,
  "changeHistory": [
    "6c348c56918973fd988b110e79231324a8befe12",
    "27c4e90efce04e1b1302f668b5eb22412e00d033"
  ],
  "changeHistoryShort": {
    "6c348c56918973fd988b110e79231324a8befe12": "Ybodychange",
    "27c4e90efce04e1b1302f668b5eb22412e00d033": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6c348c56918973fd988b110e79231324a8befe12": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13560. S3ABlockOutputStream to support huge (many GB) file writes. Contributed by Steve Loughran\n",
      "commitDate": "18/10/16 1:16 PM",
      "commitName": "6c348c56918973fd988b110e79231324a8befe12",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "29/09/16 9:01 AM",
      "commitNameOld": "ee0c722dc8fb81ec902cd1da5958ce5adb0ab08f",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 19.18,
      "commitsBetweenForRepo": 137,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,7 @@\n     public void close() {\n-      mergeInputStreamStatistics(this);\n+      if (bytesPendingUpload.get() \u003e 0) {\n+        LOG.warn(\"Closing output stream statistics while data is still marked\" +\n+            \" as pending upload in {}\", this);\n+      }\n+      mergeOutputStreamStatistics(this);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void close() {\n      if (bytesPendingUpload.get() \u003e 0) {\n        LOG.warn(\"Closing output stream statistics while data is still marked\" +\n            \" as pending upload in {}\", this);\n      }\n      mergeOutputStreamStatistics(this);\n    }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInstrumentation.java",
      "extendedDetails": {}
    },
    "27c4e90efce04e1b1302f668b5eb22412e00d033": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13028 add low level counter metrics for S3A; use in read performance tests. contributed by: stevel\npatch includes\nHADOOP-12844 Recover when S3A fails on IOException in read()\nHADOOP-13058 S3A FS fails during init against a read-only FS if multipart purge\nHADOOP-13047 S3a Forward seek in stream length to be configurable\n",
      "commitDate": "12/05/16 11:24 AM",
      "commitName": "27c4e90efce04e1b1302f668b5eb22412e00d033",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,3 @@\n+    public void close() {\n+      mergeInputStreamStatistics(this);\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public void close() {\n      mergeInputStreamStatistics(this);\n    }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInstrumentation.java"
    }
  }
}