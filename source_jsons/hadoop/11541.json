{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ProvidedVolumeImpl.java",
  "functionName": "rewind",
  "functionId": "rewind",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/ProvidedVolumeImpl.java",
  "functionStartLine": 451,
  "functionEndLine": 464,
  "numCommitsSeen": 17,
  "timeTaken": 2502,
  "changeHistory": [
    "9c35be86e17021202823bfd3c2067ff3b312ce5c",
    "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5",
    "b668eb91556b8c85c2b4925808ccb1f769031c20"
  ],
  "changeHistoryShort": {
    "9c35be86e17021202823bfd3c2067ff3b312ce5c": "Ybodychange",
    "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5": "Ybodychange",
    "b668eb91556b8c85c2b4925808ccb1f769031c20": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9c35be86e17021202823bfd3c2067ff3b312ce5c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12713. [READ] Refactor FileRegion and BlockAliasMap to separate out HDFS metadata and PROVIDED storage metadata. Contributed by Ewan Higgs\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "9c35be86e17021202823bfd3c2067ff3b312ce5c",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "a027055dd2bf5009fe272e9ceb08305bd0a8cc31",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n     public void rewind() {\n       BlockAliasMap.Reader\u003cFileRegion\u003e reader \u003d null;\n       try {\n-        reader \u003d blockAliasMap.getReader(null);\n+        reader \u003d blockAliasMap.getReader(null, bpid);\n       } catch (IOException e) {\n         LOG.warn(\"Exception in getting reader from provided alias map\");\n       }\n       if (reader !\u003d null) {\n         blockIterator \u003d reader.iterator();\n       } else {\n         blockIterator \u003d null;\n       }\n       state \u003d new ProvidedBlockIteratorState();\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void rewind() {\n      BlockAliasMap.Reader\u003cFileRegion\u003e reader \u003d null;\n      try {\n        reader \u003d blockAliasMap.getReader(null, bpid);\n      } catch (IOException e) {\n        LOG.warn(\"Exception in getting reader from provided alias map\");\n      }\n      if (reader !\u003d null) {\n        blockIterator \u003d reader.iterator();\n      } else {\n        blockIterator \u003d null;\n      }\n      state \u003d new ProvidedBlockIteratorState();\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/ProvidedVolumeImpl.java",
      "extendedDetails": {}
    },
    "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11902. [READ] Merge BlockFormatProvider and FileRegionProvider.\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "2407c9b93aabb021b76c802b19c928fb6cbb0a85",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,14 @@\n     public void rewind() {\n-      blockIterator \u003d provider.iterator();\n+      BlockAliasMap.Reader\u003cFileRegion\u003e reader \u003d null;\n+      try {\n+        reader \u003d blockAliasMap.getReader(null);\n+      } catch (IOException e) {\n+        LOG.warn(\"Exception in getting reader from provided alias map\");\n+      }\n+      if (reader !\u003d null) {\n+        blockIterator \u003d reader.iterator();\n+      } else {\n+        blockIterator \u003d null;\n+      }\n       state \u003d new ProvidedBlockIteratorState();\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void rewind() {\n      BlockAliasMap.Reader\u003cFileRegion\u003e reader \u003d null;\n      try {\n        reader \u003d blockAliasMap.getReader(null);\n      } catch (IOException e) {\n        LOG.warn(\"Exception in getting reader from provided alias map\");\n      }\n      if (reader !\u003d null) {\n        blockIterator \u003d reader.iterator();\n      } else {\n        blockIterator \u003d null;\n      }\n      state \u003d new ProvidedBlockIteratorState();\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/ProvidedVolumeImpl.java",
      "extendedDetails": {}
    },
    "b668eb91556b8c85c2b4925808ccb1f769031c20": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-10675. Datanode support to read from external stores.\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "b668eb91556b8c85c2b4925808ccb1f769031c20",
      "commitAuthor": "Virajith Jalaparti",
      "diff": "@@ -0,0 +1,4 @@\n+    public void rewind() {\n+      blockIterator \u003d provider.iterator();\n+      state \u003d new ProvidedBlockIteratorState();\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public void rewind() {\n      blockIterator \u003d provider.iterator();\n      state \u003d new ProvidedBlockIteratorState();\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/ProvidedVolumeImpl.java"
    }
  }
}