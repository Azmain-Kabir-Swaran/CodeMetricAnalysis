{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImageFormat.java",
  "functionName": "addToParent",
  "functionId": "addToParent___parent-INodeDirectory__child-INode",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
  "functionStartLine": 670,
  "functionEndLine": 686,
  "numCommitsSeen": 197,
  "timeTaken": 9052,
  "changeHistory": [
    "25051c3bd08efc12333a6acb51782cc7800403a4",
    "d6bd920bba0d7cb77ca76c3a79d1ba1e039da9e5",
    "a6250a4943d90c10bcfe9a2a46d6558c6d1a2d50",
    "0b101bd7e875ee5597ddb8f0d887159076310ffa",
    "980e6c54bab4ffc87e168cd5c217fef44c72a878",
    "b1333e5b561d01a010e2e1311e8501879f377bdc",
    "c7cf85ccb4ff2f58839e113f1baf903a468b606d",
    "02e6b72ae148fc8c2ba02ef624536b9e48997b31",
    "b9f965de120b5278ac84a7e98aecb32aafde4c16",
    "cbbaa93ae09bf5cf643263faf78f99315c4f3a8d",
    "9821af9ce8a56a2c583f1ed938902c20e897048f",
    "9047eb516261b8c9c380d140a43dfdd5d701dee5",
    "506938f0b323784f58f1ca398ac2475b473d1670",
    "d66f9e8269424f588180f2659c8cf132a2a7dfc9",
    "d174f574bafcfefc635c64a47f258b1ce5d5c84e",
    "c1bd54daa3724b0646d2bdbe666b7d44048953ba",
    "7e8e983620f3ae3462d115972707c72b7d9cbabd",
    "10dc6b09272dbf2022907681e134104e7d418021",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "25051c3bd08efc12333a6acb51782cc7800403a4": "Yexceptionschange",
    "d6bd920bba0d7cb77ca76c3a79d1ba1e039da9e5": "Ybodychange",
    "a6250a4943d90c10bcfe9a2a46d6558c6d1a2d50": "Ybodychange",
    "0b101bd7e875ee5597ddb8f0d887159076310ffa": "Ybodychange",
    "980e6c54bab4ffc87e168cd5c217fef44c72a878": "Ybodychange",
    "b1333e5b561d01a010e2e1311e8501879f377bdc": "Ybodychange",
    "c7cf85ccb4ff2f58839e113f1baf903a468b606d": "Ybodychange",
    "02e6b72ae148fc8c2ba02ef624536b9e48997b31": "Ybodychange",
    "b9f965de120b5278ac84a7e98aecb32aafde4c16": "Ybodychange",
    "cbbaa93ae09bf5cf643263faf78f99315c4f3a8d": "Ymodifierchange",
    "9821af9ce8a56a2c583f1ed938902c20e897048f": "Ybodychange",
    "9047eb516261b8c9c380d140a43dfdd5d701dee5": "Ybodychange",
    "506938f0b323784f58f1ca398ac2475b473d1670": "Ymultichange(Ymovefromfile,Yreturntypechange,Ybodychange,Yparameterchange)",
    "d66f9e8269424f588180f2659c8cf132a2a7dfc9": "Ymultichange(Yparameterchange,Ybodychange)",
    "d174f574bafcfefc635c64a47f258b1ce5d5c84e": "Ybodychange",
    "c1bd54daa3724b0646d2bdbe666b7d44048953ba": "Yexceptionschange",
    "7e8e983620f3ae3462d115972707c72b7d9cbabd": "Ybodychange",
    "10dc6b09272dbf2022907681e134104e7d418021": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "25051c3bd08efc12333a6acb51782cc7800403a4": {
      "type": "Yexceptionschange",
      "commitMessage": "HDFS-9569. Log the name of the fsimage being loaded for better supportability. (Yongjun Zhang)\n",
      "commitDate": "12/01/16 9:22 AM",
      "commitName": "25051c3bd08efc12333a6acb51782cc7800403a4",
      "commitAuthor": "Yongjun Zhang",
      "commitDateOld": "27/08/15 1:02 AM",
      "commitNameOld": "164cbe643988f878f0f4100a4de51783e5b6738e",
      "commitAuthorOld": "Walter Su",
      "daysBetweenCommits": 138.39,
      "commitsBetweenForRepo": 944,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,17 @@\n-  private void addToParent(INodeDirectory parent, INode child) {\n+  private void addToParent(INodeDirectory parent, INode child)\n+      throws IllegalReservedPathException {\n     FSDirectory fsDir \u003d namesystem.dir;\n     if (parent \u003d\u003d fsDir.rootDir) {\n         child.setLocalName(renameReservedRootComponentOnUpgrade(\n             child.getLocalNameBytes(), getLayoutVersion()));\n     }\n     // NOTE: This does not update space counts for parents\n     if (!parent.addChild(child)) {\n       return;\n     }\n     namesystem.dir.cacheName(child);\n \n     if (child.isFile()) {\n       updateBlocksMap(child.asFile());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addToParent(INodeDirectory parent, INode child)\n      throws IllegalReservedPathException {\n    FSDirectory fsDir \u003d namesystem.dir;\n    if (parent \u003d\u003d fsDir.rootDir) {\n        child.setLocalName(renameReservedRootComponentOnUpgrade(\n            child.getLocalNameBytes(), getLayoutVersion()));\n    }\n    // NOTE: This does not update space counts for parents\n    if (!parent.addChild(child)) {\n      return;\n    }\n    namesystem.dir.cacheName(child);\n\n    if (child.isFile()) {\n      updateBlocksMap(child.asFile());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[IllegalReservedPathException]"
      }
    },
    "d6bd920bba0d7cb77ca76c3a79d1ba1e039da9e5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5709. Improve NameNode upgrade with existing reserved paths and path components. Contributed by Andrew Wang.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1564645 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/02/14 10:48 PM",
      "commitName": "d6bd920bba0d7cb77ca76c3a79d1ba1e039da9e5",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "16/01/14 5:32 PM",
      "commitNameOld": "a7ec44d41b0ad1fa133408a10caaae32a27ea569",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 19.22,
      "commitsBetweenForRepo": 121,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,16 @@\n   private void addToParent(INodeDirectory parent, INode child) {\n     FSDirectory fsDir \u003d namesystem.dir;\n-    if (parent \u003d\u003d fsDir.rootDir \u0026\u0026 FSDirectory.isReservedName(child)) {\n-        throw new HadoopIllegalArgumentException(\"File name \\\"\"\n-            + child.getLocalName() + \"\\\" is reserved. Please \"\n-            + \" change the name of the existing file or directory to another \"\n-            + \"name before upgrading to this release.\");\n+    if (parent \u003d\u003d fsDir.rootDir) {\n+        child.setLocalName(renameReservedRootComponentOnUpgrade(\n+            child.getLocalNameBytes(), getLayoutVersion()));\n     }\n     // NOTE: This does not update space counts for parents\n     if (!parent.addChild(child)) {\n       return;\n     }\n     namesystem.dir.cacheName(child);\n \n     if (child.isFile()) {\n       updateBlocksMap(child.asFile());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addToParent(INodeDirectory parent, INode child) {\n    FSDirectory fsDir \u003d namesystem.dir;\n    if (parent \u003d\u003d fsDir.rootDir) {\n        child.setLocalName(renameReservedRootComponentOnUpgrade(\n            child.getLocalNameBytes(), getLayoutVersion()));\n    }\n    // NOTE: This does not update space counts for parents\n    if (!parent.addChild(child)) {\n      return;\n    }\n    namesystem.dir.cacheName(child);\n\n    if (child.isFile()) {\n      updateBlocksMap(child.asFile());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "a6250a4943d90c10bcfe9a2a46d6558c6d1a2d50": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5427. Not able to read deleted files from snapshot directly under snapshottable dir after checkpoint and NN restart. Contributed by Vinay.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1538875 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/11/13 10:38 PM",
      "commitName": "a6250a4943d90c10bcfe9a2a46d6558c6d1a2d50",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "04/10/13 10:46 AM",
      "commitNameOld": "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 31.54,
      "commitsBetweenForRepo": 196,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,18 @@\n   private void addToParent(INodeDirectory parent, INode child) {\n     FSDirectory fsDir \u003d namesystem.dir;\n     if (parent \u003d\u003d fsDir.rootDir \u0026\u0026 FSDirectory.isReservedName(child)) {\n         throw new HadoopIllegalArgumentException(\"File name \\\"\"\n             + child.getLocalName() + \"\\\" is reserved. Please \"\n             + \" change the name of the existing file or directory to another \"\n             + \"name before upgrading to this release.\");\n     }\n     // NOTE: This does not update space counts for parents\n     if (!parent.addChild(child)) {\n       return;\n     }\n     namesystem.dir.cacheName(child);\n \n     if (child.isFile()) {\n-      // Add file-\u003eblock mapping\n-      final INodeFile file \u003d child.asFile();\n-      final BlockInfo[] blocks \u003d file.getBlocks();\n-      if (blocks !\u003d null) {\n-        final BlockManager bm \u003d namesystem.getBlockManager();\n-        for (int i \u003d 0; i \u003c blocks.length; i++) {\n-          file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n-        } \n-      }\n+      updateBlocksMap(child.asFile());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addToParent(INodeDirectory parent, INode child) {\n    FSDirectory fsDir \u003d namesystem.dir;\n    if (parent \u003d\u003d fsDir.rootDir \u0026\u0026 FSDirectory.isReservedName(child)) {\n        throw new HadoopIllegalArgumentException(\"File name \\\"\"\n            + child.getLocalName() + \"\\\" is reserved. Please \"\n            + \" change the name of the existing file or directory to another \"\n            + \"name before upgrading to this release.\");\n    }\n    // NOTE: This does not update space counts for parents\n    if (!parent.addChild(child)) {\n      return;\n    }\n    namesystem.dir.cacheName(child);\n\n    if (child.isFile()) {\n      updateBlocksMap(child.asFile());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "0b101bd7e875ee5597ddb8f0d887159076310ffa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4434. Reverting change r1470089 that merges trunk to HDFS-2802.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1470194 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/04/13 9:57 AM",
      "commitName": "0b101bd7e875ee5597ddb8f0d887159076310ffa",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "19/04/13 5:02 PM",
      "commitNameOld": "9af0babe7ef9c4bc956b77aac250f8eee6c8450f",
      "commitAuthorOld": "",
      "daysBetweenCommits": 0.7,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,19 @@\n   private void addToParent(INodeDirectory parent, INode child) {\n-    FSDirectory fsDir \u003d namesystem.dir;\n-    if (parent \u003d\u003d fsDir.rootDir \u0026\u0026 FSDirectory.isReservedName(child)) {\n-        throw new HadoopIllegalArgumentException(\"File name \\\"\"\n-            + child.getLocalName() + \"\\\" is reserved. Please \"\n-            + \" change the name of the existing file or directory to another \"\n-            + \"name before upgrading to this release.\");\n-    }\n     // NOTE: This does not update space counts for parents\n     if (!parent.addChild(child)) {\n       return;\n     }\n     namesystem.dir.cacheName(child);\n \n     if (child.isFile()) {\n       // Add file-\u003eblock mapping\n       final INodeFile file \u003d child.asFile();\n       final BlockInfo[] blocks \u003d file.getBlocks();\n       if (blocks !\u003d null) {\n         final BlockManager bm \u003d namesystem.getBlockManager();\n         for (int i \u003d 0; i \u003c blocks.length; i++) {\n           file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n         } \n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addToParent(INodeDirectory parent, INode child) {\n    // NOTE: This does not update space counts for parents\n    if (!parent.addChild(child)) {\n      return;\n    }\n    namesystem.dir.cacheName(child);\n\n    if (child.isFile()) {\n      // Add file-\u003eblock mapping\n      final INodeFile file \u003d child.asFile();\n      final BlockInfo[] blocks \u003d file.getBlocks();\n      if (blocks !\u003d null) {\n        final BlockManager bm \u003d namesystem.getBlockManager();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n        } \n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "980e6c54bab4ffc87e168cd5c217fef44c72a878": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4434. Provide a mapping from INodeId to INode. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1469644 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/04/13 5:10 PM",
      "commitName": "980e6c54bab4ffc87e168cd5c217fef44c72a878",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "08/04/13 4:57 PM",
      "commitNameOld": "19201622be1db8e166d1cc0dd7e62af4702d2784",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 10.01,
      "commitsBetweenForRepo": 60,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,24 @@\n   void addToParent(INodeDirectory parent, INode child) {\n+    FSDirectory fsDir \u003d namesystem.dir;\n+    if (parent \u003d\u003d fsDir.rootDir \u0026\u0026 FSDirectory.isReservedName(child)) {\n+        throw new HadoopIllegalArgumentException(\"File name \\\"\"\n+            + child.getLocalName() + \"\\\" is reserved. Please \"\n+            + \" change the name of the existing file or directory to another \"\n+            + \"name before upgrading to this release.\");\n+    }\n     // NOTE: This does not update space counts for parents\n     if (!parent.addChild(child, false)) {\n       return;\n     }\n     namesystem.dir.cacheName(child);\n \n     if (child.isFile()) {\n       // Add file-\u003eblock mapping\n       final INodeFile file \u003d (INodeFile)child;\n       final BlockInfo[] blocks \u003d file.getBlocks();\n       final BlockManager bm \u003d namesystem.getBlockManager();\n       for (int i \u003d 0; i \u003c blocks.length; i++) {\n         file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addToParent(INodeDirectory parent, INode child) {\n    FSDirectory fsDir \u003d namesystem.dir;\n    if (parent \u003d\u003d fsDir.rootDir \u0026\u0026 FSDirectory.isReservedName(child)) {\n        throw new HadoopIllegalArgumentException(\"File name \\\"\"\n            + child.getLocalName() + \"\\\" is reserved. Please \"\n            + \" change the name of the existing file or directory to another \"\n            + \"name before upgrading to this release.\");\n    }\n    // NOTE: This does not update space counts for parents\n    if (!parent.addChild(child, false)) {\n      return;\n    }\n    namesystem.dir.cacheName(child);\n\n    if (child.isFile()) {\n      // Add file-\u003eblock mapping\n      final INodeFile file \u003d (INodeFile)child;\n      final BlockInfo[] blocks \u003d file.getBlocks();\n      final BlockManager bm \u003d namesystem.getBlockManager();\n      for (int i \u003d 0; i \u003c blocks.length; i++) {\n        file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "b1333e5b561d01a010e2e1311e8501879f377bdc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4545. With snapshots, FSDirectory.unprotectedSetReplication(..) always changes file replication but it may or may not changes block replication.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1452636 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/03/13 6:23 PM",
      "commitName": "b1333e5b561d01a010e2e1311e8501879f377bdc",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "27/02/13 7:08 PM",
      "commitNameOld": "c7cf85ccb4ff2f58839e113f1baf903a468b606d",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 4.97,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n   private void addToParent(INodeDirectory parent, INode child) {\n     // NOTE: This does not update space counts for parents\n     if (!parent.addChild(child)) {\n       return;\n     }\n     namesystem.dir.cacheName(child);\n \n     if (child.isFile()) {\n       // Add file-\u003eblock mapping\n-      final INodeFile file \u003d (INodeFile)child;\n+      final INodeFile file \u003d child.asFile();\n       final BlockInfo[] blocks \u003d file.getBlocks();\n       if (blocks !\u003d null) {\n         final BlockManager bm \u003d namesystem.getBlockManager();\n         for (int i \u003d 0; i \u003c blocks.length; i++) {\n           file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n         } \n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addToParent(INodeDirectory parent, INode child) {\n    // NOTE: This does not update space counts for parents\n    if (!parent.addChild(child)) {\n      return;\n    }\n    namesystem.dir.cacheName(child);\n\n    if (child.isFile()) {\n      // Add file-\u003eblock mapping\n      final INodeFile file \u003d child.asFile();\n      final BlockInfo[] blocks \u003d file.getBlocks();\n      if (blocks !\u003d null) {\n        final BlockManager bm \u003d namesystem.getBlockManager();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n        } \n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "c7cf85ccb4ff2f58839e113f1baf903a468b606d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4507. Update quota verification for snapshots.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1451081 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/02/13 7:08 PM",
      "commitName": "c7cf85ccb4ff2f58839e113f1baf903a468b606d",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "22/02/13 6:44 PM",
      "commitNameOld": "0deff1727ec4c82bc8babb63e6422be3fcd076f1",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 5.02,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n   private void addToParent(INodeDirectory parent, INode child) {\n     // NOTE: This does not update space counts for parents\n-    if (!parent.addChild(child, false, null)) {\n+    if (!parent.addChild(child)) {\n       return;\n     }\n     namesystem.dir.cacheName(child);\n \n     if (child.isFile()) {\n       // Add file-\u003eblock mapping\n       final INodeFile file \u003d (INodeFile)child;\n       final BlockInfo[] blocks \u003d file.getBlocks();\n       if (blocks !\u003d null) {\n         final BlockManager bm \u003d namesystem.getBlockManager();\n         for (int i \u003d 0; i \u003c blocks.length; i++) {\n           file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n         } \n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addToParent(INodeDirectory parent, INode child) {\n    // NOTE: This does not update space counts for parents\n    if (!parent.addChild(child)) {\n      return;\n    }\n    namesystem.dir.cacheName(child);\n\n    if (child.isFile()) {\n      // Add file-\u003eblock mapping\n      final INodeFile file \u003d (INodeFile)child;\n      final BlockInfo[] blocks \u003d file.getBlocks();\n      if (blocks !\u003d null) {\n        final BlockManager bm \u003d namesystem.getBlockManager();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n        } \n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "02e6b72ae148fc8c2ba02ef624536b9e48997b31": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4481. Change fsimage to support snapshot file diffs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1446000 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/02/13 4:43 PM",
      "commitName": "02e6b72ae148fc8c2ba02ef624536b9e48997b31",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "08/02/13 3:19 PM",
      "commitNameOld": "afe77ce53d3cf203690aa419e377f26cbd45a96e",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 5.06,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,19 @@\n   private void addToParent(INodeDirectory parent, INode child) {\n     // NOTE: This does not update space counts for parents\n     if (!parent.addChild(child, false, null)) {\n       return;\n     }\n     namesystem.dir.cacheName(child);\n \n     if (child.isFile()) {\n       // Add file-\u003eblock mapping\n       final INodeFile file \u003d (INodeFile)child;\n       final BlockInfo[] blocks \u003d file.getBlocks();\n-      final BlockManager bm \u003d namesystem.getBlockManager();\n-      for (int i \u003d 0; i \u003c blocks.length; i++) {\n-        file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n+      if (blocks !\u003d null) {\n+        final BlockManager bm \u003d namesystem.getBlockManager();\n+        for (int i \u003d 0; i \u003c blocks.length; i++) {\n+          file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n+        } \n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addToParent(INodeDirectory parent, INode child) {\n    // NOTE: This does not update space counts for parents\n    if (!parent.addChild(child, false, null)) {\n      return;\n    }\n    namesystem.dir.cacheName(child);\n\n    if (child.isFile()) {\n      // Add file-\u003eblock mapping\n      final INodeFile file \u003d (INodeFile)child;\n      final BlockInfo[] blocks \u003d file.getBlocks();\n      if (blocks !\u003d null) {\n        final BlockManager bm \u003d namesystem.getBlockManager();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n        } \n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "b9f965de120b5278ac84a7e98aecb32aafde4c16": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4103. Support O(1) snapshot creation.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1424782 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/12/12 5:30 PM",
      "commitName": "b9f965de120b5278ac84a7e98aecb32aafde4c16",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "16/12/12 7:40 PM",
      "commitNameOld": "cbbaa93ae09bf5cf643263faf78f99315c4f3a8d",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 3.91,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   private void addToParent(INodeDirectory parent, INode child) {\n     // NOTE: This does not update space counts for parents\n-    if (!parent.addChild(child, false)) {\n+    if (!parent.addChild(child, false, null)) {\n       return;\n     }\n     namesystem.dir.cacheName(child);\n \n     if (child.isFile()) {\n       // Add file-\u003eblock mapping\n       final INodeFile file \u003d (INodeFile)child;\n       final BlockInfo[] blocks \u003d file.getBlocks();\n       final BlockManager bm \u003d namesystem.getBlockManager();\n       for (int i \u003d 0; i \u003c blocks.length; i++) {\n         file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addToParent(INodeDirectory parent, INode child) {\n    // NOTE: This does not update space counts for parents\n    if (!parent.addChild(child, false, null)) {\n      return;\n    }\n    namesystem.dir.cacheName(child);\n\n    if (child.isFile()) {\n      // Add file-\u003eblock mapping\n      final INodeFile file \u003d (INodeFile)child;\n      final BlockInfo[] blocks \u003d file.getBlocks();\n      final BlockManager bm \u003d namesystem.getBlockManager();\n      for (int i \u003d 0; i \u003c blocks.length; i++) {\n        file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "cbbaa93ae09bf5cf643263faf78f99315c4f3a8d": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-4317. Change INode and its subclasses to support HDFS-4103.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1422748 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/12/12 7:40 PM",
      "commitName": "cbbaa93ae09bf5cf643263faf78f99315c4f3a8d",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "03/12/12 2:43 PM",
      "commitNameOld": "9821af9ce8a56a2c583f1ed938902c20e897048f",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 13.21,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n-  void addToParent(INodeDirectory parent, INode child) {\n+  private void addToParent(INodeDirectory parent, INode child) {\n     // NOTE: This does not update space counts for parents\n     if (!parent.addChild(child, false)) {\n       return;\n     }\n     namesystem.dir.cacheName(child);\n \n     if (child.isFile()) {\n       // Add file-\u003eblock mapping\n       final INodeFile file \u003d (INodeFile)child;\n       final BlockInfo[] blocks \u003d file.getBlocks();\n       final BlockManager bm \u003d namesystem.getBlockManager();\n       for (int i \u003d 0; i \u003c blocks.length; i++) {\n         file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addToParent(INodeDirectory parent, INode child) {\n    // NOTE: This does not update space counts for parents\n    if (!parent.addChild(child, false)) {\n      return;\n    }\n    namesystem.dir.cacheName(child);\n\n    if (child.isFile()) {\n      // Add file-\u003eblock mapping\n      final INodeFile file \u003d (INodeFile)child;\n      final BlockInfo[] blocks \u003d file.getBlocks();\n      final BlockManager bm \u003d namesystem.getBlockManager();\n      for (int i \u003d 0; i \u003c blocks.length; i++) {\n        file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[private]"
      }
    },
    "9821af9ce8a56a2c583f1ed938902c20e897048f": {
      "type": "Ybodychange",
      "commitMessage": "Reverting the previous merge r1416603 which committed some extra changes\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1416712 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/12/12 2:43 PM",
      "commitName": "9821af9ce8a56a2c583f1ed938902c20e897048f",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "03/12/12 10:04 AM",
      "commitNameOld": "d500d59cbef51f1b0b0291995893b85a139bcec9",
      "commitAuthorOld": "",
      "daysBetweenCommits": 0.19,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   void addToParent(INodeDirectory parent, INode child) {\n     // NOTE: This does not update space counts for parents\n-    if (!parent.addChild(child, false, null)) {\n+    if (!parent.addChild(child, false)) {\n       return;\n     }\n     namesystem.dir.cacheName(child);\n \n     if (child.isFile()) {\n       // Add file-\u003eblock mapping\n       final INodeFile file \u003d (INodeFile)child;\n       final BlockInfo[] blocks \u003d file.getBlocks();\n       final BlockManager bm \u003d namesystem.getBlockManager();\n       for (int i \u003d 0; i \u003c blocks.length; i++) {\n         file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addToParent(INodeDirectory parent, INode child) {\n    // NOTE: This does not update space counts for parents\n    if (!parent.addChild(child, false)) {\n      return;\n    }\n    namesystem.dir.cacheName(child);\n\n    if (child.isFile()) {\n      // Add file-\u003eblock mapping\n      final INodeFile file \u003d (INodeFile)child;\n      final BlockInfo[] blocks \u003d file.getBlocks();\n      final BlockManager bm \u003d namesystem.getBlockManager();\n      for (int i \u003d 0; i \u003c blocks.length; i++) {\n        file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "9047eb516261b8c9c380d140a43dfdd5d701dee5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4209. Clean up the addNode/addChild/addChildNoQuotaCheck methods in FSDirectory and INodeDirectory.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1414447 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/11/12 2:36 PM",
      "commitName": "9047eb516261b8c9c380d140a43dfdd5d701dee5",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "20/11/12 4:13 PM",
      "commitNameOld": "506938f0b323784f58f1ca398ac2475b473d1670",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 6.93,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   void addToParent(INodeDirectory parent, INode child) {\n     // NOTE: This does not update space counts for parents\n-    if (parent.addChild(child, false) \u003d\u003d null) {\n+    if (!parent.addChild(child, false)) {\n       return;\n     }\n     namesystem.dir.cacheName(child);\n \n     if (child.isFile()) {\n       // Add file-\u003eblock mapping\n       final INodeFile file \u003d (INodeFile)child;\n       final BlockInfo[] blocks \u003d file.getBlocks();\n       final BlockManager bm \u003d namesystem.getBlockManager();\n       for (int i \u003d 0; i \u003c blocks.length; i++) {\n         file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addToParent(INodeDirectory parent, INode child) {\n    // NOTE: This does not update space counts for parents\n    if (!parent.addChild(child, false)) {\n      return;\n    }\n    namesystem.dir.cacheName(child);\n\n    if (child.isFile()) {\n      // Add file-\u003eblock mapping\n      final INodeFile file \u003d (INodeFile)child;\n      final BlockInfo[] blocks \u003d file.getBlocks();\n      final BlockManager bm \u003d namesystem.getBlockManager();\n      for (int i \u003d 0; i \u003c blocks.length; i++) {\n        file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "506938f0b323784f58f1ca398ac2475b473d1670": {
      "type": "Ymultichange(Ymovefromfile,Yreturntypechange,Ybodychange,Yparameterchange)",
      "commitMessage": "HDFS-4215. Remove locking from addToParent(..) since it is used in image loading, and add INode.isFile().\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1411947 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/11/12 4:13 PM",
      "commitName": "506938f0b323784f58f1ca398ac2475b473d1670",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-4215. Remove locking from addToParent(..) since it is used in image loading, and add INode.isFile().\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1411947 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/11/12 4:13 PM",
          "commitName": "506938f0b323784f58f1ca398ac2475b473d1670",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "20/11/12 1:22 PM",
          "commitNameOld": "7dff42e798c4ec082d136800deb77c1d158f8481",
          "commitAuthorOld": "Thomas Graves",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,17 @@\n-  INodeDirectory addToParent(INodeDirectory parentINode,\n-      INode newNode, boolean propagateModTime) {\n+  void addToParent(INodeDirectory parent, INode child) {\n     // NOTE: This does not update space counts for parents\n-    INodeDirectory newParent \u003d null;\n-    writeLock();\n-    try {\n-      try {\n-        newParent \u003d rootDir.addToParent(newNode, parentINode,\n-                                        propagateModTime);\n-        cacheName(newNode);\n-      } catch (FileNotFoundException e) {\n-        return null;\n-      }\n-      if(newParent \u003d\u003d null)\n-        return null;\n-      if(!newNode.isDirectory() \u0026\u0026 !newNode.isSymlink()) {\n-        // Add file-\u003eblock mapping\n-        INodeFile newF \u003d (INodeFile)newNode;\n-        BlockInfo[] blocks \u003d newF.getBlocks();\n-        for (int i \u003d 0; i \u003c blocks.length; i++) {\n-          newF.setBlock(i, getBlockManager().addBlockCollection(blocks[i], newF));\n-        }\n-      }\n-    } finally {\n-      writeUnlock();\n+    if (parent.addChild(child, false) \u003d\u003d null) {\n+      return;\n     }\n-    return newParent;\n+    namesystem.dir.cacheName(child);\n+\n+    if (child.isFile()) {\n+      // Add file-\u003eblock mapping\n+      final INodeFile file \u003d (INodeFile)child;\n+      final BlockInfo[] blocks \u003d file.getBlocks();\n+      final BlockManager bm \u003d namesystem.getBlockManager();\n+      for (int i \u003d 0; i \u003c blocks.length; i++) {\n+        file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n+      }\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void addToParent(INodeDirectory parent, INode child) {\n    // NOTE: This does not update space counts for parents\n    if (parent.addChild(child, false) \u003d\u003d null) {\n      return;\n    }\n    namesystem.dir.cacheName(child);\n\n    if (child.isFile()) {\n      // Add file-\u003eblock mapping\n      final INodeFile file \u003d (INodeFile)child;\n      final BlockInfo[] blocks \u003d file.getBlocks();\n      final BlockManager bm \u003d namesystem.getBlockManager();\n      for (int i \u003d 0; i \u003c blocks.length; i++) {\n        file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
            "oldMethodName": "addToParent",
            "newMethodName": "addToParent"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-4215. Remove locking from addToParent(..) since it is used in image loading, and add INode.isFile().\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1411947 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/11/12 4:13 PM",
          "commitName": "506938f0b323784f58f1ca398ac2475b473d1670",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "20/11/12 1:22 PM",
          "commitNameOld": "7dff42e798c4ec082d136800deb77c1d158f8481",
          "commitAuthorOld": "Thomas Graves",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,17 @@\n-  INodeDirectory addToParent(INodeDirectory parentINode,\n-      INode newNode, boolean propagateModTime) {\n+  void addToParent(INodeDirectory parent, INode child) {\n     // NOTE: This does not update space counts for parents\n-    INodeDirectory newParent \u003d null;\n-    writeLock();\n-    try {\n-      try {\n-        newParent \u003d rootDir.addToParent(newNode, parentINode,\n-                                        propagateModTime);\n-        cacheName(newNode);\n-      } catch (FileNotFoundException e) {\n-        return null;\n-      }\n-      if(newParent \u003d\u003d null)\n-        return null;\n-      if(!newNode.isDirectory() \u0026\u0026 !newNode.isSymlink()) {\n-        // Add file-\u003eblock mapping\n-        INodeFile newF \u003d (INodeFile)newNode;\n-        BlockInfo[] blocks \u003d newF.getBlocks();\n-        for (int i \u003d 0; i \u003c blocks.length; i++) {\n-          newF.setBlock(i, getBlockManager().addBlockCollection(blocks[i], newF));\n-        }\n-      }\n-    } finally {\n-      writeUnlock();\n+    if (parent.addChild(child, false) \u003d\u003d null) {\n+      return;\n     }\n-    return newParent;\n+    namesystem.dir.cacheName(child);\n+\n+    if (child.isFile()) {\n+      // Add file-\u003eblock mapping\n+      final INodeFile file \u003d (INodeFile)child;\n+      final BlockInfo[] blocks \u003d file.getBlocks();\n+      final BlockManager bm \u003d namesystem.getBlockManager();\n+      for (int i \u003d 0; i \u003c blocks.length; i++) {\n+        file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n+      }\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void addToParent(INodeDirectory parent, INode child) {\n    // NOTE: This does not update space counts for parents\n    if (parent.addChild(child, false) \u003d\u003d null) {\n      return;\n    }\n    namesystem.dir.cacheName(child);\n\n    if (child.isFile()) {\n      // Add file-\u003eblock mapping\n      final INodeFile file \u003d (INodeFile)child;\n      final BlockInfo[] blocks \u003d file.getBlocks();\n      final BlockManager bm \u003d namesystem.getBlockManager();\n      for (int i \u003d 0; i \u003c blocks.length; i++) {\n        file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
          "extendedDetails": {
            "oldValue": "INodeDirectory",
            "newValue": "void"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4215. Remove locking from addToParent(..) since it is used in image loading, and add INode.isFile().\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1411947 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/11/12 4:13 PM",
          "commitName": "506938f0b323784f58f1ca398ac2475b473d1670",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "20/11/12 1:22 PM",
          "commitNameOld": "7dff42e798c4ec082d136800deb77c1d158f8481",
          "commitAuthorOld": "Thomas Graves",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,17 @@\n-  INodeDirectory addToParent(INodeDirectory parentINode,\n-      INode newNode, boolean propagateModTime) {\n+  void addToParent(INodeDirectory parent, INode child) {\n     // NOTE: This does not update space counts for parents\n-    INodeDirectory newParent \u003d null;\n-    writeLock();\n-    try {\n-      try {\n-        newParent \u003d rootDir.addToParent(newNode, parentINode,\n-                                        propagateModTime);\n-        cacheName(newNode);\n-      } catch (FileNotFoundException e) {\n-        return null;\n-      }\n-      if(newParent \u003d\u003d null)\n-        return null;\n-      if(!newNode.isDirectory() \u0026\u0026 !newNode.isSymlink()) {\n-        // Add file-\u003eblock mapping\n-        INodeFile newF \u003d (INodeFile)newNode;\n-        BlockInfo[] blocks \u003d newF.getBlocks();\n-        for (int i \u003d 0; i \u003c blocks.length; i++) {\n-          newF.setBlock(i, getBlockManager().addBlockCollection(blocks[i], newF));\n-        }\n-      }\n-    } finally {\n-      writeUnlock();\n+    if (parent.addChild(child, false) \u003d\u003d null) {\n+      return;\n     }\n-    return newParent;\n+    namesystem.dir.cacheName(child);\n+\n+    if (child.isFile()) {\n+      // Add file-\u003eblock mapping\n+      final INodeFile file \u003d (INodeFile)child;\n+      final BlockInfo[] blocks \u003d file.getBlocks();\n+      final BlockManager bm \u003d namesystem.getBlockManager();\n+      for (int i \u003d 0; i \u003c blocks.length; i++) {\n+        file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n+      }\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void addToParent(INodeDirectory parent, INode child) {\n    // NOTE: This does not update space counts for parents\n    if (parent.addChild(child, false) \u003d\u003d null) {\n      return;\n    }\n    namesystem.dir.cacheName(child);\n\n    if (child.isFile()) {\n      // Add file-\u003eblock mapping\n      final INodeFile file \u003d (INodeFile)child;\n      final BlockInfo[] blocks \u003d file.getBlocks();\n      final BlockManager bm \u003d namesystem.getBlockManager();\n      for (int i \u003d 0; i \u003c blocks.length; i++) {\n        file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4215. Remove locking from addToParent(..) since it is used in image loading, and add INode.isFile().\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1411947 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/11/12 4:13 PM",
          "commitName": "506938f0b323784f58f1ca398ac2475b473d1670",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "20/11/12 1:22 PM",
          "commitNameOld": "7dff42e798c4ec082d136800deb77c1d158f8481",
          "commitAuthorOld": "Thomas Graves",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,17 @@\n-  INodeDirectory addToParent(INodeDirectory parentINode,\n-      INode newNode, boolean propagateModTime) {\n+  void addToParent(INodeDirectory parent, INode child) {\n     // NOTE: This does not update space counts for parents\n-    INodeDirectory newParent \u003d null;\n-    writeLock();\n-    try {\n-      try {\n-        newParent \u003d rootDir.addToParent(newNode, parentINode,\n-                                        propagateModTime);\n-        cacheName(newNode);\n-      } catch (FileNotFoundException e) {\n-        return null;\n-      }\n-      if(newParent \u003d\u003d null)\n-        return null;\n-      if(!newNode.isDirectory() \u0026\u0026 !newNode.isSymlink()) {\n-        // Add file-\u003eblock mapping\n-        INodeFile newF \u003d (INodeFile)newNode;\n-        BlockInfo[] blocks \u003d newF.getBlocks();\n-        for (int i \u003d 0; i \u003c blocks.length; i++) {\n-          newF.setBlock(i, getBlockManager().addBlockCollection(blocks[i], newF));\n-        }\n-      }\n-    } finally {\n-      writeUnlock();\n+    if (parent.addChild(child, false) \u003d\u003d null) {\n+      return;\n     }\n-    return newParent;\n+    namesystem.dir.cacheName(child);\n+\n+    if (child.isFile()) {\n+      // Add file-\u003eblock mapping\n+      final INodeFile file \u003d (INodeFile)child;\n+      final BlockInfo[] blocks \u003d file.getBlocks();\n+      final BlockManager bm \u003d namesystem.getBlockManager();\n+      for (int i \u003d 0; i \u003c blocks.length; i++) {\n+        file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n+      }\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void addToParent(INodeDirectory parent, INode child) {\n    // NOTE: This does not update space counts for parents\n    if (parent.addChild(child, false) \u003d\u003d null) {\n      return;\n    }\n    namesystem.dir.cacheName(child);\n\n    if (child.isFile()) {\n      // Add file-\u003eblock mapping\n      final INodeFile file \u003d (INodeFile)child;\n      final BlockInfo[] blocks \u003d file.getBlocks();\n      final BlockManager bm \u003d namesystem.getBlockManager();\n      for (int i \u003d 0; i \u003c blocks.length; i++) {\n        file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
          "extendedDetails": {
            "oldValue": "[parentINode-INodeDirectory, newNode-INode, propagateModTime-boolean]",
            "newValue": "[parent-INodeDirectory, child-INode]"
          }
        }
      ]
    },
    "d66f9e8269424f588180f2659c8cf132a2a7dfc9": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-4206. Change the fields in INode and its subclasses to private.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1410996 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/11/12 2:03 PM",
      "commitName": "d66f9e8269424f588180f2659c8cf132a2a7dfc9",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4206. Change the fields in INode and its subclasses to private.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1410996 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/11/12 2:03 PM",
          "commitName": "d66f9e8269424f588180f2659c8cf132a2a7dfc9",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "14/11/12 11:21 AM",
          "commitNameOld": "59e4199d842d8590d2c73c6dba805a9746e1ef4a",
          "commitAuthorOld": "Robert Joseph Evans",
          "daysBetweenCommits": 4.11,
          "commitsBetweenForRepo": 26,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,28 @@\n-  INodeDirectory addToParent(byte[] src, INodeDirectory parentINode,\n+  INodeDirectory addToParent(INodeDirectory parentINode,\n       INode newNode, boolean propagateModTime) {\n     // NOTE: This does not update space counts for parents\n     INodeDirectory newParent \u003d null;\n     writeLock();\n     try {\n       try {\n-        newParent \u003d rootDir.addToParent(src, newNode, parentINode,\n+        newParent \u003d rootDir.addToParent(newNode, parentINode,\n                                         propagateModTime);\n         cacheName(newNode);\n       } catch (FileNotFoundException e) {\n         return null;\n       }\n       if(newParent \u003d\u003d null)\n         return null;\n       if(!newNode.isDirectory() \u0026\u0026 !newNode.isSymlink()) {\n         // Add file-\u003eblock mapping\n         INodeFile newF \u003d (INodeFile)newNode;\n         BlockInfo[] blocks \u003d newF.getBlocks();\n         for (int i \u003d 0; i \u003c blocks.length; i++) {\n           newF.setBlock(i, getBlockManager().addBlockCollection(blocks[i], newF));\n         }\n       }\n     } finally {\n       writeUnlock();\n     }\n     return newParent;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  INodeDirectory addToParent(INodeDirectory parentINode,\n      INode newNode, boolean propagateModTime) {\n    // NOTE: This does not update space counts for parents\n    INodeDirectory newParent \u003d null;\n    writeLock();\n    try {\n      try {\n        newParent \u003d rootDir.addToParent(newNode, parentINode,\n                                        propagateModTime);\n        cacheName(newNode);\n      } catch (FileNotFoundException e) {\n        return null;\n      }\n      if(newParent \u003d\u003d null)\n        return null;\n      if(!newNode.isDirectory() \u0026\u0026 !newNode.isSymlink()) {\n        // Add file-\u003eblock mapping\n        INodeFile newF \u003d (INodeFile)newNode;\n        BlockInfo[] blocks \u003d newF.getBlocks();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          newF.setBlock(i, getBlockManager().addBlockCollection(blocks[i], newF));\n        }\n      }\n    } finally {\n      writeUnlock();\n    }\n    return newParent;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[src-byte[], parentINode-INodeDirectory, newNode-INode, propagateModTime-boolean]",
            "newValue": "[parentINode-INodeDirectory, newNode-INode, propagateModTime-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4206. Change the fields in INode and its subclasses to private.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1410996 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/11/12 2:03 PM",
          "commitName": "d66f9e8269424f588180f2659c8cf132a2a7dfc9",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "14/11/12 11:21 AM",
          "commitNameOld": "59e4199d842d8590d2c73c6dba805a9746e1ef4a",
          "commitAuthorOld": "Robert Joseph Evans",
          "daysBetweenCommits": 4.11,
          "commitsBetweenForRepo": 26,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,28 @@\n-  INodeDirectory addToParent(byte[] src, INodeDirectory parentINode,\n+  INodeDirectory addToParent(INodeDirectory parentINode,\n       INode newNode, boolean propagateModTime) {\n     // NOTE: This does not update space counts for parents\n     INodeDirectory newParent \u003d null;\n     writeLock();\n     try {\n       try {\n-        newParent \u003d rootDir.addToParent(src, newNode, parentINode,\n+        newParent \u003d rootDir.addToParent(newNode, parentINode,\n                                         propagateModTime);\n         cacheName(newNode);\n       } catch (FileNotFoundException e) {\n         return null;\n       }\n       if(newParent \u003d\u003d null)\n         return null;\n       if(!newNode.isDirectory() \u0026\u0026 !newNode.isSymlink()) {\n         // Add file-\u003eblock mapping\n         INodeFile newF \u003d (INodeFile)newNode;\n         BlockInfo[] blocks \u003d newF.getBlocks();\n         for (int i \u003d 0; i \u003c blocks.length; i++) {\n           newF.setBlock(i, getBlockManager().addBlockCollection(blocks[i], newF));\n         }\n       }\n     } finally {\n       writeUnlock();\n     }\n     return newParent;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  INodeDirectory addToParent(INodeDirectory parentINode,\n      INode newNode, boolean propagateModTime) {\n    // NOTE: This does not update space counts for parents\n    INodeDirectory newParent \u003d null;\n    writeLock();\n    try {\n      try {\n        newParent \u003d rootDir.addToParent(newNode, parentINode,\n                                        propagateModTime);\n        cacheName(newNode);\n      } catch (FileNotFoundException e) {\n        return null;\n      }\n      if(newParent \u003d\u003d null)\n        return null;\n      if(!newNode.isDirectory() \u0026\u0026 !newNode.isSymlink()) {\n        // Add file-\u003eblock mapping\n        INodeFile newF \u003d (INodeFile)newNode;\n        BlockInfo[] blocks \u003d newF.getBlocks();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          newF.setBlock(i, getBlockManager().addBlockCollection(blocks[i], newF));\n        }\n      }\n    } finally {\n      writeUnlock();\n    }\n    return newParent;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {}
        }
      ]
    },
    "d174f574bafcfefc635c64a47f258b1ce5d5c84e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4143. Change blocks to private in INodeFile and renames isLink() to isSymlink() in INode.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1405237 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/11/12 5:20 PM",
      "commitName": "d174f574bafcfefc635c64a47f258b1ce5d5c84e",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "29/10/12 7:11 AM",
      "commitNameOld": "1b3b09d94794622e8336220d897a1f10c4654677",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 4.42,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n   INodeDirectory addToParent(byte[] src, INodeDirectory parentINode,\n       INode newNode, boolean propagateModTime) {\n     // NOTE: This does not update space counts for parents\n     INodeDirectory newParent \u003d null;\n     writeLock();\n     try {\n       try {\n         newParent \u003d rootDir.addToParent(src, newNode, parentINode,\n                                         propagateModTime);\n         cacheName(newNode);\n       } catch (FileNotFoundException e) {\n         return null;\n       }\n       if(newParent \u003d\u003d null)\n         return null;\n-      if(!newNode.isDirectory() \u0026\u0026 !newNode.isLink()) {\n+      if(!newNode.isDirectory() \u0026\u0026 !newNode.isSymlink()) {\n         // Add file-\u003eblock mapping\n         INodeFile newF \u003d (INodeFile)newNode;\n         BlockInfo[] blocks \u003d newF.getBlocks();\n         for (int i \u003d 0; i \u003c blocks.length; i++) {\n           newF.setBlock(i, getBlockManager().addBlockCollection(blocks[i], newF));\n         }\n       }\n     } finally {\n       writeUnlock();\n     }\n     return newParent;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  INodeDirectory addToParent(byte[] src, INodeDirectory parentINode,\n      INode newNode, boolean propagateModTime) {\n    // NOTE: This does not update space counts for parents\n    INodeDirectory newParent \u003d null;\n    writeLock();\n    try {\n      try {\n        newParent \u003d rootDir.addToParent(src, newNode, parentINode,\n                                        propagateModTime);\n        cacheName(newNode);\n      } catch (FileNotFoundException e) {\n        return null;\n      }\n      if(newParent \u003d\u003d null)\n        return null;\n      if(!newNode.isDirectory() \u0026\u0026 !newNode.isSymlink()) {\n        // Add file-\u003eblock mapping\n        INodeFile newF \u003d (INodeFile)newNode;\n        BlockInfo[] blocks \u003d newF.getBlocks();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          newF.setBlock(i, getBlockManager().addBlockCollection(blocks[i], newF));\n        }\n      }\n    } finally {\n      writeUnlock();\n    }\n    return newParent;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "c1bd54daa3724b0646d2bdbe666b7d44048953ba": {
      "type": "Yexceptionschange",
      "commitMessage": "HDFS-4073. Two minor improvements to FSDirectory.  Contributed by Jing Zhao\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1399861 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/10/12 2:18 PM",
      "commitName": "c1bd54daa3724b0646d2bdbe666b7d44048953ba",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "15/10/12 7:05 AM",
      "commitNameOld": "698fa5077ac742d025e979c053b54528e09357f3",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 3.3,
      "commitsBetweenForRepo": 29,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n   INodeDirectory addToParent(byte[] src, INodeDirectory parentINode,\n-      INode newNode, boolean propagateModTime) throws UnresolvedLinkException {\n+      INode newNode, boolean propagateModTime) {\n     // NOTE: This does not update space counts for parents\n     INodeDirectory newParent \u003d null;\n     writeLock();\n     try {\n       try {\n         newParent \u003d rootDir.addToParent(src, newNode, parentINode,\n                                         propagateModTime);\n         cacheName(newNode);\n       } catch (FileNotFoundException e) {\n         return null;\n       }\n       if(newParent \u003d\u003d null)\n         return null;\n       if(!newNode.isDirectory() \u0026\u0026 !newNode.isLink()) {\n         // Add file-\u003eblock mapping\n         INodeFile newF \u003d (INodeFile)newNode;\n         BlockInfo[] blocks \u003d newF.getBlocks();\n         for (int i \u003d 0; i \u003c blocks.length; i++) {\n           newF.setBlock(i, getBlockManager().addBlockCollection(blocks[i], newF));\n         }\n       }\n     } finally {\n       writeUnlock();\n     }\n     return newParent;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  INodeDirectory addToParent(byte[] src, INodeDirectory parentINode,\n      INode newNode, boolean propagateModTime) {\n    // NOTE: This does not update space counts for parents\n    INodeDirectory newParent \u003d null;\n    writeLock();\n    try {\n      try {\n        newParent \u003d rootDir.addToParent(src, newNode, parentINode,\n                                        propagateModTime);\n        cacheName(newNode);\n      } catch (FileNotFoundException e) {\n        return null;\n      }\n      if(newParent \u003d\u003d null)\n        return null;\n      if(!newNode.isDirectory() \u0026\u0026 !newNode.isLink()) {\n        // Add file-\u003eblock mapping\n        INodeFile newF \u003d (INodeFile)newNode;\n        BlockInfo[] blocks \u003d newF.getBlocks();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          newF.setBlock(i, getBlockManager().addBlockCollection(blocks[i], newF));\n        }\n      }\n    } finally {\n      writeUnlock();\n    }\n    return newParent;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {
        "oldValue": "[UnresolvedLinkException]",
        "newValue": "[]"
      }
    },
    "7e8e983620f3ae3462d115972707c72b7d9cbabd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3369. Rename {get|set|add}INode(..) methods in BlockManager and BlocksMap to {get|set|add}BlockCollection(..).  Contributed by John George\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1336909 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/05/12 2:41 PM",
      "commitName": "7e8e983620f3ae3462d115972707c72b7d9cbabd",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "29/02/12 4:37 PM",
      "commitNameOld": "30cffeb388f9065f0c5ce5fa53e127940a8917b6",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 70.88,
      "commitsBetweenForRepo": 491,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n   INodeDirectory addToParent(byte[] src, INodeDirectory parentINode,\n       INode newNode, boolean propagateModTime) throws UnresolvedLinkException {\n     // NOTE: This does not update space counts for parents\n     INodeDirectory newParent \u003d null;\n     writeLock();\n     try {\n       try {\n         newParent \u003d rootDir.addToParent(src, newNode, parentINode,\n                                         propagateModTime);\n         cacheName(newNode);\n       } catch (FileNotFoundException e) {\n         return null;\n       }\n       if(newParent \u003d\u003d null)\n         return null;\n       if(!newNode.isDirectory() \u0026\u0026 !newNode.isLink()) {\n         // Add file-\u003eblock mapping\n         INodeFile newF \u003d (INodeFile)newNode;\n         BlockInfo[] blocks \u003d newF.getBlocks();\n         for (int i \u003d 0; i \u003c blocks.length; i++) {\n-          newF.setBlock(i, getBlockManager().addINode(blocks[i], newF));\n+          newF.setBlock(i, getBlockManager().addBlockCollection(blocks[i], newF));\n         }\n       }\n     } finally {\n       writeUnlock();\n     }\n     return newParent;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  INodeDirectory addToParent(byte[] src, INodeDirectory parentINode,\n      INode newNode, boolean propagateModTime) throws UnresolvedLinkException {\n    // NOTE: This does not update space counts for parents\n    INodeDirectory newParent \u003d null;\n    writeLock();\n    try {\n      try {\n        newParent \u003d rootDir.addToParent(src, newNode, parentINode,\n                                        propagateModTime);\n        cacheName(newNode);\n      } catch (FileNotFoundException e) {\n        return null;\n      }\n      if(newParent \u003d\u003d null)\n        return null;\n      if(!newNode.isDirectory() \u0026\u0026 !newNode.isLink()) {\n        // Add file-\u003eblock mapping\n        INodeFile newF \u003d (INodeFile)newNode;\n        BlockInfo[] blocks \u003d newF.getBlocks();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          newF.setBlock(i, getBlockManager().addBlockCollection(blocks[i], newF));\n        }\n      }\n    } finally {\n      writeUnlock();\n    }\n    return newParent;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "10dc6b09272dbf2022907681e134104e7d418021": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1869. mkdirs should use the supplied permission for all of the created directories.  Contributed by Daryn Sharp\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1189546 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/10/11 5:02 PM",
      "commitName": "10dc6b09272dbf2022907681e134104e7d418021",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "22/09/11 1:25 AM",
      "commitNameOld": "d773bf0fb57bf6fb77dbdd52e1c186833c17361c",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 34.65,
      "commitsBetweenForRepo": 266,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n   INodeDirectory addToParent(byte[] src, INodeDirectory parentINode,\n       INode newNode, boolean propagateModTime) throws UnresolvedLinkException {\n     // NOTE: This does not update space counts for parents\n     INodeDirectory newParent \u003d null;\n     writeLock();\n     try {\n       try {\n         newParent \u003d rootDir.addToParent(src, newNode, parentINode,\n-                                        false, propagateModTime);\n+                                        propagateModTime);\n         cacheName(newNode);\n       } catch (FileNotFoundException e) {\n         return null;\n       }\n       if(newParent \u003d\u003d null)\n         return null;\n       if(!newNode.isDirectory() \u0026\u0026 !newNode.isLink()) {\n         // Add file-\u003eblock mapping\n         INodeFile newF \u003d (INodeFile)newNode;\n         BlockInfo[] blocks \u003d newF.getBlocks();\n         for (int i \u003d 0; i \u003c blocks.length; i++) {\n           newF.setBlock(i, getBlockManager().addINode(blocks[i], newF));\n         }\n       }\n     } finally {\n       writeUnlock();\n     }\n     return newParent;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  INodeDirectory addToParent(byte[] src, INodeDirectory parentINode,\n      INode newNode, boolean propagateModTime) throws UnresolvedLinkException {\n    // NOTE: This does not update space counts for parents\n    INodeDirectory newParent \u003d null;\n    writeLock();\n    try {\n      try {\n        newParent \u003d rootDir.addToParent(src, newNode, parentINode,\n                                        propagateModTime);\n        cacheName(newNode);\n      } catch (FileNotFoundException e) {\n        return null;\n      }\n      if(newParent \u003d\u003d null)\n        return null;\n      if(!newNode.isDirectory() \u0026\u0026 !newNode.isLink()) {\n        // Add file-\u003eblock mapping\n        INodeFile newF \u003d (INodeFile)newNode;\n        BlockInfo[] blocks \u003d newF.getBlocks();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          newF.setBlock(i, getBlockManager().addINode(blocks[i], newF));\n        }\n      }\n    } finally {\n      writeUnlock();\n    }\n    return newParent;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  INodeDirectory addToParent(byte[] src, INodeDirectory parentINode,\n      INode newNode, boolean propagateModTime) throws UnresolvedLinkException {\n    // NOTE: This does not update space counts for parents\n    INodeDirectory newParent \u003d null;\n    writeLock();\n    try {\n      try {\n        newParent \u003d rootDir.addToParent(src, newNode, parentINode,\n                                        false, propagateModTime);\n        cacheName(newNode);\n      } catch (FileNotFoundException e) {\n        return null;\n      }\n      if(newParent \u003d\u003d null)\n        return null;\n      if(!newNode.isDirectory() \u0026\u0026 !newNode.isLink()) {\n        // Add file-\u003eblock mapping\n        INodeFile newF \u003d (INodeFile)newNode;\n        BlockInfo[] blocks \u003d newF.getBlocks();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          newF.setBlock(i, getBlockManager().addINode(blocks[i], newF));\n        }\n      }\n    } finally {\n      writeUnlock();\n    }\n    return newParent;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  INodeDirectory addToParent(byte[] src, INodeDirectory parentINode,\n      INode newNode, boolean propagateModTime) throws UnresolvedLinkException {\n    // NOTE: This does not update space counts for parents\n    INodeDirectory newParent \u003d null;\n    writeLock();\n    try {\n      try {\n        newParent \u003d rootDir.addToParent(src, newNode, parentINode,\n                                        false, propagateModTime);\n        cacheName(newNode);\n      } catch (FileNotFoundException e) {\n        return null;\n      }\n      if(newParent \u003d\u003d null)\n        return null;\n      if(!newNode.isDirectory() \u0026\u0026 !newNode.isLink()) {\n        // Add file-\u003eblock mapping\n        INodeFile newF \u003d (INodeFile)newNode;\n        BlockInfo[] blocks \u003d newF.getBlocks();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          newF.setBlock(i, getBlockManager().addINode(blocks[i], newF));\n        }\n      }\n    } finally {\n      writeUnlock();\n    }\n    return newParent;\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,28 @@\n+  INodeDirectory addToParent(byte[] src, INodeDirectory parentINode,\n+      INode newNode, boolean propagateModTime) throws UnresolvedLinkException {\n+    // NOTE: This does not update space counts for parents\n+    INodeDirectory newParent \u003d null;\n+    writeLock();\n+    try {\n+      try {\n+        newParent \u003d rootDir.addToParent(src, newNode, parentINode,\n+                                        false, propagateModTime);\n+        cacheName(newNode);\n+      } catch (FileNotFoundException e) {\n+        return null;\n+      }\n+      if(newParent \u003d\u003d null)\n+        return null;\n+      if(!newNode.isDirectory() \u0026\u0026 !newNode.isLink()) {\n+        // Add file-\u003eblock mapping\n+        INodeFile newF \u003d (INodeFile)newNode;\n+        BlockInfo[] blocks \u003d newF.getBlocks();\n+        for (int i \u003d 0; i \u003c blocks.length; i++) {\n+          newF.setBlock(i, getBlockManager().addINode(blocks[i], newF));\n+        }\n+      }\n+    } finally {\n+      writeUnlock();\n+    }\n+    return newParent;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  INodeDirectory addToParent(byte[] src, INodeDirectory parentINode,\n      INode newNode, boolean propagateModTime) throws UnresolvedLinkException {\n    // NOTE: This does not update space counts for parents\n    INodeDirectory newParent \u003d null;\n    writeLock();\n    try {\n      try {\n        newParent \u003d rootDir.addToParent(src, newNode, parentINode,\n                                        false, propagateModTime);\n        cacheName(newNode);\n      } catch (FileNotFoundException e) {\n        return null;\n      }\n      if(newParent \u003d\u003d null)\n        return null;\n      if(!newNode.isDirectory() \u0026\u0026 !newNode.isLink()) {\n        // Add file-\u003eblock mapping\n        INodeFile newF \u003d (INodeFile)newNode;\n        BlockInfo[] blocks \u003d newF.getBlocks();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          newF.setBlock(i, getBlockManager().addINode(blocks[i], newF));\n        }\n      }\n    } finally {\n      writeUnlock();\n    }\n    return newParent;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java"
    }
  }
}