{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ContainerScheduler.java",
  "functionName": "pickOpportunisticContainersToReclaimResources",
  "functionId": "pickOpportunisticContainersToReclaimResources___containerToStartId-ContainerId",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/scheduler/ContainerScheduler.java",
  "functionStartLine": 554,
  "functionEndLine": 591,
  "numCommitsSeen": 43,
  "timeTaken": 4304,
  "changeHistory": [
    "4f8194430fc6a69d9cc99b78828fd7045d5683e8",
    "3219b7b4ac7d12aee343f6ab2980b3357fc618b6",
    "c8172f5f143d2fefafa5a412899ab7cd081b406d"
  ],
  "changeHistoryShort": {
    "4f8194430fc6a69d9cc99b78828fd7045d5683e8": "Yrename",
    "3219b7b4ac7d12aee343f6ab2980b3357fc618b6": "Ymultichange(Ymovefromfile,Yreturntypechange,Ymodifierchange,Ybodychange)",
    "c8172f5f143d2fefafa5a412899ab7cd081b406d": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4f8194430fc6a69d9cc99b78828fd7045d5683e8": {
      "type": "Yrename",
      "commitMessage": "YARN-5216. Expose configurable preemption policy for OPPORTUNISTIC containers running on the NM. (Hitesh Sharma via asuresh)\n",
      "commitDate": "14/09/17 8:51 AM",
      "commitName": "4f8194430fc6a69d9cc99b78828fd7045d5683e8",
      "commitAuthor": "Arun Suresh",
      "commitDateOld": "12/09/17 4:10 PM",
      "commitNameOld": "2ae72692fc370267141a1ee55ef372ff62302b54",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 1.7,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,38 @@\n-  private List\u003cContainer\u003e pickOpportunisticContainersToKill(\n+  private List\u003cContainer\u003e pickOpportunisticContainersToReclaimResources(\n       ContainerId containerToStartId) {\n     // The opportunistic containers that need to be killed for the\n     // given container to start.\n     List\u003cContainer\u003e extraOpportContainersToKill \u003d new ArrayList\u003c\u003e();\n     // Track resources that need to be freed.\n     ResourceUtilization resourcesToFreeUp \u003d resourcesToFreeUp(\n         containerToStartId);\n \n     // Go over the running opportunistic containers.\n     // Use a descending iterator to kill more recently started containers.\n     Iterator\u003cContainer\u003e lifoIterator \u003d new LinkedList\u003c\u003e(\n         runningContainers.values()).descendingIterator();\n     while(lifoIterator.hasNext() \u0026\u0026\n         !hasSufficientResources(resourcesToFreeUp)) {\n       Container runningCont \u003d lifoIterator.next();\n       if (runningCont.getContainerTokenIdentifier().getExecutionType() \u003d\u003d\n           ExecutionType.OPPORTUNISTIC) {\n \n         if (oppContainersToKill.containsKey(\n             runningCont.getContainerId())) {\n           // These containers have already been marked to be killed.\n           // So exclude them..\n           continue;\n         }\n         extraOpportContainersToKill.add(runningCont);\n         ContainersMonitor.decreaseResourceUtilization(\n             getContainersMonitor(), resourcesToFreeUp,\n             runningCont.getResource());\n       }\n     }\n     if (!hasSufficientResources(resourcesToFreeUp)) {\n       LOG.warn(\"There are no sufficient resources to start guaranteed [{}]\" +\n           \"at the moment. Opportunistic containers are in the process of\" +\n           \"being killed to make room.\", containerToStartId);\n     }\n     return extraOpportContainersToKill;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e pickOpportunisticContainersToReclaimResources(\n      ContainerId containerToStartId) {\n    // The opportunistic containers that need to be killed for the\n    // given container to start.\n    List\u003cContainer\u003e extraOpportContainersToKill \u003d new ArrayList\u003c\u003e();\n    // Track resources that need to be freed.\n    ResourceUtilization resourcesToFreeUp \u003d resourcesToFreeUp(\n        containerToStartId);\n\n    // Go over the running opportunistic containers.\n    // Use a descending iterator to kill more recently started containers.\n    Iterator\u003cContainer\u003e lifoIterator \u003d new LinkedList\u003c\u003e(\n        runningContainers.values()).descendingIterator();\n    while(lifoIterator.hasNext() \u0026\u0026\n        !hasSufficientResources(resourcesToFreeUp)) {\n      Container runningCont \u003d lifoIterator.next();\n      if (runningCont.getContainerTokenIdentifier().getExecutionType() \u003d\u003d\n          ExecutionType.OPPORTUNISTIC) {\n\n        if (oppContainersToKill.containsKey(\n            runningCont.getContainerId())) {\n          // These containers have already been marked to be killed.\n          // So exclude them..\n          continue;\n        }\n        extraOpportContainersToKill.add(runningCont);\n        ContainersMonitor.decreaseResourceUtilization(\n            getContainersMonitor(), resourcesToFreeUp,\n            runningCont.getResource());\n      }\n    }\n    if (!hasSufficientResources(resourcesToFreeUp)) {\n      LOG.warn(\"There are no sufficient resources to start guaranteed [{}]\" +\n          \"at the moment. Opportunistic containers are in the process of\" +\n          \"being killed to make room.\", containerToStartId);\n    }\n    return extraOpportContainersToKill;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/scheduler/ContainerScheduler.java",
      "extendedDetails": {
        "oldValue": "pickOpportunisticContainersToKill",
        "newValue": "pickOpportunisticContainersToReclaimResources"
      }
    },
    "3219b7b4ac7d12aee343f6ab2980b3357fc618b6": {
      "type": "Ymultichange(Ymovefromfile,Yreturntypechange,Ymodifierchange,Ybodychange)",
      "commitMessage": "YARN-4597. Introduce ContainerScheduler and a SCHEDULED state to NodeManager container lifecycle. (asuresh)\n",
      "commitDate": "15/11/16 7:56 AM",
      "commitName": "3219b7b4ac7d12aee343f6ab2980b3357fc618b6",
      "commitAuthor": "Arun Suresh",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "YARN-4597. Introduce ContainerScheduler and a SCHEDULED state to NodeManager container lifecycle. (asuresh)\n",
          "commitDate": "15/11/16 7:56 AM",
          "commitName": "3219b7b4ac7d12aee343f6ab2980b3357fc618b6",
          "commitAuthor": "Arun Suresh",
          "commitDateOld": "15/11/16 2:11 AM",
          "commitNameOld": "7ffb9943b8838a3bb56684e0722db40d800743a2",
          "commitAuthorOld": "Naganarasimha",
          "daysBetweenCommits": 0.24,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,42 +1,38 @@\n-  protected List\u003cContainerId\u003e pickOpportunisticContainersToKill(\n+  private List\u003cContainer\u003e pickOpportunisticContainersToKill(\n       ContainerId containerToStartId) {\n-    // The additional opportunistic containers that need to be killed for the\n+    // The opportunistic containers that need to be killed for the\n     // given container to start.\n-    List\u003cContainerId\u003e extraOpportContainersToKill \u003d new ArrayList\u003c\u003e();\n+    List\u003cContainer\u003e extraOpportContainersToKill \u003d new ArrayList\u003c\u003e();\n     // Track resources that need to be freed.\n     ResourceUtilization resourcesToFreeUp \u003d resourcesToFreeUp(\n         containerToStartId);\n \n-    // Go over the running opportunistic containers. Avoid containers that have\n-    // already been marked for killing.\n-    boolean hasSufficientResources \u003d false;\n-    for (Map.Entry\u003cContainerId, AllocatedContainerInfo\u003e runningOpportCont :\n-        allocatedOpportunisticContainers.entrySet()) {\n-      ContainerId runningOpportContId \u003d runningOpportCont.getKey();\n+    // Go over the running opportunistic containers.\n+    // Use a descending iterator to kill more recently started containers.\n+    Iterator\u003cContainer\u003e lifoIterator \u003d new LinkedList\u003c\u003e(\n+        runningContainers.values()).descendingIterator();\n+    while(lifoIterator.hasNext() \u0026\u0026\n+        !hasSufficientResources(resourcesToFreeUp)) {\n+      Container runningCont \u003d lifoIterator.next();\n+      if (runningCont.getContainerTokenIdentifier().getExecutionType() \u003d\u003d\n+          ExecutionType.OPPORTUNISTIC) {\n \n-      // If there are sufficient resources to execute the given container, do\n-      // not kill more opportunistic containers.\n-      if (resourcesToFreeUp.getPhysicalMemory() \u003c\u003d 0 \u0026\u0026\n-          resourcesToFreeUp.getVirtualMemory() \u003c\u003d 0 \u0026\u0026\n-          resourcesToFreeUp.getCPU() \u003c\u003d 0.0f) {\n-        hasSufficientResources \u003d true;\n-        break;\n-      }\n-\n-      if (!opportunisticContainersToKill.contains(runningOpportContId)) {\n-        extraOpportContainersToKill.add(runningOpportContId);\n-        opportunisticContainersToKill.add(runningOpportContId);\n-        getContainersMonitor().decreaseResourceUtilization(resourcesToFreeUp,\n-            runningOpportCont.getValue().getPti());\n+        if (oppContainersToKill.containsKey(\n+            runningCont.getContainerId())) {\n+          // These containers have already been marked to be killed.\n+          // So exclude them..\n+          continue;\n+        }\n+        extraOpportContainersToKill.add(runningCont);\n+        ContainersMonitor.decreaseResourceUtilization(\n+            getContainersMonitor(), resourcesToFreeUp,\n+            runningCont.getResource());\n       }\n     }\n-\n-    if (!hasSufficientResources) {\n-      LOG.info(\n-          \"There are no sufficient resources to start guaranteed {} even after \"\n-              + \"attempting to kill any running opportunistic containers.\",\n-          containerToStartId);\n+    if (!hasSufficientResources(resourcesToFreeUp)) {\n+      LOG.warn(\"There are no sufficient resources to start guaranteed [{}]\" +\n+          \"at the moment. Opportunistic containers are in the process of\" +\n+          \"being killed to make room.\", containerToStartId);\n     }\n-\n     return extraOpportContainersToKill;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private List\u003cContainer\u003e pickOpportunisticContainersToKill(\n      ContainerId containerToStartId) {\n    // The opportunistic containers that need to be killed for the\n    // given container to start.\n    List\u003cContainer\u003e extraOpportContainersToKill \u003d new ArrayList\u003c\u003e();\n    // Track resources that need to be freed.\n    ResourceUtilization resourcesToFreeUp \u003d resourcesToFreeUp(\n        containerToStartId);\n\n    // Go over the running opportunistic containers.\n    // Use a descending iterator to kill more recently started containers.\n    Iterator\u003cContainer\u003e lifoIterator \u003d new LinkedList\u003c\u003e(\n        runningContainers.values()).descendingIterator();\n    while(lifoIterator.hasNext() \u0026\u0026\n        !hasSufficientResources(resourcesToFreeUp)) {\n      Container runningCont \u003d lifoIterator.next();\n      if (runningCont.getContainerTokenIdentifier().getExecutionType() \u003d\u003d\n          ExecutionType.OPPORTUNISTIC) {\n\n        if (oppContainersToKill.containsKey(\n            runningCont.getContainerId())) {\n          // These containers have already been marked to be killed.\n          // So exclude them..\n          continue;\n        }\n        extraOpportContainersToKill.add(runningCont);\n        ContainersMonitor.decreaseResourceUtilization(\n            getContainersMonitor(), resourcesToFreeUp,\n            runningCont.getResource());\n      }\n    }\n    if (!hasSufficientResources(resourcesToFreeUp)) {\n      LOG.warn(\"There are no sufficient resources to start guaranteed [{}]\" +\n          \"at the moment. Opportunistic containers are in the process of\" +\n          \"being killed to make room.\", containerToStartId);\n    }\n    return extraOpportContainersToKill;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/scheduler/ContainerScheduler.java",
          "extendedDetails": {
            "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/queuing/QueuingContainerManagerImpl.java",
            "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/scheduler/ContainerScheduler.java",
            "oldMethodName": "pickOpportunisticContainersToKill",
            "newMethodName": "pickOpportunisticContainersToKill"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "YARN-4597. Introduce ContainerScheduler and a SCHEDULED state to NodeManager container lifecycle. (asuresh)\n",
          "commitDate": "15/11/16 7:56 AM",
          "commitName": "3219b7b4ac7d12aee343f6ab2980b3357fc618b6",
          "commitAuthor": "Arun Suresh",
          "commitDateOld": "15/11/16 2:11 AM",
          "commitNameOld": "7ffb9943b8838a3bb56684e0722db40d800743a2",
          "commitAuthorOld": "Naganarasimha",
          "daysBetweenCommits": 0.24,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,42 +1,38 @@\n-  protected List\u003cContainerId\u003e pickOpportunisticContainersToKill(\n+  private List\u003cContainer\u003e pickOpportunisticContainersToKill(\n       ContainerId containerToStartId) {\n-    // The additional opportunistic containers that need to be killed for the\n+    // The opportunistic containers that need to be killed for the\n     // given container to start.\n-    List\u003cContainerId\u003e extraOpportContainersToKill \u003d new ArrayList\u003c\u003e();\n+    List\u003cContainer\u003e extraOpportContainersToKill \u003d new ArrayList\u003c\u003e();\n     // Track resources that need to be freed.\n     ResourceUtilization resourcesToFreeUp \u003d resourcesToFreeUp(\n         containerToStartId);\n \n-    // Go over the running opportunistic containers. Avoid containers that have\n-    // already been marked for killing.\n-    boolean hasSufficientResources \u003d false;\n-    for (Map.Entry\u003cContainerId, AllocatedContainerInfo\u003e runningOpportCont :\n-        allocatedOpportunisticContainers.entrySet()) {\n-      ContainerId runningOpportContId \u003d runningOpportCont.getKey();\n+    // Go over the running opportunistic containers.\n+    // Use a descending iterator to kill more recently started containers.\n+    Iterator\u003cContainer\u003e lifoIterator \u003d new LinkedList\u003c\u003e(\n+        runningContainers.values()).descendingIterator();\n+    while(lifoIterator.hasNext() \u0026\u0026\n+        !hasSufficientResources(resourcesToFreeUp)) {\n+      Container runningCont \u003d lifoIterator.next();\n+      if (runningCont.getContainerTokenIdentifier().getExecutionType() \u003d\u003d\n+          ExecutionType.OPPORTUNISTIC) {\n \n-      // If there are sufficient resources to execute the given container, do\n-      // not kill more opportunistic containers.\n-      if (resourcesToFreeUp.getPhysicalMemory() \u003c\u003d 0 \u0026\u0026\n-          resourcesToFreeUp.getVirtualMemory() \u003c\u003d 0 \u0026\u0026\n-          resourcesToFreeUp.getCPU() \u003c\u003d 0.0f) {\n-        hasSufficientResources \u003d true;\n-        break;\n-      }\n-\n-      if (!opportunisticContainersToKill.contains(runningOpportContId)) {\n-        extraOpportContainersToKill.add(runningOpportContId);\n-        opportunisticContainersToKill.add(runningOpportContId);\n-        getContainersMonitor().decreaseResourceUtilization(resourcesToFreeUp,\n-            runningOpportCont.getValue().getPti());\n+        if (oppContainersToKill.containsKey(\n+            runningCont.getContainerId())) {\n+          // These containers have already been marked to be killed.\n+          // So exclude them..\n+          continue;\n+        }\n+        extraOpportContainersToKill.add(runningCont);\n+        ContainersMonitor.decreaseResourceUtilization(\n+            getContainersMonitor(), resourcesToFreeUp,\n+            runningCont.getResource());\n       }\n     }\n-\n-    if (!hasSufficientResources) {\n-      LOG.info(\n-          \"There are no sufficient resources to start guaranteed {} even after \"\n-              + \"attempting to kill any running opportunistic containers.\",\n-          containerToStartId);\n+    if (!hasSufficientResources(resourcesToFreeUp)) {\n+      LOG.warn(\"There are no sufficient resources to start guaranteed [{}]\" +\n+          \"at the moment. Opportunistic containers are in the process of\" +\n+          \"being killed to make room.\", containerToStartId);\n     }\n-\n     return extraOpportContainersToKill;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private List\u003cContainer\u003e pickOpportunisticContainersToKill(\n      ContainerId containerToStartId) {\n    // The opportunistic containers that need to be killed for the\n    // given container to start.\n    List\u003cContainer\u003e extraOpportContainersToKill \u003d new ArrayList\u003c\u003e();\n    // Track resources that need to be freed.\n    ResourceUtilization resourcesToFreeUp \u003d resourcesToFreeUp(\n        containerToStartId);\n\n    // Go over the running opportunistic containers.\n    // Use a descending iterator to kill more recently started containers.\n    Iterator\u003cContainer\u003e lifoIterator \u003d new LinkedList\u003c\u003e(\n        runningContainers.values()).descendingIterator();\n    while(lifoIterator.hasNext() \u0026\u0026\n        !hasSufficientResources(resourcesToFreeUp)) {\n      Container runningCont \u003d lifoIterator.next();\n      if (runningCont.getContainerTokenIdentifier().getExecutionType() \u003d\u003d\n          ExecutionType.OPPORTUNISTIC) {\n\n        if (oppContainersToKill.containsKey(\n            runningCont.getContainerId())) {\n          // These containers have already been marked to be killed.\n          // So exclude them..\n          continue;\n        }\n        extraOpportContainersToKill.add(runningCont);\n        ContainersMonitor.decreaseResourceUtilization(\n            getContainersMonitor(), resourcesToFreeUp,\n            runningCont.getResource());\n      }\n    }\n    if (!hasSufficientResources(resourcesToFreeUp)) {\n      LOG.warn(\"There are no sufficient resources to start guaranteed [{}]\" +\n          \"at the moment. Opportunistic containers are in the process of\" +\n          \"being killed to make room.\", containerToStartId);\n    }\n    return extraOpportContainersToKill;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/scheduler/ContainerScheduler.java",
          "extendedDetails": {
            "oldValue": "List\u003cContainerId\u003e",
            "newValue": "List\u003cContainer\u003e"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-4597. Introduce ContainerScheduler and a SCHEDULED state to NodeManager container lifecycle. (asuresh)\n",
          "commitDate": "15/11/16 7:56 AM",
          "commitName": "3219b7b4ac7d12aee343f6ab2980b3357fc618b6",
          "commitAuthor": "Arun Suresh",
          "commitDateOld": "15/11/16 2:11 AM",
          "commitNameOld": "7ffb9943b8838a3bb56684e0722db40d800743a2",
          "commitAuthorOld": "Naganarasimha",
          "daysBetweenCommits": 0.24,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,42 +1,38 @@\n-  protected List\u003cContainerId\u003e pickOpportunisticContainersToKill(\n+  private List\u003cContainer\u003e pickOpportunisticContainersToKill(\n       ContainerId containerToStartId) {\n-    // The additional opportunistic containers that need to be killed for the\n+    // The opportunistic containers that need to be killed for the\n     // given container to start.\n-    List\u003cContainerId\u003e extraOpportContainersToKill \u003d new ArrayList\u003c\u003e();\n+    List\u003cContainer\u003e extraOpportContainersToKill \u003d new ArrayList\u003c\u003e();\n     // Track resources that need to be freed.\n     ResourceUtilization resourcesToFreeUp \u003d resourcesToFreeUp(\n         containerToStartId);\n \n-    // Go over the running opportunistic containers. Avoid containers that have\n-    // already been marked for killing.\n-    boolean hasSufficientResources \u003d false;\n-    for (Map.Entry\u003cContainerId, AllocatedContainerInfo\u003e runningOpportCont :\n-        allocatedOpportunisticContainers.entrySet()) {\n-      ContainerId runningOpportContId \u003d runningOpportCont.getKey();\n+    // Go over the running opportunistic containers.\n+    // Use a descending iterator to kill more recently started containers.\n+    Iterator\u003cContainer\u003e lifoIterator \u003d new LinkedList\u003c\u003e(\n+        runningContainers.values()).descendingIterator();\n+    while(lifoIterator.hasNext() \u0026\u0026\n+        !hasSufficientResources(resourcesToFreeUp)) {\n+      Container runningCont \u003d lifoIterator.next();\n+      if (runningCont.getContainerTokenIdentifier().getExecutionType() \u003d\u003d\n+          ExecutionType.OPPORTUNISTIC) {\n \n-      // If there are sufficient resources to execute the given container, do\n-      // not kill more opportunistic containers.\n-      if (resourcesToFreeUp.getPhysicalMemory() \u003c\u003d 0 \u0026\u0026\n-          resourcesToFreeUp.getVirtualMemory() \u003c\u003d 0 \u0026\u0026\n-          resourcesToFreeUp.getCPU() \u003c\u003d 0.0f) {\n-        hasSufficientResources \u003d true;\n-        break;\n-      }\n-\n-      if (!opportunisticContainersToKill.contains(runningOpportContId)) {\n-        extraOpportContainersToKill.add(runningOpportContId);\n-        opportunisticContainersToKill.add(runningOpportContId);\n-        getContainersMonitor().decreaseResourceUtilization(resourcesToFreeUp,\n-            runningOpportCont.getValue().getPti());\n+        if (oppContainersToKill.containsKey(\n+            runningCont.getContainerId())) {\n+          // These containers have already been marked to be killed.\n+          // So exclude them..\n+          continue;\n+        }\n+        extraOpportContainersToKill.add(runningCont);\n+        ContainersMonitor.decreaseResourceUtilization(\n+            getContainersMonitor(), resourcesToFreeUp,\n+            runningCont.getResource());\n       }\n     }\n-\n-    if (!hasSufficientResources) {\n-      LOG.info(\n-          \"There are no sufficient resources to start guaranteed {} even after \"\n-              + \"attempting to kill any running opportunistic containers.\",\n-          containerToStartId);\n+    if (!hasSufficientResources(resourcesToFreeUp)) {\n+      LOG.warn(\"There are no sufficient resources to start guaranteed [{}]\" +\n+          \"at the moment. Opportunistic containers are in the process of\" +\n+          \"being killed to make room.\", containerToStartId);\n     }\n-\n     return extraOpportContainersToKill;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private List\u003cContainer\u003e pickOpportunisticContainersToKill(\n      ContainerId containerToStartId) {\n    // The opportunistic containers that need to be killed for the\n    // given container to start.\n    List\u003cContainer\u003e extraOpportContainersToKill \u003d new ArrayList\u003c\u003e();\n    // Track resources that need to be freed.\n    ResourceUtilization resourcesToFreeUp \u003d resourcesToFreeUp(\n        containerToStartId);\n\n    // Go over the running opportunistic containers.\n    // Use a descending iterator to kill more recently started containers.\n    Iterator\u003cContainer\u003e lifoIterator \u003d new LinkedList\u003c\u003e(\n        runningContainers.values()).descendingIterator();\n    while(lifoIterator.hasNext() \u0026\u0026\n        !hasSufficientResources(resourcesToFreeUp)) {\n      Container runningCont \u003d lifoIterator.next();\n      if (runningCont.getContainerTokenIdentifier().getExecutionType() \u003d\u003d\n          ExecutionType.OPPORTUNISTIC) {\n\n        if (oppContainersToKill.containsKey(\n            runningCont.getContainerId())) {\n          // These containers have already been marked to be killed.\n          // So exclude them..\n          continue;\n        }\n        extraOpportContainersToKill.add(runningCont);\n        ContainersMonitor.decreaseResourceUtilization(\n            getContainersMonitor(), resourcesToFreeUp,\n            runningCont.getResource());\n      }\n    }\n    if (!hasSufficientResources(resourcesToFreeUp)) {\n      LOG.warn(\"There are no sufficient resources to start guaranteed [{}]\" +\n          \"at the moment. Opportunistic containers are in the process of\" +\n          \"being killed to make room.\", containerToStartId);\n    }\n    return extraOpportContainersToKill;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/scheduler/ContainerScheduler.java",
          "extendedDetails": {
            "oldValue": "[protected]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-4597. Introduce ContainerScheduler and a SCHEDULED state to NodeManager container lifecycle. (asuresh)\n",
          "commitDate": "15/11/16 7:56 AM",
          "commitName": "3219b7b4ac7d12aee343f6ab2980b3357fc618b6",
          "commitAuthor": "Arun Suresh",
          "commitDateOld": "15/11/16 2:11 AM",
          "commitNameOld": "7ffb9943b8838a3bb56684e0722db40d800743a2",
          "commitAuthorOld": "Naganarasimha",
          "daysBetweenCommits": 0.24,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,42 +1,38 @@\n-  protected List\u003cContainerId\u003e pickOpportunisticContainersToKill(\n+  private List\u003cContainer\u003e pickOpportunisticContainersToKill(\n       ContainerId containerToStartId) {\n-    // The additional opportunistic containers that need to be killed for the\n+    // The opportunistic containers that need to be killed for the\n     // given container to start.\n-    List\u003cContainerId\u003e extraOpportContainersToKill \u003d new ArrayList\u003c\u003e();\n+    List\u003cContainer\u003e extraOpportContainersToKill \u003d new ArrayList\u003c\u003e();\n     // Track resources that need to be freed.\n     ResourceUtilization resourcesToFreeUp \u003d resourcesToFreeUp(\n         containerToStartId);\n \n-    // Go over the running opportunistic containers. Avoid containers that have\n-    // already been marked for killing.\n-    boolean hasSufficientResources \u003d false;\n-    for (Map.Entry\u003cContainerId, AllocatedContainerInfo\u003e runningOpportCont :\n-        allocatedOpportunisticContainers.entrySet()) {\n-      ContainerId runningOpportContId \u003d runningOpportCont.getKey();\n+    // Go over the running opportunistic containers.\n+    // Use a descending iterator to kill more recently started containers.\n+    Iterator\u003cContainer\u003e lifoIterator \u003d new LinkedList\u003c\u003e(\n+        runningContainers.values()).descendingIterator();\n+    while(lifoIterator.hasNext() \u0026\u0026\n+        !hasSufficientResources(resourcesToFreeUp)) {\n+      Container runningCont \u003d lifoIterator.next();\n+      if (runningCont.getContainerTokenIdentifier().getExecutionType() \u003d\u003d\n+          ExecutionType.OPPORTUNISTIC) {\n \n-      // If there are sufficient resources to execute the given container, do\n-      // not kill more opportunistic containers.\n-      if (resourcesToFreeUp.getPhysicalMemory() \u003c\u003d 0 \u0026\u0026\n-          resourcesToFreeUp.getVirtualMemory() \u003c\u003d 0 \u0026\u0026\n-          resourcesToFreeUp.getCPU() \u003c\u003d 0.0f) {\n-        hasSufficientResources \u003d true;\n-        break;\n-      }\n-\n-      if (!opportunisticContainersToKill.contains(runningOpportContId)) {\n-        extraOpportContainersToKill.add(runningOpportContId);\n-        opportunisticContainersToKill.add(runningOpportContId);\n-        getContainersMonitor().decreaseResourceUtilization(resourcesToFreeUp,\n-            runningOpportCont.getValue().getPti());\n+        if (oppContainersToKill.containsKey(\n+            runningCont.getContainerId())) {\n+          // These containers have already been marked to be killed.\n+          // So exclude them..\n+          continue;\n+        }\n+        extraOpportContainersToKill.add(runningCont);\n+        ContainersMonitor.decreaseResourceUtilization(\n+            getContainersMonitor(), resourcesToFreeUp,\n+            runningCont.getResource());\n       }\n     }\n-\n-    if (!hasSufficientResources) {\n-      LOG.info(\n-          \"There are no sufficient resources to start guaranteed {} even after \"\n-              + \"attempting to kill any running opportunistic containers.\",\n-          containerToStartId);\n+    if (!hasSufficientResources(resourcesToFreeUp)) {\n+      LOG.warn(\"There are no sufficient resources to start guaranteed [{}]\" +\n+          \"at the moment. Opportunistic containers are in the process of\" +\n+          \"being killed to make room.\", containerToStartId);\n     }\n-\n     return extraOpportContainersToKill;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private List\u003cContainer\u003e pickOpportunisticContainersToKill(\n      ContainerId containerToStartId) {\n    // The opportunistic containers that need to be killed for the\n    // given container to start.\n    List\u003cContainer\u003e extraOpportContainersToKill \u003d new ArrayList\u003c\u003e();\n    // Track resources that need to be freed.\n    ResourceUtilization resourcesToFreeUp \u003d resourcesToFreeUp(\n        containerToStartId);\n\n    // Go over the running opportunistic containers.\n    // Use a descending iterator to kill more recently started containers.\n    Iterator\u003cContainer\u003e lifoIterator \u003d new LinkedList\u003c\u003e(\n        runningContainers.values()).descendingIterator();\n    while(lifoIterator.hasNext() \u0026\u0026\n        !hasSufficientResources(resourcesToFreeUp)) {\n      Container runningCont \u003d lifoIterator.next();\n      if (runningCont.getContainerTokenIdentifier().getExecutionType() \u003d\u003d\n          ExecutionType.OPPORTUNISTIC) {\n\n        if (oppContainersToKill.containsKey(\n            runningCont.getContainerId())) {\n          // These containers have already been marked to be killed.\n          // So exclude them..\n          continue;\n        }\n        extraOpportContainersToKill.add(runningCont);\n        ContainersMonitor.decreaseResourceUtilization(\n            getContainersMonitor(), resourcesToFreeUp,\n            runningCont.getResource());\n      }\n    }\n    if (!hasSufficientResources(resourcesToFreeUp)) {\n      LOG.warn(\"There are no sufficient resources to start guaranteed [{}]\" +\n          \"at the moment. Opportunistic containers are in the process of\" +\n          \"being killed to make room.\", containerToStartId);\n    }\n    return extraOpportContainersToKill;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/scheduler/ContainerScheduler.java",
          "extendedDetails": {}
        }
      ]
    },
    "c8172f5f143d2fefafa5a412899ab7cd081b406d": {
      "type": "Yintroduced",
      "commitMessage": "YARN-2883. Queuing of container requests in the NM. (Konstantinos Karanasos and Arun Suresh via kasha)\n",
      "commitDate": "20/04/16 9:55 AM",
      "commitName": "c8172f5f143d2fefafa5a412899ab7cd081b406d",
      "commitAuthor": "Karthik Kambatla",
      "diff": "@@ -0,0 +1,42 @@\n+  protected List\u003cContainerId\u003e pickOpportunisticContainersToKill(\n+      ContainerId containerToStartId) {\n+    // The additional opportunistic containers that need to be killed for the\n+    // given container to start.\n+    List\u003cContainerId\u003e extraOpportContainersToKill \u003d new ArrayList\u003c\u003e();\n+    // Track resources that need to be freed.\n+    ResourceUtilization resourcesToFreeUp \u003d resourcesToFreeUp(\n+        containerToStartId);\n+\n+    // Go over the running opportunistic containers. Avoid containers that have\n+    // already been marked for killing.\n+    boolean hasSufficientResources \u003d false;\n+    for (Map.Entry\u003cContainerId, AllocatedContainerInfo\u003e runningOpportCont :\n+        allocatedOpportunisticContainers.entrySet()) {\n+      ContainerId runningOpportContId \u003d runningOpportCont.getKey();\n+\n+      // If there are sufficient resources to execute the given container, do\n+      // not kill more opportunistic containers.\n+      if (resourcesToFreeUp.getPhysicalMemory() \u003c\u003d 0 \u0026\u0026\n+          resourcesToFreeUp.getVirtualMemory() \u003c\u003d 0 \u0026\u0026\n+          resourcesToFreeUp.getCPU() \u003c\u003d 0.0f) {\n+        hasSufficientResources \u003d true;\n+        break;\n+      }\n+\n+      if (!opportunisticContainersToKill.contains(runningOpportContId)) {\n+        extraOpportContainersToKill.add(runningOpportContId);\n+        opportunisticContainersToKill.add(runningOpportContId);\n+        getContainersMonitor().decreaseResourceUtilization(resourcesToFreeUp,\n+            runningOpportCont.getValue().getPti());\n+      }\n+    }\n+\n+    if (!hasSufficientResources) {\n+      LOG.info(\n+          \"There are no sufficient resources to start guaranteed {} even after \"\n+              + \"attempting to kill any running opportunistic containers.\",\n+          containerToStartId);\n+    }\n+\n+    return extraOpportContainersToKill;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected List\u003cContainerId\u003e pickOpportunisticContainersToKill(\n      ContainerId containerToStartId) {\n    // The additional opportunistic containers that need to be killed for the\n    // given container to start.\n    List\u003cContainerId\u003e extraOpportContainersToKill \u003d new ArrayList\u003c\u003e();\n    // Track resources that need to be freed.\n    ResourceUtilization resourcesToFreeUp \u003d resourcesToFreeUp(\n        containerToStartId);\n\n    // Go over the running opportunistic containers. Avoid containers that have\n    // already been marked for killing.\n    boolean hasSufficientResources \u003d false;\n    for (Map.Entry\u003cContainerId, AllocatedContainerInfo\u003e runningOpportCont :\n        allocatedOpportunisticContainers.entrySet()) {\n      ContainerId runningOpportContId \u003d runningOpportCont.getKey();\n\n      // If there are sufficient resources to execute the given container, do\n      // not kill more opportunistic containers.\n      if (resourcesToFreeUp.getPhysicalMemory() \u003c\u003d 0 \u0026\u0026\n          resourcesToFreeUp.getVirtualMemory() \u003c\u003d 0 \u0026\u0026\n          resourcesToFreeUp.getCPU() \u003c\u003d 0.0f) {\n        hasSufficientResources \u003d true;\n        break;\n      }\n\n      if (!opportunisticContainersToKill.contains(runningOpportContId)) {\n        extraOpportContainersToKill.add(runningOpportContId);\n        opportunisticContainersToKill.add(runningOpportContId);\n        getContainersMonitor().decreaseResourceUtilization(resourcesToFreeUp,\n            runningOpportCont.getValue().getPti());\n      }\n    }\n\n    if (!hasSufficientResources) {\n      LOG.info(\n          \"There are no sufficient resources to start guaranteed {} even after \"\n              + \"attempting to kill any running opportunistic containers.\",\n          containerToStartId);\n    }\n\n    return extraOpportContainersToKill;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/queuing/QueuingContainerManagerImpl.java"
    }
  }
}