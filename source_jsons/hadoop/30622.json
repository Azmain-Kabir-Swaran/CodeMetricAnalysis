{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LeveldbTimelineStore.java",
  "functionName": "deleteNextEntity",
  "functionId": "deleteNextEntity___entityType-String__reverseTimestamp-byte[]__iterator-LeveldbIterator__pfIterator-LeveldbIterator__seeked-boolean",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
  "functionStartLine": 1398,
  "functionEndLine": 1500,
  "numCommitsSeen": 29,
  "timeTaken": 3915,
  "changeHistory": [
    "2064ca015d1584263aac0cc20c60b925a3aff612",
    "839e077faf4019d6efdcd89d95930023cd0b0a08",
    "a4aa1cb40504299d3401008fdabc795eafb28713",
    "1a78c0ff016097930edf68e8278f826b637e918c",
    "1ce4d33c2dc86d711b227a04d2f9a2ab696a24a1",
    "001078e0677e39b962ca1da81fc34d7ac9a7e65c",
    "b3ea4aebff42131642af0393748dc751cb3fc31e"
  ],
  "changeHistoryShort": {
    "2064ca015d1584263aac0cc20c60b925a3aff612": "Ybodychange",
    "839e077faf4019d6efdcd89d95930023cd0b0a08": "Ybodychange",
    "a4aa1cb40504299d3401008fdabc795eafb28713": "Ybodychange",
    "1a78c0ff016097930edf68e8278f826b637e918c": "Ybodychange",
    "1ce4d33c2dc86d711b227a04d2f9a2ab696a24a1": "Ymultichange(Yparameterchange,Ybodychange)",
    "001078e0677e39b962ca1da81fc34d7ac9a7e65c": "Yfilerename",
    "b3ea4aebff42131642af0393748dc751cb3fc31e": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2064ca015d1584263aac0cc20c60b925a3aff612": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9349.  Changed logging to use slf4j api.\n            Contributed by Prabhu Joseph\n",
      "commitDate": "15/03/19 4:20 PM",
      "commitName": "2064ca015d1584263aac0cc20c60b925a3aff612",
      "commitAuthor": "Eric Yang",
      "commitDateOld": "07/03/19 1:47 PM",
      "commitNameOld": "39b4a37e02e929a698fcf9e32f1f71bb6b977635",
      "commitAuthorOld": "Eric Yang",
      "daysBetweenCommits": 8.06,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,113 +1,103 @@\n   boolean deleteNextEntity(String entityType, byte[] reverseTimestamp,\n       LeveldbIterator iterator, LeveldbIterator pfIterator, boolean seeked)\n       throws IOException {\n     WriteBatch writeBatch \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n           .add(entityType);\n       byte[] typePrefix \u003d kb.getBytesForLookup();\n       kb.add(reverseTimestamp);\n       if (!seeked) {\n         iterator.seek(kb.getBytesForLookup());\n       }\n       if (!iterator.hasNext()) {\n         return false;\n       }\n       byte[] entityKey \u003d iterator.peekNext().getKey();\n       if (!prefixMatches(typePrefix, typePrefix.length, entityKey)) {\n         return false;\n       }\n \n       // read the start time and entity id from the current key\n       KeyParser kp \u003d new KeyParser(entityKey, typePrefix.length + 8);\n       String entityId \u003d kp.getNextString();\n       int prefixlen \u003d kp.getOffset();\n       byte[] deletePrefix \u003d new byte[prefixlen];\n       System.arraycopy(entityKey, 0, deletePrefix, 0, prefixlen);\n \n       writeBatch \u003d db.createWriteBatch();\n \n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" + entityId);\n-      }\n+      LOG.debug(\"Deleting entity type:{} id:{}\", entityType, entityId);\n       // remove start time from cache and db\n       writeBatch.delete(createStartTimeLookupKey(entityId, entityType));\n       EntityIdentifier entityIdentifier \u003d\n           new EntityIdentifier(entityId, entityType);\n       startTimeReadCache.remove(entityIdentifier);\n       startTimeWriteCache.remove(entityIdentifier);\n \n       // delete current entity\n       for (; iterator.hasNext(); iterator.next()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(entityKey, prefixlen, key)) {\n           break;\n         }\n         writeBatch.delete(key);\n \n         if (key.length \u003d\u003d prefixlen) {\n           continue;\n         }\n         if (key[prefixlen] \u003d\u003d PRIMARY_FILTERS_COLUMN[0]) {\n           kp \u003d new KeyParser(key,\n               prefixlen + PRIMARY_FILTERS_COLUMN.length);\n           String name \u003d kp.getNextString();\n           Object value \u003d GenericObjectMapper.read(key, kp.getOffset());\n           deleteKeysWithPrefix(writeBatch, addPrimaryFilterToKey(name, value,\n               deletePrefix), pfIterator);\n-          if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n-                entityId + \" primary filter entry \" + name + \" \" +\n-                value);\n-          }\n+          LOG.debug(\"Deleting entity type:{} id:{} primary filter entry {} {}\",\n+              entityType, entityId, name, value);\n         } else if (key[prefixlen] \u003d\u003d RELATED_ENTITIES_COLUMN[0]) {\n           kp \u003d new KeyParser(key,\n               prefixlen + RELATED_ENTITIES_COLUMN.length);\n           String type \u003d kp.getNextString();\n           String id \u003d kp.getNextString();\n           byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n           if (relatedEntityStartTime \u003d\u003d null) {\n             LOG.warn(\"Found no start time for \" +\n                 \"related entity \" + id + \" of type \" + type + \" while \" +\n                 \"deleting \" + entityId + \" of type \" + entityType);\n             continue;\n           }\n           writeBatch.delete(createReverseRelatedEntityKey(id, type,\n               relatedEntityStartTime, entityId, entityType));\n-          if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n-                entityId + \" from invisible reverse related entity \" +\n-                \"entry of type:\" + type + \" id:\" + id);\n-          }\n+          LOG.debug(\"Deleting entity type:{} id:{} from invisible reverse\"\n+              + \" related entity entry of type:{} id:{}\", entityType,\n+              entityId, type, id);\n         } else if (key[prefixlen] \u003d\u003d\n             INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN[0]) {\n           kp \u003d new KeyParser(key, prefixlen +\n               INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN.length);\n           String type \u003d kp.getNextString();\n           String id \u003d kp.getNextString();\n           byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n           if (relatedEntityStartTime \u003d\u003d null) {\n             LOG.warn(\"Found no start time for reverse \" +\n                 \"related entity \" + id + \" of type \" + type + \" while \" +\n                 \"deleting \" + entityId + \" of type \" + entityType);\n             continue;\n           }\n           writeBatch.delete(createRelatedEntityKey(id, type,\n               relatedEntityStartTime, entityId, entityType));\n-          if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n-                entityId + \" from related entity entry of type:\" +\n-                type + \" id:\" + id);\n-          }\n+          LOG.debug(\"Deleting entity type:{} id:{} from related entity entry\"\n+              +\" of type:{} id:{}\", entityType, entityId, type, id);\n         }\n       }\n       WriteOptions writeOptions \u003d new WriteOptions();\n       writeOptions.sync(true);\n       db.write(writeBatch, writeOptions);\n       return true;\n     } catch(DBException e) {\n       throw new IOException(e);\n     } finally {\n       IOUtils.cleanupWithLogger(LOG, writeBatch);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean deleteNextEntity(String entityType, byte[] reverseTimestamp,\n      LeveldbIterator iterator, LeveldbIterator pfIterator, boolean seeked)\n      throws IOException {\n    WriteBatch writeBatch \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n          .add(entityType);\n      byte[] typePrefix \u003d kb.getBytesForLookup();\n      kb.add(reverseTimestamp);\n      if (!seeked) {\n        iterator.seek(kb.getBytesForLookup());\n      }\n      if (!iterator.hasNext()) {\n        return false;\n      }\n      byte[] entityKey \u003d iterator.peekNext().getKey();\n      if (!prefixMatches(typePrefix, typePrefix.length, entityKey)) {\n        return false;\n      }\n\n      // read the start time and entity id from the current key\n      KeyParser kp \u003d new KeyParser(entityKey, typePrefix.length + 8);\n      String entityId \u003d kp.getNextString();\n      int prefixlen \u003d kp.getOffset();\n      byte[] deletePrefix \u003d new byte[prefixlen];\n      System.arraycopy(entityKey, 0, deletePrefix, 0, prefixlen);\n\n      writeBatch \u003d db.createWriteBatch();\n\n      LOG.debug(\"Deleting entity type:{} id:{}\", entityType, entityId);\n      // remove start time from cache and db\n      writeBatch.delete(createStartTimeLookupKey(entityId, entityType));\n      EntityIdentifier entityIdentifier \u003d\n          new EntityIdentifier(entityId, entityType);\n      startTimeReadCache.remove(entityIdentifier);\n      startTimeWriteCache.remove(entityIdentifier);\n\n      // delete current entity\n      for (; iterator.hasNext(); iterator.next()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(entityKey, prefixlen, key)) {\n          break;\n        }\n        writeBatch.delete(key);\n\n        if (key.length \u003d\u003d prefixlen) {\n          continue;\n        }\n        if (key[prefixlen] \u003d\u003d PRIMARY_FILTERS_COLUMN[0]) {\n          kp \u003d new KeyParser(key,\n              prefixlen + PRIMARY_FILTERS_COLUMN.length);\n          String name \u003d kp.getNextString();\n          Object value \u003d GenericObjectMapper.read(key, kp.getOffset());\n          deleteKeysWithPrefix(writeBatch, addPrimaryFilterToKey(name, value,\n              deletePrefix), pfIterator);\n          LOG.debug(\"Deleting entity type:{} id:{} primary filter entry {} {}\",\n              entityType, entityId, name, value);\n        } else if (key[prefixlen] \u003d\u003d RELATED_ENTITIES_COLUMN[0]) {\n          kp \u003d new KeyParser(key,\n              prefixlen + RELATED_ENTITIES_COLUMN.length);\n          String type \u003d kp.getNextString();\n          String id \u003d kp.getNextString();\n          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n          if (relatedEntityStartTime \u003d\u003d null) {\n            LOG.warn(\"Found no start time for \" +\n                \"related entity \" + id + \" of type \" + type + \" while \" +\n                \"deleting \" + entityId + \" of type \" + entityType);\n            continue;\n          }\n          writeBatch.delete(createReverseRelatedEntityKey(id, type,\n              relatedEntityStartTime, entityId, entityType));\n          LOG.debug(\"Deleting entity type:{} id:{} from invisible reverse\"\n              + \" related entity entry of type:{} id:{}\", entityType,\n              entityId, type, id);\n        } else if (key[prefixlen] \u003d\u003d\n            INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN[0]) {\n          kp \u003d new KeyParser(key, prefixlen +\n              INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN.length);\n          String type \u003d kp.getNextString();\n          String id \u003d kp.getNextString();\n          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n          if (relatedEntityStartTime \u003d\u003d null) {\n            LOG.warn(\"Found no start time for reverse \" +\n                \"related entity \" + id + \" of type \" + type + \" while \" +\n                \"deleting \" + entityId + \" of type \" + entityType);\n            continue;\n          }\n          writeBatch.delete(createRelatedEntityKey(id, type,\n              relatedEntityStartTime, entityId, entityType));\n          LOG.debug(\"Deleting entity type:{} id:{} from related entity entry\"\n              +\" of type:{} id:{}\", entityType, entityId, type, id);\n        }\n      }\n      WriteOptions writeOptions \u003d new WriteOptions();\n      writeOptions.sync(true);\n      db.write(writeBatch, writeOptions);\n      return true;\n    } catch(DBException e) {\n      throw new IOException(e);\n    } finally {\n      IOUtils.cleanupWithLogger(LOG, writeBatch);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {}
    },
    "839e077faf4019d6efdcd89d95930023cd0b0a08": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6873. Moving logging APIs over to slf4j in hadoop-yarn-server-applicationhistoryservice. Contributed by Yeliang Cang.\n",
      "commitDate": "07/08/17 2:56 AM",
      "commitName": "839e077faf4019d6efdcd89d95930023cd0b0a08",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "31/07/17 8:15 PM",
      "commitNameOld": "a4aa1cb40504299d3401008fdabc795eafb28713",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 6.28,
      "commitsBetweenForRepo": 91,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,113 +1,113 @@\n   boolean deleteNextEntity(String entityType, byte[] reverseTimestamp,\n       LeveldbIterator iterator, LeveldbIterator pfIterator, boolean seeked)\n       throws IOException {\n     WriteBatch writeBatch \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n           .add(entityType);\n       byte[] typePrefix \u003d kb.getBytesForLookup();\n       kb.add(reverseTimestamp);\n       if (!seeked) {\n         iterator.seek(kb.getBytesForLookup());\n       }\n       if (!iterator.hasNext()) {\n         return false;\n       }\n       byte[] entityKey \u003d iterator.peekNext().getKey();\n       if (!prefixMatches(typePrefix, typePrefix.length, entityKey)) {\n         return false;\n       }\n \n       // read the start time and entity id from the current key\n       KeyParser kp \u003d new KeyParser(entityKey, typePrefix.length + 8);\n       String entityId \u003d kp.getNextString();\n       int prefixlen \u003d kp.getOffset();\n       byte[] deletePrefix \u003d new byte[prefixlen];\n       System.arraycopy(entityKey, 0, deletePrefix, 0, prefixlen);\n \n       writeBatch \u003d db.createWriteBatch();\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" + entityId);\n       }\n       // remove start time from cache and db\n       writeBatch.delete(createStartTimeLookupKey(entityId, entityType));\n       EntityIdentifier entityIdentifier \u003d\n           new EntityIdentifier(entityId, entityType);\n       startTimeReadCache.remove(entityIdentifier);\n       startTimeWriteCache.remove(entityIdentifier);\n \n       // delete current entity\n       for (; iterator.hasNext(); iterator.next()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(entityKey, prefixlen, key)) {\n           break;\n         }\n         writeBatch.delete(key);\n \n         if (key.length \u003d\u003d prefixlen) {\n           continue;\n         }\n         if (key[prefixlen] \u003d\u003d PRIMARY_FILTERS_COLUMN[0]) {\n           kp \u003d new KeyParser(key,\n               prefixlen + PRIMARY_FILTERS_COLUMN.length);\n           String name \u003d kp.getNextString();\n           Object value \u003d GenericObjectMapper.read(key, kp.getOffset());\n           deleteKeysWithPrefix(writeBatch, addPrimaryFilterToKey(name, value,\n               deletePrefix), pfIterator);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                 entityId + \" primary filter entry \" + name + \" \" +\n                 value);\n           }\n         } else if (key[prefixlen] \u003d\u003d RELATED_ENTITIES_COLUMN[0]) {\n           kp \u003d new KeyParser(key,\n               prefixlen + RELATED_ENTITIES_COLUMN.length);\n           String type \u003d kp.getNextString();\n           String id \u003d kp.getNextString();\n           byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n           if (relatedEntityStartTime \u003d\u003d null) {\n             LOG.warn(\"Found no start time for \" +\n                 \"related entity \" + id + \" of type \" + type + \" while \" +\n                 \"deleting \" + entityId + \" of type \" + entityType);\n             continue;\n           }\n           writeBatch.delete(createReverseRelatedEntityKey(id, type,\n               relatedEntityStartTime, entityId, entityType));\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                 entityId + \" from invisible reverse related entity \" +\n                 \"entry of type:\" + type + \" id:\" + id);\n           }\n         } else if (key[prefixlen] \u003d\u003d\n             INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN[0]) {\n           kp \u003d new KeyParser(key, prefixlen +\n               INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN.length);\n           String type \u003d kp.getNextString();\n           String id \u003d kp.getNextString();\n           byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n           if (relatedEntityStartTime \u003d\u003d null) {\n             LOG.warn(\"Found no start time for reverse \" +\n                 \"related entity \" + id + \" of type \" + type + \" while \" +\n                 \"deleting \" + entityId + \" of type \" + entityType);\n             continue;\n           }\n           writeBatch.delete(createRelatedEntityKey(id, type,\n               relatedEntityStartTime, entityId, entityType));\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                 entityId + \" from related entity entry of type:\" +\n                 type + \" id:\" + id);\n           }\n         }\n       }\n       WriteOptions writeOptions \u003d new WriteOptions();\n       writeOptions.sync(true);\n       db.write(writeBatch, writeOptions);\n       return true;\n     } catch(DBException e) {\n       throw new IOException(e);\n     } finally {\n-      IOUtils.cleanup(LOG, writeBatch);\n+      IOUtils.cleanupWithLogger(LOG, writeBatch);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean deleteNextEntity(String entityType, byte[] reverseTimestamp,\n      LeveldbIterator iterator, LeveldbIterator pfIterator, boolean seeked)\n      throws IOException {\n    WriteBatch writeBatch \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n          .add(entityType);\n      byte[] typePrefix \u003d kb.getBytesForLookup();\n      kb.add(reverseTimestamp);\n      if (!seeked) {\n        iterator.seek(kb.getBytesForLookup());\n      }\n      if (!iterator.hasNext()) {\n        return false;\n      }\n      byte[] entityKey \u003d iterator.peekNext().getKey();\n      if (!prefixMatches(typePrefix, typePrefix.length, entityKey)) {\n        return false;\n      }\n\n      // read the start time and entity id from the current key\n      KeyParser kp \u003d new KeyParser(entityKey, typePrefix.length + 8);\n      String entityId \u003d kp.getNextString();\n      int prefixlen \u003d kp.getOffset();\n      byte[] deletePrefix \u003d new byte[prefixlen];\n      System.arraycopy(entityKey, 0, deletePrefix, 0, prefixlen);\n\n      writeBatch \u003d db.createWriteBatch();\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" + entityId);\n      }\n      // remove start time from cache and db\n      writeBatch.delete(createStartTimeLookupKey(entityId, entityType));\n      EntityIdentifier entityIdentifier \u003d\n          new EntityIdentifier(entityId, entityType);\n      startTimeReadCache.remove(entityIdentifier);\n      startTimeWriteCache.remove(entityIdentifier);\n\n      // delete current entity\n      for (; iterator.hasNext(); iterator.next()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(entityKey, prefixlen, key)) {\n          break;\n        }\n        writeBatch.delete(key);\n\n        if (key.length \u003d\u003d prefixlen) {\n          continue;\n        }\n        if (key[prefixlen] \u003d\u003d PRIMARY_FILTERS_COLUMN[0]) {\n          kp \u003d new KeyParser(key,\n              prefixlen + PRIMARY_FILTERS_COLUMN.length);\n          String name \u003d kp.getNextString();\n          Object value \u003d GenericObjectMapper.read(key, kp.getOffset());\n          deleteKeysWithPrefix(writeBatch, addPrimaryFilterToKey(name, value,\n              deletePrefix), pfIterator);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" primary filter entry \" + name + \" \" +\n                value);\n          }\n        } else if (key[prefixlen] \u003d\u003d RELATED_ENTITIES_COLUMN[0]) {\n          kp \u003d new KeyParser(key,\n              prefixlen + RELATED_ENTITIES_COLUMN.length);\n          String type \u003d kp.getNextString();\n          String id \u003d kp.getNextString();\n          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n          if (relatedEntityStartTime \u003d\u003d null) {\n            LOG.warn(\"Found no start time for \" +\n                \"related entity \" + id + \" of type \" + type + \" while \" +\n                \"deleting \" + entityId + \" of type \" + entityType);\n            continue;\n          }\n          writeBatch.delete(createReverseRelatedEntityKey(id, type,\n              relatedEntityStartTime, entityId, entityType));\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" from invisible reverse related entity \" +\n                \"entry of type:\" + type + \" id:\" + id);\n          }\n        } else if (key[prefixlen] \u003d\u003d\n            INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN[0]) {\n          kp \u003d new KeyParser(key, prefixlen +\n              INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN.length);\n          String type \u003d kp.getNextString();\n          String id \u003d kp.getNextString();\n          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n          if (relatedEntityStartTime \u003d\u003d null) {\n            LOG.warn(\"Found no start time for reverse \" +\n                \"related entity \" + id + \" of type \" + type + \" while \" +\n                \"deleting \" + entityId + \" of type \" + entityType);\n            continue;\n          }\n          writeBatch.delete(createRelatedEntityKey(id, type,\n              relatedEntityStartTime, entityId, entityType));\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" from related entity entry of type:\" +\n                type + \" id:\" + id);\n          }\n        }\n      }\n      WriteOptions writeOptions \u003d new WriteOptions();\n      writeOptions.sync(true);\n      db.write(writeBatch, writeOptions);\n      return true;\n    } catch(DBException e) {\n      throw new IOException(e);\n    } finally {\n      IOUtils.cleanupWithLogger(LOG, writeBatch);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {}
    },
    "a4aa1cb40504299d3401008fdabc795eafb28713": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"YARN-6873. Moving logging APIs over to slf4j in hadoop-yarn-server-applicationhistoryservice. Contributed by Yeliang Cang.\"\n\nThis reverts commit 1a78c0ff016097930edf68e8278f826b637e918c.\n",
      "commitDate": "31/07/17 8:15 PM",
      "commitName": "a4aa1cb40504299d3401008fdabc795eafb28713",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "31/07/17 6:53 PM",
      "commitNameOld": "1a78c0ff016097930edf68e8278f826b637e918c",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 0.06,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,113 +1,113 @@\n   boolean deleteNextEntity(String entityType, byte[] reverseTimestamp,\n       LeveldbIterator iterator, LeveldbIterator pfIterator, boolean seeked)\n       throws IOException {\n     WriteBatch writeBatch \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n           .add(entityType);\n       byte[] typePrefix \u003d kb.getBytesForLookup();\n       kb.add(reverseTimestamp);\n       if (!seeked) {\n         iterator.seek(kb.getBytesForLookup());\n       }\n       if (!iterator.hasNext()) {\n         return false;\n       }\n       byte[] entityKey \u003d iterator.peekNext().getKey();\n       if (!prefixMatches(typePrefix, typePrefix.length, entityKey)) {\n         return false;\n       }\n \n       // read the start time and entity id from the current key\n       KeyParser kp \u003d new KeyParser(entityKey, typePrefix.length + 8);\n       String entityId \u003d kp.getNextString();\n       int prefixlen \u003d kp.getOffset();\n       byte[] deletePrefix \u003d new byte[prefixlen];\n       System.arraycopy(entityKey, 0, deletePrefix, 0, prefixlen);\n \n       writeBatch \u003d db.createWriteBatch();\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" + entityId);\n       }\n       // remove start time from cache and db\n       writeBatch.delete(createStartTimeLookupKey(entityId, entityType));\n       EntityIdentifier entityIdentifier \u003d\n           new EntityIdentifier(entityId, entityType);\n       startTimeReadCache.remove(entityIdentifier);\n       startTimeWriteCache.remove(entityIdentifier);\n \n       // delete current entity\n       for (; iterator.hasNext(); iterator.next()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(entityKey, prefixlen, key)) {\n           break;\n         }\n         writeBatch.delete(key);\n \n         if (key.length \u003d\u003d prefixlen) {\n           continue;\n         }\n         if (key[prefixlen] \u003d\u003d PRIMARY_FILTERS_COLUMN[0]) {\n           kp \u003d new KeyParser(key,\n               prefixlen + PRIMARY_FILTERS_COLUMN.length);\n           String name \u003d kp.getNextString();\n           Object value \u003d GenericObjectMapper.read(key, kp.getOffset());\n           deleteKeysWithPrefix(writeBatch, addPrimaryFilterToKey(name, value,\n               deletePrefix), pfIterator);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                 entityId + \" primary filter entry \" + name + \" \" +\n                 value);\n           }\n         } else if (key[prefixlen] \u003d\u003d RELATED_ENTITIES_COLUMN[0]) {\n           kp \u003d new KeyParser(key,\n               prefixlen + RELATED_ENTITIES_COLUMN.length);\n           String type \u003d kp.getNextString();\n           String id \u003d kp.getNextString();\n           byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n           if (relatedEntityStartTime \u003d\u003d null) {\n             LOG.warn(\"Found no start time for \" +\n                 \"related entity \" + id + \" of type \" + type + \" while \" +\n                 \"deleting \" + entityId + \" of type \" + entityType);\n             continue;\n           }\n           writeBatch.delete(createReverseRelatedEntityKey(id, type,\n               relatedEntityStartTime, entityId, entityType));\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                 entityId + \" from invisible reverse related entity \" +\n                 \"entry of type:\" + type + \" id:\" + id);\n           }\n         } else if (key[prefixlen] \u003d\u003d\n             INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN[0]) {\n           kp \u003d new KeyParser(key, prefixlen +\n               INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN.length);\n           String type \u003d kp.getNextString();\n           String id \u003d kp.getNextString();\n           byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n           if (relatedEntityStartTime \u003d\u003d null) {\n             LOG.warn(\"Found no start time for reverse \" +\n                 \"related entity \" + id + \" of type \" + type + \" while \" +\n                 \"deleting \" + entityId + \" of type \" + entityType);\n             continue;\n           }\n           writeBatch.delete(createRelatedEntityKey(id, type,\n               relatedEntityStartTime, entityId, entityType));\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                 entityId + \" from related entity entry of type:\" +\n                 type + \" id:\" + id);\n           }\n         }\n       }\n       WriteOptions writeOptions \u003d new WriteOptions();\n       writeOptions.sync(true);\n       db.write(writeBatch, writeOptions);\n       return true;\n     } catch(DBException e) {\n       throw new IOException(e);\n     } finally {\n-      IOUtils.cleanupWithLogger(LOG, writeBatch);\n+      IOUtils.cleanup(LOG, writeBatch);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean deleteNextEntity(String entityType, byte[] reverseTimestamp,\n      LeveldbIterator iterator, LeveldbIterator pfIterator, boolean seeked)\n      throws IOException {\n    WriteBatch writeBatch \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n          .add(entityType);\n      byte[] typePrefix \u003d kb.getBytesForLookup();\n      kb.add(reverseTimestamp);\n      if (!seeked) {\n        iterator.seek(kb.getBytesForLookup());\n      }\n      if (!iterator.hasNext()) {\n        return false;\n      }\n      byte[] entityKey \u003d iterator.peekNext().getKey();\n      if (!prefixMatches(typePrefix, typePrefix.length, entityKey)) {\n        return false;\n      }\n\n      // read the start time and entity id from the current key\n      KeyParser kp \u003d new KeyParser(entityKey, typePrefix.length + 8);\n      String entityId \u003d kp.getNextString();\n      int prefixlen \u003d kp.getOffset();\n      byte[] deletePrefix \u003d new byte[prefixlen];\n      System.arraycopy(entityKey, 0, deletePrefix, 0, prefixlen);\n\n      writeBatch \u003d db.createWriteBatch();\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" + entityId);\n      }\n      // remove start time from cache and db\n      writeBatch.delete(createStartTimeLookupKey(entityId, entityType));\n      EntityIdentifier entityIdentifier \u003d\n          new EntityIdentifier(entityId, entityType);\n      startTimeReadCache.remove(entityIdentifier);\n      startTimeWriteCache.remove(entityIdentifier);\n\n      // delete current entity\n      for (; iterator.hasNext(); iterator.next()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(entityKey, prefixlen, key)) {\n          break;\n        }\n        writeBatch.delete(key);\n\n        if (key.length \u003d\u003d prefixlen) {\n          continue;\n        }\n        if (key[prefixlen] \u003d\u003d PRIMARY_FILTERS_COLUMN[0]) {\n          kp \u003d new KeyParser(key,\n              prefixlen + PRIMARY_FILTERS_COLUMN.length);\n          String name \u003d kp.getNextString();\n          Object value \u003d GenericObjectMapper.read(key, kp.getOffset());\n          deleteKeysWithPrefix(writeBatch, addPrimaryFilterToKey(name, value,\n              deletePrefix), pfIterator);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" primary filter entry \" + name + \" \" +\n                value);\n          }\n        } else if (key[prefixlen] \u003d\u003d RELATED_ENTITIES_COLUMN[0]) {\n          kp \u003d new KeyParser(key,\n              prefixlen + RELATED_ENTITIES_COLUMN.length);\n          String type \u003d kp.getNextString();\n          String id \u003d kp.getNextString();\n          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n          if (relatedEntityStartTime \u003d\u003d null) {\n            LOG.warn(\"Found no start time for \" +\n                \"related entity \" + id + \" of type \" + type + \" while \" +\n                \"deleting \" + entityId + \" of type \" + entityType);\n            continue;\n          }\n          writeBatch.delete(createReverseRelatedEntityKey(id, type,\n              relatedEntityStartTime, entityId, entityType));\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" from invisible reverse related entity \" +\n                \"entry of type:\" + type + \" id:\" + id);\n          }\n        } else if (key[prefixlen] \u003d\u003d\n            INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN[0]) {\n          kp \u003d new KeyParser(key, prefixlen +\n              INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN.length);\n          String type \u003d kp.getNextString();\n          String id \u003d kp.getNextString();\n          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n          if (relatedEntityStartTime \u003d\u003d null) {\n            LOG.warn(\"Found no start time for reverse \" +\n                \"related entity \" + id + \" of type \" + type + \" while \" +\n                \"deleting \" + entityId + \" of type \" + entityType);\n            continue;\n          }\n          writeBatch.delete(createRelatedEntityKey(id, type,\n              relatedEntityStartTime, entityId, entityType));\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" from related entity entry of type:\" +\n                type + \" id:\" + id);\n          }\n        }\n      }\n      WriteOptions writeOptions \u003d new WriteOptions();\n      writeOptions.sync(true);\n      db.write(writeBatch, writeOptions);\n      return true;\n    } catch(DBException e) {\n      throw new IOException(e);\n    } finally {\n      IOUtils.cleanup(LOG, writeBatch);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {}
    },
    "1a78c0ff016097930edf68e8278f826b637e918c": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6873. Moving logging APIs over to slf4j in hadoop-yarn-server-applicationhistoryservice. Contributed by Yeliang Cang.\n",
      "commitDate": "31/07/17 6:53 PM",
      "commitName": "1a78c0ff016097930edf68e8278f826b637e918c",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "10/01/17 2:24 AM",
      "commitNameOld": "4c431a694059e40e78365b02a1497a6c7e479a70",
      "commitAuthorOld": "Naganarasimha",
      "daysBetweenCommits": 202.65,
      "commitsBetweenForRepo": 1063,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,113 +1,113 @@\n   boolean deleteNextEntity(String entityType, byte[] reverseTimestamp,\n       LeveldbIterator iterator, LeveldbIterator pfIterator, boolean seeked)\n       throws IOException {\n     WriteBatch writeBatch \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n           .add(entityType);\n       byte[] typePrefix \u003d kb.getBytesForLookup();\n       kb.add(reverseTimestamp);\n       if (!seeked) {\n         iterator.seek(kb.getBytesForLookup());\n       }\n       if (!iterator.hasNext()) {\n         return false;\n       }\n       byte[] entityKey \u003d iterator.peekNext().getKey();\n       if (!prefixMatches(typePrefix, typePrefix.length, entityKey)) {\n         return false;\n       }\n \n       // read the start time and entity id from the current key\n       KeyParser kp \u003d new KeyParser(entityKey, typePrefix.length + 8);\n       String entityId \u003d kp.getNextString();\n       int prefixlen \u003d kp.getOffset();\n       byte[] deletePrefix \u003d new byte[prefixlen];\n       System.arraycopy(entityKey, 0, deletePrefix, 0, prefixlen);\n \n       writeBatch \u003d db.createWriteBatch();\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" + entityId);\n       }\n       // remove start time from cache and db\n       writeBatch.delete(createStartTimeLookupKey(entityId, entityType));\n       EntityIdentifier entityIdentifier \u003d\n           new EntityIdentifier(entityId, entityType);\n       startTimeReadCache.remove(entityIdentifier);\n       startTimeWriteCache.remove(entityIdentifier);\n \n       // delete current entity\n       for (; iterator.hasNext(); iterator.next()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(entityKey, prefixlen, key)) {\n           break;\n         }\n         writeBatch.delete(key);\n \n         if (key.length \u003d\u003d prefixlen) {\n           continue;\n         }\n         if (key[prefixlen] \u003d\u003d PRIMARY_FILTERS_COLUMN[0]) {\n           kp \u003d new KeyParser(key,\n               prefixlen + PRIMARY_FILTERS_COLUMN.length);\n           String name \u003d kp.getNextString();\n           Object value \u003d GenericObjectMapper.read(key, kp.getOffset());\n           deleteKeysWithPrefix(writeBatch, addPrimaryFilterToKey(name, value,\n               deletePrefix), pfIterator);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                 entityId + \" primary filter entry \" + name + \" \" +\n                 value);\n           }\n         } else if (key[prefixlen] \u003d\u003d RELATED_ENTITIES_COLUMN[0]) {\n           kp \u003d new KeyParser(key,\n               prefixlen + RELATED_ENTITIES_COLUMN.length);\n           String type \u003d kp.getNextString();\n           String id \u003d kp.getNextString();\n           byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n           if (relatedEntityStartTime \u003d\u003d null) {\n             LOG.warn(\"Found no start time for \" +\n                 \"related entity \" + id + \" of type \" + type + \" while \" +\n                 \"deleting \" + entityId + \" of type \" + entityType);\n             continue;\n           }\n           writeBatch.delete(createReverseRelatedEntityKey(id, type,\n               relatedEntityStartTime, entityId, entityType));\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                 entityId + \" from invisible reverse related entity \" +\n                 \"entry of type:\" + type + \" id:\" + id);\n           }\n         } else if (key[prefixlen] \u003d\u003d\n             INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN[0]) {\n           kp \u003d new KeyParser(key, prefixlen +\n               INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN.length);\n           String type \u003d kp.getNextString();\n           String id \u003d kp.getNextString();\n           byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n           if (relatedEntityStartTime \u003d\u003d null) {\n             LOG.warn(\"Found no start time for reverse \" +\n                 \"related entity \" + id + \" of type \" + type + \" while \" +\n                 \"deleting \" + entityId + \" of type \" + entityType);\n             continue;\n           }\n           writeBatch.delete(createRelatedEntityKey(id, type,\n               relatedEntityStartTime, entityId, entityType));\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                 entityId + \" from related entity entry of type:\" +\n                 type + \" id:\" + id);\n           }\n         }\n       }\n       WriteOptions writeOptions \u003d new WriteOptions();\n       writeOptions.sync(true);\n       db.write(writeBatch, writeOptions);\n       return true;\n     } catch(DBException e) {\n       throw new IOException(e);\n     } finally {\n-      IOUtils.cleanup(LOG, writeBatch);\n+      IOUtils.cleanupWithLogger(LOG, writeBatch);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean deleteNextEntity(String entityType, byte[] reverseTimestamp,\n      LeveldbIterator iterator, LeveldbIterator pfIterator, boolean seeked)\n      throws IOException {\n    WriteBatch writeBatch \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n          .add(entityType);\n      byte[] typePrefix \u003d kb.getBytesForLookup();\n      kb.add(reverseTimestamp);\n      if (!seeked) {\n        iterator.seek(kb.getBytesForLookup());\n      }\n      if (!iterator.hasNext()) {\n        return false;\n      }\n      byte[] entityKey \u003d iterator.peekNext().getKey();\n      if (!prefixMatches(typePrefix, typePrefix.length, entityKey)) {\n        return false;\n      }\n\n      // read the start time and entity id from the current key\n      KeyParser kp \u003d new KeyParser(entityKey, typePrefix.length + 8);\n      String entityId \u003d kp.getNextString();\n      int prefixlen \u003d kp.getOffset();\n      byte[] deletePrefix \u003d new byte[prefixlen];\n      System.arraycopy(entityKey, 0, deletePrefix, 0, prefixlen);\n\n      writeBatch \u003d db.createWriteBatch();\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" + entityId);\n      }\n      // remove start time from cache and db\n      writeBatch.delete(createStartTimeLookupKey(entityId, entityType));\n      EntityIdentifier entityIdentifier \u003d\n          new EntityIdentifier(entityId, entityType);\n      startTimeReadCache.remove(entityIdentifier);\n      startTimeWriteCache.remove(entityIdentifier);\n\n      // delete current entity\n      for (; iterator.hasNext(); iterator.next()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(entityKey, prefixlen, key)) {\n          break;\n        }\n        writeBatch.delete(key);\n\n        if (key.length \u003d\u003d prefixlen) {\n          continue;\n        }\n        if (key[prefixlen] \u003d\u003d PRIMARY_FILTERS_COLUMN[0]) {\n          kp \u003d new KeyParser(key,\n              prefixlen + PRIMARY_FILTERS_COLUMN.length);\n          String name \u003d kp.getNextString();\n          Object value \u003d GenericObjectMapper.read(key, kp.getOffset());\n          deleteKeysWithPrefix(writeBatch, addPrimaryFilterToKey(name, value,\n              deletePrefix), pfIterator);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" primary filter entry \" + name + \" \" +\n                value);\n          }\n        } else if (key[prefixlen] \u003d\u003d RELATED_ENTITIES_COLUMN[0]) {\n          kp \u003d new KeyParser(key,\n              prefixlen + RELATED_ENTITIES_COLUMN.length);\n          String type \u003d kp.getNextString();\n          String id \u003d kp.getNextString();\n          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n          if (relatedEntityStartTime \u003d\u003d null) {\n            LOG.warn(\"Found no start time for \" +\n                \"related entity \" + id + \" of type \" + type + \" while \" +\n                \"deleting \" + entityId + \" of type \" + entityType);\n            continue;\n          }\n          writeBatch.delete(createReverseRelatedEntityKey(id, type,\n              relatedEntityStartTime, entityId, entityType));\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" from invisible reverse related entity \" +\n                \"entry of type:\" + type + \" id:\" + id);\n          }\n        } else if (key[prefixlen] \u003d\u003d\n            INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN[0]) {\n          kp \u003d new KeyParser(key, prefixlen +\n              INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN.length);\n          String type \u003d kp.getNextString();\n          String id \u003d kp.getNextString();\n          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n          if (relatedEntityStartTime \u003d\u003d null) {\n            LOG.warn(\"Found no start time for reverse \" +\n                \"related entity \" + id + \" of type \" + type + \" while \" +\n                \"deleting \" + entityId + \" of type \" + entityType);\n            continue;\n          }\n          writeBatch.delete(createRelatedEntityKey(id, type,\n              relatedEntityStartTime, entityId, entityType));\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" from related entity entry of type:\" +\n                type + \" id:\" + id);\n          }\n        }\n      }\n      WriteOptions writeOptions \u003d new WriteOptions();\n      writeOptions.sync(true);\n      db.write(writeBatch, writeOptions);\n      return true;\n    } catch(DBException e) {\n      throw new IOException(e);\n    } finally {\n      IOUtils.cleanupWithLogger(LOG, writeBatch);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {}
    },
    "1ce4d33c2dc86d711b227a04d2f9a2ab696a24a1": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-1984. LeveldbTimelineStore does not handle db exceptions properly. Contributed by Varun Saxena\n",
      "commitDate": "24/11/14 2:36 PM",
      "commitName": "1ce4d33c2dc86d711b227a04d2f9a2ab696a24a1",
      "commitAuthor": "Jason Lowe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-1984. LeveldbTimelineStore does not handle db exceptions properly. Contributed by Varun Saxena\n",
          "commitDate": "24/11/14 2:36 PM",
          "commitName": "1ce4d33c2dc86d711b227a04d2f9a2ab696a24a1",
          "commitAuthor": "Jason Lowe",
          "commitDateOld": "07/11/14 4:11 PM",
          "commitNameOld": "4a114dd67aae83e5bb2d65470166de954acf36a2",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 16.93,
          "commitsBetweenForRepo": 118,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,111 +1,113 @@\n   boolean deleteNextEntity(String entityType, byte[] reverseTimestamp,\n-      DBIterator iterator, DBIterator pfIterator, boolean seeked)\n+      LeveldbIterator iterator, LeveldbIterator pfIterator, boolean seeked)\n       throws IOException {\n     WriteBatch writeBatch \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n           .add(entityType);\n       byte[] typePrefix \u003d kb.getBytesForLookup();\n       kb.add(reverseTimestamp);\n       if (!seeked) {\n         iterator.seek(kb.getBytesForLookup());\n       }\n       if (!iterator.hasNext()) {\n         return false;\n       }\n       byte[] entityKey \u003d iterator.peekNext().getKey();\n       if (!prefixMatches(typePrefix, typePrefix.length, entityKey)) {\n         return false;\n       }\n \n       // read the start time and entity id from the current key\n       KeyParser kp \u003d new KeyParser(entityKey, typePrefix.length + 8);\n       String entityId \u003d kp.getNextString();\n       int prefixlen \u003d kp.getOffset();\n       byte[] deletePrefix \u003d new byte[prefixlen];\n       System.arraycopy(entityKey, 0, deletePrefix, 0, prefixlen);\n \n       writeBatch \u003d db.createWriteBatch();\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" + entityId);\n       }\n       // remove start time from cache and db\n       writeBatch.delete(createStartTimeLookupKey(entityId, entityType));\n       EntityIdentifier entityIdentifier \u003d\n           new EntityIdentifier(entityId, entityType);\n       startTimeReadCache.remove(entityIdentifier);\n       startTimeWriteCache.remove(entityIdentifier);\n \n       // delete current entity\n       for (; iterator.hasNext(); iterator.next()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(entityKey, prefixlen, key)) {\n           break;\n         }\n         writeBatch.delete(key);\n \n         if (key.length \u003d\u003d prefixlen) {\n           continue;\n         }\n         if (key[prefixlen] \u003d\u003d PRIMARY_FILTERS_COLUMN[0]) {\n           kp \u003d new KeyParser(key,\n               prefixlen + PRIMARY_FILTERS_COLUMN.length);\n           String name \u003d kp.getNextString();\n           Object value \u003d GenericObjectMapper.read(key, kp.getOffset());\n           deleteKeysWithPrefix(writeBatch, addPrimaryFilterToKey(name, value,\n               deletePrefix), pfIterator);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                 entityId + \" primary filter entry \" + name + \" \" +\n                 value);\n           }\n         } else if (key[prefixlen] \u003d\u003d RELATED_ENTITIES_COLUMN[0]) {\n           kp \u003d new KeyParser(key,\n               prefixlen + RELATED_ENTITIES_COLUMN.length);\n           String type \u003d kp.getNextString();\n           String id \u003d kp.getNextString();\n           byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n           if (relatedEntityStartTime \u003d\u003d null) {\n             LOG.warn(\"Found no start time for \" +\n                 \"related entity \" + id + \" of type \" + type + \" while \" +\n                 \"deleting \" + entityId + \" of type \" + entityType);\n             continue;\n           }\n           writeBatch.delete(createReverseRelatedEntityKey(id, type,\n               relatedEntityStartTime, entityId, entityType));\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                 entityId + \" from invisible reverse related entity \" +\n                 \"entry of type:\" + type + \" id:\" + id);\n           }\n         } else if (key[prefixlen] \u003d\u003d\n             INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN[0]) {\n           kp \u003d new KeyParser(key, prefixlen +\n               INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN.length);\n           String type \u003d kp.getNextString();\n           String id \u003d kp.getNextString();\n           byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n           if (relatedEntityStartTime \u003d\u003d null) {\n             LOG.warn(\"Found no start time for reverse \" +\n                 \"related entity \" + id + \" of type \" + type + \" while \" +\n                 \"deleting \" + entityId + \" of type \" + entityType);\n             continue;\n           }\n           writeBatch.delete(createRelatedEntityKey(id, type,\n               relatedEntityStartTime, entityId, entityType));\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                 entityId + \" from related entity entry of type:\" +\n                 type + \" id:\" + id);\n           }\n         }\n       }\n       WriteOptions writeOptions \u003d new WriteOptions();\n       writeOptions.sync(true);\n       db.write(writeBatch, writeOptions);\n       return true;\n+    } catch(DBException e) {\n+      throw new IOException(e);\n     } finally {\n       IOUtils.cleanup(LOG, writeBatch);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean deleteNextEntity(String entityType, byte[] reverseTimestamp,\n      LeveldbIterator iterator, LeveldbIterator pfIterator, boolean seeked)\n      throws IOException {\n    WriteBatch writeBatch \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n          .add(entityType);\n      byte[] typePrefix \u003d kb.getBytesForLookup();\n      kb.add(reverseTimestamp);\n      if (!seeked) {\n        iterator.seek(kb.getBytesForLookup());\n      }\n      if (!iterator.hasNext()) {\n        return false;\n      }\n      byte[] entityKey \u003d iterator.peekNext().getKey();\n      if (!prefixMatches(typePrefix, typePrefix.length, entityKey)) {\n        return false;\n      }\n\n      // read the start time and entity id from the current key\n      KeyParser kp \u003d new KeyParser(entityKey, typePrefix.length + 8);\n      String entityId \u003d kp.getNextString();\n      int prefixlen \u003d kp.getOffset();\n      byte[] deletePrefix \u003d new byte[prefixlen];\n      System.arraycopy(entityKey, 0, deletePrefix, 0, prefixlen);\n\n      writeBatch \u003d db.createWriteBatch();\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" + entityId);\n      }\n      // remove start time from cache and db\n      writeBatch.delete(createStartTimeLookupKey(entityId, entityType));\n      EntityIdentifier entityIdentifier \u003d\n          new EntityIdentifier(entityId, entityType);\n      startTimeReadCache.remove(entityIdentifier);\n      startTimeWriteCache.remove(entityIdentifier);\n\n      // delete current entity\n      for (; iterator.hasNext(); iterator.next()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(entityKey, prefixlen, key)) {\n          break;\n        }\n        writeBatch.delete(key);\n\n        if (key.length \u003d\u003d prefixlen) {\n          continue;\n        }\n        if (key[prefixlen] \u003d\u003d PRIMARY_FILTERS_COLUMN[0]) {\n          kp \u003d new KeyParser(key,\n              prefixlen + PRIMARY_FILTERS_COLUMN.length);\n          String name \u003d kp.getNextString();\n          Object value \u003d GenericObjectMapper.read(key, kp.getOffset());\n          deleteKeysWithPrefix(writeBatch, addPrimaryFilterToKey(name, value,\n              deletePrefix), pfIterator);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" primary filter entry \" + name + \" \" +\n                value);\n          }\n        } else if (key[prefixlen] \u003d\u003d RELATED_ENTITIES_COLUMN[0]) {\n          kp \u003d new KeyParser(key,\n              prefixlen + RELATED_ENTITIES_COLUMN.length);\n          String type \u003d kp.getNextString();\n          String id \u003d kp.getNextString();\n          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n          if (relatedEntityStartTime \u003d\u003d null) {\n            LOG.warn(\"Found no start time for \" +\n                \"related entity \" + id + \" of type \" + type + \" while \" +\n                \"deleting \" + entityId + \" of type \" + entityType);\n            continue;\n          }\n          writeBatch.delete(createReverseRelatedEntityKey(id, type,\n              relatedEntityStartTime, entityId, entityType));\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" from invisible reverse related entity \" +\n                \"entry of type:\" + type + \" id:\" + id);\n          }\n        } else if (key[prefixlen] \u003d\u003d\n            INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN[0]) {\n          kp \u003d new KeyParser(key, prefixlen +\n              INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN.length);\n          String type \u003d kp.getNextString();\n          String id \u003d kp.getNextString();\n          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n          if (relatedEntityStartTime \u003d\u003d null) {\n            LOG.warn(\"Found no start time for reverse \" +\n                \"related entity \" + id + \" of type \" + type + \" while \" +\n                \"deleting \" + entityId + \" of type \" + entityType);\n            continue;\n          }\n          writeBatch.delete(createRelatedEntityKey(id, type,\n              relatedEntityStartTime, entityId, entityType));\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" from related entity entry of type:\" +\n                type + \" id:\" + id);\n          }\n        }\n      }\n      WriteOptions writeOptions \u003d new WriteOptions();\n      writeOptions.sync(true);\n      db.write(writeBatch, writeOptions);\n      return true;\n    } catch(DBException e) {\n      throw new IOException(e);\n    } finally {\n      IOUtils.cleanup(LOG, writeBatch);\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
          "extendedDetails": {
            "oldValue": "[entityType-String, reverseTimestamp-byte[], iterator-DBIterator, pfIterator-DBIterator, seeked-boolean]",
            "newValue": "[entityType-String, reverseTimestamp-byte[], iterator-LeveldbIterator, pfIterator-LeveldbIterator, seeked-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-1984. LeveldbTimelineStore does not handle db exceptions properly. Contributed by Varun Saxena\n",
          "commitDate": "24/11/14 2:36 PM",
          "commitName": "1ce4d33c2dc86d711b227a04d2f9a2ab696a24a1",
          "commitAuthor": "Jason Lowe",
          "commitDateOld": "07/11/14 4:11 PM",
          "commitNameOld": "4a114dd67aae83e5bb2d65470166de954acf36a2",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 16.93,
          "commitsBetweenForRepo": 118,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,111 +1,113 @@\n   boolean deleteNextEntity(String entityType, byte[] reverseTimestamp,\n-      DBIterator iterator, DBIterator pfIterator, boolean seeked)\n+      LeveldbIterator iterator, LeveldbIterator pfIterator, boolean seeked)\n       throws IOException {\n     WriteBatch writeBatch \u003d null;\n     try {\n       KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n           .add(entityType);\n       byte[] typePrefix \u003d kb.getBytesForLookup();\n       kb.add(reverseTimestamp);\n       if (!seeked) {\n         iterator.seek(kb.getBytesForLookup());\n       }\n       if (!iterator.hasNext()) {\n         return false;\n       }\n       byte[] entityKey \u003d iterator.peekNext().getKey();\n       if (!prefixMatches(typePrefix, typePrefix.length, entityKey)) {\n         return false;\n       }\n \n       // read the start time and entity id from the current key\n       KeyParser kp \u003d new KeyParser(entityKey, typePrefix.length + 8);\n       String entityId \u003d kp.getNextString();\n       int prefixlen \u003d kp.getOffset();\n       byte[] deletePrefix \u003d new byte[prefixlen];\n       System.arraycopy(entityKey, 0, deletePrefix, 0, prefixlen);\n \n       writeBatch \u003d db.createWriteBatch();\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" + entityId);\n       }\n       // remove start time from cache and db\n       writeBatch.delete(createStartTimeLookupKey(entityId, entityType));\n       EntityIdentifier entityIdentifier \u003d\n           new EntityIdentifier(entityId, entityType);\n       startTimeReadCache.remove(entityIdentifier);\n       startTimeWriteCache.remove(entityIdentifier);\n \n       // delete current entity\n       for (; iterator.hasNext(); iterator.next()) {\n         byte[] key \u003d iterator.peekNext().getKey();\n         if (!prefixMatches(entityKey, prefixlen, key)) {\n           break;\n         }\n         writeBatch.delete(key);\n \n         if (key.length \u003d\u003d prefixlen) {\n           continue;\n         }\n         if (key[prefixlen] \u003d\u003d PRIMARY_FILTERS_COLUMN[0]) {\n           kp \u003d new KeyParser(key,\n               prefixlen + PRIMARY_FILTERS_COLUMN.length);\n           String name \u003d kp.getNextString();\n           Object value \u003d GenericObjectMapper.read(key, kp.getOffset());\n           deleteKeysWithPrefix(writeBatch, addPrimaryFilterToKey(name, value,\n               deletePrefix), pfIterator);\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                 entityId + \" primary filter entry \" + name + \" \" +\n                 value);\n           }\n         } else if (key[prefixlen] \u003d\u003d RELATED_ENTITIES_COLUMN[0]) {\n           kp \u003d new KeyParser(key,\n               prefixlen + RELATED_ENTITIES_COLUMN.length);\n           String type \u003d kp.getNextString();\n           String id \u003d kp.getNextString();\n           byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n           if (relatedEntityStartTime \u003d\u003d null) {\n             LOG.warn(\"Found no start time for \" +\n                 \"related entity \" + id + \" of type \" + type + \" while \" +\n                 \"deleting \" + entityId + \" of type \" + entityType);\n             continue;\n           }\n           writeBatch.delete(createReverseRelatedEntityKey(id, type,\n               relatedEntityStartTime, entityId, entityType));\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                 entityId + \" from invisible reverse related entity \" +\n                 \"entry of type:\" + type + \" id:\" + id);\n           }\n         } else if (key[prefixlen] \u003d\u003d\n             INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN[0]) {\n           kp \u003d new KeyParser(key, prefixlen +\n               INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN.length);\n           String type \u003d kp.getNextString();\n           String id \u003d kp.getNextString();\n           byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n           if (relatedEntityStartTime \u003d\u003d null) {\n             LOG.warn(\"Found no start time for reverse \" +\n                 \"related entity \" + id + \" of type \" + type + \" while \" +\n                 \"deleting \" + entityId + \" of type \" + entityType);\n             continue;\n           }\n           writeBatch.delete(createRelatedEntityKey(id, type,\n               relatedEntityStartTime, entityId, entityType));\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                 entityId + \" from related entity entry of type:\" +\n                 type + \" id:\" + id);\n           }\n         }\n       }\n       WriteOptions writeOptions \u003d new WriteOptions();\n       writeOptions.sync(true);\n       db.write(writeBatch, writeOptions);\n       return true;\n+    } catch(DBException e) {\n+      throw new IOException(e);\n     } finally {\n       IOUtils.cleanup(LOG, writeBatch);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean deleteNextEntity(String entityType, byte[] reverseTimestamp,\n      LeveldbIterator iterator, LeveldbIterator pfIterator, boolean seeked)\n      throws IOException {\n    WriteBatch writeBatch \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n          .add(entityType);\n      byte[] typePrefix \u003d kb.getBytesForLookup();\n      kb.add(reverseTimestamp);\n      if (!seeked) {\n        iterator.seek(kb.getBytesForLookup());\n      }\n      if (!iterator.hasNext()) {\n        return false;\n      }\n      byte[] entityKey \u003d iterator.peekNext().getKey();\n      if (!prefixMatches(typePrefix, typePrefix.length, entityKey)) {\n        return false;\n      }\n\n      // read the start time and entity id from the current key\n      KeyParser kp \u003d new KeyParser(entityKey, typePrefix.length + 8);\n      String entityId \u003d kp.getNextString();\n      int prefixlen \u003d kp.getOffset();\n      byte[] deletePrefix \u003d new byte[prefixlen];\n      System.arraycopy(entityKey, 0, deletePrefix, 0, prefixlen);\n\n      writeBatch \u003d db.createWriteBatch();\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" + entityId);\n      }\n      // remove start time from cache and db\n      writeBatch.delete(createStartTimeLookupKey(entityId, entityType));\n      EntityIdentifier entityIdentifier \u003d\n          new EntityIdentifier(entityId, entityType);\n      startTimeReadCache.remove(entityIdentifier);\n      startTimeWriteCache.remove(entityIdentifier);\n\n      // delete current entity\n      for (; iterator.hasNext(); iterator.next()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(entityKey, prefixlen, key)) {\n          break;\n        }\n        writeBatch.delete(key);\n\n        if (key.length \u003d\u003d prefixlen) {\n          continue;\n        }\n        if (key[prefixlen] \u003d\u003d PRIMARY_FILTERS_COLUMN[0]) {\n          kp \u003d new KeyParser(key,\n              prefixlen + PRIMARY_FILTERS_COLUMN.length);\n          String name \u003d kp.getNextString();\n          Object value \u003d GenericObjectMapper.read(key, kp.getOffset());\n          deleteKeysWithPrefix(writeBatch, addPrimaryFilterToKey(name, value,\n              deletePrefix), pfIterator);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" primary filter entry \" + name + \" \" +\n                value);\n          }\n        } else if (key[prefixlen] \u003d\u003d RELATED_ENTITIES_COLUMN[0]) {\n          kp \u003d new KeyParser(key,\n              prefixlen + RELATED_ENTITIES_COLUMN.length);\n          String type \u003d kp.getNextString();\n          String id \u003d kp.getNextString();\n          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n          if (relatedEntityStartTime \u003d\u003d null) {\n            LOG.warn(\"Found no start time for \" +\n                \"related entity \" + id + \" of type \" + type + \" while \" +\n                \"deleting \" + entityId + \" of type \" + entityType);\n            continue;\n          }\n          writeBatch.delete(createReverseRelatedEntityKey(id, type,\n              relatedEntityStartTime, entityId, entityType));\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" from invisible reverse related entity \" +\n                \"entry of type:\" + type + \" id:\" + id);\n          }\n        } else if (key[prefixlen] \u003d\u003d\n            INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN[0]) {\n          kp \u003d new KeyParser(key, prefixlen +\n              INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN.length);\n          String type \u003d kp.getNextString();\n          String id \u003d kp.getNextString();\n          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n          if (relatedEntityStartTime \u003d\u003d null) {\n            LOG.warn(\"Found no start time for reverse \" +\n                \"related entity \" + id + \" of type \" + type + \" while \" +\n                \"deleting \" + entityId + \" of type \" + entityType);\n            continue;\n          }\n          writeBatch.delete(createRelatedEntityKey(id, type,\n              relatedEntityStartTime, entityId, entityType));\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" from related entity entry of type:\" +\n                type + \" id:\" + id);\n          }\n        }\n      }\n      WriteOptions writeOptions \u003d new WriteOptions();\n      writeOptions.sync(true);\n      db.write(writeBatch, writeOptions);\n      return true;\n    } catch(DBException e) {\n      throw new IOException(e);\n    } finally {\n      IOUtils.cleanup(LOG, writeBatch);\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
          "extendedDetails": {}
        }
      ]
    },
    "001078e0677e39b962ca1da81fc34d7ac9a7e65c": {
      "type": "Yfilerename",
      "commitMessage": "YARN-2107. Refactored timeline classes into o.a.h.y.s.timeline package. Contributed by Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1598094 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/05/14 11:09 AM",
      "commitName": "001078e0677e39b962ca1da81fc34d7ac9a7e65c",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "28/05/14 10:44 AM",
      "commitNameOld": "cfd8647d0f20c08761f908be1f5b718c1c372498",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  boolean deleteNextEntity(String entityType, byte[] reverseTimestamp,\n      DBIterator iterator, DBIterator pfIterator, boolean seeked)\n      throws IOException {\n    WriteBatch writeBatch \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n          .add(entityType);\n      byte[] typePrefix \u003d kb.getBytesForLookup();\n      kb.add(reverseTimestamp);\n      if (!seeked) {\n        iterator.seek(kb.getBytesForLookup());\n      }\n      if (!iterator.hasNext()) {\n        return false;\n      }\n      byte[] entityKey \u003d iterator.peekNext().getKey();\n      if (!prefixMatches(typePrefix, typePrefix.length, entityKey)) {\n        return false;\n      }\n\n      // read the start time and entity id from the current key\n      KeyParser kp \u003d new KeyParser(entityKey, typePrefix.length + 8);\n      String entityId \u003d kp.getNextString();\n      int prefixlen \u003d kp.getOffset();\n      byte[] deletePrefix \u003d new byte[prefixlen];\n      System.arraycopy(entityKey, 0, deletePrefix, 0, prefixlen);\n\n      writeBatch \u003d db.createWriteBatch();\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" + entityId);\n      }\n      // remove start time from cache and db\n      writeBatch.delete(createStartTimeLookupKey(entityId, entityType));\n      EntityIdentifier entityIdentifier \u003d\n          new EntityIdentifier(entityId, entityType);\n      startTimeReadCache.remove(entityIdentifier);\n      startTimeWriteCache.remove(entityIdentifier);\n\n      // delete current entity\n      for (; iterator.hasNext(); iterator.next()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(entityKey, prefixlen, key)) {\n          break;\n        }\n        writeBatch.delete(key);\n\n        if (key.length \u003d\u003d prefixlen) {\n          continue;\n        }\n        if (key[prefixlen] \u003d\u003d PRIMARY_FILTERS_COLUMN[0]) {\n          kp \u003d new KeyParser(key,\n              prefixlen + PRIMARY_FILTERS_COLUMN.length);\n          String name \u003d kp.getNextString();\n          Object value \u003d GenericObjectMapper.read(key, kp.getOffset());\n          deleteKeysWithPrefix(writeBatch, addPrimaryFilterToKey(name, value,\n              deletePrefix), pfIterator);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" primary filter entry \" + name + \" \" +\n                value);\n          }\n        } else if (key[prefixlen] \u003d\u003d RELATED_ENTITIES_COLUMN[0]) {\n          kp \u003d new KeyParser(key,\n              prefixlen + RELATED_ENTITIES_COLUMN.length);\n          String type \u003d kp.getNextString();\n          String id \u003d kp.getNextString();\n          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n          if (relatedEntityStartTime \u003d\u003d null) {\n            LOG.warn(\"Found no start time for \" +\n                \"related entity \" + id + \" of type \" + type + \" while \" +\n                \"deleting \" + entityId + \" of type \" + entityType);\n            continue;\n          }\n          writeBatch.delete(createReverseRelatedEntityKey(id, type,\n              relatedEntityStartTime, entityId, entityType));\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" from invisible reverse related entity \" +\n                \"entry of type:\" + type + \" id:\" + id);\n          }\n        } else if (key[prefixlen] \u003d\u003d\n            INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN[0]) {\n          kp \u003d new KeyParser(key, prefixlen +\n              INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN.length);\n          String type \u003d kp.getNextString();\n          String id \u003d kp.getNextString();\n          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n          if (relatedEntityStartTime \u003d\u003d null) {\n            LOG.warn(\"Found no start time for reverse \" +\n                \"related entity \" + id + \" of type \" + type + \" while \" +\n                \"deleting \" + entityId + \" of type \" + entityType);\n            continue;\n          }\n          writeBatch.delete(createRelatedEntityKey(id, type,\n              relatedEntityStartTime, entityId, entityType));\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" from related entity entry of type:\" +\n                type + \" id:\" + id);\n          }\n        }\n      }\n      WriteOptions writeOptions \u003d new WriteOptions();\n      writeOptions.sync(true);\n      db.write(writeBatch, writeOptions);\n      return true;\n    } finally {\n      IOUtils.cleanup(LOG, writeBatch);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/LeveldbTimelineStore.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java"
      }
    },
    "b3ea4aebff42131642af0393748dc751cb3fc31e": {
      "type": "Yintroduced",
      "commitMessage": "YARN-1717. Enabled periodically discarding old data in LeveldbTimelineStore. Contributed by Billie Rinaldi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1577693 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/03/14 1:35 PM",
      "commitName": "b3ea4aebff42131642af0393748dc751cb3fc31e",
      "commitAuthor": "Zhijie Shen",
      "diff": "@@ -0,0 +1,111 @@\n+  boolean deleteNextEntity(String entityType, byte[] reverseTimestamp,\n+      DBIterator iterator, DBIterator pfIterator, boolean seeked)\n+      throws IOException {\n+    WriteBatch writeBatch \u003d null;\n+    try {\n+      KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n+          .add(entityType);\n+      byte[] typePrefix \u003d kb.getBytesForLookup();\n+      kb.add(reverseTimestamp);\n+      if (!seeked) {\n+        iterator.seek(kb.getBytesForLookup());\n+      }\n+      if (!iterator.hasNext()) {\n+        return false;\n+      }\n+      byte[] entityKey \u003d iterator.peekNext().getKey();\n+      if (!prefixMatches(typePrefix, typePrefix.length, entityKey)) {\n+        return false;\n+      }\n+\n+      // read the start time and entity id from the current key\n+      KeyParser kp \u003d new KeyParser(entityKey, typePrefix.length + 8);\n+      String entityId \u003d kp.getNextString();\n+      int prefixlen \u003d kp.getOffset();\n+      byte[] deletePrefix \u003d new byte[prefixlen];\n+      System.arraycopy(entityKey, 0, deletePrefix, 0, prefixlen);\n+\n+      writeBatch \u003d db.createWriteBatch();\n+\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" + entityId);\n+      }\n+      // remove start time from cache and db\n+      writeBatch.delete(createStartTimeLookupKey(entityId, entityType));\n+      EntityIdentifier entityIdentifier \u003d\n+          new EntityIdentifier(entityId, entityType);\n+      startTimeReadCache.remove(entityIdentifier);\n+      startTimeWriteCache.remove(entityIdentifier);\n+\n+      // delete current entity\n+      for (; iterator.hasNext(); iterator.next()) {\n+        byte[] key \u003d iterator.peekNext().getKey();\n+        if (!prefixMatches(entityKey, prefixlen, key)) {\n+          break;\n+        }\n+        writeBatch.delete(key);\n+\n+        if (key.length \u003d\u003d prefixlen) {\n+          continue;\n+        }\n+        if (key[prefixlen] \u003d\u003d PRIMARY_FILTERS_COLUMN[0]) {\n+          kp \u003d new KeyParser(key,\n+              prefixlen + PRIMARY_FILTERS_COLUMN.length);\n+          String name \u003d kp.getNextString();\n+          Object value \u003d GenericObjectMapper.read(key, kp.getOffset());\n+          deleteKeysWithPrefix(writeBatch, addPrimaryFilterToKey(name, value,\n+              deletePrefix), pfIterator);\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n+                entityId + \" primary filter entry \" + name + \" \" +\n+                value);\n+          }\n+        } else if (key[prefixlen] \u003d\u003d RELATED_ENTITIES_COLUMN[0]) {\n+          kp \u003d new KeyParser(key,\n+              prefixlen + RELATED_ENTITIES_COLUMN.length);\n+          String type \u003d kp.getNextString();\n+          String id \u003d kp.getNextString();\n+          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n+          if (relatedEntityStartTime \u003d\u003d null) {\n+            LOG.warn(\"Found no start time for \" +\n+                \"related entity \" + id + \" of type \" + type + \" while \" +\n+                \"deleting \" + entityId + \" of type \" + entityType);\n+            continue;\n+          }\n+          writeBatch.delete(createReverseRelatedEntityKey(id, type,\n+              relatedEntityStartTime, entityId, entityType));\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n+                entityId + \" from invisible reverse related entity \" +\n+                \"entry of type:\" + type + \" id:\" + id);\n+          }\n+        } else if (key[prefixlen] \u003d\u003d\n+            INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN[0]) {\n+          kp \u003d new KeyParser(key, prefixlen +\n+              INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN.length);\n+          String type \u003d kp.getNextString();\n+          String id \u003d kp.getNextString();\n+          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n+          if (relatedEntityStartTime \u003d\u003d null) {\n+            LOG.warn(\"Found no start time for reverse \" +\n+                \"related entity \" + id + \" of type \" + type + \" while \" +\n+                \"deleting \" + entityId + \" of type \" + entityType);\n+            continue;\n+          }\n+          writeBatch.delete(createRelatedEntityKey(id, type,\n+              relatedEntityStartTime, entityId, entityType));\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n+                entityId + \" from related entity entry of type:\" +\n+                type + \" id:\" + id);\n+          }\n+        }\n+      }\n+      WriteOptions writeOptions \u003d new WriteOptions();\n+      writeOptions.sync(true);\n+      db.write(writeBatch, writeOptions);\n+      return true;\n+    } finally {\n+      IOUtils.cleanup(LOG, writeBatch);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  boolean deleteNextEntity(String entityType, byte[] reverseTimestamp,\n      DBIterator iterator, DBIterator pfIterator, boolean seeked)\n      throws IOException {\n    WriteBatch writeBatch \u003d null;\n    try {\n      KeyBuilder kb \u003d KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)\n          .add(entityType);\n      byte[] typePrefix \u003d kb.getBytesForLookup();\n      kb.add(reverseTimestamp);\n      if (!seeked) {\n        iterator.seek(kb.getBytesForLookup());\n      }\n      if (!iterator.hasNext()) {\n        return false;\n      }\n      byte[] entityKey \u003d iterator.peekNext().getKey();\n      if (!prefixMatches(typePrefix, typePrefix.length, entityKey)) {\n        return false;\n      }\n\n      // read the start time and entity id from the current key\n      KeyParser kp \u003d new KeyParser(entityKey, typePrefix.length + 8);\n      String entityId \u003d kp.getNextString();\n      int prefixlen \u003d kp.getOffset();\n      byte[] deletePrefix \u003d new byte[prefixlen];\n      System.arraycopy(entityKey, 0, deletePrefix, 0, prefixlen);\n\n      writeBatch \u003d db.createWriteBatch();\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" + entityId);\n      }\n      // remove start time from cache and db\n      writeBatch.delete(createStartTimeLookupKey(entityId, entityType));\n      EntityIdentifier entityIdentifier \u003d\n          new EntityIdentifier(entityId, entityType);\n      startTimeReadCache.remove(entityIdentifier);\n      startTimeWriteCache.remove(entityIdentifier);\n\n      // delete current entity\n      for (; iterator.hasNext(); iterator.next()) {\n        byte[] key \u003d iterator.peekNext().getKey();\n        if (!prefixMatches(entityKey, prefixlen, key)) {\n          break;\n        }\n        writeBatch.delete(key);\n\n        if (key.length \u003d\u003d prefixlen) {\n          continue;\n        }\n        if (key[prefixlen] \u003d\u003d PRIMARY_FILTERS_COLUMN[0]) {\n          kp \u003d new KeyParser(key,\n              prefixlen + PRIMARY_FILTERS_COLUMN.length);\n          String name \u003d kp.getNextString();\n          Object value \u003d GenericObjectMapper.read(key, kp.getOffset());\n          deleteKeysWithPrefix(writeBatch, addPrimaryFilterToKey(name, value,\n              deletePrefix), pfIterator);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" primary filter entry \" + name + \" \" +\n                value);\n          }\n        } else if (key[prefixlen] \u003d\u003d RELATED_ENTITIES_COLUMN[0]) {\n          kp \u003d new KeyParser(key,\n              prefixlen + RELATED_ENTITIES_COLUMN.length);\n          String type \u003d kp.getNextString();\n          String id \u003d kp.getNextString();\n          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n          if (relatedEntityStartTime \u003d\u003d null) {\n            LOG.warn(\"Found no start time for \" +\n                \"related entity \" + id + \" of type \" + type + \" while \" +\n                \"deleting \" + entityId + \" of type \" + entityType);\n            continue;\n          }\n          writeBatch.delete(createReverseRelatedEntityKey(id, type,\n              relatedEntityStartTime, entityId, entityType));\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" from invisible reverse related entity \" +\n                \"entry of type:\" + type + \" id:\" + id);\n          }\n        } else if (key[prefixlen] \u003d\u003d\n            INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN[0]) {\n          kp \u003d new KeyParser(key, prefixlen +\n              INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN.length);\n          String type \u003d kp.getNextString();\n          String id \u003d kp.getNextString();\n          byte[] relatedEntityStartTime \u003d getStartTime(id, type);\n          if (relatedEntityStartTime \u003d\u003d null) {\n            LOG.warn(\"Found no start time for reverse \" +\n                \"related entity \" + id + \" of type \" + type + \" while \" +\n                \"deleting \" + entityId + \" of type \" + entityType);\n            continue;\n          }\n          writeBatch.delete(createRelatedEntityKey(id, type,\n              relatedEntityStartTime, entityId, entityType));\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Deleting entity type:\" + entityType + \" id:\" +\n                entityId + \" from related entity entry of type:\" +\n                type + \" id:\" + id);\n          }\n        }\n      }\n      WriteOptions writeOptions \u003d new WriteOptions();\n      writeOptions.sync(true);\n      db.write(writeBatch, writeOptions);\n      return true;\n    } finally {\n      IOUtils.cleanup(LOG, writeBatch);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/timeline/LeveldbTimelineStore.java"
    }
  }
}