{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "StripedReader.java",
  "functionName": "doReadMinimumSources",
  "functionId": "doReadMinimumSources___reconstructLength-int__corruptedBlocks-CorruptedBlocks",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedReader.java",
  "functionStartLine": 276,
  "functionEndLine": 351,
  "numCommitsSeen": 6,
  "timeTaken": 1470,
  "changeHistory": [
    "08bb6c49a5aec32b7d9f29238560f947420405d6",
    "3c18a53cbd2efabb2ad108d63a0b0b558424115f"
  ],
  "changeHistoryShort": {
    "08bb6c49a5aec32b7d9f29238560f947420405d6": "Ybodychange",
    "3c18a53cbd2efabb2ad108d63a0b0b558424115f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "08bb6c49a5aec32b7d9f29238560f947420405d6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13926. ThreadLocal aggregations for FileSystem.Statistics are incorrect with striped reads.\nContributed by Xiao Chen, Hrishikesh Gadre.\n\nSigned-off-by: Xiao Chen \u003cxiao@apache.org\u003e\n",
      "commitDate": "08/10/18 8:31 PM",
      "commitName": "08bb6c49a5aec32b7d9f29238560f947420405d6",
      "commitAuthor": "Hrishikesh Gadre",
      "commitDateOld": "28/07/17 10:50 AM",
      "commitNameOld": "77791e4c36ddc9305306c83806bf486d4d32575d",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 437.4,
      "commitsBetweenForRepo": 3926,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,76 @@\n   int[] doReadMinimumSources(int reconstructLength,\n                              CorruptedBlocks corruptedBlocks)\n       throws IOException {\n     Preconditions.checkArgument(reconstructLength \u003e\u003d 0 \u0026\u0026\n         reconstructLength \u003c\u003d bufferSize);\n     int nSuccess \u003d 0;\n     int[] newSuccess \u003d new int[minRequiredSources];\n     BitSet usedFlag \u003d new BitSet(sources.length);\n     /*\n      * Read from minimum source DNs required, the success list contains\n      * source DNs which we think best.\n      */\n     for (int i \u003d 0; i \u003c minRequiredSources; i++) {\n       StripedBlockReader reader \u003d readers.get(successList[i]);\n       int toRead \u003d getReadLength(liveIndices[successList[i]],\n           reconstructLength);\n       if (toRead \u003e 0) {\n-        Callable\u003cVoid\u003e readCallable \u003d\n+        Callable\u003cBlockReadStats\u003e readCallable \u003d\n             reader.readFromBlock(toRead, corruptedBlocks);\n-        Future\u003cVoid\u003e f \u003d readService.submit(readCallable);\n+        Future\u003cBlockReadStats\u003e f \u003d readService.submit(readCallable);\n         futures.put(f, successList[i]);\n       } else {\n         // If the read length is 0, we don\u0027t need to do real read\n         reader.getReadBuffer().position(0);\n         newSuccess[nSuccess++] \u003d successList[i];\n       }\n       usedFlag.set(successList[i]);\n     }\n \n     while (!futures.isEmpty()) {\n       try {\n         StripingChunkReadResult result \u003d\n             StripedBlockUtil.getNextCompletedStripedRead(\n                 readService, futures, stripedReadTimeoutInMills);\n         int resultIndex \u003d -1;\n         if (result.state \u003d\u003d StripingChunkReadResult.SUCCESSFUL) {\n           resultIndex \u003d result.index;\n         } else if (result.state \u003d\u003d StripingChunkReadResult.FAILED) {\n           // If read failed for some source DN, we should not use it anymore\n           // and schedule read from another source DN.\n           StripedBlockReader failedReader \u003d readers.get(result.index);\n           failedReader.closeBlockReader();\n           resultIndex \u003d scheduleNewRead(usedFlag,\n               reconstructLength, corruptedBlocks);\n         } else if (result.state \u003d\u003d StripingChunkReadResult.TIMEOUT) {\n           // If timeout, we also schedule a new read.\n           resultIndex \u003d scheduleNewRead(usedFlag,\n               reconstructLength, corruptedBlocks);\n         }\n         if (resultIndex \u003e\u003d 0) {\n           newSuccess[nSuccess++] \u003d resultIndex;\n           if (nSuccess \u003e\u003d minRequiredSources) {\n             // cancel remaining reads if we read successfully from minimum\n             // number of source DNs required by reconstruction.\n             cancelReads(futures.keySet());\n             futures.clear();\n             break;\n           }\n         }\n       } catch (InterruptedException e) {\n         LOG.info(\"Read data interrupted.\", e);\n         cancelReads(futures.keySet());\n         futures.clear();\n         break;\n       }\n     }\n \n     if (nSuccess \u003c minRequiredSources) {\n       String error \u003d \"Can\u0027t read data from minimum number of sources \"\n           + \"required by reconstruction, block id: \" +\n           reconstructor.getBlockGroup().getBlockId();\n       throw new IOException(error);\n     }\n \n     return newSuccess;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  int[] doReadMinimumSources(int reconstructLength,\n                             CorruptedBlocks corruptedBlocks)\n      throws IOException {\n    Preconditions.checkArgument(reconstructLength \u003e\u003d 0 \u0026\u0026\n        reconstructLength \u003c\u003d bufferSize);\n    int nSuccess \u003d 0;\n    int[] newSuccess \u003d new int[minRequiredSources];\n    BitSet usedFlag \u003d new BitSet(sources.length);\n    /*\n     * Read from minimum source DNs required, the success list contains\n     * source DNs which we think best.\n     */\n    for (int i \u003d 0; i \u003c minRequiredSources; i++) {\n      StripedBlockReader reader \u003d readers.get(successList[i]);\n      int toRead \u003d getReadLength(liveIndices[successList[i]],\n          reconstructLength);\n      if (toRead \u003e 0) {\n        Callable\u003cBlockReadStats\u003e readCallable \u003d\n            reader.readFromBlock(toRead, corruptedBlocks);\n        Future\u003cBlockReadStats\u003e f \u003d readService.submit(readCallable);\n        futures.put(f, successList[i]);\n      } else {\n        // If the read length is 0, we don\u0027t need to do real read\n        reader.getReadBuffer().position(0);\n        newSuccess[nSuccess++] \u003d successList[i];\n      }\n      usedFlag.set(successList[i]);\n    }\n\n    while (!futures.isEmpty()) {\n      try {\n        StripingChunkReadResult result \u003d\n            StripedBlockUtil.getNextCompletedStripedRead(\n                readService, futures, stripedReadTimeoutInMills);\n        int resultIndex \u003d -1;\n        if (result.state \u003d\u003d StripingChunkReadResult.SUCCESSFUL) {\n          resultIndex \u003d result.index;\n        } else if (result.state \u003d\u003d StripingChunkReadResult.FAILED) {\n          // If read failed for some source DN, we should not use it anymore\n          // and schedule read from another source DN.\n          StripedBlockReader failedReader \u003d readers.get(result.index);\n          failedReader.closeBlockReader();\n          resultIndex \u003d scheduleNewRead(usedFlag,\n              reconstructLength, corruptedBlocks);\n        } else if (result.state \u003d\u003d StripingChunkReadResult.TIMEOUT) {\n          // If timeout, we also schedule a new read.\n          resultIndex \u003d scheduleNewRead(usedFlag,\n              reconstructLength, corruptedBlocks);\n        }\n        if (resultIndex \u003e\u003d 0) {\n          newSuccess[nSuccess++] \u003d resultIndex;\n          if (nSuccess \u003e\u003d minRequiredSources) {\n            // cancel remaining reads if we read successfully from minimum\n            // number of source DNs required by reconstruction.\n            cancelReads(futures.keySet());\n            futures.clear();\n            break;\n          }\n        }\n      } catch (InterruptedException e) {\n        LOG.info(\"Read data interrupted.\", e);\n        cancelReads(futures.keySet());\n        futures.clear();\n        break;\n      }\n    }\n\n    if (nSuccess \u003c minRequiredSources) {\n      String error \u003d \"Can\u0027t read data from minimum number of sources \"\n          + \"required by reconstruction, block id: \" +\n          reconstructor.getBlockGroup().getBlockId();\n      throw new IOException(error);\n    }\n\n    return newSuccess;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedReader.java",
      "extendedDetails": {}
    },
    "3c18a53cbd2efabb2ad108d63a0b0b558424115f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9719. Refactoring ErasureCodingWorker into smaller reusable constructs. Contributed by Kai Zheng.\n",
      "commitDate": "06/04/16 10:50 PM",
      "commitName": "3c18a53cbd2efabb2ad108d63a0b0b558424115f",
      "commitAuthor": "Uma Maheswara Rao G",
      "diff": "@@ -0,0 +1,76 @@\n+  int[] doReadMinimumSources(int reconstructLength,\n+                             CorruptedBlocks corruptedBlocks)\n+      throws IOException {\n+    Preconditions.checkArgument(reconstructLength \u003e\u003d 0 \u0026\u0026\n+        reconstructLength \u003c\u003d bufferSize);\n+    int nSuccess \u003d 0;\n+    int[] newSuccess \u003d new int[minRequiredSources];\n+    BitSet usedFlag \u003d new BitSet(sources.length);\n+    /*\n+     * Read from minimum source DNs required, the success list contains\n+     * source DNs which we think best.\n+     */\n+    for (int i \u003d 0; i \u003c minRequiredSources; i++) {\n+      StripedBlockReader reader \u003d readers.get(successList[i]);\n+      int toRead \u003d getReadLength(liveIndices[successList[i]],\n+          reconstructLength);\n+      if (toRead \u003e 0) {\n+        Callable\u003cVoid\u003e readCallable \u003d\n+            reader.readFromBlock(toRead, corruptedBlocks);\n+        Future\u003cVoid\u003e f \u003d readService.submit(readCallable);\n+        futures.put(f, successList[i]);\n+      } else {\n+        // If the read length is 0, we don\u0027t need to do real read\n+        reader.getReadBuffer().position(0);\n+        newSuccess[nSuccess++] \u003d successList[i];\n+      }\n+      usedFlag.set(successList[i]);\n+    }\n+\n+    while (!futures.isEmpty()) {\n+      try {\n+        StripingChunkReadResult result \u003d\n+            StripedBlockUtil.getNextCompletedStripedRead(\n+                readService, futures, stripedReadTimeoutInMills);\n+        int resultIndex \u003d -1;\n+        if (result.state \u003d\u003d StripingChunkReadResult.SUCCESSFUL) {\n+          resultIndex \u003d result.index;\n+        } else if (result.state \u003d\u003d StripingChunkReadResult.FAILED) {\n+          // If read failed for some source DN, we should not use it anymore\n+          // and schedule read from another source DN.\n+          StripedBlockReader failedReader \u003d readers.get(result.index);\n+          failedReader.closeBlockReader();\n+          resultIndex \u003d scheduleNewRead(usedFlag,\n+              reconstructLength, corruptedBlocks);\n+        } else if (result.state \u003d\u003d StripingChunkReadResult.TIMEOUT) {\n+          // If timeout, we also schedule a new read.\n+          resultIndex \u003d scheduleNewRead(usedFlag,\n+              reconstructLength, corruptedBlocks);\n+        }\n+        if (resultIndex \u003e\u003d 0) {\n+          newSuccess[nSuccess++] \u003d resultIndex;\n+          if (nSuccess \u003e\u003d minRequiredSources) {\n+            // cancel remaining reads if we read successfully from minimum\n+            // number of source DNs required by reconstruction.\n+            cancelReads(futures.keySet());\n+            futures.clear();\n+            break;\n+          }\n+        }\n+      } catch (InterruptedException e) {\n+        LOG.info(\"Read data interrupted.\", e);\n+        cancelReads(futures.keySet());\n+        futures.clear();\n+        break;\n+      }\n+    }\n+\n+    if (nSuccess \u003c minRequiredSources) {\n+      String error \u003d \"Can\u0027t read data from minimum number of sources \"\n+          + \"required by reconstruction, block id: \" +\n+          reconstructor.getBlockGroup().getBlockId();\n+      throw new IOException(error);\n+    }\n+\n+    return newSuccess;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  int[] doReadMinimumSources(int reconstructLength,\n                             CorruptedBlocks corruptedBlocks)\n      throws IOException {\n    Preconditions.checkArgument(reconstructLength \u003e\u003d 0 \u0026\u0026\n        reconstructLength \u003c\u003d bufferSize);\n    int nSuccess \u003d 0;\n    int[] newSuccess \u003d new int[minRequiredSources];\n    BitSet usedFlag \u003d new BitSet(sources.length);\n    /*\n     * Read from minimum source DNs required, the success list contains\n     * source DNs which we think best.\n     */\n    for (int i \u003d 0; i \u003c minRequiredSources; i++) {\n      StripedBlockReader reader \u003d readers.get(successList[i]);\n      int toRead \u003d getReadLength(liveIndices[successList[i]],\n          reconstructLength);\n      if (toRead \u003e 0) {\n        Callable\u003cVoid\u003e readCallable \u003d\n            reader.readFromBlock(toRead, corruptedBlocks);\n        Future\u003cVoid\u003e f \u003d readService.submit(readCallable);\n        futures.put(f, successList[i]);\n      } else {\n        // If the read length is 0, we don\u0027t need to do real read\n        reader.getReadBuffer().position(0);\n        newSuccess[nSuccess++] \u003d successList[i];\n      }\n      usedFlag.set(successList[i]);\n    }\n\n    while (!futures.isEmpty()) {\n      try {\n        StripingChunkReadResult result \u003d\n            StripedBlockUtil.getNextCompletedStripedRead(\n                readService, futures, stripedReadTimeoutInMills);\n        int resultIndex \u003d -1;\n        if (result.state \u003d\u003d StripingChunkReadResult.SUCCESSFUL) {\n          resultIndex \u003d result.index;\n        } else if (result.state \u003d\u003d StripingChunkReadResult.FAILED) {\n          // If read failed for some source DN, we should not use it anymore\n          // and schedule read from another source DN.\n          StripedBlockReader failedReader \u003d readers.get(result.index);\n          failedReader.closeBlockReader();\n          resultIndex \u003d scheduleNewRead(usedFlag,\n              reconstructLength, corruptedBlocks);\n        } else if (result.state \u003d\u003d StripingChunkReadResult.TIMEOUT) {\n          // If timeout, we also schedule a new read.\n          resultIndex \u003d scheduleNewRead(usedFlag,\n              reconstructLength, corruptedBlocks);\n        }\n        if (resultIndex \u003e\u003d 0) {\n          newSuccess[nSuccess++] \u003d resultIndex;\n          if (nSuccess \u003e\u003d minRequiredSources) {\n            // cancel remaining reads if we read successfully from minimum\n            // number of source DNs required by reconstruction.\n            cancelReads(futures.keySet());\n            futures.clear();\n            break;\n          }\n        }\n      } catch (InterruptedException e) {\n        LOG.info(\"Read data interrupted.\", e);\n        cancelReads(futures.keySet());\n        futures.clear();\n        break;\n      }\n    }\n\n    if (nSuccess \u003c minRequiredSources) {\n      String error \u003d \"Can\u0027t read data from minimum number of sources \"\n          + \"required by reconstruction, block id: \" +\n          reconstructor.getBlockGroup().getBlockId();\n      throw new IOException(error);\n    }\n\n    return newSuccess;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedReader.java"
    }
  }
}