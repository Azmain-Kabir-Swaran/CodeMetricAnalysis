{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BPServiceActor.java",
  "functionName": "triggerHeartbeatForTests",
  "functionId": "triggerHeartbeatForTests",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java",
  "functionStartLine": 326,
  "functionEndLine": 338,
  "numCommitsSeen": 125,
  "timeTaken": 3379,
  "changeHistory": [
    "4e5e1c0f9938e51699c0437731e7b2eef699d6da",
    "dfc1c4c303cf15afc6c3361ed9d3238562f73cbd",
    "01f37e42f050207b7659bf74e2484cf8bdae2d89",
    "6c0ccb5989c2053f5a1ebab0dd9fdb7b4019fda8",
    "7527e943e6c8ea909f22d9d66246ac6c8bc2d6a0",
    "31c91706f7d17da006ef2d6c541f8dd092fae077",
    "6016e95feec93f0e17a8a1370c0ede735ca13f55"
  ],
  "changeHistoryShort": {
    "4e5e1c0f9938e51699c0437731e7b2eef699d6da": "Ybodychange",
    "dfc1c4c303cf15afc6c3361ed9d3238562f73cbd": "Ybodychange",
    "01f37e42f050207b7659bf74e2484cf8bdae2d89": "Ybodychange",
    "6c0ccb5989c2053f5a1ebab0dd9fdb7b4019fda8": "Yexceptionschange",
    "7527e943e6c8ea909f22d9d66246ac6c8bc2d6a0": "Ybodychange",
    "31c91706f7d17da006ef2d6c541f8dd092fae077": "Ybodychange",
    "6016e95feec93f0e17a8a1370c0ede735ca13f55": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4e5e1c0f9938e51699c0437731e7b2eef699d6da": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9726. Refactor IBR code to a new class.\n",
      "commitDate": "05/02/16 7:17 AM",
      "commitName": "4e5e1c0f9938e51699c0437731e7b2eef699d6da",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "02/02/16 11:23 AM",
      "commitNameOld": "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 2.83,
      "commitsBetweenForRepo": 25,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   void triggerHeartbeatForTests() {\n-    synchronized (pendingIncrementalBRperStorage) {\n+    synchronized (ibrManager) {\n       final long nextHeartbeatTime \u003d scheduler.scheduleHeartbeat();\n-      pendingIncrementalBRperStorage.notifyAll();\n+      ibrManager.notifyAll();\n       while (nextHeartbeatTime - scheduler.nextHeartbeatTime \u003e\u003d 0) {\n         try {\n-          pendingIncrementalBRperStorage.wait(100);\n+          ibrManager.wait(100);\n         } catch (InterruptedException e) {\n           return;\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void triggerHeartbeatForTests() {\n    synchronized (ibrManager) {\n      final long nextHeartbeatTime \u003d scheduler.scheduleHeartbeat();\n      ibrManager.notifyAll();\n      while (nextHeartbeatTime - scheduler.nextHeartbeatTime \u003e\u003d 0) {\n        try {\n          ibrManager.wait(100);\n        } catch (InterruptedException e) {\n          return;\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java",
      "extendedDetails": {}
    },
    "dfc1c4c303cf15afc6c3361ed9d3238562f73cbd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8163. Using monotonicNow for block report scheduling causes test failures on recently restarted systems. (Arpit Agarwal)\n",
      "commitDate": "21/04/15 10:58 AM",
      "commitName": "dfc1c4c303cf15afc6c3361ed9d3238562f73cbd",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "08/04/15 9:43 PM",
      "commitNameOld": "b1e059089d6a5b2b7006d7d384c6df81ed268bd9",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 12.55,
      "commitsBetweenForRepo": 85,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   void triggerHeartbeatForTests() {\n     synchronized (pendingIncrementalBRperStorage) {\n-      lastHeartbeat \u003d 0;\n+      final long nextHeartbeatTime \u003d scheduler.scheduleHeartbeat();\n       pendingIncrementalBRperStorage.notifyAll();\n-      while (lastHeartbeat \u003d\u003d 0) {\n+      while (nextHeartbeatTime - scheduler.nextHeartbeatTime \u003e\u003d 0) {\n         try {\n           pendingIncrementalBRperStorage.wait(100);\n         } catch (InterruptedException e) {\n           return;\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void triggerHeartbeatForTests() {\n    synchronized (pendingIncrementalBRperStorage) {\n      final long nextHeartbeatTime \u003d scheduler.scheduleHeartbeat();\n      pendingIncrementalBRperStorage.notifyAll();\n      while (nextHeartbeatTime - scheduler.nextHeartbeatTime \u003e\u003d 0) {\n        try {\n          pendingIncrementalBRperStorage.wait(100);\n        } catch (InterruptedException e) {\n          return;\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java",
      "extendedDetails": {}
    },
    "01f37e42f050207b7659bf74e2484cf8bdae2d89": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5390. Send one incremental block report per storage directory.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1534891 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/10/13 6:28 PM",
      "commitName": "01f37e42f050207b7659bf74e2484cf8bdae2d89",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "21/10/13 7:22 PM",
      "commitNameOld": "0ebab3a88a5f172a1180f4e88a91cf6194b273ca",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.96,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   void triggerHeartbeatForTests() {\n-    synchronized (pendingIncrementalBR) {\n+    synchronized (pendingIncrementalBRperStorage) {\n       lastHeartbeat \u003d 0;\n-      pendingIncrementalBR.notifyAll();\n+      pendingIncrementalBRperStorage.notifyAll();\n       while (lastHeartbeat \u003d\u003d 0) {\n         try {\n-          pendingIncrementalBR.wait(100);\n+          pendingIncrementalBRperStorage.wait(100);\n         } catch (InterruptedException e) {\n           return;\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void triggerHeartbeatForTests() {\n    synchronized (pendingIncrementalBRperStorage) {\n      lastHeartbeat \u003d 0;\n      pendingIncrementalBRperStorage.notifyAll();\n      while (lastHeartbeat \u003d\u003d 0) {\n        try {\n          pendingIncrementalBRperStorage.wait(100);\n        } catch (InterruptedException e) {\n          return;\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java",
      "extendedDetails": {}
    },
    "6c0ccb5989c2053f5a1ebab0dd9fdb7b4019fda8": {
      "type": "Yexceptionschange",
      "commitMessage": "HDFS-2686. Remove DistributedUpgrade related code. Contributed by Suresh Srinivas\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1375800 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/08/12 2:18 PM",
      "commitName": "6c0ccb5989c2053f5a1ebab0dd9fdb7b4019fda8",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "12/07/12 12:01 PM",
      "commitNameOld": "4a5ba3b7bd2360fd9605863630b477d362874e1e",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 40.1,
      "commitsBetweenForRepo": 216,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n-  void triggerHeartbeatForTests() throws IOException {\n+  void triggerHeartbeatForTests() {\n     synchronized (pendingIncrementalBR) {\n       lastHeartbeat \u003d 0;\n       pendingIncrementalBR.notifyAll();\n       while (lastHeartbeat \u003d\u003d 0) {\n         try {\n           pendingIncrementalBR.wait(100);\n         } catch (InterruptedException e) {\n           return;\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void triggerHeartbeatForTests() {\n    synchronized (pendingIncrementalBR) {\n      lastHeartbeat \u003d 0;\n      pendingIncrementalBR.notifyAll();\n      while (lastHeartbeat \u003d\u003d 0) {\n        try {\n          pendingIncrementalBR.wait(100);\n        } catch (InterruptedException e) {\n          return;\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java",
      "extendedDetails": {
        "oldValue": "[IOException]",
        "newValue": "[]"
      }
    },
    "7527e943e6c8ea909f22d9d66246ac6c8bc2d6a0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2972. Small optimization building incremental block report. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1292497 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/02/12 12:37 PM",
      "commitName": "7527e943e6c8ea909f22d9d66246ac6c8bc2d6a0",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "13/02/12 1:00 PM",
      "commitNameOld": "db187cf40ee307524c48cededd58710a4dfb4812",
      "commitAuthorOld": "",
      "daysBetweenCommits": 8.98,
      "commitsBetweenForRepo": 60,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   void triggerHeartbeatForTests() throws IOException {\n-    synchronized (receivedAndDeletedBlockList) {\n+    synchronized (pendingIncrementalBR) {\n       lastHeartbeat \u003d 0;\n-      receivedAndDeletedBlockList.notifyAll();\n+      pendingIncrementalBR.notifyAll();\n       while (lastHeartbeat \u003d\u003d 0) {\n         try {\n-          receivedAndDeletedBlockList.wait(100);\n+          pendingIncrementalBR.wait(100);\n         } catch (InterruptedException e) {\n           return;\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void triggerHeartbeatForTests() throws IOException {\n    synchronized (pendingIncrementalBR) {\n      lastHeartbeat \u003d 0;\n      pendingIncrementalBR.notifyAll();\n      while (lastHeartbeat \u003d\u003d 0) {\n        try {\n          pendingIncrementalBR.wait(100);\n        } catch (InterruptedException e) {\n          return;\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java",
      "extendedDetails": {}
    },
    "31c91706f7d17da006ef2d6c541f8dd092fae077": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1972. Fencing mechanism for block invalidations and replications. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1221608 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/12/11 8:32 PM",
      "commitName": "31c91706f7d17da006ef2d6c541f8dd092fae077",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "18/12/11 9:34 PM",
      "commitNameOld": "8ff28f4549338d925bceecd15b02c6a8467c251a",
      "commitAuthorOld": "",
      "daysBetweenCommits": 1.96,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,13 @@\n   void triggerHeartbeatForTests() throws IOException {\n     synchronized (receivedAndDeletedBlockList) {\n       lastHeartbeat \u003d 0;\n       receivedAndDeletedBlockList.notifyAll();\n+      while (lastHeartbeat \u003d\u003d 0) {\n+        try {\n+          receivedAndDeletedBlockList.wait(100);\n+        } catch (InterruptedException e) {\n+          return;\n+        }\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void triggerHeartbeatForTests() throws IOException {\n    synchronized (receivedAndDeletedBlockList) {\n      lastHeartbeat \u003d 0;\n      receivedAndDeletedBlockList.notifyAll();\n      while (lastHeartbeat \u003d\u003d 0) {\n        try {\n          receivedAndDeletedBlockList.wait(100);\n        } catch (InterruptedException e) {\n          return;\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java",
      "extendedDetails": {}
    },
    "6016e95feec93f0e17a8a1370c0ede735ca13f55": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2627. Determine DN\u0027s view of which NN is active based on heartbeat responses. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1211735 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/12/11 6:00 PM",
      "commitName": "6016e95feec93f0e17a8a1370c0ede735ca13f55",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,6 @@\n+  void triggerHeartbeatForTests() throws IOException {\n+    synchronized (receivedAndDeletedBlockList) {\n+      lastHeartbeat \u003d 0;\n+      receivedAndDeletedBlockList.notifyAll();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void triggerHeartbeatForTests() throws IOException {\n    synchronized (receivedAndDeletedBlockList) {\n      lastHeartbeat \u003d 0;\n      receivedAndDeletedBlockList.notifyAll();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java"
    }
  }
}