{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AliyunOSSBlockOutputStream.java",
  "functionName": "close",
  "functionId": "close",
  "sourceFilePath": "hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSBlockOutputStream.java",
  "functionStartLine": 92,
  "functionEndLine": 130,
  "numCommitsSeen": 11,
  "timeTaken": 3621,
  "changeHistory": [
    "2d8282bb8248e6984878626c4cdc7148aa2e7202",
    "f87b3b11c46704dcdb63089dd971e2a5ba1deaac",
    "1f425271a73fff1fdbe3fbfdb71e906fd1ac0574",
    "2b635125fb059fc204ed35bc0e264c42dd3a9fe9",
    "0857f116b754d83d3c540cd6f989087af24fef27",
    "6542d17ea460ec222137c4b275b13daf15d3fca3",
    "d33e928fbeb1764a724c8f3c051bb0d8be82bbff",
    "4d84c814fcaf074022593c057d8f8dec4cd461fa",
    "a5d5342228050a778b20e95adf7885bdba39985d"
  ],
  "changeHistoryShort": {
    "2d8282bb8248e6984878626c4cdc7148aa2e7202": "Ybodychange",
    "f87b3b11c46704dcdb63089dd971e2a5ba1deaac": "Ybodychange",
    "1f425271a73fff1fdbe3fbfdb71e906fd1ac0574": "Ybodychange",
    "2b635125fb059fc204ed35bc0e264c42dd3a9fe9": "Ybodychange",
    "0857f116b754d83d3c540cd6f989087af24fef27": "Ybodychange",
    "6542d17ea460ec222137c4b275b13daf15d3fca3": "Ymultichange(Ymovefromfile,Ybodychange)",
    "d33e928fbeb1764a724c8f3c051bb0d8be82bbff": "Ybodychange",
    "4d84c814fcaf074022593c057d8f8dec4cd461fa": "Ybodychange",
    "a5d5342228050a778b20e95adf7885bdba39985d": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2d8282bb8248e6984878626c4cdc7148aa2e7202": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16306. AliyunOSS: Remove temporary files when upload small files to OSS. Contributed by wujinhu.\n",
      "commitDate": "14/05/19 2:05 PM",
      "commitName": "2d8282bb8248e6984878626c4cdc7148aa2e7202",
      "commitAuthor": "Weiwei Yang",
      "commitDateOld": "06/01/19 11:56 PM",
      "commitNameOld": "f87b3b11c46704dcdb63089dd971e2a5ba1deaac",
      "commitAuthorOld": "Weiwei Yang",
      "daysBetweenCommits": 127.55,
      "commitsBetweenForRepo": 918,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,39 @@\n   public synchronized void close() throws IOException {\n     if (closed) {\n       return;\n     }\n \n     blockStream.flush();\n     blockStream.close();\n     if (!blockFiles.values().contains(blockFile)) {\n       blockId++;\n       blockFiles.put(blockId, blockFile);\n     }\n \n     try {\n       if (blockFiles.size() \u003d\u003d 1) {\n         // just upload it directly\n         store.uploadObject(key, blockFile);\n       } else {\n         if (blockWritten \u003e 0) {\n           ListenableFuture\u003cPartETag\u003e partETagFuture \u003d\n               executorService.submit(() -\u003e {\n                 PartETag partETag \u003d store.uploadPart(blockFile, key, uploadId,\n                     blockId);\n                 return partETag;\n               });\n           partETagsFutures.add(partETagFuture);\n         }\n         // wait for the partial uploads to finish\n         final List\u003cPartETag\u003e partETags \u003d waitForAllPartUploads();\n         if (null \u003d\u003d partETags) {\n           throw new IOException(\"Failed to multipart upload to oss, abort it.\");\n         }\n         store.completeMultipartUpload(key, uploadId,\n             new ArrayList\u003c\u003e(partETags));\n       }\n     } finally {\n-      removePartFiles();\n+      removeTemporaryFiles();\n       closed \u003d true;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void close() throws IOException {\n    if (closed) {\n      return;\n    }\n\n    blockStream.flush();\n    blockStream.close();\n    if (!blockFiles.values().contains(blockFile)) {\n      blockId++;\n      blockFiles.put(blockId, blockFile);\n    }\n\n    try {\n      if (blockFiles.size() \u003d\u003d 1) {\n        // just upload it directly\n        store.uploadObject(key, blockFile);\n      } else {\n        if (blockWritten \u003e 0) {\n          ListenableFuture\u003cPartETag\u003e partETagFuture \u003d\n              executorService.submit(() -\u003e {\n                PartETag partETag \u003d store.uploadPart(blockFile, key, uploadId,\n                    blockId);\n                return partETag;\n              });\n          partETagsFutures.add(partETagFuture);\n        }\n        // wait for the partial uploads to finish\n        final List\u003cPartETag\u003e partETags \u003d waitForAllPartUploads();\n        if (null \u003d\u003d partETags) {\n          throw new IOException(\"Failed to multipart upload to oss, abort it.\");\n        }\n        store.completeMultipartUpload(key, uploadId,\n            new ArrayList\u003c\u003e(partETags));\n      }\n    } finally {\n      removeTemporaryFiles();\n      closed \u003d true;\n    }\n  }",
      "path": "hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSBlockOutputStream.java",
      "extendedDetails": {}
    },
    "f87b3b11c46704dcdb63089dd971e2a5ba1deaac": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16030. AliyunOSS: bring fixes back from HADOOP-15671. Contributed by wujinhu.\n",
      "commitDate": "06/01/19 11:56 PM",
      "commitName": "f87b3b11c46704dcdb63089dd971e2a5ba1deaac",
      "commitAuthor": "Weiwei Yang",
      "commitDateOld": "05/01/19 12:35 AM",
      "commitNameOld": "1f425271a73fff1fdbe3fbfdb71e906fd1ac0574",
      "commitAuthorOld": "Sunil G",
      "daysBetweenCommits": 1.97,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,39 @@\n   public synchronized void close() throws IOException {\n     if (closed) {\n       return;\n     }\n \n     blockStream.flush();\n     blockStream.close();\n     if (!blockFiles.values().contains(blockFile)) {\n       blockId++;\n       blockFiles.put(blockId, blockFile);\n     }\n \n     try {\n       if (blockFiles.size() \u003d\u003d 1) {\n         // just upload it directly\n         store.uploadObject(key, blockFile);\n       } else {\n         if (blockWritten \u003e 0) {\n           ListenableFuture\u003cPartETag\u003e partETagFuture \u003d\n               executorService.submit(() -\u003e {\n                 PartETag partETag \u003d store.uploadPart(blockFile, key, uploadId,\n                     blockId);\n                 return partETag;\n               });\n           partETagsFutures.add(partETagFuture);\n         }\n         // wait for the partial uploads to finish\n         final List\u003cPartETag\u003e partETags \u003d waitForAllPartUploads();\n         if (null \u003d\u003d partETags) {\n           throw new IOException(\"Failed to multipart upload to oss, abort it.\");\n         }\n-        store.completeMultipartUpload(key, uploadId, partETags);\n+        store.completeMultipartUpload(key, uploadId,\n+            new ArrayList\u003c\u003e(partETags));\n       }\n     } finally {\n       removePartFiles();\n       closed \u003d true;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void close() throws IOException {\n    if (closed) {\n      return;\n    }\n\n    blockStream.flush();\n    blockStream.close();\n    if (!blockFiles.values().contains(blockFile)) {\n      blockId++;\n      blockFiles.put(blockId, blockFile);\n    }\n\n    try {\n      if (blockFiles.size() \u003d\u003d 1) {\n        // just upload it directly\n        store.uploadObject(key, blockFile);\n      } else {\n        if (blockWritten \u003e 0) {\n          ListenableFuture\u003cPartETag\u003e partETagFuture \u003d\n              executorService.submit(() -\u003e {\n                PartETag partETag \u003d store.uploadPart(blockFile, key, uploadId,\n                    blockId);\n                return partETag;\n              });\n          partETagsFutures.add(partETagFuture);\n        }\n        // wait for the partial uploads to finish\n        final List\u003cPartETag\u003e partETags \u003d waitForAllPartUploads();\n        if (null \u003d\u003d partETags) {\n          throw new IOException(\"Failed to multipart upload to oss, abort it.\");\n        }\n        store.completeMultipartUpload(key, uploadId,\n            new ArrayList\u003c\u003e(partETags));\n      }\n    } finally {\n      removePartFiles();\n      closed \u003d true;\n    }\n  }",
      "path": "hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSBlockOutputStream.java",
      "extendedDetails": {}
    },
    "1f425271a73fff1fdbe3fbfdb71e906fd1ac0574": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HADOOP-15759. AliyunOSS: Update oss-sdk version to 3.0.0. Contributed by Jinhu Wu.\"\n\nThis reverts commit e4fca6aae46a3c04fc56897986a4ab4e5aa98503.\n\nRevert \"HADOOP-15671. AliyunOSS: Support Assume Roles in AliyunOSS. Contributed by Jinhu Wu.\"\n\nThis reverts commit 2b635125fb059fc204ed35bc0e264c42dd3a9fe9.\n",
      "commitDate": "05/01/19 12:35 AM",
      "commitName": "1f425271a73fff1fdbe3fbfdb71e906fd1ac0574",
      "commitAuthor": "Sunil G",
      "commitDateOld": "25/09/18 4:48 AM",
      "commitNameOld": "2b635125fb059fc204ed35bc0e264c42dd3a9fe9",
      "commitAuthorOld": "Sammi Chen",
      "daysBetweenCommits": 101.87,
      "commitsBetweenForRepo": 768,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,38 @@\n   public synchronized void close() throws IOException {\n     if (closed) {\n       return;\n     }\n \n     blockStream.flush();\n     blockStream.close();\n     if (!blockFiles.values().contains(blockFile)) {\n       blockId++;\n       blockFiles.put(blockId, blockFile);\n     }\n \n     try {\n       if (blockFiles.size() \u003d\u003d 1) {\n         // just upload it directly\n         store.uploadObject(key, blockFile);\n       } else {\n         if (blockWritten \u003e 0) {\n           ListenableFuture\u003cPartETag\u003e partETagFuture \u003d\n               executorService.submit(() -\u003e {\n                 PartETag partETag \u003d store.uploadPart(blockFile, key, uploadId,\n                     blockId);\n                 return partETag;\n               });\n           partETagsFutures.add(partETagFuture);\n         }\n         // wait for the partial uploads to finish\n         final List\u003cPartETag\u003e partETags \u003d waitForAllPartUploads();\n         if (null \u003d\u003d partETags) {\n           throw new IOException(\"Failed to multipart upload to oss, abort it.\");\n         }\n-        store.completeMultipartUpload(key, uploadId,\n-            new ArrayList\u003c\u003e(partETags));\n+        store.completeMultipartUpload(key, uploadId, partETags);\n       }\n     } finally {\n       removePartFiles();\n       closed \u003d true;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void close() throws IOException {\n    if (closed) {\n      return;\n    }\n\n    blockStream.flush();\n    blockStream.close();\n    if (!blockFiles.values().contains(blockFile)) {\n      blockId++;\n      blockFiles.put(blockId, blockFile);\n    }\n\n    try {\n      if (blockFiles.size() \u003d\u003d 1) {\n        // just upload it directly\n        store.uploadObject(key, blockFile);\n      } else {\n        if (blockWritten \u003e 0) {\n          ListenableFuture\u003cPartETag\u003e partETagFuture \u003d\n              executorService.submit(() -\u003e {\n                PartETag partETag \u003d store.uploadPart(blockFile, key, uploadId,\n                    blockId);\n                return partETag;\n              });\n          partETagsFutures.add(partETagFuture);\n        }\n        // wait for the partial uploads to finish\n        final List\u003cPartETag\u003e partETags \u003d waitForAllPartUploads();\n        if (null \u003d\u003d partETags) {\n          throw new IOException(\"Failed to multipart upload to oss, abort it.\");\n        }\n        store.completeMultipartUpload(key, uploadId, partETags);\n      }\n    } finally {\n      removePartFiles();\n      closed \u003d true;\n    }\n  }",
      "path": "hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSBlockOutputStream.java",
      "extendedDetails": {}
    },
    "2b635125fb059fc204ed35bc0e264c42dd3a9fe9": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15671. AliyunOSS: Support Assume Roles in AliyunOSS. Contributed by Jinhu Wu.\n",
      "commitDate": "25/09/18 4:48 AM",
      "commitName": "2b635125fb059fc204ed35bc0e264c42dd3a9fe9",
      "commitAuthor": "Sammi Chen",
      "commitDateOld": "29/07/18 7:53 PM",
      "commitNameOld": "0857f116b754d83d3c540cd6f989087af24fef27",
      "commitAuthorOld": "Sammi Chen",
      "daysBetweenCommits": 57.37,
      "commitsBetweenForRepo": 533,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,39 @@\n   public synchronized void close() throws IOException {\n     if (closed) {\n       return;\n     }\n \n     blockStream.flush();\n     blockStream.close();\n     if (!blockFiles.values().contains(blockFile)) {\n       blockId++;\n       blockFiles.put(blockId, blockFile);\n     }\n \n     try {\n       if (blockFiles.size() \u003d\u003d 1) {\n         // just upload it directly\n         store.uploadObject(key, blockFile);\n       } else {\n         if (blockWritten \u003e 0) {\n           ListenableFuture\u003cPartETag\u003e partETagFuture \u003d\n               executorService.submit(() -\u003e {\n                 PartETag partETag \u003d store.uploadPart(blockFile, key, uploadId,\n                     blockId);\n                 return partETag;\n               });\n           partETagsFutures.add(partETagFuture);\n         }\n         // wait for the partial uploads to finish\n         final List\u003cPartETag\u003e partETags \u003d waitForAllPartUploads();\n         if (null \u003d\u003d partETags) {\n           throw new IOException(\"Failed to multipart upload to oss, abort it.\");\n         }\n-        store.completeMultipartUpload(key, uploadId, partETags);\n+        store.completeMultipartUpload(key, uploadId,\n+            new ArrayList\u003c\u003e(partETags));\n       }\n     } finally {\n       removePartFiles();\n       closed \u003d true;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void close() throws IOException {\n    if (closed) {\n      return;\n    }\n\n    blockStream.flush();\n    blockStream.close();\n    if (!blockFiles.values().contains(blockFile)) {\n      blockId++;\n      blockFiles.put(blockId, blockFile);\n    }\n\n    try {\n      if (blockFiles.size() \u003d\u003d 1) {\n        // just upload it directly\n        store.uploadObject(key, blockFile);\n      } else {\n        if (blockWritten \u003e 0) {\n          ListenableFuture\u003cPartETag\u003e partETagFuture \u003d\n              executorService.submit(() -\u003e {\n                PartETag partETag \u003d store.uploadPart(blockFile, key, uploadId,\n                    blockId);\n                return partETag;\n              });\n          partETagsFutures.add(partETagFuture);\n        }\n        // wait for the partial uploads to finish\n        final List\u003cPartETag\u003e partETags \u003d waitForAllPartUploads();\n        if (null \u003d\u003d partETags) {\n          throw new IOException(\"Failed to multipart upload to oss, abort it.\");\n        }\n        store.completeMultipartUpload(key, uploadId,\n            new ArrayList\u003c\u003e(partETags));\n      }\n    } finally {\n      removePartFiles();\n      closed \u003d true;\n    }\n  }",
      "path": "hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSBlockOutputStream.java",
      "extendedDetails": {}
    },
    "0857f116b754d83d3c540cd6f989087af24fef27": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15607. AliyunOSS: fix duplicated partNumber issue in AliyunOSSBlockOutputStream. Contributed by Jinhu Wu.\n",
      "commitDate": "29/07/18 7:53 PM",
      "commitName": "0857f116b754d83d3c540cd6f989087af24fef27",
      "commitAuthor": "Sammi Chen",
      "commitDateOld": "30/03/18 5:23 AM",
      "commitNameOld": "6542d17ea460ec222137c4b275b13daf15d3fca3",
      "commitAuthorOld": "Sammi Chen",
      "daysBetweenCommits": 121.6,
      "commitsBetweenForRepo": 1341,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,38 @@\n   public synchronized void close() throws IOException {\n     if (closed) {\n       return;\n     }\n \n     blockStream.flush();\n     blockStream.close();\n-    if (!blockFiles.contains(blockFile)) {\n-      blockFiles.add(blockFile);\n+    if (!blockFiles.values().contains(blockFile)) {\n+      blockId++;\n+      blockFiles.put(blockId, blockFile);\n     }\n \n     try {\n       if (blockFiles.size() \u003d\u003d 1) {\n         // just upload it directly\n         store.uploadObject(key, blockFile);\n       } else {\n         if (blockWritten \u003e 0) {\n           ListenableFuture\u003cPartETag\u003e partETagFuture \u003d\n               executorService.submit(() -\u003e {\n                 PartETag partETag \u003d store.uploadPart(blockFile, key, uploadId,\n-                    blockId + 1);\n+                    blockId);\n                 return partETag;\n               });\n           partETagsFutures.add(partETagFuture);\n         }\n         // wait for the partial uploads to finish\n         final List\u003cPartETag\u003e partETags \u003d waitForAllPartUploads();\n         if (null \u003d\u003d partETags) {\n           throw new IOException(\"Failed to multipart upload to oss, abort it.\");\n         }\n         store.completeMultipartUpload(key, uploadId, partETags);\n       }\n     } finally {\n-      for (File tFile: blockFiles) {\n-        if (tFile.exists() \u0026\u0026 !tFile.delete()) {\n-          LOG.warn(\"Failed to delete temporary file {}\", tFile);\n-        }\n-      }\n+      removePartFiles();\n       closed \u003d true;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void close() throws IOException {\n    if (closed) {\n      return;\n    }\n\n    blockStream.flush();\n    blockStream.close();\n    if (!blockFiles.values().contains(blockFile)) {\n      blockId++;\n      blockFiles.put(blockId, blockFile);\n    }\n\n    try {\n      if (blockFiles.size() \u003d\u003d 1) {\n        // just upload it directly\n        store.uploadObject(key, blockFile);\n      } else {\n        if (blockWritten \u003e 0) {\n          ListenableFuture\u003cPartETag\u003e partETagFuture \u003d\n              executorService.submit(() -\u003e {\n                PartETag partETag \u003d store.uploadPart(blockFile, key, uploadId,\n                    blockId);\n                return partETag;\n              });\n          partETagsFutures.add(partETagFuture);\n        }\n        // wait for the partial uploads to finish\n        final List\u003cPartETag\u003e partETags \u003d waitForAllPartUploads();\n        if (null \u003d\u003d partETags) {\n          throw new IOException(\"Failed to multipart upload to oss, abort it.\");\n        }\n        store.completeMultipartUpload(key, uploadId, partETags);\n      }\n    } finally {\n      removePartFiles();\n      closed \u003d true;\n    }\n  }",
      "path": "hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSBlockOutputStream.java",
      "extendedDetails": {}
    },
    "6542d17ea460ec222137c4b275b13daf15d3fca3": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HADOOP-14999. AliyunOSS: provide one asynchronous multi-part based uploading mechanism. Contributed by Genmao Yu.\n",
      "commitDate": "30/03/18 5:23 AM",
      "commitName": "6542d17ea460ec222137c4b275b13daf15d3fca3",
      "commitAuthor": "Sammi Chen",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HADOOP-14999. AliyunOSS: provide one asynchronous multi-part based uploading mechanism. Contributed by Genmao Yu.\n",
          "commitDate": "30/03/18 5:23 AM",
          "commitName": "6542d17ea460ec222137c4b275b13daf15d3fca3",
          "commitAuthor": "Sammi Chen",
          "commitDateOld": "29/03/18 5:16 PM",
          "commitNameOld": "2216bde322961c0fe33b5822510880a65d5c45fd",
          "commitAuthorOld": "Konstantin V Shvachko",
          "daysBetweenCommits": 0.5,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,41 @@\n   public synchronized void close() throws IOException {\n     if (closed) {\n       return;\n     }\n-    closed \u003d true;\n-    if (backupStream !\u003d null) {\n-      backupStream.close();\n+\n+    blockStream.flush();\n+    blockStream.close();\n+    if (!blockFiles.contains(blockFile)) {\n+      blockFiles.add(blockFile);\n     }\n-    long dataLen \u003d tmpFile.length();\n+\n     try {\n-      if (dataLen \u003c\u003d partSizeThreshold) {\n-        store.uploadObject(key, tmpFile);\n+      if (blockFiles.size() \u003d\u003d 1) {\n+        // just upload it directly\n+        store.uploadObject(key, blockFile);\n       } else {\n-        store.multipartUploadObject(key, tmpFile);\n+        if (blockWritten \u003e 0) {\n+          ListenableFuture\u003cPartETag\u003e partETagFuture \u003d\n+              executorService.submit(() -\u003e {\n+                PartETag partETag \u003d store.uploadPart(blockFile, key, uploadId,\n+                    blockId + 1);\n+                return partETag;\n+              });\n+          partETagsFutures.add(partETagFuture);\n+        }\n+        // wait for the partial uploads to finish\n+        final List\u003cPartETag\u003e partETags \u003d waitForAllPartUploads();\n+        if (null \u003d\u003d partETags) {\n+          throw new IOException(\"Failed to multipart upload to oss, abort it.\");\n+        }\n+        store.completeMultipartUpload(key, uploadId, partETags);\n       }\n     } finally {\n-      if (!tmpFile.delete()) {\n-        LOG.warn(\"Can not delete file: \" + tmpFile);\n+      for (File tFile: blockFiles) {\n+        if (tFile.exists() \u0026\u0026 !tFile.delete()) {\n+          LOG.warn(\"Failed to delete temporary file {}\", tFile);\n+        }\n       }\n+      closed \u003d true;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void close() throws IOException {\n    if (closed) {\n      return;\n    }\n\n    blockStream.flush();\n    blockStream.close();\n    if (!blockFiles.contains(blockFile)) {\n      blockFiles.add(blockFile);\n    }\n\n    try {\n      if (blockFiles.size() \u003d\u003d 1) {\n        // just upload it directly\n        store.uploadObject(key, blockFile);\n      } else {\n        if (blockWritten \u003e 0) {\n          ListenableFuture\u003cPartETag\u003e partETagFuture \u003d\n              executorService.submit(() -\u003e {\n                PartETag partETag \u003d store.uploadPart(blockFile, key, uploadId,\n                    blockId + 1);\n                return partETag;\n              });\n          partETagsFutures.add(partETagFuture);\n        }\n        // wait for the partial uploads to finish\n        final List\u003cPartETag\u003e partETags \u003d waitForAllPartUploads();\n        if (null \u003d\u003d partETags) {\n          throw new IOException(\"Failed to multipart upload to oss, abort it.\");\n        }\n        store.completeMultipartUpload(key, uploadId, partETags);\n      }\n    } finally {\n      for (File tFile: blockFiles) {\n        if (tFile.exists() \u0026\u0026 !tFile.delete()) {\n          LOG.warn(\"Failed to delete temporary file {}\", tFile);\n        }\n      }\n      closed \u003d true;\n    }\n  }",
          "path": "hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSBlockOutputStream.java",
          "extendedDetails": {
            "oldPath": "hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSOutputStream.java",
            "newPath": "hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSBlockOutputStream.java",
            "oldMethodName": "close",
            "newMethodName": "close"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-14999. AliyunOSS: provide one asynchronous multi-part based uploading mechanism. Contributed by Genmao Yu.\n",
          "commitDate": "30/03/18 5:23 AM",
          "commitName": "6542d17ea460ec222137c4b275b13daf15d3fca3",
          "commitAuthor": "Sammi Chen",
          "commitDateOld": "29/03/18 5:16 PM",
          "commitNameOld": "2216bde322961c0fe33b5822510880a65d5c45fd",
          "commitAuthorOld": "Konstantin V Shvachko",
          "daysBetweenCommits": 0.5,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,41 @@\n   public synchronized void close() throws IOException {\n     if (closed) {\n       return;\n     }\n-    closed \u003d true;\n-    if (backupStream !\u003d null) {\n-      backupStream.close();\n+\n+    blockStream.flush();\n+    blockStream.close();\n+    if (!blockFiles.contains(blockFile)) {\n+      blockFiles.add(blockFile);\n     }\n-    long dataLen \u003d tmpFile.length();\n+\n     try {\n-      if (dataLen \u003c\u003d partSizeThreshold) {\n-        store.uploadObject(key, tmpFile);\n+      if (blockFiles.size() \u003d\u003d 1) {\n+        // just upload it directly\n+        store.uploadObject(key, blockFile);\n       } else {\n-        store.multipartUploadObject(key, tmpFile);\n+        if (blockWritten \u003e 0) {\n+          ListenableFuture\u003cPartETag\u003e partETagFuture \u003d\n+              executorService.submit(() -\u003e {\n+                PartETag partETag \u003d store.uploadPart(blockFile, key, uploadId,\n+                    blockId + 1);\n+                return partETag;\n+              });\n+          partETagsFutures.add(partETagFuture);\n+        }\n+        // wait for the partial uploads to finish\n+        final List\u003cPartETag\u003e partETags \u003d waitForAllPartUploads();\n+        if (null \u003d\u003d partETags) {\n+          throw new IOException(\"Failed to multipart upload to oss, abort it.\");\n+        }\n+        store.completeMultipartUpload(key, uploadId, partETags);\n       }\n     } finally {\n-      if (!tmpFile.delete()) {\n-        LOG.warn(\"Can not delete file: \" + tmpFile);\n+      for (File tFile: blockFiles) {\n+        if (tFile.exists() \u0026\u0026 !tFile.delete()) {\n+          LOG.warn(\"Failed to delete temporary file {}\", tFile);\n+        }\n       }\n+      closed \u003d true;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void close() throws IOException {\n    if (closed) {\n      return;\n    }\n\n    blockStream.flush();\n    blockStream.close();\n    if (!blockFiles.contains(blockFile)) {\n      blockFiles.add(blockFile);\n    }\n\n    try {\n      if (blockFiles.size() \u003d\u003d 1) {\n        // just upload it directly\n        store.uploadObject(key, blockFile);\n      } else {\n        if (blockWritten \u003e 0) {\n          ListenableFuture\u003cPartETag\u003e partETagFuture \u003d\n              executorService.submit(() -\u003e {\n                PartETag partETag \u003d store.uploadPart(blockFile, key, uploadId,\n                    blockId + 1);\n                return partETag;\n              });\n          partETagsFutures.add(partETagFuture);\n        }\n        // wait for the partial uploads to finish\n        final List\u003cPartETag\u003e partETags \u003d waitForAllPartUploads();\n        if (null \u003d\u003d partETags) {\n          throw new IOException(\"Failed to multipart upload to oss, abort it.\");\n        }\n        store.completeMultipartUpload(key, uploadId, partETags);\n      }\n    } finally {\n      for (File tFile: blockFiles) {\n        if (tFile.exists() \u0026\u0026 !tFile.delete()) {\n          LOG.warn(\"Failed to delete temporary file {}\", tFile);\n        }\n      }\n      closed \u003d true;\n    }\n  }",
          "path": "hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSBlockOutputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "d33e928fbeb1764a724c8f3c051bb0d8be82bbff": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13529. Do some code refactoring. Contributed by Genmao Yu.\n",
      "commitDate": "06/09/16 8:15 PM",
      "commitName": "d33e928fbeb1764a724c8f3c051bb0d8be82bbff",
      "commitAuthor": "Mingfei",
      "commitDateOld": "06/09/16 8:15 PM",
      "commitNameOld": "cdb77110e77b70ed0c1125b2a6a422a8c7c28ec7",
      "commitAuthorOld": "Mingfei",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   public synchronized void close() throws IOException {\n     if (closed) {\n       return;\n     }\n     closed \u003d true;\n     if (backupStream !\u003d null) {\n       backupStream.close();\n     }\n     long dataLen \u003d tmpFile.length();\n     try {\n       if (dataLen \u003c\u003d partSizeThreshold) {\n-        uploadObject();\n+        store.uploadObject(key, tmpFile);\n       } else {\n-        multipartUploadObject();\n+        store.multipartUploadObject(key, tmpFile);\n       }\n     } finally {\n       if (!tmpFile.delete()) {\n         LOG.warn(\"Can not delete file: \" + tmpFile);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void close() throws IOException {\n    if (closed) {\n      return;\n    }\n    closed \u003d true;\n    if (backupStream !\u003d null) {\n      backupStream.close();\n    }\n    long dataLen \u003d tmpFile.length();\n    try {\n      if (dataLen \u003c\u003d partSizeThreshold) {\n        store.uploadObject(key, tmpFile);\n      } else {\n        store.multipartUploadObject(key, tmpFile);\n      }\n    } finally {\n      if (!tmpFile.delete()) {\n        LOG.warn(\"Can not delete file: \" + tmpFile);\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSOutputStream.java",
      "extendedDetails": {}
    },
    "4d84c814fcaf074022593c057d8f8dec4cd461fa": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13491. Fix several warnings from findbugs. Contributed by Genmao Yu.\n",
      "commitDate": "06/09/16 8:15 PM",
      "commitName": "4d84c814fcaf074022593c057d8f8dec4cd461fa",
      "commitAuthor": "Mingfei",
      "commitDateOld": "06/09/16 8:15 PM",
      "commitNameOld": "a5d5342228050a778b20e95adf7885bdba39985d",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,21 @@\n   public synchronized void close() throws IOException {\n     if (closed) {\n       return;\n     }\n     closed \u003d true;\n     if (backupStream !\u003d null) {\n       backupStream.close();\n     }\n     long dataLen \u003d tmpFile.length();\n     try {\n       if (dataLen \u003c\u003d partSizeThreshold) {\n         uploadObject();\n       } else {\n         multipartUploadObject();\n       }\n     } finally {\n-      tmpFile.delete();\n+      if (!tmpFile.delete()) {\n+        LOG.warn(\"Can not delete file: \" + tmpFile);\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void close() throws IOException {\n    if (closed) {\n      return;\n    }\n    closed \u003d true;\n    if (backupStream !\u003d null) {\n      backupStream.close();\n    }\n    long dataLen \u003d tmpFile.length();\n    try {\n      if (dataLen \u003c\u003d partSizeThreshold) {\n        uploadObject();\n      } else {\n        multipartUploadObject();\n      }\n    } finally {\n      if (!tmpFile.delete()) {\n        LOG.warn(\"Can not delete file: \" + tmpFile);\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSOutputStream.java",
      "extendedDetails": {}
    },
    "a5d5342228050a778b20e95adf7885bdba39985d": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-12756. Incorporate Aliyun OSS file system implementation. Contributed by Mingfei Shi and Lin Zhou\n",
      "commitDate": "06/09/16 8:15 PM",
      "commitName": "a5d5342228050a778b20e95adf7885bdba39985d",
      "commitAuthor": "Kai Zheng",
      "diff": "@@ -0,0 +1,19 @@\n+  public synchronized void close() throws IOException {\n+    if (closed) {\n+      return;\n+    }\n+    closed \u003d true;\n+    if (backupStream !\u003d null) {\n+      backupStream.close();\n+    }\n+    long dataLen \u003d tmpFile.length();\n+    try {\n+      if (dataLen \u003c\u003d partSizeThreshold) {\n+        uploadObject();\n+      } else {\n+        multipartUploadObject();\n+      }\n+    } finally {\n+      tmpFile.delete();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void close() throws IOException {\n    if (closed) {\n      return;\n    }\n    closed \u003d true;\n    if (backupStream !\u003d null) {\n      backupStream.close();\n    }\n    long dataLen \u003d tmpFile.length();\n    try {\n      if (dataLen \u003c\u003d partSizeThreshold) {\n        uploadObject();\n      } else {\n        multipartUploadObject();\n      }\n    } finally {\n      tmpFile.delete();\n    }\n  }",
      "path": "hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSOutputStream.java"
    }
  }
}