{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "OpenFileCtx.java",
  "functionName": "waitForDump",
  "functionId": "waitForDump",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
  "functionStartLine": 272,
  "functionEndLine": 302,
  "numCommitsSeen": 67,
  "timeTaken": 2232,
  "changeHistory": [
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
    "d71d40a63d198991077d5babd70be5e9787a53f1",
    "28e3d09230971b32f74284311931525cb7ad1b7c",
    "37f587563a943a827fbff865f5302bac6d202415"
  ],
  "changeHistoryShort": {
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": "Ybodychange",
    "d71d40a63d198991077d5babd70be5e9787a53f1": "Ymultichange(Yrename,Ybodychange)",
    "28e3d09230971b32f74284311931525cb7ad1b7c": "Ymultichange(Yparameterchange,Ybodychange)",
    "37f587563a943a827fbff865f5302bac6d202415": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10571. Use Log.*(Object, Throwable) overload to log exceptions.\nContributed by Andras Bokor.\n",
      "commitDate": "14/02/18 8:20 AM",
      "commitName": "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "10/10/17 10:38 AM",
      "commitNameOld": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
      "commitAuthorOld": "Jitendra Pandey",
      "daysBetweenCommits": 126.95,
      "commitsBetweenForRepo": 833,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,31 @@\n   private void waitForDump() {\n     if (!enabledDump) {\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Do nothing, dump is disabled.\");\n-      }\n+      LOG.debug(\"Do nothing, dump is disabled.\");\n       return;\n     }\n \n     if (nonSequentialWriteInMemory.get() \u003c DUMP_WRITE_WATER_MARK) {\n       return;\n     }\n \n     // wake up the dumper thread to dump the data\n     synchronized (this) {\n       if (nonSequentialWriteInMemory.get() \u003e\u003d DUMP_WRITE_WATER_MARK) {\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"Asking dumper to dump...\");\n-        }\n+        LOG.debug(\"Asking dumper to dump...\");\n         if (dumpThread \u003d\u003d null) {\n           dumpThread \u003d new Daemon(new Dumper());\n           dumpThread.start();\n         } else {\n           this.notifyAll();          \n         }\n       }\n       \n       while (nonSequentialWriteInMemory.get() \u003e\u003d DUMP_WRITE_WATER_MARK) {\n         try {\n           this.wait();\n         } catch (InterruptedException ignored) {\n         }\n       }\n \n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void waitForDump() {\n    if (!enabledDump) {\n      LOG.debug(\"Do nothing, dump is disabled.\");\n      return;\n    }\n\n    if (nonSequentialWriteInMemory.get() \u003c DUMP_WRITE_WATER_MARK) {\n      return;\n    }\n\n    // wake up the dumper thread to dump the data\n    synchronized (this) {\n      if (nonSequentialWriteInMemory.get() \u003e\u003d DUMP_WRITE_WATER_MARK) {\n        LOG.debug(\"Asking dumper to dump...\");\n        if (dumpThread \u003d\u003d null) {\n          dumpThread \u003d new Daemon(new Dumper());\n          dumpThread.start();\n        } else {\n          this.notifyAll();          \n        }\n      }\n      \n      while (nonSequentialWriteInMemory.get() \u003e\u003d DUMP_WRITE_WATER_MARK) {\n        try {\n          this.wait();\n        } catch (InterruptedException ignored) {\n        }\n      }\n\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "d71d40a63d198991077d5babd70be5e9787a53f1": {
      "type": "Ymultichange(Yrename,Ybodychange)",
      "commitMessage": "HDFS-7180. NFSv3 gateway frequently gets stuck due to GC. Contributed by Brandon Li\n",
      "commitDate": "22/10/14 9:27 PM",
      "commitName": "d71d40a63d198991077d5babd70be5e9787a53f1",
      "commitAuthor": "Brandon Li",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-7180. NFSv3 gateway frequently gets stuck due to GC. Contributed by Brandon Li\n",
          "commitDate": "22/10/14 9:27 PM",
          "commitName": "d71d40a63d198991077d5babd70be5e9787a53f1",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "21/10/14 10:20 AM",
          "commitNameOld": "b6f9d5538cf2b425652687e99503f3d566b2056a",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 1.46,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,27 +1,35 @@\n-  private void checkDump() {\n+  private void waitForDump() {\n     if (!enabledDump) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Do nothing, dump is disabled.\");\n       }\n       return;\n     }\n \n     if (nonSequentialWriteInMemory.get() \u003c DUMP_WRITE_WATER_MARK) {\n       return;\n     }\n \n     // wake up the dumper thread to dump the data\n     synchronized (this) {\n       if (nonSequentialWriteInMemory.get() \u003e\u003d DUMP_WRITE_WATER_MARK) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Asking dumper to dump...\");\n         }\n         if (dumpThread \u003d\u003d null) {\n           dumpThread \u003d new Daemon(new Dumper());\n           dumpThread.start();\n         } else {\n           this.notifyAll();          \n         }\n       }\n+      \n+      while (nonSequentialWriteInMemory.get() \u003e\u003d DUMP_WRITE_WATER_MARK) {\n+        try {\n+          this.wait();\n+        } catch (InterruptedException ignored) {\n+        }\n+      }\n+\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void waitForDump() {\n    if (!enabledDump) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Do nothing, dump is disabled.\");\n      }\n      return;\n    }\n\n    if (nonSequentialWriteInMemory.get() \u003c DUMP_WRITE_WATER_MARK) {\n      return;\n    }\n\n    // wake up the dumper thread to dump the data\n    synchronized (this) {\n      if (nonSequentialWriteInMemory.get() \u003e\u003d DUMP_WRITE_WATER_MARK) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Asking dumper to dump...\");\n        }\n        if (dumpThread \u003d\u003d null) {\n          dumpThread \u003d new Daemon(new Dumper());\n          dumpThread.start();\n        } else {\n          this.notifyAll();          \n        }\n      }\n      \n      while (nonSequentialWriteInMemory.get() \u003e\u003d DUMP_WRITE_WATER_MARK) {\n        try {\n          this.wait();\n        } catch (InterruptedException ignored) {\n        }\n      }\n\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
          "extendedDetails": {
            "oldValue": "checkDump",
            "newValue": "waitForDump"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7180. NFSv3 gateway frequently gets stuck due to GC. Contributed by Brandon Li\n",
          "commitDate": "22/10/14 9:27 PM",
          "commitName": "d71d40a63d198991077d5babd70be5e9787a53f1",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "21/10/14 10:20 AM",
          "commitNameOld": "b6f9d5538cf2b425652687e99503f3d566b2056a",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 1.46,
          "commitsBetweenForRepo": 23,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,27 +1,35 @@\n-  private void checkDump() {\n+  private void waitForDump() {\n     if (!enabledDump) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Do nothing, dump is disabled.\");\n       }\n       return;\n     }\n \n     if (nonSequentialWriteInMemory.get() \u003c DUMP_WRITE_WATER_MARK) {\n       return;\n     }\n \n     // wake up the dumper thread to dump the data\n     synchronized (this) {\n       if (nonSequentialWriteInMemory.get() \u003e\u003d DUMP_WRITE_WATER_MARK) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Asking dumper to dump...\");\n         }\n         if (dumpThread \u003d\u003d null) {\n           dumpThread \u003d new Daemon(new Dumper());\n           dumpThread.start();\n         } else {\n           this.notifyAll();          \n         }\n       }\n+      \n+      while (nonSequentialWriteInMemory.get() \u003e\u003d DUMP_WRITE_WATER_MARK) {\n+        try {\n+          this.wait();\n+        } catch (InterruptedException ignored) {\n+        }\n+      }\n+\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void waitForDump() {\n    if (!enabledDump) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Do nothing, dump is disabled.\");\n      }\n      return;\n    }\n\n    if (nonSequentialWriteInMemory.get() \u003c DUMP_WRITE_WATER_MARK) {\n      return;\n    }\n\n    // wake up the dumper thread to dump the data\n    synchronized (this) {\n      if (nonSequentialWriteInMemory.get() \u003e\u003d DUMP_WRITE_WATER_MARK) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Asking dumper to dump...\");\n        }\n        if (dumpThread \u003d\u003d null) {\n          dumpThread \u003d new Daemon(new Dumper());\n          dumpThread.start();\n        } else {\n          this.notifyAll();          \n        }\n      }\n      \n      while (nonSequentialWriteInMemory.get() \u003e\u003d DUMP_WRITE_WATER_MARK) {\n        try {\n          this.wait();\n        } catch (InterruptedException ignored) {\n        }\n      }\n\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
          "extendedDetails": {}
        }
      ]
    },
    "28e3d09230971b32f74284311931525cb7ad1b7c": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-4971. Move IO operations out of locking in OpenFileCtx. Contributed by Jing Zhao and Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1525681 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/09/13 1:02 PM",
      "commitName": "28e3d09230971b32f74284311931525cb7ad1b7c",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4971. Move IO operations out of locking in OpenFileCtx. Contributed by Jing Zhao and Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1525681 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/09/13 1:02 PM",
          "commitName": "28e3d09230971b32f74284311931525cb7ad1b7c",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "17/09/13 11:08 PM",
          "commitNameOld": "5e18410e06dd63113c49029894007e0878312903",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 5.58,
          "commitsBetweenForRepo": 25,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,75 +1,27 @@\n-  private void checkDump(long count) {\n-    assert (ctxLock.isLocked());\n-\n-    // Always update the in memory count\n-    updateNonSequentialWriteInMemory(count);\n-\n+  private void checkDump() {\n     if (!enabledDump) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Do nothing, dump is disabled.\");\n       }\n       return;\n     }\n \n-    if (nonSequentialWriteInMemory \u003c DUMP_WRITE_WATER_MARK) {\n+    if (nonSequentialWriteInMemory.get() \u003c DUMP_WRITE_WATER_MARK) {\n       return;\n     }\n \n-    // Create dump outputstream for the first time\n-    if (dumpOut \u003d\u003d null) {\n-      LOG.info(\"Create dump file:\" + dumpFilePath);\n-      File dumpFile \u003d new File(dumpFilePath);\n-      try {\n-        if (dumpFile.exists()) {\n-          LOG.fatal(\"The dump file should not exist:\" + dumpFilePath);\n-          throw new RuntimeException(\"The dump file should not exist:\"\n-              + dumpFilePath);\n+    // wake up the dumper thread to dump the data\n+    synchronized (this) {\n+      if (nonSequentialWriteInMemory.get() \u003e\u003d DUMP_WRITE_WATER_MARK) {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Asking dumper to dump...\");\n         }\n-        dumpOut \u003d new FileOutputStream(dumpFile);\n-      } catch (IOException e) {\n-        LOG.error(\"Got failure when creating dump stream \" + dumpFilePath\n-            + \" with error:\" + e);\n-        enabledDump \u003d false;\n-        IOUtils.cleanup(LOG, dumpOut);\n-        return;\n-      }\n-    }\n-    // Get raf for the first dump\n-    if (raf \u003d\u003d null) {\n-      try {\n-        raf \u003d new RandomAccessFile(dumpFilePath, \"r\");\n-      } catch (FileNotFoundException e) {\n-        LOG.error(\"Can\u0027t get random access to file \" + dumpFilePath);\n-        // Disable dump\n-        enabledDump \u003d false;\n-        return;\n-      }\n-    }\n-    \n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"Start dump, current write number:\" + pendingWrites.size());\n-    }\n-    Iterator\u003cOffsetRange\u003e it \u003d pendingWrites.keySet().iterator();\n-    while (it.hasNext()) {\n-      OffsetRange key \u003d it.next();\n-      WriteCtx writeCtx \u003d pendingWrites.get(key);\n-      try {\n-        long dumpedDataSize \u003d writeCtx.dumpData(dumpOut, raf);\n-        if (dumpedDataSize \u003e 0) {\n-          updateNonSequentialWriteInMemory(-dumpedDataSize);\n+        if (dumpThread \u003d\u003d null) {\n+          dumpThread \u003d new Daemon(new Dumper());\n+          dumpThread.start();\n+        } else {\n+          this.notifyAll();          \n         }\n-      } catch (IOException e) {\n-        LOG.error(\"Dump data failed:\" + writeCtx + \" with error:\" + e);\n-        // Disable dump\n-        enabledDump \u003d false;\n-        return;\n       }\n     }\n-    if (nonSequentialWriteInMemory !\u003d 0) {\n-      LOG.fatal(\"After dump, nonSequentialWriteInMemory is not zero: \"\n-          + nonSequentialWriteInMemory);\n-      throw new RuntimeException(\n-          \"After dump, nonSequentialWriteInMemory is not zero: \"\n-              + nonSequentialWriteInMemory);\n-    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void checkDump() {\n    if (!enabledDump) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Do nothing, dump is disabled.\");\n      }\n      return;\n    }\n\n    if (nonSequentialWriteInMemory.get() \u003c DUMP_WRITE_WATER_MARK) {\n      return;\n    }\n\n    // wake up the dumper thread to dump the data\n    synchronized (this) {\n      if (nonSequentialWriteInMemory.get() \u003e\u003d DUMP_WRITE_WATER_MARK) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Asking dumper to dump...\");\n        }\n        if (dumpThread \u003d\u003d null) {\n          dumpThread \u003d new Daemon(new Dumper());\n          dumpThread.start();\n        } else {\n          this.notifyAll();          \n        }\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
          "extendedDetails": {
            "oldValue": "[count-long]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4971. Move IO operations out of locking in OpenFileCtx. Contributed by Jing Zhao and Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1525681 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/09/13 1:02 PM",
          "commitName": "28e3d09230971b32f74284311931525cb7ad1b7c",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "17/09/13 11:08 PM",
          "commitNameOld": "5e18410e06dd63113c49029894007e0878312903",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 5.58,
          "commitsBetweenForRepo": 25,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,75 +1,27 @@\n-  private void checkDump(long count) {\n-    assert (ctxLock.isLocked());\n-\n-    // Always update the in memory count\n-    updateNonSequentialWriteInMemory(count);\n-\n+  private void checkDump() {\n     if (!enabledDump) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Do nothing, dump is disabled.\");\n       }\n       return;\n     }\n \n-    if (nonSequentialWriteInMemory \u003c DUMP_WRITE_WATER_MARK) {\n+    if (nonSequentialWriteInMemory.get() \u003c DUMP_WRITE_WATER_MARK) {\n       return;\n     }\n \n-    // Create dump outputstream for the first time\n-    if (dumpOut \u003d\u003d null) {\n-      LOG.info(\"Create dump file:\" + dumpFilePath);\n-      File dumpFile \u003d new File(dumpFilePath);\n-      try {\n-        if (dumpFile.exists()) {\n-          LOG.fatal(\"The dump file should not exist:\" + dumpFilePath);\n-          throw new RuntimeException(\"The dump file should not exist:\"\n-              + dumpFilePath);\n+    // wake up the dumper thread to dump the data\n+    synchronized (this) {\n+      if (nonSequentialWriteInMemory.get() \u003e\u003d DUMP_WRITE_WATER_MARK) {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Asking dumper to dump...\");\n         }\n-        dumpOut \u003d new FileOutputStream(dumpFile);\n-      } catch (IOException e) {\n-        LOG.error(\"Got failure when creating dump stream \" + dumpFilePath\n-            + \" with error:\" + e);\n-        enabledDump \u003d false;\n-        IOUtils.cleanup(LOG, dumpOut);\n-        return;\n-      }\n-    }\n-    // Get raf for the first dump\n-    if (raf \u003d\u003d null) {\n-      try {\n-        raf \u003d new RandomAccessFile(dumpFilePath, \"r\");\n-      } catch (FileNotFoundException e) {\n-        LOG.error(\"Can\u0027t get random access to file \" + dumpFilePath);\n-        // Disable dump\n-        enabledDump \u003d false;\n-        return;\n-      }\n-    }\n-    \n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"Start dump, current write number:\" + pendingWrites.size());\n-    }\n-    Iterator\u003cOffsetRange\u003e it \u003d pendingWrites.keySet().iterator();\n-    while (it.hasNext()) {\n-      OffsetRange key \u003d it.next();\n-      WriteCtx writeCtx \u003d pendingWrites.get(key);\n-      try {\n-        long dumpedDataSize \u003d writeCtx.dumpData(dumpOut, raf);\n-        if (dumpedDataSize \u003e 0) {\n-          updateNonSequentialWriteInMemory(-dumpedDataSize);\n+        if (dumpThread \u003d\u003d null) {\n+          dumpThread \u003d new Daemon(new Dumper());\n+          dumpThread.start();\n+        } else {\n+          this.notifyAll();          \n         }\n-      } catch (IOException e) {\n-        LOG.error(\"Dump data failed:\" + writeCtx + \" with error:\" + e);\n-        // Disable dump\n-        enabledDump \u003d false;\n-        return;\n       }\n     }\n-    if (nonSequentialWriteInMemory !\u003d 0) {\n-      LOG.fatal(\"After dump, nonSequentialWriteInMemory is not zero: \"\n-          + nonSequentialWriteInMemory);\n-      throw new RuntimeException(\n-          \"After dump, nonSequentialWriteInMemory is not zero: \"\n-              + nonSequentialWriteInMemory);\n-    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void checkDump() {\n    if (!enabledDump) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Do nothing, dump is disabled.\");\n      }\n      return;\n    }\n\n    if (nonSequentialWriteInMemory.get() \u003c DUMP_WRITE_WATER_MARK) {\n      return;\n    }\n\n    // wake up the dumper thread to dump the data\n    synchronized (this) {\n      if (nonSequentialWriteInMemory.get() \u003e\u003d DUMP_WRITE_WATER_MARK) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Asking dumper to dump...\");\n        }\n        if (dumpThread \u003d\u003d null) {\n          dumpThread \u003d new Daemon(new Dumper());\n          dumpThread.start();\n        } else {\n          this.notifyAll();          \n        }\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
          "extendedDetails": {}
        }
      ]
    },
    "37f587563a943a827fbff865f5302bac6d202415": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4762 Provide HDFS based NFSv3 and Mountd implementation. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1499029 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/07/13 10:31 AM",
      "commitName": "37f587563a943a827fbff865f5302bac6d202415",
      "commitAuthor": "Brandon Li",
      "diff": "@@ -0,0 +1,75 @@\n+  private void checkDump(long count) {\n+    assert (ctxLock.isLocked());\n+\n+    // Always update the in memory count\n+    updateNonSequentialWriteInMemory(count);\n+\n+    if (!enabledDump) {\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Do nothing, dump is disabled.\");\n+      }\n+      return;\n+    }\n+\n+    if (nonSequentialWriteInMemory \u003c DUMP_WRITE_WATER_MARK) {\n+      return;\n+    }\n+\n+    // Create dump outputstream for the first time\n+    if (dumpOut \u003d\u003d null) {\n+      LOG.info(\"Create dump file:\" + dumpFilePath);\n+      File dumpFile \u003d new File(dumpFilePath);\n+      try {\n+        if (dumpFile.exists()) {\n+          LOG.fatal(\"The dump file should not exist:\" + dumpFilePath);\n+          throw new RuntimeException(\"The dump file should not exist:\"\n+              + dumpFilePath);\n+        }\n+        dumpOut \u003d new FileOutputStream(dumpFile);\n+      } catch (IOException e) {\n+        LOG.error(\"Got failure when creating dump stream \" + dumpFilePath\n+            + \" with error:\" + e);\n+        enabledDump \u003d false;\n+        IOUtils.cleanup(LOG, dumpOut);\n+        return;\n+      }\n+    }\n+    // Get raf for the first dump\n+    if (raf \u003d\u003d null) {\n+      try {\n+        raf \u003d new RandomAccessFile(dumpFilePath, \"r\");\n+      } catch (FileNotFoundException e) {\n+        LOG.error(\"Can\u0027t get random access to file \" + dumpFilePath);\n+        // Disable dump\n+        enabledDump \u003d false;\n+        return;\n+      }\n+    }\n+    \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Start dump, current write number:\" + pendingWrites.size());\n+    }\n+    Iterator\u003cOffsetRange\u003e it \u003d pendingWrites.keySet().iterator();\n+    while (it.hasNext()) {\n+      OffsetRange key \u003d it.next();\n+      WriteCtx writeCtx \u003d pendingWrites.get(key);\n+      try {\n+        long dumpedDataSize \u003d writeCtx.dumpData(dumpOut, raf);\n+        if (dumpedDataSize \u003e 0) {\n+          updateNonSequentialWriteInMemory(-dumpedDataSize);\n+        }\n+      } catch (IOException e) {\n+        LOG.error(\"Dump data failed:\" + writeCtx + \" with error:\" + e);\n+        // Disable dump\n+        enabledDump \u003d false;\n+        return;\n+      }\n+    }\n+    if (nonSequentialWriteInMemory !\u003d 0) {\n+      LOG.fatal(\"After dump, nonSequentialWriteInMemory is not zero: \"\n+          + nonSequentialWriteInMemory);\n+      throw new RuntimeException(\n+          \"After dump, nonSequentialWriteInMemory is not zero: \"\n+              + nonSequentialWriteInMemory);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void checkDump(long count) {\n    assert (ctxLock.isLocked());\n\n    // Always update the in memory count\n    updateNonSequentialWriteInMemory(count);\n\n    if (!enabledDump) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Do nothing, dump is disabled.\");\n      }\n      return;\n    }\n\n    if (nonSequentialWriteInMemory \u003c DUMP_WRITE_WATER_MARK) {\n      return;\n    }\n\n    // Create dump outputstream for the first time\n    if (dumpOut \u003d\u003d null) {\n      LOG.info(\"Create dump file:\" + dumpFilePath);\n      File dumpFile \u003d new File(dumpFilePath);\n      try {\n        if (dumpFile.exists()) {\n          LOG.fatal(\"The dump file should not exist:\" + dumpFilePath);\n          throw new RuntimeException(\"The dump file should not exist:\"\n              + dumpFilePath);\n        }\n        dumpOut \u003d new FileOutputStream(dumpFile);\n      } catch (IOException e) {\n        LOG.error(\"Got failure when creating dump stream \" + dumpFilePath\n            + \" with error:\" + e);\n        enabledDump \u003d false;\n        IOUtils.cleanup(LOG, dumpOut);\n        return;\n      }\n    }\n    // Get raf for the first dump\n    if (raf \u003d\u003d null) {\n      try {\n        raf \u003d new RandomAccessFile(dumpFilePath, \"r\");\n      } catch (FileNotFoundException e) {\n        LOG.error(\"Can\u0027t get random access to file \" + dumpFilePath);\n        // Disable dump\n        enabledDump \u003d false;\n        return;\n      }\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Start dump, current write number:\" + pendingWrites.size());\n    }\n    Iterator\u003cOffsetRange\u003e it \u003d pendingWrites.keySet().iterator();\n    while (it.hasNext()) {\n      OffsetRange key \u003d it.next();\n      WriteCtx writeCtx \u003d pendingWrites.get(key);\n      try {\n        long dumpedDataSize \u003d writeCtx.dumpData(dumpOut, raf);\n        if (dumpedDataSize \u003e 0) {\n          updateNonSequentialWriteInMemory(-dumpedDataSize);\n        }\n      } catch (IOException e) {\n        LOG.error(\"Dump data failed:\" + writeCtx + \" with error:\" + e);\n        // Disable dump\n        enabledDump \u003d false;\n        return;\n      }\n    }\n    if (nonSequentialWriteInMemory !\u003d 0) {\n      LOG.fatal(\"After dump, nonSequentialWriteInMemory is not zero: \"\n          + nonSequentialWriteInMemory);\n      throw new RuntimeException(\n          \"After dump, nonSequentialWriteInMemory is not zero: \"\n              + nonSequentialWriteInMemory);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java"
    }
  }
}