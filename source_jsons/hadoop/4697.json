{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NameNodeProxies.java",
  "functionName": "createProxy",
  "functionId": "createProxy___conf-Configuration__nameNodeUri-URI__xface-Class__T__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
  "functionStartLine": 96,
  "functionEndLine": 99,
  "numCommitsSeen": 66,
  "timeTaken": 2687,
  "changeHistory": [
    "f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5",
    "7ba5913797c49d5001ad95558eadd119c3361060",
    "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85",
    "33ade356b35223654a077103ed7fbed89f3f2321",
    "0aa09f6d5a97f523e9ee6f30bb44f206433ead0a",
    "c69dfdd5e14af490790dff8227b11962ec816577",
    "481f84597bf842df45b068cc24c328112e8bcf40",
    "02919e61f6935813bc3dbe23cc89e00e0cb02918",
    "212678f036f4f96493bc14a584e758f97cf65573"
  ],
  "changeHistoryShort": {
    "f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5": "Ybodychange",
    "7ba5913797c49d5001ad95558eadd119c3361060": "Ybodychange",
    "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85": "Ybodychange",
    "33ade356b35223654a077103ed7fbed89f3f2321": "Ybodychange",
    "0aa09f6d5a97f523e9ee6f30bb44f206433ead0a": "Ybodychange",
    "c69dfdd5e14af490790dff8227b11962ec816577": "Ymultichange(Ymovefromfile,Ybodychange)",
    "481f84597bf842df45b068cc24c328112e8bcf40": "Ymultichange(Yrename,Yparameterchange,Yreturntypechange,Ybodychange)",
    "02919e61f6935813bc3dbe23cc89e00e0cb02918": "Ybodychange",
    "212678f036f4f96493bc14a584e758f97cf65573": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7073. Allow falling back to a non-SASL connection on DataTransferProtocol in several edge cases. Contributed by Chris Nauroth.\n",
      "commitDate": "19/09/14 9:23 PM",
      "commitName": "f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5",
      "commitAuthor": "cnauroth",
      "commitDateOld": "17/07/14 4:11 PM",
      "commitNameOld": "7ba5913797c49d5001ad95558eadd119c3361060",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 64.22,
      "commitsBetweenForRepo": 611,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,4 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n       URI nameNodeUri, Class\u003cT\u003e xface) throws IOException {\n-    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n-        createFailoverProxyProvider(conf, nameNodeUri, xface, true);\n-  \n-    if (failoverProxyProvider \u003d\u003d null) {\n-      // Non-HA case\n-      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n-          UserGroupInformation.getCurrentUser(), true);\n-    } else {\n-      // HA case\n-      Conf config \u003d new Conf(conf);\n-      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n-          RetryPolicies.failoverOnNetworkException(\n-              RetryPolicies.TRY_ONCE_THEN_FAIL, config.maxFailoverAttempts,\n-              config.maxRetryAttempts, config.failoverSleepBaseMillis,\n-              config.failoverSleepMaxMillis));\n-\n-      Text dtService;\n-      if (failoverProxyProvider.useLogicalURI()) {\n-        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri,\n-            HdfsConstants.HDFS_URI_SCHEME);\n-      } else {\n-        dtService \u003d SecurityUtil.buildTokenService(\n-            NameNode.getAddress(nameNodeUri));\n-      }\n-      return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n-          NameNode.getAddress(nameNodeUri));\n-    }\n+    return createProxy(conf, nameNodeUri, xface, null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface) throws IOException {\n    return createProxy(conf, nameNodeUri, xface, null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "7ba5913797c49d5001ad95558eadd119c3361060": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6667. In HDFS HA mode, Distcp/SLive with webhdfs on secure cluster fails with Client cannot authenticate via:[TOKEN, KERBEROS] error. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1611508 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/07/14 4:11 PM",
      "commitName": "7ba5913797c49d5001ad95558eadd119c3361060",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "17/07/14 10:37 AM",
      "commitNameOld": "f4151bbf4f54dc33836c76e6860aa043a9626e48",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.23,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,30 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n       URI nameNodeUri, Class\u003cT\u003e xface) throws IOException {\n     AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n         createFailoverProxyProvider(conf, nameNodeUri, xface, true);\n   \n     if (failoverProxyProvider \u003d\u003d null) {\n       // Non-HA case\n       return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n           UserGroupInformation.getCurrentUser(), true);\n     } else {\n       // HA case\n       Conf config \u003d new Conf(conf);\n       T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n           RetryPolicies.failoverOnNetworkException(\n               RetryPolicies.TRY_ONCE_THEN_FAIL, config.maxFailoverAttempts,\n               config.maxRetryAttempts, config.failoverSleepBaseMillis,\n               config.failoverSleepMaxMillis));\n \n       Text dtService;\n       if (failoverProxyProvider.useLogicalURI()) {\n-        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n+        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri,\n+            HdfsConstants.HDFS_URI_SCHEME);\n       } else {\n         dtService \u003d SecurityUtil.buildTokenService(\n             NameNode.getAddress(nameNodeUri));\n       }\n       return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n           NameNode.getAddress(nameNodeUri));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface) throws IOException {\n    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n        createFailoverProxyProvider(conf, nameNodeUri, xface, true);\n  \n    if (failoverProxyProvider \u003d\u003d null) {\n      // Non-HA case\n      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n          UserGroupInformation.getCurrentUser(), true);\n    } else {\n      // HA case\n      Conf config \u003d new Conf(conf);\n      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n          RetryPolicies.failoverOnNetworkException(\n              RetryPolicies.TRY_ONCE_THEN_FAIL, config.maxFailoverAttempts,\n              config.maxRetryAttempts, config.failoverSleepBaseMillis,\n              config.failoverSleepMaxMillis));\n\n      Text dtService;\n      if (failoverProxyProvider.useLogicalURI()) {\n        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri,\n            HdfsConstants.HDFS_URI_SCHEME);\n      } else {\n        dtService \u003d SecurityUtil.buildTokenService(\n            NameNode.getAddress(nameNodeUri));\n      }\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n          NameNode.getAddress(nameNodeUri));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6507. Improve DFSAdmin to support HA cluster better. (Contributd by Zesheng Wu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1604692 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/06/14 10:16 PM",
      "commitName": "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "13/05/14 9:19 AM",
      "commitNameOld": "33ade356b35223654a077103ed7fbed89f3f2321",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 40.54,
      "commitsBetweenForRepo": 250,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,29 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n       URI nameNodeUri, Class\u003cT\u003e xface) throws IOException {\n     AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n         createFailoverProxyProvider(conf, nameNodeUri, xface, true);\n   \n     if (failoverProxyProvider \u003d\u003d null) {\n       // Non-HA case\n       return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n           UserGroupInformation.getCurrentUser(), true);\n     } else {\n       // HA case\n       Conf config \u003d new Conf(conf);\n       T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n           RetryPolicies.failoverOnNetworkException(\n               RetryPolicies.TRY_ONCE_THEN_FAIL, config.maxFailoverAttempts,\n               config.maxRetryAttempts, config.failoverSleepBaseMillis,\n               config.failoverSleepMaxMillis));\n \n       Text dtService;\n       if (failoverProxyProvider.useLogicalURI()) {\n         dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n       } else {\n         dtService \u003d SecurityUtil.buildTokenService(\n             NameNode.getAddress(nameNodeUri));\n       }\n-      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n+      return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n+          NameNode.getAddress(nameNodeUri));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface) throws IOException {\n    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n        createFailoverProxyProvider(conf, nameNodeUri, xface, true);\n  \n    if (failoverProxyProvider \u003d\u003d null) {\n      // Non-HA case\n      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n          UserGroupInformation.getCurrentUser(), true);\n    } else {\n      // HA case\n      Conf config \u003d new Conf(conf);\n      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n          RetryPolicies.failoverOnNetworkException(\n              RetryPolicies.TRY_ONCE_THEN_FAIL, config.maxFailoverAttempts,\n              config.maxRetryAttempts, config.failoverSleepBaseMillis,\n              config.failoverSleepMaxMillis));\n\n      Text dtService;\n      if (failoverProxyProvider.useLogicalURI()) {\n        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n      } else {\n        dtService \u003d SecurityUtil.buildTokenService(\n            NameNode.getAddress(nameNodeUri));\n      }\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n          NameNode.getAddress(nameNodeUri));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "33ade356b35223654a077103ed7fbed89f3f2321": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6334. Client failover proxy provider for IP failover based NN HA. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594263 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/05/14 9:19 AM",
      "commitName": "33ade356b35223654a077103ed7fbed89f3f2321",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "28/02/14 11:48 AM",
      "commitNameOld": "d00605f8f0214ed8e2304db8688e140f0a1d62d8",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 73.85,
      "commitsBetweenForRepo": 483,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,28 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n       URI nameNodeUri, Class\u003cT\u003e xface) throws IOException {\n-    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d\n-        getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n+    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n+        createFailoverProxyProvider(conf, nameNodeUri, xface, true);\n   \n-    if (failoverProxyProviderClass \u003d\u003d null) {\n+    if (failoverProxyProvider \u003d\u003d null) {\n       // Non-HA case\n       return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n           UserGroupInformation.getCurrentUser(), true);\n     } else {\n       // HA case\n-      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d NameNodeProxies\n-          .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface,\n-              nameNodeUri);\n       Conf config \u003d new Conf(conf);\n       T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n           RetryPolicies.failoverOnNetworkException(\n               RetryPolicies.TRY_ONCE_THEN_FAIL, config.maxFailoverAttempts,\n               config.maxRetryAttempts, config.failoverSleepBaseMillis,\n               config.failoverSleepMaxMillis));\n-      \n-      Text dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n+\n+      Text dtService;\n+      if (failoverProxyProvider.useLogicalURI()) {\n+        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n+      } else {\n+        dtService \u003d SecurityUtil.buildTokenService(\n+            NameNode.getAddress(nameNodeUri));\n+      }\n       return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface) throws IOException {\n    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n        createFailoverProxyProvider(conf, nameNodeUri, xface, true);\n  \n    if (failoverProxyProvider \u003d\u003d null) {\n      // Non-HA case\n      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n          UserGroupInformation.getCurrentUser(), true);\n    } else {\n      // HA case\n      Conf config \u003d new Conf(conf);\n      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n          RetryPolicies.failoverOnNetworkException(\n              RetryPolicies.TRY_ONCE_THEN_FAIL, config.maxFailoverAttempts,\n              config.maxRetryAttempts, config.failoverSleepBaseMillis,\n              config.failoverSleepMaxMillis));\n\n      Text dtService;\n      if (failoverProxyProvider.useLogicalURI()) {\n        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n      } else {\n        dtService \u003d SecurityUtil.buildTokenService(\n            NameNode.getAddress(nameNodeUri));\n      }\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "0aa09f6d5a97f523e9ee6f30bb44f206433ead0a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5399. Revisit SafeModeException and corresponding retry policies. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1564629 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/02/14 8:18 PM",
      "commitName": "0aa09f6d5a97f523e9ee6f30bb44f206433ead0a",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "12/09/13 9:29 PM",
      "commitNameOld": "965ce2041a7adfbbe5fc8b77a85c0d1179ef20df",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 144.99,
      "commitsBetweenForRepo": 889,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,25 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n       URI nameNodeUri, Class\u003cT\u003e xface) throws IOException {\n     Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d\n         getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n   \n     if (failoverProxyProviderClass \u003d\u003d null) {\n       // Non-HA case\n       return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n           UserGroupInformation.getCurrentUser(), true);\n     } else {\n       // HA case\n       FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d NameNodeProxies\n           .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface,\n               nameNodeUri);\n       Conf config \u003d new Conf(conf);\n-      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n-          .failoverOnNetworkException(RetryPolicies.TRY_ONCE_THEN_FAIL,\n-              config.maxFailoverAttempts, config.failoverSleepBaseMillis,\n+      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n+          RetryPolicies.failoverOnNetworkException(\n+              RetryPolicies.TRY_ONCE_THEN_FAIL, config.maxFailoverAttempts,\n+              config.maxRetryAttempts, config.failoverSleepBaseMillis,\n               config.failoverSleepMaxMillis));\n       \n       Text dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n       return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface) throws IOException {\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d\n        getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n  \n    if (failoverProxyProviderClass \u003d\u003d null) {\n      // Non-HA case\n      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n          UserGroupInformation.getCurrentUser(), true);\n    } else {\n      // HA case\n      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d NameNodeProxies\n          .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface,\n              nameNodeUri);\n      Conf config \u003d new Conf(conf);\n      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n          RetryPolicies.failoverOnNetworkException(\n              RetryPolicies.TRY_ONCE_THEN_FAIL, config.maxFailoverAttempts,\n              config.maxRetryAttempts, config.failoverSleepBaseMillis,\n              config.failoverSleepMaxMillis));\n      \n      Text dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "c69dfdd5e14af490790dff8227b11962ec816577": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-2958. Sweep for remaining proxy construction which doesn\u0027t go through failover path.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1294811 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/02/12 12:09 PM",
      "commitName": "c69dfdd5e14af490790dff8227b11962ec816577",
      "commitAuthor": "Aaron Myers",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-2958. Sweep for remaining proxy construction which doesn\u0027t go through failover path.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1294811 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "28/02/12 12:09 PM",
          "commitName": "c69dfdd5e14af490790dff8227b11962ec816577",
          "commitAuthor": "Aaron Myers",
          "commitDateOld": "28/02/12 10:38 AM",
          "commitNameOld": "1ab31b1715e9db498847725dadfb82b16f71143b",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.06,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,24 @@\n-  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(\n-      Configuration conf, URI nameNodeUri,\n-      Class\u003cT\u003e xface) throws IOException {\n+  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n+      URI nameNodeUri, Class\u003cT\u003e xface) throws IOException {\n     Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d\n-        HAUtil.getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n-\n+        getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n+  \n     if (failoverProxyProviderClass \u003d\u003d null) {\n       // Non-HA case\n-      return createNonHAProxy(conf, nameNodeUri, xface);\n+      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n+          UserGroupInformation.getCurrentUser(), true);\n     } else {\n       // HA case\n-      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d HAUtil\n+      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d NameNodeProxies\n           .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface,\n               nameNodeUri);\n       Conf config \u003d new Conf(conf);\n       T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n           .failoverOnNetworkException(RetryPolicies.TRY_ONCE_THEN_FAIL,\n               config.maxFailoverAttempts, config.failoverSleepBaseMillis,\n               config.failoverSleepMaxMillis));\n       \n-      Text dtService \u003d buildTokenServiceForLogicalUri(nameNodeUri);\n+      Text dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n       return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface) throws IOException {\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d\n        getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n  \n    if (failoverProxyProviderClass \u003d\u003d null) {\n      // Non-HA case\n      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n          UserGroupInformation.getCurrentUser(), true);\n    } else {\n      // HA case\n      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d NameNodeProxies\n          .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface,\n              nameNodeUri);\n      Conf config \u003d new Conf(conf);\n      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n          .failoverOnNetworkException(RetryPolicies.TRY_ONCE_THEN_FAIL,\n              config.maxFailoverAttempts, config.failoverSleepBaseMillis,\n              config.failoverSleepMaxMillis));\n      \n      Text dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
            "oldMethodName": "createProxy",
            "newMethodName": "createProxy"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2958. Sweep for remaining proxy construction which doesn\u0027t go through failover path.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1294811 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "28/02/12 12:09 PM",
          "commitName": "c69dfdd5e14af490790dff8227b11962ec816577",
          "commitAuthor": "Aaron Myers",
          "commitDateOld": "28/02/12 10:38 AM",
          "commitNameOld": "1ab31b1715e9db498847725dadfb82b16f71143b",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.06,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,24 @@\n-  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(\n-      Configuration conf, URI nameNodeUri,\n-      Class\u003cT\u003e xface) throws IOException {\n+  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n+      URI nameNodeUri, Class\u003cT\u003e xface) throws IOException {\n     Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d\n-        HAUtil.getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n-\n+        getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n+  \n     if (failoverProxyProviderClass \u003d\u003d null) {\n       // Non-HA case\n-      return createNonHAProxy(conf, nameNodeUri, xface);\n+      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n+          UserGroupInformation.getCurrentUser(), true);\n     } else {\n       // HA case\n-      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d HAUtil\n+      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d NameNodeProxies\n           .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface,\n               nameNodeUri);\n       Conf config \u003d new Conf(conf);\n       T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n           .failoverOnNetworkException(RetryPolicies.TRY_ONCE_THEN_FAIL,\n               config.maxFailoverAttempts, config.failoverSleepBaseMillis,\n               config.failoverSleepMaxMillis));\n       \n-      Text dtService \u003d buildTokenServiceForLogicalUri(nameNodeUri);\n+      Text dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n       return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface) throws IOException {\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d\n        getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n  \n    if (failoverProxyProviderClass \u003d\u003d null) {\n      // Non-HA case\n      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n          UserGroupInformation.getCurrentUser(), true);\n    } else {\n      // HA case\n      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d NameNodeProxies\n          .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface,\n              nameNodeUri);\n      Conf config \u003d new Conf(conf);\n      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n          .failoverOnNetworkException(RetryPolicies.TRY_ONCE_THEN_FAIL,\n              config.maxFailoverAttempts, config.failoverSleepBaseMillis,\n              config.failoverSleepMaxMillis));\n      \n      Text dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
          "extendedDetails": {}
        }
      ]
    },
    "481f84597bf842df45b068cc24c328112e8bcf40": {
      "type": "Ymultichange(Yrename,Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-2904. Client support for getting delegation tokens. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1293486 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/02/12 4:03 PM",
      "commitName": "481f84597bf842df45b068cc24c328112e8bcf40",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-2904. Client support for getting delegation tokens. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1293486 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/02/12 4:03 PM",
          "commitName": "481f84597bf842df45b068cc24c328112e8bcf40",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "06/02/12 12:21 AM",
          "commitNameOld": "c17b4f8eefe5b77b77761a0bb46b49cd1ea6965d",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 18.65,
          "commitsBetweenForRepo": 159,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,24 @@\n-  public static Object createFailoverProxy(Configuration conf, URI nameNodeUri,\n-      Class xface) throws IOException {\n-    Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass \u003d HAUtil\n-        .getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n-    if (failoverProxyProviderClass !\u003d null) {\n-      FailoverProxyProvider\u003c?\u003e failoverProxyProvider \u003d HAUtil\n+  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(\n+      Configuration conf, URI nameNodeUri,\n+      Class\u003cT\u003e xface) throws IOException {\n+    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d\n+        HAUtil.getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n+\n+    if (failoverProxyProviderClass \u003d\u003d null) {\n+      // Non-HA case\n+      return createNonHAProxy(conf, nameNodeUri, xface);\n+    } else {\n+      // HA case\n+      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d HAUtil\n           .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface,\n               nameNodeUri);\n       Conf config \u003d new Conf(conf);\n-      return RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n+      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n           .failoverOnNetworkException(RetryPolicies.TRY_ONCE_THEN_FAIL,\n               config.maxFailoverAttempts, config.failoverSleepBaseMillis,\n               config.failoverSleepMaxMillis));\n+      \n+      Text dtService \u003d buildTokenServiceForLogicalUri(nameNodeUri);\n+      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n     }\n-    return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(\n      Configuration conf, URI nameNodeUri,\n      Class\u003cT\u003e xface) throws IOException {\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d\n        HAUtil.getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n\n    if (failoverProxyProviderClass \u003d\u003d null) {\n      // Non-HA case\n      return createNonHAProxy(conf, nameNodeUri, xface);\n    } else {\n      // HA case\n      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d HAUtil\n          .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface,\n              nameNodeUri);\n      Conf config \u003d new Conf(conf);\n      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n          .failoverOnNetworkException(RetryPolicies.TRY_ONCE_THEN_FAIL,\n              config.maxFailoverAttempts, config.failoverSleepBaseMillis,\n              config.failoverSleepMaxMillis));\n      \n      Text dtService \u003d buildTokenServiceForLogicalUri(nameNodeUri);\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
          "extendedDetails": {
            "oldValue": "createFailoverProxy",
            "newValue": "createProxy"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2904. Client support for getting delegation tokens. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1293486 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/02/12 4:03 PM",
          "commitName": "481f84597bf842df45b068cc24c328112e8bcf40",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "06/02/12 12:21 AM",
          "commitNameOld": "c17b4f8eefe5b77b77761a0bb46b49cd1ea6965d",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 18.65,
          "commitsBetweenForRepo": 159,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,24 @@\n-  public static Object createFailoverProxy(Configuration conf, URI nameNodeUri,\n-      Class xface) throws IOException {\n-    Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass \u003d HAUtil\n-        .getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n-    if (failoverProxyProviderClass !\u003d null) {\n-      FailoverProxyProvider\u003c?\u003e failoverProxyProvider \u003d HAUtil\n+  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(\n+      Configuration conf, URI nameNodeUri,\n+      Class\u003cT\u003e xface) throws IOException {\n+    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d\n+        HAUtil.getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n+\n+    if (failoverProxyProviderClass \u003d\u003d null) {\n+      // Non-HA case\n+      return createNonHAProxy(conf, nameNodeUri, xface);\n+    } else {\n+      // HA case\n+      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d HAUtil\n           .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface,\n               nameNodeUri);\n       Conf config \u003d new Conf(conf);\n-      return RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n+      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n           .failoverOnNetworkException(RetryPolicies.TRY_ONCE_THEN_FAIL,\n               config.maxFailoverAttempts, config.failoverSleepBaseMillis,\n               config.failoverSleepMaxMillis));\n+      \n+      Text dtService \u003d buildTokenServiceForLogicalUri(nameNodeUri);\n+      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n     }\n-    return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(\n      Configuration conf, URI nameNodeUri,\n      Class\u003cT\u003e xface) throws IOException {\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d\n        HAUtil.getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n\n    if (failoverProxyProviderClass \u003d\u003d null) {\n      // Non-HA case\n      return createNonHAProxy(conf, nameNodeUri, xface);\n    } else {\n      // HA case\n      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d HAUtil\n          .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface,\n              nameNodeUri);\n      Conf config \u003d new Conf(conf);\n      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n          .failoverOnNetworkException(RetryPolicies.TRY_ONCE_THEN_FAIL,\n              config.maxFailoverAttempts, config.failoverSleepBaseMillis,\n              config.failoverSleepMaxMillis));\n      \n      Text dtService \u003d buildTokenServiceForLogicalUri(nameNodeUri);\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
          "extendedDetails": {
            "oldValue": "[conf-Configuration, nameNodeUri-URI, xface-Class]",
            "newValue": "[conf-Configuration, nameNodeUri-URI, xface-Class\u003cT\u003e]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-2904. Client support for getting delegation tokens. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1293486 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/02/12 4:03 PM",
          "commitName": "481f84597bf842df45b068cc24c328112e8bcf40",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "06/02/12 12:21 AM",
          "commitNameOld": "c17b4f8eefe5b77b77761a0bb46b49cd1ea6965d",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 18.65,
          "commitsBetweenForRepo": 159,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,24 @@\n-  public static Object createFailoverProxy(Configuration conf, URI nameNodeUri,\n-      Class xface) throws IOException {\n-    Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass \u003d HAUtil\n-        .getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n-    if (failoverProxyProviderClass !\u003d null) {\n-      FailoverProxyProvider\u003c?\u003e failoverProxyProvider \u003d HAUtil\n+  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(\n+      Configuration conf, URI nameNodeUri,\n+      Class\u003cT\u003e xface) throws IOException {\n+    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d\n+        HAUtil.getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n+\n+    if (failoverProxyProviderClass \u003d\u003d null) {\n+      // Non-HA case\n+      return createNonHAProxy(conf, nameNodeUri, xface);\n+    } else {\n+      // HA case\n+      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d HAUtil\n           .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface,\n               nameNodeUri);\n       Conf config \u003d new Conf(conf);\n-      return RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n+      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n           .failoverOnNetworkException(RetryPolicies.TRY_ONCE_THEN_FAIL,\n               config.maxFailoverAttempts, config.failoverSleepBaseMillis,\n               config.failoverSleepMaxMillis));\n+      \n+      Text dtService \u003d buildTokenServiceForLogicalUri(nameNodeUri);\n+      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n     }\n-    return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(\n      Configuration conf, URI nameNodeUri,\n      Class\u003cT\u003e xface) throws IOException {\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d\n        HAUtil.getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n\n    if (failoverProxyProviderClass \u003d\u003d null) {\n      // Non-HA case\n      return createNonHAProxy(conf, nameNodeUri, xface);\n    } else {\n      // HA case\n      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d HAUtil\n          .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface,\n              nameNodeUri);\n      Conf config \u003d new Conf(conf);\n      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n          .failoverOnNetworkException(RetryPolicies.TRY_ONCE_THEN_FAIL,\n              config.maxFailoverAttempts, config.failoverSleepBaseMillis,\n              config.failoverSleepMaxMillis));\n      \n      Text dtService \u003d buildTokenServiceForLogicalUri(nameNodeUri);\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
          "extendedDetails": {
            "oldValue": "Object",
            "newValue": "ProxyAndInfo\u003cT\u003e"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2904. Client support for getting delegation tokens. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1293486 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/02/12 4:03 PM",
          "commitName": "481f84597bf842df45b068cc24c328112e8bcf40",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "06/02/12 12:21 AM",
          "commitNameOld": "c17b4f8eefe5b77b77761a0bb46b49cd1ea6965d",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 18.65,
          "commitsBetweenForRepo": 159,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,16 +1,24 @@\n-  public static Object createFailoverProxy(Configuration conf, URI nameNodeUri,\n-      Class xface) throws IOException {\n-    Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass \u003d HAUtil\n-        .getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n-    if (failoverProxyProviderClass !\u003d null) {\n-      FailoverProxyProvider\u003c?\u003e failoverProxyProvider \u003d HAUtil\n+  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(\n+      Configuration conf, URI nameNodeUri,\n+      Class\u003cT\u003e xface) throws IOException {\n+    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d\n+        HAUtil.getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n+\n+    if (failoverProxyProviderClass \u003d\u003d null) {\n+      // Non-HA case\n+      return createNonHAProxy(conf, nameNodeUri, xface);\n+    } else {\n+      // HA case\n+      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d HAUtil\n           .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface,\n               nameNodeUri);\n       Conf config \u003d new Conf(conf);\n-      return RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n+      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n           .failoverOnNetworkException(RetryPolicies.TRY_ONCE_THEN_FAIL,\n               config.maxFailoverAttempts, config.failoverSleepBaseMillis,\n               config.failoverSleepMaxMillis));\n+      \n+      Text dtService \u003d buildTokenServiceForLogicalUri(nameNodeUri);\n+      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n     }\n-    return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(\n      Configuration conf, URI nameNodeUri,\n      Class\u003cT\u003e xface) throws IOException {\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d\n        HAUtil.getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n\n    if (failoverProxyProviderClass \u003d\u003d null) {\n      // Non-HA case\n      return createNonHAProxy(conf, nameNodeUri, xface);\n    } else {\n      // HA case\n      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d HAUtil\n          .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface,\n              nameNodeUri);\n      Conf config \u003d new Conf(conf);\n      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n          .failoverOnNetworkException(RetryPolicies.TRY_ONCE_THEN_FAIL,\n              config.maxFailoverAttempts, config.failoverSleepBaseMillis,\n              config.failoverSleepMaxMillis));\n      \n      Text dtService \u003d buildTokenServiceForLogicalUri(nameNodeUri);\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
          "extendedDetails": {}
        }
      ]
    },
    "02919e61f6935813bc3dbe23cc89e00e0cb02918": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2367. Enable the configuration of multiple HA cluster addresses. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1233549 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/01/12 11:41 AM",
      "commitName": "02919e61f6935813bc3dbe23cc89e00e0cb02918",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "16/01/12 7:10 PM",
      "commitNameOld": "212678f036f4f96493bc14a584e758f97cf65573",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 2.69,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,16 @@\n   public static Object createFailoverProxy(Configuration conf, URI nameNodeUri,\n       Class xface) throws IOException {\n     Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass \u003d HAUtil\n         .getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n     if (failoverProxyProviderClass !\u003d null) {\n       FailoverProxyProvider\u003c?\u003e failoverProxyProvider \u003d HAUtil\n-          .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface);\n+          .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface,\n+              nameNodeUri);\n       Conf config \u003d new Conf(conf);\n       return RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n           .failoverOnNetworkException(RetryPolicies.TRY_ONCE_THEN_FAIL,\n               config.maxFailoverAttempts, config.failoverSleepBaseMillis,\n               config.failoverSleepMaxMillis));\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static Object createFailoverProxy(Configuration conf, URI nameNodeUri,\n      Class xface) throws IOException {\n    Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass \u003d HAUtil\n        .getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n    if (failoverProxyProviderClass !\u003d null) {\n      FailoverProxyProvider\u003c?\u003e failoverProxyProvider \u003d HAUtil\n          .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface,\n              nameNodeUri);\n      Conf config \u003d new Conf(conf);\n      return RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n          .failoverOnNetworkException(RetryPolicies.TRY_ONCE_THEN_FAIL,\n              config.maxFailoverAttempts, config.failoverSleepBaseMillis,\n              config.failoverSleepMaxMillis));\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
      "extendedDetails": {}
    },
    "212678f036f4f96493bc14a584e758f97cf65573": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2767. ConfiguredFailoverProxyProvider should support NameNodeProtocol. Contributed by Uma Maheswara Rao G.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1232284 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/01/12 7:10 PM",
      "commitName": "212678f036f4f96493bc14a584e758f97cf65573",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,15 @@\n+  public static Object createFailoverProxy(Configuration conf, URI nameNodeUri,\n+      Class xface) throws IOException {\n+    Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass \u003d HAUtil\n+        .getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n+    if (failoverProxyProviderClass !\u003d null) {\n+      FailoverProxyProvider\u003c?\u003e failoverProxyProvider \u003d HAUtil\n+          .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface);\n+      Conf config \u003d new Conf(conf);\n+      return RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n+          .failoverOnNetworkException(RetryPolicies.TRY_ONCE_THEN_FAIL,\n+              config.maxFailoverAttempts, config.failoverSleepBaseMillis,\n+              config.failoverSleepMaxMillis));\n+    }\n+    return null;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static Object createFailoverProxy(Configuration conf, URI nameNodeUri,\n      Class xface) throws IOException {\n    Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass \u003d HAUtil\n        .getFailoverProxyProviderClass(conf, nameNodeUri, xface);\n    if (failoverProxyProviderClass !\u003d null) {\n      FailoverProxyProvider\u003c?\u003e failoverProxyProvider \u003d HAUtil\n          .createFailoverProxyProvider(conf, failoverProxyProviderClass, xface);\n      Conf config \u003d new Conf(conf);\n      return RetryProxy.create(xface, failoverProxyProvider, RetryPolicies\n          .failoverOnNetworkException(RetryPolicies.TRY_ONCE_THEN_FAIL,\n              config.maxFailoverAttempts, config.failoverSleepBaseMillis,\n              config.failoverSleepMaxMillis));\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java"
    }
  }
}