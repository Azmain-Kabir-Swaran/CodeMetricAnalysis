{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "findAndMarkBlockAsCorrupt",
  "functionId": "findAndMarkBlockAsCorrupt___blk-ExtendedBlock(modifiers-final)__dn-DatanodeInfo(modifiers-final)__storageID-String__reason-String",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 1768,
  "functionEndLine": 1804,
  "numCommitsSeen": 477,
  "timeTaken": 15222,
  "changeHistory": [
    "6243eabb48390fffada2418ade5adf9e0766afbe",
    "663eba0ab1c73b45f98e46ffc87ad8fd91584046",
    "d311a38a6b32bbb210bd8748cfb65463e9c0740e",
    "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5",
    "4928f5473394981829e5ffd4b16ea0801baf5c45",
    "ba9371492036983a9899398907ab41fe548f29b3",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
    "3ae38ec7dfa1aaf451cf889cec6cf862379af32a",
    "45db4d204b796eee6dd0e39d3cc94b70c47028d4",
    "be01103af7e60fededeb76fa60776edc3f7018fa"
  ],
  "changeHistoryShort": {
    "6243eabb48390fffada2418ade5adf9e0766afbe": "Ybodychange",
    "663eba0ab1c73b45f98e46ffc87ad8fd91584046": "Ybodychange",
    "d311a38a6b32bbb210bd8748cfb65463e9c0740e": "Ybodychange",
    "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5": "Ybodychange",
    "4928f5473394981829e5ffd4b16ea0801baf5c45": "Ybodychange",
    "ba9371492036983a9899398907ab41fe548f29b3": "Ybodychange",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": "Ybodychange",
    "3ae38ec7dfa1aaf451cf889cec6cf862379af32a": "Ybodychange",
    "45db4d204b796eee6dd0e39d3cc94b70c47028d4": "Ybodychange",
    "be01103af7e60fededeb76fa60776edc3f7018fa": "Ybodychange"
  },
  "changeHistoryDetails": {
    "6243eabb48390fffada2418ade5adf9e0766afbe": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9958. BlockManager#createLocatedBlocks can throw NPE for corruptBlocks on failed storages. Contributed by Kuhu Shukla\n",
      "commitDate": "28/04/16 10:44 AM",
      "commitName": "6243eabb48390fffada2418ade5adf9e0766afbe",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "27/04/16 2:22 PM",
      "commitNameOld": "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 0.85,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,37 @@\n   public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n       final DatanodeInfo dn, String storageID, String reason) throws IOException {\n     assert namesystem.hasWriteLock();\n     final Block reportedBlock \u003d blk.getLocalBlock();\n     final BlockInfo storedBlock \u003d getStoredBlock(reportedBlock);\n     if (storedBlock \u003d\u003d null) {\n       // Check if the replica is in the blockMap, if not\n       // ignore the request for now. This could happen when BlockScanner\n       // thread of Datanode reports bad block before Block reports are sent\n       // by the Datanode on startup\n       blockLog.debug(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found\", blk);\n       return;\n     }\n \n     DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n     if (node \u003d\u003d null) {\n       throw new IOException(\"Cannot mark \" + blk\n           + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n           + \") does not exist\");\n     }\n-    \n+    DatanodeStorageInfo storage \u003d null;\n+    if (storageID !\u003d null) {\n+      storage \u003d node.getStorageInfo(storageID);\n+    }\n+    if (storage \u003d\u003d null) {\n+      storage \u003d storedBlock.findStorageInfo(node);\n+    }\n+\n+    if (storage \u003d\u003d null) {\n+      blockLog.debug(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found on {}\",\n+          blk, dn);\n+      return;\n+    }\n     markBlockAsCorrupt(new BlockToMarkCorrupt(reportedBlock, storedBlock,\n             blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n-        storageID \u003d\u003d null ? null : node.getStorageInfo(storageID),\n-        node);\n+        storage, node);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n      final DatanodeInfo dn, String storageID, String reason) throws IOException {\n    assert namesystem.hasWriteLock();\n    final Block reportedBlock \u003d blk.getLocalBlock();\n    final BlockInfo storedBlock \u003d getStoredBlock(reportedBlock);\n    if (storedBlock \u003d\u003d null) {\n      // Check if the replica is in the blockMap, if not\n      // ignore the request for now. This could happen when BlockScanner\n      // thread of Datanode reports bad block before Block reports are sent\n      // by the Datanode on startup\n      blockLog.debug(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found\", blk);\n      return;\n    }\n\n    DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n    if (node \u003d\u003d null) {\n      throw new IOException(\"Cannot mark \" + blk\n          + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n          + \") does not exist\");\n    }\n    DatanodeStorageInfo storage \u003d null;\n    if (storageID !\u003d null) {\n      storage \u003d node.getStorageInfo(storageID);\n    }\n    if (storage \u003d\u003d null) {\n      storage \u003d storedBlock.findStorageInfo(node);\n    }\n\n    if (storage \u003d\u003d null) {\n      blockLog.debug(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found on {}\",\n          blk, dn);\n      return;\n    }\n    markBlockAsCorrupt(new BlockToMarkCorrupt(reportedBlock, storedBlock,\n            blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n        storage, node);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "663eba0ab1c73b45f98e46ffc87ad8fd91584046": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-8623. Refactor NameNode handling of invalid, corrupt, and under-recovery blocks. Contributed by Zhe Zhang.\"\n\nThis reverts commit de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5.\n",
      "commitDate": "06/08/15 10:21 AM",
      "commitName": "663eba0ab1c73b45f98e46ffc87ad8fd91584046",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "31/07/15 4:15 PM",
      "commitNameOld": "d311a38a6b32bbb210bd8748cfb65463e9c0740e",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 5.75,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,25 @@\n   public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n       final DatanodeInfo dn, String storageID, String reason) throws IOException {\n     assert namesystem.hasWriteLock();\n-    final Block reportedBlock \u003d blk.getLocalBlock();\n-    final BlockInfo storedBlock \u003d getStoredBlock(reportedBlock);\n+    final BlockInfo storedBlock \u003d getStoredBlock(blk.getLocalBlock());\n     if (storedBlock \u003d\u003d null) {\n       // Check if the replica is in the blockMap, if not\n       // ignore the request for now. This could happen when BlockScanner\n       // thread of Datanode reports bad block before Block reports are sent\n       // by the Datanode on startup\n       blockLog.debug(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found\", blk);\n       return;\n     }\n \n     DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n     if (node \u003d\u003d null) {\n       throw new IOException(\"Cannot mark \" + blk\n           + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n           + \") does not exist\");\n     }\n-\n-    markBlockAsCorrupt(new BlockToMarkCorrupt(reportedBlock, storedBlock,\n+    \n+    markBlockAsCorrupt(new BlockToMarkCorrupt(storedBlock,\n             blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n         storageID \u003d\u003d null ? null : node.getStorageInfo(storageID),\n         node);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n      final DatanodeInfo dn, String storageID, String reason) throws IOException {\n    assert namesystem.hasWriteLock();\n    final BlockInfo storedBlock \u003d getStoredBlock(blk.getLocalBlock());\n    if (storedBlock \u003d\u003d null) {\n      // Check if the replica is in the blockMap, if not\n      // ignore the request for now. This could happen when BlockScanner\n      // thread of Datanode reports bad block before Block reports are sent\n      // by the Datanode on startup\n      blockLog.debug(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found\", blk);\n      return;\n    }\n\n    DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n    if (node \u003d\u003d null) {\n      throw new IOException(\"Cannot mark \" + blk\n          + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n          + \") does not exist\");\n    }\n    \n    markBlockAsCorrupt(new BlockToMarkCorrupt(storedBlock,\n            blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n        storageID \u003d\u003d null ? null : node.getStorageInfo(storageID),\n        node);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "d311a38a6b32bbb210bd8748cfb65463e9c0740e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6860. BlockStateChange logs are too noisy. Contributed by Chang Li and Xiaoyu Yao.\n",
      "commitDate": "31/07/15 4:15 PM",
      "commitName": "d311a38a6b32bbb210bd8748cfb65463e9c0740e",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "29/07/15 12:48 AM",
      "commitNameOld": "2a1d656196cf9750fa482cb10893684e8a2ce7c3",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 2.64,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,26 @@\n   public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n       final DatanodeInfo dn, String storageID, String reason) throws IOException {\n     assert namesystem.hasWriteLock();\n     final Block reportedBlock \u003d blk.getLocalBlock();\n     final BlockInfo storedBlock \u003d getStoredBlock(reportedBlock);\n     if (storedBlock \u003d\u003d null) {\n       // Check if the replica is in the blockMap, if not\n       // ignore the request for now. This could happen when BlockScanner\n       // thread of Datanode reports bad block before Block reports are sent\n       // by the Datanode on startup\n-      blockLog.info(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found\", blk);\n+      blockLog.debug(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found\", blk);\n       return;\n     }\n \n     DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n     if (node \u003d\u003d null) {\n       throw new IOException(\"Cannot mark \" + blk\n           + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n           + \") does not exist\");\n     }\n \n     markBlockAsCorrupt(new BlockToMarkCorrupt(reportedBlock, storedBlock,\n             blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n         storageID \u003d\u003d null ? null : node.getStorageInfo(storageID),\n         node);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n      final DatanodeInfo dn, String storageID, String reason) throws IOException {\n    assert namesystem.hasWriteLock();\n    final Block reportedBlock \u003d blk.getLocalBlock();\n    final BlockInfo storedBlock \u003d getStoredBlock(reportedBlock);\n    if (storedBlock \u003d\u003d null) {\n      // Check if the replica is in the blockMap, if not\n      // ignore the request for now. This could happen when BlockScanner\n      // thread of Datanode reports bad block before Block reports are sent\n      // by the Datanode on startup\n      blockLog.debug(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found\", blk);\n      return;\n    }\n\n    DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n    if (node \u003d\u003d null) {\n      throw new IOException(\"Cannot mark \" + blk\n          + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n          + \") does not exist\");\n    }\n\n    markBlockAsCorrupt(new BlockToMarkCorrupt(reportedBlock, storedBlock,\n            blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n        storageID \u003d\u003d null ? null : node.getStorageInfo(storageID),\n        node);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8623. Refactor NameNode handling of invalid, corrupt, and under-recovery blocks. Contributed by Zhe Zhang.\n",
      "commitDate": "26/06/15 10:49 AM",
      "commitName": "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "24/06/15 2:42 PM",
      "commitNameOld": "afe9ea3c12e1f5a71922400eadb642960bc87ca1",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 1.84,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,26 @@\n   public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n       final DatanodeInfo dn, String storageID, String reason) throws IOException {\n     assert namesystem.hasWriteLock();\n-    final BlockInfo storedBlock \u003d getStoredBlock(blk.getLocalBlock());\n+    final Block reportedBlock \u003d blk.getLocalBlock();\n+    final BlockInfo storedBlock \u003d getStoredBlock(reportedBlock);\n     if (storedBlock \u003d\u003d null) {\n       // Check if the replica is in the blockMap, if not\n       // ignore the request for now. This could happen when BlockScanner\n       // thread of Datanode reports bad block before Block reports are sent\n       // by the Datanode on startup\n       blockLog.info(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found\", blk);\n       return;\n     }\n \n     DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n     if (node \u003d\u003d null) {\n       throw new IOException(\"Cannot mark \" + blk\n           + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n           + \") does not exist\");\n     }\n-    \n-    markBlockAsCorrupt(new BlockToMarkCorrupt(storedBlock,\n+\n+    markBlockAsCorrupt(new BlockToMarkCorrupt(reportedBlock, storedBlock,\n             blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n         storageID \u003d\u003d null ? null : node.getStorageInfo(storageID),\n         node);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n      final DatanodeInfo dn, String storageID, String reason) throws IOException {\n    assert namesystem.hasWriteLock();\n    final Block reportedBlock \u003d blk.getLocalBlock();\n    final BlockInfo storedBlock \u003d getStoredBlock(reportedBlock);\n    if (storedBlock \u003d\u003d null) {\n      // Check if the replica is in the blockMap, if not\n      // ignore the request for now. This could happen when BlockScanner\n      // thread of Datanode reports bad block before Block reports are sent\n      // by the Datanode on startup\n      blockLog.info(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found\", blk);\n      return;\n    }\n\n    DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n    if (node \u003d\u003d null) {\n      throw new IOException(\"Cannot mark \" + blk\n          + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n          + \") does not exist\");\n    }\n\n    markBlockAsCorrupt(new BlockToMarkCorrupt(reportedBlock, storedBlock,\n            blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n        storageID \u003d\u003d null ? null : node.getStorageInfo(storageID),\n        node);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "4928f5473394981829e5ffd4b16ea0801baf5c45": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8482. Rename BlockInfoContiguous to BlockInfo. Contributed by Zhe Zhang.\n",
      "commitDate": "27/05/15 3:42 PM",
      "commitName": "4928f5473394981829e5ffd4b16ea0801baf5c45",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "19/05/15 11:05 AM",
      "commitNameOld": "8860e352c394372e4eb3ebdf82ea899567f34e4e",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 8.19,
      "commitsBetweenForRepo": 52,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,25 @@\n   public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n       final DatanodeInfo dn, String storageID, String reason) throws IOException {\n     assert namesystem.hasWriteLock();\n-    final BlockInfoContiguous storedBlock \u003d getStoredBlock(blk.getLocalBlock());\n+    final BlockInfo storedBlock \u003d getStoredBlock(blk.getLocalBlock());\n     if (storedBlock \u003d\u003d null) {\n       // Check if the replica is in the blockMap, if not\n       // ignore the request for now. This could happen when BlockScanner\n       // thread of Datanode reports bad block before Block reports are sent\n       // by the Datanode on startup\n       blockLog.info(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found\", blk);\n       return;\n     }\n \n     DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n     if (node \u003d\u003d null) {\n       throw new IOException(\"Cannot mark \" + blk\n           + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n           + \") does not exist\");\n     }\n     \n     markBlockAsCorrupt(new BlockToMarkCorrupt(storedBlock,\n             blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n         storageID \u003d\u003d null ? null : node.getStorageInfo(storageID),\n         node);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n      final DatanodeInfo dn, String storageID, String reason) throws IOException {\n    assert namesystem.hasWriteLock();\n    final BlockInfo storedBlock \u003d getStoredBlock(blk.getLocalBlock());\n    if (storedBlock \u003d\u003d null) {\n      // Check if the replica is in the blockMap, if not\n      // ignore the request for now. This could happen when BlockScanner\n      // thread of Datanode reports bad block before Block reports are sent\n      // by the Datanode on startup\n      blockLog.info(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found\", blk);\n      return;\n    }\n\n    DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n    if (node \u003d\u003d null) {\n      throw new IOException(\"Cannot mark \" + blk\n          + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n          + \") does not exist\");\n    }\n    \n    markBlockAsCorrupt(new BlockToMarkCorrupt(storedBlock,\n            blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n        storageID \u003d\u003d null ? null : node.getStorageInfo(storageID),\n        node);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "ba9371492036983a9899398907ab41fe548f29b3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7716. Erasure Coding: extend BlockInfo to handle EC info. Contributed by Jing Zhao.\n",
      "commitDate": "26/05/15 11:07 AM",
      "commitName": "ba9371492036983a9899398907ab41fe548f29b3",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "26/05/15 11:03 AM",
      "commitNameOld": "0c1da5a0300f015a7e39f2b40a73fb06c65a78c8",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,26 @@\n   public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n       final DatanodeInfo dn, String storageID, String reason) throws IOException {\n     assert namesystem.hasWriteLock();\n-    final BlockInfoContiguous storedBlock \u003d getStoredBlock(blk.getLocalBlock());\n+    final Block reportedBlock \u003d blk.getLocalBlock();\n+    final BlockInfo storedBlock \u003d getStoredBlock(reportedBlock);\n     if (storedBlock \u003d\u003d null) {\n       // Check if the replica is in the blockMap, if not\n       // ignore the request for now. This could happen when BlockScanner\n       // thread of Datanode reports bad block before Block reports are sent\n       // by the Datanode on startup\n       blockLog.info(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found\", blk);\n       return;\n     }\n \n     DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n     if (node \u003d\u003d null) {\n       throw new IOException(\"Cannot mark \" + blk\n           + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n           + \") does not exist\");\n     }\n     \n-    markBlockAsCorrupt(new BlockToMarkCorrupt(storedBlock,\n+    markBlockAsCorrupt(new BlockToMarkCorrupt(reportedBlock, storedBlock,\n             blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n         storageID \u003d\u003d null ? null : node.getStorageInfo(storageID),\n         node);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n      final DatanodeInfo dn, String storageID, String reason) throws IOException {\n    assert namesystem.hasWriteLock();\n    final Block reportedBlock \u003d blk.getLocalBlock();\n    final BlockInfo storedBlock \u003d getStoredBlock(reportedBlock);\n    if (storedBlock \u003d\u003d null) {\n      // Check if the replica is in the blockMap, if not\n      // ignore the request for now. This could happen when BlockScanner\n      // thread of Datanode reports bad block before Block reports are sent\n      // by the Datanode on startup\n      blockLog.info(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found\", blk);\n      return;\n    }\n\n    DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n    if (node \u003d\u003d null) {\n      throw new IOException(\"Cannot mark \" + blk\n          + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n          + \") does not exist\");\n    }\n    \n    markBlockAsCorrupt(new BlockToMarkCorrupt(reportedBlock, storedBlock,\n            blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n        storageID \u003d\u003d null ? null : node.getStorageInfo(storageID),\n        node);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7743. Code cleanup of BlockInfo and rename BlockInfo to BlockInfoContiguous. Contributed by Jing Zhao.\n",
      "commitDate": "08/02/15 11:51 AM",
      "commitName": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "04/02/15 11:31 AM",
      "commitNameOld": "9175105eeaecf0a1d60b57989b73ce45cee4689b",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 4.01,
      "commitsBetweenForRepo": 50,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,25 @@\n   public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n       final DatanodeInfo dn, String storageID, String reason) throws IOException {\n     assert namesystem.hasWriteLock();\n-    final BlockInfo storedBlock \u003d getStoredBlock(blk.getLocalBlock());\n+    final BlockInfoContiguous storedBlock \u003d getStoredBlock(blk.getLocalBlock());\n     if (storedBlock \u003d\u003d null) {\n       // Check if the replica is in the blockMap, if not\n       // ignore the request for now. This could happen when BlockScanner\n       // thread of Datanode reports bad block before Block reports are sent\n       // by the Datanode on startup\n       blockLog.info(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found\", blk);\n       return;\n     }\n \n     DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n     if (node \u003d\u003d null) {\n       throw new IOException(\"Cannot mark \" + blk\n           + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n           + \") does not exist\");\n     }\n     \n     markBlockAsCorrupt(new BlockToMarkCorrupt(storedBlock,\n             blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n         storageID \u003d\u003d null ? null : node.getStorageInfo(storageID),\n         node);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n      final DatanodeInfo dn, String storageID, String reason) throws IOException {\n    assert namesystem.hasWriteLock();\n    final BlockInfoContiguous storedBlock \u003d getStoredBlock(blk.getLocalBlock());\n    if (storedBlock \u003d\u003d null) {\n      // Check if the replica is in the blockMap, if not\n      // ignore the request for now. This could happen when BlockScanner\n      // thread of Datanode reports bad block before Block reports are sent\n      // by the Datanode on startup\n      blockLog.info(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found\", blk);\n      return;\n    }\n\n    DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n    if (node \u003d\u003d null) {\n      throw new IOException(\"Cannot mark \" + blk\n          + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n          + \") does not exist\");\n    }\n    \n    markBlockAsCorrupt(new BlockToMarkCorrupt(storedBlock,\n            blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n        storageID \u003d\u003d null ? null : node.getStorageInfo(storageID),\n        node);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "3ae38ec7dfa1aaf451cf889cec6cf862379af32a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7712. Switch blockStateChangeLog to use slf4j.\n",
      "commitDate": "03/02/15 3:01 PM",
      "commitName": "3ae38ec7dfa1aaf451cf889cec6cf862379af32a",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "30/01/15 11:33 AM",
      "commitNameOld": "951b3608a8cb1d9063b9be9c740b524c137b816f",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 4.14,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,25 @@\n   public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n       final DatanodeInfo dn, String storageID, String reason) throws IOException {\n     assert namesystem.hasWriteLock();\n     final BlockInfo storedBlock \u003d getStoredBlock(blk.getLocalBlock());\n     if (storedBlock \u003d\u003d null) {\n       // Check if the replica is in the blockMap, if not\n       // ignore the request for now. This could happen when BlockScanner\n       // thread of Datanode reports bad block before Block reports are sent\n       // by the Datanode on startup\n-      blockLog.info(\"BLOCK* findAndMarkBlockAsCorrupt: \"\n-          + blk + \" not found\");\n+      blockLog.info(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found\", blk);\n       return;\n     }\n \n     DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n     if (node \u003d\u003d null) {\n       throw new IOException(\"Cannot mark \" + blk\n           + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n           + \") does not exist\");\n     }\n     \n     markBlockAsCorrupt(new BlockToMarkCorrupt(storedBlock,\n             blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n         storageID \u003d\u003d null ? null : node.getStorageInfo(storageID),\n         node);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n      final DatanodeInfo dn, String storageID, String reason) throws IOException {\n    assert namesystem.hasWriteLock();\n    final BlockInfo storedBlock \u003d getStoredBlock(blk.getLocalBlock());\n    if (storedBlock \u003d\u003d null) {\n      // Check if the replica is in the blockMap, if not\n      // ignore the request for now. This could happen when BlockScanner\n      // thread of Datanode reports bad block before Block reports are sent\n      // by the Datanode on startup\n      blockLog.info(\"BLOCK* findAndMarkBlockAsCorrupt: {} not found\", blk);\n      return;\n    }\n\n    DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n    if (node \u003d\u003d null) {\n      throw new IOException(\"Cannot mark \" + blk\n          + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n          + \") does not exist\");\n    }\n    \n    markBlockAsCorrupt(new BlockToMarkCorrupt(storedBlock,\n            blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n        storageID \u003d\u003d null ? null : node.getStorageInfo(storageID),\n        node);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "45db4d204b796eee6dd0e39d3cc94b70c47028d4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6794. Update BlockManager methods to use DatanodeStorageInfo where possible. (Arpit Agarwal)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1615169 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/08/14 9:58 AM",
      "commitName": "45db4d204b796eee6dd0e39d3cc94b70c47028d4",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "31/07/14 6:05 PM",
      "commitNameOld": "b8597e6a10b2e8df1bee4e8ce0c8be345f7e007d",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.66,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,26 @@\n   public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n       final DatanodeInfo dn, String storageID, String reason) throws IOException {\n     assert namesystem.hasWriteLock();\n     final BlockInfo storedBlock \u003d getStoredBlock(blk.getLocalBlock());\n     if (storedBlock \u003d\u003d null) {\n       // Check if the replica is in the blockMap, if not\n       // ignore the request for now. This could happen when BlockScanner\n       // thread of Datanode reports bad block before Block reports are sent\n       // by the Datanode on startup\n       blockLog.info(\"BLOCK* findAndMarkBlockAsCorrupt: \"\n           + blk + \" not found\");\n       return;\n     }\n+\n+    DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n+    if (node \u003d\u003d null) {\n+      throw new IOException(\"Cannot mark \" + blk\n+          + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n+          + \") does not exist\");\n+    }\n+    \n     markBlockAsCorrupt(new BlockToMarkCorrupt(storedBlock,\n-        blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n-        dn, storageID);\n+            blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n+        storageID \u003d\u003d null ? null : node.getStorageInfo(storageID),\n+        node);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n      final DatanodeInfo dn, String storageID, String reason) throws IOException {\n    assert namesystem.hasWriteLock();\n    final BlockInfo storedBlock \u003d getStoredBlock(blk.getLocalBlock());\n    if (storedBlock \u003d\u003d null) {\n      // Check if the replica is in the blockMap, if not\n      // ignore the request for now. This could happen when BlockScanner\n      // thread of Datanode reports bad block before Block reports are sent\n      // by the Datanode on startup\n      blockLog.info(\"BLOCK* findAndMarkBlockAsCorrupt: \"\n          + blk + \" not found\");\n      return;\n    }\n\n    DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n    if (node \u003d\u003d null) {\n      throw new IOException(\"Cannot mark \" + blk\n          + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n          + \") does not exist\");\n    }\n    \n    markBlockAsCorrupt(new BlockToMarkCorrupt(storedBlock,\n            blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n        storageID \u003d\u003d null ? null : node.getStorageInfo(storageID),\n        node);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "be01103af7e60fededeb76fa60776edc3f7018fa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3493. Invalidate corrupted blocks as long as minimum replication is satisfied. Contributed by Juan Yu and Vinayakumar B.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1602291 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/14 2:06 PM",
      "commitName": "be01103af7e60fededeb76fa60776edc3f7018fa",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "02/06/14 5:47 PM",
      "commitNameOld": "a29d2d337164de59375aa45d4fbb9a431facade7",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 9.85,
      "commitsBetweenForRepo": 55,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,17 @@\n   public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n       final DatanodeInfo dn, String storageID, String reason) throws IOException {\n     assert namesystem.hasWriteLock();\n     final BlockInfo storedBlock \u003d getStoredBlock(blk.getLocalBlock());\n     if (storedBlock \u003d\u003d null) {\n       // Check if the replica is in the blockMap, if not\n       // ignore the request for now. This could happen when BlockScanner\n       // thread of Datanode reports bad block before Block reports are sent\n       // by the Datanode on startup\n       blockLog.info(\"BLOCK* findAndMarkBlockAsCorrupt: \"\n           + blk + \" not found\");\n       return;\n     }\n-    markBlockAsCorrupt(new BlockToMarkCorrupt(storedBlock, reason,\n-        Reason.CORRUPTION_REPORTED), dn, storageID);\n+    markBlockAsCorrupt(new BlockToMarkCorrupt(storedBlock,\n+        blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n+        dn, storageID);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n      final DatanodeInfo dn, String storageID, String reason) throws IOException {\n    assert namesystem.hasWriteLock();\n    final BlockInfo storedBlock \u003d getStoredBlock(blk.getLocalBlock());\n    if (storedBlock \u003d\u003d null) {\n      // Check if the replica is in the blockMap, if not\n      // ignore the request for now. This could happen when BlockScanner\n      // thread of Datanode reports bad block before Block reports are sent\n      // by the Datanode on startup\n      blockLog.info(\"BLOCK* findAndMarkBlockAsCorrupt: \"\n          + blk + \" not found\");\n      return;\n    }\n    markBlockAsCorrupt(new BlockToMarkCorrupt(storedBlock,\n        blk.getGenerationStamp(), reason, Reason.CORRUPTION_REPORTED),\n        dn, storageID);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    }
  }
}