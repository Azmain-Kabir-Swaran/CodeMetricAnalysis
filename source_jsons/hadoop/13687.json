{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPlacementPolicyDefault.java",
  "functionName": "chooseFromNextRack",
  "functionId": "chooseFromNextRack___next-Node__excludedNodes-Set__Node____blocksize-long__maxNodesPerRack-int__results-List__DatanodeStorageInfo____avoidStaleNodes-boolean__storageTypes-EnumMap__StorageType,Integer__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
  "functionStartLine": 718,
  "functionEndLine": 736,
  "numCommitsSeen": 99,
  "timeTaken": 2962,
  "changeHistory": [
    "f5ecc0bc080cb8a64c6d4632fc1c121f93d95c5e",
    "3a3566e1d1ab5f78cfb734796b41802fe039196d",
    "22a41dce4af4d5b533ba875b322551db1c152878"
  ],
  "changeHistoryShort": {
    "f5ecc0bc080cb8a64c6d4632fc1c121f93d95c5e": "Ybodychange",
    "3a3566e1d1ab5f78cfb734796b41802fe039196d": "Ybodychange",
    "22a41dce4af4d5b533ba875b322551db1c152878": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f5ecc0bc080cb8a64c6d4632fc1c121f93d95c5e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14103. Review Logging of BlockPlacementPolicyDefault. Contributed by David Mollitor.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "19/06/19 10:06 AM",
      "commitName": "f5ecc0bc080cb8a64c6d4632fc1c121f93d95c5e",
      "commitAuthor": "David Mollitor",
      "commitDateOld": "06/06/19 10:20 AM",
      "commitNameOld": "944adc61b1830388d520d4052fc7eb6c7ba2790d",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 12.99,
      "commitsBetweenForRepo": 103,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,19 @@\n   private DatanodeStorageInfo chooseFromNextRack(Node next,\n       Set\u003cNode\u003e excludedNodes,\n       long blocksize,\n       int maxNodesPerRack,\n       List\u003cDatanodeStorageInfo\u003e results,\n       boolean avoidStaleNodes,\n       EnumMap\u003cStorageType, Integer\u003e storageTypes) throws NotEnoughReplicasException {\n     final String nextRack \u003d next.getNetworkLocation();\n     try {\n       return chooseRandom(nextRack, excludedNodes, blocksize, maxNodesPerRack,\n           results, avoidStaleNodes, storageTypes);\n-    } catch(NotEnoughReplicasException e) {\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Failed to choose from the next rack (location \u003d \" + nextRack\n-            + \"), retry choosing randomly\", e);\n-      }\n-      //otherwise randomly choose one from the network\n+    } catch (NotEnoughReplicasException e) {\n+      LOG.debug(\"Failed to choose from the next rack (location \u003d {}), \"\n+          + \"retry choosing randomly\", nextRack, e);\n+        // otherwise randomly choose one from the network\n       return chooseRandom(NodeBase.ROOT, excludedNodes, blocksize,\n           maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private DatanodeStorageInfo chooseFromNextRack(Node next,\n      Set\u003cNode\u003e excludedNodes,\n      long blocksize,\n      int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results,\n      boolean avoidStaleNodes,\n      EnumMap\u003cStorageType, Integer\u003e storageTypes) throws NotEnoughReplicasException {\n    final String nextRack \u003d next.getNetworkLocation();\n    try {\n      return chooseRandom(nextRack, excludedNodes, blocksize, maxNodesPerRack,\n          results, avoidStaleNodes, storageTypes);\n    } catch (NotEnoughReplicasException e) {\n      LOG.debug(\"Failed to choose from the next rack (location \u003d {}), \"\n          + \"retry choosing randomly\", nextRack, e);\n        // otherwise randomly choose one from the network\n      return chooseRandom(NodeBase.ROOT, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "3a3566e1d1ab5f78cfb734796b41802fe039196d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12732. Correct spellings of ramdomly to randomly in log. Contributed by hu xiaodong.\n",
      "commitDate": "08/11/17 10:14 PM",
      "commitName": "3a3566e1d1ab5f78cfb734796b41802fe039196d",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "16/05/17 7:51 PM",
      "commitNameOld": "ec21ce425f4e5637be716406f9d0e038921550d7",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 176.14,
      "commitsBetweenForRepo": 1326,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   private DatanodeStorageInfo chooseFromNextRack(Node next,\n       Set\u003cNode\u003e excludedNodes,\n       long blocksize,\n       int maxNodesPerRack,\n       List\u003cDatanodeStorageInfo\u003e results,\n       boolean avoidStaleNodes,\n       EnumMap\u003cStorageType, Integer\u003e storageTypes) throws NotEnoughReplicasException {\n     final String nextRack \u003d next.getNetworkLocation();\n     try {\n       return chooseRandom(nextRack, excludedNodes, blocksize, maxNodesPerRack,\n           results, avoidStaleNodes, storageTypes);\n     } catch(NotEnoughReplicasException e) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Failed to choose from the next rack (location \u003d \" + nextRack\n-            + \"), retry choosing ramdomly\", e);\n+            + \"), retry choosing randomly\", e);\n       }\n       //otherwise randomly choose one from the network\n       return chooseRandom(NodeBase.ROOT, excludedNodes, blocksize,\n           maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private DatanodeStorageInfo chooseFromNextRack(Node next,\n      Set\u003cNode\u003e excludedNodes,\n      long blocksize,\n      int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results,\n      boolean avoidStaleNodes,\n      EnumMap\u003cStorageType, Integer\u003e storageTypes) throws NotEnoughReplicasException {\n    final String nextRack \u003d next.getNetworkLocation();\n    try {\n      return chooseRandom(nextRack, excludedNodes, blocksize, maxNodesPerRack,\n          results, avoidStaleNodes, storageTypes);\n    } catch(NotEnoughReplicasException e) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Failed to choose from the next rack (location \u003d \" + nextRack\n            + \"), retry choosing randomly\", e);\n      }\n      //otherwise randomly choose one from the network\n      return chooseRandom(NodeBase.ROOT, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "22a41dce4af4d5b533ba875b322551db1c152878": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6997: add more tests for data migration and replicaion.\n",
      "commitDate": "06/09/14 4:44 PM",
      "commitName": "22a41dce4af4d5b533ba875b322551db1c152878",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "diff": "@@ -0,0 +1,21 @@\n+  private DatanodeStorageInfo chooseFromNextRack(Node next,\n+      Set\u003cNode\u003e excludedNodes,\n+      long blocksize,\n+      int maxNodesPerRack,\n+      List\u003cDatanodeStorageInfo\u003e results,\n+      boolean avoidStaleNodes,\n+      EnumMap\u003cStorageType, Integer\u003e storageTypes) throws NotEnoughReplicasException {\n+    final String nextRack \u003d next.getNetworkLocation();\n+    try {\n+      return chooseRandom(nextRack, excludedNodes, blocksize, maxNodesPerRack,\n+          results, avoidStaleNodes, storageTypes);\n+    } catch(NotEnoughReplicasException e) {\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Failed to choose from the next rack (location \u003d \" + nextRack\n+            + \"), retry choosing ramdomly\", e);\n+      }\n+      //otherwise randomly choose one from the network\n+      return chooseRandom(NodeBase.ROOT, excludedNodes, blocksize,\n+          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private DatanodeStorageInfo chooseFromNextRack(Node next,\n      Set\u003cNode\u003e excludedNodes,\n      long blocksize,\n      int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results,\n      boolean avoidStaleNodes,\n      EnumMap\u003cStorageType, Integer\u003e storageTypes) throws NotEnoughReplicasException {\n    final String nextRack \u003d next.getNetworkLocation();\n    try {\n      return chooseRandom(nextRack, excludedNodes, blocksize, maxNodesPerRack,\n          results, avoidStaleNodes, storageTypes);\n    } catch(NotEnoughReplicasException e) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Failed to choose from the next rack (location \u003d \" + nextRack\n            + \"), retry choosing ramdomly\", e);\n      }\n      //otherwise randomly choose one from the network\n      return chooseRandom(NodeBase.ROOT, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java"
    }
  }
}