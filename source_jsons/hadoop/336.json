{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSStripedInputStream.java",
  "functionName": "readWithStrategy",
  "functionId": "readWithStrategy___strategy-ReaderStrategy",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
  "functionStartLine": 390,
  "functionEndLine": 431,
  "numCommitsSeen": 37,
  "timeTaken": 2009,
  "changeHistory": [
    "960940e0e08f7839775f2d8a352b444d104d36b4",
    "6eba79232f36b36e0196163adc8fe4219a6b6bf9",
    "793447f79924c97c2b562d5e41fa85adf19673fe",
    "cd8b6889a74a949e37f4b2eb664cdf3b59bfb93b",
    "8808779db351fe444388d4acb3094766b5980718",
    "95363bcc7dae28ba9ae2cd7ee9a258fcb58cd932"
  ],
  "changeHistoryShort": {
    "960940e0e08f7839775f2d8a352b444d104d36b4": "Ybodychange",
    "6eba79232f36b36e0196163adc8fe4219a6b6bf9": "Ybodychange",
    "793447f79924c97c2b562d5e41fa85adf19673fe": "Ymultichange(Yparameterchange,Ybodychange)",
    "cd8b6889a74a949e37f4b2eb664cdf3b59bfb93b": "Ybodychange",
    "8808779db351fe444388d4acb3094766b5980718": "Ybodychange",
    "95363bcc7dae28ba9ae2cd7ee9a258fcb58cd932": "Ybodychange"
  },
  "changeHistoryDetails": {
    "960940e0e08f7839775f2d8a352b444d104d36b4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13539. DFSStripedInputStream NPE when reportCheckSumFailure.\n",
      "commitDate": "14/05/18 9:28 AM",
      "commitName": "960940e0e08f7839775f2d8a352b444d104d36b4",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "26/04/18 1:54 PM",
      "commitNameOld": "a8e428b2dc0883184b43cb776d5c7196aaa3bf56",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 17.82,
      "commitsBetweenForRepo": 135,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,42 +1,42 @@\n   protected synchronized int readWithStrategy(ReaderStrategy strategy)\n       throws IOException {\n     dfsClient.checkOpen();\n     if (closed.get()) {\n       throw new IOException(\"Stream closed\");\n     }\n \n     int len \u003d strategy.getTargetLength();\n     CorruptedBlocks corruptedBlocks \u003d new CorruptedBlocks();\n     if (pos \u003c getFileLength()) {\n       try {\n         if (pos \u003e blockEnd) {\n           blockSeekTo(pos);\n         }\n         int realLen \u003d (int) Math.min(len, (blockEnd - pos + 1L));\n         synchronized (infoLock) {\n           if (locatedBlocks.isLastBlockComplete()) {\n             realLen \u003d (int) Math.min(realLen,\n                 locatedBlocks.getFileLength() - pos);\n           }\n         }\n \n         /** Number of bytes already read into buffer */\n         int result \u003d 0;\n         while (result \u003c realLen) {\n           if (!curStripeRange.include(getOffsetInBlockGroup())) {\n             readOneStripe(corruptedBlocks);\n           }\n           int ret \u003d copyToTargetBuf(strategy, realLen - result);\n           result +\u003d ret;\n           pos +\u003d ret;\n         }\n         return result;\n       } finally {\n         // Check if need to report block replicas corruption either read\n         // was successful or ChecksumException occurred.\n-        reportCheckSumFailure(corruptedBlocks,\n-            currentLocatedBlock.getLocations().length, true);\n+        reportCheckSumFailure(corruptedBlocks, getCurrentBlockLocationsLength(),\n+            true);\n       }\n     }\n     return -1;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized int readWithStrategy(ReaderStrategy strategy)\n      throws IOException {\n    dfsClient.checkOpen();\n    if (closed.get()) {\n      throw new IOException(\"Stream closed\");\n    }\n\n    int len \u003d strategy.getTargetLength();\n    CorruptedBlocks corruptedBlocks \u003d new CorruptedBlocks();\n    if (pos \u003c getFileLength()) {\n      try {\n        if (pos \u003e blockEnd) {\n          blockSeekTo(pos);\n        }\n        int realLen \u003d (int) Math.min(len, (blockEnd - pos + 1L));\n        synchronized (infoLock) {\n          if (locatedBlocks.isLastBlockComplete()) {\n            realLen \u003d (int) Math.min(realLen,\n                locatedBlocks.getFileLength() - pos);\n          }\n        }\n\n        /** Number of bytes already read into buffer */\n        int result \u003d 0;\n        while (result \u003c realLen) {\n          if (!curStripeRange.include(getOffsetInBlockGroup())) {\n            readOneStripe(corruptedBlocks);\n          }\n          int ret \u003d copyToTargetBuf(strategy, realLen - result);\n          result +\u003d ret;\n          pos +\u003d ret;\n        }\n        return result;\n      } finally {\n        // Check if need to report block replicas corruption either read\n        // was successful or ChecksumException occurred.\n        reportCheckSumFailure(corruptedBlocks, getCurrentBlockLocationsLength(),\n            true);\n      }\n    }\n    return -1;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
      "extendedDetails": {}
    },
    "6eba79232f36b36e0196163adc8fe4219a6b6bf9": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14271. Correct spelling of \u0027occurred\u0027 and variants. Contributed by Yeliang Cang\n",
      "commitDate": "03/04/17 8:13 PM",
      "commitName": "6eba79232f36b36e0196163adc8fe4219a6b6bf9",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "28/03/17 11:11 PM",
      "commitNameOld": "84d787b9d51196010495d51dc5ebf66c01c340ab",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 5.88,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,42 +1,42 @@\n   protected synchronized int readWithStrategy(ReaderStrategy strategy)\n       throws IOException {\n     dfsClient.checkOpen();\n     if (closed.get()) {\n       throw new IOException(\"Stream closed\");\n     }\n \n     int len \u003d strategy.getTargetLength();\n     CorruptedBlocks corruptedBlocks \u003d new CorruptedBlocks();\n     if (pos \u003c getFileLength()) {\n       try {\n         if (pos \u003e blockEnd) {\n           blockSeekTo(pos);\n         }\n         int realLen \u003d (int) Math.min(len, (blockEnd - pos + 1L));\n         synchronized (infoLock) {\n           if (locatedBlocks.isLastBlockComplete()) {\n             realLen \u003d (int) Math.min(realLen,\n                 locatedBlocks.getFileLength() - pos);\n           }\n         }\n \n         /** Number of bytes already read into buffer */\n         int result \u003d 0;\n         while (result \u003c realLen) {\n           if (!curStripeRange.include(getOffsetInBlockGroup())) {\n             readOneStripe(corruptedBlocks);\n           }\n           int ret \u003d copyToTargetBuf(strategy, realLen - result);\n           result +\u003d ret;\n           pos +\u003d ret;\n         }\n         return result;\n       } finally {\n         // Check if need to report block replicas corruption either read\n-        // was successful or ChecksumException occured.\n+        // was successful or ChecksumException occurred.\n         reportCheckSumFailure(corruptedBlocks,\n             currentLocatedBlock.getLocations().length, true);\n       }\n     }\n     return -1;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized int readWithStrategy(ReaderStrategy strategy)\n      throws IOException {\n    dfsClient.checkOpen();\n    if (closed.get()) {\n      throw new IOException(\"Stream closed\");\n    }\n\n    int len \u003d strategy.getTargetLength();\n    CorruptedBlocks corruptedBlocks \u003d new CorruptedBlocks();\n    if (pos \u003c getFileLength()) {\n      try {\n        if (pos \u003e blockEnd) {\n          blockSeekTo(pos);\n        }\n        int realLen \u003d (int) Math.min(len, (blockEnd - pos + 1L));\n        synchronized (infoLock) {\n          if (locatedBlocks.isLastBlockComplete()) {\n            realLen \u003d (int) Math.min(realLen,\n                locatedBlocks.getFileLength() - pos);\n          }\n        }\n\n        /** Number of bytes already read into buffer */\n        int result \u003d 0;\n        while (result \u003c realLen) {\n          if (!curStripeRange.include(getOffsetInBlockGroup())) {\n            readOneStripe(corruptedBlocks);\n          }\n          int ret \u003d copyToTargetBuf(strategy, realLen - result);\n          result +\u003d ret;\n          pos +\u003d ret;\n        }\n        return result;\n      } finally {\n        // Check if need to report block replicas corruption either read\n        // was successful or ChecksumException occurred.\n        reportCheckSumFailure(corruptedBlocks,\n            currentLocatedBlock.getLocations().length, true);\n      }\n    }\n    return -1;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
      "extendedDetails": {}
    },
    "793447f79924c97c2b562d5e41fa85adf19673fe": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-8905. Refactor DFSInputStream#ReaderStrategy. Contributed by Kai Zheng and Sammi Chen\n",
      "commitDate": "24/08/16 6:57 AM",
      "commitName": "793447f79924c97c2b562d5e41fa85adf19673fe",
      "commitAuthor": "Kai Zheng",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-8905. Refactor DFSInputStream#ReaderStrategy. Contributed by Kai Zheng and Sammi Chen\n",
          "commitDate": "24/08/16 6:57 AM",
          "commitName": "793447f79924c97c2b562d5e41fa85adf19673fe",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "12/08/16 10:52 PM",
          "commitNameOld": "b5af9be72c72734d668f817c99d889031922a951",
          "commitAuthorOld": "Kai Zheng",
          "daysBetweenCommits": 11.34,
          "commitsBetweenForRepo": 76,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,42 @@\n-  protected synchronized int readWithStrategy(ReaderStrategy strategy,\n-      int off, int len) throws IOException {\n+  protected synchronized int readWithStrategy(ReaderStrategy strategy)\n+      throws IOException {\n     dfsClient.checkOpen();\n     if (closed.get()) {\n       throw new IOException(\"Stream closed\");\n     }\n \n+    int len \u003d strategy.getTargetLength();\n     CorruptedBlocks corruptedBlocks \u003d new CorruptedBlocks();\n     if (pos \u003c getFileLength()) {\n       try {\n         if (pos \u003e blockEnd) {\n           blockSeekTo(pos);\n         }\n         int realLen \u003d (int) Math.min(len, (blockEnd - pos + 1L));\n         synchronized (infoLock) {\n           if (locatedBlocks.isLastBlockComplete()) {\n             realLen \u003d (int) Math.min(realLen,\n                 locatedBlocks.getFileLength() - pos);\n           }\n         }\n \n         /** Number of bytes already read into buffer */\n         int result \u003d 0;\n         while (result \u003c realLen) {\n           if (!curStripeRange.include(getOffsetInBlockGroup())) {\n             readOneStripe(corruptedBlocks);\n           }\n-          int ret \u003d copyToTargetBuf(strategy, off + result, realLen - result);\n+          int ret \u003d copyToTargetBuf(strategy, realLen - result);\n           result +\u003d ret;\n           pos +\u003d ret;\n         }\n         return result;\n       } finally {\n         // Check if need to report block replicas corruption either read\n         // was successful or ChecksumException occured.\n         reportCheckSumFailure(corruptedBlocks,\n             currentLocatedBlock.getLocations().length, true);\n       }\n     }\n     return -1;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected synchronized int readWithStrategy(ReaderStrategy strategy)\n      throws IOException {\n    dfsClient.checkOpen();\n    if (closed.get()) {\n      throw new IOException(\"Stream closed\");\n    }\n\n    int len \u003d strategy.getTargetLength();\n    CorruptedBlocks corruptedBlocks \u003d new CorruptedBlocks();\n    if (pos \u003c getFileLength()) {\n      try {\n        if (pos \u003e blockEnd) {\n          blockSeekTo(pos);\n        }\n        int realLen \u003d (int) Math.min(len, (blockEnd - pos + 1L));\n        synchronized (infoLock) {\n          if (locatedBlocks.isLastBlockComplete()) {\n            realLen \u003d (int) Math.min(realLen,\n                locatedBlocks.getFileLength() - pos);\n          }\n        }\n\n        /** Number of bytes already read into buffer */\n        int result \u003d 0;\n        while (result \u003c realLen) {\n          if (!curStripeRange.include(getOffsetInBlockGroup())) {\n            readOneStripe(corruptedBlocks);\n          }\n          int ret \u003d copyToTargetBuf(strategy, realLen - result);\n          result +\u003d ret;\n          pos +\u003d ret;\n        }\n        return result;\n      } finally {\n        // Check if need to report block replicas corruption either read\n        // was successful or ChecksumException occured.\n        reportCheckSumFailure(corruptedBlocks,\n            currentLocatedBlock.getLocations().length, true);\n      }\n    }\n    return -1;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
          "extendedDetails": {
            "oldValue": "[strategy-ReaderStrategy, off-int, len-int]",
            "newValue": "[strategy-ReaderStrategy]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8905. Refactor DFSInputStream#ReaderStrategy. Contributed by Kai Zheng and Sammi Chen\n",
          "commitDate": "24/08/16 6:57 AM",
          "commitName": "793447f79924c97c2b562d5e41fa85adf19673fe",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "12/08/16 10:52 PM",
          "commitNameOld": "b5af9be72c72734d668f817c99d889031922a951",
          "commitAuthorOld": "Kai Zheng",
          "daysBetweenCommits": 11.34,
          "commitsBetweenForRepo": 76,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,42 @@\n-  protected synchronized int readWithStrategy(ReaderStrategy strategy,\n-      int off, int len) throws IOException {\n+  protected synchronized int readWithStrategy(ReaderStrategy strategy)\n+      throws IOException {\n     dfsClient.checkOpen();\n     if (closed.get()) {\n       throw new IOException(\"Stream closed\");\n     }\n \n+    int len \u003d strategy.getTargetLength();\n     CorruptedBlocks corruptedBlocks \u003d new CorruptedBlocks();\n     if (pos \u003c getFileLength()) {\n       try {\n         if (pos \u003e blockEnd) {\n           blockSeekTo(pos);\n         }\n         int realLen \u003d (int) Math.min(len, (blockEnd - pos + 1L));\n         synchronized (infoLock) {\n           if (locatedBlocks.isLastBlockComplete()) {\n             realLen \u003d (int) Math.min(realLen,\n                 locatedBlocks.getFileLength() - pos);\n           }\n         }\n \n         /** Number of bytes already read into buffer */\n         int result \u003d 0;\n         while (result \u003c realLen) {\n           if (!curStripeRange.include(getOffsetInBlockGroup())) {\n             readOneStripe(corruptedBlocks);\n           }\n-          int ret \u003d copyToTargetBuf(strategy, off + result, realLen - result);\n+          int ret \u003d copyToTargetBuf(strategy, realLen - result);\n           result +\u003d ret;\n           pos +\u003d ret;\n         }\n         return result;\n       } finally {\n         // Check if need to report block replicas corruption either read\n         // was successful or ChecksumException occured.\n         reportCheckSumFailure(corruptedBlocks,\n             currentLocatedBlock.getLocations().length, true);\n       }\n     }\n     return -1;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected synchronized int readWithStrategy(ReaderStrategy strategy)\n      throws IOException {\n    dfsClient.checkOpen();\n    if (closed.get()) {\n      throw new IOException(\"Stream closed\");\n    }\n\n    int len \u003d strategy.getTargetLength();\n    CorruptedBlocks corruptedBlocks \u003d new CorruptedBlocks();\n    if (pos \u003c getFileLength()) {\n      try {\n        if (pos \u003e blockEnd) {\n          blockSeekTo(pos);\n        }\n        int realLen \u003d (int) Math.min(len, (blockEnd - pos + 1L));\n        synchronized (infoLock) {\n          if (locatedBlocks.isLastBlockComplete()) {\n            realLen \u003d (int) Math.min(realLen,\n                locatedBlocks.getFileLength() - pos);\n          }\n        }\n\n        /** Number of bytes already read into buffer */\n        int result \u003d 0;\n        while (result \u003c realLen) {\n          if (!curStripeRange.include(getOffsetInBlockGroup())) {\n            readOneStripe(corruptedBlocks);\n          }\n          int ret \u003d copyToTargetBuf(strategy, realLen - result);\n          result +\u003d ret;\n          pos +\u003d ret;\n        }\n        return result;\n      } finally {\n        // Check if need to report block replicas corruption either read\n        // was successful or ChecksumException occured.\n        reportCheckSumFailure(corruptedBlocks,\n            currentLocatedBlock.getLocations().length, true);\n      }\n    }\n    return -1;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd8b6889a74a949e37f4b2eb664cdf3b59bfb93b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9579. Provide bytes-read-by-network-distance metrics at FileSystem.Statistics level (Ming Ma via sjlee)\n",
      "commitDate": "19/03/16 2:02 PM",
      "commitName": "cd8b6889a74a949e37f4b2eb664cdf3b59bfb93b",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "28/02/16 3:00 PM",
      "commitNameOld": "321a80c759e887f52bb4f40c49328527f04560a1",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 19.92,
      "commitsBetweenForRepo": 117,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,41 @@\n   protected synchronized int readWithStrategy(ReaderStrategy strategy,\n       int off, int len) throws IOException {\n     dfsClient.checkOpen();\n     if (closed.get()) {\n       throw new IOException(\"Stream closed\");\n     }\n \n     CorruptedBlocks corruptedBlocks \u003d new CorruptedBlocks();\n     if (pos \u003c getFileLength()) {\n       try {\n         if (pos \u003e blockEnd) {\n           blockSeekTo(pos);\n         }\n         int realLen \u003d (int) Math.min(len, (blockEnd - pos + 1L));\n         synchronized (infoLock) {\n           if (locatedBlocks.isLastBlockComplete()) {\n             realLen \u003d (int) Math.min(realLen,\n                 locatedBlocks.getFileLength() - pos);\n           }\n         }\n \n         /** Number of bytes already read into buffer */\n         int result \u003d 0;\n         while (result \u003c realLen) {\n           if (!curStripeRange.include(getOffsetInBlockGroup())) {\n             readOneStripe(corruptedBlocks);\n           }\n           int ret \u003d copyToTargetBuf(strategy, off + result, realLen - result);\n           result +\u003d ret;\n           pos +\u003d ret;\n         }\n-        if (dfsClient.stats !\u003d null) {\n-          dfsClient.stats.incrementBytesRead(result);\n-        }\n         return result;\n       } finally {\n         // Check if need to report block replicas corruption either read\n         // was successful or ChecksumException occured.\n         reportCheckSumFailure(corruptedBlocks,\n             currentLocatedBlock.getLocations().length, true);\n       }\n     }\n     return -1;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized int readWithStrategy(ReaderStrategy strategy,\n      int off, int len) throws IOException {\n    dfsClient.checkOpen();\n    if (closed.get()) {\n      throw new IOException(\"Stream closed\");\n    }\n\n    CorruptedBlocks corruptedBlocks \u003d new CorruptedBlocks();\n    if (pos \u003c getFileLength()) {\n      try {\n        if (pos \u003e blockEnd) {\n          blockSeekTo(pos);\n        }\n        int realLen \u003d (int) Math.min(len, (blockEnd - pos + 1L));\n        synchronized (infoLock) {\n          if (locatedBlocks.isLastBlockComplete()) {\n            realLen \u003d (int) Math.min(realLen,\n                locatedBlocks.getFileLength() - pos);\n          }\n        }\n\n        /** Number of bytes already read into buffer */\n        int result \u003d 0;\n        while (result \u003c realLen) {\n          if (!curStripeRange.include(getOffsetInBlockGroup())) {\n            readOneStripe(corruptedBlocks);\n          }\n          int ret \u003d copyToTargetBuf(strategy, off + result, realLen - result);\n          result +\u003d ret;\n          pos +\u003d ret;\n        }\n        return result;\n      } finally {\n        // Check if need to report block replicas corruption either read\n        // was successful or ChecksumException occured.\n        reportCheckSumFailure(corruptedBlocks,\n            currentLocatedBlock.getLocations().length, true);\n      }\n    }\n    return -1;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
      "extendedDetails": {}
    },
    "8808779db351fe444388d4acb3094766b5980718": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9734. Refactoring of checksum failure report related codes. Contributed by Kai Zheng.\n\nChange-Id: Ie69a77e3498a360959f8e213c51fb2b17c28b64a\n",
      "commitDate": "25/02/16 9:55 AM",
      "commitName": "8808779db351fe444388d4acb3094766b5980718",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "19/02/16 7:02 PM",
      "commitNameOld": "e54cc2931262bf49682a8323da9811976218c03b",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 5.62,
      "commitsBetweenForRepo": 38,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n   protected synchronized int readWithStrategy(ReaderStrategy strategy,\n       int off, int len) throws IOException {\n     dfsClient.checkOpen();\n     if (closed.get()) {\n       throw new IOException(\"Stream closed\");\n     }\n-    Map\u003cExtendedBlock, Set\u003cDatanodeInfo\u003e\u003e corruptedBlockMap \u003d\n-        new ConcurrentHashMap\u003c\u003e();\n+\n+    CorruptedBlocks corruptedBlocks \u003d new CorruptedBlocks();\n     if (pos \u003c getFileLength()) {\n       try {\n         if (pos \u003e blockEnd) {\n           blockSeekTo(pos);\n         }\n         int realLen \u003d (int) Math.min(len, (blockEnd - pos + 1L));\n         synchronized (infoLock) {\n           if (locatedBlocks.isLastBlockComplete()) {\n             realLen \u003d (int) Math.min(realLen,\n                 locatedBlocks.getFileLength() - pos);\n           }\n         }\n \n         /** Number of bytes already read into buffer */\n         int result \u003d 0;\n         while (result \u003c realLen) {\n           if (!curStripeRange.include(getOffsetInBlockGroup())) {\n-            readOneStripe(corruptedBlockMap);\n+            readOneStripe(corruptedBlocks);\n           }\n           int ret \u003d copyToTargetBuf(strategy, off + result, realLen - result);\n           result +\u003d ret;\n           pos +\u003d ret;\n         }\n         if (dfsClient.stats !\u003d null) {\n           dfsClient.stats.incrementBytesRead(result);\n         }\n         return result;\n       } finally {\n         // Check if need to report block replicas corruption either read\n         // was successful or ChecksumException occured.\n-        reportCheckSumFailure(corruptedBlockMap,\n+        reportCheckSumFailure(corruptedBlocks,\n             currentLocatedBlock.getLocations().length, true);\n       }\n     }\n     return -1;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized int readWithStrategy(ReaderStrategy strategy,\n      int off, int len) throws IOException {\n    dfsClient.checkOpen();\n    if (closed.get()) {\n      throw new IOException(\"Stream closed\");\n    }\n\n    CorruptedBlocks corruptedBlocks \u003d new CorruptedBlocks();\n    if (pos \u003c getFileLength()) {\n      try {\n        if (pos \u003e blockEnd) {\n          blockSeekTo(pos);\n        }\n        int realLen \u003d (int) Math.min(len, (blockEnd - pos + 1L));\n        synchronized (infoLock) {\n          if (locatedBlocks.isLastBlockComplete()) {\n            realLen \u003d (int) Math.min(realLen,\n                locatedBlocks.getFileLength() - pos);\n          }\n        }\n\n        /** Number of bytes already read into buffer */\n        int result \u003d 0;\n        while (result \u003c realLen) {\n          if (!curStripeRange.include(getOffsetInBlockGroup())) {\n            readOneStripe(corruptedBlocks);\n          }\n          int ret \u003d copyToTargetBuf(strategy, off + result, realLen - result);\n          result +\u003d ret;\n          pos +\u003d ret;\n        }\n        if (dfsClient.stats !\u003d null) {\n          dfsClient.stats.incrementBytesRead(result);\n        }\n        return result;\n      } finally {\n        // Check if need to report block replicas corruption either read\n        // was successful or ChecksumException occured.\n        reportCheckSumFailure(corruptedBlocks,\n            currentLocatedBlock.getLocations().length, true);\n      }\n    }\n    return -1;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
      "extendedDetails": {}
    },
    "95363bcc7dae28ba9ae2cd7ee9a258fcb58cd932": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9646. ErasureCodingWorker may fail when recovering data blocks with length less than the first internal block. Contributed by Jing Zhao.\n",
      "commitDate": "22/01/16 9:46 AM",
      "commitName": "95363bcc7dae28ba9ae2cd7ee9a258fcb58cd932",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "01/11/15 6:40 PM",
      "commitNameOld": "6e4f8a46c5ce983493cb0ac2234fceafdb3a5613",
      "commitAuthorOld": "Walter Su",
      "daysBetweenCommits": 81.63,
      "commitsBetweenForRepo": 510,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n   protected synchronized int readWithStrategy(ReaderStrategy strategy,\n       int off, int len) throws IOException {\n     dfsClient.checkOpen();\n     if (closed.get()) {\n       throw new IOException(\"Stream closed\");\n     }\n     Map\u003cExtendedBlock, Set\u003cDatanodeInfo\u003e\u003e corruptedBlockMap \u003d\n         new ConcurrentHashMap\u003c\u003e();\n     if (pos \u003c getFileLength()) {\n       try {\n         if (pos \u003e blockEnd) {\n           blockSeekTo(pos);\n         }\n         int realLen \u003d (int) Math.min(len, (blockEnd - pos + 1L));\n         synchronized (infoLock) {\n           if (locatedBlocks.isLastBlockComplete()) {\n             realLen \u003d (int) Math.min(realLen,\n                 locatedBlocks.getFileLength() - pos);\n           }\n         }\n \n         /** Number of bytes already read into buffer */\n         int result \u003d 0;\n         while (result \u003c realLen) {\n           if (!curStripeRange.include(getOffsetInBlockGroup())) {\n             readOneStripe(corruptedBlockMap);\n           }\n           int ret \u003d copyToTargetBuf(strategy, off + result, realLen - result);\n           result +\u003d ret;\n           pos +\u003d ret;\n         }\n         if (dfsClient.stats !\u003d null) {\n           dfsClient.stats.incrementBytesRead(result);\n         }\n         return result;\n       } finally {\n         // Check if need to report block replicas corruption either read\n         // was successful or ChecksumException occured.\n         reportCheckSumFailure(corruptedBlockMap,\n-            currentLocatedBlock.getLocations().length);\n+            currentLocatedBlock.getLocations().length, true);\n       }\n     }\n     return -1;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized int readWithStrategy(ReaderStrategy strategy,\n      int off, int len) throws IOException {\n    dfsClient.checkOpen();\n    if (closed.get()) {\n      throw new IOException(\"Stream closed\");\n    }\n    Map\u003cExtendedBlock, Set\u003cDatanodeInfo\u003e\u003e corruptedBlockMap \u003d\n        new ConcurrentHashMap\u003c\u003e();\n    if (pos \u003c getFileLength()) {\n      try {\n        if (pos \u003e blockEnd) {\n          blockSeekTo(pos);\n        }\n        int realLen \u003d (int) Math.min(len, (blockEnd - pos + 1L));\n        synchronized (infoLock) {\n          if (locatedBlocks.isLastBlockComplete()) {\n            realLen \u003d (int) Math.min(realLen,\n                locatedBlocks.getFileLength() - pos);\n          }\n        }\n\n        /** Number of bytes already read into buffer */\n        int result \u003d 0;\n        while (result \u003c realLen) {\n          if (!curStripeRange.include(getOffsetInBlockGroup())) {\n            readOneStripe(corruptedBlockMap);\n          }\n          int ret \u003d copyToTargetBuf(strategy, off + result, realLen - result);\n          result +\u003d ret;\n          pos +\u003d ret;\n        }\n        if (dfsClient.stats !\u003d null) {\n          dfsClient.stats.incrementBytesRead(result);\n        }\n        return result;\n      } finally {\n        // Check if need to report block replicas corruption either read\n        // was successful or ChecksumException occured.\n        reportCheckSumFailure(corruptedBlockMap,\n            currentLocatedBlock.getLocations().length, true);\n      }\n    }\n    return -1;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
      "extendedDetails": {}
    }
  }
}