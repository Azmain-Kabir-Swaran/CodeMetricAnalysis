{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSNamesystem.java",
  "functionName": "getVerifyECWithTopologyResult",
  "functionId": "getVerifyECWithTopologyResult",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
  "functionStartLine": 8673,
  "functionEndLine": 8681,
  "numCommitsSeen": 873,
  "timeTaken": 6165,
  "changeHistory": [
    "92c58901d767f4fea571274544a590608c911cb8",
    "951cdd7e4cbe68284620f6805f85c51301150c58",
    "dd5e7c6b7239a93f2391beaa11181e442a387db4"
  ],
  "changeHistoryShort": {
    "92c58901d767f4fea571274544a590608c911cb8": "Ybodychange",
    "951cdd7e4cbe68284620f6805f85c51301150c58": "Ybodychange",
    "dd5e7c6b7239a93f2391beaa11181e442a387db4": "Yintroduced"
  },
  "changeHistoryDetails": {
    "92c58901d767f4fea571274544a590608c911cb8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15117. EC: Add getECTopologyResultForPolicies to DistributedFileSystem. Contributed by Ayush Saxena\n",
      "commitDate": "23/01/20 4:48 AM",
      "commitName": "92c58901d767f4fea571274544a590608c911cb8",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "15/01/20 5:22 PM",
      "commitNameOld": "d7c4f8ab21c56a52afcfbd0a56d9120e61376d0c",
      "commitAuthorOld": "Chao Sun",
      "daysBetweenCommits": 7.48,
      "commitsBetweenForRepo": 24,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,9 @@\n   public String getVerifyECWithTopologyResult() {\n-    int numOfDataNodes \u003d getBlockManager().getDatanodeManager()\n-        .getNumOfDataNodes();\n-    int numOfRacks \u003d getBlockManager().getDatanodeManager()\n-        .getNetworkTopology().getNumOfRacks();\n-    ErasureCodingPolicy[] enabledEcPolicies \u003d\n-        getErasureCodingPolicyManager().getCopyOfEnabledPolicies();\n     ECTopologyVerifierResult result \u003d\n-        ECTopologyVerifier.getECTopologyVerifierResult(\n-            numOfRacks, numOfDataNodes, enabledEcPolicies);\n+        getEcTopologyVerifierResultForEnabledPolicies();\n \n     Map\u003cString, String\u003e resultMap \u003d new HashMap\u003cString, String\u003e();\n     resultMap.put(\"isSupported\", Boolean.toString(result.isSupported()));\n     resultMap.put(\"resultMessage\", result.getResultMessage());\n     return JSON.toString(resultMap);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String getVerifyECWithTopologyResult() {\n    ECTopologyVerifierResult result \u003d\n        getEcTopologyVerifierResultForEnabledPolicies();\n\n    Map\u003cString, String\u003e resultMap \u003d new HashMap\u003cString, String\u003e();\n    resultMap.put(\"isSupported\", Boolean.toString(result.isSupported()));\n    resultMap.put(\"resultMessage\", result.getResultMessage());\n    return JSON.toString(resultMap);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "951cdd7e4cbe68284620f6805f85c51301150c58": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14061. Check if the cluster topology supports the EC policy before setting, enabling or adding it. Contributed by Kitti Nanasi.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "23/01/19 2:40 PM",
      "commitName": "951cdd7e4cbe68284620f6805f85c51301150c58",
      "commitAuthor": "Kitti Nanasi",
      "commitDateOld": "11/01/19 10:54 AM",
      "commitNameOld": "fb8932a727f757b2e9c1c61a18145878d0eb77bd",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 12.16,
      "commitsBetweenForRepo": 95,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n   public String getVerifyECWithTopologyResult() {\n     int numOfDataNodes \u003d getBlockManager().getDatanodeManager()\n         .getNumOfDataNodes();\n     int numOfRacks \u003d getBlockManager().getDatanodeManager()\n         .getNetworkTopology().getNumOfRacks();\n-    ErasureCodingPolicyInfo[] ecPolicies \u003d\n-        getErasureCodingPolicyManager().getCopyOfPolicies();\n+    ErasureCodingPolicy[] enabledEcPolicies \u003d\n+        getErasureCodingPolicyManager().getCopyOfEnabledPolicies();\n     ECTopologyVerifierResult result \u003d\n-        ECTopologyVerifier.getECTopologyVerifierResult(ecPolicies,\n-        numOfRacks, numOfDataNodes);\n+        ECTopologyVerifier.getECTopologyVerifierResult(\n+            numOfRacks, numOfDataNodes, enabledEcPolicies);\n \n     Map\u003cString, String\u003e resultMap \u003d new HashMap\u003cString, String\u003e();\n     resultMap.put(\"isSupported\", Boolean.toString(result.isSupported()));\n     resultMap.put(\"resultMessage\", result.getResultMessage());\n     return JSON.toString(resultMap);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String getVerifyECWithTopologyResult() {\n    int numOfDataNodes \u003d getBlockManager().getDatanodeManager()\n        .getNumOfDataNodes();\n    int numOfRacks \u003d getBlockManager().getDatanodeManager()\n        .getNetworkTopology().getNumOfRacks();\n    ErasureCodingPolicy[] enabledEcPolicies \u003d\n        getErasureCodingPolicyManager().getCopyOfEnabledPolicies();\n    ECTopologyVerifierResult result \u003d\n        ECTopologyVerifier.getECTopologyVerifierResult(\n            numOfRacks, numOfDataNodes, enabledEcPolicies);\n\n    Map\u003cString, String\u003e resultMap \u003d new HashMap\u003cString, String\u003e();\n    resultMap.put(\"isSupported\", Boolean.toString(result.isSupported()));\n    resultMap.put(\"resultMessage\", result.getResultMessage());\n    return JSON.toString(resultMap);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "dd5e7c6b7239a93f2391beaa11181e442a387db4": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-12946. Add a tool to check rack configuration against EC policies. Contributed by Kitti Nanasi.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "03/12/18 10:01 AM",
      "commitName": "dd5e7c6b7239a93f2391beaa11181e442a387db4",
      "commitAuthor": "Kitti Nanasi",
      "diff": "@@ -0,0 +1,16 @@\n+  public String getVerifyECWithTopologyResult() {\n+    int numOfDataNodes \u003d getBlockManager().getDatanodeManager()\n+        .getNumOfDataNodes();\n+    int numOfRacks \u003d getBlockManager().getDatanodeManager()\n+        .getNetworkTopology().getNumOfRacks();\n+    ErasureCodingPolicyInfo[] ecPolicies \u003d\n+        getErasureCodingPolicyManager().getCopyOfPolicies();\n+    ECTopologyVerifierResult result \u003d\n+        ECTopologyVerifier.getECTopologyVerifierResult(ecPolicies,\n+        numOfRacks, numOfDataNodes);\n+\n+    Map\u003cString, String\u003e resultMap \u003d new HashMap\u003cString, String\u003e();\n+    resultMap.put(\"isSupported\", Boolean.toString(result.isSupported()));\n+    resultMap.put(\"resultMessage\", result.getResultMessage());\n+    return JSON.toString(resultMap);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public String getVerifyECWithTopologyResult() {\n    int numOfDataNodes \u003d getBlockManager().getDatanodeManager()\n        .getNumOfDataNodes();\n    int numOfRacks \u003d getBlockManager().getDatanodeManager()\n        .getNetworkTopology().getNumOfRacks();\n    ErasureCodingPolicyInfo[] ecPolicies \u003d\n        getErasureCodingPolicyManager().getCopyOfPolicies();\n    ECTopologyVerifierResult result \u003d\n        ECTopologyVerifier.getECTopologyVerifierResult(ecPolicies,\n        numOfRacks, numOfDataNodes);\n\n    Map\u003cString, String\u003e resultMap \u003d new HashMap\u003cString, String\u003e();\n    resultMap.put(\"isSupported\", Boolean.toString(result.isSupported()));\n    resultMap.put(\"resultMessage\", result.getResultMessage());\n    return JSON.toString(resultMap);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}