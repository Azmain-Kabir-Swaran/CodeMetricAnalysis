{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeLifelineProtocolClientSideTranslatorPB.java",
  "functionName": "sendLifeline",
  "functionId": "sendLifeline___registration-DatanodeRegistration__reports-StorageReport[]__cacheCapacity-long__cacheUsed-long__xmitsInProgress-int__xceiverCount-int__failedVolumes-int__volumeFailureSummary-VolumeFailureSummary",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeLifelineProtocolClientSideTranslatorPB.java",
  "functionStartLine": 80,
  "functionEndLine": 104,
  "numCommitsSeen": 2,
  "timeTaken": 1375,
  "changeHistory": [
    "2759689d7d23001f007cb0dbe2521de90734dd5c"
  ],
  "changeHistoryShort": {
    "2759689d7d23001f007cb0dbe2521de90734dd5c": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2759689d7d23001f007cb0dbe2521de90734dd5c": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9239. DataNode Lifeline Protocol: an alternative protocol for reporting DataNode liveness. Contributed by Chris Nauroth.\n",
      "commitDate": "04/03/16 3:29 PM",
      "commitName": "2759689d7d23001f007cb0dbe2521de90734dd5c",
      "commitAuthor": "Chris Nauroth",
      "diff": "@@ -0,0 +1,25 @@\n+  public void sendLifeline(DatanodeRegistration registration,\n+      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n+      int xmitsInProgress, int xceiverCount, int failedVolumes,\n+      VolumeFailureSummary volumeFailureSummary) throws IOException {\n+    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n+        .setRegistration(PBHelper.convert(registration))\n+        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n+        .setFailedVolumes(failedVolumes);\n+    builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n+    if (cacheCapacity !\u003d 0) {\n+      builder.setCacheCapacity(cacheCapacity);\n+    }\n+    if (cacheUsed !\u003d 0) {\n+      builder.setCacheUsed(cacheUsed);\n+    }\n+    if (volumeFailureSummary !\u003d null) {\n+      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n+          volumeFailureSummary));\n+    }\n+    try {\n+      rpcProxy.sendLifeline(NULL_CONTROLLER, builder.build());\n+    } catch (ServiceException se) {\n+      throw ProtobufHelper.getRemoteException(se);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void sendLifeline(DatanodeRegistration registration,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xmitsInProgress, int xceiverCount, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary) throws IOException {\n    HeartbeatRequestProto.Builder builder \u003d HeartbeatRequestProto.newBuilder()\n        .setRegistration(PBHelper.convert(registration))\n        .setXmitsInProgress(xmitsInProgress).setXceiverCount(xceiverCount)\n        .setFailedVolumes(failedVolumes);\n    builder.addAllReports(PBHelperClient.convertStorageReports(reports));\n    if (cacheCapacity !\u003d 0) {\n      builder.setCacheCapacity(cacheCapacity);\n    }\n    if (cacheUsed !\u003d 0) {\n      builder.setCacheUsed(cacheUsed);\n    }\n    if (volumeFailureSummary !\u003d null) {\n      builder.setVolumeFailureSummary(PBHelper.convertVolumeFailureSummary(\n          volumeFailureSummary));\n    }\n    try {\n      rpcProxy.sendLifeline(NULL_CONTROLLER, builder.build());\n    } catch (ServiceException se) {\n      throw ProtobufHelper.getRemoteException(se);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeLifelineProtocolClientSideTranslatorPB.java"
    }
  }
}