{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RouterClientProtocol.java",
  "functionName": "getFileInfoAll",
  "functionId": "getFileInfoAll___locations-List__RemoteLocation__(modifiers-final)__method-RemoteMethod(modifiers-final)__timeOutMs-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
  "functionStartLine": 1927,
  "functionEndLine": 1952,
  "numCommitsSeen": 40,
  "timeTaken": 1487,
  "changeHistory": [
    "6c42d4050461ab71c88f123569649793dc53aebd"
  ],
  "changeHistoryShort": {
    "6c42d4050461ab71c88f123569649793dc53aebd": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6c42d4050461ab71c88f123569649793dc53aebd": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-14316. RBF: Support unavailable subclusters for mount points with multiple destinations. Contributed by Inigo Goiri.\n",
      "commitDate": "24/06/19 9:33 AM",
      "commitName": "6c42d4050461ab71c88f123569649793dc53aebd",
      "commitAuthor": "Ayush Saxena",
      "diff": "@@ -0,0 +1,26 @@\n+  private HdfsFileStatus getFileInfoAll(final List\u003cRemoteLocation\u003e locations,\n+      final RemoteMethod method, long timeOutMs) throws IOException {\n+\n+    // Get the file info from everybody\n+    Map\u003cRemoteLocation, HdfsFileStatus\u003e results \u003d\n+        rpcClient.invokeConcurrent(locations, method, false, false, timeOutMs,\n+            HdfsFileStatus.class);\n+    int children \u003d 0;\n+    // We return the first file\n+    HdfsFileStatus dirStatus \u003d null;\n+    for (RemoteLocation loc : locations) {\n+      HdfsFileStatus fileStatus \u003d results.get(loc);\n+      if (fileStatus !\u003d null) {\n+        children +\u003d fileStatus.getChildrenNum();\n+        if (!fileStatus.isDirectory()) {\n+          return fileStatus;\n+        } else if (dirStatus \u003d\u003d null) {\n+          dirStatus \u003d fileStatus;\n+        }\n+      }\n+    }\n+    if (dirStatus !\u003d null) {\n+      return updateMountPointStatus(dirStatus, children);\n+    }\n+    return null;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private HdfsFileStatus getFileInfoAll(final List\u003cRemoteLocation\u003e locations,\n      final RemoteMethod method, long timeOutMs) throws IOException {\n\n    // Get the file info from everybody\n    Map\u003cRemoteLocation, HdfsFileStatus\u003e results \u003d\n        rpcClient.invokeConcurrent(locations, method, false, false, timeOutMs,\n            HdfsFileStatus.class);\n    int children \u003d 0;\n    // We return the first file\n    HdfsFileStatus dirStatus \u003d null;\n    for (RemoteLocation loc : locations) {\n      HdfsFileStatus fileStatus \u003d results.get(loc);\n      if (fileStatus !\u003d null) {\n        children +\u003d fileStatus.getChildrenNum();\n        if (!fileStatus.isDirectory()) {\n          return fileStatus;\n        } else if (dirStatus \u003d\u003d null) {\n          dirStatus \u003d fileStatus;\n        }\n      }\n    }\n    if (dirStatus !\u003d null) {\n      return updateMountPointStatus(dirStatus, children);\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java"
    }
  }
}