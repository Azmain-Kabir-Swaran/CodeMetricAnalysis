{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AggregatedLogFormat.java",
  "functionName": "readAContainerLogsForALogType",
  "functionId": "readAContainerLogsForALogType___valueStream-DataInputStream__out-PrintStream",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
  "functionStartLine": 901,
  "functionEndLine": 905,
  "numCommitsSeen": 61,
  "timeTaken": 8670,
  "changeHistory": [
    "58e9f24e0f06efede21085b7ffe36af042fa7b38",
    "f81dc3f995579c1b94b11d60e9fc6da56c8a9496",
    "2826a35469acd262c76fa26e730a21843ac6e856",
    "67699c2d187a8480a46acf5031652ff19196823d",
    "e1fdf62123625e4ba399af02f8aad500637d29d1",
    "c27601fefebd0af887a12d684bfc6f90d9fc0321",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "58e9f24e0f06efede21085b7ffe36af042fa7b38": "Ybodychange",
    "f81dc3f995579c1b94b11d60e9fc6da56c8a9496": "Ybodychange",
    "2826a35469acd262c76fa26e730a21843ac6e856": "Ybodychange",
    "67699c2d187a8480a46acf5031652ff19196823d": "Ymultichange(Yparameterchange,Ybodychange)",
    "e1fdf62123625e4ba399af02f8aad500637d29d1": "Yfilerename",
    "c27601fefebd0af887a12d684bfc6f90d9fc0321": "Yfilerename",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "58e9f24e0f06efede21085b7ffe36af042fa7b38": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2788. Fixed backwards compatiblity issues with log-aggregation feature that were caused when adding log-upload-time via YARN-2703. Contributed by Xuan Gong.\n",
      "commitDate": "03/11/14 1:16 PM",
      "commitName": "58e9f24e0f06efede21085b7ffe36af042fa7b38",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "26/10/14 12:57 PM",
      "commitNameOld": "caecd9fffe7c6216be31f3ab65349182045451fa",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 8.05,
      "commitsBetweenForRepo": 84,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,5 @@\n     public static void readAContainerLogsForALogType(\n         DataInputStream valueStream, PrintStream out)\n           throws IOException {\n-\n-      byte[] buf \u003d new byte[65535];\n-\n-      String fileType \u003d valueStream.readUTF();\n-      long uploadTime \u003d valueStream.readLong();\n-      String fileLengthStr \u003d valueStream.readUTF();\n-      long fileLength \u003d Long.parseLong(fileLengthStr);\n-      out.print(\"LogType: \");\n-      out.println(fileType);\n-      out.print(\"LogUploadTime: \");\n-      out.println(Times.format(uploadTime));\n-      out.print(\"LogLength: \");\n-      out.println(fileLengthStr);\n-      out.println(\"Log Contents:\");\n-\n-      long curRead \u003d 0;\n-      long pendingRead \u003d fileLength - curRead;\n-      int toRead \u003d\n-                pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n-      int len \u003d valueStream.read(buf, 0, toRead);\n-      while (len !\u003d -1 \u0026\u0026 curRead \u003c fileLength) {\n-        out.write(buf, 0, len);\n-        curRead +\u003d len;\n-\n-        pendingRead \u003d fileLength - curRead;\n-        toRead \u003d\n-                  pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n-        len \u003d valueStream.read(buf, 0, toRead);\n-      }\n-      out.println(\"\");\n+      readAContainerLogsForALogType(valueStream, out, -1);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public static void readAContainerLogsForALogType(\n        DataInputStream valueStream, PrintStream out)\n          throws IOException {\n      readAContainerLogsForALogType(valueStream, out, -1);\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
      "extendedDetails": {}
    },
    "f81dc3f995579c1b94b11d60e9fc6da56c8a9496": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2703. Added logUploadedTime into LogValue for better display. Contributed by Xuan Gong.\n",
      "commitDate": "24/10/14 2:10 PM",
      "commitName": "f81dc3f995579c1b94b11d60e9fc6da56c8a9496",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "24/10/14 11:13 AM",
      "commitNameOld": "e31f0a6558b106662c83e1f797216e412b6689a9",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 0.12,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,34 @@\n     public static void readAContainerLogsForALogType(\n         DataInputStream valueStream, PrintStream out)\n           throws IOException {\n \n       byte[] buf \u003d new byte[65535];\n \n       String fileType \u003d valueStream.readUTF();\n+      long uploadTime \u003d valueStream.readLong();\n       String fileLengthStr \u003d valueStream.readUTF();\n       long fileLength \u003d Long.parseLong(fileLengthStr);\n       out.print(\"LogType: \");\n       out.println(fileType);\n+      out.print(\"LogUploadTime: \");\n+      out.println(Times.format(uploadTime));\n       out.print(\"LogLength: \");\n       out.println(fileLengthStr);\n       out.println(\"Log Contents:\");\n \n       long curRead \u003d 0;\n       long pendingRead \u003d fileLength - curRead;\n       int toRead \u003d\n                 pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n       int len \u003d valueStream.read(buf, 0, toRead);\n       while (len !\u003d -1 \u0026\u0026 curRead \u003c fileLength) {\n         out.write(buf, 0, len);\n         curRead +\u003d len;\n \n         pendingRead \u003d fileLength - curRead;\n         toRead \u003d\n                   pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n         len \u003d valueStream.read(buf, 0, toRead);\n       }\n       out.println(\"\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public static void readAContainerLogsForALogType(\n        DataInputStream valueStream, PrintStream out)\n          throws IOException {\n\n      byte[] buf \u003d new byte[65535];\n\n      String fileType \u003d valueStream.readUTF();\n      long uploadTime \u003d valueStream.readLong();\n      String fileLengthStr \u003d valueStream.readUTF();\n      long fileLength \u003d Long.parseLong(fileLengthStr);\n      out.print(\"LogType: \");\n      out.println(fileType);\n      out.print(\"LogUploadTime: \");\n      out.println(Times.format(uploadTime));\n      out.print(\"LogLength: \");\n      out.println(fileLengthStr);\n      out.println(\"Log Contents:\");\n\n      long curRead \u003d 0;\n      long pendingRead \u003d fileLength - curRead;\n      int toRead \u003d\n                pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n      int len \u003d valueStream.read(buf, 0, toRead);\n      while (len !\u003d -1 \u0026\u0026 curRead \u003c fileLength) {\n        out.write(buf, 0, len);\n        curRead +\u003d len;\n\n        pendingRead \u003d fileLength - curRead;\n        toRead \u003d\n                  pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n        len \u003d valueStream.read(buf, 0, toRead);\n      }\n      out.println(\"\");\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
      "extendedDetails": {}
    },
    "2826a35469acd262c76fa26e730a21843ac6e856": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1670. Fixed a bug in log-aggregation that can cause the writer to write more log-data than the log-length that it records. Contributed by Mit Desai.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1580005 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/03/14 11:35 AM",
      "commitName": "2826a35469acd262c76fa26e730a21843ac6e856",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "16/12/13 11:27 AM",
      "commitNameOld": "5a1b33507b935f91d6dee6056fe840e778fb198e",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 94.96,
      "commitsBetweenForRepo": 707,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n     public static void readAContainerLogsForALogType(\n         DataInputStream valueStream, PrintStream out)\n           throws IOException {\n \n       byte[] buf \u003d new byte[65535];\n \n       String fileType \u003d valueStream.readUTF();\n       String fileLengthStr \u003d valueStream.readUTF();\n       long fileLength \u003d Long.parseLong(fileLengthStr);\n       out.print(\"LogType: \");\n       out.println(fileType);\n       out.print(\"LogLength: \");\n       out.println(fileLengthStr);\n       out.println(\"Log Contents:\");\n \n-      int curRead \u003d 0;\n+      long curRead \u003d 0;\n       long pendingRead \u003d fileLength - curRead;\n       int toRead \u003d\n                 pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n       int len \u003d valueStream.read(buf, 0, toRead);\n       while (len !\u003d -1 \u0026\u0026 curRead \u003c fileLength) {\n         out.write(buf, 0, len);\n         curRead +\u003d len;\n \n         pendingRead \u003d fileLength - curRead;\n         toRead \u003d\n                   pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n         len \u003d valueStream.read(buf, 0, toRead);\n       }\n       out.println(\"\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public static void readAContainerLogsForALogType(\n        DataInputStream valueStream, PrintStream out)\n          throws IOException {\n\n      byte[] buf \u003d new byte[65535];\n\n      String fileType \u003d valueStream.readUTF();\n      String fileLengthStr \u003d valueStream.readUTF();\n      long fileLength \u003d Long.parseLong(fileLengthStr);\n      out.print(\"LogType: \");\n      out.println(fileType);\n      out.print(\"LogLength: \");\n      out.println(fileLengthStr);\n      out.println(\"Log Contents:\");\n\n      long curRead \u003d 0;\n      long pendingRead \u003d fileLength - curRead;\n      int toRead \u003d\n                pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n      int len \u003d valueStream.read(buf, 0, toRead);\n      while (len !\u003d -1 \u0026\u0026 curRead \u003c fileLength) {\n        out.write(buf, 0, len);\n        curRead +\u003d len;\n\n        pendingRead \u003d fileLength - curRead;\n        toRead \u003d\n                  pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n        len \u003d valueStream.read(buf, 0, toRead);\n      }\n      out.println(\"\");\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
      "extendedDetails": {}
    },
    "67699c2d187a8480a46acf5031652ff19196823d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-200. yarn log does not output all needed information, and is in a binary format. Contributed by Ravi Prakash\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1458466 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/03/13 12:29 PM",
      "commitName": "67699c2d187a8480a46acf5031652ff19196823d",
      "commitAuthor": "Jason Darrell Lowe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-200. yarn log does not output all needed information, and is in a binary format. Contributed by Ravi Prakash\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1458466 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "19/03/13 12:29 PM",
          "commitName": "67699c2d187a8480a46acf5031652ff19196823d",
          "commitAuthor": "Jason Darrell Lowe",
          "commitDateOld": "04/03/13 12:08 PM",
          "commitNameOld": "9334dc23f9685e3a99ce76060fc77341f3456018",
          "commitAuthorOld": "Robert Joseph Evans",
          "daysBetweenCommits": 14.97,
          "commitsBetweenForRepo": 88,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,30 +1,31 @@\n     public static void readAContainerLogsForALogType(\n-        DataInputStream valueStream, DataOutputStream out)\n+        DataInputStream valueStream, PrintStream out)\n           throws IOException {\n \n       byte[] buf \u003d new byte[65535];\n \n       String fileType \u003d valueStream.readUTF();\n       String fileLengthStr \u003d valueStream.readUTF();\n       long fileLength \u003d Long.parseLong(fileLengthStr);\n-      out.writeUTF(\"\\nLogType:\");\n-      out.writeUTF(fileType);\n-      out.writeUTF(\"\\nLogLength:\");\n-      out.writeUTF(fileLengthStr);\n-      out.writeUTF(\"\\nLog Contents:\\n\");\n+      out.print(\"LogType: \");\n+      out.println(fileType);\n+      out.print(\"LogLength: \");\n+      out.println(fileLengthStr);\n+      out.println(\"Log Contents:\");\n \n       int curRead \u003d 0;\n       long pendingRead \u003d fileLength - curRead;\n       int toRead \u003d\n                 pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n       int len \u003d valueStream.read(buf, 0, toRead);\n       while (len !\u003d -1 \u0026\u0026 curRead \u003c fileLength) {\n         out.write(buf, 0, len);\n         curRead +\u003d len;\n \n         pendingRead \u003d fileLength - curRead;\n         toRead \u003d\n                   pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n         len \u003d valueStream.read(buf, 0, toRead);\n       }\n+      out.println(\"\");\n     }\n\\ No newline at end of file\n",
          "actualSource": "    public static void readAContainerLogsForALogType(\n        DataInputStream valueStream, PrintStream out)\n          throws IOException {\n\n      byte[] buf \u003d new byte[65535];\n\n      String fileType \u003d valueStream.readUTF();\n      String fileLengthStr \u003d valueStream.readUTF();\n      long fileLength \u003d Long.parseLong(fileLengthStr);\n      out.print(\"LogType: \");\n      out.println(fileType);\n      out.print(\"LogLength: \");\n      out.println(fileLengthStr);\n      out.println(\"Log Contents:\");\n\n      int curRead \u003d 0;\n      long pendingRead \u003d fileLength - curRead;\n      int toRead \u003d\n                pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n      int len \u003d valueStream.read(buf, 0, toRead);\n      while (len !\u003d -1 \u0026\u0026 curRead \u003c fileLength) {\n        out.write(buf, 0, len);\n        curRead +\u003d len;\n\n        pendingRead \u003d fileLength - curRead;\n        toRead \u003d\n                  pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n        len \u003d valueStream.read(buf, 0, toRead);\n      }\n      out.println(\"\");\n    }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
          "extendedDetails": {
            "oldValue": "[valueStream-DataInputStream, out-DataOutputStream]",
            "newValue": "[valueStream-DataInputStream, out-PrintStream]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-200. yarn log does not output all needed information, and is in a binary format. Contributed by Ravi Prakash\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1458466 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "19/03/13 12:29 PM",
          "commitName": "67699c2d187a8480a46acf5031652ff19196823d",
          "commitAuthor": "Jason Darrell Lowe",
          "commitDateOld": "04/03/13 12:08 PM",
          "commitNameOld": "9334dc23f9685e3a99ce76060fc77341f3456018",
          "commitAuthorOld": "Robert Joseph Evans",
          "daysBetweenCommits": 14.97,
          "commitsBetweenForRepo": 88,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,30 +1,31 @@\n     public static void readAContainerLogsForALogType(\n-        DataInputStream valueStream, DataOutputStream out)\n+        DataInputStream valueStream, PrintStream out)\n           throws IOException {\n \n       byte[] buf \u003d new byte[65535];\n \n       String fileType \u003d valueStream.readUTF();\n       String fileLengthStr \u003d valueStream.readUTF();\n       long fileLength \u003d Long.parseLong(fileLengthStr);\n-      out.writeUTF(\"\\nLogType:\");\n-      out.writeUTF(fileType);\n-      out.writeUTF(\"\\nLogLength:\");\n-      out.writeUTF(fileLengthStr);\n-      out.writeUTF(\"\\nLog Contents:\\n\");\n+      out.print(\"LogType: \");\n+      out.println(fileType);\n+      out.print(\"LogLength: \");\n+      out.println(fileLengthStr);\n+      out.println(\"Log Contents:\");\n \n       int curRead \u003d 0;\n       long pendingRead \u003d fileLength - curRead;\n       int toRead \u003d\n                 pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n       int len \u003d valueStream.read(buf, 0, toRead);\n       while (len !\u003d -1 \u0026\u0026 curRead \u003c fileLength) {\n         out.write(buf, 0, len);\n         curRead +\u003d len;\n \n         pendingRead \u003d fileLength - curRead;\n         toRead \u003d\n                   pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n         len \u003d valueStream.read(buf, 0, toRead);\n       }\n+      out.println(\"\");\n     }\n\\ No newline at end of file\n",
          "actualSource": "    public static void readAContainerLogsForALogType(\n        DataInputStream valueStream, PrintStream out)\n          throws IOException {\n\n      byte[] buf \u003d new byte[65535];\n\n      String fileType \u003d valueStream.readUTF();\n      String fileLengthStr \u003d valueStream.readUTF();\n      long fileLength \u003d Long.parseLong(fileLengthStr);\n      out.print(\"LogType: \");\n      out.println(fileType);\n      out.print(\"LogLength: \");\n      out.println(fileLengthStr);\n      out.println(\"Log Contents:\");\n\n      int curRead \u003d 0;\n      long pendingRead \u003d fileLength - curRead;\n      int toRead \u003d\n                pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n      int len \u003d valueStream.read(buf, 0, toRead);\n      while (len !\u003d -1 \u0026\u0026 curRead \u003c fileLength) {\n        out.write(buf, 0, len);\n        curRead +\u003d len;\n\n        pendingRead \u003d fileLength - curRead;\n        toRead \u003d\n                  pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n        len \u003d valueStream.read(buf, 0, toRead);\n      }\n      out.println(\"\");\n    }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
          "extendedDetails": {}
        }
      ]
    },
    "e1fdf62123625e4ba399af02f8aad500637d29d1": {
      "type": "Yfilerename",
      "commitMessage": "YARN-1. Promote YARN to be a sub-project of Apache Hadoop.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370666 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/12 10:22 PM",
      "commitName": "e1fdf62123625e4ba399af02f8aad500637d29d1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "07/08/12 7:53 PM",
      "commitNameOld": "34554d1e11ee1d5b564d7d9ed3e6d55931d72749",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public static void readAContainerLogsForALogType(\n        DataInputStream valueStream, DataOutputStream out)\n          throws IOException {\n\n      byte[] buf \u003d new byte[65535];\n\n      String fileType \u003d valueStream.readUTF();\n      String fileLengthStr \u003d valueStream.readUTF();\n      long fileLength \u003d Long.parseLong(fileLengthStr);\n      out.writeUTF(\"\\nLogType:\");\n      out.writeUTF(fileType);\n      out.writeUTF(\"\\nLogLength:\");\n      out.writeUTF(fileLengthStr);\n      out.writeUTF(\"\\nLog Contents:\\n\");\n\n      int curRead \u003d 0;\n      long pendingRead \u003d fileLength - curRead;\n      int toRead \u003d\n                pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n      int len \u003d valueStream.read(buf, 0, toRead);\n      while (len !\u003d -1 \u0026\u0026 curRead \u003c fileLength) {\n        out.write(buf, 0, len);\n        curRead +\u003d len;\n\n        pendingRead \u003d fileLength - curRead;\n        toRead \u003d\n                  pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n        len \u003d valueStream.read(buf, 0, toRead);\n      }\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java"
      }
    },
    "c27601fefebd0af887a12d684bfc6f90d9fc0321": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-3297. Moved log related components into yarn-common so that HistoryServer and clients can use them without depending on the yarn-server-nodemanager module. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1196986 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/11/11 1:02 AM",
      "commitName": "c27601fefebd0af887a12d684bfc6f90d9fc0321",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "03/11/11 12:06 AM",
      "commitNameOld": "0df4878033b797b9313c887ca9d75f8ea104d029",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public static void readAContainerLogsForALogType(\n        DataInputStream valueStream, DataOutputStream out)\n          throws IOException {\n\n      byte[] buf \u003d new byte[65535];\n\n      String fileType \u003d valueStream.readUTF();\n      String fileLengthStr \u003d valueStream.readUTF();\n      long fileLength \u003d Long.parseLong(fileLengthStr);\n      out.writeUTF(\"\\nLogType:\");\n      out.writeUTF(fileType);\n      out.writeUTF(\"\\nLogLength:\");\n      out.writeUTF(fileLengthStr);\n      out.writeUTF(\"\\nLog Contents:\\n\");\n\n      int curRead \u003d 0;\n      long pendingRead \u003d fileLength - curRead;\n      int toRead \u003d\n                pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n      int len \u003d valueStream.read(buf, 0, toRead);\n      while (len !\u003d -1 \u0026\u0026 curRead \u003c fileLength) {\n        out.write(buf, 0, len);\n        curRead +\u003d len;\n\n        pendingRead \u003d fileLength - curRead;\n        toRead \u003d\n                  pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n        len \u003d valueStream.read(buf, 0, toRead);\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/AggregatedLogFormat.java",
        "newPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java"
      }
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public static void readAContainerLogsForALogType(\n        DataInputStream valueStream, DataOutputStream out)\n          throws IOException {\n\n      byte[] buf \u003d new byte[65535];\n\n      String fileType \u003d valueStream.readUTF();\n      String fileLengthStr \u003d valueStream.readUTF();\n      long fileLength \u003d Long.parseLong(fileLengthStr);\n      out.writeUTF(\"\\nLogType:\");\n      out.writeUTF(fileType);\n      out.writeUTF(\"\\nLogLength:\");\n      out.writeUTF(fileLengthStr);\n      out.writeUTF(\"\\nLog Contents:\\n\");\n\n      int curRead \u003d 0;\n      long pendingRead \u003d fileLength - curRead;\n      int toRead \u003d\n                pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n      int len \u003d valueStream.read(buf, 0, toRead);\n      while (len !\u003d -1 \u0026\u0026 curRead \u003c fileLength) {\n        out.write(buf, 0, len);\n        curRead +\u003d len;\n\n        pendingRead \u003d fileLength - curRead;\n        toRead \u003d\n                  pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n        len \u003d valueStream.read(buf, 0, toRead);\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/AggregatedLogFormat.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/AggregatedLogFormat.java",
        "newPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/AggregatedLogFormat.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,30 @@\n+    public static void readAContainerLogsForALogType(\n+        DataInputStream valueStream, DataOutputStream out)\n+          throws IOException {\n+\n+      byte[] buf \u003d new byte[65535];\n+\n+      String fileType \u003d valueStream.readUTF();\n+      String fileLengthStr \u003d valueStream.readUTF();\n+      long fileLength \u003d Long.parseLong(fileLengthStr);\n+      out.writeUTF(\"\\nLogType:\");\n+      out.writeUTF(fileType);\n+      out.writeUTF(\"\\nLogLength:\");\n+      out.writeUTF(fileLengthStr);\n+      out.writeUTF(\"\\nLog Contents:\\n\");\n+\n+      int curRead \u003d 0;\n+      long pendingRead \u003d fileLength - curRead;\n+      int toRead \u003d\n+                pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n+      int len \u003d valueStream.read(buf, 0, toRead);\n+      while (len !\u003d -1 \u0026\u0026 curRead \u003c fileLength) {\n+        out.write(buf, 0, len);\n+        curRead +\u003d len;\n+\n+        pendingRead \u003d fileLength - curRead;\n+        toRead \u003d\n+                  pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n+        len \u003d valueStream.read(buf, 0, toRead);\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public static void readAContainerLogsForALogType(\n        DataInputStream valueStream, DataOutputStream out)\n          throws IOException {\n\n      byte[] buf \u003d new byte[65535];\n\n      String fileType \u003d valueStream.readUTF();\n      String fileLengthStr \u003d valueStream.readUTF();\n      long fileLength \u003d Long.parseLong(fileLengthStr);\n      out.writeUTF(\"\\nLogType:\");\n      out.writeUTF(fileType);\n      out.writeUTF(\"\\nLogLength:\");\n      out.writeUTF(fileLengthStr);\n      out.writeUTF(\"\\nLog Contents:\\n\");\n\n      int curRead \u003d 0;\n      long pendingRead \u003d fileLength - curRead;\n      int toRead \u003d\n                pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n      int len \u003d valueStream.read(buf, 0, toRead);\n      while (len !\u003d -1 \u0026\u0026 curRead \u003c fileLength) {\n        out.write(buf, 0, len);\n        curRead +\u003d len;\n\n        pendingRead \u003d fileLength - curRead;\n        toRead \u003d\n                  pendingRead \u003e buf.length ? buf.length : (int) pendingRead;\n        len \u003d valueStream.read(buf, 0, toRead);\n      }\n    }",
      "path": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/AggregatedLogFormat.java"
    }
  }
}