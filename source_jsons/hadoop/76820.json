{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "GaloisField.java",
  "functionName": "substitute",
  "functionId": "substitute___p-byte[][]__offsets-int[]__len-int__q-byte[]__offset-int__x-int",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/util/GaloisField.java",
  "functionStartLine": 422,
  "functionEndLine": 434,
  "numCommitsSeen": 7,
  "timeTaken": 1062,
  "changeHistory": [
    "4ad484883f773c702a1874fc12816ef1a4a54136",
    "343c0e76fcd95ac739ca7cd6742c9d617e19fc37"
  ],
  "changeHistoryShort": {
    "4ad484883f773c702a1874fc12816ef1a4a54136": "Ybodychange",
    "343c0e76fcd95ac739ca7cd6742c9d617e19fc37": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4ad484883f773c702a1874fc12816ef1a4a54136": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11847 Enhance raw coder allowing to read least required inputs in decoding. Contributed by Kai Zheng\n",
      "commitDate": "26/05/15 12:07 PM",
      "commitName": "4ad484883f773c702a1874fc12816ef1a4a54136",
      "commitAuthor": "Kai Zheng",
      "commitDateOld": "26/05/15 12:02 PM",
      "commitNameOld": "343c0e76fcd95ac739ca7cd6742c9d617e19fc37",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   public void substitute(byte[][] p, int[] offsets,\n                          int len, byte[] q, int offset, int x) {\n     int y \u003d 1, iIdx, oIdx;\n     for (int i \u003d 0; i \u003c p.length; i++) {\n       byte[] pi \u003d p[i];\n       for (iIdx \u003d offsets[i], oIdx \u003d offset;\n            iIdx \u003c offsets[i] + len; iIdx++, oIdx++) {\n-        int pij \u003d pi[iIdx] \u0026 0x000000FF;\n+        int pij \u003d pi !\u003d null ? pi[iIdx] \u0026 0x000000FF : 0;\n         q[oIdx] \u003d (byte) (q[oIdx] ^ mulTable[pij][y]);\n       }\n       y \u003d mulTable[x][y];\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void substitute(byte[][] p, int[] offsets,\n                         int len, byte[] q, int offset, int x) {\n    int y \u003d 1, iIdx, oIdx;\n    for (int i \u003d 0; i \u003c p.length; i++) {\n      byte[] pi \u003d p[i];\n      for (iIdx \u003d offsets[i], oIdx \u003d offset;\n           iIdx \u003c offsets[i] + len; iIdx++, oIdx++) {\n        int pij \u003d pi !\u003d null ? pi[iIdx] \u0026 0x000000FF : 0;\n        q[oIdx] \u003d (byte) (q[oIdx] ^ mulTable[pij][y]);\n      }\n      y \u003d mulTable[x][y];\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/util/GaloisField.java",
      "extendedDetails": {}
    },
    "343c0e76fcd95ac739ca7cd6742c9d617e19fc37": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-11938. Enhance ByteBuffer version encode/decode API of raw erasure coder. Contributed by Kai Zheng.\n",
      "commitDate": "26/05/15 12:02 PM",
      "commitName": "343c0e76fcd95ac739ca7cd6742c9d617e19fc37",
      "commitAuthor": "Zhe Zhang",
      "diff": "@@ -0,0 +1,13 @@\n+  public void substitute(byte[][] p, int[] offsets,\n+                         int len, byte[] q, int offset, int x) {\n+    int y \u003d 1, iIdx, oIdx;\n+    for (int i \u003d 0; i \u003c p.length; i++) {\n+      byte[] pi \u003d p[i];\n+      for (iIdx \u003d offsets[i], oIdx \u003d offset;\n+           iIdx \u003c offsets[i] + len; iIdx++, oIdx++) {\n+        int pij \u003d pi[iIdx] \u0026 0x000000FF;\n+        q[oIdx] \u003d (byte) (q[oIdx] ^ mulTable[pij][y]);\n+      }\n+      y \u003d mulTable[x][y];\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void substitute(byte[][] p, int[] offsets,\n                         int len, byte[] q, int offset, int x) {\n    int y \u003d 1, iIdx, oIdx;\n    for (int i \u003d 0; i \u003c p.length; i++) {\n      byte[] pi \u003d p[i];\n      for (iIdx \u003d offsets[i], oIdx \u003d offset;\n           iIdx \u003c offsets[i] + len; iIdx++, oIdx++) {\n        int pij \u003d pi[iIdx] \u0026 0x000000FF;\n        q[oIdx] \u003d (byte) (q[oIdx] ^ mulTable[pij][y]);\n      }\n      y \u003d mulTable[x][y];\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/util/GaloisField.java"
    }
  }
}