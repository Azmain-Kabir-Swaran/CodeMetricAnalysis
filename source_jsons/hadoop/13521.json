{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockInfoStriped.java",
  "functionName": "findStorageInfoFromEnd",
  "functionId": "findStorageInfoFromEnd___storage-DatanodeStorageInfo",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.java",
  "functionStartLine": 147,
  "functionEndLine": 156,
  "numCommitsSeen": 83,
  "timeTaken": 4871,
  "changeHistory": [
    "ba9371492036983a9899398907ab41fe548f29b3",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
    "0ed8732feef9f4027e9fc95b6d4852444c1f3426"
  ],
  "changeHistoryShort": {
    "ba9371492036983a9899398907ab41fe548f29b3": "Ymultichange(Ymovefromfile,Yreturntypechange,Ymodifierchange,Ybodychange,Yrename,Yparameterchange)",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": "Yfilerename",
    "0ed8732feef9f4027e9fc95b6d4852444c1f3426": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "ba9371492036983a9899398907ab41fe548f29b3": {
      "type": "Ymultichange(Ymovefromfile,Yreturntypechange,Ymodifierchange,Ybodychange,Yrename,Yparameterchange)",
      "commitMessage": "HDFS-7716. Erasure Coding: extend BlockInfo to handle EC info. Contributed by Jing Zhao.\n",
      "commitDate": "26/05/15 11:07 AM",
      "commitName": "ba9371492036983a9899398907ab41fe548f29b3",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-7716. Erasure Coding: extend BlockInfo to handle EC info. Contributed by Jing Zhao.\n",
          "commitDate": "26/05/15 11:07 AM",
          "commitName": "ba9371492036983a9899398907ab41fe548f29b3",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "26/05/15 11:03 AM",
          "commitNameOld": "b29f3bde4d2fd2f2c4abd6d7b5f97a81bb50efb2",
          "commitAuthorOld": "Kai Zheng",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,10 @@\n-  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n-    int len \u003d getCapacity();\n-    for(int idx \u003d 0; idx \u003c len; idx++) {\n+  private int findStorageInfoFromEnd(DatanodeStorageInfo storage) {\n+    final int len \u003d getCapacity();\n+    for(int idx \u003d len - 1; idx \u003e\u003d 0; idx--) {\n       DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n-      if(cur \u003d\u003d null)\n-        break;\n-      if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n-        return cur;\n+      if (storage.equals(cur)) {\n+        return idx;\n+      }\n     }\n-    return null;\n+    return -1;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int findStorageInfoFromEnd(DatanodeStorageInfo storage) {\n    final int len \u003d getCapacity();\n    for(int idx \u003d len - 1; idx \u003e\u003d 0; idx--) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if (storage.equals(cur)) {\n        return idx;\n      }\n    }\n    return -1;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoContiguous.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.java",
            "oldMethodName": "findStorageInfo",
            "newMethodName": "findStorageInfoFromEnd"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-7716. Erasure Coding: extend BlockInfo to handle EC info. Contributed by Jing Zhao.\n",
          "commitDate": "26/05/15 11:07 AM",
          "commitName": "ba9371492036983a9899398907ab41fe548f29b3",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "26/05/15 11:03 AM",
          "commitNameOld": "b29f3bde4d2fd2f2c4abd6d7b5f97a81bb50efb2",
          "commitAuthorOld": "Kai Zheng",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,10 @@\n-  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n-    int len \u003d getCapacity();\n-    for(int idx \u003d 0; idx \u003c len; idx++) {\n+  private int findStorageInfoFromEnd(DatanodeStorageInfo storage) {\n+    final int len \u003d getCapacity();\n+    for(int idx \u003d len - 1; idx \u003e\u003d 0; idx--) {\n       DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n-      if(cur \u003d\u003d null)\n-        break;\n-      if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n-        return cur;\n+      if (storage.equals(cur)) {\n+        return idx;\n+      }\n     }\n-    return null;\n+    return -1;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int findStorageInfoFromEnd(DatanodeStorageInfo storage) {\n    final int len \u003d getCapacity();\n    for(int idx \u003d len - 1; idx \u003e\u003d 0; idx--) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if (storage.equals(cur)) {\n        return idx;\n      }\n    }\n    return -1;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.java",
          "extendedDetails": {
            "oldValue": "DatanodeStorageInfo",
            "newValue": "int"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-7716. Erasure Coding: extend BlockInfo to handle EC info. Contributed by Jing Zhao.\n",
          "commitDate": "26/05/15 11:07 AM",
          "commitName": "ba9371492036983a9899398907ab41fe548f29b3",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "26/05/15 11:03 AM",
          "commitNameOld": "b29f3bde4d2fd2f2c4abd6d7b5f97a81bb50efb2",
          "commitAuthorOld": "Kai Zheng",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,10 @@\n-  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n-    int len \u003d getCapacity();\n-    for(int idx \u003d 0; idx \u003c len; idx++) {\n+  private int findStorageInfoFromEnd(DatanodeStorageInfo storage) {\n+    final int len \u003d getCapacity();\n+    for(int idx \u003d len - 1; idx \u003e\u003d 0; idx--) {\n       DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n-      if(cur \u003d\u003d null)\n-        break;\n-      if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n-        return cur;\n+      if (storage.equals(cur)) {\n+        return idx;\n+      }\n     }\n-    return null;\n+    return -1;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int findStorageInfoFromEnd(DatanodeStorageInfo storage) {\n    final int len \u003d getCapacity();\n    for(int idx \u003d len - 1; idx \u003e\u003d 0; idx--) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if (storage.equals(cur)) {\n        return idx;\n      }\n    }\n    return -1;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7716. Erasure Coding: extend BlockInfo to handle EC info. Contributed by Jing Zhao.\n",
          "commitDate": "26/05/15 11:07 AM",
          "commitName": "ba9371492036983a9899398907ab41fe548f29b3",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "26/05/15 11:03 AM",
          "commitNameOld": "b29f3bde4d2fd2f2c4abd6d7b5f97a81bb50efb2",
          "commitAuthorOld": "Kai Zheng",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,10 @@\n-  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n-    int len \u003d getCapacity();\n-    for(int idx \u003d 0; idx \u003c len; idx++) {\n+  private int findStorageInfoFromEnd(DatanodeStorageInfo storage) {\n+    final int len \u003d getCapacity();\n+    for(int idx \u003d len - 1; idx \u003e\u003d 0; idx--) {\n       DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n-      if(cur \u003d\u003d null)\n-        break;\n-      if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n-        return cur;\n+      if (storage.equals(cur)) {\n+        return idx;\n+      }\n     }\n-    return null;\n+    return -1;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int findStorageInfoFromEnd(DatanodeStorageInfo storage) {\n    final int len \u003d getCapacity();\n    for(int idx \u003d len - 1; idx \u003e\u003d 0; idx--) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if (storage.equals(cur)) {\n        return idx;\n      }\n    }\n    return -1;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.java",
          "extendedDetails": {}
        },
        {
          "type": "Yrename",
          "commitMessage": "HDFS-7716. Erasure Coding: extend BlockInfo to handle EC info. Contributed by Jing Zhao.\n",
          "commitDate": "26/05/15 11:07 AM",
          "commitName": "ba9371492036983a9899398907ab41fe548f29b3",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "26/05/15 11:03 AM",
          "commitNameOld": "b29f3bde4d2fd2f2c4abd6d7b5f97a81bb50efb2",
          "commitAuthorOld": "Kai Zheng",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,10 @@\n-  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n-    int len \u003d getCapacity();\n-    for(int idx \u003d 0; idx \u003c len; idx++) {\n+  private int findStorageInfoFromEnd(DatanodeStorageInfo storage) {\n+    final int len \u003d getCapacity();\n+    for(int idx \u003d len - 1; idx \u003e\u003d 0; idx--) {\n       DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n-      if(cur \u003d\u003d null)\n-        break;\n-      if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n-        return cur;\n+      if (storage.equals(cur)) {\n+        return idx;\n+      }\n     }\n-    return null;\n+    return -1;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int findStorageInfoFromEnd(DatanodeStorageInfo storage) {\n    final int len \u003d getCapacity();\n    for(int idx \u003d len - 1; idx \u003e\u003d 0; idx--) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if (storage.equals(cur)) {\n        return idx;\n      }\n    }\n    return -1;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.java",
          "extendedDetails": {
            "oldValue": "findStorageInfo",
            "newValue": "findStorageInfoFromEnd"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7716. Erasure Coding: extend BlockInfo to handle EC info. Contributed by Jing Zhao.\n",
          "commitDate": "26/05/15 11:07 AM",
          "commitName": "ba9371492036983a9899398907ab41fe548f29b3",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "26/05/15 11:03 AM",
          "commitNameOld": "b29f3bde4d2fd2f2c4abd6d7b5f97a81bb50efb2",
          "commitAuthorOld": "Kai Zheng",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,10 @@\n-  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n-    int len \u003d getCapacity();\n-    for(int idx \u003d 0; idx \u003c len; idx++) {\n+  private int findStorageInfoFromEnd(DatanodeStorageInfo storage) {\n+    final int len \u003d getCapacity();\n+    for(int idx \u003d len - 1; idx \u003e\u003d 0; idx--) {\n       DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n-      if(cur \u003d\u003d null)\n-        break;\n-      if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n-        return cur;\n+      if (storage.equals(cur)) {\n+        return idx;\n+      }\n     }\n-    return null;\n+    return -1;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int findStorageInfoFromEnd(DatanodeStorageInfo storage) {\n    final int len \u003d getCapacity();\n    for(int idx \u003d len - 1; idx \u003e\u003d 0; idx--) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if (storage.equals(cur)) {\n        return idx;\n      }\n    }\n    return -1;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.java",
          "extendedDetails": {
            "oldValue": "[dn-DatanodeDescriptor]",
            "newValue": "[storage-DatanodeStorageInfo]"
          }
        }
      ]
    },
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-7743. Code cleanup of BlockInfo and rename BlockInfo to BlockInfoContiguous. Contributed by Jing Zhao.\n",
      "commitDate": "08/02/15 11:51 AM",
      "commitName": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "07/02/15 10:43 AM",
      "commitNameOld": "ef01768333ec0e59e7d747864183835e756a7bf6",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 1.05,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n    int len \u003d getCapacity();\n    for(int idx \u003d 0; idx \u003c len; idx++) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if(cur \u003d\u003d null)\n        break;\n      if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n        return cur;\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoContiguous.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfo.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoContiguous.java"
      }
    },
    "0ed8732feef9f4027e9fc95b6d4852444c1f3426": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-6812. Remove addBlock and replaceBlock from DatanodeDescriptor.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616426 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/14 12:30 AM",
      "commitName": "0ed8732feef9f4027e9fc95b6d4852444c1f3426",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6812. Remove addBlock and replaceBlock from DatanodeDescriptor.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616426 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/08/14 12:30 AM",
          "commitName": "0ed8732feef9f4027e9fc95b6d4852444c1f3426",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "18/06/14 12:37 PM",
          "commitNameOld": "52d18aa217a308e8343ca8b23b5a2dedda77270f",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 49.5,
          "commitsBetweenForRepo": 348,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,11 @@\n-  int findStorageInfo(DatanodeInfo dn) {\n+  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n     int len \u003d getCapacity();\n     for(int idx \u003d 0; idx \u003c len; idx++) {\n       DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n       if(cur \u003d\u003d null)\n         break;\n       if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n-        return idx;\n+        return cur;\n     }\n-    return -1;\n+    return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n    int len \u003d getCapacity();\n    for(int idx \u003d 0; idx \u003c len; idx++) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if(cur \u003d\u003d null)\n        break;\n      if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n        return cur;\n    }\n    return null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfo.java",
          "extendedDetails": {
            "oldValue": "[dn-DatanodeInfo]",
            "newValue": "[dn-DatanodeDescriptor]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-6812. Remove addBlock and replaceBlock from DatanodeDescriptor.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616426 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/08/14 12:30 AM",
          "commitName": "0ed8732feef9f4027e9fc95b6d4852444c1f3426",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "18/06/14 12:37 PM",
          "commitNameOld": "52d18aa217a308e8343ca8b23b5a2dedda77270f",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 49.5,
          "commitsBetweenForRepo": 348,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,11 @@\n-  int findStorageInfo(DatanodeInfo dn) {\n+  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n     int len \u003d getCapacity();\n     for(int idx \u003d 0; idx \u003c len; idx++) {\n       DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n       if(cur \u003d\u003d null)\n         break;\n       if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n-        return idx;\n+        return cur;\n     }\n-    return -1;\n+    return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n    int len \u003d getCapacity();\n    for(int idx \u003d 0; idx \u003c len; idx++) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if(cur \u003d\u003d null)\n        break;\n      if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n        return cur;\n    }\n    return null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfo.java",
          "extendedDetails": {
            "oldValue": "int",
            "newValue": "DatanodeStorageInfo"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6812. Remove addBlock and replaceBlock from DatanodeDescriptor.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616426 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/08/14 12:30 AM",
          "commitName": "0ed8732feef9f4027e9fc95b6d4852444c1f3426",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "18/06/14 12:37 PM",
          "commitNameOld": "52d18aa217a308e8343ca8b23b5a2dedda77270f",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 49.5,
          "commitsBetweenForRepo": 348,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,11 @@\n-  int findStorageInfo(DatanodeInfo dn) {\n+  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n     int len \u003d getCapacity();\n     for(int idx \u003d 0; idx \u003c len; idx++) {\n       DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n       if(cur \u003d\u003d null)\n         break;\n       if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n-        return idx;\n+        return cur;\n     }\n-    return -1;\n+    return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  DatanodeStorageInfo findStorageInfo(DatanodeDescriptor dn) {\n    int len \u003d getCapacity();\n    for(int idx \u003d 0; idx \u003c len; idx++) {\n      DatanodeStorageInfo cur \u003d getStorageInfo(idx);\n      if(cur \u003d\u003d null)\n        break;\n      if(cur.getDatanodeDescriptor() \u003d\u003d dn)\n        return cur;\n    }\n    return null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfo.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}