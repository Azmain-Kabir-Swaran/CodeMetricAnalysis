{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeAdminManager.java",
  "functionName": "startDecommission",
  "functionId": "startDecommission___node-DatanodeDescriptor",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
  "functionStartLine": 176,
  "functionEndLine": 193,
  "numCommitsSeen": 169,
  "timeTaken": 13586,
  "changeHistory": [
    "c93cb6790e0f1c64efd03d859f907a0522010894",
    "6f81cc0beea00843b44424417f09d8ee12cd7bae",
    "79df1e750ef558afed6d166ce225a23061b36aed",
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
    "6af0d74a75f0f58d5e92e2e91e87735b9a62bb12",
    "75ead273bea8a7dad61c4f99c3a16cab2697c498",
    "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a",
    "5bd048e8378034b496bacc73b470a25d855aceb1",
    "551024915d487957d9e829493ab319c8e31dfa81",
    "282be1b38e5cd141ed7e2b2194bfb67a7c2f7f15",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
    "be7dd8333a7e56e732171db0781786987de03195",
    "0663dbaac0a19719ddf9cd4290ba893bfca69da2",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "7fac946ac983e31613fd62836c8ac9c4a579210a",
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": "Ybodychange",
    "6f81cc0beea00843b44424417f09d8ee12cd7bae": "Ybodychange",
    "79df1e750ef558afed6d166ce225a23061b36aed": "Yfilerename",
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": "Ybodychange",
    "6af0d74a75f0f58d5e92e2e91e87735b9a62bb12": "Ybodychange",
    "75ead273bea8a7dad61c4f99c3a16cab2697c498": "Ybodychange",
    "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a": "Ymultichange(Ymovefromfile,Ybodychange)",
    "5bd048e8378034b496bacc73b470a25d855aceb1": "Ybodychange",
    "551024915d487957d9e829493ab319c8e31dfa81": "Ymodifierchange",
    "282be1b38e5cd141ed7e2b2194bfb67a7c2f7f15": "Ybodychange",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": "Ybodychange",
    "be7dd8333a7e56e732171db0781786987de03195": "Ybodychange",
    "0663dbaac0a19719ddf9cd4290ba893bfca69da2": "Yexceptionschange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "7fac946ac983e31613fd62836c8ac9c4a579210a": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange)",
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange)",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14854. Create improved decommission monitor implementation. Contributed by Stephen O\u0027Donnell.\n\nReviewed-by: Inigo Goiri \u003cinigoiri@apache.org\u003e\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "10/12/19 5:16 PM",
      "commitName": "c93cb6790e0f1c64efd03d859f907a0522010894",
      "commitAuthor": "Stephen O\u0027Donnell",
      "commitDateOld": "19/10/19 5:40 PM",
      "commitNameOld": "447f46d9628db54e77f88e2d109587cc7dfd6154",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 52.02,
      "commitsBetweenForRepo": 198,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   public void startDecommission(DatanodeDescriptor node) {\n     if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n       // Update DN stats maintained by HeartbeatManager\n       hbManager.startDecommission(node);\n       // hbManager.startDecommission will set dead node to decommissioned.\n       if (node.isDecommissionInProgress()) {\n         for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n           LOG.info(\"Starting decommission of {} {} with {} blocks\",\n               node, storage, storage.numBlocks());\n         }\n         node.getLeavingServiceStatus().setStartTime(monotonicNow());\n-        pendingNodes.add(node);\n+        monitor.startTrackingNode(node);\n       }\n     } else {\n       LOG.trace(\"startDecommission: Node {} in {}, nothing to do.\",\n           node, node.getAdminState());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void startDecommission(DatanodeDescriptor node) {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      // Update DN stats maintained by HeartbeatManager\n      hbManager.startDecommission(node);\n      // hbManager.startDecommission will set dead node to decommissioned.\n      if (node.isDecommissionInProgress()) {\n        for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n          LOG.info(\"Starting decommission of {} {} with {} blocks\",\n              node, storage, storage.numBlocks());\n        }\n        node.getLeavingServiceStatus().setStartTime(monotonicNow());\n        monitor.startTrackingNode(node);\n      }\n    } else {\n      LOG.trace(\"startDecommission: Node {} in {}, nothing to do.\",\n          node, node.getAdminState());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
      "extendedDetails": {}
    },
    "6f81cc0beea00843b44424417f09d8ee12cd7bae": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13167. DatanodeAdminManager Improvements. Contributed by BELUGA BEHR.\n",
      "commitDate": "20/02/18 3:18 PM",
      "commitName": "6f81cc0beea00843b44424417f09d8ee12cd7bae",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "02/01/18 2:59 PM",
      "commitNameOld": "42a1c98597e6dba2e371510a6b2b6b1fb94e4090",
      "commitAuthorOld": "Manoj Govindassamy",
      "daysBetweenCommits": 49.01,
      "commitsBetweenForRepo": 297,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   public void startDecommission(DatanodeDescriptor node) {\n     if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n       // Update DN stats maintained by HeartbeatManager\n       hbManager.startDecommission(node);\n       // hbManager.startDecommission will set dead node to decommissioned.\n       if (node.isDecommissionInProgress()) {\n         for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n           LOG.info(\"Starting decommission of {} {} with {} blocks\",\n               node, storage, storage.numBlocks());\n         }\n         node.getLeavingServiceStatus().setStartTime(monotonicNow());\n         pendingNodes.add(node);\n       }\n     } else {\n-      LOG.trace(\"startDecommission: Node {} in {}, nothing to do.\" +\n+      LOG.trace(\"startDecommission: Node {} in {}, nothing to do.\",\n           node, node.getAdminState());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void startDecommission(DatanodeDescriptor node) {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      // Update DN stats maintained by HeartbeatManager\n      hbManager.startDecommission(node);\n      // hbManager.startDecommission will set dead node to decommissioned.\n      if (node.isDecommissionInProgress()) {\n        for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n          LOG.info(\"Starting decommission of {} {} with {} blocks\",\n              node, storage, storage.numBlocks());\n        }\n        node.getLeavingServiceStatus().setStartTime(monotonicNow());\n        pendingNodes.add(node);\n      }\n    } else {\n      LOG.trace(\"startDecommission: Node {} in {}, nothing to do.\",\n          node, node.getAdminState());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
      "extendedDetails": {}
    },
    "79df1e750ef558afed6d166ce225a23061b36aed": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-9388. Decommission related code to support Maintenance State for datanodes.\n",
      "commitDate": "02/08/17 2:22 PM",
      "commitName": "79df1e750ef558afed6d166ce225a23061b36aed",
      "commitAuthor": "Manoj Govindassamy",
      "commitDateOld": "02/08/17 12:12 PM",
      "commitNameOld": "12e44e7bdaf53d3720a89d32f0cc2717241bd6b2",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 0.09,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void startDecommission(DatanodeDescriptor node) {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      // Update DN stats maintained by HeartbeatManager\n      hbManager.startDecommission(node);\n      // hbManager.startDecommission will set dead node to decommissioned.\n      if (node.isDecommissionInProgress()) {\n        for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n          LOG.info(\"Starting decommission of {} {} with {} blocks\",\n              node, storage, storage.numBlocks());\n        }\n        node.getLeavingServiceStatus().setStartTime(monotonicNow());\n        pendingNodes.add(node);\n      }\n    } else {\n      LOG.trace(\"startDecommission: Node {} in {}, nothing to do.\" +\n          node, node.getAdminState());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java"
      }
    },
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
      "commitDate": "17/10/16 5:45 PM",
      "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
      "commitAuthor": "Ming Ma",
      "commitDateOld": "13/10/16 11:52 AM",
      "commitNameOld": "332a61fd74fd2a9874319232c583ab5d2c53ff03",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 4.25,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   public void startDecommission(DatanodeDescriptor node) {\n     if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n       // Update DN stats maintained by HeartbeatManager\n       hbManager.startDecommission(node);\n       // hbManager.startDecommission will set dead node to decommissioned.\n       if (node.isDecommissionInProgress()) {\n         for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n           LOG.info(\"Starting decommission of {} {} with {} blocks\",\n               node, storage, storage.numBlocks());\n         }\n-        node.decommissioningStatus.setStartTime(monotonicNow());\n+        node.getLeavingServiceStatus().setStartTime(monotonicNow());\n         pendingNodes.add(node);\n       }\n     } else {\n       LOG.trace(\"startDecommission: Node {} in {}, nothing to do.\" +\n           node, node.getAdminState());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void startDecommission(DatanodeDescriptor node) {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      // Update DN stats maintained by HeartbeatManager\n      hbManager.startDecommission(node);\n      // hbManager.startDecommission will set dead node to decommissioned.\n      if (node.isDecommissionInProgress()) {\n        for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n          LOG.info(\"Starting decommission of {} {} with {} blocks\",\n              node, storage, storage.numBlocks());\n        }\n        node.getLeavingServiceStatus().setStartTime(monotonicNow());\n        pendingNodes.add(node);\n      }\n    } else {\n      LOG.trace(\"startDecommission: Node {} in {}, nothing to do.\" +\n          node, node.getAdminState());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
      "extendedDetails": {}
    },
    "6af0d74a75f0f58d5e92e2e91e87735b9a62bb12": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7725. Incorrect \u0027nodes in service\u0027 metrics caused all writes to fail. Contributed by Ming Ma.\n",
      "commitDate": "08/04/15 3:52 PM",
      "commitName": "6af0d74a75f0f58d5e92e2e91e87735b9a62bb12",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "20/03/15 12:02 PM",
      "commitNameOld": "75ead273bea8a7dad61c4f99c3a16cab2697c498",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 19.16,
      "commitsBetweenForRepo": 165,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,18 @@\n   public void startDecommission(DatanodeDescriptor node) {\n-    if (!node.isDecommissionInProgress()) {\n-      if (!node.isAlive) {\n-        LOG.info(\"Dead node {} is decommissioned immediately.\", node);\n-        node.setDecommissioned();\n-      } else if (!node.isDecommissioned()) {\n+    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n+      // Update DN stats maintained by HeartbeatManager\n+      hbManager.startDecommission(node);\n+      // hbManager.startDecommission will set dead node to decommissioned.\n+      if (node.isDecommissionInProgress()) {\n         for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n-          LOG.info(\"Starting decommission of {} {} with {} blocks\", \n+          LOG.info(\"Starting decommission of {} {} with {} blocks\",\n               node, storage, storage.numBlocks());\n         }\n-        // Update DN stats maintained by HeartbeatManager\n-        hbManager.startDecommission(node);\n         node.decommissioningStatus.setStartTime(monotonicNow());\n         pendingNodes.add(node);\n       }\n     } else {\n-      LOG.trace(\"startDecommission: Node {} is already decommission in \"\n-              + \"progress, nothing to do.\", node);\n+      LOG.trace(\"startDecommission: Node {} in {}, nothing to do.\" +\n+          node, node.getAdminState());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void startDecommission(DatanodeDescriptor node) {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      // Update DN stats maintained by HeartbeatManager\n      hbManager.startDecommission(node);\n      // hbManager.startDecommission will set dead node to decommissioned.\n      if (node.isDecommissionInProgress()) {\n        for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n          LOG.info(\"Starting decommission of {} {} with {} blocks\",\n              node, storage, storage.numBlocks());\n        }\n        node.decommissioningStatus.setStartTime(monotonicNow());\n        pendingNodes.add(node);\n      }\n    } else {\n      LOG.trace(\"startDecommission: Node {} in {}, nothing to do.\" +\n          node, node.getAdminState());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
      "extendedDetails": {}
    },
    "75ead273bea8a7dad61c4f99c3a16cab2697c498": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6841. Use Time.monotonicNow() wherever applicable instead of Time.now(). Contributed by Vinayakumar B\n",
      "commitDate": "20/03/15 12:02 PM",
      "commitName": "75ead273bea8a7dad61c4f99c3a16cab2697c498",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "08/03/15 6:31 PM",
      "commitNameOld": "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 11.73,
      "commitsBetweenForRepo": 118,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n   public void startDecommission(DatanodeDescriptor node) {\n     if (!node.isDecommissionInProgress()) {\n       if (!node.isAlive) {\n         LOG.info(\"Dead node {} is decommissioned immediately.\", node);\n         node.setDecommissioned();\n       } else if (!node.isDecommissioned()) {\n         for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n           LOG.info(\"Starting decommission of {} {} with {} blocks\", \n               node, storage, storage.numBlocks());\n         }\n         // Update DN stats maintained by HeartbeatManager\n         hbManager.startDecommission(node);\n-        node.decommissioningStatus.setStartTime(now());\n+        node.decommissioningStatus.setStartTime(monotonicNow());\n         pendingNodes.add(node);\n       }\n     } else {\n       LOG.trace(\"startDecommission: Node {} is already decommission in \"\n               + \"progress, nothing to do.\", node);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void startDecommission(DatanodeDescriptor node) {\n    if (!node.isDecommissionInProgress()) {\n      if (!node.isAlive) {\n        LOG.info(\"Dead node {} is decommissioned immediately.\", node);\n        node.setDecommissioned();\n      } else if (!node.isDecommissioned()) {\n        for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n          LOG.info(\"Starting decommission of {} {} with {} blocks\", \n              node, storage, storage.numBlocks());\n        }\n        // Update DN stats maintained by HeartbeatManager\n        hbManager.startDecommission(node);\n        node.decommissioningStatus.setStartTime(monotonicNow());\n        pendingNodes.add(node);\n      }\n    } else {\n      LOG.trace(\"startDecommission: Node {} is already decommission in \"\n              + \"progress, nothing to do.\", node);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
      "extendedDetails": {}
    },
    "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-7411. Change decommission logic to throttle by blocks rather\nthan nodes in each interval. Contributed by Andrew Wang\n",
      "commitDate": "08/03/15 6:31 PM",
      "commitName": "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a",
      "commitAuthor": "Chris Douglas",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-7411. Change decommission logic to throttle by blocks rather\nthan nodes in each interval. Contributed by Andrew Wang\n",
          "commitDate": "08/03/15 6:31 PM",
          "commitName": "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a",
          "commitAuthor": "Chris Douglas",
          "commitDateOld": "08/03/15 2:47 PM",
          "commitNameOld": "7ce3c7635392c32f0504191ddd8417fb20509caa",
          "commitAuthorOld": "Junping Du",
          "daysBetweenCommits": 0.16,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,20 @@\n   public void startDecommission(DatanodeDescriptor node) {\n     if (!node.isDecommissionInProgress()) {\n       if (!node.isAlive) {\n-        LOG.info(\"Dead node \" + node + \" is decommissioned immediately.\");\n+        LOG.info(\"Dead node {} is decommissioned immediately.\", node);\n         node.setDecommissioned();\n       } else if (!node.isDecommissioned()) {\n         for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n-          LOG.info(\"Start Decommissioning \" + node + \" \" + storage\n-              + \" with \" + storage.numBlocks() + \" blocks\");\n+          LOG.info(\"Starting decommission of {} {} with {} blocks\", \n+              node, storage, storage.numBlocks());\n         }\n-        heartbeatManager.startDecommission(node);\n+        // Update DN stats maintained by HeartbeatManager\n+        hbManager.startDecommission(node);\n         node.decommissioningStatus.setStartTime(now());\n-\n-        // all the blocks that reside on this node have to be replicated.\n-        checkDecommissionState(node);\n+        pendingNodes.add(node);\n       }\n+    } else {\n+      LOG.trace(\"startDecommission: Node {} is already decommission in \"\n+              + \"progress, nothing to do.\", node);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void startDecommission(DatanodeDescriptor node) {\n    if (!node.isDecommissionInProgress()) {\n      if (!node.isAlive) {\n        LOG.info(\"Dead node {} is decommissioned immediately.\", node);\n        node.setDecommissioned();\n      } else if (!node.isDecommissioned()) {\n        for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n          LOG.info(\"Starting decommission of {} {} with {} blocks\", \n              node, storage, storage.numBlocks());\n        }\n        // Update DN stats maintained by HeartbeatManager\n        hbManager.startDecommission(node);\n        node.decommissioningStatus.setStartTime(now());\n        pendingNodes.add(node);\n      }\n    } else {\n      LOG.trace(\"startDecommission: Node {} is already decommission in \"\n              + \"progress, nothing to do.\", node);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
            "oldMethodName": "startDecommission",
            "newMethodName": "startDecommission"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7411. Change decommission logic to throttle by blocks rather\nthan nodes in each interval. Contributed by Andrew Wang\n",
          "commitDate": "08/03/15 6:31 PM",
          "commitName": "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a",
          "commitAuthor": "Chris Douglas",
          "commitDateOld": "08/03/15 2:47 PM",
          "commitNameOld": "7ce3c7635392c32f0504191ddd8417fb20509caa",
          "commitAuthorOld": "Junping Du",
          "daysBetweenCommits": 0.16,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,20 @@\n   public void startDecommission(DatanodeDescriptor node) {\n     if (!node.isDecommissionInProgress()) {\n       if (!node.isAlive) {\n-        LOG.info(\"Dead node \" + node + \" is decommissioned immediately.\");\n+        LOG.info(\"Dead node {} is decommissioned immediately.\", node);\n         node.setDecommissioned();\n       } else if (!node.isDecommissioned()) {\n         for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n-          LOG.info(\"Start Decommissioning \" + node + \" \" + storage\n-              + \" with \" + storage.numBlocks() + \" blocks\");\n+          LOG.info(\"Starting decommission of {} {} with {} blocks\", \n+              node, storage, storage.numBlocks());\n         }\n-        heartbeatManager.startDecommission(node);\n+        // Update DN stats maintained by HeartbeatManager\n+        hbManager.startDecommission(node);\n         node.decommissioningStatus.setStartTime(now());\n-\n-        // all the blocks that reside on this node have to be replicated.\n-        checkDecommissionState(node);\n+        pendingNodes.add(node);\n       }\n+    } else {\n+      LOG.trace(\"startDecommission: Node {} is already decommission in \"\n+              + \"progress, nothing to do.\", node);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void startDecommission(DatanodeDescriptor node) {\n    if (!node.isDecommissionInProgress()) {\n      if (!node.isAlive) {\n        LOG.info(\"Dead node {} is decommissioned immediately.\", node);\n        node.setDecommissioned();\n      } else if (!node.isDecommissioned()) {\n        for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n          LOG.info(\"Starting decommission of {} {} with {} blocks\", \n              node, storage, storage.numBlocks());\n        }\n        // Update DN stats maintained by HeartbeatManager\n        hbManager.startDecommission(node);\n        node.decommissioningStatus.setStartTime(now());\n        pendingNodes.add(node);\n      }\n    } else {\n      LOG.trace(\"startDecommission: Node {} is already decommission in \"\n              + \"progress, nothing to do.\", node);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "5bd048e8378034b496bacc73b470a25d855aceb1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7373. Allow decommissioning of dead DataNodes. Contributed by Zhe Zhang.\n",
      "commitDate": "18/11/14 10:16 PM",
      "commitName": "5bd048e8378034b496bacc73b470a25d855aceb1",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "18/11/14 10:14 PM",
      "commitNameOld": "406c09ad1150c4971c2b7675fcb0263d40517fbf",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,18 @@\n   public void startDecommission(DatanodeDescriptor node) {\n-    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n-      for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n-        LOG.info(\"Start Decommissioning \" + node + \" \" + storage\n-            + \" with \" + storage.numBlocks() + \" blocks\");\n+    if (!node.isDecommissionInProgress()) {\n+      if (!node.isAlive) {\n+        LOG.info(\"Dead node \" + node + \" is decommissioned immediately.\");\n+        node.setDecommissioned();\n+      } else if (!node.isDecommissioned()) {\n+        for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n+          LOG.info(\"Start Decommissioning \" + node + \" \" + storage\n+              + \" with \" + storage.numBlocks() + \" blocks\");\n+        }\n+        heartbeatManager.startDecommission(node);\n+        node.decommissioningStatus.setStartTime(now());\n+\n+        // all the blocks that reside on this node have to be replicated.\n+        checkDecommissionState(node);\n       }\n-      heartbeatManager.startDecommission(node);\n-      node.decommissioningStatus.setStartTime(now());\n-      \n-      // all the blocks that reside on this node have to be replicated.\n-      checkDecommissionState(node);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void startDecommission(DatanodeDescriptor node) {\n    if (!node.isDecommissionInProgress()) {\n      if (!node.isAlive) {\n        LOG.info(\"Dead node \" + node + \" is decommissioned immediately.\");\n        node.setDecommissioned();\n      } else if (!node.isDecommissioned()) {\n        for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n          LOG.info(\"Start Decommissioning \" + node + \" \" + storage\n              + \" with \" + storage.numBlocks() + \" blocks\");\n        }\n        heartbeatManager.startDecommission(node);\n        node.decommissioningStatus.setStartTime(now());\n\n        // all the blocks that reside on this node have to be replicated.\n        checkDecommissionState(node);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "551024915d487957d9e829493ab319c8e31dfa81": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-6599. 2.4 addBlock is 10 to 20 times slower compared to 0.23 (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1611737 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/07/14 10:58 AM",
      "commitName": "551024915d487957d9e829493ab319c8e31dfa81",
      "commitAuthor": "Daryn Sharp",
      "commitDateOld": "09/06/14 5:39 PM",
      "commitNameOld": "123c563fe6f7a655f11d7414f992d448c5047006",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 38.72,
      "commitsBetweenForRepo": 277,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n-  private void startDecommission(DatanodeDescriptor node) {\n+  public void startDecommission(DatanodeDescriptor node) {\n     if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n       for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n         LOG.info(\"Start Decommissioning \" + node + \" \" + storage\n             + \" with \" + storage.numBlocks() + \" blocks\");\n       }\n       heartbeatManager.startDecommission(node);\n       node.decommissioningStatus.setStartTime(now());\n       \n       // all the blocks that reside on this node have to be replicated.\n       checkDecommissionState(node);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void startDecommission(DatanodeDescriptor node) {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n        LOG.info(\"Start Decommissioning \" + node + \" \" + storage\n            + \" with \" + storage.numBlocks() + \" blocks\");\n      }\n      heartbeatManager.startDecommission(node);\n      node.decommissioningStatus.setStartTime(now());\n      \n      // all the blocks that reside on this node have to be replicated.\n      checkDecommissionState(node);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldValue": "[private]",
        "newValue": "[public]"
      }
    },
    "282be1b38e5cd141ed7e2b2194bfb67a7c2f7f15": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5134. Move blockContentsStale, heartbeatedSinceFailover and firstBlockReport from DatanodeDescriptor to DatanodeStorageInfo; and fix a synchronization problem in DatanodeStorageInfo.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1520938 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/09/13 3:53 PM",
      "commitName": "282be1b38e5cd141ed7e2b2194bfb67a7c2f7f15",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "03/09/13 12:01 PM",
      "commitNameOld": "336c0344f5fbcbe1b230742af7a38c6b4735bc9e",
      "commitAuthorOld": "",
      "daysBetweenCommits": 5.16,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,13 @@\n   private void startDecommission(DatanodeDescriptor node) {\n     if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n-      LOG.info(\"Start Decommissioning \" + node + \" with \" + \n-          node.numBlocks() +  \" blocks\");\n+      for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n+        LOG.info(\"Start Decommissioning \" + node + \" \" + storage\n+            + \" with \" + storage.numBlocks() + \" blocks\");\n+      }\n       heartbeatManager.startDecommission(node);\n       node.decommissioningStatus.setStartTime(now());\n       \n       // all the blocks that reside on this node have to be replicated.\n       checkDecommissionState(node);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startDecommission(DatanodeDescriptor node) {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      for (DatanodeStorageInfo storage : node.getStorageInfos()) {\n        LOG.info(\"Start Decommissioning \" + node + \" \" + storage\n            + \" with \" + storage.numBlocks() + \" blocks\");\n      }\n      heartbeatManager.startDecommission(node);\n      node.decommissioningStatus.setStartTime(now());\n      \n      // all the blocks that reside on this node have to be replicated.\n      checkDecommissionState(node);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4122. Cleanup HDFS logs and reduce the size of logged messages. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1403120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/10/12 4:10 PM",
      "commitName": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "17/10/12 2:34 PM",
      "commitNameOld": "4d5600f6c714732d16bed29f0bc210eb72901545",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 11.07,
      "commitsBetweenForRepo": 61,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n   private void startDecommission(DatanodeDescriptor node) {\n     if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n-      LOG.info(\"Start Decommissioning node \" + node + \" with \" + \n-          node.numBlocks() +  \" blocks.\");\n+      LOG.info(\"Start Decommissioning \" + node + \" with \" + \n+          node.numBlocks() +  \" blocks\");\n       heartbeatManager.startDecommission(node);\n       node.decommissioningStatus.setStartTime(now());\n       \n       // all the blocks that reside on this node have to be replicated.\n       checkDecommissionState(node);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startDecommission(DatanodeDescriptor node) {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      LOG.info(\"Start Decommissioning \" + node + \" with \" + \n          node.numBlocks() +  \" blocks\");\n      heartbeatManager.startDecommission(node);\n      node.decommissioningStatus.setStartTime(now());\n      \n      // all the blocks that reside on this node have to be replicated.\n      checkDecommissionState(node);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "be7dd8333a7e56e732171db0781786987de03195": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3144. Refactor DatanodeID#getName by use. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308205 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/04/12 3:12 PM",
      "commitName": "be7dd8333a7e56e732171db0781786987de03195",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "31/03/12 8:41 PM",
      "commitNameOld": "0663dbaac0a19719ddf9cd4290ba893bfca69da2",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.77,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n   private void startDecommission(DatanodeDescriptor node) {\n     if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n-      LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n+      LOG.info(\"Start Decommissioning node \" + node + \" with \" + \n           node.numBlocks() +  \" blocks.\");\n       heartbeatManager.startDecommission(node);\n       node.decommissioningStatus.setStartTime(now());\n       \n       // all the blocks that reside on this node have to be replicated.\n       checkDecommissionState(node);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startDecommission(DatanodeDescriptor node) {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      LOG.info(\"Start Decommissioning node \" + node + \" with \" + \n          node.numBlocks() +  \" blocks.\");\n      heartbeatManager.startDecommission(node);\n      node.decommissioningStatus.setStartTime(now());\n      \n      // all the blocks that reside on this node have to be replicated.\n      checkDecommissionState(node);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "0663dbaac0a19719ddf9cd4290ba893bfca69da2": {
      "type": "Yexceptionschange",
      "commitMessage": "HDFS-3171. The DatanodeID \"name\" field is overloaded. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308014 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/03/12 8:41 PM",
      "commitName": "0663dbaac0a19719ddf9cd4290ba893bfca69da2",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "31/03/12 12:58 PM",
      "commitNameOld": "8bd825bb6f35fd6fef397e3ccae0898bf7bed201",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.32,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n-  private void startDecommission(DatanodeDescriptor node) throws IOException {\n+  private void startDecommission(DatanodeDescriptor node) {\n     if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n       LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n           node.numBlocks() +  \" blocks.\");\n       heartbeatManager.startDecommission(node);\n       node.decommissioningStatus.setStartTime(now());\n       \n       // all the blocks that reside on this node have to be replicated.\n       checkDecommissionState(node);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startDecommission(DatanodeDescriptor node) {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n          node.numBlocks() +  \" blocks.\");\n      heartbeatManager.startDecommission(node);\n      node.decommissioningStatus.setStartTime(now());\n      \n      // all the blocks that reside on this node have to be replicated.\n      checkDecommissionState(node);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldValue": "[IOException]",
        "newValue": "[]"
      }
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void startDecommission(DatanodeDescriptor node) throws IOException {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n          node.numBlocks() +  \" blocks.\");\n      heartbeatManager.startDecommission(node);\n      node.decommissioningStatus.setStartTime(now());\n      \n      // all the blocks that reside on this node have to be replicated.\n      checkDecommissionState(node);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void startDecommission(DatanodeDescriptor node) throws IOException {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n          node.numBlocks() +  \" blocks.\");\n      heartbeatManager.startDecommission(node);\n      node.decommissioningStatus.setStartTime(now());\n      \n      // all the blocks that reside on this node have to be replicated.\n      checkDecommissionState(node);\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java"
      }
    },
    "7fac946ac983e31613fd62836c8ac9c4a579210a": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-2108. Move datanode heartbeat handling from namenode package to blockmanagement package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154042 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/08/11 3:55 PM",
      "commitName": "7fac946ac983e31613fd62836c8ac9c4a579210a",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-2108. Move datanode heartbeat handling from namenode package to blockmanagement package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154042 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/08/11 3:55 PM",
          "commitName": "7fac946ac983e31613fd62836c8ac9c4a579210a",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "04/08/11 2:56 PM",
          "commitNameOld": "23762da4fa17ce6ea7b70722147977123a28a7e6",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,11 @@\n-  void startDecommission(DatanodeDescriptor node) throws IOException {\n+  private void startDecommission(DatanodeDescriptor node) throws IOException {\n     if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n       LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n           node.numBlocks() +  \" blocks.\");\n-      synchronized (namesystem.heartbeats) {\n-        namesystem.updateStats(node, false);\n-        node.startDecommission();\n-        namesystem.updateStats(node, true);\n-      }\n+      heartbeatManager.startDecommission(node);\n       node.decommissioningStatus.setStartTime(now());\n       \n       // all the blocks that reside on this node have to be replicated.\n-      checkDecommissionStateInternal(node);\n+      checkDecommissionState(node);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void startDecommission(DatanodeDescriptor node) throws IOException {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n          node.numBlocks() +  \" blocks.\");\n      heartbeatManager.startDecommission(node);\n      node.decommissioningStatus.setStartTime(now());\n      \n      // all the blocks that reside on this node have to be replicated.\n      checkDecommissionState(node);\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {
            "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
            "newPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
            "oldMethodName": "startDecommission",
            "newMethodName": "startDecommission"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-2108. Move datanode heartbeat handling from namenode package to blockmanagement package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154042 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/08/11 3:55 PM",
          "commitName": "7fac946ac983e31613fd62836c8ac9c4a579210a",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "04/08/11 2:56 PM",
          "commitNameOld": "23762da4fa17ce6ea7b70722147977123a28a7e6",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,11 @@\n-  void startDecommission(DatanodeDescriptor node) throws IOException {\n+  private void startDecommission(DatanodeDescriptor node) throws IOException {\n     if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n       LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n           node.numBlocks() +  \" blocks.\");\n-      synchronized (namesystem.heartbeats) {\n-        namesystem.updateStats(node, false);\n-        node.startDecommission();\n-        namesystem.updateStats(node, true);\n-      }\n+      heartbeatManager.startDecommission(node);\n       node.decommissioningStatus.setStartTime(now());\n       \n       // all the blocks that reside on this node have to be replicated.\n-      checkDecommissionStateInternal(node);\n+      checkDecommissionState(node);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void startDecommission(DatanodeDescriptor node) throws IOException {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n          node.numBlocks() +  \" blocks.\");\n      heartbeatManager.startDecommission(node);\n      node.decommissioningStatus.setStartTime(now());\n      \n      // all the blocks that reside on this node have to be replicated.\n      checkDecommissionState(node);\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2108. Move datanode heartbeat handling from namenode package to blockmanagement package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154042 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/08/11 3:55 PM",
          "commitName": "7fac946ac983e31613fd62836c8ac9c4a579210a",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "04/08/11 2:56 PM",
          "commitNameOld": "23762da4fa17ce6ea7b70722147977123a28a7e6",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,11 @@\n-  void startDecommission(DatanodeDescriptor node) throws IOException {\n+  private void startDecommission(DatanodeDescriptor node) throws IOException {\n     if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n       LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n           node.numBlocks() +  \" blocks.\");\n-      synchronized (namesystem.heartbeats) {\n-        namesystem.updateStats(node, false);\n-        node.startDecommission();\n-        namesystem.updateStats(node, true);\n-      }\n+      heartbeatManager.startDecommission(node);\n       node.decommissioningStatus.setStartTime(now());\n       \n       // all the blocks that reside on this node have to be replicated.\n-      checkDecommissionStateInternal(node);\n+      checkDecommissionState(node);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void startDecommission(DatanodeDescriptor node) throws IOException {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n          node.numBlocks() +  \" blocks.\");\n      heartbeatManager.startDecommission(node);\n      node.decommissioningStatus.setStartTime(now());\n      \n      // all the blocks that reside on this node have to be replicated.\n      checkDecommissionState(node);\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-2167.  Move dnsToSwitchMapping and hostsReader from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149455 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/07/11 9:20 PM",
      "commitName": "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-2167.  Move dnsToSwitchMapping and hostsReader from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149455 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/07/11 9:20 PM",
          "commitName": "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/07/11 12:16 PM",
          "commitNameOld": "c187bdc0a28e4f3b9378e2b1daa964c23b599383",
          "commitAuthorOld": "Owen O\u0027Malley",
          "daysBetweenCommits": 0.38,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,15 @@\n-  private void startDecommission(DatanodeDescriptor node) \n-    throws IOException {\n-    assert hasWriteLock();\n+  void startDecommission(DatanodeDescriptor node) throws IOException {\n     if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n       LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n           node.numBlocks() +  \" blocks.\");\n-      synchronized (heartbeats) {\n-        updateStats(node, false);\n+      synchronized (namesystem.heartbeats) {\n+        namesystem.updateStats(node, false);\n         node.startDecommission();\n-        updateStats(node, true);\n+        namesystem.updateStats(node, true);\n       }\n       node.decommissioningStatus.setStartTime(now());\n       \n       // all the blocks that reside on this node have to be replicated.\n       checkDecommissionStateInternal(node);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void startDecommission(DatanodeDescriptor node) throws IOException {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n          node.numBlocks() +  \" blocks.\");\n      synchronized (namesystem.heartbeats) {\n        namesystem.updateStats(node, false);\n        node.startDecommission();\n        namesystem.updateStats(node, true);\n      }\n      node.decommissioningStatus.setStartTime(now());\n      \n      // all the blocks that reside on this node have to be replicated.\n      checkDecommissionStateInternal(node);\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
            "newPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
            "oldMethodName": "startDecommission",
            "newMethodName": "startDecommission"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-2167.  Move dnsToSwitchMapping and hostsReader from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149455 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/07/11 9:20 PM",
          "commitName": "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/07/11 12:16 PM",
          "commitNameOld": "c187bdc0a28e4f3b9378e2b1daa964c23b599383",
          "commitAuthorOld": "Owen O\u0027Malley",
          "daysBetweenCommits": 0.38,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,15 @@\n-  private void startDecommission(DatanodeDescriptor node) \n-    throws IOException {\n-    assert hasWriteLock();\n+  void startDecommission(DatanodeDescriptor node) throws IOException {\n     if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n       LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n           node.numBlocks() +  \" blocks.\");\n-      synchronized (heartbeats) {\n-        updateStats(node, false);\n+      synchronized (namesystem.heartbeats) {\n+        namesystem.updateStats(node, false);\n         node.startDecommission();\n-        updateStats(node, true);\n+        namesystem.updateStats(node, true);\n       }\n       node.decommissioningStatus.setStartTime(now());\n       \n       // all the blocks that reside on this node have to be replicated.\n       checkDecommissionStateInternal(node);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void startDecommission(DatanodeDescriptor node) throws IOException {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n          node.numBlocks() +  \" blocks.\");\n      synchronized (namesystem.heartbeats) {\n        namesystem.updateStats(node, false);\n        node.startDecommission();\n        namesystem.updateStats(node, true);\n      }\n      node.decommissioningStatus.setStartTime(now());\n      \n      // all the blocks that reside on this node have to be replicated.\n      checkDecommissionStateInternal(node);\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2167.  Move dnsToSwitchMapping and hostsReader from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149455 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/07/11 9:20 PM",
          "commitName": "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/07/11 12:16 PM",
          "commitNameOld": "c187bdc0a28e4f3b9378e2b1daa964c23b599383",
          "commitAuthorOld": "Owen O\u0027Malley",
          "daysBetweenCommits": 0.38,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,15 @@\n-  private void startDecommission(DatanodeDescriptor node) \n-    throws IOException {\n-    assert hasWriteLock();\n+  void startDecommission(DatanodeDescriptor node) throws IOException {\n     if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n       LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n           node.numBlocks() +  \" blocks.\");\n-      synchronized (heartbeats) {\n-        updateStats(node, false);\n+      synchronized (namesystem.heartbeats) {\n+        namesystem.updateStats(node, false);\n         node.startDecommission();\n-        updateStats(node, true);\n+        namesystem.updateStats(node, true);\n       }\n       node.decommissioningStatus.setStartTime(now());\n       \n       // all the blocks that reside on this node have to be replicated.\n       checkDecommissionStateInternal(node);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void startDecommission(DatanodeDescriptor node) throws IOException {\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n          node.numBlocks() +  \" blocks.\");\n      synchronized (namesystem.heartbeats) {\n        namesystem.updateStats(node, false);\n        node.startDecommission();\n        namesystem.updateStats(node, true);\n      }\n      node.decommissioningStatus.setStartTime(now());\n      \n      // all the blocks that reside on this node have to be replicated.\n      checkDecommissionStateInternal(node);\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,17 @@\n+  private void startDecommission(DatanodeDescriptor node) \n+    throws IOException {\n+    assert hasWriteLock();\n+    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n+      LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n+          node.numBlocks() +  \" blocks.\");\n+      synchronized (heartbeats) {\n+        updateStats(node, false);\n+        node.startDecommission();\n+        updateStats(node, true);\n+      }\n+      node.decommissioningStatus.setStartTime(now());\n+      \n+      // all the blocks that reside on this node have to be replicated.\n+      checkDecommissionStateInternal(node);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void startDecommission(DatanodeDescriptor node) \n    throws IOException {\n    assert hasWriteLock();\n    if (!node.isDecommissionInProgress() \u0026\u0026 !node.isDecommissioned()) {\n      LOG.info(\"Start Decommissioning node \" + node.getName() + \" with \" + \n          node.numBlocks() +  \" blocks.\");\n      synchronized (heartbeats) {\n        updateStats(node, false);\n        node.startDecommission();\n        updateStats(node, true);\n      }\n      node.decommissioningStatus.setStartTime(now());\n      \n      // all the blocks that reside on this node have to be replicated.\n      checkDecommissionStateInternal(node);\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}