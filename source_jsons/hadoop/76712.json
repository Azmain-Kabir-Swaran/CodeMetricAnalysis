{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RSRawDecoder.java",
  "functionName": "doDecode",
  "functionId": "doDecode___decodingState-ByteBufferDecodingState",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawDecoder.java",
  "functionStartLine": 74,
  "functionEndLine": 84,
  "numCommitsSeen": 22,
  "timeTaken": 2486,
  "changeHistory": [
    "77202fa1035a54496d11d07472fbc399148ff630",
    "19e8f076919932b17f24ec4090df1926677651e7",
    "c89a14a8a4fe58f01f0cba643f2bc203e1a8701e"
  ],
  "changeHistoryShort": {
    "77202fa1035a54496d11d07472fbc399148ff630": "Ymultichange(Yparameterchange,Ybodychange)",
    "19e8f076919932b17f24ec4090df1926677651e7": "Ymultichange(Yfilerename,Ybodychange)",
    "c89a14a8a4fe58f01f0cba643f2bc203e1a8701e": "Yintroduced"
  },
  "changeHistoryDetails": {
    "77202fa1035a54496d11d07472fbc399148ff630": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HADOOP-13010. Refactor raw erasure coders. Contributed by Kai Zheng\n",
      "commitDate": "26/05/16 10:23 PM",
      "commitName": "77202fa1035a54496d11d07472fbc399148ff630",
      "commitAuthor": "Kai Zheng",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-13010. Refactor raw erasure coders. Contributed by Kai Zheng\n",
          "commitDate": "26/05/16 10:23 PM",
          "commitName": "77202fa1035a54496d11d07472fbc399148ff630",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "14/03/16 4:45 PM",
          "commitNameOld": "19e8f076919932b17f24ec4090df1926677651e7",
          "commitAuthorOld": "Zhe Zhang",
          "daysBetweenCommits": 73.23,
          "commitsBetweenForRepo": 460,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,10 +1,11 @@\n-  protected void doDecode(ByteBuffer[] inputs, int[] erasedIndexes,\n-                          ByteBuffer[] outputs) {\n-    prepareDecoding(inputs, erasedIndexes);\n+  protected void doDecode(ByteBufferDecodingState decodingState) {\n+    CoderUtil.resetOutputBuffers(decodingState.outputs,\n+        decodingState.decodeLength);\n+    prepareDecoding(decodingState.inputs, decodingState.erasedIndexes);\n \n     ByteBuffer[] realInputs \u003d new ByteBuffer[getNumDataUnits()];\n     for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n-      realInputs[i] \u003d inputs[validIndexes[i]];\n+      realInputs[i] \u003d decodingState.inputs[validIndexes[i]];\n     }\n-    RSUtil.encodeData(gfTables, realInputs, outputs);\n+    RSUtil.encodeData(gfTables, realInputs, decodingState.outputs);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void doDecode(ByteBufferDecodingState decodingState) {\n    CoderUtil.resetOutputBuffers(decodingState.outputs,\n        decodingState.decodeLength);\n    prepareDecoding(decodingState.inputs, decodingState.erasedIndexes);\n\n    ByteBuffer[] realInputs \u003d new ByteBuffer[getNumDataUnits()];\n    for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n      realInputs[i] \u003d decodingState.inputs[validIndexes[i]];\n    }\n    RSUtil.encodeData(gfTables, realInputs, decodingState.outputs);\n  }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawDecoder.java",
          "extendedDetails": {
            "oldValue": "[inputs-ByteBuffer[], erasedIndexes-int[], outputs-ByteBuffer[]]",
            "newValue": "[decodingState-ByteBufferDecodingState]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-13010. Refactor raw erasure coders. Contributed by Kai Zheng\n",
          "commitDate": "26/05/16 10:23 PM",
          "commitName": "77202fa1035a54496d11d07472fbc399148ff630",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "14/03/16 4:45 PM",
          "commitNameOld": "19e8f076919932b17f24ec4090df1926677651e7",
          "commitAuthorOld": "Zhe Zhang",
          "daysBetweenCommits": 73.23,
          "commitsBetweenForRepo": 460,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,10 +1,11 @@\n-  protected void doDecode(ByteBuffer[] inputs, int[] erasedIndexes,\n-                          ByteBuffer[] outputs) {\n-    prepareDecoding(inputs, erasedIndexes);\n+  protected void doDecode(ByteBufferDecodingState decodingState) {\n+    CoderUtil.resetOutputBuffers(decodingState.outputs,\n+        decodingState.decodeLength);\n+    prepareDecoding(decodingState.inputs, decodingState.erasedIndexes);\n \n     ByteBuffer[] realInputs \u003d new ByteBuffer[getNumDataUnits()];\n     for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n-      realInputs[i] \u003d inputs[validIndexes[i]];\n+      realInputs[i] \u003d decodingState.inputs[validIndexes[i]];\n     }\n-    RSUtil.encodeData(gfTables, realInputs, outputs);\n+    RSUtil.encodeData(gfTables, realInputs, decodingState.outputs);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void doDecode(ByteBufferDecodingState decodingState) {\n    CoderUtil.resetOutputBuffers(decodingState.outputs,\n        decodingState.decodeLength);\n    prepareDecoding(decodingState.inputs, decodingState.erasedIndexes);\n\n    ByteBuffer[] realInputs \u003d new ByteBuffer[getNumDataUnits()];\n    for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n      realInputs[i] \u003d decodingState.inputs[validIndexes[i]];\n    }\n    RSUtil.encodeData(gfTables, realInputs, decodingState.outputs);\n  }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawDecoder.java",
          "extendedDetails": {}
        }
      ]
    },
    "19e8f076919932b17f24ec4090df1926677651e7": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "HADOOP-12826. Rename the new Java coder and make it default. Contributed by Rui Li.\n",
      "commitDate": "14/03/16 4:45 PM",
      "commitName": "19e8f076919932b17f24ec4090df1926677651e7",
      "commitAuthor": "Zhe Zhang",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "HADOOP-12826. Rename the new Java coder and make it default. Contributed by Rui Li.\n",
          "commitDate": "14/03/16 4:45 PM",
          "commitName": "19e8f076919932b17f24ec4090df1926677651e7",
          "commitAuthor": "Zhe Zhang",
          "commitDateOld": "14/03/16 3:48 PM",
          "commitNameOld": "1898810cda83e6d273a2963b56ed499c0fb91118",
          "commitAuthorOld": "Tsz-Wo Nicholas Sze",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,10 +1,10 @@\n   protected void doDecode(ByteBuffer[] inputs, int[] erasedIndexes,\n                           ByteBuffer[] outputs) {\n     prepareDecoding(inputs, erasedIndexes);\n \n     ByteBuffer[] realInputs \u003d new ByteBuffer[getNumDataUnits()];\n     for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n       realInputs[i] \u003d inputs[validIndexes[i]];\n     }\n-    RSUtil2.encodeData(gfTables, realInputs, outputs);\n+    RSUtil.encodeData(gfTables, realInputs, outputs);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void doDecode(ByteBuffer[] inputs, int[] erasedIndexes,\n                          ByteBuffer[] outputs) {\n    prepareDecoding(inputs, erasedIndexes);\n\n    ByteBuffer[] realInputs \u003d new ByteBuffer[getNumDataUnits()];\n    for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n      realInputs[i] \u003d inputs[validIndexes[i]];\n    }\n    RSUtil.encodeData(gfTables, realInputs, outputs);\n  }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawDecoder.java",
          "extendedDetails": {
            "oldPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawDecoder2.java",
            "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawDecoder.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-12826. Rename the new Java coder and make it default. Contributed by Rui Li.\n",
          "commitDate": "14/03/16 4:45 PM",
          "commitName": "19e8f076919932b17f24ec4090df1926677651e7",
          "commitAuthor": "Zhe Zhang",
          "commitDateOld": "14/03/16 3:48 PM",
          "commitNameOld": "1898810cda83e6d273a2963b56ed499c0fb91118",
          "commitAuthorOld": "Tsz-Wo Nicholas Sze",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,10 +1,10 @@\n   protected void doDecode(ByteBuffer[] inputs, int[] erasedIndexes,\n                           ByteBuffer[] outputs) {\n     prepareDecoding(inputs, erasedIndexes);\n \n     ByteBuffer[] realInputs \u003d new ByteBuffer[getNumDataUnits()];\n     for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n       realInputs[i] \u003d inputs[validIndexes[i]];\n     }\n-    RSUtil2.encodeData(gfTables, realInputs, outputs);\n+    RSUtil.encodeData(gfTables, realInputs, outputs);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void doDecode(ByteBuffer[] inputs, int[] erasedIndexes,\n                          ByteBuffer[] outputs) {\n    prepareDecoding(inputs, erasedIndexes);\n\n    ByteBuffer[] realInputs \u003d new ByteBuffer[getNumDataUnits()];\n    for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n      realInputs[i] \u003d inputs[validIndexes[i]];\n    }\n    RSUtil.encodeData(gfTables, realInputs, outputs);\n  }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawDecoder.java",
          "extendedDetails": {}
        }
      ]
    },
    "c89a14a8a4fe58f01f0cba643f2bc203e1a8701e": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-12041. Implement another Reed-Solomon coder in pure Java. Contributed by Kai Zheng.\n\nChange-Id: I35ff2e498d4f988c9a064f74374f7c7258b7a6b7\n",
      "commitDate": "03/02/16 3:05 PM",
      "commitName": "c89a14a8a4fe58f01f0cba643f2bc203e1a8701e",
      "commitAuthor": "zhezhang",
      "diff": "@@ -0,0 +1,10 @@\n+  protected void doDecode(ByteBuffer[] inputs, int[] erasedIndexes,\n+                          ByteBuffer[] outputs) {\n+    prepareDecoding(inputs, erasedIndexes);\n+\n+    ByteBuffer[] realInputs \u003d new ByteBuffer[getNumDataUnits()];\n+    for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n+      realInputs[i] \u003d inputs[validIndexes[i]];\n+    }\n+    RSUtil2.encodeData(gfTables, realInputs, outputs);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected void doDecode(ByteBuffer[] inputs, int[] erasedIndexes,\n                          ByteBuffer[] outputs) {\n    prepareDecoding(inputs, erasedIndexes);\n\n    ByteBuffer[] realInputs \u003d new ByteBuffer[getNumDataUnits()];\n    for (int i \u003d 0; i \u003c getNumDataUnits(); i++) {\n      realInputs[i] \u003d inputs[validIndexes[i]];\n    }\n    RSUtil2.encodeData(gfTables, realInputs, outputs);\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/RSRawDecoder2.java"
    }
  }
}