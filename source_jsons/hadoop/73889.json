{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Server.java",
  "functionName": "unwrapPacketAndProcessRpcs",
  "functionId": "unwrapPacketAndProcessRpcs___inBuf-byte[]",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
  "functionStartLine": 2487,
  "functionEndLine": 2523,
  "numCommitsSeen": 257,
  "timeTaken": 7245,
  "changeHistory": [
    "b6bb99c18a772d2179d5cc6757cddf141e8d39c0",
    "580a8334963709e728ed677c815fb7fef9bca70e",
    "c03c8fe199429a43c6aa944016566738abd9b193",
    "63a1273f2a8e0b668ff70330262adedee63112d9",
    "65be21267587f04a2c33af65b951211cc9085b15",
    "a3a9d72e98a9cc0f94af7c832dd13c408856636d",
    "eb2a60338715e517ba8e4d32ecfe28691a882188",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
    "940389afce6a1b9b9e1519aed528cbc444786756"
  ],
  "changeHistoryShort": {
    "b6bb99c18a772d2179d5cc6757cddf141e8d39c0": "Ymultichange(Yexceptionschange,Ybodychange)",
    "580a8334963709e728ed677c815fb7fef9bca70e": "Ybodychange",
    "c03c8fe199429a43c6aa944016566738abd9b193": "Ybodychange",
    "63a1273f2a8e0b668ff70330262adedee63112d9": "Ybodychange",
    "65be21267587f04a2c33af65b951211cc9085b15": "Yexceptionschange",
    "a3a9d72e98a9cc0f94af7c832dd13c408856636d": "Yrename",
    "eb2a60338715e517ba8e4d32ecfe28691a882188": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yfilerename",
    "940389afce6a1b9b9e1519aed528cbc444786756": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b6bb99c18a772d2179d5cc6757cddf141e8d39c0": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HADOOP-14034. Allow ipc layer exceptions to selectively close connections. Contributed by Daryn Sharp.\n",
      "commitDate": "09/02/17 8:47 AM",
      "commitName": "b6bb99c18a772d2179d5cc6757cddf141e8d39c0",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HADOOP-14034. Allow ipc layer exceptions to selectively close connections. Contributed by Daryn Sharp.\n",
          "commitDate": "09/02/17 8:47 AM",
          "commitName": "b6bb99c18a772d2179d5cc6757cddf141e8d39c0",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "28/11/16 9:07 PM",
          "commitNameOld": "67d9f2808efb34b9a7b0b824cb4033b95ad33474",
          "commitAuthorOld": "Akira Ajisaka",
          "daysBetweenCommits": 72.49,
          "commitsBetweenForRepo": 352,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,36 +1,37 @@\n     private void unwrapPacketAndProcessRpcs(byte[] inBuf)\n-        throws WrappedRpcServerException, IOException, InterruptedException {\n+        throws IOException, InterruptedException {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Have read input token of size \" + inBuf.length\n             + \" for processing by saslServer.unwrap()\");\n       }\n       inBuf \u003d saslServer.unwrap(inBuf, 0, inBuf.length);\n       ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n           inBuf));\n       // Read all RPCs contained in the inBuf, even partial ones\n-      while (true) {\n+      while (!shouldClose()) { // stop if a fatal response has been sent.\n         int count \u003d -1;\n         if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n           count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n           if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n             return;\n         }\n \n         if (unwrappedData \u003d\u003d null) {\n           unwrappedDataLengthBuffer.flip();\n           int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n           unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n         }\n \n         count \u003d channelRead(ch, unwrappedData);\n         if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n           return;\n \n         if (unwrappedData.remaining() \u003d\u003d 0) {\n           unwrappedDataLengthBuffer.clear();\n           unwrappedData.flip();\n-          processOneRpc(unwrappedData);\n-          unwrappedData \u003d null;\n+          ByteBuffer requestData \u003d unwrappedData;\n+          unwrappedData \u003d null; // null out in case processOneRpc throws.\n+          processOneRpc(requestData);\n         }\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void unwrapPacketAndProcessRpcs(byte[] inBuf)\n        throws IOException, InterruptedException {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Have read input token of size \" + inBuf.length\n            + \" for processing by saslServer.unwrap()\");\n      }\n      inBuf \u003d saslServer.unwrap(inBuf, 0, inBuf.length);\n      ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n          inBuf));\n      // Read all RPCs contained in the inBuf, even partial ones\n      while (!shouldClose()) { // stop if a fatal response has been sent.\n        int count \u003d -1;\n        if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n          count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n          if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n            return;\n        }\n\n        if (unwrappedData \u003d\u003d null) {\n          unwrappedDataLengthBuffer.flip();\n          int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n          unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n        }\n\n        count \u003d channelRead(ch, unwrappedData);\n        if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n          return;\n\n        if (unwrappedData.remaining() \u003d\u003d 0) {\n          unwrappedDataLengthBuffer.clear();\n          unwrappedData.flip();\n          ByteBuffer requestData \u003d unwrappedData;\n          unwrappedData \u003d null; // null out in case processOneRpc throws.\n          processOneRpc(requestData);\n        }\n      }\n    }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
          "extendedDetails": {
            "oldValue": "[WrappedRpcServerException, IOException, InterruptedException]",
            "newValue": "[IOException, InterruptedException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-14034. Allow ipc layer exceptions to selectively close connections. Contributed by Daryn Sharp.\n",
          "commitDate": "09/02/17 8:47 AM",
          "commitName": "b6bb99c18a772d2179d5cc6757cddf141e8d39c0",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "28/11/16 9:07 PM",
          "commitNameOld": "67d9f2808efb34b9a7b0b824cb4033b95ad33474",
          "commitAuthorOld": "Akira Ajisaka",
          "daysBetweenCommits": 72.49,
          "commitsBetweenForRepo": 352,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,36 +1,37 @@\n     private void unwrapPacketAndProcessRpcs(byte[] inBuf)\n-        throws WrappedRpcServerException, IOException, InterruptedException {\n+        throws IOException, InterruptedException {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Have read input token of size \" + inBuf.length\n             + \" for processing by saslServer.unwrap()\");\n       }\n       inBuf \u003d saslServer.unwrap(inBuf, 0, inBuf.length);\n       ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n           inBuf));\n       // Read all RPCs contained in the inBuf, even partial ones\n-      while (true) {\n+      while (!shouldClose()) { // stop if a fatal response has been sent.\n         int count \u003d -1;\n         if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n           count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n           if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n             return;\n         }\n \n         if (unwrappedData \u003d\u003d null) {\n           unwrappedDataLengthBuffer.flip();\n           int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n           unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n         }\n \n         count \u003d channelRead(ch, unwrappedData);\n         if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n           return;\n \n         if (unwrappedData.remaining() \u003d\u003d 0) {\n           unwrappedDataLengthBuffer.clear();\n           unwrappedData.flip();\n-          processOneRpc(unwrappedData);\n-          unwrappedData \u003d null;\n+          ByteBuffer requestData \u003d unwrappedData;\n+          unwrappedData \u003d null; // null out in case processOneRpc throws.\n+          processOneRpc(requestData);\n         }\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void unwrapPacketAndProcessRpcs(byte[] inBuf)\n        throws IOException, InterruptedException {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Have read input token of size \" + inBuf.length\n            + \" for processing by saslServer.unwrap()\");\n      }\n      inBuf \u003d saslServer.unwrap(inBuf, 0, inBuf.length);\n      ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n          inBuf));\n      // Read all RPCs contained in the inBuf, even partial ones\n      while (!shouldClose()) { // stop if a fatal response has been sent.\n        int count \u003d -1;\n        if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n          count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n          if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n            return;\n        }\n\n        if (unwrappedData \u003d\u003d null) {\n          unwrappedDataLengthBuffer.flip();\n          int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n          unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n        }\n\n        count \u003d channelRead(ch, unwrappedData);\n        if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n          return;\n\n        if (unwrappedData.remaining() \u003d\u003d 0) {\n          unwrappedDataLengthBuffer.clear();\n          unwrappedData.flip();\n          ByteBuffer requestData \u003d unwrappedData;\n          unwrappedData \u003d null; // null out in case processOneRpc throws.\n          processOneRpc(requestData);\n        }\n      }\n    }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
          "extendedDetails": {}
        }
      ]
    },
    "580a8334963709e728ed677c815fb7fef9bca70e": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13483. Optimize IPC server protobuf decoding. Contributed by Daryn Sharp.\n",
      "commitDate": "03/08/16 11:22 AM",
      "commitName": "580a8334963709e728ed677c815fb7fef9bca70e",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "03/08/16 7:31 AM",
      "commitNameOld": "2d8227605fe22c1c05f31729edc8939013763c05",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.16,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,36 @@\n     private void unwrapPacketAndProcessRpcs(byte[] inBuf)\n         throws WrappedRpcServerException, IOException, InterruptedException {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Have read input token of size \" + inBuf.length\n             + \" for processing by saslServer.unwrap()\");\n       }\n       inBuf \u003d saslServer.unwrap(inBuf, 0, inBuf.length);\n       ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n           inBuf));\n       // Read all RPCs contained in the inBuf, even partial ones\n       while (true) {\n         int count \u003d -1;\n         if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n           count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n           if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n             return;\n         }\n \n         if (unwrappedData \u003d\u003d null) {\n           unwrappedDataLengthBuffer.flip();\n           int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n           unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n         }\n \n         count \u003d channelRead(ch, unwrappedData);\n         if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n           return;\n \n         if (unwrappedData.remaining() \u003d\u003d 0) {\n           unwrappedDataLengthBuffer.clear();\n           unwrappedData.flip();\n-          processOneRpc(unwrappedData.array());\n+          processOneRpc(unwrappedData);\n           unwrappedData \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void unwrapPacketAndProcessRpcs(byte[] inBuf)\n        throws WrappedRpcServerException, IOException, InterruptedException {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Have read input token of size \" + inBuf.length\n            + \" for processing by saslServer.unwrap()\");\n      }\n      inBuf \u003d saslServer.unwrap(inBuf, 0, inBuf.length);\n      ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n          inBuf));\n      // Read all RPCs contained in the inBuf, even partial ones\n      while (true) {\n        int count \u003d -1;\n        if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n          count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n          if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n            return;\n        }\n\n        if (unwrappedData \u003d\u003d null) {\n          unwrappedDataLengthBuffer.flip();\n          int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n          unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n        }\n\n        count \u003d channelRead(ch, unwrappedData);\n        if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n          return;\n\n        if (unwrappedData.remaining() \u003d\u003d 0) {\n          unwrappedDataLengthBuffer.clear();\n          unwrappedData.flip();\n          processOneRpc(unwrappedData);\n          unwrappedData \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "c03c8fe199429a43c6aa944016566738abd9b193": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9820. RPCv9 wire protocol is insufficient to support multiplexing. Contributed by Daryn Sharp.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1512091 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/08/13 4:02 PM",
      "commitName": "c03c8fe199429a43c6aa944016566738abd9b193",
      "commitAuthor": "Jitendra Nath Pandey",
      "commitDateOld": "05/08/13 4:01 PM",
      "commitNameOld": "63a1273f2a8e0b668ff70330262adedee63112d9",
      "commitAuthorOld": "Daryn Sharp",
      "daysBetweenCommits": 3.0,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,36 @@\n     private void unwrapPacketAndProcessRpcs(byte[] inBuf)\n         throws WrappedRpcServerException, IOException, InterruptedException {\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Have read input token of size \" + inBuf.length\n+            + \" for processing by saslServer.unwrap()\");\n+      }\n+      inBuf \u003d saslServer.unwrap(inBuf, 0, inBuf.length);\n       ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n           inBuf));\n       // Read all RPCs contained in the inBuf, even partial ones\n       while (true) {\n         int count \u003d -1;\n         if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n           count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n           if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n             return;\n         }\n \n         if (unwrappedData \u003d\u003d null) {\n           unwrappedDataLengthBuffer.flip();\n           int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n           unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n         }\n \n         count \u003d channelRead(ch, unwrappedData);\n         if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n           return;\n \n         if (unwrappedData.remaining() \u003d\u003d 0) {\n           unwrappedDataLengthBuffer.clear();\n           unwrappedData.flip();\n           processOneRpc(unwrappedData.array());\n           unwrappedData \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void unwrapPacketAndProcessRpcs(byte[] inBuf)\n        throws WrappedRpcServerException, IOException, InterruptedException {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Have read input token of size \" + inBuf.length\n            + \" for processing by saslServer.unwrap()\");\n      }\n      inBuf \u003d saslServer.unwrap(inBuf, 0, inBuf.length);\n      ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n          inBuf));\n      // Read all RPCs contained in the inBuf, even partial ones\n      while (true) {\n        int count \u003d -1;\n        if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n          count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n          if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n            return;\n        }\n\n        if (unwrappedData \u003d\u003d null) {\n          unwrappedDataLengthBuffer.flip();\n          int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n          unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n        }\n\n        count \u003d channelRead(ch, unwrappedData);\n        if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n          return;\n\n        if (unwrappedData.remaining() \u003d\u003d 0) {\n          unwrappedDataLengthBuffer.clear();\n          unwrappedData.flip();\n          processOneRpc(unwrappedData.array());\n          unwrappedData \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "63a1273f2a8e0b668ff70330262adedee63112d9": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9832. Add RPC header to client ping (daryn)\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1510793 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/08/13 4:01 PM",
      "commitName": "63a1273f2a8e0b668ff70330262adedee63112d9",
      "commitAuthor": "Daryn Sharp",
      "commitDateOld": "05/08/13 3:02 PM",
      "commitNameOld": "f5312aedb9fa3dc895d61844b5c3202b02554f80",
      "commitAuthorOld": "Daryn Sharp",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,31 @@\n     private void unwrapPacketAndProcessRpcs(byte[] inBuf)\n         throws WrappedRpcServerException, IOException, InterruptedException {\n       ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n           inBuf));\n       // Read all RPCs contained in the inBuf, even partial ones\n       while (true) {\n         int count \u003d -1;\n         if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n           count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n           if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n             return;\n         }\n \n         if (unwrappedData \u003d\u003d null) {\n           unwrappedDataLengthBuffer.flip();\n           int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n-\n-          if (unwrappedDataLength \u003d\u003d RpcConstants.PING_CALL_ID) {\n-            if (LOG.isDebugEnabled())\n-              LOG.debug(\"Received ping message\");\n-            unwrappedDataLengthBuffer.clear();\n-            continue; // ping message\n-          }\n           unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n         }\n \n         count \u003d channelRead(ch, unwrappedData);\n         if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n           return;\n \n         if (unwrappedData.remaining() \u003d\u003d 0) {\n           unwrappedDataLengthBuffer.clear();\n           unwrappedData.flip();\n           processOneRpc(unwrappedData.array());\n           unwrappedData \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void unwrapPacketAndProcessRpcs(byte[] inBuf)\n        throws WrappedRpcServerException, IOException, InterruptedException {\n      ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n          inBuf));\n      // Read all RPCs contained in the inBuf, even partial ones\n      while (true) {\n        int count \u003d -1;\n        if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n          count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n          if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n            return;\n        }\n\n        if (unwrappedData \u003d\u003d null) {\n          unwrappedDataLengthBuffer.flip();\n          int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n          unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n        }\n\n        count \u003d channelRead(ch, unwrappedData);\n        if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n          return;\n\n        if (unwrappedData.remaining() \u003d\u003d 0) {\n          unwrappedDataLengthBuffer.clear();\n          unwrappedData.flip();\n          processOneRpc(unwrappedData.array());\n          unwrappedData \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "65be21267587f04a2c33af65b951211cc9085b15": {
      "type": "Yexceptionschange",
      "commitMessage": "HADOOP-9698. [RPC v9] Client must honor server\u0027s SASL negotiate response (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1508086 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/13 7:44 AM",
      "commitName": "65be21267587f04a2c33af65b951211cc9085b15",
      "commitAuthor": "Daryn Sharp",
      "commitDateOld": "24/07/13 12:48 AM",
      "commitNameOld": "a0a986dda77ea03dac9cfc7e0631bae611034ef4",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 5.29,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,38 @@\n-    private void unwrapPacketAndProcessRpcs(byte[] inBuf) throws IOException,\n-        InterruptedException {\n+    private void unwrapPacketAndProcessRpcs(byte[] inBuf)\n+        throws WrappedRpcServerException, IOException, InterruptedException {\n       ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n           inBuf));\n       // Read all RPCs contained in the inBuf, even partial ones\n       while (true) {\n         int count \u003d -1;\n         if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n           count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n           if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n             return;\n         }\n \n         if (unwrappedData \u003d\u003d null) {\n           unwrappedDataLengthBuffer.flip();\n           int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n \n           if (unwrappedDataLength \u003d\u003d RpcConstants.PING_CALL_ID) {\n             if (LOG.isDebugEnabled())\n               LOG.debug(\"Received ping message\");\n             unwrappedDataLengthBuffer.clear();\n             continue; // ping message\n           }\n           unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n         }\n \n         count \u003d channelRead(ch, unwrappedData);\n         if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n           return;\n \n         if (unwrappedData.remaining() \u003d\u003d 0) {\n           unwrappedDataLengthBuffer.clear();\n           unwrappedData.flip();\n           processOneRpc(unwrappedData.array());\n           unwrappedData \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void unwrapPacketAndProcessRpcs(byte[] inBuf)\n        throws WrappedRpcServerException, IOException, InterruptedException {\n      ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n          inBuf));\n      // Read all RPCs contained in the inBuf, even partial ones\n      while (true) {\n        int count \u003d -1;\n        if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n          count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n          if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n            return;\n        }\n\n        if (unwrappedData \u003d\u003d null) {\n          unwrappedDataLengthBuffer.flip();\n          int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n\n          if (unwrappedDataLength \u003d\u003d RpcConstants.PING_CALL_ID) {\n            if (LOG.isDebugEnabled())\n              LOG.debug(\"Received ping message\");\n            unwrappedDataLengthBuffer.clear();\n            continue; // ping message\n          }\n          unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n        }\n\n        count \u003d channelRead(ch, unwrappedData);\n        if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n          return;\n\n        if (unwrappedData.remaining() \u003d\u003d 0) {\n          unwrappedDataLengthBuffer.clear();\n          unwrappedData.flip();\n          processOneRpc(unwrappedData.array());\n          unwrappedData \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {
        "oldValue": "[IOException, InterruptedException]",
        "newValue": "[WrappedRpcServerException, IOException, InterruptedException]"
      }
    },
    "a3a9d72e98a9cc0f94af7c832dd13c408856636d": {
      "type": "Yrename",
      "commitMessage": "HADOOP-9683. [RPC v9] Wrap IpcConnectionContext in RPC headers (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1503811 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/07/13 10:59 AM",
      "commitName": "a3a9d72e98a9cc0f94af7c832dd13c408856636d",
      "commitAuthor": "Daryn Sharp",
      "commitDateOld": "09/07/13 4:45 PM",
      "commitNameOld": "0a5f16a89e3942953d7d6c2d26542764298c6430",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 6.76,
      "commitsBetweenForRepo": 40,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,38 @@\n-    private void processUnwrappedData(byte[] inBuf) throws IOException,\n+    private void unwrapPacketAndProcessRpcs(byte[] inBuf) throws IOException,\n         InterruptedException {\n       ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n           inBuf));\n       // Read all RPCs contained in the inBuf, even partial ones\n       while (true) {\n         int count \u003d -1;\n         if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n           count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n           if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n             return;\n         }\n \n         if (unwrappedData \u003d\u003d null) {\n           unwrappedDataLengthBuffer.flip();\n           int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n \n           if (unwrappedDataLength \u003d\u003d RpcConstants.PING_CALL_ID) {\n             if (LOG.isDebugEnabled())\n               LOG.debug(\"Received ping message\");\n             unwrappedDataLengthBuffer.clear();\n             continue; // ping message\n           }\n           unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n         }\n \n         count \u003d channelRead(ch, unwrappedData);\n         if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n           return;\n \n         if (unwrappedData.remaining() \u003d\u003d 0) {\n           unwrappedDataLengthBuffer.clear();\n           unwrappedData.flip();\n           processOneRpc(unwrappedData.array());\n           unwrappedData \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void unwrapPacketAndProcessRpcs(byte[] inBuf) throws IOException,\n        InterruptedException {\n      ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n          inBuf));\n      // Read all RPCs contained in the inBuf, even partial ones\n      while (true) {\n        int count \u003d -1;\n        if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n          count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n          if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n            return;\n        }\n\n        if (unwrappedData \u003d\u003d null) {\n          unwrappedDataLengthBuffer.flip();\n          int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n\n          if (unwrappedDataLength \u003d\u003d RpcConstants.PING_CALL_ID) {\n            if (LOG.isDebugEnabled())\n              LOG.debug(\"Received ping message\");\n            unwrappedDataLengthBuffer.clear();\n            continue; // ping message\n          }\n          unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n        }\n\n        count \u003d channelRead(ch, unwrappedData);\n        if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n          return;\n\n        if (unwrappedData.remaining() \u003d\u003d 0) {\n          unwrappedDataLengthBuffer.clear();\n          unwrappedData.flip();\n          processOneRpc(unwrappedData.array());\n          unwrappedData \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {
        "oldValue": "processUnwrappedData",
        "newValue": "unwrapPacketAndProcessRpcs"
      }
    },
    "eb2a60338715e517ba8e4d32ecfe28691a882188": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9688. Add globally unique Client ID to RPC requests. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1500843 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/07/13 10:08 AM",
      "commitName": "eb2a60338715e517ba8e4d32ecfe28691a882188",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "01/07/13 4:17 PM",
      "commitNameOld": "805e9b5b6d835d1b7a50af18967afb8eebdf8606",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 6.74,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,38 @@\n     private void processUnwrappedData(byte[] inBuf) throws IOException,\n         InterruptedException {\n       ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n           inBuf));\n       // Read all RPCs contained in the inBuf, even partial ones\n       while (true) {\n         int count \u003d -1;\n         if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n           count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n           if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n             return;\n         }\n \n         if (unwrappedData \u003d\u003d null) {\n           unwrappedDataLengthBuffer.flip();\n           int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n \n-          if (unwrappedDataLength \u003d\u003d Client.PING_CALL_ID) {\n+          if (unwrappedDataLength \u003d\u003d RpcConstants.PING_CALL_ID) {\n             if (LOG.isDebugEnabled())\n               LOG.debug(\"Received ping message\");\n             unwrappedDataLengthBuffer.clear();\n             continue; // ping message\n           }\n           unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n         }\n \n         count \u003d channelRead(ch, unwrappedData);\n         if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n           return;\n \n         if (unwrappedData.remaining() \u003d\u003d 0) {\n           unwrappedDataLengthBuffer.clear();\n           unwrappedData.flip();\n           processOneRpc(unwrappedData.array());\n           unwrappedData \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processUnwrappedData(byte[] inBuf) throws IOException,\n        InterruptedException {\n      ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n          inBuf));\n      // Read all RPCs contained in the inBuf, even partial ones\n      while (true) {\n        int count \u003d -1;\n        if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n          count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n          if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n            return;\n        }\n\n        if (unwrappedData \u003d\u003d null) {\n          unwrappedDataLengthBuffer.flip();\n          int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n\n          if (unwrappedDataLength \u003d\u003d RpcConstants.PING_CALL_ID) {\n            if (LOG.isDebugEnabled())\n              LOG.debug(\"Received ping message\");\n            unwrappedDataLengthBuffer.clear();\n            continue; // ping message\n          }\n          unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n        }\n\n        count \u003d channelRead(ch, unwrappedData);\n        if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n          return;\n\n        if (unwrappedData.remaining() \u003d\u003d 0) {\n          unwrappedDataLengthBuffer.clear();\n          unwrappedData.flip();\n          processOneRpc(unwrappedData.array());\n          unwrappedData \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void processUnwrappedData(byte[] inBuf) throws IOException,\n        InterruptedException {\n      ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n          inBuf));\n      // Read all RPCs contained in the inBuf, even partial ones\n      while (true) {\n        int count \u003d -1;\n        if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n          count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n          if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n            return;\n        }\n\n        if (unwrappedData \u003d\u003d null) {\n          unwrappedDataLengthBuffer.flip();\n          int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n\n          if (unwrappedDataLength \u003d\u003d Client.PING_CALL_ID) {\n            if (LOG.isDebugEnabled())\n              LOG.debug(\"Received ping message\");\n            unwrappedDataLengthBuffer.clear();\n            continue; // ping message\n          }\n          unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n        }\n\n        count \u003d channelRead(ch, unwrappedData);\n        if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n          return;\n\n        if (unwrappedData.remaining() \u003d\u003d 0) {\n          unwrappedDataLengthBuffer.clear();\n          unwrappedData.flip();\n          processOneRpc(unwrappedData.array());\n          unwrappedData \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {
        "oldPath": "hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java"
      }
    },
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-6671. Use maven for hadoop common builds. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1153184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/08/11 9:37 AM",
      "commitName": "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
      "commitAuthor": "Thomas White",
      "commitDateOld": "01/08/11 3:53 PM",
      "commitNameOld": "9bac807cedbcff34e1a144fb475eff267e5ed86d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void processUnwrappedData(byte[] inBuf) throws IOException,\n        InterruptedException {\n      ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n          inBuf));\n      // Read all RPCs contained in the inBuf, even partial ones\n      while (true) {\n        int count \u003d -1;\n        if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n          count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n          if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n            return;\n        }\n\n        if (unwrappedData \u003d\u003d null) {\n          unwrappedDataLengthBuffer.flip();\n          int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n\n          if (unwrappedDataLength \u003d\u003d Client.PING_CALL_ID) {\n            if (LOG.isDebugEnabled())\n              LOG.debug(\"Received ping message\");\n            unwrappedDataLengthBuffer.clear();\n            continue; // ping message\n          }\n          unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n        }\n\n        count \u003d channelRead(ch, unwrappedData);\n        if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n          return;\n\n        if (unwrappedData.remaining() \u003d\u003d 0) {\n          unwrappedDataLengthBuffer.clear();\n          unwrappedData.flip();\n          processOneRpc(unwrappedData.array());\n          unwrappedData \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {
        "oldPath": "common/src/java/org/apache/hadoop/ipc/Server.java",
        "newPath": "hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "11/06/11 9:13 PM",
      "commitNameOld": "a285fb5effe9ba3be4ec5f942afaf5ddd1186151",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void processUnwrappedData(byte[] inBuf) throws IOException,\n        InterruptedException {\n      ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n          inBuf));\n      // Read all RPCs contained in the inBuf, even partial ones\n      while (true) {\n        int count \u003d -1;\n        if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n          count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n          if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n            return;\n        }\n\n        if (unwrappedData \u003d\u003d null) {\n          unwrappedDataLengthBuffer.flip();\n          int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n\n          if (unwrappedDataLength \u003d\u003d Client.PING_CALL_ID) {\n            if (LOG.isDebugEnabled())\n              LOG.debug(\"Received ping message\");\n            unwrappedDataLengthBuffer.clear();\n            continue; // ping message\n          }\n          unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n        }\n\n        count \u003d channelRead(ch, unwrappedData);\n        if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n          return;\n\n        if (unwrappedData.remaining() \u003d\u003d 0) {\n          unwrappedDataLengthBuffer.clear();\n          unwrappedData.flip();\n          processOneRpc(unwrappedData.array());\n          unwrappedData \u003d null;\n        }\n      }\n    }",
      "path": "common/src/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/hadoop/ipc/Server.java",
        "newPath": "common/src/java/org/apache/hadoop/ipc/Server.java"
      }
    },
    "940389afce6a1b9b9e1519aed528cbc444786756": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-6419. Adds SASL based authentication to RPC. Contributed by Kan Zhang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@905860 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/02/10 5:30 PM",
      "commitName": "940389afce6a1b9b9e1519aed528cbc444786756",
      "commitAuthor": "Devaraj Das",
      "diff": "@@ -0,0 +1,38 @@\n+    private void processUnwrappedData(byte[] inBuf) throws IOException,\n+        InterruptedException {\n+      ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n+          inBuf));\n+      // Read all RPCs contained in the inBuf, even partial ones\n+      while (true) {\n+        int count \u003d -1;\n+        if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n+          count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n+          if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n+            return;\n+        }\n+\n+        if (unwrappedData \u003d\u003d null) {\n+          unwrappedDataLengthBuffer.flip();\n+          int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n+\n+          if (unwrappedDataLength \u003d\u003d Client.PING_CALL_ID) {\n+            if (LOG.isDebugEnabled())\n+              LOG.debug(\"Received ping message\");\n+            unwrappedDataLengthBuffer.clear();\n+            continue; // ping message\n+          }\n+          unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n+        }\n+\n+        count \u003d channelRead(ch, unwrappedData);\n+        if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n+          return;\n+\n+        if (unwrappedData.remaining() \u003d\u003d 0) {\n+          unwrappedDataLengthBuffer.clear();\n+          unwrappedData.flip();\n+          processOneRpc(unwrappedData.array());\n+          unwrappedData \u003d null;\n+        }\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private void processUnwrappedData(byte[] inBuf) throws IOException,\n        InterruptedException {\n      ReadableByteChannel ch \u003d Channels.newChannel(new ByteArrayInputStream(\n          inBuf));\n      // Read all RPCs contained in the inBuf, even partial ones\n      while (true) {\n        int count \u003d -1;\n        if (unwrappedDataLengthBuffer.remaining() \u003e 0) {\n          count \u003d channelRead(ch, unwrappedDataLengthBuffer);\n          if (count \u003c\u003d 0 || unwrappedDataLengthBuffer.remaining() \u003e 0)\n            return;\n        }\n\n        if (unwrappedData \u003d\u003d null) {\n          unwrappedDataLengthBuffer.flip();\n          int unwrappedDataLength \u003d unwrappedDataLengthBuffer.getInt();\n\n          if (unwrappedDataLength \u003d\u003d Client.PING_CALL_ID) {\n            if (LOG.isDebugEnabled())\n              LOG.debug(\"Received ping message\");\n            unwrappedDataLengthBuffer.clear();\n            continue; // ping message\n          }\n          unwrappedData \u003d ByteBuffer.allocate(unwrappedDataLength);\n        }\n\n        count \u003d channelRead(ch, unwrappedData);\n        if (count \u003c\u003d 0 || unwrappedData.remaining() \u003e 0)\n          return;\n\n        if (unwrappedData.remaining() \u003d\u003d 0) {\n          unwrappedDataLengthBuffer.clear();\n          unwrappedData.flip();\n          processOneRpc(unwrappedData.array());\n          unwrappedData \u003d null;\n        }\n      }\n    }",
      "path": "src/java/org/apache/hadoop/ipc/Server.java"
    }
  }
}