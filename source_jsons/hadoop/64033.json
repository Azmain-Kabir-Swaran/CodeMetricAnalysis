{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3ADataBlocks.java",
  "functionName": "close",
  "functionId": "close",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java",
  "functionStartLine": 193,
  "functionEndLine": 194,
  "numCommitsSeen": 5,
  "timeTaken": 1654,
  "changeHistory": [
    "dab00da19f25619ccc71c7f803a235b21766bf1e",
    "6c348c56918973fd988b110e79231324a8befe12"
  ],
  "changeHistoryShort": {
    "dab00da19f25619ccc71c7f803a235b21766bf1e": "Ymultichange(Ymodifierchange,Yexceptionschange,Ybodychange)",
    "6c348c56918973fd988b110e79231324a8befe12": "Yintroduced"
  },
  "changeHistoryDetails": {
    "dab00da19f25619ccc71c7f803a235b21766bf1e": {
      "type": "Ymultichange(Ymodifierchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "HADOOP-14028. S3A BlockOutputStreams doesn\u0027t delete temporary files in multipart uploads or handle part upload failures.\nContributed by Steve Loughran.\n\n(cherry picked from commit 29fe5af017b945d8750c074ca39031b5b777eddd)\n",
      "commitDate": "25/02/17 7:35 AM",
      "commitName": "dab00da19f25619ccc71c7f803a235b21766bf1e",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HADOOP-14028. S3A BlockOutputStreams doesn\u0027t delete temporary files in multipart uploads or handle part upload failures.\nContributed by Steve Loughran.\n\n(cherry picked from commit 29fe5af017b945d8750c074ca39031b5b777eddd)\n",
          "commitDate": "25/02/17 7:35 AM",
          "commitName": "dab00da19f25619ccc71c7f803a235b21766bf1e",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "20/02/17 8:21 AM",
          "commitNameOld": "8035749c26947dc641ef87dac041050d439a16d1",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 4.97,
          "commitsBetweenForRepo": 37,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,5 @@\n-      public void close() throws IOException {\n-        try {\n-          super.close();\n-        } finally {\n-          if (!closed.getAndSet(true)) {\n-            if (!bufferFile.delete()) {\n-              LOG.warn(\"delete({}) returned false\",\n-                  bufferFile.getAbsoluteFile());\n-            }\n-          }\n-        }\n-      }\n\\ No newline at end of file\n+        public synchronized void close() {\n+          LOG.debug(\"ByteBufferInputStream.close() for {}\",\n+              ByteBufferBlock.super.toString());\n+          byteBuffer \u003d null;\n+        }\n\\ No newline at end of file\n",
          "actualSource": "        public synchronized void close() {\n          LOG.debug(\"ByteBufferInputStream.close() for {}\",\n              ByteBufferBlock.super.toString());\n          byteBuffer \u003d null;\n        }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[public, synchronized]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "HADOOP-14028. S3A BlockOutputStreams doesn\u0027t delete temporary files in multipart uploads or handle part upload failures.\nContributed by Steve Loughran.\n\n(cherry picked from commit 29fe5af017b945d8750c074ca39031b5b777eddd)\n",
          "commitDate": "25/02/17 7:35 AM",
          "commitName": "dab00da19f25619ccc71c7f803a235b21766bf1e",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "20/02/17 8:21 AM",
          "commitNameOld": "8035749c26947dc641ef87dac041050d439a16d1",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 4.97,
          "commitsBetweenForRepo": 37,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,5 @@\n-      public void close() throws IOException {\n-        try {\n-          super.close();\n-        } finally {\n-          if (!closed.getAndSet(true)) {\n-            if (!bufferFile.delete()) {\n-              LOG.warn(\"delete({}) returned false\",\n-                  bufferFile.getAbsoluteFile());\n-            }\n-          }\n-        }\n-      }\n\\ No newline at end of file\n+        public synchronized void close() {\n+          LOG.debug(\"ByteBufferInputStream.close() for {}\",\n+              ByteBufferBlock.super.toString());\n+          byteBuffer \u003d null;\n+        }\n\\ No newline at end of file\n",
          "actualSource": "        public synchronized void close() {\n          LOG.debug(\"ByteBufferInputStream.close() for {}\",\n              ByteBufferBlock.super.toString());\n          byteBuffer \u003d null;\n        }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java",
          "extendedDetails": {
            "oldValue": "[IOException]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-14028. S3A BlockOutputStreams doesn\u0027t delete temporary files in multipart uploads or handle part upload failures.\nContributed by Steve Loughran.\n\n(cherry picked from commit 29fe5af017b945d8750c074ca39031b5b777eddd)\n",
          "commitDate": "25/02/17 7:35 AM",
          "commitName": "dab00da19f25619ccc71c7f803a235b21766bf1e",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "20/02/17 8:21 AM",
          "commitNameOld": "8035749c26947dc641ef87dac041050d439a16d1",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 4.97,
          "commitsBetweenForRepo": 37,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,5 @@\n-      public void close() throws IOException {\n-        try {\n-          super.close();\n-        } finally {\n-          if (!closed.getAndSet(true)) {\n-            if (!bufferFile.delete()) {\n-              LOG.warn(\"delete({}) returned false\",\n-                  bufferFile.getAbsoluteFile());\n-            }\n-          }\n-        }\n-      }\n\\ No newline at end of file\n+        public synchronized void close() {\n+          LOG.debug(\"ByteBufferInputStream.close() for {}\",\n+              ByteBufferBlock.super.toString());\n+          byteBuffer \u003d null;\n+        }\n\\ No newline at end of file\n",
          "actualSource": "        public synchronized void close() {\n          LOG.debug(\"ByteBufferInputStream.close() for {}\",\n              ByteBufferBlock.super.toString());\n          byteBuffer \u003d null;\n        }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java",
          "extendedDetails": {}
        }
      ]
    },
    "6c348c56918973fd988b110e79231324a8befe12": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13560. S3ABlockOutputStream to support huge (many GB) file writes. Contributed by Steve Loughran\n",
      "commitDate": "18/10/16 1:16 PM",
      "commitName": "6c348c56918973fd988b110e79231324a8befe12",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,12 @@\n+      public void close() throws IOException {\n+        try {\n+          super.close();\n+        } finally {\n+          if (!closed.getAndSet(true)) {\n+            if (!bufferFile.delete()) {\n+              LOG.warn(\"delete({}) returned false\",\n+                  bufferFile.getAbsoluteFile());\n+            }\n+          }\n+        }\n+      }\n\\ No newline at end of file\n",
      "actualSource": "      public void close() throws IOException {\n        try {\n          super.close();\n        } finally {\n          if (!closed.getAndSet(true)) {\n            if (!bufferFile.delete()) {\n              LOG.warn(\"delete({}) returned false\",\n                  bufferFile.getAbsoluteFile());\n            }\n          }\n        }\n      }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ADataBlocks.java"
    }
  }
}