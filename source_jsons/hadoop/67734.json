{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DynamicRecordReader.java",
  "functionName": "initialize",
  "functionId": "initialize___inputSplit-InputSplit__taskAttemptContext-TaskAttemptContext",
  "sourceFilePath": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/lib/DynamicRecordReader.java",
  "functionStartLine": 69,
  "functionEndLine": 83,
  "numCommitsSeen": 4,
  "timeTaken": 671,
  "changeHistory": [
    "2868ca0328d908056745223fb38d9a90fd2811ba",
    "d06948002fb0cabf72cc0d46bf2fa67d45370f67"
  ],
  "changeHistoryShort": {
    "2868ca0328d908056745223fb38d9a90fd2811ba": "Ybodychange",
    "d06948002fb0cabf72cc0d46bf2fa67d45370f67": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2868ca0328d908056745223fb38d9a90fd2811ba": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6451. DistCp has incorrect chunkFilePath for multiple jobs when strategy is dynamic. Contributed by Kuhu Shukla.\n",
      "commitDate": "30/10/15 12:56 PM",
      "commitName": "2868ca0328d908056745223fb38d9a90fd2811ba",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "03/03/15 1:06 AM",
      "commitNameOld": "9ae7f9eb7baeb244e1b95aabc93ad8124870b9a9",
      "commitAuthorOld": "Tsuyoshi Ozawa",
      "daysBetweenCommits": 241.45,
      "commitsBetweenForRepo": 2078,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,15 @@\n   public void initialize(InputSplit inputSplit,\n                          TaskAttemptContext taskAttemptContext)\n                          throws IOException, InterruptedException {\n     numRecordsPerChunk \u003d DynamicInputFormat.getNumEntriesPerChunk(\n             taskAttemptContext.getConfiguration());\n     this.taskAttemptContext \u003d taskAttemptContext;\n     configuration \u003d taskAttemptContext.getConfiguration();\n     taskId \u003d taskAttemptContext.getTaskAttemptID().getTaskID();\n-    chunk \u003d DynamicInputChunk.acquire(this.taskAttemptContext);\n+    chunk \u003d chunkContext.acquire(this.taskAttemptContext);\n     timeOfLastChunkDirScan \u003d System.currentTimeMillis();\n     isChunkDirAlreadyScanned \u003d false;\n \n     totalNumRecords \u003d getTotalNumRecords();\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(InputSplit inputSplit,\n                         TaskAttemptContext taskAttemptContext)\n                         throws IOException, InterruptedException {\n    numRecordsPerChunk \u003d DynamicInputFormat.getNumEntriesPerChunk(\n            taskAttemptContext.getConfiguration());\n    this.taskAttemptContext \u003d taskAttemptContext;\n    configuration \u003d taskAttemptContext.getConfiguration();\n    taskId \u003d taskAttemptContext.getTaskAttemptID().getTaskID();\n    chunk \u003d chunkContext.acquire(this.taskAttemptContext);\n    timeOfLastChunkDirScan \u003d System.currentTimeMillis();\n    isChunkDirAlreadyScanned \u003d false;\n\n    totalNumRecords \u003d getTotalNumRecords();\n\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/lib/DynamicRecordReader.java",
      "extendedDetails": {}
    },
    "d06948002fb0cabf72cc0d46bf2fa67d45370f67": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-2765. DistCp Rewrite. (Mithun Radhakrishnan via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1236045 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/01/12 10:36 PM",
      "commitName": "d06948002fb0cabf72cc0d46bf2fa67d45370f67",
      "commitAuthor": "Mahadev Konar",
      "diff": "@@ -0,0 +1,15 @@\n+  public void initialize(InputSplit inputSplit,\n+                         TaskAttemptContext taskAttemptContext)\n+                         throws IOException, InterruptedException {\n+    numRecordsPerChunk \u003d DynamicInputFormat.getNumEntriesPerChunk(\n+            taskAttemptContext.getConfiguration());\n+    this.taskAttemptContext \u003d taskAttemptContext;\n+    configuration \u003d taskAttemptContext.getConfiguration();\n+    taskId \u003d taskAttemptContext.getTaskAttemptID().getTaskID();\n+    chunk \u003d DynamicInputChunk.acquire(this.taskAttemptContext);\n+    timeOfLastChunkDirScan \u003d System.currentTimeMillis();\n+    isChunkDirAlreadyScanned \u003d false;\n+\n+    totalNumRecords \u003d getTotalNumRecords();\n+\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(InputSplit inputSplit,\n                         TaskAttemptContext taskAttemptContext)\n                         throws IOException, InterruptedException {\n    numRecordsPerChunk \u003d DynamicInputFormat.getNumEntriesPerChunk(\n            taskAttemptContext.getConfiguration());\n    this.taskAttemptContext \u003d taskAttemptContext;\n    configuration \u003d taskAttemptContext.getConfiguration();\n    taskId \u003d taskAttemptContext.getTaskAttemptID().getTaskID();\n    chunk \u003d DynamicInputChunk.acquire(this.taskAttemptContext);\n    timeOfLastChunkDirScan \u003d System.currentTimeMillis();\n    isChunkDirAlreadyScanned \u003d false;\n\n    totalNumRecords \u003d getTotalNumRecords();\n\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/lib/DynamicRecordReader.java"
    }
  }
}