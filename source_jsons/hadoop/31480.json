{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "SubApplicationTableRW.java",
  "functionName": "createTable",
  "functionId": "createTable___admin-Admin__hbaseConf-Configuration",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/subapplication/SubApplicationTableRW.java",
  "functionStartLine": 84,
  "functionEndLine": 126,
  "numCommitsSeen": 3,
  "timeTaken": 1130,
  "changeHistory": [
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
    "a990ff70c25e2ab746578500720c531f23e0851e"
  ],
  "changeHistoryShort": {
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": "Yfilerename",
    "a990ff70c25e2ab746578500720c531f23e0851e": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2": {
      "type": "Yfilerename",
      "commitMessage": "YARN-7919. Refactor timelineservice-hbase module into submodules. Contributed by Haibo Chen.\n",
      "commitDate": "17/02/18 7:00 AM",
      "commitName": "9af30d46c6e82332a8eda20cb3eb5f987e25e7a2",
      "commitAuthor": "Rohith Sharma K S",
      "commitDateOld": "17/02/18 3:24 AM",
      "commitNameOld": "a1e56a62863d8d494af309ec5f476c4b7e4d5ef9",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 0.15,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void createTable(Admin admin, Configuration hbaseConf)\n      throws IOException {\n\n    TableName table \u003d getTableName(hbaseConf);\n    if (admin.tableExists(table)) {\n      // do not disable / delete existing table\n      // similar to the approach taken by map-reduce jobs when\n      // output directory exists\n      throw new IOException(\"Table \" + table.getNameAsString()\n          + \" already exists.\");\n    }\n\n    HTableDescriptor subAppTableDescp \u003d new HTableDescriptor(table);\n    HColumnDescriptor infoCF \u003d\n        new HColumnDescriptor(SubApplicationColumnFamily.INFO.getBytes());\n    infoCF.setBloomFilterType(BloomType.ROWCOL);\n    subAppTableDescp.addFamily(infoCF);\n\n    HColumnDescriptor configCF \u003d\n        new HColumnDescriptor(SubApplicationColumnFamily.CONFIGS.getBytes());\n    configCF.setBloomFilterType(BloomType.ROWCOL);\n    configCF.setBlockCacheEnabled(true);\n    subAppTableDescp.addFamily(configCF);\n\n    HColumnDescriptor metricsCF \u003d\n        new HColumnDescriptor(SubApplicationColumnFamily.METRICS.getBytes());\n    subAppTableDescp.addFamily(metricsCF);\n    metricsCF.setBlockCacheEnabled(true);\n    // always keep 1 version (the latest)\n    metricsCF.setMinVersions(1);\n    metricsCF.setMaxVersions(\n        hbaseConf.getInt(METRICS_MAX_VERSIONS, DEFAULT_METRICS_MAX_VERSIONS));\n    metricsCF.setTimeToLive(hbaseConf.getInt(METRICS_TTL_CONF_NAME,\n        DEFAULT_METRICS_TTL));\n    subAppTableDescp.setRegionSplitPolicyClassName(\n        \"org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy\");\n    subAppTableDescp.setValue(\"KeyPrefixRegionSplitPolicy.prefix_length\",\n        TimelineHBaseSchemaConstants.USERNAME_SPLIT_KEY_PREFIX_LENGTH);\n    admin.createTable(subAppTableDescp,\n        TimelineHBaseSchemaConstants.getUsernameSplits());\n    LOG.info(\"Status of table creation for \" + table.getNameAsString() + \"\u003d\"\n        + admin.tableExists(table));\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/subapplication/SubApplicationTableRW.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/subapplication/SubApplicationTable.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/subapplication/SubApplicationTableRW.java"
      }
    },
    "a990ff70c25e2ab746578500720c531f23e0851e": {
      "type": "Yintroduced",
      "commitMessage": "YARN-6733. Add table for storing sub-application entities. Contributed by Vrushali C.\n",
      "commitDate": "29/08/17 10:59 PM",
      "commitName": "a990ff70c25e2ab746578500720c531f23e0851e",
      "commitAuthor": "Rohith Sharma K S",
      "diff": "@@ -0,0 +1,43 @@\n+  public void createTable(Admin admin, Configuration hbaseConf)\n+      throws IOException {\n+\n+    TableName table \u003d getTableName(hbaseConf);\n+    if (admin.tableExists(table)) {\n+      // do not disable / delete existing table\n+      // similar to the approach taken by map-reduce jobs when\n+      // output directory exists\n+      throw new IOException(\"Table \" + table.getNameAsString()\n+          + \" already exists.\");\n+    }\n+\n+    HTableDescriptor subAppTableDescp \u003d new HTableDescriptor(table);\n+    HColumnDescriptor infoCF \u003d\n+        new HColumnDescriptor(SubApplicationColumnFamily.INFO.getBytes());\n+    infoCF.setBloomFilterType(BloomType.ROWCOL);\n+    subAppTableDescp.addFamily(infoCF);\n+\n+    HColumnDescriptor configCF \u003d\n+        new HColumnDescriptor(SubApplicationColumnFamily.CONFIGS.getBytes());\n+    configCF.setBloomFilterType(BloomType.ROWCOL);\n+    configCF.setBlockCacheEnabled(true);\n+    subAppTableDescp.addFamily(configCF);\n+\n+    HColumnDescriptor metricsCF \u003d\n+        new HColumnDescriptor(SubApplicationColumnFamily.METRICS.getBytes());\n+    subAppTableDescp.addFamily(metricsCF);\n+    metricsCF.setBlockCacheEnabled(true);\n+    // always keep 1 version (the latest)\n+    metricsCF.setMinVersions(1);\n+    metricsCF.setMaxVersions(\n+        hbaseConf.getInt(METRICS_MAX_VERSIONS, DEFAULT_METRICS_MAX_VERSIONS));\n+    metricsCF.setTimeToLive(hbaseConf.getInt(METRICS_TTL_CONF_NAME,\n+        DEFAULT_METRICS_TTL));\n+    subAppTableDescp.setRegionSplitPolicyClassName(\n+        \"org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy\");\n+    subAppTableDescp.setValue(\"KeyPrefixRegionSplitPolicy.prefix_length\",\n+        TimelineHBaseSchemaConstants.USERNAME_SPLIT_KEY_PREFIX_LENGTH);\n+    admin.createTable(subAppTableDescp,\n+        TimelineHBaseSchemaConstants.getUsernameSplits());\n+    LOG.info(\"Status of table creation for \" + table.getNameAsString() + \"\u003d\"\n+        + admin.tableExists(table));\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void createTable(Admin admin, Configuration hbaseConf)\n      throws IOException {\n\n    TableName table \u003d getTableName(hbaseConf);\n    if (admin.tableExists(table)) {\n      // do not disable / delete existing table\n      // similar to the approach taken by map-reduce jobs when\n      // output directory exists\n      throw new IOException(\"Table \" + table.getNameAsString()\n          + \" already exists.\");\n    }\n\n    HTableDescriptor subAppTableDescp \u003d new HTableDescriptor(table);\n    HColumnDescriptor infoCF \u003d\n        new HColumnDescriptor(SubApplicationColumnFamily.INFO.getBytes());\n    infoCF.setBloomFilterType(BloomType.ROWCOL);\n    subAppTableDescp.addFamily(infoCF);\n\n    HColumnDescriptor configCF \u003d\n        new HColumnDescriptor(SubApplicationColumnFamily.CONFIGS.getBytes());\n    configCF.setBloomFilterType(BloomType.ROWCOL);\n    configCF.setBlockCacheEnabled(true);\n    subAppTableDescp.addFamily(configCF);\n\n    HColumnDescriptor metricsCF \u003d\n        new HColumnDescriptor(SubApplicationColumnFamily.METRICS.getBytes());\n    subAppTableDescp.addFamily(metricsCF);\n    metricsCF.setBlockCacheEnabled(true);\n    // always keep 1 version (the latest)\n    metricsCF.setMinVersions(1);\n    metricsCF.setMaxVersions(\n        hbaseConf.getInt(METRICS_MAX_VERSIONS, DEFAULT_METRICS_MAX_VERSIONS));\n    metricsCF.setTimeToLive(hbaseConf.getInt(METRICS_TTL_CONF_NAME,\n        DEFAULT_METRICS_TTL));\n    subAppTableDescp.setRegionSplitPolicyClassName(\n        \"org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy\");\n    subAppTableDescp.setValue(\"KeyPrefixRegionSplitPolicy.prefix_length\",\n        TimelineHBaseSchemaConstants.USERNAME_SPLIT_KEY_PREFIX_LENGTH);\n    admin.createTable(subAppTableDescp,\n        TimelineHBaseSchemaConstants.getUsernameSplits());\n    LOG.info(\"Status of table creation for \" + table.getNameAsString() + \"\u003d\"\n        + admin.tableExists(table));\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/subapplication/SubApplicationTable.java"
    }
  }
}