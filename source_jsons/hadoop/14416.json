{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Journal.java",
  "functionName": "startLogSegment",
  "functionId": "startLogSegment___reqInfo-RequestInfo__txid-long__layoutVersion-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
  "functionStartLine": 568,
  "functionEndLine": 624,
  "numCommitsSeen": 99,
  "timeTaken": 3837,
  "changeHistory": [
    "151c8ddbe4c05fcb5f251fa4450edc452f6c735a",
    "6beb25ab7e4f5454dba0315a296081e61753f301",
    "53bad4eb008ec553dcdbe01e7ae975dcecde6590",
    "9dab514b22f49322738935cfd915c2b4eba50b88",
    "663e7484c04c197eed53f10a7808140f1c955277",
    "60c20e559b8036410e2d9081b9c60d1e04e56253",
    "8021d9199f278345aca6211f318145342ad036f4",
    "1e68d4726b225fb4a62eb8d79a3160dd03059ccb",
    "c95a1674b61ef2a6963dc64604986ef90a8c636d",
    "f765fdb65701e61887daedb2b369af4be12cb432",
    "74d4573a23db5586c6e47ff2277aa7c35237da34"
  ],
  "changeHistoryShort": {
    "151c8ddbe4c05fcb5f251fa4450edc452f6c735a": "Ybodychange",
    "6beb25ab7e4f5454dba0315a296081e61753f301": "Ybodychange",
    "53bad4eb008ec553dcdbe01e7ae975dcecde6590": "Ybodychange",
    "9dab514b22f49322738935cfd915c2b4eba50b88": "Ymultichange(Yparameterchange,Ybodychange)",
    "663e7484c04c197eed53f10a7808140f1c955277": "Ybodychange",
    "60c20e559b8036410e2d9081b9c60d1e04e56253": "Ybodychange",
    "8021d9199f278345aca6211f318145342ad036f4": "Ybodychange",
    "1e68d4726b225fb4a62eb8d79a3160dd03059ccb": "Ybodychange",
    "c95a1674b61ef2a6963dc64604986ef90a8c636d": "Ybodychange",
    "f765fdb65701e61887daedb2b369af4be12cb432": "Ybodychange",
    "74d4573a23db5586c6e47ff2277aa7c35237da34": "Yintroduced"
  },
  "changeHistoryDetails": {
    "151c8ddbe4c05fcb5f251fa4450edc452f6c735a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13608. [SBN read] Edit Tail Fast Path Part 2: Add ability for JournalNode to serve edits via RPC. Contributed by Erik Krogen.\n",
      "commitDate": "24/12/18 9:33 AM",
      "commitName": "151c8ddbe4c05fcb5f251fa4450edc452f6c735a",
      "commitAuthor": "Erik Krogen",
      "commitDateOld": "06/09/18 2:48 PM",
      "commitNameOld": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 108.82,
      "commitsBetweenForRepo": 926,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,56 +1,57 @@\n   public synchronized void startLogSegment(RequestInfo reqInfo, long txid,\n       int layoutVersion) throws IOException {\n     assert fjm !\u003d null;\n     checkFormatted();\n     checkRequest(reqInfo);\n     \n     if (curSegment !\u003d null) {\n       LOG.warn(\"Client is requesting a new log segment \" + txid + \n           \" though we are already writing \" + curSegment + \". \" +\n           \"Aborting the current segment in order to begin the new one.\" +\n           \" ; journal id: \" + journalId);\n       // The writer may have lost a connection to us and is now\n       // re-connecting after the connection came back.\n       // We should abort our own old segment.\n       abortCurSegment();\n     }\n \n     // Paranoid sanity check: we should never overwrite a finalized log file.\n     // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n     // This can happen if the writer crashes exactly at the start of a segment.\n     EditLogFile existing \u003d fjm.getLogFile(txid);\n     if (existing !\u003d null) {\n       if (!existing.isInProgress()) {\n         throw new IllegalStateException(\"Already have a finalized segment \" +\n             existing + \" beginning at \" + txid + \" ; journal id: \" + journalId);\n       }\n       \n       // If it\u0027s in-progress, it should only contain one transaction,\n       // because the \"startLogSegment\" transaction is written alone at the\n       // start of each segment. \n       existing.scanLog(Long.MAX_VALUE, false);\n       if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n         throw new IllegalStateException(\"The log file \" +\n             existing + \" seems to contain valid transactions\" +\n             \" ; journal id: \" + journalId);\n       }\n     }\n     \n     long curLastWriterEpoch \u003d lastWriterEpoch.get();\n     if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n       LOG.info(\"Updating lastWriterEpoch from \" + curLastWriterEpoch +\n           \" to \" + reqInfo.getEpoch() + \" for client \" +\n           Server.getRemoteIp() + \" ; journal id: \" + journalId);\n       lastWriterEpoch.set(reqInfo.getEpoch());\n     }\n \n     // The fact that we are starting a segment at this txid indicates\n     // that any previous recovery for this same segment was aborted.\n     // Otherwise, no writer would have started writing. So, we can\n     // remove the record of the older segment here.\n     purgePaxosDecision(txid);\n     \n     curSegment \u003d fjm.startLogSegment(txid, layoutVersion);\n     curSegmentTxId \u003d txid;\n+    curSegmentLayoutVersion \u003d layoutVersion;\n     nextTxId \u003d txid;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void startLogSegment(RequestInfo reqInfo, long txid,\n      int layoutVersion) throws IOException {\n    assert fjm !\u003d null;\n    checkFormatted();\n    checkRequest(reqInfo);\n    \n    if (curSegment !\u003d null) {\n      LOG.warn(\"Client is requesting a new log segment \" + txid + \n          \" though we are already writing \" + curSegment + \". \" +\n          \"Aborting the current segment in order to begin the new one.\" +\n          \" ; journal id: \" + journalId);\n      // The writer may have lost a connection to us and is now\n      // re-connecting after the connection came back.\n      // We should abort our own old segment.\n      abortCurSegment();\n    }\n\n    // Paranoid sanity check: we should never overwrite a finalized log file.\n    // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n    // This can happen if the writer crashes exactly at the start of a segment.\n    EditLogFile existing \u003d fjm.getLogFile(txid);\n    if (existing !\u003d null) {\n      if (!existing.isInProgress()) {\n        throw new IllegalStateException(\"Already have a finalized segment \" +\n            existing + \" beginning at \" + txid + \" ; journal id: \" + journalId);\n      }\n      \n      // If it\u0027s in-progress, it should only contain one transaction,\n      // because the \"startLogSegment\" transaction is written alone at the\n      // start of each segment. \n      existing.scanLog(Long.MAX_VALUE, false);\n      if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n        throw new IllegalStateException(\"The log file \" +\n            existing + \" seems to contain valid transactions\" +\n            \" ; journal id: \" + journalId);\n      }\n    }\n    \n    long curLastWriterEpoch \u003d lastWriterEpoch.get();\n    if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n      LOG.info(\"Updating lastWriterEpoch from \" + curLastWriterEpoch +\n          \" to \" + reqInfo.getEpoch() + \" for client \" +\n          Server.getRemoteIp() + \" ; journal id: \" + journalId);\n      lastWriterEpoch.set(reqInfo.getEpoch());\n    }\n\n    // The fact that we are starting a segment at this txid indicates\n    // that any previous recovery for this same segment was aborted.\n    // Otherwise, no writer would have started writing. So, we can\n    // remove the record of the older segment here.\n    purgePaxosDecision(txid);\n    \n    curSegment \u003d fjm.startLogSegment(txid, layoutVersion);\n    curSegmentTxId \u003d txid;\n    curSegmentLayoutVersion \u003d layoutVersion;\n    nextTxId \u003d txid;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "6beb25ab7e4f5454dba0315a296081e61753f301": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13544. Improve logging for JournalNode in federated cluster.\n",
      "commitDate": "14/05/18 10:12 AM",
      "commitName": "6beb25ab7e4f5454dba0315a296081e61753f301",
      "commitAuthor": "Hanisha Koneru",
      "commitDateOld": "13/10/17 2:22 PM",
      "commitNameOld": "8dd1eeb94fef59feaf19182dd8f1fcf1389c7f34",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 212.83,
      "commitsBetweenForRepo": 2051,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,56 @@\n   public synchronized void startLogSegment(RequestInfo reqInfo, long txid,\n       int layoutVersion) throws IOException {\n     assert fjm !\u003d null;\n     checkFormatted();\n     checkRequest(reqInfo);\n     \n     if (curSegment !\u003d null) {\n       LOG.warn(\"Client is requesting a new log segment \" + txid + \n           \" though we are already writing \" + curSegment + \". \" +\n-          \"Aborting the current segment in order to begin the new one.\");\n+          \"Aborting the current segment in order to begin the new one.\" +\n+          \" ; journal id: \" + journalId);\n       // The writer may have lost a connection to us and is now\n       // re-connecting after the connection came back.\n       // We should abort our own old segment.\n       abortCurSegment();\n     }\n \n     // Paranoid sanity check: we should never overwrite a finalized log file.\n     // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n     // This can happen if the writer crashes exactly at the start of a segment.\n     EditLogFile existing \u003d fjm.getLogFile(txid);\n     if (existing !\u003d null) {\n       if (!existing.isInProgress()) {\n         throw new IllegalStateException(\"Already have a finalized segment \" +\n-            existing + \" beginning at \" + txid);\n+            existing + \" beginning at \" + txid + \" ; journal id: \" + journalId);\n       }\n       \n       // If it\u0027s in-progress, it should only contain one transaction,\n       // because the \"startLogSegment\" transaction is written alone at the\n       // start of each segment. \n       existing.scanLog(Long.MAX_VALUE, false);\n       if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n         throw new IllegalStateException(\"The log file \" +\n-            existing + \" seems to contain valid transactions\");\n+            existing + \" seems to contain valid transactions\" +\n+            \" ; journal id: \" + journalId);\n       }\n     }\n     \n     long curLastWriterEpoch \u003d lastWriterEpoch.get();\n     if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n       LOG.info(\"Updating lastWriterEpoch from \" + curLastWriterEpoch +\n           \" to \" + reqInfo.getEpoch() + \" for client \" +\n-          Server.getRemoteIp());\n+          Server.getRemoteIp() + \" ; journal id: \" + journalId);\n       lastWriterEpoch.set(reqInfo.getEpoch());\n     }\n \n     // The fact that we are starting a segment at this txid indicates\n     // that any previous recovery for this same segment was aborted.\n     // Otherwise, no writer would have started writing. So, we can\n     // remove the record of the older segment here.\n     purgePaxosDecision(txid);\n     \n     curSegment \u003d fjm.startLogSegment(txid, layoutVersion);\n     curSegmentTxId \u003d txid;\n     nextTxId \u003d txid;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void startLogSegment(RequestInfo reqInfo, long txid,\n      int layoutVersion) throws IOException {\n    assert fjm !\u003d null;\n    checkFormatted();\n    checkRequest(reqInfo);\n    \n    if (curSegment !\u003d null) {\n      LOG.warn(\"Client is requesting a new log segment \" + txid + \n          \" though we are already writing \" + curSegment + \". \" +\n          \"Aborting the current segment in order to begin the new one.\" +\n          \" ; journal id: \" + journalId);\n      // The writer may have lost a connection to us and is now\n      // re-connecting after the connection came back.\n      // We should abort our own old segment.\n      abortCurSegment();\n    }\n\n    // Paranoid sanity check: we should never overwrite a finalized log file.\n    // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n    // This can happen if the writer crashes exactly at the start of a segment.\n    EditLogFile existing \u003d fjm.getLogFile(txid);\n    if (existing !\u003d null) {\n      if (!existing.isInProgress()) {\n        throw new IllegalStateException(\"Already have a finalized segment \" +\n            existing + \" beginning at \" + txid + \" ; journal id: \" + journalId);\n      }\n      \n      // If it\u0027s in-progress, it should only contain one transaction,\n      // because the \"startLogSegment\" transaction is written alone at the\n      // start of each segment. \n      existing.scanLog(Long.MAX_VALUE, false);\n      if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n        throw new IllegalStateException(\"The log file \" +\n            existing + \" seems to contain valid transactions\" +\n            \" ; journal id: \" + journalId);\n      }\n    }\n    \n    long curLastWriterEpoch \u003d lastWriterEpoch.get();\n    if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n      LOG.info(\"Updating lastWriterEpoch from \" + curLastWriterEpoch +\n          \" to \" + reqInfo.getEpoch() + \" for client \" +\n          Server.getRemoteIp() + \" ; journal id: \" + journalId);\n      lastWriterEpoch.set(reqInfo.getEpoch());\n    }\n\n    // The fact that we are starting a segment at this txid indicates\n    // that any previous recovery for this same segment was aborted.\n    // Otherwise, no writer would have started writing. So, we can\n    // remove the record of the older segment here.\n    purgePaxosDecision(txid);\n    \n    curSegment \u003d fjm.startLogSegment(txid, layoutVersion);\n    curSegmentTxId \u003d txid;\n    nextTxId \u003d txid;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "53bad4eb008ec553dcdbe01e7ae975dcecde6590": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8996. Consolidate validateLog and scanLog in FJM#EditLogFile (Zhe Zhang via Colin P. McCabe)\n",
      "commitDate": "14/09/15 3:22 PM",
      "commitName": "53bad4eb008ec553dcdbe01e7ae975dcecde6590",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "08/09/15 10:33 PM",
      "commitNameOld": "94cf7ab9d28a885181afeb2c181dfe857d158254",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 5.7,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,54 @@\n   public synchronized void startLogSegment(RequestInfo reqInfo, long txid,\n       int layoutVersion) throws IOException {\n     assert fjm !\u003d null;\n     checkFormatted();\n     checkRequest(reqInfo);\n     \n     if (curSegment !\u003d null) {\n       LOG.warn(\"Client is requesting a new log segment \" + txid + \n           \" though we are already writing \" + curSegment + \". \" +\n           \"Aborting the current segment in order to begin the new one.\");\n       // The writer may have lost a connection to us and is now\n       // re-connecting after the connection came back.\n       // We should abort our own old segment.\n       abortCurSegment();\n     }\n \n     // Paranoid sanity check: we should never overwrite a finalized log file.\n     // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n     // This can happen if the writer crashes exactly at the start of a segment.\n     EditLogFile existing \u003d fjm.getLogFile(txid);\n     if (existing !\u003d null) {\n       if (!existing.isInProgress()) {\n         throw new IllegalStateException(\"Already have a finalized segment \" +\n             existing + \" beginning at \" + txid);\n       }\n       \n       // If it\u0027s in-progress, it should only contain one transaction,\n       // because the \"startLogSegment\" transaction is written alone at the\n       // start of each segment. \n-      existing.scanLog();\n+      existing.scanLog(Long.MAX_VALUE, false);\n       if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n         throw new IllegalStateException(\"The log file \" +\n             existing + \" seems to contain valid transactions\");\n       }\n     }\n     \n     long curLastWriterEpoch \u003d lastWriterEpoch.get();\n     if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n       LOG.info(\"Updating lastWriterEpoch from \" + curLastWriterEpoch +\n           \" to \" + reqInfo.getEpoch() + \" for client \" +\n           Server.getRemoteIp());\n       lastWriterEpoch.set(reqInfo.getEpoch());\n     }\n \n     // The fact that we are starting a segment at this txid indicates\n     // that any previous recovery for this same segment was aborted.\n     // Otherwise, no writer would have started writing. So, we can\n     // remove the record of the older segment here.\n     purgePaxosDecision(txid);\n     \n     curSegment \u003d fjm.startLogSegment(txid, layoutVersion);\n     curSegmentTxId \u003d txid;\n     nextTxId \u003d txid;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void startLogSegment(RequestInfo reqInfo, long txid,\n      int layoutVersion) throws IOException {\n    assert fjm !\u003d null;\n    checkFormatted();\n    checkRequest(reqInfo);\n    \n    if (curSegment !\u003d null) {\n      LOG.warn(\"Client is requesting a new log segment \" + txid + \n          \" though we are already writing \" + curSegment + \". \" +\n          \"Aborting the current segment in order to begin the new one.\");\n      // The writer may have lost a connection to us and is now\n      // re-connecting after the connection came back.\n      // We should abort our own old segment.\n      abortCurSegment();\n    }\n\n    // Paranoid sanity check: we should never overwrite a finalized log file.\n    // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n    // This can happen if the writer crashes exactly at the start of a segment.\n    EditLogFile existing \u003d fjm.getLogFile(txid);\n    if (existing !\u003d null) {\n      if (!existing.isInProgress()) {\n        throw new IllegalStateException(\"Already have a finalized segment \" +\n            existing + \" beginning at \" + txid);\n      }\n      \n      // If it\u0027s in-progress, it should only contain one transaction,\n      // because the \"startLogSegment\" transaction is written alone at the\n      // start of each segment. \n      existing.scanLog(Long.MAX_VALUE, false);\n      if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n        throw new IllegalStateException(\"The log file \" +\n            existing + \" seems to contain valid transactions\");\n      }\n    }\n    \n    long curLastWriterEpoch \u003d lastWriterEpoch.get();\n    if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n      LOG.info(\"Updating lastWriterEpoch from \" + curLastWriterEpoch +\n          \" to \" + reqInfo.getEpoch() + \" for client \" +\n          Server.getRemoteIp());\n      lastWriterEpoch.set(reqInfo.getEpoch());\n    }\n\n    // The fact that we are starting a segment at this txid indicates\n    // that any previous recovery for this same segment was aborted.\n    // Otherwise, no writer would have started writing. So, we can\n    // remove the record of the older segment here.\n    purgePaxosDecision(txid);\n    \n    curSegment \u003d fjm.startLogSegment(txid, layoutVersion);\n    curSegmentTxId \u003d txid;\n    nextTxId \u003d txid;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "9dab514b22f49322738935cfd915c2b4eba50b88": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6038. Allow JournalNode to handle editlog produced by new release with future layoutversion. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1579813 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/03/14 4:06 PM",
      "commitName": "9dab514b22f49322738935cfd915c2b4eba50b88",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6038. Allow JournalNode to handle editlog produced by new release with future layoutversion. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1579813 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/03/14 4:06 PM",
          "commitName": "9dab514b22f49322738935cfd915c2b4eba50b88",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "20/02/14 3:21 PM",
          "commitNameOld": "329c7051817c956bfc64661f4e1349b7009a2747",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 27.99,
          "commitsBetweenForRepo": 248,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,54 +1,54 @@\n-  public synchronized void startLogSegment(RequestInfo reqInfo, long txid)\n-      throws IOException {\n+  public synchronized void startLogSegment(RequestInfo reqInfo, long txid,\n+      int layoutVersion) throws IOException {\n     assert fjm !\u003d null;\n     checkFormatted();\n     checkRequest(reqInfo);\n     \n     if (curSegment !\u003d null) {\n       LOG.warn(\"Client is requesting a new log segment \" + txid + \n           \" though we are already writing \" + curSegment + \". \" +\n           \"Aborting the current segment in order to begin the new one.\");\n       // The writer may have lost a connection to us and is now\n       // re-connecting after the connection came back.\n       // We should abort our own old segment.\n       abortCurSegment();\n     }\n \n     // Paranoid sanity check: we should never overwrite a finalized log file.\n     // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n     // This can happen if the writer crashes exactly at the start of a segment.\n     EditLogFile existing \u003d fjm.getLogFile(txid);\n     if (existing !\u003d null) {\n       if (!existing.isInProgress()) {\n         throw new IllegalStateException(\"Already have a finalized segment \" +\n             existing + \" beginning at \" + txid);\n       }\n       \n       // If it\u0027s in-progress, it should only contain one transaction,\n       // because the \"startLogSegment\" transaction is written alone at the\n       // start of each segment. \n-      existing.validateLog();\n+      existing.scanLog();\n       if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n         throw new IllegalStateException(\"The log file \" +\n             existing + \" seems to contain valid transactions\");\n       }\n     }\n     \n     long curLastWriterEpoch \u003d lastWriterEpoch.get();\n     if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n       LOG.info(\"Updating lastWriterEpoch from \" + curLastWriterEpoch +\n           \" to \" + reqInfo.getEpoch() + \" for client \" +\n           Server.getRemoteIp());\n       lastWriterEpoch.set(reqInfo.getEpoch());\n     }\n \n     // The fact that we are starting a segment at this txid indicates\n     // that any previous recovery for this same segment was aborted.\n     // Otherwise, no writer would have started writing. So, we can\n     // remove the record of the older segment here.\n     purgePaxosDecision(txid);\n     \n-    curSegment \u003d fjm.startLogSegment(txid);\n+    curSegment \u003d fjm.startLogSegment(txid, layoutVersion);\n     curSegmentTxId \u003d txid;\n     nextTxId \u003d txid;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void startLogSegment(RequestInfo reqInfo, long txid,\n      int layoutVersion) throws IOException {\n    assert fjm !\u003d null;\n    checkFormatted();\n    checkRequest(reqInfo);\n    \n    if (curSegment !\u003d null) {\n      LOG.warn(\"Client is requesting a new log segment \" + txid + \n          \" though we are already writing \" + curSegment + \". \" +\n          \"Aborting the current segment in order to begin the new one.\");\n      // The writer may have lost a connection to us and is now\n      // re-connecting after the connection came back.\n      // We should abort our own old segment.\n      abortCurSegment();\n    }\n\n    // Paranoid sanity check: we should never overwrite a finalized log file.\n    // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n    // This can happen if the writer crashes exactly at the start of a segment.\n    EditLogFile existing \u003d fjm.getLogFile(txid);\n    if (existing !\u003d null) {\n      if (!existing.isInProgress()) {\n        throw new IllegalStateException(\"Already have a finalized segment \" +\n            existing + \" beginning at \" + txid);\n      }\n      \n      // If it\u0027s in-progress, it should only contain one transaction,\n      // because the \"startLogSegment\" transaction is written alone at the\n      // start of each segment. \n      existing.scanLog();\n      if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n        throw new IllegalStateException(\"The log file \" +\n            existing + \" seems to contain valid transactions\");\n      }\n    }\n    \n    long curLastWriterEpoch \u003d lastWriterEpoch.get();\n    if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n      LOG.info(\"Updating lastWriterEpoch from \" + curLastWriterEpoch +\n          \" to \" + reqInfo.getEpoch() + \" for client \" +\n          Server.getRemoteIp());\n      lastWriterEpoch.set(reqInfo.getEpoch());\n    }\n\n    // The fact that we are starting a segment at this txid indicates\n    // that any previous recovery for this same segment was aborted.\n    // Otherwise, no writer would have started writing. So, we can\n    // remove the record of the older segment here.\n    purgePaxosDecision(txid);\n    \n    curSegment \u003d fjm.startLogSegment(txid, layoutVersion);\n    curSegmentTxId \u003d txid;\n    nextTxId \u003d txid;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
          "extendedDetails": {
            "oldValue": "[reqInfo-RequestInfo, txid-long]",
            "newValue": "[reqInfo-RequestInfo, txid-long, layoutVersion-int]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6038. Allow JournalNode to handle editlog produced by new release with future layoutversion. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1579813 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/03/14 4:06 PM",
          "commitName": "9dab514b22f49322738935cfd915c2b4eba50b88",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "20/02/14 3:21 PM",
          "commitNameOld": "329c7051817c956bfc64661f4e1349b7009a2747",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 27.99,
          "commitsBetweenForRepo": 248,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,54 +1,54 @@\n-  public synchronized void startLogSegment(RequestInfo reqInfo, long txid)\n-      throws IOException {\n+  public synchronized void startLogSegment(RequestInfo reqInfo, long txid,\n+      int layoutVersion) throws IOException {\n     assert fjm !\u003d null;\n     checkFormatted();\n     checkRequest(reqInfo);\n     \n     if (curSegment !\u003d null) {\n       LOG.warn(\"Client is requesting a new log segment \" + txid + \n           \" though we are already writing \" + curSegment + \". \" +\n           \"Aborting the current segment in order to begin the new one.\");\n       // The writer may have lost a connection to us and is now\n       // re-connecting after the connection came back.\n       // We should abort our own old segment.\n       abortCurSegment();\n     }\n \n     // Paranoid sanity check: we should never overwrite a finalized log file.\n     // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n     // This can happen if the writer crashes exactly at the start of a segment.\n     EditLogFile existing \u003d fjm.getLogFile(txid);\n     if (existing !\u003d null) {\n       if (!existing.isInProgress()) {\n         throw new IllegalStateException(\"Already have a finalized segment \" +\n             existing + \" beginning at \" + txid);\n       }\n       \n       // If it\u0027s in-progress, it should only contain one transaction,\n       // because the \"startLogSegment\" transaction is written alone at the\n       // start of each segment. \n-      existing.validateLog();\n+      existing.scanLog();\n       if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n         throw new IllegalStateException(\"The log file \" +\n             existing + \" seems to contain valid transactions\");\n       }\n     }\n     \n     long curLastWriterEpoch \u003d lastWriterEpoch.get();\n     if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n       LOG.info(\"Updating lastWriterEpoch from \" + curLastWriterEpoch +\n           \" to \" + reqInfo.getEpoch() + \" for client \" +\n           Server.getRemoteIp());\n       lastWriterEpoch.set(reqInfo.getEpoch());\n     }\n \n     // The fact that we are starting a segment at this txid indicates\n     // that any previous recovery for this same segment was aborted.\n     // Otherwise, no writer would have started writing. So, we can\n     // remove the record of the older segment here.\n     purgePaxosDecision(txid);\n     \n-    curSegment \u003d fjm.startLogSegment(txid);\n+    curSegment \u003d fjm.startLogSegment(txid, layoutVersion);\n     curSegmentTxId \u003d txid;\n     nextTxId \u003d txid;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void startLogSegment(RequestInfo reqInfo, long txid,\n      int layoutVersion) throws IOException {\n    assert fjm !\u003d null;\n    checkFormatted();\n    checkRequest(reqInfo);\n    \n    if (curSegment !\u003d null) {\n      LOG.warn(\"Client is requesting a new log segment \" + txid + \n          \" though we are already writing \" + curSegment + \". \" +\n          \"Aborting the current segment in order to begin the new one.\");\n      // The writer may have lost a connection to us and is now\n      // re-connecting after the connection came back.\n      // We should abort our own old segment.\n      abortCurSegment();\n    }\n\n    // Paranoid sanity check: we should never overwrite a finalized log file.\n    // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n    // This can happen if the writer crashes exactly at the start of a segment.\n    EditLogFile existing \u003d fjm.getLogFile(txid);\n    if (existing !\u003d null) {\n      if (!existing.isInProgress()) {\n        throw new IllegalStateException(\"Already have a finalized segment \" +\n            existing + \" beginning at \" + txid);\n      }\n      \n      // If it\u0027s in-progress, it should only contain one transaction,\n      // because the \"startLogSegment\" transaction is written alone at the\n      // start of each segment. \n      existing.scanLog();\n      if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n        throw new IllegalStateException(\"The log file \" +\n            existing + \" seems to contain valid transactions\");\n      }\n    }\n    \n    long curLastWriterEpoch \u003d lastWriterEpoch.get();\n    if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n      LOG.info(\"Updating lastWriterEpoch from \" + curLastWriterEpoch +\n          \" to \" + reqInfo.getEpoch() + \" for client \" +\n          Server.getRemoteIp());\n      lastWriterEpoch.set(reqInfo.getEpoch());\n    }\n\n    // The fact that we are starting a segment at this txid indicates\n    // that any previous recovery for this same segment was aborted.\n    // Otherwise, no writer would have started writing. So, we can\n    // remove the record of the older segment here.\n    purgePaxosDecision(txid);\n    \n    curSegment \u003d fjm.startLogSegment(txid, layoutVersion);\n    curSegmentTxId \u003d txid;\n    nextTxId \u003d txid;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
          "extendedDetails": {}
        }
      ]
    },
    "663e7484c04c197eed53f10a7808140f1c955277": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3950. QJM: misc TODO cleanup, improved log messages, etc. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1387704 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/09/12 11:52 AM",
      "commitName": "663e7484c04c197eed53f10a7808140f1c955277",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "17/09/12 2:51 PM",
      "commitNameOld": "83c14fbd24353b5e882f065faec81e58449afed3",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 1.88,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,52 +1,54 @@\n   public synchronized void startLogSegment(RequestInfo reqInfo, long txid)\n       throws IOException {\n     assert fjm !\u003d null;\n     checkFormatted();\n     checkRequest(reqInfo);\n     \n     if (curSegment !\u003d null) {\n       LOG.warn(\"Client is requesting a new log segment \" + txid + \n           \" though we are already writing \" + curSegment + \". \" +\n           \"Aborting the current segment in order to begin the new one.\");\n       // The writer may have lost a connection to us and is now\n       // re-connecting after the connection came back.\n       // We should abort our own old segment.\n       abortCurSegment();\n     }\n \n     // Paranoid sanity check: we should never overwrite a finalized log file.\n     // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n     // This can happen if the writer crashes exactly at the start of a segment.\n     EditLogFile existing \u003d fjm.getLogFile(txid);\n     if (existing !\u003d null) {\n       if (!existing.isInProgress()) {\n         throw new IllegalStateException(\"Already have a finalized segment \" +\n             existing + \" beginning at \" + txid);\n       }\n       \n       // If it\u0027s in-progress, it should only contain one transaction,\n       // because the \"startLogSegment\" transaction is written alone at the\n       // start of each segment. \n       existing.validateLog();\n       if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n         throw new IllegalStateException(\"The log file \" +\n             existing + \" seems to contain valid transactions\");\n       }\n     }\n     \n     long curLastWriterEpoch \u003d lastWriterEpoch.get();\n     if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n-      LOG.info(\"Recording lastWriterEpoch \u003d \" + reqInfo.getEpoch());\n+      LOG.info(\"Updating lastWriterEpoch from \" + curLastWriterEpoch +\n+          \" to \" + reqInfo.getEpoch() + \" for client \" +\n+          Server.getRemoteIp());\n       lastWriterEpoch.set(reqInfo.getEpoch());\n     }\n \n     // The fact that we are starting a segment at this txid indicates\n     // that any previous recovery for this same segment was aborted.\n     // Otherwise, no writer would have started writing. So, we can\n     // remove the record of the older segment here.\n     purgePaxosDecision(txid);\n     \n     curSegment \u003d fjm.startLogSegment(txid);\n     curSegmentTxId \u003d txid;\n     nextTxId \u003d txid;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void startLogSegment(RequestInfo reqInfo, long txid)\n      throws IOException {\n    assert fjm !\u003d null;\n    checkFormatted();\n    checkRequest(reqInfo);\n    \n    if (curSegment !\u003d null) {\n      LOG.warn(\"Client is requesting a new log segment \" + txid + \n          \" though we are already writing \" + curSegment + \". \" +\n          \"Aborting the current segment in order to begin the new one.\");\n      // The writer may have lost a connection to us and is now\n      // re-connecting after the connection came back.\n      // We should abort our own old segment.\n      abortCurSegment();\n    }\n\n    // Paranoid sanity check: we should never overwrite a finalized log file.\n    // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n    // This can happen if the writer crashes exactly at the start of a segment.\n    EditLogFile existing \u003d fjm.getLogFile(txid);\n    if (existing !\u003d null) {\n      if (!existing.isInProgress()) {\n        throw new IllegalStateException(\"Already have a finalized segment \" +\n            existing + \" beginning at \" + txid);\n      }\n      \n      // If it\u0027s in-progress, it should only contain one transaction,\n      // because the \"startLogSegment\" transaction is written alone at the\n      // start of each segment. \n      existing.validateLog();\n      if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n        throw new IllegalStateException(\"The log file \" +\n            existing + \" seems to contain valid transactions\");\n      }\n    }\n    \n    long curLastWriterEpoch \u003d lastWriterEpoch.get();\n    if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n      LOG.info(\"Updating lastWriterEpoch from \" + curLastWriterEpoch +\n          \" to \" + reqInfo.getEpoch() + \" for client \" +\n          Server.getRemoteIp());\n      lastWriterEpoch.set(reqInfo.getEpoch());\n    }\n\n    // The fact that we are starting a segment at this txid indicates\n    // that any previous recovery for this same segment was aborted.\n    // Otherwise, no writer would have started writing. So, we can\n    // remove the record of the older segment here.\n    purgePaxosDecision(txid);\n    \n    curSegment \u003d fjm.startLogSegment(txid);\n    curSegmentTxId \u003d txid;\n    nextTxId \u003d txid;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "60c20e559b8036410e2d9081b9c60d1e04e56253": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3900. QJM: avoid validating log segments on log rolls. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1383041 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/09/12 11:53 AM",
      "commitName": "60c20e559b8036410e2d9081b9c60d1e04e56253",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "10/09/12 11:51 AM",
      "commitNameOld": "ca4582222e89114e4c61d38fbf973a66d2867abf",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,52 @@\n   public synchronized void startLogSegment(RequestInfo reqInfo, long txid)\n       throws IOException {\n     assert fjm !\u003d null;\n     checkFormatted();\n     checkRequest(reqInfo);\n     \n     if (curSegment !\u003d null) {\n       LOG.warn(\"Client is requesting a new log segment \" + txid + \n           \" though we are already writing \" + curSegment + \". \" +\n           \"Aborting the current segment in order to begin the new one.\");\n       // The writer may have lost a connection to us and is now\n       // re-connecting after the connection came back.\n       // We should abort our own old segment.\n-      curSegment.abort();\n-      curSegment \u003d null;\n+      abortCurSegment();\n     }\n \n     // Paranoid sanity check: we should never overwrite a finalized log file.\n     // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n     // This can happen if the writer crashes exactly at the start of a segment.\n     EditLogFile existing \u003d fjm.getLogFile(txid);\n     if (existing !\u003d null) {\n       if (!existing.isInProgress()) {\n         throw new IllegalStateException(\"Already have a finalized segment \" +\n             existing + \" beginning at \" + txid);\n       }\n       \n       // If it\u0027s in-progress, it should only contain one transaction,\n       // because the \"startLogSegment\" transaction is written alone at the\n       // start of each segment. \n       existing.validateLog();\n       if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n         throw new IllegalStateException(\"The log file \" +\n             existing + \" seems to contain valid transactions\");\n       }\n     }\n     \n     long curLastWriterEpoch \u003d lastWriterEpoch.get();\n     if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n       LOG.info(\"Recording lastWriterEpoch \u003d \" + reqInfo.getEpoch());\n       lastWriterEpoch.set(reqInfo.getEpoch());\n     }\n \n     // The fact that we are starting a segment at this txid indicates\n     // that any previous recovery for this same segment was aborted.\n     // Otherwise, no writer would have started writing. So, we can\n     // remove the record of the older segment here.\n     purgePaxosDecision(txid);\n     \n     curSegment \u003d fjm.startLogSegment(txid);\n     curSegmentTxId \u003d txid;\n     nextTxId \u003d txid;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void startLogSegment(RequestInfo reqInfo, long txid)\n      throws IOException {\n    assert fjm !\u003d null;\n    checkFormatted();\n    checkRequest(reqInfo);\n    \n    if (curSegment !\u003d null) {\n      LOG.warn(\"Client is requesting a new log segment \" + txid + \n          \" though we are already writing \" + curSegment + \". \" +\n          \"Aborting the current segment in order to begin the new one.\");\n      // The writer may have lost a connection to us and is now\n      // re-connecting after the connection came back.\n      // We should abort our own old segment.\n      abortCurSegment();\n    }\n\n    // Paranoid sanity check: we should never overwrite a finalized log file.\n    // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n    // This can happen if the writer crashes exactly at the start of a segment.\n    EditLogFile existing \u003d fjm.getLogFile(txid);\n    if (existing !\u003d null) {\n      if (!existing.isInProgress()) {\n        throw new IllegalStateException(\"Already have a finalized segment \" +\n            existing + \" beginning at \" + txid);\n      }\n      \n      // If it\u0027s in-progress, it should only contain one transaction,\n      // because the \"startLogSegment\" transaction is written alone at the\n      // start of each segment. \n      existing.validateLog();\n      if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n        throw new IllegalStateException(\"The log file \" +\n            existing + \" seems to contain valid transactions\");\n      }\n    }\n    \n    long curLastWriterEpoch \u003d lastWriterEpoch.get();\n    if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n      LOG.info(\"Recording lastWriterEpoch \u003d \" + reqInfo.getEpoch());\n      lastWriterEpoch.set(reqInfo.getEpoch());\n    }\n\n    // The fact that we are starting a segment at this txid indicates\n    // that any previous recovery for this same segment was aborted.\n    // Otherwise, no writer would have started writing. So, we can\n    // remove the record of the older segment here.\n    purgePaxosDecision(txid);\n    \n    curSegment \u003d fjm.startLogSegment(txid);\n    curSegmentTxId \u003d txid;\n    nextTxId \u003d txid;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "8021d9199f278345aca6211f318145342ad036f4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3863. Track last \"committed\" txid in QJM. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1380976 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/09/12 9:13 PM",
      "commitName": "8021d9199f278345aca6211f318145342ad036f4",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "27/08/12 12:55 PM",
      "commitNameOld": "1e68d4726b225fb4a62eb8d79a3160dd03059ccb",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 8.35,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,53 @@\n   public synchronized void startLogSegment(RequestInfo reqInfo, long txid)\n       throws IOException {\n     assert fjm !\u003d null;\n-    checkRequest(reqInfo);\n     checkFormatted();\n+    checkRequest(reqInfo);\n     \n     if (curSegment !\u003d null) {\n       LOG.warn(\"Client is requesting a new log segment \" + txid + \n           \" though we are already writing \" + curSegment + \". \" +\n           \"Aborting the current segment in order to begin the new one.\");\n       // The writer may have lost a connection to us and is now\n       // re-connecting after the connection came back.\n       // We should abort our own old segment.\n       curSegment.abort();\n       curSegment \u003d null;\n     }\n \n     // Paranoid sanity check: we should never overwrite a finalized log file.\n     // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n     // This can happen if the writer crashes exactly at the start of a segment.\n     EditLogFile existing \u003d fjm.getLogFile(txid);\n     if (existing !\u003d null) {\n       if (!existing.isInProgress()) {\n         throw new IllegalStateException(\"Already have a finalized segment \" +\n             existing + \" beginning at \" + txid);\n       }\n       \n       // If it\u0027s in-progress, it should only contain one transaction,\n       // because the \"startLogSegment\" transaction is written alone at the\n       // start of each segment. \n       existing.validateLog();\n       if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n         throw new IllegalStateException(\"The log file \" +\n             existing + \" seems to contain valid transactions\");\n       }\n     }\n     \n     long curLastWriterEpoch \u003d lastWriterEpoch.get();\n     if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n       LOG.info(\"Recording lastWriterEpoch \u003d \" + reqInfo.getEpoch());\n       lastWriterEpoch.set(reqInfo.getEpoch());\n     }\n \n     // The fact that we are starting a segment at this txid indicates\n     // that any previous recovery for this same segment was aborted.\n     // Otherwise, no writer would have started writing. So, we can\n     // remove the record of the older segment here.\n     purgePaxosDecision(txid);\n     \n     curSegment \u003d fjm.startLogSegment(txid);\n     curSegmentTxId \u003d txid;\n     nextTxId \u003d txid;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void startLogSegment(RequestInfo reqInfo, long txid)\n      throws IOException {\n    assert fjm !\u003d null;\n    checkFormatted();\n    checkRequest(reqInfo);\n    \n    if (curSegment !\u003d null) {\n      LOG.warn(\"Client is requesting a new log segment \" + txid + \n          \" though we are already writing \" + curSegment + \". \" +\n          \"Aborting the current segment in order to begin the new one.\");\n      // The writer may have lost a connection to us and is now\n      // re-connecting after the connection came back.\n      // We should abort our own old segment.\n      curSegment.abort();\n      curSegment \u003d null;\n    }\n\n    // Paranoid sanity check: we should never overwrite a finalized log file.\n    // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n    // This can happen if the writer crashes exactly at the start of a segment.\n    EditLogFile existing \u003d fjm.getLogFile(txid);\n    if (existing !\u003d null) {\n      if (!existing.isInProgress()) {\n        throw new IllegalStateException(\"Already have a finalized segment \" +\n            existing + \" beginning at \" + txid);\n      }\n      \n      // If it\u0027s in-progress, it should only contain one transaction,\n      // because the \"startLogSegment\" transaction is written alone at the\n      // start of each segment. \n      existing.validateLog();\n      if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n        throw new IllegalStateException(\"The log file \" +\n            existing + \" seems to contain valid transactions\");\n      }\n    }\n    \n    long curLastWriterEpoch \u003d lastWriterEpoch.get();\n    if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n      LOG.info(\"Recording lastWriterEpoch \u003d \" + reqInfo.getEpoch());\n      lastWriterEpoch.set(reqInfo.getEpoch());\n    }\n\n    // The fact that we are starting a segment at this txid indicates\n    // that any previous recovery for this same segment was aborted.\n    // Otherwise, no writer would have started writing. So, we can\n    // remove the record of the older segment here.\n    purgePaxosDecision(txid);\n    \n    curSegment \u003d fjm.startLogSegment(txid);\n    curSegmentTxId \u003d txid;\n    nextTxId \u003d txid;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "1e68d4726b225fb4a62eb8d79a3160dd03059ccb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3845. Fixes for edge cases in QJM recovery protocol. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1377809 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/08/12 12:55 PM",
      "commitName": "1e68d4726b225fb4a62eb8d79a3160dd03059ccb",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "15/08/12 11:58 AM",
      "commitNameOld": "42cdc1b0835abb4a331d40f30f2c210143b747bc",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 12.04,
      "commitsBetweenForRepo": 78,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,53 @@\n   public synchronized void startLogSegment(RequestInfo reqInfo, long txid)\n       throws IOException {\n     assert fjm !\u003d null;\n     checkRequest(reqInfo);\n     checkFormatted();\n     \n     if (curSegment !\u003d null) {\n       LOG.warn(\"Client is requesting a new log segment \" + txid + \n           \" though we are already writing \" + curSegment + \". \" +\n           \"Aborting the current segment in order to begin the new one.\");\n       // The writer may have lost a connection to us and is now\n       // re-connecting after the connection came back.\n       // We should abort our own old segment.\n       curSegment.abort();\n       curSegment \u003d null;\n     }\n \n     // Paranoid sanity check: we should never overwrite a finalized log file.\n     // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n     // This can happen if the writer crashes exactly at the start of a segment.\n     EditLogFile existing \u003d fjm.getLogFile(txid);\n     if (existing !\u003d null) {\n       if (!existing.isInProgress()) {\n         throw new IllegalStateException(\"Already have a finalized segment \" +\n             existing + \" beginning at \" + txid);\n       }\n       \n       // If it\u0027s in-progress, it should only contain one transaction,\n       // because the \"startLogSegment\" transaction is written alone at the\n       // start of each segment. \n       existing.validateLog();\n       if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n         throw new IllegalStateException(\"The log file \" +\n             existing + \" seems to contain valid transactions\");\n       }\n     }\n     \n+    long curLastWriterEpoch \u003d lastWriterEpoch.get();\n+    if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n+      LOG.info(\"Recording lastWriterEpoch \u003d \" + reqInfo.getEpoch());\n+      lastWriterEpoch.set(reqInfo.getEpoch());\n+    }\n+\n+    // The fact that we are starting a segment at this txid indicates\n+    // that any previous recovery for this same segment was aborted.\n+    // Otherwise, no writer would have started writing. So, we can\n+    // remove the record of the older segment here.\n+    purgePaxosDecision(txid);\n+    \n     curSegment \u003d fjm.startLogSegment(txid);\n     curSegmentTxId \u003d txid;\n     nextTxId \u003d txid;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void startLogSegment(RequestInfo reqInfo, long txid)\n      throws IOException {\n    assert fjm !\u003d null;\n    checkRequest(reqInfo);\n    checkFormatted();\n    \n    if (curSegment !\u003d null) {\n      LOG.warn(\"Client is requesting a new log segment \" + txid + \n          \" though we are already writing \" + curSegment + \". \" +\n          \"Aborting the current segment in order to begin the new one.\");\n      // The writer may have lost a connection to us and is now\n      // re-connecting after the connection came back.\n      // We should abort our own old segment.\n      curSegment.abort();\n      curSegment \u003d null;\n    }\n\n    // Paranoid sanity check: we should never overwrite a finalized log file.\n    // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n    // This can happen if the writer crashes exactly at the start of a segment.\n    EditLogFile existing \u003d fjm.getLogFile(txid);\n    if (existing !\u003d null) {\n      if (!existing.isInProgress()) {\n        throw new IllegalStateException(\"Already have a finalized segment \" +\n            existing + \" beginning at \" + txid);\n      }\n      \n      // If it\u0027s in-progress, it should only contain one transaction,\n      // because the \"startLogSegment\" transaction is written alone at the\n      // start of each segment. \n      existing.validateLog();\n      if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n        throw new IllegalStateException(\"The log file \" +\n            existing + \" seems to contain valid transactions\");\n      }\n    }\n    \n    long curLastWriterEpoch \u003d lastWriterEpoch.get();\n    if (curLastWriterEpoch !\u003d reqInfo.getEpoch()) {\n      LOG.info(\"Recording lastWriterEpoch \u003d \" + reqInfo.getEpoch());\n      lastWriterEpoch.set(reqInfo.getEpoch());\n    }\n\n    // The fact that we are starting a segment at this txid indicates\n    // that any previous recovery for this same segment was aborted.\n    // Otherwise, no writer would have started writing. So, we can\n    // remove the record of the older segment here.\n    purgePaxosDecision(txid);\n    \n    curSegment \u003d fjm.startLogSegment(txid);\n    curSegmentTxId \u003d txid;\n    nextTxId \u003d txid;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "c95a1674b61ef2a6963dc64604986ef90a8c636d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3799. QJM: handle empty log segments during recovery. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1373183 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/08/12 5:57 PM",
      "commitName": "c95a1674b61ef2a6963dc64604986ef90a8c636d",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "14/08/12 5:54 PM",
      "commitNameOld": "4a9b3c693def87579298fb59b7df0b8892a3508e",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,41 @@\n   public synchronized void startLogSegment(RequestInfo reqInfo, long txid)\n       throws IOException {\n     assert fjm !\u003d null;\n     checkRequest(reqInfo);\n     checkFormatted();\n     \n-    Preconditions.checkState(curSegment \u003d\u003d null,\n-        \"Can\u0027t start a log segment, already writing \" + curSegment);\n-    Preconditions.checkState(nextTxId \u003d\u003d txid || nextTxId \u003d\u003d HdfsConstants.INVALID_TXID,\n-        \"Can\u0027t start log segment \" + txid + \" expecting nextTxId\u003d\" + nextTxId);\n+    if (curSegment !\u003d null) {\n+      LOG.warn(\"Client is requesting a new log segment \" + txid + \n+          \" though we are already writing \" + curSegment + \". \" +\n+          \"Aborting the current segment in order to begin the new one.\");\n+      // The writer may have lost a connection to us and is now\n+      // re-connecting after the connection came back.\n+      // We should abort our own old segment.\n+      curSegment.abort();\n+      curSegment \u003d null;\n+    }\n+\n+    // Paranoid sanity check: we should never overwrite a finalized log file.\n+    // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n+    // This can happen if the writer crashes exactly at the start of a segment.\n+    EditLogFile existing \u003d fjm.getLogFile(txid);\n+    if (existing !\u003d null) {\n+      if (!existing.isInProgress()) {\n+        throw new IllegalStateException(\"Already have a finalized segment \" +\n+            existing + \" beginning at \" + txid);\n+      }\n+      \n+      // If it\u0027s in-progress, it should only contain one transaction,\n+      // because the \"startLogSegment\" transaction is written alone at the\n+      // start of each segment. \n+      existing.validateLog();\n+      if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n+        throw new IllegalStateException(\"The log file \" +\n+            existing + \" seems to contain valid transactions\");\n+      }\n+    }\n+    \n     curSegment \u003d fjm.startLogSegment(txid);\n     curSegmentTxId \u003d txid;\n     nextTxId \u003d txid;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void startLogSegment(RequestInfo reqInfo, long txid)\n      throws IOException {\n    assert fjm !\u003d null;\n    checkRequest(reqInfo);\n    checkFormatted();\n    \n    if (curSegment !\u003d null) {\n      LOG.warn(\"Client is requesting a new log segment \" + txid + \n          \" though we are already writing \" + curSegment + \". \" +\n          \"Aborting the current segment in order to begin the new one.\");\n      // The writer may have lost a connection to us and is now\n      // re-connecting after the connection came back.\n      // We should abort our own old segment.\n      curSegment.abort();\n      curSegment \u003d null;\n    }\n\n    // Paranoid sanity check: we should never overwrite a finalized log file.\n    // Additionally, if it\u0027s in-progress, it should have at most 1 transaction.\n    // This can happen if the writer crashes exactly at the start of a segment.\n    EditLogFile existing \u003d fjm.getLogFile(txid);\n    if (existing !\u003d null) {\n      if (!existing.isInProgress()) {\n        throw new IllegalStateException(\"Already have a finalized segment \" +\n            existing + \" beginning at \" + txid);\n      }\n      \n      // If it\u0027s in-progress, it should only contain one transaction,\n      // because the \"startLogSegment\" transaction is written alone at the\n      // start of each segment. \n      existing.validateLog();\n      if (existing.getLastTxId() !\u003d existing.getFirstTxId()) {\n        throw new IllegalStateException(\"The log file \" +\n            existing + \" seems to contain valid transactions\");\n      }\n    }\n    \n    curSegment \u003d fjm.startLogSegment(txid);\n    curSegmentTxId \u003d txid;\n    nextTxId \u003d txid;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "f765fdb65701e61887daedb2b369af4be12cb432": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3793. Implement genericized format() in QJM. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1373177 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/08/12 5:48 PM",
      "commitName": "f765fdb65701e61887daedb2b369af4be12cb432",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "25/07/12 2:47 PM",
      "commitNameOld": "b17018e4b821ec860144d8bd38bc1fcb0d7eeaa5",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 20.13,
      "commitsBetweenForRepo": 82,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,14 @@\n   public synchronized void startLogSegment(RequestInfo reqInfo, long txid)\n       throws IOException {\n     assert fjm !\u003d null;\n     checkRequest(reqInfo);\n+    checkFormatted();\n     \n     Preconditions.checkState(curSegment \u003d\u003d null,\n         \"Can\u0027t start a log segment, already writing \" + curSegment);\n     Preconditions.checkState(nextTxId \u003d\u003d txid || nextTxId \u003d\u003d HdfsConstants.INVALID_TXID,\n         \"Can\u0027t start log segment \" + txid + \" expecting nextTxId\u003d\" + nextTxId);\n     curSegment \u003d fjm.startLogSegment(txid);\n     curSegmentTxId \u003d txid;\n     nextTxId \u003d txid;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void startLogSegment(RequestInfo reqInfo, long txid)\n      throws IOException {\n    assert fjm !\u003d null;\n    checkRequest(reqInfo);\n    checkFormatted();\n    \n    Preconditions.checkState(curSegment \u003d\u003d null,\n        \"Can\u0027t start a log segment, already writing \" + curSegment);\n    Preconditions.checkState(nextTxId \u003d\u003d txid || nextTxId \u003d\u003d HdfsConstants.INVALID_TXID,\n        \"Can\u0027t start log segment \" + txid + \" expecting nextTxId\u003d\" + nextTxId);\n    curSegment \u003d fjm.startLogSegment(txid);\n    curSegmentTxId \u003d txid;\n    nextTxId \u003d txid;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "74d4573a23db5586c6e47ff2277aa7c35237da34": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1363596 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/07/12 5:25 PM",
      "commitName": "74d4573a23db5586c6e47ff2277aa7c35237da34",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,13 @@\n+  public synchronized void startLogSegment(RequestInfo reqInfo, long txid)\n+      throws IOException {\n+    assert fjm !\u003d null;\n+    checkRequest(reqInfo);\n+    \n+    Preconditions.checkState(curSegment \u003d\u003d null,\n+        \"Can\u0027t start a log segment, already writing \" + curSegment);\n+    Preconditions.checkState(nextTxId \u003d\u003d txid || nextTxId \u003d\u003d HdfsConstants.INVALID_TXID,\n+        \"Can\u0027t start log segment \" + txid + \" expecting nextTxId\u003d\" + nextTxId);\n+    curSegment \u003d fjm.startLogSegment(txid);\n+    curSegmentTxId \u003d txid;\n+    nextTxId \u003d txid;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void startLogSegment(RequestInfo reqInfo, long txid)\n      throws IOException {\n    assert fjm !\u003d null;\n    checkRequest(reqInfo);\n    \n    Preconditions.checkState(curSegment \u003d\u003d null,\n        \"Can\u0027t start a log segment, already writing \" + curSegment);\n    Preconditions.checkState(nextTxId \u003d\u003d txid || nextTxId \u003d\u003d HdfsConstants.INVALID_TXID,\n        \"Can\u0027t start log segment \" + txid + \" expecting nextTxId\u003d\" + nextTxId);\n    curSegment \u003d fjm.startLogSegment(txid);\n    curSegmentTxId \u003d txid;\n    nextTxId \u003d txid;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java"
    }
  }
}