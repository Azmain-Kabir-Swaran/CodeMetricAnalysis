{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "MapReduceChildJVM.java",
  "functionName": "setVMEnv",
  "functionId": "setVMEnv___environment-Map__String,String____task-Task",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java",
  "functionStartLine": 55,
  "functionEndLine": 101,
  "numCommitsSeen": 25,
  "timeTaken": 8428,
  "changeHistory": [
    "4571351cccf6d4977469d3d623cf045b06a5f5f0",
    "03ab24aa01ffea1cacf1fa9cbbf73c3f2904d981",
    "8a06949df87fe22b3a16080bc7b4155ad6f13895",
    "96e0ca2d272dc7ecd7f7f0e65a0c596fcc063bcb",
    "27e8c86999bc6a972a99216060b11ef35b7de858",
    "0870734787d7005d85697549eab5b6479d97d453",
    "408656614495674992349fbda3981559ada3de0b",
    "ab787f44aabfff0cd01b79a08a52ffaf923558b3",
    "c1d90772b6e38bb4e4be7ed75cb5d34f3048ad7b",
    "d00b3c49f6fb3f6a617add6203c6b55f6c345940",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "4571351cccf6d4977469d3d623cf045b06a5f5f0": "Ybodychange",
    "03ab24aa01ffea1cacf1fa9cbbf73c3f2904d981": "Ybodychange",
    "8a06949df87fe22b3a16080bc7b4155ad6f13895": "Ybodychange",
    "96e0ca2d272dc7ecd7f7f0e65a0c596fcc063bcb": "Ybodychange",
    "27e8c86999bc6a972a99216060b11ef35b7de858": "Ybodychange",
    "0870734787d7005d85697549eab5b6479d97d453": "Ybodychange",
    "408656614495674992349fbda3981559ada3de0b": "Ybodychange",
    "ab787f44aabfff0cd01b79a08a52ffaf923558b3": "Ybodychange",
    "c1d90772b6e38bb4e4be7ed75cb5d34f3048ad7b": "Ybodychange",
    "d00b3c49f6fb3f6a617add6203c6b55f6c345940": "Ymultichange(Yparameterchange,Ybodychange)",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4571351cccf6d4977469d3d623cf045b06a5f5f0": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-7069. Add ability to specify user environment variables individually. Contributed by Jim Brennan\n",
      "commitDate": "12/04/18 9:12 AM",
      "commitName": "4571351cccf6d4977469d3d623cf045b06a5f5f0",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "21/01/15 6:42 PM",
      "commitNameOld": "a003f71cacd35834a1abbc2ffb5446a1166caf73",
      "commitAuthorOld": "Gera Shegalov",
      "daysBetweenCommits": 1176.56,
      "commitsBetweenForRepo": 8516,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,47 @@\n   public static void setVMEnv(Map\u003cString, String\u003e environment,\n       Task task) {\n \n     JobConf conf \u003d task.conf;\n-    // Add the env variables passed by the user\n-    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n-    MRApps.setEnvFromInputString(environment, mapredChildEnv, conf);\n+    boolean isMap \u003d task.isMapTask();\n \n-    // Set logging level in the environment.\n-    // This is so that, if the child forks another \"bin/hadoop\" (common in\n-    // streaming) it will have the correct loglevel.\n-    environment.put(\n-        \"HADOOP_ROOT_LOGGER\", \n-        MRApps.getChildLogLevel(conf, task.isMapTask()) + \",console\");\n+    // Remove these before adding the user variables to prevent\n+    // MRApps.setEnvFromInputProperty() from appending to them.\n+    String hadoopRootLoggerKey \u003d \"HADOOP_ROOT_LOGGER\";\n+    String hadoopClientOptsKey \u003d \"HADOOP_CLIENT_OPTS\";\n+    environment.remove(hadoopRootLoggerKey);\n+    environment.remove(hadoopClientOptsKey);\n \n-    // TODO: The following is useful for instance in streaming tasks. Should be\n-    // set in ApplicationMaster\u0027s env by the RM.\n-    String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n-    if (hadoopClientOpts \u003d\u003d null) {\n-      hadoopClientOpts \u003d \"\";\n-    } else {\n-      hadoopClientOpts \u003d hadoopClientOpts + \" \";\n+    // Add the environment variables passed by the user\n+    MRApps.setEnvFromInputProperty(environment, getChildEnvProp(conf, isMap),\n+        getChildEnvDefaultValue(conf), conf);\n+\n+    // Set HADOOP_ROOT_LOGGER and HADOOP_CLIENTS if the user did not set them.\n+    if (!environment.containsKey(hadoopRootLoggerKey)) {\n+      // Set the value for logging level in the environment.\n+      // This is so that, if the child forks another \"bin/hadoop\" (common in\n+      // streaming) it will have the correct loglevel.\n+      environment.put(hadoopRootLoggerKey,\n+          MRApps.getChildLogLevel(conf, task.isMapTask()) + \",console\");\n     }\n-    environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n-    \n-    // setEnvFromInputString above will add env variable values from\n-    // mapredChildEnv to existing variables. We want to overwrite\n-    // HADOOP_ROOT_LOGGER and HADOOP_CLIENT_OPTS if the user set it explicitly.\n-    Map\u003cString, String\u003e tmpEnv \u003d new HashMap\u003cString, String\u003e();\n-    MRApps.setEnvFromInputString(tmpEnv, mapredChildEnv, conf);\n-    String[] keys \u003d { \"HADOOP_ROOT_LOGGER\", \"HADOOP_CLIENT_OPTS\" };\n-    for (String key : keys) {\n-      if (tmpEnv.containsKey(key)) {\n-        environment.put(key, tmpEnv.get(key));\n+    if (!environment.containsKey(hadoopClientOptsKey)) {\n+      // TODO: The following is useful for instance in streaming tasks.\n+      // Should be set in ApplicationMaster\u0027s env by the RM.\n+      String hadoopClientOptsValue \u003d System.getenv(hadoopClientOptsKey);\n+      if (hadoopClientOptsValue \u003d\u003d null) {\n+        hadoopClientOptsValue \u003d \"\";\n+      } else {\n+        hadoopClientOptsValue \u003d hadoopClientOptsValue + \" \";\n       }\n+      environment.put(hadoopClientOptsKey, hadoopClientOptsValue);\n     }\n \n     // Add stdout/stderr env\n     environment.put(\n         MRJobConfig.STDOUT_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDOUT)\n         );\n     environment.put(\n         MRJobConfig.STDERR_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDERR)\n         );\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void setVMEnv(Map\u003cString, String\u003e environment,\n      Task task) {\n\n    JobConf conf \u003d task.conf;\n    boolean isMap \u003d task.isMapTask();\n\n    // Remove these before adding the user variables to prevent\n    // MRApps.setEnvFromInputProperty() from appending to them.\n    String hadoopRootLoggerKey \u003d \"HADOOP_ROOT_LOGGER\";\n    String hadoopClientOptsKey \u003d \"HADOOP_CLIENT_OPTS\";\n    environment.remove(hadoopRootLoggerKey);\n    environment.remove(hadoopClientOptsKey);\n\n    // Add the environment variables passed by the user\n    MRApps.setEnvFromInputProperty(environment, getChildEnvProp(conf, isMap),\n        getChildEnvDefaultValue(conf), conf);\n\n    // Set HADOOP_ROOT_LOGGER and HADOOP_CLIENTS if the user did not set them.\n    if (!environment.containsKey(hadoopRootLoggerKey)) {\n      // Set the value for logging level in the environment.\n      // This is so that, if the child forks another \"bin/hadoop\" (common in\n      // streaming) it will have the correct loglevel.\n      environment.put(hadoopRootLoggerKey,\n          MRApps.getChildLogLevel(conf, task.isMapTask()) + \",console\");\n    }\n    if (!environment.containsKey(hadoopClientOptsKey)) {\n      // TODO: The following is useful for instance in streaming tasks.\n      // Should be set in ApplicationMaster\u0027s env by the RM.\n      String hadoopClientOptsValue \u003d System.getenv(hadoopClientOptsKey);\n      if (hadoopClientOptsValue \u003d\u003d null) {\n        hadoopClientOptsValue \u003d \"\";\n      } else {\n        hadoopClientOptsValue \u003d hadoopClientOptsValue + \" \";\n      }\n      environment.put(hadoopClientOptsKey, hadoopClientOptsValue);\n    }\n\n    // Add stdout/stderr env\n    environment.put(\n        MRJobConfig.STDOUT_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDOUT)\n        );\n    environment.put(\n        MRJobConfig.STDERR_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDERR)\n        );\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java",
      "extendedDetails": {}
    },
    "03ab24aa01ffea1cacf1fa9cbbf73c3f2904d981": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5932. Provide an option to use a dedicated reduce-side shuffle log. Contributed by Gera Shegalov\n",
      "commitDate": "03/12/14 9:02 AM",
      "commitName": "03ab24aa01ffea1cacf1fa9cbbf73c3f2904d981",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "25/11/14 4:24 PM",
      "commitNameOld": "a655973e781caf662b360c96e0fa3f5a873cf676",
      "commitAuthorOld": "Karthik Kambatla",
      "daysBetweenCommits": 7.69,
      "commitsBetweenForRepo": 38,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,47 @@\n   public static void setVMEnv(Map\u003cString, String\u003e environment,\n       Task task) {\n \n     JobConf conf \u003d task.conf;\n     // Add the env variables passed by the user\n     String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n     MRApps.setEnvFromInputString(environment, mapredChildEnv, conf);\n \n     // Set logging level in the environment.\n     // This is so that, if the child forks another \"bin/hadoop\" (common in\n     // streaming) it will have the correct loglevel.\n     environment.put(\n         \"HADOOP_ROOT_LOGGER\", \n-        getChildLogLevel(conf, task.isMapTask()) + \",console\");\n+        MRApps.getChildLogLevel(conf, task.isMapTask()) + \",console\");\n \n     // TODO: The following is useful for instance in streaming tasks. Should be\n     // set in ApplicationMaster\u0027s env by the RM.\n     String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n     if (hadoopClientOpts \u003d\u003d null) {\n       hadoopClientOpts \u003d \"\";\n     } else {\n       hadoopClientOpts \u003d hadoopClientOpts + \" \";\n     }\n     environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n     \n     // setEnvFromInputString above will add env variable values from\n     // mapredChildEnv to existing variables. We want to overwrite\n     // HADOOP_ROOT_LOGGER and HADOOP_CLIENT_OPTS if the user set it explicitly.\n     Map\u003cString, String\u003e tmpEnv \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setEnvFromInputString(tmpEnv, mapredChildEnv, conf);\n     String[] keys \u003d { \"HADOOP_ROOT_LOGGER\", \"HADOOP_CLIENT_OPTS\" };\n     for (String key : keys) {\n       if (tmpEnv.containsKey(key)) {\n         environment.put(key, tmpEnv.get(key));\n       }\n     }\n \n     // Add stdout/stderr env\n     environment.put(\n         MRJobConfig.STDOUT_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDOUT)\n         );\n     environment.put(\n         MRJobConfig.STDERR_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDERR)\n         );\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void setVMEnv(Map\u003cString, String\u003e environment,\n      Task task) {\n\n    JobConf conf \u003d task.conf;\n    // Add the env variables passed by the user\n    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n    MRApps.setEnvFromInputString(environment, mapredChildEnv, conf);\n\n    // Set logging level in the environment.\n    // This is so that, if the child forks another \"bin/hadoop\" (common in\n    // streaming) it will have the correct loglevel.\n    environment.put(\n        \"HADOOP_ROOT_LOGGER\", \n        MRApps.getChildLogLevel(conf, task.isMapTask()) + \",console\");\n\n    // TODO: The following is useful for instance in streaming tasks. Should be\n    // set in ApplicationMaster\u0027s env by the RM.\n    String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n    if (hadoopClientOpts \u003d\u003d null) {\n      hadoopClientOpts \u003d \"\";\n    } else {\n      hadoopClientOpts \u003d hadoopClientOpts + \" \";\n    }\n    environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n    \n    // setEnvFromInputString above will add env variable values from\n    // mapredChildEnv to existing variables. We want to overwrite\n    // HADOOP_ROOT_LOGGER and HADOOP_CLIENT_OPTS if the user set it explicitly.\n    Map\u003cString, String\u003e tmpEnv \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setEnvFromInputString(tmpEnv, mapredChildEnv, conf);\n    String[] keys \u003d { \"HADOOP_ROOT_LOGGER\", \"HADOOP_CLIENT_OPTS\" };\n    for (String key : keys) {\n      if (tmpEnv.containsKey(key)) {\n        environment.put(key, tmpEnv.get(key));\n      }\n    }\n\n    // Add stdout/stderr env\n    environment.put(\n        MRJobConfig.STDOUT_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDOUT)\n        );\n    environment.put(\n        MRJobConfig.STDERR_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDERR)\n        );\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java",
      "extendedDetails": {}
    },
    "8a06949df87fe22b3a16080bc7b4155ad6f13895": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5806. Fixed a bug in MRAppMaster so as to enable users to properly override HADOOP_ROOT_LOGGER or HADOOP_CLIENT_OPTS. Contributed by Varun Vasudev.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1580100 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/03/14 5:32 PM",
      "commitName": "8a06949df87fe22b3a16080bc7b4155ad6f13895",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "16/03/14 11:32 AM",
      "commitNameOld": "96e0ca2d272dc7ecd7f7f0e65a0c596fcc063bcb",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 5.25,
      "commitsBetweenForRepo": 49,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,47 @@\n   public static void setVMEnv(Map\u003cString, String\u003e environment,\n       Task task) {\n \n     JobConf conf \u003d task.conf;\n     // Add the env variables passed by the user\n     String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n     MRApps.setEnvFromInputString(environment, mapredChildEnv, conf);\n \n     // Set logging level in the environment.\n     // This is so that, if the child forks another \"bin/hadoop\" (common in\n     // streaming) it will have the correct loglevel.\n     environment.put(\n         \"HADOOP_ROOT_LOGGER\", \n-        getChildLogLevel(conf, task.isMapTask()) + \",CLA\"); \n+        getChildLogLevel(conf, task.isMapTask()) + \",console\");\n \n     // TODO: The following is useful for instance in streaming tasks. Should be\n     // set in ApplicationMaster\u0027s env by the RM.\n     String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n     if (hadoopClientOpts \u003d\u003d null) {\n       hadoopClientOpts \u003d \"\";\n     } else {\n       hadoopClientOpts \u003d hadoopClientOpts + \" \";\n     }\n-    // FIXME: don\u0027t think this is also needed given we already set java\n-    // properties.\n-    long logSize \u003d TaskLog.getTaskLogLength(conf);\n-    Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n-    setupLog4jProperties(task, logProps, logSize);\n-    Iterator\u003cString\u003e it \u003d logProps.iterator();\n-    StringBuffer buffer \u003d new StringBuffer();\n-    while (it.hasNext()) {\n-      buffer.append(\" \" + it.next());\n-    }\n-    hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n     environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n+    \n+    // setEnvFromInputString above will add env variable values from\n+    // mapredChildEnv to existing variables. We want to overwrite\n+    // HADOOP_ROOT_LOGGER and HADOOP_CLIENT_OPTS if the user set it explicitly.\n+    Map\u003cString, String\u003e tmpEnv \u003d new HashMap\u003cString, String\u003e();\n+    MRApps.setEnvFromInputString(tmpEnv, mapredChildEnv, conf);\n+    String[] keys \u003d { \"HADOOP_ROOT_LOGGER\", \"HADOOP_CLIENT_OPTS\" };\n+    for (String key : keys) {\n+      if (tmpEnv.containsKey(key)) {\n+        environment.put(key, tmpEnv.get(key));\n+      }\n+    }\n \n     // Add stdout/stderr env\n     environment.put(\n         MRJobConfig.STDOUT_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDOUT)\n         );\n     environment.put(\n         MRJobConfig.STDERR_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDERR)\n         );\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void setVMEnv(Map\u003cString, String\u003e environment,\n      Task task) {\n\n    JobConf conf \u003d task.conf;\n    // Add the env variables passed by the user\n    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n    MRApps.setEnvFromInputString(environment, mapredChildEnv, conf);\n\n    // Set logging level in the environment.\n    // This is so that, if the child forks another \"bin/hadoop\" (common in\n    // streaming) it will have the correct loglevel.\n    environment.put(\n        \"HADOOP_ROOT_LOGGER\", \n        getChildLogLevel(conf, task.isMapTask()) + \",console\");\n\n    // TODO: The following is useful for instance in streaming tasks. Should be\n    // set in ApplicationMaster\u0027s env by the RM.\n    String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n    if (hadoopClientOpts \u003d\u003d null) {\n      hadoopClientOpts \u003d \"\";\n    } else {\n      hadoopClientOpts \u003d hadoopClientOpts + \" \";\n    }\n    environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n    \n    // setEnvFromInputString above will add env variable values from\n    // mapredChildEnv to existing variables. We want to overwrite\n    // HADOOP_ROOT_LOGGER and HADOOP_CLIENT_OPTS if the user set it explicitly.\n    Map\u003cString, String\u003e tmpEnv \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setEnvFromInputString(tmpEnv, mapredChildEnv, conf);\n    String[] keys \u003d { \"HADOOP_ROOT_LOGGER\", \"HADOOP_CLIENT_OPTS\" };\n    for (String key : keys) {\n      if (tmpEnv.containsKey(key)) {\n        environment.put(key, tmpEnv.get(key));\n      }\n    }\n\n    // Add stdout/stderr env\n    environment.put(\n        MRJobConfig.STDOUT_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDOUT)\n        );\n    environment.put(\n        MRJobConfig.STDERR_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDERR)\n        );\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java",
      "extendedDetails": {}
    },
    "96e0ca2d272dc7ecd7f7f0e65a0c596fcc063bcb": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1824. Improved NodeManager and clients to be able to handle cross platform application submissions. Contributed by Jian He.\nMAPREDUCE-4052. Improved MapReduce clients to use NodeManagers\u0027 ability to handle cross platform application submissions. Contributed by Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1578135 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/03/14 11:32 AM",
      "commitName": "96e0ca2d272dc7ecd7f7f0e65a0c596fcc063bcb",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/01/14 9:43 AM",
      "commitNameOld": "f667371746de02c52434af6e48f3e2a4f83917ac",
      "commitAuthorOld": "Sanford Ryza",
      "daysBetweenCommits": 58.03,
      "commitsBetweenForRepo": 506,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,46 @@\n   public static void setVMEnv(Map\u003cString, String\u003e environment,\n       Task task) {\n \n     JobConf conf \u003d task.conf;\n-\n     // Add the env variables passed by the user\n     String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n-    Apps.setEnvFromInputString(environment, mapredChildEnv);\n+    MRApps.setEnvFromInputString(environment, mapredChildEnv, conf);\n \n     // Set logging level in the environment.\n     // This is so that, if the child forks another \"bin/hadoop\" (common in\n     // streaming) it will have the correct loglevel.\n     environment.put(\n         \"HADOOP_ROOT_LOGGER\", \n         getChildLogLevel(conf, task.isMapTask()) + \",CLA\"); \n \n     // TODO: The following is useful for instance in streaming tasks. Should be\n     // set in ApplicationMaster\u0027s env by the RM.\n     String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n     if (hadoopClientOpts \u003d\u003d null) {\n       hadoopClientOpts \u003d \"\";\n     } else {\n       hadoopClientOpts \u003d hadoopClientOpts + \" \";\n     }\n     // FIXME: don\u0027t think this is also needed given we already set java\n     // properties.\n     long logSize \u003d TaskLog.getTaskLogLength(conf);\n     Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n     setupLog4jProperties(task, logProps, logSize);\n     Iterator\u003cString\u003e it \u003d logProps.iterator();\n     StringBuffer buffer \u003d new StringBuffer();\n     while (it.hasNext()) {\n       buffer.append(\" \" + it.next());\n     }\n     hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n     environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n \n     // Add stdout/stderr env\n     environment.put(\n         MRJobConfig.STDOUT_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDOUT)\n         );\n     environment.put(\n         MRJobConfig.STDERR_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDERR)\n         );\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void setVMEnv(Map\u003cString, String\u003e environment,\n      Task task) {\n\n    JobConf conf \u003d task.conf;\n    // Add the env variables passed by the user\n    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n    MRApps.setEnvFromInputString(environment, mapredChildEnv, conf);\n\n    // Set logging level in the environment.\n    // This is so that, if the child forks another \"bin/hadoop\" (common in\n    // streaming) it will have the correct loglevel.\n    environment.put(\n        \"HADOOP_ROOT_LOGGER\", \n        getChildLogLevel(conf, task.isMapTask()) + \",CLA\"); \n\n    // TODO: The following is useful for instance in streaming tasks. Should be\n    // set in ApplicationMaster\u0027s env by the RM.\n    String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n    if (hadoopClientOpts \u003d\u003d null) {\n      hadoopClientOpts \u003d \"\";\n    } else {\n      hadoopClientOpts \u003d hadoopClientOpts + \" \";\n    }\n    // FIXME: don\u0027t think this is also needed given we already set java\n    // properties.\n    long logSize \u003d TaskLog.getTaskLogLength(conf);\n    Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n    setupLog4jProperties(task, logProps, logSize);\n    Iterator\u003cString\u003e it \u003d logProps.iterator();\n    StringBuffer buffer \u003d new StringBuffer();\n    while (it.hasNext()) {\n      buffer.append(\" \" + it.next());\n    }\n    hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n    environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n\n    // Add stdout/stderr env\n    environment.put(\n        MRJobConfig.STDOUT_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDOUT)\n        );\n    environment.put(\n        MRJobConfig.STDERR_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDERR)\n        );\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java",
      "extendedDetails": {}
    },
    "27e8c86999bc6a972a99216060b11ef35b7de858": {
      "type": "Ybodychange",
      "commitMessage": "YARN-561. Modified NodeManager to set key information into the environment of every container that it launches. Contributed by Xuan Gong.\nMAPREDUCE-5175. Updated MR App to not set envs that will be set by NMs anyways after YARN-561. Contributed by Xuan Gong.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1471156 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/04/13 2:39 PM",
      "commitName": "27e8c86999bc6a972a99216060b11ef35b7de858",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "06/03/13 11:15 AM",
      "commitNameOld": "638801cce16fc1dc3259c541dc30a599faaddda1",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 48.1,
      "commitsBetweenForRepo": 266,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,47 @@\n   public static void setVMEnv(Map\u003cString, String\u003e environment,\n       Task task) {\n \n     JobConf conf \u003d task.conf;\n \n     // Add the env variables passed by the user\n     String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n     Apps.setEnvFromInputString(environment, mapredChildEnv);\n \n     // Set logging level in the environment.\n     // This is so that, if the child forks another \"bin/hadoop\" (common in\n     // streaming) it will have the correct loglevel.\n     environment.put(\n         \"HADOOP_ROOT_LOGGER\", \n         getChildLogLevel(conf, task.isMapTask()) + \",CLA\"); \n \n     // TODO: The following is useful for instance in streaming tasks. Should be\n     // set in ApplicationMaster\u0027s env by the RM.\n     String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n     if (hadoopClientOpts \u003d\u003d null) {\n       hadoopClientOpts \u003d \"\";\n     } else {\n       hadoopClientOpts \u003d hadoopClientOpts + \" \";\n     }\n     // FIXME: don\u0027t think this is also needed given we already set java\n     // properties.\n     long logSize \u003d TaskLog.getTaskLogLength(conf);\n     Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n     setupLog4jProperties(task, logProps, logSize);\n     Iterator\u003cString\u003e it \u003d logProps.iterator();\n     StringBuffer buffer \u003d new StringBuffer();\n     while (it.hasNext()) {\n       buffer.append(\" \" + it.next());\n     }\n     hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n     environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n \n     // Add stdout/stderr env\n     environment.put(\n         MRJobConfig.STDOUT_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDOUT)\n         );\n     environment.put(\n         MRJobConfig.STDERR_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDERR)\n         );\n-    environment.put(MRJobConfig.APPLICATION_ATTEMPT_ID_ENV, \n-        \tconf.get(MRJobConfig.APPLICATION_ATTEMPT_ID).toString());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void setVMEnv(Map\u003cString, String\u003e environment,\n      Task task) {\n\n    JobConf conf \u003d task.conf;\n\n    // Add the env variables passed by the user\n    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n    Apps.setEnvFromInputString(environment, mapredChildEnv);\n\n    // Set logging level in the environment.\n    // This is so that, if the child forks another \"bin/hadoop\" (common in\n    // streaming) it will have the correct loglevel.\n    environment.put(\n        \"HADOOP_ROOT_LOGGER\", \n        getChildLogLevel(conf, task.isMapTask()) + \",CLA\"); \n\n    // TODO: The following is useful for instance in streaming tasks. Should be\n    // set in ApplicationMaster\u0027s env by the RM.\n    String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n    if (hadoopClientOpts \u003d\u003d null) {\n      hadoopClientOpts \u003d \"\";\n    } else {\n      hadoopClientOpts \u003d hadoopClientOpts + \" \";\n    }\n    // FIXME: don\u0027t think this is also needed given we already set java\n    // properties.\n    long logSize \u003d TaskLog.getTaskLogLength(conf);\n    Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n    setupLog4jProperties(task, logProps, logSize);\n    Iterator\u003cString\u003e it \u003d logProps.iterator();\n    StringBuffer buffer \u003d new StringBuffer();\n    while (it.hasNext()) {\n      buffer.append(\" \" + it.next());\n    }\n    hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n    environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n\n    // Add stdout/stderr env\n    environment.put(\n        MRJobConfig.STDOUT_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDOUT)\n        );\n    environment.put(\n        MRJobConfig.STDERR_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDERR)\n        );\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java",
      "extendedDetails": {}
    },
    "0870734787d7005d85697549eab5b6479d97d453": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3566. Fixed MR AM to construct CLC only once across all tasks. Contributed by Vinod K V.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1227422 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/01/12 5:29 PM",
      "commitName": "0870734787d7005d85697549eab5b6479d97d453",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "13/12/11 3:35 PM",
      "commitNameOld": "b7ae5a6cb7b2d3e3112ac53007e984caeb07de58",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 22.08,
      "commitsBetweenForRepo": 84,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,49 @@\n   public static void setVMEnv(Map\u003cString, String\u003e environment,\n       Task task) {\n \n     JobConf conf \u003d task.conf;\n \n-    // Shell\n-    environment.put(\n-        Environment.SHELL.name(), \n-        conf.get(\n-            MRJobConfig.MAPRED_ADMIN_USER_SHELL, \n-            MRJobConfig.DEFAULT_SHELL)\n-            );\n-    \n-    // Add pwd to LD_LIBRARY_PATH, add this before adding anything else\n-    Apps.addToEnvironment(\n-        environment, \n-        Environment.LD_LIBRARY_PATH.name(), \n-        Environment.PWD.$());\n-\n-    // Add the env variables passed by the user \u0026 admin\n+    // Add the env variables passed by the user\n     String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n     Apps.setEnvFromInputString(environment, mapredChildEnv);\n-    Apps.setEnvFromInputString(\n-        environment, \n-        conf.get(\n-            MRJobConfig.MAPRED_ADMIN_USER_ENV, \n-            MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV)\n-        );\n \n     // Set logging level in the environment.\n     // This is so that, if the child forks another \"bin/hadoop\" (common in\n     // streaming) it will have the correct loglevel.\n     environment.put(\n         \"HADOOP_ROOT_LOGGER\", \n         getChildLogLevel(conf, task.isMapTask()) + \",CLA\"); \n \n     // TODO: The following is useful for instance in streaming tasks. Should be\n     // set in ApplicationMaster\u0027s env by the RM.\n     String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n     if (hadoopClientOpts \u003d\u003d null) {\n       hadoopClientOpts \u003d \"\";\n     } else {\n       hadoopClientOpts \u003d hadoopClientOpts + \" \";\n     }\n     // FIXME: don\u0027t think this is also needed given we already set java\n     // properties.\n     long logSize \u003d TaskLog.getTaskLogLength(conf);\n     Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n     setupLog4jProperties(task, logProps, logSize);\n     Iterator\u003cString\u003e it \u003d logProps.iterator();\n     StringBuffer buffer \u003d new StringBuffer();\n     while (it.hasNext()) {\n       buffer.append(\" \" + it.next());\n     }\n     hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n     environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n \n     // Add stdout/stderr env\n     environment.put(\n         MRJobConfig.STDOUT_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDOUT)\n         );\n     environment.put(\n         MRJobConfig.STDERR_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDERR)\n         );\n     environment.put(MRJobConfig.APPLICATION_ATTEMPT_ID_ENV, \n         \tconf.get(MRJobConfig.APPLICATION_ATTEMPT_ID).toString());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void setVMEnv(Map\u003cString, String\u003e environment,\n      Task task) {\n\n    JobConf conf \u003d task.conf;\n\n    // Add the env variables passed by the user\n    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n    Apps.setEnvFromInputString(environment, mapredChildEnv);\n\n    // Set logging level in the environment.\n    // This is so that, if the child forks another \"bin/hadoop\" (common in\n    // streaming) it will have the correct loglevel.\n    environment.put(\n        \"HADOOP_ROOT_LOGGER\", \n        getChildLogLevel(conf, task.isMapTask()) + \",CLA\"); \n\n    // TODO: The following is useful for instance in streaming tasks. Should be\n    // set in ApplicationMaster\u0027s env by the RM.\n    String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n    if (hadoopClientOpts \u003d\u003d null) {\n      hadoopClientOpts \u003d \"\";\n    } else {\n      hadoopClientOpts \u003d hadoopClientOpts + \" \";\n    }\n    // FIXME: don\u0027t think this is also needed given we already set java\n    // properties.\n    long logSize \u003d TaskLog.getTaskLogLength(conf);\n    Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n    setupLog4jProperties(task, logProps, logSize);\n    Iterator\u003cString\u003e it \u003d logProps.iterator();\n    StringBuffer buffer \u003d new StringBuffer();\n    while (it.hasNext()) {\n      buffer.append(\" \" + it.next());\n    }\n    hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n    environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n\n    // Add stdout/stderr env\n    environment.put(\n        MRJobConfig.STDOUT_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDOUT)\n        );\n    environment.put(\n        MRJobConfig.STDERR_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDERR)\n        );\n    environment.put(MRJobConfig.APPLICATION_ATTEMPT_ID_ENV, \n        \tconf.get(MRJobConfig.APPLICATION_ATTEMPT_ID).toString());\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java",
      "extendedDetails": {}
    },
    "408656614495674992349fbda3981559ada3de0b": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2708. Designed and implemented MR Application Master recovery to make MR AMs resume their progress after restart. Contributed by Sharad Agarwal.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1188043 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/10/11 1:41 AM",
      "commitName": "408656614495674992349fbda3981559ada3de0b",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "18/10/11 2:45 PM",
      "commitNameOld": "ab787f44aabfff0cd01b79a08a52ffaf923558b3",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 5.46,
      "commitsBetweenForRepo": 42,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,69 @@\n   public static void setVMEnv(Map\u003cString, String\u003e environment,\n       Task task) {\n \n     JobConf conf \u003d task.conf;\n \n     // Shell\n     environment.put(\n         Environment.SHELL.name(), \n         conf.get(\n             MRJobConfig.MAPRED_ADMIN_USER_SHELL, \n             MRJobConfig.DEFAULT_SHELL)\n             );\n     \n     // Add pwd to LD_LIBRARY_PATH, add this before adding anything else\n     Apps.addToEnvironment(\n         environment, \n         Environment.LD_LIBRARY_PATH.name(), \n         Environment.PWD.$());\n \n     // Add the env variables passed by the user \u0026 admin\n     String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n     Apps.setEnvFromInputString(environment, mapredChildEnv);\n     Apps.setEnvFromInputString(\n         environment, \n         conf.get(\n             MRJobConfig.MAPRED_ADMIN_USER_ENV, \n             MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV)\n         );\n \n     // Set logging level in the environment.\n     // This is so that, if the child forks another \"bin/hadoop\" (common in\n     // streaming) it will have the correct loglevel.\n     environment.put(\n         \"HADOOP_ROOT_LOGGER\", \n         getChildLogLevel(conf, task.isMapTask()) + \",CLA\"); \n \n     // TODO: The following is useful for instance in streaming tasks. Should be\n     // set in ApplicationMaster\u0027s env by the RM.\n     String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n     if (hadoopClientOpts \u003d\u003d null) {\n       hadoopClientOpts \u003d \"\";\n     } else {\n       hadoopClientOpts \u003d hadoopClientOpts + \" \";\n     }\n     // FIXME: don\u0027t think this is also needed given we already set java\n     // properties.\n     long logSize \u003d TaskLog.getTaskLogLength(conf);\n     Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n     setupLog4jProperties(task, logProps, logSize);\n     Iterator\u003cString\u003e it \u003d logProps.iterator();\n     StringBuffer buffer \u003d new StringBuffer();\n     while (it.hasNext()) {\n       buffer.append(\" \" + it.next());\n     }\n     hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n     environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n \n     // Add stdout/stderr env\n     environment.put(\n         MRJobConfig.STDOUT_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDOUT)\n         );\n     environment.put(\n         MRJobConfig.STDERR_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDERR)\n         );\n+    environment.put(MRJobConfig.APPLICATION_ATTEMPT_ID_ENV, \n+        \tconf.get(MRJobConfig.APPLICATION_ATTEMPT_ID).toString());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void setVMEnv(Map\u003cString, String\u003e environment,\n      Task task) {\n\n    JobConf conf \u003d task.conf;\n\n    // Shell\n    environment.put(\n        Environment.SHELL.name(), \n        conf.get(\n            MRJobConfig.MAPRED_ADMIN_USER_SHELL, \n            MRJobConfig.DEFAULT_SHELL)\n            );\n    \n    // Add pwd to LD_LIBRARY_PATH, add this before adding anything else\n    Apps.addToEnvironment(\n        environment, \n        Environment.LD_LIBRARY_PATH.name(), \n        Environment.PWD.$());\n\n    // Add the env variables passed by the user \u0026 admin\n    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n    Apps.setEnvFromInputString(environment, mapredChildEnv);\n    Apps.setEnvFromInputString(\n        environment, \n        conf.get(\n            MRJobConfig.MAPRED_ADMIN_USER_ENV, \n            MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV)\n        );\n\n    // Set logging level in the environment.\n    // This is so that, if the child forks another \"bin/hadoop\" (common in\n    // streaming) it will have the correct loglevel.\n    environment.put(\n        \"HADOOP_ROOT_LOGGER\", \n        getChildLogLevel(conf, task.isMapTask()) + \",CLA\"); \n\n    // TODO: The following is useful for instance in streaming tasks. Should be\n    // set in ApplicationMaster\u0027s env by the RM.\n    String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n    if (hadoopClientOpts \u003d\u003d null) {\n      hadoopClientOpts \u003d \"\";\n    } else {\n      hadoopClientOpts \u003d hadoopClientOpts + \" \";\n    }\n    // FIXME: don\u0027t think this is also needed given we already set java\n    // properties.\n    long logSize \u003d TaskLog.getTaskLogLength(conf);\n    Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n    setupLog4jProperties(task, logProps, logSize);\n    Iterator\u003cString\u003e it \u003d logProps.iterator();\n    StringBuffer buffer \u003d new StringBuffer();\n    while (it.hasNext()) {\n      buffer.append(\" \" + it.next());\n    }\n    hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n    environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n\n    // Add stdout/stderr env\n    environment.put(\n        MRJobConfig.STDOUT_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDOUT)\n        );\n    environment.put(\n        MRJobConfig.STDERR_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDERR)\n        );\n    environment.put(MRJobConfig.APPLICATION_ATTEMPT_ID_ENV, \n        \tconf.get(MRJobConfig.APPLICATION_ATTEMPT_ID).toString());\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java",
      "extendedDetails": {}
    },
    "ab787f44aabfff0cd01b79a08a52ffaf923558b3": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3165. Ensure logging options are set correctly for MR AM and tasks. Contributed by Todd Lipcon. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1185887 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/10/11 2:45 PM",
      "commitName": "ab787f44aabfff0cd01b79a08a52ffaf923558b3",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "17/10/11 6:22 PM",
      "commitNameOld": "c1d90772b6e38bb4e4be7ed75cb5d34f3048ad7b",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.85,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,67 @@\n   public static void setVMEnv(Map\u003cString, String\u003e environment,\n       Task task) {\n \n     JobConf conf \u003d task.conf;\n \n     // Shell\n     environment.put(\n         Environment.SHELL.name(), \n         conf.get(\n             MRJobConfig.MAPRED_ADMIN_USER_SHELL, \n             MRJobConfig.DEFAULT_SHELL)\n             );\n     \n     // Add pwd to LD_LIBRARY_PATH, add this before adding anything else\n     Apps.addToEnvironment(\n         environment, \n         Environment.LD_LIBRARY_PATH.name(), \n         Environment.PWD.$());\n \n     // Add the env variables passed by the user \u0026 admin\n     String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n     Apps.setEnvFromInputString(environment, mapredChildEnv);\n     Apps.setEnvFromInputString(\n         environment, \n         conf.get(\n             MRJobConfig.MAPRED_ADMIN_USER_ENV, \n             MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV)\n         );\n \n-    // Set logging level\n+    // Set logging level in the environment.\n+    // This is so that, if the child forks another \"bin/hadoop\" (common in\n+    // streaming) it will have the correct loglevel.\n     environment.put(\n         \"HADOOP_ROOT_LOGGER\", \n         getChildLogLevel(conf, task.isMapTask()) + \",CLA\"); \n \n     // TODO: The following is useful for instance in streaming tasks. Should be\n     // set in ApplicationMaster\u0027s env by the RM.\n     String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n     if (hadoopClientOpts \u003d\u003d null) {\n       hadoopClientOpts \u003d \"\";\n     } else {\n       hadoopClientOpts \u003d hadoopClientOpts + \" \";\n     }\n     // FIXME: don\u0027t think this is also needed given we already set java\n     // properties.\n     long logSize \u003d TaskLog.getTaskLogLength(conf);\n     Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n-    setupLog4jProperties(logProps, logSize);\n+    setupLog4jProperties(task, logProps, logSize);\n     Iterator\u003cString\u003e it \u003d logProps.iterator();\n     StringBuffer buffer \u003d new StringBuffer();\n     while (it.hasNext()) {\n       buffer.append(\" \" + it.next());\n     }\n     hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n     environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n \n     // Add stdout/stderr env\n     environment.put(\n         MRJobConfig.STDOUT_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDOUT)\n         );\n     environment.put(\n         MRJobConfig.STDERR_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDERR)\n         );\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void setVMEnv(Map\u003cString, String\u003e environment,\n      Task task) {\n\n    JobConf conf \u003d task.conf;\n\n    // Shell\n    environment.put(\n        Environment.SHELL.name(), \n        conf.get(\n            MRJobConfig.MAPRED_ADMIN_USER_SHELL, \n            MRJobConfig.DEFAULT_SHELL)\n            );\n    \n    // Add pwd to LD_LIBRARY_PATH, add this before adding anything else\n    Apps.addToEnvironment(\n        environment, \n        Environment.LD_LIBRARY_PATH.name(), \n        Environment.PWD.$());\n\n    // Add the env variables passed by the user \u0026 admin\n    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n    Apps.setEnvFromInputString(environment, mapredChildEnv);\n    Apps.setEnvFromInputString(\n        environment, \n        conf.get(\n            MRJobConfig.MAPRED_ADMIN_USER_ENV, \n            MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV)\n        );\n\n    // Set logging level in the environment.\n    // This is so that, if the child forks another \"bin/hadoop\" (common in\n    // streaming) it will have the correct loglevel.\n    environment.put(\n        \"HADOOP_ROOT_LOGGER\", \n        getChildLogLevel(conf, task.isMapTask()) + \",CLA\"); \n\n    // TODO: The following is useful for instance in streaming tasks. Should be\n    // set in ApplicationMaster\u0027s env by the RM.\n    String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n    if (hadoopClientOpts \u003d\u003d null) {\n      hadoopClientOpts \u003d \"\";\n    } else {\n      hadoopClientOpts \u003d hadoopClientOpts + \" \";\n    }\n    // FIXME: don\u0027t think this is also needed given we already set java\n    // properties.\n    long logSize \u003d TaskLog.getTaskLogLength(conf);\n    Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n    setupLog4jProperties(task, logProps, logSize);\n    Iterator\u003cString\u003e it \u003d logProps.iterator();\n    StringBuffer buffer \u003d new StringBuffer();\n    while (it.hasNext()) {\n      buffer.append(\" \" + it.next());\n    }\n    hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n    environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n\n    // Add stdout/stderr env\n    environment.put(\n        MRJobConfig.STDOUT_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDOUT)\n        );\n    environment.put(\n        MRJobConfig.STDERR_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDERR)\n        );\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java",
      "extendedDetails": {}
    },
    "c1d90772b6e38bb4e4be7ed75cb5d34f3048ad7b": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3068. Added a whitelist of environment variables for containers from the NodeManager and set MALLOC_ARENA_MAX for all daemons and containers. Contributed by Chris Riccomini. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1185447 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/10/11 6:22 PM",
      "commitName": "c1d90772b6e38bb4e4be7ed75cb5d34f3048ad7b",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "22/09/11 8:14 AM",
      "commitNameOld": "4806d7ba74c668817ea6f35421c559eaf57a997e",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 25.42,
      "commitsBetweenForRepo": 189,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,65 @@\n   public static void setVMEnv(Map\u003cString, String\u003e environment,\n       Task task) {\n \n     JobConf conf \u003d task.conf;\n \n     // Shell\n     environment.put(\n         Environment.SHELL.name(), \n         conf.get(\n             MRJobConfig.MAPRED_ADMIN_USER_SHELL, \n             MRJobConfig.DEFAULT_SHELL)\n             );\n     \n     // Add pwd to LD_LIBRARY_PATH, add this before adding anything else\n-    MRApps.addToEnvironment(\n+    Apps.addToEnvironment(\n         environment, \n         Environment.LD_LIBRARY_PATH.name(), \n         Environment.PWD.$());\n \n     // Add the env variables passed by the user \u0026 admin\n     String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n-    MRApps.setEnvFromInputString(environment, mapredChildEnv);\n-    MRApps.setEnvFromInputString(\n+    Apps.setEnvFromInputString(environment, mapredChildEnv);\n+    Apps.setEnvFromInputString(\n         environment, \n         conf.get(\n             MRJobConfig.MAPRED_ADMIN_USER_ENV, \n             MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV)\n         );\n \n     // Set logging level\n     environment.put(\n         \"HADOOP_ROOT_LOGGER\", \n         getChildLogLevel(conf, task.isMapTask()) + \",CLA\"); \n \n     // TODO: The following is useful for instance in streaming tasks. Should be\n     // set in ApplicationMaster\u0027s env by the RM.\n     String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n     if (hadoopClientOpts \u003d\u003d null) {\n       hadoopClientOpts \u003d \"\";\n     } else {\n       hadoopClientOpts \u003d hadoopClientOpts + \" \";\n     }\n     // FIXME: don\u0027t think this is also needed given we already set java\n     // properties.\n     long logSize \u003d TaskLog.getTaskLogLength(conf);\n     Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n     setupLog4jProperties(logProps, logSize);\n     Iterator\u003cString\u003e it \u003d logProps.iterator();\n     StringBuffer buffer \u003d new StringBuffer();\n     while (it.hasNext()) {\n       buffer.append(\" \" + it.next());\n     }\n     hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n     environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n \n     // Add stdout/stderr env\n     environment.put(\n         MRJobConfig.STDOUT_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDOUT)\n         );\n     environment.put(\n         MRJobConfig.STDERR_LOGFILE_ENV,\n         getTaskLogFile(TaskLog.LogName.STDERR)\n         );\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void setVMEnv(Map\u003cString, String\u003e environment,\n      Task task) {\n\n    JobConf conf \u003d task.conf;\n\n    // Shell\n    environment.put(\n        Environment.SHELL.name(), \n        conf.get(\n            MRJobConfig.MAPRED_ADMIN_USER_SHELL, \n            MRJobConfig.DEFAULT_SHELL)\n            );\n    \n    // Add pwd to LD_LIBRARY_PATH, add this before adding anything else\n    Apps.addToEnvironment(\n        environment, \n        Environment.LD_LIBRARY_PATH.name(), \n        Environment.PWD.$());\n\n    // Add the env variables passed by the user \u0026 admin\n    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n    Apps.setEnvFromInputString(environment, mapredChildEnv);\n    Apps.setEnvFromInputString(\n        environment, \n        conf.get(\n            MRJobConfig.MAPRED_ADMIN_USER_ENV, \n            MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV)\n        );\n\n    // Set logging level\n    environment.put(\n        \"HADOOP_ROOT_LOGGER\", \n        getChildLogLevel(conf, task.isMapTask()) + \",CLA\"); \n\n    // TODO: The following is useful for instance in streaming tasks. Should be\n    // set in ApplicationMaster\u0027s env by the RM.\n    String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n    if (hadoopClientOpts \u003d\u003d null) {\n      hadoopClientOpts \u003d \"\";\n    } else {\n      hadoopClientOpts \u003d hadoopClientOpts + \" \";\n    }\n    // FIXME: don\u0027t think this is also needed given we already set java\n    // properties.\n    long logSize \u003d TaskLog.getTaskLogLength(conf);\n    Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n    setupLog4jProperties(logProps, logSize);\n    Iterator\u003cString\u003e it \u003d logProps.iterator();\n    StringBuffer buffer \u003d new StringBuffer();\n    while (it.hasNext()) {\n      buffer.append(\" \" + it.next());\n    }\n    hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n    environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n\n    // Add stdout/stderr env\n    environment.put(\n        MRJobConfig.STDOUT_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDOUT)\n        );\n    environment.put(\n        MRJobConfig.STDERR_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDERR)\n        );\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java",
      "extendedDetails": {}
    },
    "d00b3c49f6fb3f6a617add6203c6b55f6c345940": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "MAPREDUCE-2880. Improved classpath-construction for mapreduce AM and containers. Contributed by Arun C Murthy.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1173783 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/09/11 11:28 AM",
      "commitName": "d00b3c49f6fb3f6a617add6203c6b55f6c345940",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-2880. Improved classpath-construction for mapreduce AM and containers. Contributed by Arun C Murthy.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1173783 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/09/11 11:28 AM",
          "commitName": "d00b3c49f6fb3f6a617add6203c6b55f6c345940",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "24/08/11 5:14 PM",
          "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
          "commitAuthorOld": "Arun Murthy",
          "daysBetweenCommits": 27.76,
          "commitsBetweenForRepo": 171,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,86 +1,65 @@\n-  public static void setVMEnv(Map\u003cString, String\u003e env,\n-      List\u003cString\u003e classPaths, String pwd, String containerLogDir,\n-      String nmLdLibraryPath, Task task, CharSequence applicationTokensFile) {\n+  public static void setVMEnv(Map\u003cString, String\u003e environment,\n+      Task task) {\n \n     JobConf conf \u003d task.conf;\n \n-    // Add classpath.\n-    CharSequence cp \u003d env.get(\"CLASSPATH\");\n-    String classpath \u003d StringUtils.join(SYSTEM_PATH_SEPARATOR, classPaths);\n-    if (null \u003d\u003d cp) {\n-      env.put(\"CLASSPATH\", classpath);\n-    } else {\n-      env.put(\"CLASSPATH\", classpath + SYSTEM_PATH_SEPARATOR + cp);\n-    }\n+    // Shell\n+    environment.put(\n+        Environment.SHELL.name(), \n+        conf.get(\n+            MRJobConfig.MAPRED_ADMIN_USER_SHELL, \n+            MRJobConfig.DEFAULT_SHELL)\n+            );\n+    \n+    // Add pwd to LD_LIBRARY_PATH, add this before adding anything else\n+    MRApps.addToEnvironment(\n+        environment, \n+        Environment.LD_LIBRARY_PATH.name(), \n+        Environment.PWD.$());\n \n-    /////// Environmental variable LD_LIBRARY_PATH\n-    StringBuilder ldLibraryPath \u003d new StringBuilder();\n+    // Add the env variables passed by the user \u0026 admin\n+    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n+    MRApps.setEnvFromInputString(environment, mapredChildEnv);\n+    MRApps.setEnvFromInputString(\n+        environment, \n+        conf.get(\n+            MRJobConfig.MAPRED_ADMIN_USER_ENV, \n+            MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV)\n+        );\n \n-    ldLibraryPath.append(nmLdLibraryPath);\n-    ldLibraryPath.append(SYSTEM_PATH_SEPARATOR);\n-    ldLibraryPath.append(pwd);\n-    env.put(\"LD_LIBRARY_PATH\", ldLibraryPath.toString());\n-    /////// Environmental variable LD_LIBRARY_PATH\n-\n-    // for the child of task jvm, set hadoop.root.logger\n-    env.put(\"HADOOP_ROOT_LOGGER\", \"DEBUG,CLA\"); // TODO: Debug\n+    // Set logging level\n+    environment.put(\n+        \"HADOOP_ROOT_LOGGER\", \n+        getChildLogLevel(conf, task.isMapTask()) + \",CLA\"); \n \n     // TODO: The following is useful for instance in streaming tasks. Should be\n     // set in ApplicationMaster\u0027s env by the RM.\n     String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n     if (hadoopClientOpts \u003d\u003d null) {\n       hadoopClientOpts \u003d \"\";\n     } else {\n       hadoopClientOpts \u003d hadoopClientOpts + \" \";\n     }\n     // FIXME: don\u0027t think this is also needed given we already set java\n     // properties.\n     long logSize \u003d TaskLog.getTaskLogLength(conf);\n     Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n-    setupLog4jProperties(logProps, logSize, containerLogDir);\n+    setupLog4jProperties(logProps, logSize);\n     Iterator\u003cString\u003e it \u003d logProps.iterator();\n     StringBuffer buffer \u003d new StringBuffer();\n     while (it.hasNext()) {\n       buffer.append(\" \" + it.next());\n     }\n     hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n-    \n-    env.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n+    environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n \n-    // add the env variables passed by the user\n-    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n-    if (mapredChildEnv !\u003d null \u0026\u0026 mapredChildEnv.length() \u003e 0) {\n-      String childEnvs[] \u003d mapredChildEnv.split(\",\");\n-      for (String cEnv : childEnvs) {\n-        String[] parts \u003d cEnv.split(\"\u003d\"); // split on \u0027\u003d\u0027\n-        String value \u003d (String) env.get(parts[0]);\n-        if (value !\u003d null) {\n-          // replace $env with the child\u0027s env constructed by tt\u0027s\n-          // example LD_LIBRARY_PATH\u003d$LD_LIBRARY_PATH:/tmp\n-          value \u003d parts[1].replace(\"$\" + parts[0], value);\n-        } else {\n-          // this key is not configured by the tt for the child .. get it \n-          // from the tt\u0027s env\n-          // example PATH\u003d$PATH:/tmp\n-          value \u003d System.getenv(parts[0]); // Get from NM?\n-          if (value !\u003d null) {\n-            // the env key is present in the tt\u0027s env\n-            value \u003d parts[1].replace(\"$\" + parts[0], value);\n-          } else {\n-            // the env key is note present anywhere .. simply set it\n-            // example X\u003d$X:/tmp or X\u003d/tmp\n-            value \u003d parts[1].replace(\"$\" + parts[0], \"\");\n-          }\n-        }\n-        env.put(parts[0], value);\n-      }\n-    }\n-\n-    //This should not be set here (If an OS check is requied. moved to ContainerLuanch)\n-    // env.put(\"JVM_PID\", \"`echo $$`\");\n-\n-    env.put(Constants.STDOUT_LOGFILE_ENV,\n-        getTaskLogFile(containerLogDir, TaskLog.LogName.STDOUT).toString());\n-    env.put(Constants.STDERR_LOGFILE_ENV,\n-        getTaskLogFile(containerLogDir, TaskLog.LogName.STDERR).toString());\n+    // Add stdout/stderr env\n+    environment.put(\n+        MRJobConfig.STDOUT_LOGFILE_ENV,\n+        getTaskLogFile(TaskLog.LogName.STDOUT)\n+        );\n+    environment.put(\n+        MRJobConfig.STDERR_LOGFILE_ENV,\n+        getTaskLogFile(TaskLog.LogName.STDERR)\n+        );\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static void setVMEnv(Map\u003cString, String\u003e environment,\n      Task task) {\n\n    JobConf conf \u003d task.conf;\n\n    // Shell\n    environment.put(\n        Environment.SHELL.name(), \n        conf.get(\n            MRJobConfig.MAPRED_ADMIN_USER_SHELL, \n            MRJobConfig.DEFAULT_SHELL)\n            );\n    \n    // Add pwd to LD_LIBRARY_PATH, add this before adding anything else\n    MRApps.addToEnvironment(\n        environment, \n        Environment.LD_LIBRARY_PATH.name(), \n        Environment.PWD.$());\n\n    // Add the env variables passed by the user \u0026 admin\n    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n    MRApps.setEnvFromInputString(environment, mapredChildEnv);\n    MRApps.setEnvFromInputString(\n        environment, \n        conf.get(\n            MRJobConfig.MAPRED_ADMIN_USER_ENV, \n            MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV)\n        );\n\n    // Set logging level\n    environment.put(\n        \"HADOOP_ROOT_LOGGER\", \n        getChildLogLevel(conf, task.isMapTask()) + \",CLA\"); \n\n    // TODO: The following is useful for instance in streaming tasks. Should be\n    // set in ApplicationMaster\u0027s env by the RM.\n    String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n    if (hadoopClientOpts \u003d\u003d null) {\n      hadoopClientOpts \u003d \"\";\n    } else {\n      hadoopClientOpts \u003d hadoopClientOpts + \" \";\n    }\n    // FIXME: don\u0027t think this is also needed given we already set java\n    // properties.\n    long logSize \u003d TaskLog.getTaskLogLength(conf);\n    Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n    setupLog4jProperties(logProps, logSize);\n    Iterator\u003cString\u003e it \u003d logProps.iterator();\n    StringBuffer buffer \u003d new StringBuffer();\n    while (it.hasNext()) {\n      buffer.append(\" \" + it.next());\n    }\n    hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n    environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n\n    // Add stdout/stderr env\n    environment.put(\n        MRJobConfig.STDOUT_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDOUT)\n        );\n    environment.put(\n        MRJobConfig.STDERR_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDERR)\n        );\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java",
          "extendedDetails": {
            "oldValue": "[env-Map\u003cString,String\u003e, classPaths-List\u003cString\u003e, pwd-String, containerLogDir-String, nmLdLibraryPath-String, task-Task, applicationTokensFile-CharSequence]",
            "newValue": "[environment-Map\u003cString,String\u003e, task-Task]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-2880. Improved classpath-construction for mapreduce AM and containers. Contributed by Arun C Murthy.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1173783 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/09/11 11:28 AM",
          "commitName": "d00b3c49f6fb3f6a617add6203c6b55f6c345940",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "24/08/11 5:14 PM",
          "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
          "commitAuthorOld": "Arun Murthy",
          "daysBetweenCommits": 27.76,
          "commitsBetweenForRepo": 171,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,86 +1,65 @@\n-  public static void setVMEnv(Map\u003cString, String\u003e env,\n-      List\u003cString\u003e classPaths, String pwd, String containerLogDir,\n-      String nmLdLibraryPath, Task task, CharSequence applicationTokensFile) {\n+  public static void setVMEnv(Map\u003cString, String\u003e environment,\n+      Task task) {\n \n     JobConf conf \u003d task.conf;\n \n-    // Add classpath.\n-    CharSequence cp \u003d env.get(\"CLASSPATH\");\n-    String classpath \u003d StringUtils.join(SYSTEM_PATH_SEPARATOR, classPaths);\n-    if (null \u003d\u003d cp) {\n-      env.put(\"CLASSPATH\", classpath);\n-    } else {\n-      env.put(\"CLASSPATH\", classpath + SYSTEM_PATH_SEPARATOR + cp);\n-    }\n+    // Shell\n+    environment.put(\n+        Environment.SHELL.name(), \n+        conf.get(\n+            MRJobConfig.MAPRED_ADMIN_USER_SHELL, \n+            MRJobConfig.DEFAULT_SHELL)\n+            );\n+    \n+    // Add pwd to LD_LIBRARY_PATH, add this before adding anything else\n+    MRApps.addToEnvironment(\n+        environment, \n+        Environment.LD_LIBRARY_PATH.name(), \n+        Environment.PWD.$());\n \n-    /////// Environmental variable LD_LIBRARY_PATH\n-    StringBuilder ldLibraryPath \u003d new StringBuilder();\n+    // Add the env variables passed by the user \u0026 admin\n+    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n+    MRApps.setEnvFromInputString(environment, mapredChildEnv);\n+    MRApps.setEnvFromInputString(\n+        environment, \n+        conf.get(\n+            MRJobConfig.MAPRED_ADMIN_USER_ENV, \n+            MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV)\n+        );\n \n-    ldLibraryPath.append(nmLdLibraryPath);\n-    ldLibraryPath.append(SYSTEM_PATH_SEPARATOR);\n-    ldLibraryPath.append(pwd);\n-    env.put(\"LD_LIBRARY_PATH\", ldLibraryPath.toString());\n-    /////// Environmental variable LD_LIBRARY_PATH\n-\n-    // for the child of task jvm, set hadoop.root.logger\n-    env.put(\"HADOOP_ROOT_LOGGER\", \"DEBUG,CLA\"); // TODO: Debug\n+    // Set logging level\n+    environment.put(\n+        \"HADOOP_ROOT_LOGGER\", \n+        getChildLogLevel(conf, task.isMapTask()) + \",CLA\"); \n \n     // TODO: The following is useful for instance in streaming tasks. Should be\n     // set in ApplicationMaster\u0027s env by the RM.\n     String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n     if (hadoopClientOpts \u003d\u003d null) {\n       hadoopClientOpts \u003d \"\";\n     } else {\n       hadoopClientOpts \u003d hadoopClientOpts + \" \";\n     }\n     // FIXME: don\u0027t think this is also needed given we already set java\n     // properties.\n     long logSize \u003d TaskLog.getTaskLogLength(conf);\n     Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n-    setupLog4jProperties(logProps, logSize, containerLogDir);\n+    setupLog4jProperties(logProps, logSize);\n     Iterator\u003cString\u003e it \u003d logProps.iterator();\n     StringBuffer buffer \u003d new StringBuffer();\n     while (it.hasNext()) {\n       buffer.append(\" \" + it.next());\n     }\n     hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n-    \n-    env.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n+    environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n \n-    // add the env variables passed by the user\n-    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n-    if (mapredChildEnv !\u003d null \u0026\u0026 mapredChildEnv.length() \u003e 0) {\n-      String childEnvs[] \u003d mapredChildEnv.split(\",\");\n-      for (String cEnv : childEnvs) {\n-        String[] parts \u003d cEnv.split(\"\u003d\"); // split on \u0027\u003d\u0027\n-        String value \u003d (String) env.get(parts[0]);\n-        if (value !\u003d null) {\n-          // replace $env with the child\u0027s env constructed by tt\u0027s\n-          // example LD_LIBRARY_PATH\u003d$LD_LIBRARY_PATH:/tmp\n-          value \u003d parts[1].replace(\"$\" + parts[0], value);\n-        } else {\n-          // this key is not configured by the tt for the child .. get it \n-          // from the tt\u0027s env\n-          // example PATH\u003d$PATH:/tmp\n-          value \u003d System.getenv(parts[0]); // Get from NM?\n-          if (value !\u003d null) {\n-            // the env key is present in the tt\u0027s env\n-            value \u003d parts[1].replace(\"$\" + parts[0], value);\n-          } else {\n-            // the env key is note present anywhere .. simply set it\n-            // example X\u003d$X:/tmp or X\u003d/tmp\n-            value \u003d parts[1].replace(\"$\" + parts[0], \"\");\n-          }\n-        }\n-        env.put(parts[0], value);\n-      }\n-    }\n-\n-    //This should not be set here (If an OS check is requied. moved to ContainerLuanch)\n-    // env.put(\"JVM_PID\", \"`echo $$`\");\n-\n-    env.put(Constants.STDOUT_LOGFILE_ENV,\n-        getTaskLogFile(containerLogDir, TaskLog.LogName.STDOUT).toString());\n-    env.put(Constants.STDERR_LOGFILE_ENV,\n-        getTaskLogFile(containerLogDir, TaskLog.LogName.STDERR).toString());\n+    // Add stdout/stderr env\n+    environment.put(\n+        MRJobConfig.STDOUT_LOGFILE_ENV,\n+        getTaskLogFile(TaskLog.LogName.STDOUT)\n+        );\n+    environment.put(\n+        MRJobConfig.STDERR_LOGFILE_ENV,\n+        getTaskLogFile(TaskLog.LogName.STDERR)\n+        );\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static void setVMEnv(Map\u003cString, String\u003e environment,\n      Task task) {\n\n    JobConf conf \u003d task.conf;\n\n    // Shell\n    environment.put(\n        Environment.SHELL.name(), \n        conf.get(\n            MRJobConfig.MAPRED_ADMIN_USER_SHELL, \n            MRJobConfig.DEFAULT_SHELL)\n            );\n    \n    // Add pwd to LD_LIBRARY_PATH, add this before adding anything else\n    MRApps.addToEnvironment(\n        environment, \n        Environment.LD_LIBRARY_PATH.name(), \n        Environment.PWD.$());\n\n    // Add the env variables passed by the user \u0026 admin\n    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n    MRApps.setEnvFromInputString(environment, mapredChildEnv);\n    MRApps.setEnvFromInputString(\n        environment, \n        conf.get(\n            MRJobConfig.MAPRED_ADMIN_USER_ENV, \n            MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV)\n        );\n\n    // Set logging level\n    environment.put(\n        \"HADOOP_ROOT_LOGGER\", \n        getChildLogLevel(conf, task.isMapTask()) + \",CLA\"); \n\n    // TODO: The following is useful for instance in streaming tasks. Should be\n    // set in ApplicationMaster\u0027s env by the RM.\n    String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n    if (hadoopClientOpts \u003d\u003d null) {\n      hadoopClientOpts \u003d \"\";\n    } else {\n      hadoopClientOpts \u003d hadoopClientOpts + \" \";\n    }\n    // FIXME: don\u0027t think this is also needed given we already set java\n    // properties.\n    long logSize \u003d TaskLog.getTaskLogLength(conf);\n    Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n    setupLog4jProperties(logProps, logSize);\n    Iterator\u003cString\u003e it \u003d logProps.iterator();\n    StringBuffer buffer \u003d new StringBuffer();\n    while (it.hasNext()) {\n      buffer.append(\" \" + it.next());\n    }\n    hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n    environment.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n\n    // Add stdout/stderr env\n    environment.put(\n        MRJobConfig.STDOUT_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDOUT)\n        );\n    environment.put(\n        MRJobConfig.STDERR_LOGFILE_ENV,\n        getTaskLogFile(TaskLog.LogName.STDERR)\n        );\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public static void setVMEnv(Map\u003cString, String\u003e env,\n      List\u003cString\u003e classPaths, String pwd, String containerLogDir,\n      String nmLdLibraryPath, Task task, CharSequence applicationTokensFile) {\n\n    JobConf conf \u003d task.conf;\n\n    // Add classpath.\n    CharSequence cp \u003d env.get(\"CLASSPATH\");\n    String classpath \u003d StringUtils.join(SYSTEM_PATH_SEPARATOR, classPaths);\n    if (null \u003d\u003d cp) {\n      env.put(\"CLASSPATH\", classpath);\n    } else {\n      env.put(\"CLASSPATH\", classpath + SYSTEM_PATH_SEPARATOR + cp);\n    }\n\n    /////// Environmental variable LD_LIBRARY_PATH\n    StringBuilder ldLibraryPath \u003d new StringBuilder();\n\n    ldLibraryPath.append(nmLdLibraryPath);\n    ldLibraryPath.append(SYSTEM_PATH_SEPARATOR);\n    ldLibraryPath.append(pwd);\n    env.put(\"LD_LIBRARY_PATH\", ldLibraryPath.toString());\n    /////// Environmental variable LD_LIBRARY_PATH\n\n    // for the child of task jvm, set hadoop.root.logger\n    env.put(\"HADOOP_ROOT_LOGGER\", \"DEBUG,CLA\"); // TODO: Debug\n\n    // TODO: The following is useful for instance in streaming tasks. Should be\n    // set in ApplicationMaster\u0027s env by the RM.\n    String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n    if (hadoopClientOpts \u003d\u003d null) {\n      hadoopClientOpts \u003d \"\";\n    } else {\n      hadoopClientOpts \u003d hadoopClientOpts + \" \";\n    }\n    // FIXME: don\u0027t think this is also needed given we already set java\n    // properties.\n    long logSize \u003d TaskLog.getTaskLogLength(conf);\n    Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n    setupLog4jProperties(logProps, logSize, containerLogDir);\n    Iterator\u003cString\u003e it \u003d logProps.iterator();\n    StringBuffer buffer \u003d new StringBuffer();\n    while (it.hasNext()) {\n      buffer.append(\" \" + it.next());\n    }\n    hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n    \n    env.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n\n    // add the env variables passed by the user\n    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n    if (mapredChildEnv !\u003d null \u0026\u0026 mapredChildEnv.length() \u003e 0) {\n      String childEnvs[] \u003d mapredChildEnv.split(\",\");\n      for (String cEnv : childEnvs) {\n        String[] parts \u003d cEnv.split(\"\u003d\"); // split on \u0027\u003d\u0027\n        String value \u003d (String) env.get(parts[0]);\n        if (value !\u003d null) {\n          // replace $env with the child\u0027s env constructed by tt\u0027s\n          // example LD_LIBRARY_PATH\u003d$LD_LIBRARY_PATH:/tmp\n          value \u003d parts[1].replace(\"$\" + parts[0], value);\n        } else {\n          // this key is not configured by the tt for the child .. get it \n          // from the tt\u0027s env\n          // example PATH\u003d$PATH:/tmp\n          value \u003d System.getenv(parts[0]); // Get from NM?\n          if (value !\u003d null) {\n            // the env key is present in the tt\u0027s env\n            value \u003d parts[1].replace(\"$\" + parts[0], value);\n          } else {\n            // the env key is note present anywhere .. simply set it\n            // example X\u003d$X:/tmp or X\u003d/tmp\n            value \u003d parts[1].replace(\"$\" + parts[0], \"\");\n          }\n        }\n        env.put(parts[0], value);\n      }\n    }\n\n    //This should not be set here (If an OS check is requied. moved to ContainerLuanch)\n    // env.put(\"JVM_PID\", \"`echo $$`\");\n\n    env.put(Constants.STDOUT_LOGFILE_ENV,\n        getTaskLogFile(containerLogDir, TaskLog.LogName.STDOUT).toString());\n    env.put(Constants.STDERR_LOGFILE_ENV,\n        getTaskLogFile(containerLogDir, TaskLog.LogName.STDERR).toString());\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,86 @@\n+  public static void setVMEnv(Map\u003cString, String\u003e env,\n+      List\u003cString\u003e classPaths, String pwd, String containerLogDir,\n+      String nmLdLibraryPath, Task task, CharSequence applicationTokensFile) {\n+\n+    JobConf conf \u003d task.conf;\n+\n+    // Add classpath.\n+    CharSequence cp \u003d env.get(\"CLASSPATH\");\n+    String classpath \u003d StringUtils.join(SYSTEM_PATH_SEPARATOR, classPaths);\n+    if (null \u003d\u003d cp) {\n+      env.put(\"CLASSPATH\", classpath);\n+    } else {\n+      env.put(\"CLASSPATH\", classpath + SYSTEM_PATH_SEPARATOR + cp);\n+    }\n+\n+    /////// Environmental variable LD_LIBRARY_PATH\n+    StringBuilder ldLibraryPath \u003d new StringBuilder();\n+\n+    ldLibraryPath.append(nmLdLibraryPath);\n+    ldLibraryPath.append(SYSTEM_PATH_SEPARATOR);\n+    ldLibraryPath.append(pwd);\n+    env.put(\"LD_LIBRARY_PATH\", ldLibraryPath.toString());\n+    /////// Environmental variable LD_LIBRARY_PATH\n+\n+    // for the child of task jvm, set hadoop.root.logger\n+    env.put(\"HADOOP_ROOT_LOGGER\", \"DEBUG,CLA\"); // TODO: Debug\n+\n+    // TODO: The following is useful for instance in streaming tasks. Should be\n+    // set in ApplicationMaster\u0027s env by the RM.\n+    String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n+    if (hadoopClientOpts \u003d\u003d null) {\n+      hadoopClientOpts \u003d \"\";\n+    } else {\n+      hadoopClientOpts \u003d hadoopClientOpts + \" \";\n+    }\n+    // FIXME: don\u0027t think this is also needed given we already set java\n+    // properties.\n+    long logSize \u003d TaskLog.getTaskLogLength(conf);\n+    Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n+    setupLog4jProperties(logProps, logSize, containerLogDir);\n+    Iterator\u003cString\u003e it \u003d logProps.iterator();\n+    StringBuffer buffer \u003d new StringBuffer();\n+    while (it.hasNext()) {\n+      buffer.append(\" \" + it.next());\n+    }\n+    hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n+    \n+    env.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n+\n+    // add the env variables passed by the user\n+    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n+    if (mapredChildEnv !\u003d null \u0026\u0026 mapredChildEnv.length() \u003e 0) {\n+      String childEnvs[] \u003d mapredChildEnv.split(\",\");\n+      for (String cEnv : childEnvs) {\n+        String[] parts \u003d cEnv.split(\"\u003d\"); // split on \u0027\u003d\u0027\n+        String value \u003d (String) env.get(parts[0]);\n+        if (value !\u003d null) {\n+          // replace $env with the child\u0027s env constructed by tt\u0027s\n+          // example LD_LIBRARY_PATH\u003d$LD_LIBRARY_PATH:/tmp\n+          value \u003d parts[1].replace(\"$\" + parts[0], value);\n+        } else {\n+          // this key is not configured by the tt for the child .. get it \n+          // from the tt\u0027s env\n+          // example PATH\u003d$PATH:/tmp\n+          value \u003d System.getenv(parts[0]); // Get from NM?\n+          if (value !\u003d null) {\n+            // the env key is present in the tt\u0027s env\n+            value \u003d parts[1].replace(\"$\" + parts[0], value);\n+          } else {\n+            // the env key is note present anywhere .. simply set it\n+            // example X\u003d$X:/tmp or X\u003d/tmp\n+            value \u003d parts[1].replace(\"$\" + parts[0], \"\");\n+          }\n+        }\n+        env.put(parts[0], value);\n+      }\n+    }\n+\n+    //This should not be set here (If an OS check is requied. moved to ContainerLuanch)\n+    // env.put(\"JVM_PID\", \"`echo $$`\");\n+\n+    env.put(Constants.STDOUT_LOGFILE_ENV,\n+        getTaskLogFile(containerLogDir, TaskLog.LogName.STDOUT).toString());\n+    env.put(Constants.STDERR_LOGFILE_ENV,\n+        getTaskLogFile(containerLogDir, TaskLog.LogName.STDERR).toString());\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static void setVMEnv(Map\u003cString, String\u003e env,\n      List\u003cString\u003e classPaths, String pwd, String containerLogDir,\n      String nmLdLibraryPath, Task task, CharSequence applicationTokensFile) {\n\n    JobConf conf \u003d task.conf;\n\n    // Add classpath.\n    CharSequence cp \u003d env.get(\"CLASSPATH\");\n    String classpath \u003d StringUtils.join(SYSTEM_PATH_SEPARATOR, classPaths);\n    if (null \u003d\u003d cp) {\n      env.put(\"CLASSPATH\", classpath);\n    } else {\n      env.put(\"CLASSPATH\", classpath + SYSTEM_PATH_SEPARATOR + cp);\n    }\n\n    /////// Environmental variable LD_LIBRARY_PATH\n    StringBuilder ldLibraryPath \u003d new StringBuilder();\n\n    ldLibraryPath.append(nmLdLibraryPath);\n    ldLibraryPath.append(SYSTEM_PATH_SEPARATOR);\n    ldLibraryPath.append(pwd);\n    env.put(\"LD_LIBRARY_PATH\", ldLibraryPath.toString());\n    /////// Environmental variable LD_LIBRARY_PATH\n\n    // for the child of task jvm, set hadoop.root.logger\n    env.put(\"HADOOP_ROOT_LOGGER\", \"DEBUG,CLA\"); // TODO: Debug\n\n    // TODO: The following is useful for instance in streaming tasks. Should be\n    // set in ApplicationMaster\u0027s env by the RM.\n    String hadoopClientOpts \u003d System.getenv(\"HADOOP_CLIENT_OPTS\");\n    if (hadoopClientOpts \u003d\u003d null) {\n      hadoopClientOpts \u003d \"\";\n    } else {\n      hadoopClientOpts \u003d hadoopClientOpts + \" \";\n    }\n    // FIXME: don\u0027t think this is also needed given we already set java\n    // properties.\n    long logSize \u003d TaskLog.getTaskLogLength(conf);\n    Vector\u003cString\u003e logProps \u003d new Vector\u003cString\u003e(4);\n    setupLog4jProperties(logProps, logSize, containerLogDir);\n    Iterator\u003cString\u003e it \u003d logProps.iterator();\n    StringBuffer buffer \u003d new StringBuffer();\n    while (it.hasNext()) {\n      buffer.append(\" \" + it.next());\n    }\n    hadoopClientOpts \u003d hadoopClientOpts + buffer.toString();\n    \n    env.put(\"HADOOP_CLIENT_OPTS\", hadoopClientOpts);\n\n    // add the env variables passed by the user\n    String mapredChildEnv \u003d getChildEnv(conf, task.isMapTask());\n    if (mapredChildEnv !\u003d null \u0026\u0026 mapredChildEnv.length() \u003e 0) {\n      String childEnvs[] \u003d mapredChildEnv.split(\",\");\n      for (String cEnv : childEnvs) {\n        String[] parts \u003d cEnv.split(\"\u003d\"); // split on \u0027\u003d\u0027\n        String value \u003d (String) env.get(parts[0]);\n        if (value !\u003d null) {\n          // replace $env with the child\u0027s env constructed by tt\u0027s\n          // example LD_LIBRARY_PATH\u003d$LD_LIBRARY_PATH:/tmp\n          value \u003d parts[1].replace(\"$\" + parts[0], value);\n        } else {\n          // this key is not configured by the tt for the child .. get it \n          // from the tt\u0027s env\n          // example PATH\u003d$PATH:/tmp\n          value \u003d System.getenv(parts[0]); // Get from NM?\n          if (value !\u003d null) {\n            // the env key is present in the tt\u0027s env\n            value \u003d parts[1].replace(\"$\" + parts[0], value);\n          } else {\n            // the env key is note present anywhere .. simply set it\n            // example X\u003d$X:/tmp or X\u003d/tmp\n            value \u003d parts[1].replace(\"$\" + parts[0], \"\");\n          }\n        }\n        env.put(parts[0], value);\n      }\n    }\n\n    //This should not be set here (If an OS check is requied. moved to ContainerLuanch)\n    // env.put(\"JVM_PID\", \"`echo $$`\");\n\n    env.put(Constants.STDOUT_LOGFILE_ENV,\n        getTaskLogFile(containerLogDir, TaskLog.LogName.STDOUT).toString());\n    env.put(Constants.STDERR_LOGFILE_ENV,\n        getTaskLogFile(containerLogDir, TaskLog.LogName.STDERR).toString());\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java"
    }
  }
}