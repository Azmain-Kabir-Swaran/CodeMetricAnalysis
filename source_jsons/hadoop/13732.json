{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPlacementPolicy.java",
  "functionName": "splitNodesWithRack",
  "functionId": "splitNodesWithRack___availableSet-Iterable__T__(modifiers-final)__candidates-Collection__T__(modifiers-final)__rackMap-Map__String,List__T____(modifiers-final)__moreThanOne-List__T__(modifiers-final)__exactlyOne-List__T__(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicy.java",
  "functionStartLine": 238,
  "functionEndLine": 263,
  "numCommitsSeen": 90,
  "timeTaken": 3695,
  "changeHistory": [
    "408f2c807bbaaaa37ce1b69a5dfa9d76ed427d6e",
    "ec414600ede8e305c584818565b50e055ea5d2b5",
    "08466eaa0045658fa7919a634e48f2d0669f8414",
    "bbab35e6d87aeebbc1848d7072c59af780536425"
  ],
  "changeHistoryShort": {
    "408f2c807bbaaaa37ce1b69a5dfa9d76ed427d6e": "Ymultichange(Yparameterchange,Ybodychange)",
    "ec414600ede8e305c584818565b50e055ea5d2b5": "Ymultichange(Yparameterchange,Ybodychange)",
    "08466eaa0045658fa7919a634e48f2d0669f8414": "Ymultichange(Yparameterchange,Ybodychange)",
    "bbab35e6d87aeebbc1848d7072c59af780536425": "Yintroduced"
  },
  "changeHistoryDetails": {
    "408f2c807bbaaaa37ce1b69a5dfa9d76ed427d6e": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-9866. BlockManager#chooseExcessReplicasStriped may weaken rack fault tolerance. Contributed by Jing Zhao.\n",
      "commitDate": "28/02/16 2:54 PM",
      "commitName": "408f2c807bbaaaa37ce1b69a5dfa9d76ed427d6e",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9866. BlockManager#chooseExcessReplicasStriped may weaken rack fault tolerance. Contributed by Jing Zhao.\n",
          "commitDate": "28/02/16 2:54 PM",
          "commitName": "408f2c807bbaaaa37ce1b69a5dfa9d76ed427d6e",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "04/11/15 10:22 AM",
          "commitNameOld": "ec414600ede8e305c584818565b50e055ea5d2b5",
          "commitAuthorOld": "Lei Xu",
          "daysBetweenCommits": 116.19,
          "commitsBetweenForRepo": 735,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,26 @@\n   public \u003cT\u003e void splitNodesWithRack(\n-      final Iterable\u003cT\u003e storagesOrDataNodes,\n+      final Iterable\u003cT\u003e availableSet,\n+      final Collection\u003cT\u003e candidates,\n       final Map\u003cString, List\u003cT\u003e\u003e rackMap,\n       final List\u003cT\u003e moreThanOne,\n       final List\u003cT\u003e exactlyOne) {\n-    for(T s: storagesOrDataNodes) {\n+    for(T s: availableSet) {\n       final String rackName \u003d getRack(getDatanodeInfo(s));\n       List\u003cT\u003e storageList \u003d rackMap.get(rackName);\n       if (storageList \u003d\u003d null) {\n-        storageList \u003d new ArrayList\u003cT\u003e();\n+        storageList \u003d new ArrayList\u003c\u003e();\n         rackMap.put(rackName, storageList);\n       }\n       storageList.add(s);\n     }\n-    // split nodes into two sets\n-    for(List\u003cT\u003e storageList : rackMap.values()) {\n-      if (storageList.size() \u003d\u003d 1) {\n+    for (T candidate : candidates) {\n+      final String rackName \u003d getRack(getDatanodeInfo(candidate));\n+      if (rackMap.get(rackName).size() \u003d\u003d 1) {\n         // exactlyOne contains nodes on rack with only one replica\n-        exactlyOne.add(storageList.get(0));\n+        exactlyOne.add(candidate);\n       } else {\n         // moreThanOne contains nodes on rack with more than one replica\n-        moreThanOne.addAll(storageList);\n+        moreThanOne.add(candidate);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public \u003cT\u003e void splitNodesWithRack(\n      final Iterable\u003cT\u003e availableSet,\n      final Collection\u003cT\u003e candidates,\n      final Map\u003cString, List\u003cT\u003e\u003e rackMap,\n      final List\u003cT\u003e moreThanOne,\n      final List\u003cT\u003e exactlyOne) {\n    for(T s: availableSet) {\n      final String rackName \u003d getRack(getDatanodeInfo(s));\n      List\u003cT\u003e storageList \u003d rackMap.get(rackName);\n      if (storageList \u003d\u003d null) {\n        storageList \u003d new ArrayList\u003c\u003e();\n        rackMap.put(rackName, storageList);\n      }\n      storageList.add(s);\n    }\n    for (T candidate : candidates) {\n      final String rackName \u003d getRack(getDatanodeInfo(candidate));\n      if (rackMap.get(rackName).size() \u003d\u003d 1) {\n        // exactlyOne contains nodes on rack with only one replica\n        exactlyOne.add(candidate);\n      } else {\n        // moreThanOne contains nodes on rack with more than one replica\n        moreThanOne.add(candidate);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicy.java",
          "extendedDetails": {
            "oldValue": "[storagesOrDataNodes-Iterable\u003cT\u003e(modifiers-final), rackMap-Map\u003cString,List\u003cT\u003e\u003e(modifiers-final), moreThanOne-List\u003cT\u003e(modifiers-final), exactlyOne-List\u003cT\u003e(modifiers-final)]",
            "newValue": "[availableSet-Iterable\u003cT\u003e(modifiers-final), candidates-Collection\u003cT\u003e(modifiers-final), rackMap-Map\u003cString,List\u003cT\u003e\u003e(modifiers-final), moreThanOne-List\u003cT\u003e(modifiers-final), exactlyOne-List\u003cT\u003e(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9866. BlockManager#chooseExcessReplicasStriped may weaken rack fault tolerance. Contributed by Jing Zhao.\n",
          "commitDate": "28/02/16 2:54 PM",
          "commitName": "408f2c807bbaaaa37ce1b69a5dfa9d76ed427d6e",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "04/11/15 10:22 AM",
          "commitNameOld": "ec414600ede8e305c584818565b50e055ea5d2b5",
          "commitAuthorOld": "Lei Xu",
          "daysBetweenCommits": 116.19,
          "commitsBetweenForRepo": 735,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,26 @@\n   public \u003cT\u003e void splitNodesWithRack(\n-      final Iterable\u003cT\u003e storagesOrDataNodes,\n+      final Iterable\u003cT\u003e availableSet,\n+      final Collection\u003cT\u003e candidates,\n       final Map\u003cString, List\u003cT\u003e\u003e rackMap,\n       final List\u003cT\u003e moreThanOne,\n       final List\u003cT\u003e exactlyOne) {\n-    for(T s: storagesOrDataNodes) {\n+    for(T s: availableSet) {\n       final String rackName \u003d getRack(getDatanodeInfo(s));\n       List\u003cT\u003e storageList \u003d rackMap.get(rackName);\n       if (storageList \u003d\u003d null) {\n-        storageList \u003d new ArrayList\u003cT\u003e();\n+        storageList \u003d new ArrayList\u003c\u003e();\n         rackMap.put(rackName, storageList);\n       }\n       storageList.add(s);\n     }\n-    // split nodes into two sets\n-    for(List\u003cT\u003e storageList : rackMap.values()) {\n-      if (storageList.size() \u003d\u003d 1) {\n+    for (T candidate : candidates) {\n+      final String rackName \u003d getRack(getDatanodeInfo(candidate));\n+      if (rackMap.get(rackName).size() \u003d\u003d 1) {\n         // exactlyOne contains nodes on rack with only one replica\n-        exactlyOne.add(storageList.get(0));\n+        exactlyOne.add(candidate);\n       } else {\n         // moreThanOne contains nodes on rack with more than one replica\n-        moreThanOne.addAll(storageList);\n+        moreThanOne.add(candidate);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public \u003cT\u003e void splitNodesWithRack(\n      final Iterable\u003cT\u003e availableSet,\n      final Collection\u003cT\u003e candidates,\n      final Map\u003cString, List\u003cT\u003e\u003e rackMap,\n      final List\u003cT\u003e moreThanOne,\n      final List\u003cT\u003e exactlyOne) {\n    for(T s: availableSet) {\n      final String rackName \u003d getRack(getDatanodeInfo(s));\n      List\u003cT\u003e storageList \u003d rackMap.get(rackName);\n      if (storageList \u003d\u003d null) {\n        storageList \u003d new ArrayList\u003c\u003e();\n        rackMap.put(rackName, storageList);\n      }\n      storageList.add(s);\n    }\n    for (T candidate : candidates) {\n      final String rackName \u003d getRack(getDatanodeInfo(candidate));\n      if (rackMap.get(rackName).size() \u003d\u003d 1) {\n        // exactlyOne contains nodes on rack with only one replica\n        exactlyOne.add(candidate);\n      } else {\n        // moreThanOne contains nodes on rack with more than one replica\n        moreThanOne.add(candidate);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicy.java",
          "extendedDetails": {}
        }
      ]
    },
    "ec414600ede8e305c584818565b50e055ea5d2b5": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-9007. Fix HDFS Balancer to honor upgrade domain policy. (Ming Ma via lei)\n",
      "commitDate": "04/11/15 10:22 AM",
      "commitName": "ec414600ede8e305c584818565b50e055ea5d2b5",
      "commitAuthor": "Lei Xu",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9007. Fix HDFS Balancer to honor upgrade domain policy. (Ming Ma via lei)\n",
          "commitDate": "04/11/15 10:22 AM",
          "commitName": "ec414600ede8e305c584818565b50e055ea5d2b5",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "02/11/15 7:36 PM",
          "commitNameOld": "d565480da2f646b40c3180e1ccb2935c9863dfef",
          "commitAuthorOld": "Ming Ma",
          "daysBetweenCommits": 1.62,
          "commitsBetweenForRepo": 15,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,25 @@\n-  public void splitNodesWithRack(\n-      final Iterable\u003cDatanodeStorageInfo\u003e storages,\n-      final Map\u003cString, List\u003cDatanodeStorageInfo\u003e\u003e rackMap,\n-      final List\u003cDatanodeStorageInfo\u003e moreThanOne,\n-      final List\u003cDatanodeStorageInfo\u003e exactlyOne) {\n-    for(DatanodeStorageInfo s: storages) {\n-      final String rackName \u003d getRack(s.getDatanodeDescriptor());\n-      List\u003cDatanodeStorageInfo\u003e storageList \u003d rackMap.get(rackName);\n+  public \u003cT\u003e void splitNodesWithRack(\n+      final Iterable\u003cT\u003e storagesOrDataNodes,\n+      final Map\u003cString, List\u003cT\u003e\u003e rackMap,\n+      final List\u003cT\u003e moreThanOne,\n+      final List\u003cT\u003e exactlyOne) {\n+    for(T s: storagesOrDataNodes) {\n+      final String rackName \u003d getRack(getDatanodeInfo(s));\n+      List\u003cT\u003e storageList \u003d rackMap.get(rackName);\n       if (storageList \u003d\u003d null) {\n-        storageList \u003d new ArrayList\u003cDatanodeStorageInfo\u003e();\n+        storageList \u003d new ArrayList\u003cT\u003e();\n         rackMap.put(rackName, storageList);\n       }\n       storageList.add(s);\n     }\n-    \n     // split nodes into two sets\n-    for(List\u003cDatanodeStorageInfo\u003e storageList : rackMap.values()) {\n+    for(List\u003cT\u003e storageList : rackMap.values()) {\n       if (storageList.size() \u003d\u003d 1) {\n         // exactlyOne contains nodes on rack with only one replica\n         exactlyOne.add(storageList.get(0));\n       } else {\n         // moreThanOne contains nodes on rack with more than one replica\n         moreThanOne.addAll(storageList);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public \u003cT\u003e void splitNodesWithRack(\n      final Iterable\u003cT\u003e storagesOrDataNodes,\n      final Map\u003cString, List\u003cT\u003e\u003e rackMap,\n      final List\u003cT\u003e moreThanOne,\n      final List\u003cT\u003e exactlyOne) {\n    for(T s: storagesOrDataNodes) {\n      final String rackName \u003d getRack(getDatanodeInfo(s));\n      List\u003cT\u003e storageList \u003d rackMap.get(rackName);\n      if (storageList \u003d\u003d null) {\n        storageList \u003d new ArrayList\u003cT\u003e();\n        rackMap.put(rackName, storageList);\n      }\n      storageList.add(s);\n    }\n    // split nodes into two sets\n    for(List\u003cT\u003e storageList : rackMap.values()) {\n      if (storageList.size() \u003d\u003d 1) {\n        // exactlyOne contains nodes on rack with only one replica\n        exactlyOne.add(storageList.get(0));\n      } else {\n        // moreThanOne contains nodes on rack with more than one replica\n        moreThanOne.addAll(storageList);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicy.java",
          "extendedDetails": {
            "oldValue": "[storages-Iterable\u003cDatanodeStorageInfo\u003e(modifiers-final), rackMap-Map\u003cString,List\u003cDatanodeStorageInfo\u003e\u003e(modifiers-final), moreThanOne-List\u003cDatanodeStorageInfo\u003e(modifiers-final), exactlyOne-List\u003cDatanodeStorageInfo\u003e(modifiers-final)]",
            "newValue": "[storagesOrDataNodes-Iterable\u003cT\u003e(modifiers-final), rackMap-Map\u003cString,List\u003cT\u003e\u003e(modifiers-final), moreThanOne-List\u003cT\u003e(modifiers-final), exactlyOne-List\u003cT\u003e(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9007. Fix HDFS Balancer to honor upgrade domain policy. (Ming Ma via lei)\n",
          "commitDate": "04/11/15 10:22 AM",
          "commitName": "ec414600ede8e305c584818565b50e055ea5d2b5",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "02/11/15 7:36 PM",
          "commitNameOld": "d565480da2f646b40c3180e1ccb2935c9863dfef",
          "commitAuthorOld": "Ming Ma",
          "daysBetweenCommits": 1.62,
          "commitsBetweenForRepo": 15,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,25 @@\n-  public void splitNodesWithRack(\n-      final Iterable\u003cDatanodeStorageInfo\u003e storages,\n-      final Map\u003cString, List\u003cDatanodeStorageInfo\u003e\u003e rackMap,\n-      final List\u003cDatanodeStorageInfo\u003e moreThanOne,\n-      final List\u003cDatanodeStorageInfo\u003e exactlyOne) {\n-    for(DatanodeStorageInfo s: storages) {\n-      final String rackName \u003d getRack(s.getDatanodeDescriptor());\n-      List\u003cDatanodeStorageInfo\u003e storageList \u003d rackMap.get(rackName);\n+  public \u003cT\u003e void splitNodesWithRack(\n+      final Iterable\u003cT\u003e storagesOrDataNodes,\n+      final Map\u003cString, List\u003cT\u003e\u003e rackMap,\n+      final List\u003cT\u003e moreThanOne,\n+      final List\u003cT\u003e exactlyOne) {\n+    for(T s: storagesOrDataNodes) {\n+      final String rackName \u003d getRack(getDatanodeInfo(s));\n+      List\u003cT\u003e storageList \u003d rackMap.get(rackName);\n       if (storageList \u003d\u003d null) {\n-        storageList \u003d new ArrayList\u003cDatanodeStorageInfo\u003e();\n+        storageList \u003d new ArrayList\u003cT\u003e();\n         rackMap.put(rackName, storageList);\n       }\n       storageList.add(s);\n     }\n-    \n     // split nodes into two sets\n-    for(List\u003cDatanodeStorageInfo\u003e storageList : rackMap.values()) {\n+    for(List\u003cT\u003e storageList : rackMap.values()) {\n       if (storageList.size() \u003d\u003d 1) {\n         // exactlyOne contains nodes on rack with only one replica\n         exactlyOne.add(storageList.get(0));\n       } else {\n         // moreThanOne contains nodes on rack with more than one replica\n         moreThanOne.addAll(storageList);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public \u003cT\u003e void splitNodesWithRack(\n      final Iterable\u003cT\u003e storagesOrDataNodes,\n      final Map\u003cString, List\u003cT\u003e\u003e rackMap,\n      final List\u003cT\u003e moreThanOne,\n      final List\u003cT\u003e exactlyOne) {\n    for(T s: storagesOrDataNodes) {\n      final String rackName \u003d getRack(getDatanodeInfo(s));\n      List\u003cT\u003e storageList \u003d rackMap.get(rackName);\n      if (storageList \u003d\u003d null) {\n        storageList \u003d new ArrayList\u003cT\u003e();\n        rackMap.put(rackName, storageList);\n      }\n      storageList.add(s);\n    }\n    // split nodes into two sets\n    for(List\u003cT\u003e storageList : rackMap.values()) {\n      if (storageList.size() \u003d\u003d 1) {\n        // exactlyOne contains nodes on rack with only one replica\n        exactlyOne.add(storageList.get(0));\n      } else {\n        // moreThanOne contains nodes on rack with more than one replica\n        moreThanOne.addAll(storageList);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicy.java",
          "extendedDetails": {}
        }
      ]
    },
    "08466eaa0045658fa7919a634e48f2d0669f8414": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6700. BlockPlacementPolicy shoud choose storage but not datanode for deletion.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1611731 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/07/14 10:40 AM",
      "commitName": "08466eaa0045658fa7919a634e48f2d0669f8414",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6700. BlockPlacementPolicy shoud choose storage but not datanode for deletion.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1611731 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/07/14 10:40 AM",
          "commitName": "08466eaa0045658fa7919a634e48f2d0669f8414",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "03/05/14 4:02 AM",
          "commitNameOld": "b2f65c276da2c4420a0974a7e2d75e081abf5d63",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 76.28,
          "commitsBetweenForRepo": 475,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,26 @@\n   public void splitNodesWithRack(\n-      Collection\u003cDatanodeDescriptor\u003e dataNodes,\n-      final Map\u003cString, List\u003cDatanodeDescriptor\u003e\u003e rackMap,\n-      final List\u003cDatanodeDescriptor\u003e moreThanOne,\n-      final List\u003cDatanodeDescriptor\u003e exactlyOne) {\n-    for(DatanodeDescriptor node : dataNodes) {\n-      final String rackName \u003d getRack(node);\n-      List\u003cDatanodeDescriptor\u003e datanodeList \u003d rackMap.get(rackName);\n-      if (datanodeList \u003d\u003d null) {\n-        datanodeList \u003d new ArrayList\u003cDatanodeDescriptor\u003e();\n-        rackMap.put(rackName, datanodeList);\n+      final Iterable\u003cDatanodeStorageInfo\u003e storages,\n+      final Map\u003cString, List\u003cDatanodeStorageInfo\u003e\u003e rackMap,\n+      final List\u003cDatanodeStorageInfo\u003e moreThanOne,\n+      final List\u003cDatanodeStorageInfo\u003e exactlyOne) {\n+    for(DatanodeStorageInfo s: storages) {\n+      final String rackName \u003d getRack(s.getDatanodeDescriptor());\n+      List\u003cDatanodeStorageInfo\u003e storageList \u003d rackMap.get(rackName);\n+      if (storageList \u003d\u003d null) {\n+        storageList \u003d new ArrayList\u003cDatanodeStorageInfo\u003e();\n+        rackMap.put(rackName, storageList);\n       }\n-      datanodeList.add(node);\n+      storageList.add(s);\n     }\n     \n     // split nodes into two sets\n-    for(List\u003cDatanodeDescriptor\u003e datanodeList : rackMap.values()) {\n-      if (datanodeList.size() \u003d\u003d 1) {\n+    for(List\u003cDatanodeStorageInfo\u003e storageList : rackMap.values()) {\n+      if (storageList.size() \u003d\u003d 1) {\n         // exactlyOne contains nodes on rack with only one replica\n-        exactlyOne.add(datanodeList.get(0));\n+        exactlyOne.add(storageList.get(0));\n       } else {\n         // moreThanOne contains nodes on rack with more than one replica\n-        moreThanOne.addAll(datanodeList);\n+        moreThanOne.addAll(storageList);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void splitNodesWithRack(\n      final Iterable\u003cDatanodeStorageInfo\u003e storages,\n      final Map\u003cString, List\u003cDatanodeStorageInfo\u003e\u003e rackMap,\n      final List\u003cDatanodeStorageInfo\u003e moreThanOne,\n      final List\u003cDatanodeStorageInfo\u003e exactlyOne) {\n    for(DatanodeStorageInfo s: storages) {\n      final String rackName \u003d getRack(s.getDatanodeDescriptor());\n      List\u003cDatanodeStorageInfo\u003e storageList \u003d rackMap.get(rackName);\n      if (storageList \u003d\u003d null) {\n        storageList \u003d new ArrayList\u003cDatanodeStorageInfo\u003e();\n        rackMap.put(rackName, storageList);\n      }\n      storageList.add(s);\n    }\n    \n    // split nodes into two sets\n    for(List\u003cDatanodeStorageInfo\u003e storageList : rackMap.values()) {\n      if (storageList.size() \u003d\u003d 1) {\n        // exactlyOne contains nodes on rack with only one replica\n        exactlyOne.add(storageList.get(0));\n      } else {\n        // moreThanOne contains nodes on rack with more than one replica\n        moreThanOne.addAll(storageList);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicy.java",
          "extendedDetails": {
            "oldValue": "[dataNodes-Collection\u003cDatanodeDescriptor\u003e, rackMap-Map\u003cString,List\u003cDatanodeDescriptor\u003e\u003e(modifiers-final), moreThanOne-List\u003cDatanodeDescriptor\u003e(modifiers-final), exactlyOne-List\u003cDatanodeDescriptor\u003e(modifiers-final)]",
            "newValue": "[storages-Iterable\u003cDatanodeStorageInfo\u003e(modifiers-final), rackMap-Map\u003cString,List\u003cDatanodeStorageInfo\u003e\u003e(modifiers-final), moreThanOne-List\u003cDatanodeStorageInfo\u003e(modifiers-final), exactlyOne-List\u003cDatanodeStorageInfo\u003e(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6700. BlockPlacementPolicy shoud choose storage but not datanode for deletion.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1611731 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/07/14 10:40 AM",
          "commitName": "08466eaa0045658fa7919a634e48f2d0669f8414",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "03/05/14 4:02 AM",
          "commitNameOld": "b2f65c276da2c4420a0974a7e2d75e081abf5d63",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 76.28,
          "commitsBetweenForRepo": 475,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,26 @@\n   public void splitNodesWithRack(\n-      Collection\u003cDatanodeDescriptor\u003e dataNodes,\n-      final Map\u003cString, List\u003cDatanodeDescriptor\u003e\u003e rackMap,\n-      final List\u003cDatanodeDescriptor\u003e moreThanOne,\n-      final List\u003cDatanodeDescriptor\u003e exactlyOne) {\n-    for(DatanodeDescriptor node : dataNodes) {\n-      final String rackName \u003d getRack(node);\n-      List\u003cDatanodeDescriptor\u003e datanodeList \u003d rackMap.get(rackName);\n-      if (datanodeList \u003d\u003d null) {\n-        datanodeList \u003d new ArrayList\u003cDatanodeDescriptor\u003e();\n-        rackMap.put(rackName, datanodeList);\n+      final Iterable\u003cDatanodeStorageInfo\u003e storages,\n+      final Map\u003cString, List\u003cDatanodeStorageInfo\u003e\u003e rackMap,\n+      final List\u003cDatanodeStorageInfo\u003e moreThanOne,\n+      final List\u003cDatanodeStorageInfo\u003e exactlyOne) {\n+    for(DatanodeStorageInfo s: storages) {\n+      final String rackName \u003d getRack(s.getDatanodeDescriptor());\n+      List\u003cDatanodeStorageInfo\u003e storageList \u003d rackMap.get(rackName);\n+      if (storageList \u003d\u003d null) {\n+        storageList \u003d new ArrayList\u003cDatanodeStorageInfo\u003e();\n+        rackMap.put(rackName, storageList);\n       }\n-      datanodeList.add(node);\n+      storageList.add(s);\n     }\n     \n     // split nodes into two sets\n-    for(List\u003cDatanodeDescriptor\u003e datanodeList : rackMap.values()) {\n-      if (datanodeList.size() \u003d\u003d 1) {\n+    for(List\u003cDatanodeStorageInfo\u003e storageList : rackMap.values()) {\n+      if (storageList.size() \u003d\u003d 1) {\n         // exactlyOne contains nodes on rack with only one replica\n-        exactlyOne.add(datanodeList.get(0));\n+        exactlyOne.add(storageList.get(0));\n       } else {\n         // moreThanOne contains nodes on rack with more than one replica\n-        moreThanOne.addAll(datanodeList);\n+        moreThanOne.addAll(storageList);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void splitNodesWithRack(\n      final Iterable\u003cDatanodeStorageInfo\u003e storages,\n      final Map\u003cString, List\u003cDatanodeStorageInfo\u003e\u003e rackMap,\n      final List\u003cDatanodeStorageInfo\u003e moreThanOne,\n      final List\u003cDatanodeStorageInfo\u003e exactlyOne) {\n    for(DatanodeStorageInfo s: storages) {\n      final String rackName \u003d getRack(s.getDatanodeDescriptor());\n      List\u003cDatanodeStorageInfo\u003e storageList \u003d rackMap.get(rackName);\n      if (storageList \u003d\u003d null) {\n        storageList \u003d new ArrayList\u003cDatanodeStorageInfo\u003e();\n        rackMap.put(rackName, storageList);\n      }\n      storageList.add(s);\n    }\n    \n    // split nodes into two sets\n    for(List\u003cDatanodeStorageInfo\u003e storageList : rackMap.values()) {\n      if (storageList.size() \u003d\u003d 1) {\n        // exactlyOne contains nodes on rack with only one replica\n        exactlyOne.add(storageList.get(0));\n      } else {\n        // moreThanOne contains nodes on rack with more than one replica\n        moreThanOne.addAll(storageList);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicy.java",
          "extendedDetails": {}
        }
      ]
    },
    "bbab35e6d87aeebbc1848d7072c59af780536425": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3498. Support replica removal in BlockPlacementPolicy and make BlockPlacementPolicyDefault extensible for reusing code in subclasses.  Contributed by Junping Du\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1353807 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/06/12 8:25 PM",
      "commitName": "bbab35e6d87aeebbc1848d7072c59af780536425",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,26 @@\n+  public void splitNodesWithRack(\n+      Collection\u003cDatanodeDescriptor\u003e dataNodes,\n+      final Map\u003cString, List\u003cDatanodeDescriptor\u003e\u003e rackMap,\n+      final List\u003cDatanodeDescriptor\u003e moreThanOne,\n+      final List\u003cDatanodeDescriptor\u003e exactlyOne) {\n+    for(DatanodeDescriptor node : dataNodes) {\n+      final String rackName \u003d getRack(node);\n+      List\u003cDatanodeDescriptor\u003e datanodeList \u003d rackMap.get(rackName);\n+      if (datanodeList \u003d\u003d null) {\n+        datanodeList \u003d new ArrayList\u003cDatanodeDescriptor\u003e();\n+        rackMap.put(rackName, datanodeList);\n+      }\n+      datanodeList.add(node);\n+    }\n+    \n+    // split nodes into two sets\n+    for(List\u003cDatanodeDescriptor\u003e datanodeList : rackMap.values()) {\n+      if (datanodeList.size() \u003d\u003d 1) {\n+        // exactlyOne contains nodes on rack with only one replica\n+        exactlyOne.add(datanodeList.get(0));\n+      } else {\n+        // moreThanOne contains nodes on rack with more than one replica\n+        moreThanOne.addAll(datanodeList);\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void splitNodesWithRack(\n      Collection\u003cDatanodeDescriptor\u003e dataNodes,\n      final Map\u003cString, List\u003cDatanodeDescriptor\u003e\u003e rackMap,\n      final List\u003cDatanodeDescriptor\u003e moreThanOne,\n      final List\u003cDatanodeDescriptor\u003e exactlyOne) {\n    for(DatanodeDescriptor node : dataNodes) {\n      final String rackName \u003d getRack(node);\n      List\u003cDatanodeDescriptor\u003e datanodeList \u003d rackMap.get(rackName);\n      if (datanodeList \u003d\u003d null) {\n        datanodeList \u003d new ArrayList\u003cDatanodeDescriptor\u003e();\n        rackMap.put(rackName, datanodeList);\n      }\n      datanodeList.add(node);\n    }\n    \n    // split nodes into two sets\n    for(List\u003cDatanodeDescriptor\u003e datanodeList : rackMap.values()) {\n      if (datanodeList.size() \u003d\u003d 1) {\n        // exactlyOne contains nodes on rack with only one replica\n        exactlyOne.add(datanodeList.get(0));\n      } else {\n        // moreThanOne contains nodes on rack with more than one replica\n        moreThanOne.addAll(datanodeList);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicy.java"
    }
  }
}