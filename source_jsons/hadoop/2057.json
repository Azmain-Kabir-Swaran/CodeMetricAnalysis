{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LocatedBlock.java",
  "functionName": "addCachedLoc",
  "functionId": "addCachedLoc___loc-DatanodeInfo",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/LocatedBlock.java",
  "functionStartLine": 236,
  "functionEndLine": 255,
  "numCommitsSeen": 30,
  "timeTaken": 2238,
  "changeHistory": [
    "8175c4f6b9fc17ff2e0fc568d798f9b6f2487696",
    "5c97db07fb306842f49d73a67a90cecec19a7833",
    "ab934e85947dcf2092050023909dd81ae274ff45",
    "3fc8792b5c75fca9fc4f6cf4b95fb2927c62e624"
  ],
  "changeHistoryShort": {
    "8175c4f6b9fc17ff2e0fc568d798f9b6f2487696": "Ybodychange",
    "5c97db07fb306842f49d73a67a90cecec19a7833": "Yfilerename",
    "ab934e85947dcf2092050023909dd81ae274ff45": "Ybodychange",
    "3fc8792b5c75fca9fc4f6cf4b95fb2927c62e624": "Yintroduced"
  },
  "changeHistoryDetails": {
    "8175c4f6b9fc17ff2e0fc568d798f9b6f2487696": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9250. Add Precondition check to LocatedBlock#addCachedLoc. Contributed by Xiao Chen.\n",
      "commitDate": "19/10/15 4:12 PM",
      "commitName": "8175c4f6b9fc17ff2e0fc568d798f9b6f2487696",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "03/10/15 11:38 AM",
      "commitNameOld": "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 16.19,
      "commitsBetweenForRepo": 118,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,20 @@\n   public void addCachedLoc(DatanodeInfo loc) {\n     List\u003cDatanodeInfo\u003e cachedList \u003d Lists.newArrayList(cachedLocs);\n     if (cachedList.contains(loc)) {\n       return;\n     }\n     // Try to re-use a DatanodeInfo already in loc\n     for (DatanodeInfoWithStorage di : locs) {\n       if (loc.equals(di)) {\n         cachedList.add(di);\n         cachedLocs \u003d cachedList.toArray(cachedLocs);\n         return;\n       }\n     }\n     // Not present in loc, add it and go\n     cachedList.add(loc);\n+    Preconditions.checkArgument(cachedLocs !\u003d EMPTY_LOCS,\n+        \"Cached locations should only be added when having a backing\"\n+            + \" disk replica!\", loc, locs.length, Arrays.toString(locs));\n     cachedLocs \u003d cachedList.toArray(cachedLocs);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void addCachedLoc(DatanodeInfo loc) {\n    List\u003cDatanodeInfo\u003e cachedList \u003d Lists.newArrayList(cachedLocs);\n    if (cachedList.contains(loc)) {\n      return;\n    }\n    // Try to re-use a DatanodeInfo already in loc\n    for (DatanodeInfoWithStorage di : locs) {\n      if (loc.equals(di)) {\n        cachedList.add(di);\n        cachedLocs \u003d cachedList.toArray(cachedLocs);\n        return;\n      }\n    }\n    // Not present in loc, add it and go\n    cachedList.add(loc);\n    Preconditions.checkArgument(cachedLocs !\u003d EMPTY_LOCS,\n        \"Cached locations should only be added when having a backing\"\n            + \" disk replica!\", loc, locs.length, Arrays.toString(locs));\n    cachedLocs \u003d cachedList.toArray(cachedLocs);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/LocatedBlock.java",
      "extendedDetails": {}
    },
    "5c97db07fb306842f49d73a67a90cecec19a7833": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8169. Move LocatedBlocks and related classes to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "20/04/15 12:36 AM",
      "commitName": "5c97db07fb306842f49d73a67a90cecec19a7833",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "19/04/15 4:09 PM",
      "commitNameOld": "8511d80804de052618168a456a475ee0f7aa6d8c",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.35,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void addCachedLoc(DatanodeInfo loc) {\n    List\u003cDatanodeInfo\u003e cachedList \u003d Lists.newArrayList(cachedLocs);\n    if (cachedList.contains(loc)) {\n      return;\n    }\n    // Try to re-use a DatanodeInfo already in loc\n    for (DatanodeInfoWithStorage di : locs) {\n      if (loc.equals(di)) {\n        cachedList.add(di);\n        cachedLocs \u003d cachedList.toArray(cachedLocs);\n        return;\n      }\n    }\n    // Not present in loc, add it and go\n    cachedList.add(loc);\n    cachedLocs \u003d cachedList.toArray(cachedLocs);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/LocatedBlock.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LocatedBlock.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/LocatedBlock.java"
      }
    },
    "ab934e85947dcf2092050023909dd81ae274ff45": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7647. DatanodeManager.sortLocatedBlocks sorts DatanodeInfos but not StorageIDs. (Contributed by Milan Desai)\n",
      "commitDate": "09/02/15 12:17 PM",
      "commitName": "ab934e85947dcf2092050023909dd81ae274ff45",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "27/10/14 9:38 AM",
      "commitNameOld": "463aec11718e47d4aabb86a7a539cb973460aae6",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 105.15,
      "commitsBetweenForRepo": 772,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   public void addCachedLoc(DatanodeInfo loc) {\n     List\u003cDatanodeInfo\u003e cachedList \u003d Lists.newArrayList(cachedLocs);\n     if (cachedList.contains(loc)) {\n       return;\n     }\n     // Try to re-use a DatanodeInfo already in loc\n-    for (int i\u003d0; i\u003clocs.length; i++) {\n-      if (locs[i].equals(loc)) {\n-        cachedList.add(locs[i]);\n+    for (DatanodeInfoWithStorage di : locs) {\n+      if (loc.equals(di)) {\n+        cachedList.add(di);\n         cachedLocs \u003d cachedList.toArray(cachedLocs);\n         return;\n       }\n     }\n     // Not present in loc, add it and go\n     cachedList.add(loc);\n     cachedLocs \u003d cachedList.toArray(cachedLocs);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void addCachedLoc(DatanodeInfo loc) {\n    List\u003cDatanodeInfo\u003e cachedList \u003d Lists.newArrayList(cachedLocs);\n    if (cachedList.contains(loc)) {\n      return;\n    }\n    // Try to re-use a DatanodeInfo already in loc\n    for (DatanodeInfoWithStorage di : locs) {\n      if (loc.equals(di)) {\n        cachedList.add(di);\n        cachedLocs \u003d cachedList.toArray(cachedLocs);\n        return;\n      }\n    }\n    // Not present in loc, add it and go\n    cachedList.add(loc);\n    cachedLocs \u003d cachedList.toArray(cachedLocs);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LocatedBlock.java",
      "extendedDetails": {}
    },
    "3fc8792b5c75fca9fc4f6cf4b95fb2927c62e624": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5304. Expose if a block replica is cached in getFileBlockLocations. (Contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1530802 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/10/13 2:30 PM",
      "commitName": "3fc8792b5c75fca9fc4f6cf4b95fb2927c62e624",
      "commitAuthor": "Andrew Wang",
      "diff": "@@ -0,0 +1,17 @@\n+  public void addCachedLoc(DatanodeInfo loc) {\n+    List\u003cDatanodeInfo\u003e cachedList \u003d Lists.newArrayList(cachedLocs);\n+    if (cachedList.contains(loc)) {\n+      return;\n+    }\n+    // Try to re-use a DatanodeInfo already in loc\n+    for (int i\u003d0; i\u003clocs.length; i++) {\n+      if (locs[i].equals(loc)) {\n+        cachedList.add(locs[i]);\n+        cachedLocs \u003d cachedList.toArray(cachedLocs);\n+        return;\n+      }\n+    }\n+    // Not present in loc, add it and go\n+    cachedList.add(loc);\n+    cachedLocs \u003d cachedList.toArray(cachedLocs);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void addCachedLoc(DatanodeInfo loc) {\n    List\u003cDatanodeInfo\u003e cachedList \u003d Lists.newArrayList(cachedLocs);\n    if (cachedList.contains(loc)) {\n      return;\n    }\n    // Try to re-use a DatanodeInfo already in loc\n    for (int i\u003d0; i\u003clocs.length; i++) {\n      if (locs[i].equals(loc)) {\n        cachedList.add(locs[i]);\n        cachedLocs \u003d cachedList.toArray(cachedLocs);\n        return;\n      }\n    }\n    // Not present in loc, add it and go\n    cachedList.add(loc);\n    cachedLocs \u003d cachedList.toArray(cachedLocs);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LocatedBlock.java"
    }
  }
}