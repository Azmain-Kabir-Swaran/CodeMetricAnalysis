{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockReceiver.java",
  "functionName": "run",
  "functionId": "run",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
  "functionStartLine": 1370,
  "functionEndLine": 1513,
  "numCommitsSeen": 111,
  "timeTaken": 9993,
  "changeHistory": [
    "6e04b00df1bf4f0a45571c9fc4361e4e8a05f7ee",
    "eb73ba6ed5f7c5500cc0ef36ca22aae4e71046fa",
    "603f3ef1386048111940b66f3a0750ab84d0588f",
    "c25817159af17753b398956cfe6ff14984801b01",
    "99e5204ff5326430558b6f6fd9da7c44654c15d7",
    "c4980a2f343778544ca20ebea1338651793ea0d9",
    "b7f4a3156c0f5c600816c469637237ba6c9b330c",
    "7b0f9bb2583cd9b7274f1e31c173c1c6a7ce467b",
    "33518e561368c372bf9254b6b55a9b0c499fbd4d",
    "e9459baec5a46651c156fbae5f8f3c9cc8325ef0",
    "1c6b5d2b5841e5219a98937088cde4ae63869f80",
    "98a692fd6361365db4afb9523a5d83ee32774112",
    "7e56bfe40589a1aa9b5ef20b342e421823cd0592",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
    "e0ef844280b98dc699ed3f9d948b83828bb8d297",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "6e04b00df1bf4f0a45571c9fc4361e4e8a05f7ee": "Ybodychange",
    "eb73ba6ed5f7c5500cc0ef36ca22aae4e71046fa": "Ybodychange",
    "603f3ef1386048111940b66f3a0750ab84d0588f": "Ybodychange",
    "c25817159af17753b398956cfe6ff14984801b01": "Ybodychange",
    "99e5204ff5326430558b6f6fd9da7c44654c15d7": "Ybodychange",
    "c4980a2f343778544ca20ebea1338651793ea0d9": "Ybodychange",
    "b7f4a3156c0f5c600816c469637237ba6c9b330c": "Ybodychange",
    "7b0f9bb2583cd9b7274f1e31c173c1c6a7ce467b": "Ybodychange",
    "33518e561368c372bf9254b6b55a9b0c499fbd4d": "Ybodychange",
    "e9459baec5a46651c156fbae5f8f3c9cc8325ef0": "Ybodychange",
    "1c6b5d2b5841e5219a98937088cde4ae63869f80": "Ybodychange",
    "98a692fd6361365db4afb9523a5d83ee32774112": "Ybodychange",
    "7e56bfe40589a1aa9b5ef20b342e421823cd0592": "Ybodychange",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": "Ybodychange",
    "e0ef844280b98dc699ed3f9d948b83828bb8d297": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6e04b00df1bf4f0a45571c9fc4361e4e8a05f7ee": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12288. Fix DataNode\u0027s xceiver count calculation. Contributed by Lisheng Sun.\n",
      "commitDate": "23/05/20 9:58 AM",
      "commitName": "6e04b00df1bf4f0a45571c9fc4361e4e8a05f7ee",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "04/11/19 9:40 AM",
      "commitNameOld": "eb73ba6ed5f7c5500cc0ef36ca22aae4e71046fa",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 200.97,
      "commitsBetweenForRepo": 702,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,140 +1,144 @@\n     public void run() {\n+      datanode.metrics.incrDataNodePacketResponderCount();\n       boolean lastPacketInBlock \u003d false;\n       final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n       while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n         long totalAckTimeNanos \u003d 0;\n         boolean isInterrupted \u003d false;\n         try {\n           Packet pkt \u003d null;\n           long expected \u003d -2;\n           PipelineAck ack \u003d new PipelineAck();\n           long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n           long ackRecvNanoTime \u003d 0;\n           try {\n             if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n               DataNodeFaultInjector.get().failPipeline(replicaInfo, mirrorAddr);\n               // read an ack from downstream datanode\n               ack.readFields(downstreamIn);\n               ackRecvNanoTime \u003d System.nanoTime();\n               if (LOG.isDebugEnabled()) {\n                 LOG.debug(myString + \" got \" + ack);\n               }\n               // Process an OOB ACK.\n               Status oobStatus \u003d ack.getOOBStatus();\n               if (oobStatus !\u003d null) {\n                 LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                 sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                     PipelineAck.combineHeader(datanode.getECN(),\n                       Status.SUCCESS));\n                 continue;\n               }\n               seqno \u003d ack.getSeqno();\n             }\n             if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                 || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n               pkt \u003d waitForAckHead(seqno);\n               if (!isRunning()) {\n                 break;\n               }\n               expected \u003d pkt.seqno;\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                   \u0026\u0026 seqno !\u003d expected) {\n                 throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                     + \", received\u003d\" + seqno);\n               }\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                 // The total ack time includes the ack times of downstream\n                 // nodes.\n                 // The value is 0 if this responder doesn\u0027t have a downstream\n                 // DN in the pipeline.\n                 totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                 // Report the elapsed time from ack send to ack receive minus\n                 // the downstream ack time.\n                 long ackTimeNanos \u003d totalAckTimeNanos\n                     - ack.getDownstreamAckTimeNanos();\n                 if (ackTimeNanos \u003c 0) {\n                   if (LOG.isDebugEnabled()) {\n                     LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                         + \"ns.\");\n                   }\n                 } else {\n                   datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                 }\n               }\n               lastPacketInBlock \u003d pkt.lastPacketInBlock;\n             }\n           } catch (InterruptedException ine) {\n             isInterrupted \u003d true;\n           } catch (IOException ioe) {\n             if (Thread.interrupted()) {\n               isInterrupted \u003d true;\n             } else if (ioe instanceof EOFException \u0026\u0026 !packetSentInTime()) {\n               // The downstream error was caused by upstream including this\n               // node not sending packet in time. Let the upstream determine\n               // who is at fault.  If the immediate upstream node thinks it\n               // has sent a packet in time, this node will be reported as bad.\n               // Otherwise, the upstream node will propagate the error up by\n               // closing the connection.\n               LOG.warn(\"The downstream error might be due to congestion in \" +\n                   \"upstream including this node. Propagating the error: \",\n                   ioe);\n               throw ioe;\n             } else {\n               // continue to run even if can not read from mirror\n               // notify client of the error\n               // and wait for the client to shut down the pipeline\n               mirrorError \u003d true;\n               LOG.info(myString, ioe);\n             }\n           }\n \n           if (Thread.interrupted() || isInterrupted) {\n             /*\n              * The receiver thread cancelled this thread. We could also check\n              * any other status updates from the receiver thread (e.g. if it is\n              * ok to write to replyOut). It is prudent to not send any more\n              * status back to the client because this datanode has a problem.\n              * The upstream datanode will detect that this datanode is bad, and\n              * rightly so.\n              *\n              * The receiver thread can also interrupt this thread for sending\n              * an out-of-band response upstream.\n              */\n             LOG.info(myString + \": Thread is interrupted.\");\n             running \u003d false;\n             continue;\n           }\n \n           if (lastPacketInBlock) {\n             // Finalize the block and close the block file\n             finalizeBlock(startTime);\n           }\n \n           Status myStatus \u003d pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS;\n           sendAckUpstream(ack, expected, totalAckTimeNanos,\n             (pkt !\u003d null ? pkt.offsetInBlock : 0),\n             PipelineAck.combineHeader(datanode.getECN(), myStatus));\n           if (pkt !\u003d null) {\n             // remove the packet from the ack queue\n             removeAckHead();\n           }\n         } catch (IOException e) {\n           LOG.warn(\"IOException in PacketResponder.run(): \", e);\n           if (running) {\n             // Volume error check moved to FileIoProvider\n             LOG.info(myString, e);\n             running \u003d false;\n             if (!Thread.interrupted()) { // failure not caused by interruption\n               receiverThread.interrupt();\n             }\n           }\n         } catch (Throwable e) {\n           if (running) {\n             LOG.info(myString, e);\n             running \u003d false;\n             receiverThread.interrupt();\n           }\n         }\n       }\n+      // Any exception will be caught and processed in the previous loop, so we\n+      // will always arrive here when the thread exiting\n+      datanode.metrics.decrDataNodePacketResponderCount();\n       LOG.info(myString + \" terminating\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      datanode.metrics.incrDataNodePacketResponderCount();\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n        long totalAckTimeNanos \u003d 0;\n        boolean isInterrupted \u003d false;\n        try {\n          Packet pkt \u003d null;\n          long expected \u003d -2;\n          PipelineAck ack \u003d new PipelineAck();\n          long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n          long ackRecvNanoTime \u003d 0;\n          try {\n            if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n              DataNodeFaultInjector.get().failPipeline(replicaInfo, mirrorAddr);\n              // read an ack from downstream datanode\n              ack.readFields(downstreamIn);\n              ackRecvNanoTime \u003d System.nanoTime();\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(myString + \" got \" + ack);\n              }\n              // Process an OOB ACK.\n              Status oobStatus \u003d ack.getOOBStatus();\n              if (oobStatus !\u003d null) {\n                LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                    PipelineAck.combineHeader(datanode.getECN(),\n                      Status.SUCCESS));\n                continue;\n              }\n              seqno \u003d ack.getSeqno();\n            }\n            if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n              pkt \u003d waitForAckHead(seqno);\n              if (!isRunning()) {\n                break;\n              }\n              expected \u003d pkt.seqno;\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                  \u0026\u0026 seqno !\u003d expected) {\n                throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                    + \", received\u003d\" + seqno);\n              }\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                // The total ack time includes the ack times of downstream\n                // nodes.\n                // The value is 0 if this responder doesn\u0027t have a downstream\n                // DN in the pipeline.\n                totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                // Report the elapsed time from ack send to ack receive minus\n                // the downstream ack time.\n                long ackTimeNanos \u003d totalAckTimeNanos\n                    - ack.getDownstreamAckTimeNanos();\n                if (ackTimeNanos \u003c 0) {\n                  if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                        + \"ns.\");\n                  }\n                } else {\n                  datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                }\n              }\n              lastPacketInBlock \u003d pkt.lastPacketInBlock;\n            }\n          } catch (InterruptedException ine) {\n            isInterrupted \u003d true;\n          } catch (IOException ioe) {\n            if (Thread.interrupted()) {\n              isInterrupted \u003d true;\n            } else if (ioe instanceof EOFException \u0026\u0026 !packetSentInTime()) {\n              // The downstream error was caused by upstream including this\n              // node not sending packet in time. Let the upstream determine\n              // who is at fault.  If the immediate upstream node thinks it\n              // has sent a packet in time, this node will be reported as bad.\n              // Otherwise, the upstream node will propagate the error up by\n              // closing the connection.\n              LOG.warn(\"The downstream error might be due to congestion in \" +\n                  \"upstream including this node. Propagating the error: \",\n                  ioe);\n              throw ioe;\n            } else {\n              // continue to run even if can not read from mirror\n              // notify client of the error\n              // and wait for the client to shut down the pipeline\n              mirrorError \u003d true;\n              LOG.info(myString, ioe);\n            }\n          }\n\n          if (Thread.interrupted() || isInterrupted) {\n            /*\n             * The receiver thread cancelled this thread. We could also check\n             * any other status updates from the receiver thread (e.g. if it is\n             * ok to write to replyOut). It is prudent to not send any more\n             * status back to the client because this datanode has a problem.\n             * The upstream datanode will detect that this datanode is bad, and\n             * rightly so.\n             *\n             * The receiver thread can also interrupt this thread for sending\n             * an out-of-band response upstream.\n             */\n            LOG.info(myString + \": Thread is interrupted.\");\n            running \u003d false;\n            continue;\n          }\n\n          if (lastPacketInBlock) {\n            // Finalize the block and close the block file\n            finalizeBlock(startTime);\n          }\n\n          Status myStatus \u003d pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS;\n          sendAckUpstream(ack, expected, totalAckTimeNanos,\n            (pkt !\u003d null ? pkt.offsetInBlock : 0),\n            PipelineAck.combineHeader(datanode.getECN(), myStatus));\n          if (pkt !\u003d null) {\n            // remove the packet from the ack queue\n            removeAckHead();\n          }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in PacketResponder.run(): \", e);\n          if (running) {\n            // Volume error check moved to FileIoProvider\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      // Any exception will be caught and processed in the previous loop, so we\n      // will always arrive here when the thread exiting\n      datanode.metrics.decrDataNodePacketResponderCount();\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "eb73ba6ed5f7c5500cc0ef36ca22aae4e71046fa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14945. Revise PacketResponder\u0027s log. Contributed by Xudong Cao.\n",
      "commitDate": "04/11/19 9:40 AM",
      "commitName": "eb73ba6ed5f7c5500cc0ef36ca22aae4e71046fa",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "06/06/19 11:59 AM",
      "commitNameOld": "e1dfc060f8f0247f97127c75c9284a068fc93907",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 150.95,
      "commitsBetweenForRepo": 1176,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,140 +1,140 @@\n     public void run() {\n       boolean lastPacketInBlock \u003d false;\n       final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n       while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n         long totalAckTimeNanos \u003d 0;\n         boolean isInterrupted \u003d false;\n         try {\n           Packet pkt \u003d null;\n           long expected \u003d -2;\n           PipelineAck ack \u003d new PipelineAck();\n           long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n           long ackRecvNanoTime \u003d 0;\n           try {\n             if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n               DataNodeFaultInjector.get().failPipeline(replicaInfo, mirrorAddr);\n               // read an ack from downstream datanode\n               ack.readFields(downstreamIn);\n               ackRecvNanoTime \u003d System.nanoTime();\n               if (LOG.isDebugEnabled()) {\n                 LOG.debug(myString + \" got \" + ack);\n               }\n               // Process an OOB ACK.\n               Status oobStatus \u003d ack.getOOBStatus();\n               if (oobStatus !\u003d null) {\n                 LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                 sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                     PipelineAck.combineHeader(datanode.getECN(),\n                       Status.SUCCESS));\n                 continue;\n               }\n               seqno \u003d ack.getSeqno();\n             }\n             if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                 || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n               pkt \u003d waitForAckHead(seqno);\n               if (!isRunning()) {\n                 break;\n               }\n               expected \u003d pkt.seqno;\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                   \u0026\u0026 seqno !\u003d expected) {\n                 throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                     + \", received\u003d\" + seqno);\n               }\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                 // The total ack time includes the ack times of downstream\n                 // nodes.\n                 // The value is 0 if this responder doesn\u0027t have a downstream\n                 // DN in the pipeline.\n                 totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                 // Report the elapsed time from ack send to ack receive minus\n                 // the downstream ack time.\n                 long ackTimeNanos \u003d totalAckTimeNanos\n                     - ack.getDownstreamAckTimeNanos();\n                 if (ackTimeNanos \u003c 0) {\n                   if (LOG.isDebugEnabled()) {\n                     LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                         + \"ns.\");\n                   }\n                 } else {\n                   datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                 }\n               }\n               lastPacketInBlock \u003d pkt.lastPacketInBlock;\n             }\n           } catch (InterruptedException ine) {\n             isInterrupted \u003d true;\n           } catch (IOException ioe) {\n             if (Thread.interrupted()) {\n               isInterrupted \u003d true;\n             } else if (ioe instanceof EOFException \u0026\u0026 !packetSentInTime()) {\n               // The downstream error was caused by upstream including this\n               // node not sending packet in time. Let the upstream determine\n               // who is at fault.  If the immediate upstream node thinks it\n               // has sent a packet in time, this node will be reported as bad.\n               // Otherwise, the upstream node will propagate the error up by\n               // closing the connection.\n               LOG.warn(\"The downstream error might be due to congestion in \" +\n                   \"upstream including this node. Propagating the error: \",\n                   ioe);\n               throw ioe;\n             } else {\n               // continue to run even if can not read from mirror\n               // notify client of the error\n               // and wait for the client to shut down the pipeline\n               mirrorError \u003d true;\n               LOG.info(myString, ioe);\n             }\n           }\n \n           if (Thread.interrupted() || isInterrupted) {\n             /*\n              * The receiver thread cancelled this thread. We could also check\n              * any other status updates from the receiver thread (e.g. if it is\n              * ok to write to replyOut). It is prudent to not send any more\n              * status back to the client because this datanode has a problem.\n              * The upstream datanode will detect that this datanode is bad, and\n              * rightly so.\n              *\n              * The receiver thread can also interrupt this thread for sending\n              * an out-of-band response upstream.\n              */\n             LOG.info(myString + \": Thread is interrupted.\");\n             running \u003d false;\n             continue;\n           }\n \n           if (lastPacketInBlock) {\n             // Finalize the block and close the block file\n             finalizeBlock(startTime);\n           }\n \n           Status myStatus \u003d pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS;\n           sendAckUpstream(ack, expected, totalAckTimeNanos,\n             (pkt !\u003d null ? pkt.offsetInBlock : 0),\n             PipelineAck.combineHeader(datanode.getECN(), myStatus));\n           if (pkt !\u003d null) {\n             // remove the packet from the ack queue\n             removeAckHead();\n           }\n         } catch (IOException e) {\n-          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n+          LOG.warn(\"IOException in PacketResponder.run(): \", e);\n           if (running) {\n             // Volume error check moved to FileIoProvider\n             LOG.info(myString, e);\n             running \u003d false;\n             if (!Thread.interrupted()) { // failure not caused by interruption\n               receiverThread.interrupt();\n             }\n           }\n         } catch (Throwable e) {\n           if (running) {\n             LOG.info(myString, e);\n             running \u003d false;\n             receiverThread.interrupt();\n           }\n         }\n       }\n       LOG.info(myString + \" terminating\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n        long totalAckTimeNanos \u003d 0;\n        boolean isInterrupted \u003d false;\n        try {\n          Packet pkt \u003d null;\n          long expected \u003d -2;\n          PipelineAck ack \u003d new PipelineAck();\n          long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n          long ackRecvNanoTime \u003d 0;\n          try {\n            if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n              DataNodeFaultInjector.get().failPipeline(replicaInfo, mirrorAddr);\n              // read an ack from downstream datanode\n              ack.readFields(downstreamIn);\n              ackRecvNanoTime \u003d System.nanoTime();\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(myString + \" got \" + ack);\n              }\n              // Process an OOB ACK.\n              Status oobStatus \u003d ack.getOOBStatus();\n              if (oobStatus !\u003d null) {\n                LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                    PipelineAck.combineHeader(datanode.getECN(),\n                      Status.SUCCESS));\n                continue;\n              }\n              seqno \u003d ack.getSeqno();\n            }\n            if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n              pkt \u003d waitForAckHead(seqno);\n              if (!isRunning()) {\n                break;\n              }\n              expected \u003d pkt.seqno;\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                  \u0026\u0026 seqno !\u003d expected) {\n                throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                    + \", received\u003d\" + seqno);\n              }\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                // The total ack time includes the ack times of downstream\n                // nodes.\n                // The value is 0 if this responder doesn\u0027t have a downstream\n                // DN in the pipeline.\n                totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                // Report the elapsed time from ack send to ack receive minus\n                // the downstream ack time.\n                long ackTimeNanos \u003d totalAckTimeNanos\n                    - ack.getDownstreamAckTimeNanos();\n                if (ackTimeNanos \u003c 0) {\n                  if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                        + \"ns.\");\n                  }\n                } else {\n                  datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                }\n              }\n              lastPacketInBlock \u003d pkt.lastPacketInBlock;\n            }\n          } catch (InterruptedException ine) {\n            isInterrupted \u003d true;\n          } catch (IOException ioe) {\n            if (Thread.interrupted()) {\n              isInterrupted \u003d true;\n            } else if (ioe instanceof EOFException \u0026\u0026 !packetSentInTime()) {\n              // The downstream error was caused by upstream including this\n              // node not sending packet in time. Let the upstream determine\n              // who is at fault.  If the immediate upstream node thinks it\n              // has sent a packet in time, this node will be reported as bad.\n              // Otherwise, the upstream node will propagate the error up by\n              // closing the connection.\n              LOG.warn(\"The downstream error might be due to congestion in \" +\n                  \"upstream including this node. Propagating the error: \",\n                  ioe);\n              throw ioe;\n            } else {\n              // continue to run even if can not read from mirror\n              // notify client of the error\n              // and wait for the client to shut down the pipeline\n              mirrorError \u003d true;\n              LOG.info(myString, ioe);\n            }\n          }\n\n          if (Thread.interrupted() || isInterrupted) {\n            /*\n             * The receiver thread cancelled this thread. We could also check\n             * any other status updates from the receiver thread (e.g. if it is\n             * ok to write to replyOut). It is prudent to not send any more\n             * status back to the client because this datanode has a problem.\n             * The upstream datanode will detect that this datanode is bad, and\n             * rightly so.\n             *\n             * The receiver thread can also interrupt this thread for sending\n             * an out-of-band response upstream.\n             */\n            LOG.info(myString + \": Thread is interrupted.\");\n            running \u003d false;\n            continue;\n          }\n\n          if (lastPacketInBlock) {\n            // Finalize the block and close the block file\n            finalizeBlock(startTime);\n          }\n\n          Status myStatus \u003d pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS;\n          sendAckUpstream(ack, expected, totalAckTimeNanos,\n            (pkt !\u003d null ? pkt.offsetInBlock : 0),\n            PipelineAck.combineHeader(datanode.getECN(), myStatus));\n          if (pkt !\u003d null) {\n            // remove the packet from the ack queue\n            removeAckHead();\n          }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in PacketResponder.run(): \", e);\n          if (running) {\n            // Volume error check moved to FileIoProvider\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "603f3ef1386048111940b66f3a0750ab84d0588f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11274. Datanode should only check the failed volume upon IO errors. Contributed by Xiaoyu Yao.\n",
      "commitDate": "28/12/16 10:08 PM",
      "commitName": "603f3ef1386048111940b66f3a0750ab84d0588f",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "22/12/16 11:46 PM",
      "commitNameOld": "4e9029653dfa7a803d73c173cb7044f7e0dc1eb1",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 5.93,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,140 +1,140 @@\n     public void run() {\n       boolean lastPacketInBlock \u003d false;\n       final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n       while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n         long totalAckTimeNanos \u003d 0;\n         boolean isInterrupted \u003d false;\n         try {\n           Packet pkt \u003d null;\n           long expected \u003d -2;\n           PipelineAck ack \u003d new PipelineAck();\n           long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n           long ackRecvNanoTime \u003d 0;\n           try {\n             if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n               DataNodeFaultInjector.get().failPipeline(replicaInfo, mirrorAddr);\n               // read an ack from downstream datanode\n               ack.readFields(downstreamIn);\n               ackRecvNanoTime \u003d System.nanoTime();\n               if (LOG.isDebugEnabled()) {\n                 LOG.debug(myString + \" got \" + ack);\n               }\n               // Process an OOB ACK.\n               Status oobStatus \u003d ack.getOOBStatus();\n               if (oobStatus !\u003d null) {\n                 LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                 sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                     PipelineAck.combineHeader(datanode.getECN(),\n                       Status.SUCCESS));\n                 continue;\n               }\n               seqno \u003d ack.getSeqno();\n             }\n             if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                 || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n               pkt \u003d waitForAckHead(seqno);\n               if (!isRunning()) {\n                 break;\n               }\n               expected \u003d pkt.seqno;\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                   \u0026\u0026 seqno !\u003d expected) {\n                 throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                     + \", received\u003d\" + seqno);\n               }\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                 // The total ack time includes the ack times of downstream\n                 // nodes.\n                 // The value is 0 if this responder doesn\u0027t have a downstream\n                 // DN in the pipeline.\n                 totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                 // Report the elapsed time from ack send to ack receive minus\n                 // the downstream ack time.\n                 long ackTimeNanos \u003d totalAckTimeNanos\n                     - ack.getDownstreamAckTimeNanos();\n                 if (ackTimeNanos \u003c 0) {\n                   if (LOG.isDebugEnabled()) {\n                     LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                         + \"ns.\");\n                   }\n                 } else {\n                   datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                 }\n               }\n               lastPacketInBlock \u003d pkt.lastPacketInBlock;\n             }\n           } catch (InterruptedException ine) {\n             isInterrupted \u003d true;\n           } catch (IOException ioe) {\n             if (Thread.interrupted()) {\n               isInterrupted \u003d true;\n             } else if (ioe instanceof EOFException \u0026\u0026 !packetSentInTime()) {\n               // The downstream error was caused by upstream including this\n               // node not sending packet in time. Let the upstream determine\n               // who is at fault.  If the immediate upstream node thinks it\n               // has sent a packet in time, this node will be reported as bad.\n               // Otherwise, the upstream node will propagate the error up by\n               // closing the connection.\n               LOG.warn(\"The downstream error might be due to congestion in \" +\n                   \"upstream including this node. Propagating the error: \",\n                   ioe);\n               throw ioe;\n             } else {\n               // continue to run even if can not read from mirror\n               // notify client of the error\n               // and wait for the client to shut down the pipeline\n               mirrorError \u003d true;\n               LOG.info(myString, ioe);\n             }\n           }\n \n           if (Thread.interrupted() || isInterrupted) {\n             /*\n              * The receiver thread cancelled this thread. We could also check\n              * any other status updates from the receiver thread (e.g. if it is\n              * ok to write to replyOut). It is prudent to not send any more\n              * status back to the client because this datanode has a problem.\n              * The upstream datanode will detect that this datanode is bad, and\n              * rightly so.\n              *\n              * The receiver thread can also interrupt this thread for sending\n              * an out-of-band response upstream.\n              */\n             LOG.info(myString + \": Thread is interrupted.\");\n             running \u003d false;\n             continue;\n           }\n \n           if (lastPacketInBlock) {\n             // Finalize the block and close the block file\n             finalizeBlock(startTime);\n           }\n \n           Status myStatus \u003d pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS;\n           sendAckUpstream(ack, expected, totalAckTimeNanos,\n             (pkt !\u003d null ? pkt.offsetInBlock : 0),\n             PipelineAck.combineHeader(datanode.getECN(), myStatus));\n           if (pkt !\u003d null) {\n             // remove the packet from the ack queue\n             removeAckHead();\n           }\n         } catch (IOException e) {\n           LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n           if (running) {\n-            datanode.checkDiskErrorAsync();\n+            // Volume error check moved to FileIoProvider\n             LOG.info(myString, e);\n             running \u003d false;\n             if (!Thread.interrupted()) { // failure not caused by interruption\n               receiverThread.interrupt();\n             }\n           }\n         } catch (Throwable e) {\n           if (running) {\n             LOG.info(myString, e);\n             running \u003d false;\n             receiverThread.interrupt();\n           }\n         }\n       }\n       LOG.info(myString + \" terminating\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n        long totalAckTimeNanos \u003d 0;\n        boolean isInterrupted \u003d false;\n        try {\n          Packet pkt \u003d null;\n          long expected \u003d -2;\n          PipelineAck ack \u003d new PipelineAck();\n          long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n          long ackRecvNanoTime \u003d 0;\n          try {\n            if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n              DataNodeFaultInjector.get().failPipeline(replicaInfo, mirrorAddr);\n              // read an ack from downstream datanode\n              ack.readFields(downstreamIn);\n              ackRecvNanoTime \u003d System.nanoTime();\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(myString + \" got \" + ack);\n              }\n              // Process an OOB ACK.\n              Status oobStatus \u003d ack.getOOBStatus();\n              if (oobStatus !\u003d null) {\n                LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                    PipelineAck.combineHeader(datanode.getECN(),\n                      Status.SUCCESS));\n                continue;\n              }\n              seqno \u003d ack.getSeqno();\n            }\n            if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n              pkt \u003d waitForAckHead(seqno);\n              if (!isRunning()) {\n                break;\n              }\n              expected \u003d pkt.seqno;\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                  \u0026\u0026 seqno !\u003d expected) {\n                throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                    + \", received\u003d\" + seqno);\n              }\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                // The total ack time includes the ack times of downstream\n                // nodes.\n                // The value is 0 if this responder doesn\u0027t have a downstream\n                // DN in the pipeline.\n                totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                // Report the elapsed time from ack send to ack receive minus\n                // the downstream ack time.\n                long ackTimeNanos \u003d totalAckTimeNanos\n                    - ack.getDownstreamAckTimeNanos();\n                if (ackTimeNanos \u003c 0) {\n                  if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                        + \"ns.\");\n                  }\n                } else {\n                  datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                }\n              }\n              lastPacketInBlock \u003d pkt.lastPacketInBlock;\n            }\n          } catch (InterruptedException ine) {\n            isInterrupted \u003d true;\n          } catch (IOException ioe) {\n            if (Thread.interrupted()) {\n              isInterrupted \u003d true;\n            } else if (ioe instanceof EOFException \u0026\u0026 !packetSentInTime()) {\n              // The downstream error was caused by upstream including this\n              // node not sending packet in time. Let the upstream determine\n              // who is at fault.  If the immediate upstream node thinks it\n              // has sent a packet in time, this node will be reported as bad.\n              // Otherwise, the upstream node will propagate the error up by\n              // closing the connection.\n              LOG.warn(\"The downstream error might be due to congestion in \" +\n                  \"upstream including this node. Propagating the error: \",\n                  ioe);\n              throw ioe;\n            } else {\n              // continue to run even if can not read from mirror\n              // notify client of the error\n              // and wait for the client to shut down the pipeline\n              mirrorError \u003d true;\n              LOG.info(myString, ioe);\n            }\n          }\n\n          if (Thread.interrupted() || isInterrupted) {\n            /*\n             * The receiver thread cancelled this thread. We could also check\n             * any other status updates from the receiver thread (e.g. if it is\n             * ok to write to replyOut). It is prudent to not send any more\n             * status back to the client because this datanode has a problem.\n             * The upstream datanode will detect that this datanode is bad, and\n             * rightly so.\n             *\n             * The receiver thread can also interrupt this thread for sending\n             * an out-of-band response upstream.\n             */\n            LOG.info(myString + \": Thread is interrupted.\");\n            running \u003d false;\n            continue;\n          }\n\n          if (lastPacketInBlock) {\n            // Finalize the block and close the block file\n            finalizeBlock(startTime);\n          }\n\n          Status myStatus \u003d pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS;\n          sendAckUpstream(ack, expected, totalAckTimeNanos,\n            (pkt !\u003d null ? pkt.offsetInBlock : 0),\n            PipelineAck.combineHeader(datanode.getECN(), myStatus));\n          if (pkt !\u003d null) {\n            // remove the packet from the ack queue\n            removeAckHead();\n          }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n          if (running) {\n            // Volume error check moved to FileIoProvider\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "c25817159af17753b398956cfe6ff14984801b01": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10652. Add a unit test for HDFS-4660. Contributed by Vinayakumar B., Wei-Chiu Chuang, Yongjun Zhang.\n",
      "commitDate": "27/08/16 10:51 PM",
      "commitName": "c25817159af17753b398956cfe6ff14984801b01",
      "commitAuthor": "Yongjun Zhang",
      "commitDateOld": "27/07/16 1:58 PM",
      "commitNameOld": "eb7ff0c9927131f4a797148b970a95a1abf7d847",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 31.37,
      "commitsBetweenForRepo": 230,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,139 +1,140 @@\n     public void run() {\n       boolean lastPacketInBlock \u003d false;\n       final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n       while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n         long totalAckTimeNanos \u003d 0;\n         boolean isInterrupted \u003d false;\n         try {\n           Packet pkt \u003d null;\n           long expected \u003d -2;\n           PipelineAck ack \u003d new PipelineAck();\n           long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n           long ackRecvNanoTime \u003d 0;\n           try {\n             if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n+              DataNodeFaultInjector.get().failPipeline(replicaInfo, mirrorAddr);\n               // read an ack from downstream datanode\n               ack.readFields(downstreamIn);\n               ackRecvNanoTime \u003d System.nanoTime();\n               if (LOG.isDebugEnabled()) {\n                 LOG.debug(myString + \" got \" + ack);\n               }\n               // Process an OOB ACK.\n               Status oobStatus \u003d ack.getOOBStatus();\n               if (oobStatus !\u003d null) {\n                 LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                 sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                     PipelineAck.combineHeader(datanode.getECN(),\n                       Status.SUCCESS));\n                 continue;\n               }\n               seqno \u003d ack.getSeqno();\n             }\n             if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                 || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n               pkt \u003d waitForAckHead(seqno);\n               if (!isRunning()) {\n                 break;\n               }\n               expected \u003d pkt.seqno;\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                   \u0026\u0026 seqno !\u003d expected) {\n                 throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                     + \", received\u003d\" + seqno);\n               }\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                 // The total ack time includes the ack times of downstream\n                 // nodes.\n                 // The value is 0 if this responder doesn\u0027t have a downstream\n                 // DN in the pipeline.\n                 totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                 // Report the elapsed time from ack send to ack receive minus\n                 // the downstream ack time.\n                 long ackTimeNanos \u003d totalAckTimeNanos\n                     - ack.getDownstreamAckTimeNanos();\n                 if (ackTimeNanos \u003c 0) {\n                   if (LOG.isDebugEnabled()) {\n                     LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                         + \"ns.\");\n                   }\n                 } else {\n                   datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                 }\n               }\n               lastPacketInBlock \u003d pkt.lastPacketInBlock;\n             }\n           } catch (InterruptedException ine) {\n             isInterrupted \u003d true;\n           } catch (IOException ioe) {\n             if (Thread.interrupted()) {\n               isInterrupted \u003d true;\n             } else if (ioe instanceof EOFException \u0026\u0026 !packetSentInTime()) {\n               // The downstream error was caused by upstream including this\n               // node not sending packet in time. Let the upstream determine\n               // who is at fault.  If the immediate upstream node thinks it\n               // has sent a packet in time, this node will be reported as bad.\n               // Otherwise, the upstream node will propagate the error up by\n               // closing the connection.\n               LOG.warn(\"The downstream error might be due to congestion in \" +\n                   \"upstream including this node. Propagating the error: \",\n                   ioe);\n               throw ioe;\n             } else {\n               // continue to run even if can not read from mirror\n               // notify client of the error\n               // and wait for the client to shut down the pipeline\n               mirrorError \u003d true;\n               LOG.info(myString, ioe);\n             }\n           }\n \n           if (Thread.interrupted() || isInterrupted) {\n             /*\n              * The receiver thread cancelled this thread. We could also check\n              * any other status updates from the receiver thread (e.g. if it is\n              * ok to write to replyOut). It is prudent to not send any more\n              * status back to the client because this datanode has a problem.\n              * The upstream datanode will detect that this datanode is bad, and\n              * rightly so.\n              *\n              * The receiver thread can also interrupt this thread for sending\n              * an out-of-band response upstream.\n              */\n             LOG.info(myString + \": Thread is interrupted.\");\n             running \u003d false;\n             continue;\n           }\n \n           if (lastPacketInBlock) {\n             // Finalize the block and close the block file\n             finalizeBlock(startTime);\n           }\n \n           Status myStatus \u003d pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS;\n           sendAckUpstream(ack, expected, totalAckTimeNanos,\n             (pkt !\u003d null ? pkt.offsetInBlock : 0),\n             PipelineAck.combineHeader(datanode.getECN(), myStatus));\n           if (pkt !\u003d null) {\n             // remove the packet from the ack queue\n             removeAckHead();\n           }\n         } catch (IOException e) {\n           LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n           if (running) {\n             datanode.checkDiskErrorAsync();\n             LOG.info(myString, e);\n             running \u003d false;\n             if (!Thread.interrupted()) { // failure not caused by interruption\n               receiverThread.interrupt();\n             }\n           }\n         } catch (Throwable e) {\n           if (running) {\n             LOG.info(myString, e);\n             running \u003d false;\n             receiverThread.interrupt();\n           }\n         }\n       }\n       LOG.info(myString + \" terminating\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n        long totalAckTimeNanos \u003d 0;\n        boolean isInterrupted \u003d false;\n        try {\n          Packet pkt \u003d null;\n          long expected \u003d -2;\n          PipelineAck ack \u003d new PipelineAck();\n          long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n          long ackRecvNanoTime \u003d 0;\n          try {\n            if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n              DataNodeFaultInjector.get().failPipeline(replicaInfo, mirrorAddr);\n              // read an ack from downstream datanode\n              ack.readFields(downstreamIn);\n              ackRecvNanoTime \u003d System.nanoTime();\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(myString + \" got \" + ack);\n              }\n              // Process an OOB ACK.\n              Status oobStatus \u003d ack.getOOBStatus();\n              if (oobStatus !\u003d null) {\n                LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                    PipelineAck.combineHeader(datanode.getECN(),\n                      Status.SUCCESS));\n                continue;\n              }\n              seqno \u003d ack.getSeqno();\n            }\n            if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n              pkt \u003d waitForAckHead(seqno);\n              if (!isRunning()) {\n                break;\n              }\n              expected \u003d pkt.seqno;\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                  \u0026\u0026 seqno !\u003d expected) {\n                throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                    + \", received\u003d\" + seqno);\n              }\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                // The total ack time includes the ack times of downstream\n                // nodes.\n                // The value is 0 if this responder doesn\u0027t have a downstream\n                // DN in the pipeline.\n                totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                // Report the elapsed time from ack send to ack receive minus\n                // the downstream ack time.\n                long ackTimeNanos \u003d totalAckTimeNanos\n                    - ack.getDownstreamAckTimeNanos();\n                if (ackTimeNanos \u003c 0) {\n                  if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                        + \"ns.\");\n                  }\n                } else {\n                  datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                }\n              }\n              lastPacketInBlock \u003d pkt.lastPacketInBlock;\n            }\n          } catch (InterruptedException ine) {\n            isInterrupted \u003d true;\n          } catch (IOException ioe) {\n            if (Thread.interrupted()) {\n              isInterrupted \u003d true;\n            } else if (ioe instanceof EOFException \u0026\u0026 !packetSentInTime()) {\n              // The downstream error was caused by upstream including this\n              // node not sending packet in time. Let the upstream determine\n              // who is at fault.  If the immediate upstream node thinks it\n              // has sent a packet in time, this node will be reported as bad.\n              // Otherwise, the upstream node will propagate the error up by\n              // closing the connection.\n              LOG.warn(\"The downstream error might be due to congestion in \" +\n                  \"upstream including this node. Propagating the error: \",\n                  ioe);\n              throw ioe;\n            } else {\n              // continue to run even if can not read from mirror\n              // notify client of the error\n              // and wait for the client to shut down the pipeline\n              mirrorError \u003d true;\n              LOG.info(myString, ioe);\n            }\n          }\n\n          if (Thread.interrupted() || isInterrupted) {\n            /*\n             * The receiver thread cancelled this thread. We could also check\n             * any other status updates from the receiver thread (e.g. if it is\n             * ok to write to replyOut). It is prudent to not send any more\n             * status back to the client because this datanode has a problem.\n             * The upstream datanode will detect that this datanode is bad, and\n             * rightly so.\n             *\n             * The receiver thread can also interrupt this thread for sending\n             * an out-of-band response upstream.\n             */\n            LOG.info(myString + \": Thread is interrupted.\");\n            running \u003d false;\n            continue;\n          }\n\n          if (lastPacketInBlock) {\n            // Finalize the block and close the block file\n            finalizeBlock(startTime);\n          }\n\n          Status myStatus \u003d pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS;\n          sendAckUpstream(ack, expected, totalAckTimeNanos,\n            (pkt !\u003d null ? pkt.offsetInBlock : 0),\n            PipelineAck.combineHeader(datanode.getECN(), myStatus));\n          if (pkt !\u003d null) {\n            // remove the packet from the ack queue\n            removeAckHead();\n          }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n          if (running) {\n            datanode.checkDiskErrorAsync();\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "99e5204ff5326430558b6f6fd9da7c44654c15d7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9178. Slow datanode I/O can cause a wrong node to be marked bad. Contributed by Kihwal Lee.\n",
      "commitDate": "07/10/15 8:17 AM",
      "commitName": "99e5204ff5326430558b6f6fd9da7c44654c15d7",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "26/09/15 11:08 AM",
      "commitNameOld": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 10.88,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,128 +1,139 @@\n     public void run() {\n       boolean lastPacketInBlock \u003d false;\n       final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n       while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n         long totalAckTimeNanos \u003d 0;\n         boolean isInterrupted \u003d false;\n         try {\n           Packet pkt \u003d null;\n           long expected \u003d -2;\n           PipelineAck ack \u003d new PipelineAck();\n           long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n           long ackRecvNanoTime \u003d 0;\n           try {\n             if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n               // read an ack from downstream datanode\n               ack.readFields(downstreamIn);\n               ackRecvNanoTime \u003d System.nanoTime();\n               if (LOG.isDebugEnabled()) {\n                 LOG.debug(myString + \" got \" + ack);\n               }\n               // Process an OOB ACK.\n               Status oobStatus \u003d ack.getOOBStatus();\n               if (oobStatus !\u003d null) {\n                 LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                 sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                     PipelineAck.combineHeader(datanode.getECN(),\n                       Status.SUCCESS));\n                 continue;\n               }\n               seqno \u003d ack.getSeqno();\n             }\n             if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                 || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n               pkt \u003d waitForAckHead(seqno);\n               if (!isRunning()) {\n                 break;\n               }\n               expected \u003d pkt.seqno;\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                   \u0026\u0026 seqno !\u003d expected) {\n                 throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                     + \", received\u003d\" + seqno);\n               }\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                 // The total ack time includes the ack times of downstream\n                 // nodes.\n                 // The value is 0 if this responder doesn\u0027t have a downstream\n                 // DN in the pipeline.\n                 totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                 // Report the elapsed time from ack send to ack receive minus\n                 // the downstream ack time.\n                 long ackTimeNanos \u003d totalAckTimeNanos\n                     - ack.getDownstreamAckTimeNanos();\n                 if (ackTimeNanos \u003c 0) {\n                   if (LOG.isDebugEnabled()) {\n                     LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                         + \"ns.\");\n                   }\n                 } else {\n                   datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                 }\n               }\n               lastPacketInBlock \u003d pkt.lastPacketInBlock;\n             }\n           } catch (InterruptedException ine) {\n             isInterrupted \u003d true;\n           } catch (IOException ioe) {\n             if (Thread.interrupted()) {\n               isInterrupted \u003d true;\n+            } else if (ioe instanceof EOFException \u0026\u0026 !packetSentInTime()) {\n+              // The downstream error was caused by upstream including this\n+              // node not sending packet in time. Let the upstream determine\n+              // who is at fault.  If the immediate upstream node thinks it\n+              // has sent a packet in time, this node will be reported as bad.\n+              // Otherwise, the upstream node will propagate the error up by\n+              // closing the connection.\n+              LOG.warn(\"The downstream error might be due to congestion in \" +\n+                  \"upstream including this node. Propagating the error: \",\n+                  ioe);\n+              throw ioe;\n             } else {\n               // continue to run even if can not read from mirror\n               // notify client of the error\n               // and wait for the client to shut down the pipeline\n               mirrorError \u003d true;\n               LOG.info(myString, ioe);\n             }\n           }\n \n           if (Thread.interrupted() || isInterrupted) {\n             /*\n              * The receiver thread cancelled this thread. We could also check\n              * any other status updates from the receiver thread (e.g. if it is\n              * ok to write to replyOut). It is prudent to not send any more\n              * status back to the client because this datanode has a problem.\n              * The upstream datanode will detect that this datanode is bad, and\n              * rightly so.\n              *\n              * The receiver thread can also interrupt this thread for sending\n              * an out-of-band response upstream.\n              */\n             LOG.info(myString + \": Thread is interrupted.\");\n             running \u003d false;\n             continue;\n           }\n \n           if (lastPacketInBlock) {\n             // Finalize the block and close the block file\n             finalizeBlock(startTime);\n           }\n \n           Status myStatus \u003d pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS;\n           sendAckUpstream(ack, expected, totalAckTimeNanos,\n             (pkt !\u003d null ? pkt.offsetInBlock : 0),\n             PipelineAck.combineHeader(datanode.getECN(), myStatus));\n           if (pkt !\u003d null) {\n             // remove the packet from the ack queue\n             removeAckHead();\n           }\n         } catch (IOException e) {\n           LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n           if (running) {\n             datanode.checkDiskErrorAsync();\n             LOG.info(myString, e);\n             running \u003d false;\n             if (!Thread.interrupted()) { // failure not caused by interruption\n               receiverThread.interrupt();\n             }\n           }\n         } catch (Throwable e) {\n           if (running) {\n             LOG.info(myString, e);\n             running \u003d false;\n             receiverThread.interrupt();\n           }\n         }\n       }\n       LOG.info(myString + \" terminating\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n        long totalAckTimeNanos \u003d 0;\n        boolean isInterrupted \u003d false;\n        try {\n          Packet pkt \u003d null;\n          long expected \u003d -2;\n          PipelineAck ack \u003d new PipelineAck();\n          long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n          long ackRecvNanoTime \u003d 0;\n          try {\n            if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n              // read an ack from downstream datanode\n              ack.readFields(downstreamIn);\n              ackRecvNanoTime \u003d System.nanoTime();\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(myString + \" got \" + ack);\n              }\n              // Process an OOB ACK.\n              Status oobStatus \u003d ack.getOOBStatus();\n              if (oobStatus !\u003d null) {\n                LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                    PipelineAck.combineHeader(datanode.getECN(),\n                      Status.SUCCESS));\n                continue;\n              }\n              seqno \u003d ack.getSeqno();\n            }\n            if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n              pkt \u003d waitForAckHead(seqno);\n              if (!isRunning()) {\n                break;\n              }\n              expected \u003d pkt.seqno;\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                  \u0026\u0026 seqno !\u003d expected) {\n                throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                    + \", received\u003d\" + seqno);\n              }\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                // The total ack time includes the ack times of downstream\n                // nodes.\n                // The value is 0 if this responder doesn\u0027t have a downstream\n                // DN in the pipeline.\n                totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                // Report the elapsed time from ack send to ack receive minus\n                // the downstream ack time.\n                long ackTimeNanos \u003d totalAckTimeNanos\n                    - ack.getDownstreamAckTimeNanos();\n                if (ackTimeNanos \u003c 0) {\n                  if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                        + \"ns.\");\n                  }\n                } else {\n                  datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                }\n              }\n              lastPacketInBlock \u003d pkt.lastPacketInBlock;\n            }\n          } catch (InterruptedException ine) {\n            isInterrupted \u003d true;\n          } catch (IOException ioe) {\n            if (Thread.interrupted()) {\n              isInterrupted \u003d true;\n            } else if (ioe instanceof EOFException \u0026\u0026 !packetSentInTime()) {\n              // The downstream error was caused by upstream including this\n              // node not sending packet in time. Let the upstream determine\n              // who is at fault.  If the immediate upstream node thinks it\n              // has sent a packet in time, this node will be reported as bad.\n              // Otherwise, the upstream node will propagate the error up by\n              // closing the connection.\n              LOG.warn(\"The downstream error might be due to congestion in \" +\n                  \"upstream including this node. Propagating the error: \",\n                  ioe);\n              throw ioe;\n            } else {\n              // continue to run even if can not read from mirror\n              // notify client of the error\n              // and wait for the client to shut down the pipeline\n              mirrorError \u003d true;\n              LOG.info(myString, ioe);\n            }\n          }\n\n          if (Thread.interrupted() || isInterrupted) {\n            /*\n             * The receiver thread cancelled this thread. We could also check\n             * any other status updates from the receiver thread (e.g. if it is\n             * ok to write to replyOut). It is prudent to not send any more\n             * status back to the client because this datanode has a problem.\n             * The upstream datanode will detect that this datanode is bad, and\n             * rightly so.\n             *\n             * The receiver thread can also interrupt this thread for sending\n             * an out-of-band response upstream.\n             */\n            LOG.info(myString + \": Thread is interrupted.\");\n            running \u003d false;\n            continue;\n          }\n\n          if (lastPacketInBlock) {\n            // Finalize the block and close the block file\n            finalizeBlock(startTime);\n          }\n\n          Status myStatus \u003d pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS;\n          sendAckUpstream(ack, expected, totalAckTimeNanos,\n            (pkt !\u003d null ? pkt.offsetInBlock : 0),\n            PipelineAck.combineHeader(datanode.getECN(), myStatus));\n          if (pkt !\u003d null) {\n            // remove the packet from the ack queue\n            removeAckHead();\n          }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n          if (running) {\n            datanode.checkDiskErrorAsync();\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "c4980a2f343778544ca20ebea1338651793ea0d9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7270. Add congestion signaling capability to DataNode write protocol. Contributed by Haohui Mai.\n",
      "commitDate": "05/02/15 10:58 AM",
      "commitName": "c4980a2f343778544ca20ebea1338651793ea0d9",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "22/01/15 10:37 AM",
      "commitNameOld": "5f124efb3e090f96f217bee22f3c8897f9772f14",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 14.01,
      "commitsBetweenForRepo": 115,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,126 +1,128 @@\n     public void run() {\n       boolean lastPacketInBlock \u003d false;\n       final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n       while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n         long totalAckTimeNanos \u003d 0;\n         boolean isInterrupted \u003d false;\n         try {\n           Packet pkt \u003d null;\n           long expected \u003d -2;\n           PipelineAck ack \u003d new PipelineAck();\n           long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n           long ackRecvNanoTime \u003d 0;\n           try {\n             if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n               // read an ack from downstream datanode\n               ack.readFields(downstreamIn);\n               ackRecvNanoTime \u003d System.nanoTime();\n               if (LOG.isDebugEnabled()) {\n                 LOG.debug(myString + \" got \" + ack);\n               }\n               // Process an OOB ACK.\n               Status oobStatus \u003d ack.getOOBStatus();\n               if (oobStatus !\u003d null) {\n                 LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                 sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n-                    Status.SUCCESS);\n+                    PipelineAck.combineHeader(datanode.getECN(),\n+                      Status.SUCCESS));\n                 continue;\n               }\n               seqno \u003d ack.getSeqno();\n             }\n             if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                 || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n               pkt \u003d waitForAckHead(seqno);\n               if (!isRunning()) {\n                 break;\n               }\n               expected \u003d pkt.seqno;\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                   \u0026\u0026 seqno !\u003d expected) {\n                 throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                     + \", received\u003d\" + seqno);\n               }\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                 // The total ack time includes the ack times of downstream\n                 // nodes.\n                 // The value is 0 if this responder doesn\u0027t have a downstream\n                 // DN in the pipeline.\n                 totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                 // Report the elapsed time from ack send to ack receive minus\n                 // the downstream ack time.\n                 long ackTimeNanos \u003d totalAckTimeNanos\n                     - ack.getDownstreamAckTimeNanos();\n                 if (ackTimeNanos \u003c 0) {\n                   if (LOG.isDebugEnabled()) {\n                     LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                         + \"ns.\");\n                   }\n                 } else {\n                   datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                 }\n               }\n               lastPacketInBlock \u003d pkt.lastPacketInBlock;\n             }\n           } catch (InterruptedException ine) {\n             isInterrupted \u003d true;\n           } catch (IOException ioe) {\n             if (Thread.interrupted()) {\n               isInterrupted \u003d true;\n             } else {\n               // continue to run even if can not read from mirror\n               // notify client of the error\n               // and wait for the client to shut down the pipeline\n               mirrorError \u003d true;\n               LOG.info(myString, ioe);\n             }\n           }\n \n           if (Thread.interrupted() || isInterrupted) {\n             /*\n              * The receiver thread cancelled this thread. We could also check\n              * any other status updates from the receiver thread (e.g. if it is\n              * ok to write to replyOut). It is prudent to not send any more\n              * status back to the client because this datanode has a problem.\n              * The upstream datanode will detect that this datanode is bad, and\n              * rightly so.\n              *\n              * The receiver thread can also interrupt this thread for sending\n              * an out-of-band response upstream.\n              */\n             LOG.info(myString + \": Thread is interrupted.\");\n             running \u003d false;\n             continue;\n           }\n \n           if (lastPacketInBlock) {\n             // Finalize the block and close the block file\n             finalizeBlock(startTime);\n           }\n \n+          Status myStatus \u003d pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS;\n           sendAckUpstream(ack, expected, totalAckTimeNanos,\n-              (pkt !\u003d null ? pkt.offsetInBlock : 0), \n-              (pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS));\n+            (pkt !\u003d null ? pkt.offsetInBlock : 0),\n+            PipelineAck.combineHeader(datanode.getECN(), myStatus));\n           if (pkt !\u003d null) {\n             // remove the packet from the ack queue\n             removeAckHead();\n           }\n         } catch (IOException e) {\n           LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n           if (running) {\n             datanode.checkDiskErrorAsync();\n             LOG.info(myString, e);\n             running \u003d false;\n             if (!Thread.interrupted()) { // failure not caused by interruption\n               receiverThread.interrupt();\n             }\n           }\n         } catch (Throwable e) {\n           if (running) {\n             LOG.info(myString, e);\n             running \u003d false;\n             receiverThread.interrupt();\n           }\n         }\n       }\n       LOG.info(myString + \" terminating\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n        long totalAckTimeNanos \u003d 0;\n        boolean isInterrupted \u003d false;\n        try {\n          Packet pkt \u003d null;\n          long expected \u003d -2;\n          PipelineAck ack \u003d new PipelineAck();\n          long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n          long ackRecvNanoTime \u003d 0;\n          try {\n            if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n              // read an ack from downstream datanode\n              ack.readFields(downstreamIn);\n              ackRecvNanoTime \u003d System.nanoTime();\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(myString + \" got \" + ack);\n              }\n              // Process an OOB ACK.\n              Status oobStatus \u003d ack.getOOBStatus();\n              if (oobStatus !\u003d null) {\n                LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                    PipelineAck.combineHeader(datanode.getECN(),\n                      Status.SUCCESS));\n                continue;\n              }\n              seqno \u003d ack.getSeqno();\n            }\n            if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n              pkt \u003d waitForAckHead(seqno);\n              if (!isRunning()) {\n                break;\n              }\n              expected \u003d pkt.seqno;\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                  \u0026\u0026 seqno !\u003d expected) {\n                throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                    + \", received\u003d\" + seqno);\n              }\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                // The total ack time includes the ack times of downstream\n                // nodes.\n                // The value is 0 if this responder doesn\u0027t have a downstream\n                // DN in the pipeline.\n                totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                // Report the elapsed time from ack send to ack receive minus\n                // the downstream ack time.\n                long ackTimeNanos \u003d totalAckTimeNanos\n                    - ack.getDownstreamAckTimeNanos();\n                if (ackTimeNanos \u003c 0) {\n                  if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                        + \"ns.\");\n                  }\n                } else {\n                  datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                }\n              }\n              lastPacketInBlock \u003d pkt.lastPacketInBlock;\n            }\n          } catch (InterruptedException ine) {\n            isInterrupted \u003d true;\n          } catch (IOException ioe) {\n            if (Thread.interrupted()) {\n              isInterrupted \u003d true;\n            } else {\n              // continue to run even if can not read from mirror\n              // notify client of the error\n              // and wait for the client to shut down the pipeline\n              mirrorError \u003d true;\n              LOG.info(myString, ioe);\n            }\n          }\n\n          if (Thread.interrupted() || isInterrupted) {\n            /*\n             * The receiver thread cancelled this thread. We could also check\n             * any other status updates from the receiver thread (e.g. if it is\n             * ok to write to replyOut). It is prudent to not send any more\n             * status back to the client because this datanode has a problem.\n             * The upstream datanode will detect that this datanode is bad, and\n             * rightly so.\n             *\n             * The receiver thread can also interrupt this thread for sending\n             * an out-of-band response upstream.\n             */\n            LOG.info(myString + \": Thread is interrupted.\");\n            running \u003d false;\n            continue;\n          }\n\n          if (lastPacketInBlock) {\n            // Finalize the block and close the block file\n            finalizeBlock(startTime);\n          }\n\n          Status myStatus \u003d pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS;\n          sendAckUpstream(ack, expected, totalAckTimeNanos,\n            (pkt !\u003d null ? pkt.offsetInBlock : 0),\n            PipelineAck.combineHeader(datanode.getECN(), myStatus));\n          if (pkt !\u003d null) {\n            // remove the packet from the ack queue\n            removeAckHead();\n          }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n          if (running) {\n            datanode.checkDiskErrorAsync();\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "b7f4a3156c0f5c600816c469637237ba6c9b330c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7496. Fix FsVolume removal race conditions on the DataNode by reference-counting the volume instances (lei via cmccabe)\n",
      "commitDate": "20/01/15 7:05 PM",
      "commitName": "b7f4a3156c0f5c600816c469637237ba6c9b330c",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "11/12/14 12:36 PM",
      "commitNameOld": "b9f6d0c956f0278c8b9b83e05b523a442a730ebb",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 40.27,
      "commitsBetweenForRepo": 212,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,147 +1,126 @@\n     public void run() {\n       boolean lastPacketInBlock \u003d false;\n       final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n       while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n         long totalAckTimeNanos \u003d 0;\n         boolean isInterrupted \u003d false;\n         try {\n           Packet pkt \u003d null;\n           long expected \u003d -2;\n           PipelineAck ack \u003d new PipelineAck();\n           long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n           long ackRecvNanoTime \u003d 0;\n           try {\n             if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n               // read an ack from downstream datanode\n               ack.readFields(downstreamIn);\n               ackRecvNanoTime \u003d System.nanoTime();\n               if (LOG.isDebugEnabled()) {\n                 LOG.debug(myString + \" got \" + ack);\n               }\n               // Process an OOB ACK.\n               Status oobStatus \u003d ack.getOOBStatus();\n               if (oobStatus !\u003d null) {\n                 LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                 sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                     Status.SUCCESS);\n                 continue;\n               }\n               seqno \u003d ack.getSeqno();\n             }\n             if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                 || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n               pkt \u003d waitForAckHead(seqno);\n               if (!isRunning()) {\n                 break;\n               }\n               expected \u003d pkt.seqno;\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                   \u0026\u0026 seqno !\u003d expected) {\n                 throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                     + \", received\u003d\" + seqno);\n               }\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                 // The total ack time includes the ack times of downstream\n                 // nodes.\n                 // The value is 0 if this responder doesn\u0027t have a downstream\n                 // DN in the pipeline.\n                 totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                 // Report the elapsed time from ack send to ack receive minus\n                 // the downstream ack time.\n                 long ackTimeNanos \u003d totalAckTimeNanos\n                     - ack.getDownstreamAckTimeNanos();\n                 if (ackTimeNanos \u003c 0) {\n                   if (LOG.isDebugEnabled()) {\n                     LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                         + \"ns.\");\n                   }\n                 } else {\n                   datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                 }\n               }\n               lastPacketInBlock \u003d pkt.lastPacketInBlock;\n             }\n           } catch (InterruptedException ine) {\n             isInterrupted \u003d true;\n           } catch (IOException ioe) {\n             if (Thread.interrupted()) {\n               isInterrupted \u003d true;\n             } else {\n               // continue to run even if can not read from mirror\n               // notify client of the error\n               // and wait for the client to shut down the pipeline\n               mirrorError \u003d true;\n               LOG.info(myString, ioe);\n             }\n           }\n \n           if (Thread.interrupted() || isInterrupted) {\n             /*\n              * The receiver thread cancelled this thread. We could also check\n              * any other status updates from the receiver thread (e.g. if it is\n              * ok to write to replyOut). It is prudent to not send any more\n              * status back to the client because this datanode has a problem.\n              * The upstream datanode will detect that this datanode is bad, and\n              * rightly so.\n              *\n              * The receiver thread can also interrupt this thread for sending\n              * an out-of-band response upstream.\n              */\n             LOG.info(myString + \": Thread is interrupted.\");\n             running \u003d false;\n             continue;\n           }\n \n           if (lastPacketInBlock) {\n             // Finalize the block and close the block file\n-            try {\n-              finalizeBlock(startTime);\n-            } catch (ReplicaNotFoundException e) {\n-              // Verify that the exception is due to volume removal.\n-              FsVolumeSpi volume;\n-              synchronized (datanode.data) {\n-                volume \u003d datanode.data.getVolume(block);\n-              }\n-              if (volume \u003d\u003d null) {\n-                // ReplicaInfo has been removed due to the corresponding data\n-                // volume has been removed. Don\u0027t need to check disk error.\n-                LOG.info(myString\n-                    + \": BlockReceiver is interrupted because the block pool \"\n-                    + block.getBlockPoolId() + \" has been removed.\", e);\n-                sendAckUpstream(ack, expected, totalAckTimeNanos, 0,\n-                    Status.OOB_INTERRUPTED);\n-                running \u003d false;\n-                receiverThread.interrupt();\n-                continue;\n-              }\n-              throw e;\n-            }\n+            finalizeBlock(startTime);\n           }\n \n           sendAckUpstream(ack, expected, totalAckTimeNanos,\n               (pkt !\u003d null ? pkt.offsetInBlock : 0), \n               (pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS));\n           if (pkt !\u003d null) {\n             // remove the packet from the ack queue\n             removeAckHead();\n           }\n         } catch (IOException e) {\n           LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n           if (running) {\n             datanode.checkDiskErrorAsync();\n             LOG.info(myString, e);\n             running \u003d false;\n             if (!Thread.interrupted()) { // failure not caused by interruption\n               receiverThread.interrupt();\n             }\n           }\n         } catch (Throwable e) {\n           if (running) {\n             LOG.info(myString, e);\n             running \u003d false;\n             receiverThread.interrupt();\n           }\n         }\n       }\n       LOG.info(myString + \" terminating\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n        long totalAckTimeNanos \u003d 0;\n        boolean isInterrupted \u003d false;\n        try {\n          Packet pkt \u003d null;\n          long expected \u003d -2;\n          PipelineAck ack \u003d new PipelineAck();\n          long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n          long ackRecvNanoTime \u003d 0;\n          try {\n            if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n              // read an ack from downstream datanode\n              ack.readFields(downstreamIn);\n              ackRecvNanoTime \u003d System.nanoTime();\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(myString + \" got \" + ack);\n              }\n              // Process an OOB ACK.\n              Status oobStatus \u003d ack.getOOBStatus();\n              if (oobStatus !\u003d null) {\n                LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                    Status.SUCCESS);\n                continue;\n              }\n              seqno \u003d ack.getSeqno();\n            }\n            if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n              pkt \u003d waitForAckHead(seqno);\n              if (!isRunning()) {\n                break;\n              }\n              expected \u003d pkt.seqno;\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                  \u0026\u0026 seqno !\u003d expected) {\n                throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                    + \", received\u003d\" + seqno);\n              }\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                // The total ack time includes the ack times of downstream\n                // nodes.\n                // The value is 0 if this responder doesn\u0027t have a downstream\n                // DN in the pipeline.\n                totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                // Report the elapsed time from ack send to ack receive minus\n                // the downstream ack time.\n                long ackTimeNanos \u003d totalAckTimeNanos\n                    - ack.getDownstreamAckTimeNanos();\n                if (ackTimeNanos \u003c 0) {\n                  if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                        + \"ns.\");\n                  }\n                } else {\n                  datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                }\n              }\n              lastPacketInBlock \u003d pkt.lastPacketInBlock;\n            }\n          } catch (InterruptedException ine) {\n            isInterrupted \u003d true;\n          } catch (IOException ioe) {\n            if (Thread.interrupted()) {\n              isInterrupted \u003d true;\n            } else {\n              // continue to run even if can not read from mirror\n              // notify client of the error\n              // and wait for the client to shut down the pipeline\n              mirrorError \u003d true;\n              LOG.info(myString, ioe);\n            }\n          }\n\n          if (Thread.interrupted() || isInterrupted) {\n            /*\n             * The receiver thread cancelled this thread. We could also check\n             * any other status updates from the receiver thread (e.g. if it is\n             * ok to write to replyOut). It is prudent to not send any more\n             * status back to the client because this datanode has a problem.\n             * The upstream datanode will detect that this datanode is bad, and\n             * rightly so.\n             *\n             * The receiver thread can also interrupt this thread for sending\n             * an out-of-band response upstream.\n             */\n            LOG.info(myString + \": Thread is interrupted.\");\n            running \u003d false;\n            continue;\n          }\n\n          if (lastPacketInBlock) {\n            // Finalize the block and close the block file\n            finalizeBlock(startTime);\n          }\n\n          sendAckUpstream(ack, expected, totalAckTimeNanos,\n              (pkt !\u003d null ? pkt.offsetInBlock : 0), \n              (pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS));\n          if (pkt !\u003d null) {\n            // remove the packet from the ack queue\n            removeAckHead();\n          }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n          if (running) {\n            datanode.checkDiskErrorAsync();\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "7b0f9bb2583cd9b7274f1e31c173c1c6a7ce467b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6877. Avoid calling checkDisk when an HDFS volume is removed during a write. (Lei Xu via Colin P. McCabe)\n",
      "commitDate": "22/10/14 1:38 PM",
      "commitName": "7b0f9bb2583cd9b7274f1e31c173c1c6a7ce467b",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "27/08/14 9:47 PM",
      "commitNameOld": "a317bd7b02c37bd57743bfad59593ec12f53f4ed",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 55.66,
      "commitsBetweenForRepo": 565,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,126 +1,147 @@\n     public void run() {\n       boolean lastPacketInBlock \u003d false;\n       final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n       while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n         long totalAckTimeNanos \u003d 0;\n         boolean isInterrupted \u003d false;\n         try {\n           Packet pkt \u003d null;\n           long expected \u003d -2;\n           PipelineAck ack \u003d new PipelineAck();\n           long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n           long ackRecvNanoTime \u003d 0;\n           try {\n             if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n               // read an ack from downstream datanode\n               ack.readFields(downstreamIn);\n               ackRecvNanoTime \u003d System.nanoTime();\n               if (LOG.isDebugEnabled()) {\n                 LOG.debug(myString + \" got \" + ack);\n               }\n               // Process an OOB ACK.\n               Status oobStatus \u003d ack.getOOBStatus();\n               if (oobStatus !\u003d null) {\n                 LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                 sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                     Status.SUCCESS);\n                 continue;\n               }\n               seqno \u003d ack.getSeqno();\n             }\n             if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                 || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n               pkt \u003d waitForAckHead(seqno);\n               if (!isRunning()) {\n                 break;\n               }\n               expected \u003d pkt.seqno;\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                   \u0026\u0026 seqno !\u003d expected) {\n                 throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                     + \", received\u003d\" + seqno);\n               }\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                 // The total ack time includes the ack times of downstream\n                 // nodes.\n                 // The value is 0 if this responder doesn\u0027t have a downstream\n                 // DN in the pipeline.\n                 totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                 // Report the elapsed time from ack send to ack receive minus\n                 // the downstream ack time.\n                 long ackTimeNanos \u003d totalAckTimeNanos\n                     - ack.getDownstreamAckTimeNanos();\n                 if (ackTimeNanos \u003c 0) {\n                   if (LOG.isDebugEnabled()) {\n                     LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                         + \"ns.\");\n                   }\n                 } else {\n                   datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                 }\n               }\n               lastPacketInBlock \u003d pkt.lastPacketInBlock;\n             }\n           } catch (InterruptedException ine) {\n             isInterrupted \u003d true;\n           } catch (IOException ioe) {\n             if (Thread.interrupted()) {\n               isInterrupted \u003d true;\n             } else {\n               // continue to run even if can not read from mirror\n               // notify client of the error\n               // and wait for the client to shut down the pipeline\n               mirrorError \u003d true;\n               LOG.info(myString, ioe);\n             }\n           }\n \n           if (Thread.interrupted() || isInterrupted) {\n             /*\n              * The receiver thread cancelled this thread. We could also check\n              * any other status updates from the receiver thread (e.g. if it is\n              * ok to write to replyOut). It is prudent to not send any more\n              * status back to the client because this datanode has a problem.\n              * The upstream datanode will detect that this datanode is bad, and\n              * rightly so.\n              *\n              * The receiver thread can also interrupt this thread for sending\n              * an out-of-band response upstream.\n              */\n             LOG.info(myString + \": Thread is interrupted.\");\n             running \u003d false;\n             continue;\n           }\n \n           if (lastPacketInBlock) {\n             // Finalize the block and close the block file\n-            finalizeBlock(startTime);\n+            try {\n+              finalizeBlock(startTime);\n+            } catch (ReplicaNotFoundException e) {\n+              // Verify that the exception is due to volume removal.\n+              FsVolumeSpi volume;\n+              synchronized (datanode.data) {\n+                volume \u003d datanode.data.getVolume(block);\n+              }\n+              if (volume \u003d\u003d null) {\n+                // ReplicaInfo has been removed due to the corresponding data\n+                // volume has been removed. Don\u0027t need to check disk error.\n+                LOG.info(myString\n+                    + \": BlockReceiver is interrupted because the block pool \"\n+                    + block.getBlockPoolId() + \" has been removed.\", e);\n+                sendAckUpstream(ack, expected, totalAckTimeNanos, 0,\n+                    Status.OOB_INTERRUPTED);\n+                running \u003d false;\n+                receiverThread.interrupt();\n+                continue;\n+              }\n+              throw e;\n+            }\n           }\n \n           sendAckUpstream(ack, expected, totalAckTimeNanos,\n               (pkt !\u003d null ? pkt.offsetInBlock : 0), \n               (pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS));\n           if (pkt !\u003d null) {\n             // remove the packet from the ack queue\n             removeAckHead();\n           }\n         } catch (IOException e) {\n           LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n           if (running) {\n             datanode.checkDiskErrorAsync();\n             LOG.info(myString, e);\n             running \u003d false;\n             if (!Thread.interrupted()) { // failure not caused by interruption\n               receiverThread.interrupt();\n             }\n           }\n         } catch (Throwable e) {\n           if (running) {\n             LOG.info(myString, e);\n             running \u003d false;\n             receiverThread.interrupt();\n           }\n         }\n       }\n       LOG.info(myString + \" terminating\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n        long totalAckTimeNanos \u003d 0;\n        boolean isInterrupted \u003d false;\n        try {\n          Packet pkt \u003d null;\n          long expected \u003d -2;\n          PipelineAck ack \u003d new PipelineAck();\n          long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n          long ackRecvNanoTime \u003d 0;\n          try {\n            if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n              // read an ack from downstream datanode\n              ack.readFields(downstreamIn);\n              ackRecvNanoTime \u003d System.nanoTime();\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(myString + \" got \" + ack);\n              }\n              // Process an OOB ACK.\n              Status oobStatus \u003d ack.getOOBStatus();\n              if (oobStatus !\u003d null) {\n                LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                    Status.SUCCESS);\n                continue;\n              }\n              seqno \u003d ack.getSeqno();\n            }\n            if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n              pkt \u003d waitForAckHead(seqno);\n              if (!isRunning()) {\n                break;\n              }\n              expected \u003d pkt.seqno;\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                  \u0026\u0026 seqno !\u003d expected) {\n                throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                    + \", received\u003d\" + seqno);\n              }\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                // The total ack time includes the ack times of downstream\n                // nodes.\n                // The value is 0 if this responder doesn\u0027t have a downstream\n                // DN in the pipeline.\n                totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                // Report the elapsed time from ack send to ack receive minus\n                // the downstream ack time.\n                long ackTimeNanos \u003d totalAckTimeNanos\n                    - ack.getDownstreamAckTimeNanos();\n                if (ackTimeNanos \u003c 0) {\n                  if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                        + \"ns.\");\n                  }\n                } else {\n                  datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                }\n              }\n              lastPacketInBlock \u003d pkt.lastPacketInBlock;\n            }\n          } catch (InterruptedException ine) {\n            isInterrupted \u003d true;\n          } catch (IOException ioe) {\n            if (Thread.interrupted()) {\n              isInterrupted \u003d true;\n            } else {\n              // continue to run even if can not read from mirror\n              // notify client of the error\n              // and wait for the client to shut down the pipeline\n              mirrorError \u003d true;\n              LOG.info(myString, ioe);\n            }\n          }\n\n          if (Thread.interrupted() || isInterrupted) {\n            /*\n             * The receiver thread cancelled this thread. We could also check\n             * any other status updates from the receiver thread (e.g. if it is\n             * ok to write to replyOut). It is prudent to not send any more\n             * status back to the client because this datanode has a problem.\n             * The upstream datanode will detect that this datanode is bad, and\n             * rightly so.\n             *\n             * The receiver thread can also interrupt this thread for sending\n             * an out-of-band response upstream.\n             */\n            LOG.info(myString + \": Thread is interrupted.\");\n            running \u003d false;\n            continue;\n          }\n\n          if (lastPacketInBlock) {\n            // Finalize the block and close the block file\n            try {\n              finalizeBlock(startTime);\n            } catch (ReplicaNotFoundException e) {\n              // Verify that the exception is due to volume removal.\n              FsVolumeSpi volume;\n              synchronized (datanode.data) {\n                volume \u003d datanode.data.getVolume(block);\n              }\n              if (volume \u003d\u003d null) {\n                // ReplicaInfo has been removed due to the corresponding data\n                // volume has been removed. Don\u0027t need to check disk error.\n                LOG.info(myString\n                    + \": BlockReceiver is interrupted because the block pool \"\n                    + block.getBlockPoolId() + \" has been removed.\", e);\n                sendAckUpstream(ack, expected, totalAckTimeNanos, 0,\n                    Status.OOB_INTERRUPTED);\n                running \u003d false;\n                receiverThread.interrupt();\n                continue;\n              }\n              throw e;\n            }\n          }\n\n          sendAckUpstream(ack, expected, totalAckTimeNanos,\n              (pkt !\u003d null ? pkt.offsetInBlock : 0), \n              (pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS));\n          if (pkt !\u003d null) {\n            // remove the packet from the ack queue\n            removeAckHead();\n          }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n          if (running) {\n            datanode.checkDiskErrorAsync();\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "33518e561368c372bf9254b6b55a9b0c499fbd4d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5185. DN fails to startup if one of the data dir is full. Contributed by Vinayakumar B.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1615504 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/08/14 1:43 AM",
      "commitName": "33518e561368c372bf9254b6b55a9b0c499fbd4d",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "22/07/14 12:41 AM",
      "commitNameOld": "25b0e8471ed744578b2d8e3f0debe5477b268e54",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 13.04,
      "commitsBetweenForRepo": 88,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,126 +1,126 @@\n     public void run() {\n       boolean lastPacketInBlock \u003d false;\n       final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n       while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n         long totalAckTimeNanos \u003d 0;\n         boolean isInterrupted \u003d false;\n         try {\n           Packet pkt \u003d null;\n           long expected \u003d -2;\n           PipelineAck ack \u003d new PipelineAck();\n           long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n           long ackRecvNanoTime \u003d 0;\n           try {\n             if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n               // read an ack from downstream datanode\n               ack.readFields(downstreamIn);\n               ackRecvNanoTime \u003d System.nanoTime();\n               if (LOG.isDebugEnabled()) {\n                 LOG.debug(myString + \" got \" + ack);\n               }\n               // Process an OOB ACK.\n               Status oobStatus \u003d ack.getOOBStatus();\n               if (oobStatus !\u003d null) {\n                 LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                 sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                     Status.SUCCESS);\n                 continue;\n               }\n               seqno \u003d ack.getSeqno();\n             }\n             if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                 || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n               pkt \u003d waitForAckHead(seqno);\n               if (!isRunning()) {\n                 break;\n               }\n               expected \u003d pkt.seqno;\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                   \u0026\u0026 seqno !\u003d expected) {\n                 throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                     + \", received\u003d\" + seqno);\n               }\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                 // The total ack time includes the ack times of downstream\n                 // nodes.\n                 // The value is 0 if this responder doesn\u0027t have a downstream\n                 // DN in the pipeline.\n                 totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                 // Report the elapsed time from ack send to ack receive minus\n                 // the downstream ack time.\n                 long ackTimeNanos \u003d totalAckTimeNanos\n                     - ack.getDownstreamAckTimeNanos();\n                 if (ackTimeNanos \u003c 0) {\n                   if (LOG.isDebugEnabled()) {\n                     LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                         + \"ns.\");\n                   }\n                 } else {\n                   datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                 }\n               }\n               lastPacketInBlock \u003d pkt.lastPacketInBlock;\n             }\n           } catch (InterruptedException ine) {\n             isInterrupted \u003d true;\n           } catch (IOException ioe) {\n             if (Thread.interrupted()) {\n               isInterrupted \u003d true;\n             } else {\n               // continue to run even if can not read from mirror\n               // notify client of the error\n               // and wait for the client to shut down the pipeline\n               mirrorError \u003d true;\n               LOG.info(myString, ioe);\n             }\n           }\n \n           if (Thread.interrupted() || isInterrupted) {\n             /*\n              * The receiver thread cancelled this thread. We could also check\n              * any other status updates from the receiver thread (e.g. if it is\n              * ok to write to replyOut). It is prudent to not send any more\n              * status back to the client because this datanode has a problem.\n              * The upstream datanode will detect that this datanode is bad, and\n              * rightly so.\n              *\n              * The receiver thread can also interrupt this thread for sending\n              * an out-of-band response upstream.\n              */\n             LOG.info(myString + \": Thread is interrupted.\");\n             running \u003d false;\n             continue;\n           }\n \n           if (lastPacketInBlock) {\n             // Finalize the block and close the block file\n             finalizeBlock(startTime);\n           }\n \n           sendAckUpstream(ack, expected, totalAckTimeNanos,\n               (pkt !\u003d null ? pkt.offsetInBlock : 0), \n               (pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS));\n           if (pkt !\u003d null) {\n             // remove the packet from the ack queue\n             removeAckHead();\n           }\n         } catch (IOException e) {\n           LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n           if (running) {\n-            datanode.checkDiskError();\n+            datanode.checkDiskErrorAsync();\n             LOG.info(myString, e);\n             running \u003d false;\n             if (!Thread.interrupted()) { // failure not caused by interruption\n               receiverThread.interrupt();\n             }\n           }\n         } catch (Throwable e) {\n           if (running) {\n             LOG.info(myString, e);\n             running \u003d false;\n             receiverThread.interrupt();\n           }\n         }\n       }\n       LOG.info(myString + \" terminating\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n        long totalAckTimeNanos \u003d 0;\n        boolean isInterrupted \u003d false;\n        try {\n          Packet pkt \u003d null;\n          long expected \u003d -2;\n          PipelineAck ack \u003d new PipelineAck();\n          long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n          long ackRecvNanoTime \u003d 0;\n          try {\n            if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n              // read an ack from downstream datanode\n              ack.readFields(downstreamIn);\n              ackRecvNanoTime \u003d System.nanoTime();\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(myString + \" got \" + ack);\n              }\n              // Process an OOB ACK.\n              Status oobStatus \u003d ack.getOOBStatus();\n              if (oobStatus !\u003d null) {\n                LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                    Status.SUCCESS);\n                continue;\n              }\n              seqno \u003d ack.getSeqno();\n            }\n            if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n              pkt \u003d waitForAckHead(seqno);\n              if (!isRunning()) {\n                break;\n              }\n              expected \u003d pkt.seqno;\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                  \u0026\u0026 seqno !\u003d expected) {\n                throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                    + \", received\u003d\" + seqno);\n              }\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                // The total ack time includes the ack times of downstream\n                // nodes.\n                // The value is 0 if this responder doesn\u0027t have a downstream\n                // DN in the pipeline.\n                totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                // Report the elapsed time from ack send to ack receive minus\n                // the downstream ack time.\n                long ackTimeNanos \u003d totalAckTimeNanos\n                    - ack.getDownstreamAckTimeNanos();\n                if (ackTimeNanos \u003c 0) {\n                  if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                        + \"ns.\");\n                  }\n                } else {\n                  datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                }\n              }\n              lastPacketInBlock \u003d pkt.lastPacketInBlock;\n            }\n          } catch (InterruptedException ine) {\n            isInterrupted \u003d true;\n          } catch (IOException ioe) {\n            if (Thread.interrupted()) {\n              isInterrupted \u003d true;\n            } else {\n              // continue to run even if can not read from mirror\n              // notify client of the error\n              // and wait for the client to shut down the pipeline\n              mirrorError \u003d true;\n              LOG.info(myString, ioe);\n            }\n          }\n\n          if (Thread.interrupted() || isInterrupted) {\n            /*\n             * The receiver thread cancelled this thread. We could also check\n             * any other status updates from the receiver thread (e.g. if it is\n             * ok to write to replyOut). It is prudent to not send any more\n             * status back to the client because this datanode has a problem.\n             * The upstream datanode will detect that this datanode is bad, and\n             * rightly so.\n             *\n             * The receiver thread can also interrupt this thread for sending\n             * an out-of-band response upstream.\n             */\n            LOG.info(myString + \": Thread is interrupted.\");\n            running \u003d false;\n            continue;\n          }\n\n          if (lastPacketInBlock) {\n            // Finalize the block and close the block file\n            finalizeBlock(startTime);\n          }\n\n          sendAckUpstream(ack, expected, totalAckTimeNanos,\n              (pkt !\u003d null ? pkt.offsetInBlock : 0), \n              (pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS));\n          if (pkt !\u003d null) {\n            // remove the packet from the ack queue\n            removeAckHead();\n          }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n          if (running) {\n            datanode.checkDiskErrorAsync();\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "e9459baec5a46651c156fbae5f8f3c9cc8325ef0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5522. Datanode disk error check may be incorrectly skipped. Contributed by Rushabh Shah.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594055 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/05/14 12:08 PM",
      "commitName": "e9459baec5a46651c156fbae5f8f3c9cc8325ef0",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "23/04/14 10:05 PM",
      "commitNameOld": "f36f0dde8866e2233dad26b38a8d432d2302a51a",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 18.58,
      "commitsBetweenForRepo": 88,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,130 +1,126 @@\n     public void run() {\n       boolean lastPacketInBlock \u003d false;\n       final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n       while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n         long totalAckTimeNanos \u003d 0;\n         boolean isInterrupted \u003d false;\n         try {\n           Packet pkt \u003d null;\n           long expected \u003d -2;\n           PipelineAck ack \u003d new PipelineAck();\n           long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n           long ackRecvNanoTime \u003d 0;\n           try {\n             if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n               // read an ack from downstream datanode\n               ack.readFields(downstreamIn);\n               ackRecvNanoTime \u003d System.nanoTime();\n               if (LOG.isDebugEnabled()) {\n                 LOG.debug(myString + \" got \" + ack);\n               }\n               // Process an OOB ACK.\n               Status oobStatus \u003d ack.getOOBStatus();\n               if (oobStatus !\u003d null) {\n                 LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                 sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                     Status.SUCCESS);\n                 continue;\n               }\n               seqno \u003d ack.getSeqno();\n             }\n             if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                 || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n               pkt \u003d waitForAckHead(seqno);\n               if (!isRunning()) {\n                 break;\n               }\n               expected \u003d pkt.seqno;\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                   \u0026\u0026 seqno !\u003d expected) {\n                 throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                     + \", received\u003d\" + seqno);\n               }\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                 // The total ack time includes the ack times of downstream\n                 // nodes.\n                 // The value is 0 if this responder doesn\u0027t have a downstream\n                 // DN in the pipeline.\n                 totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                 // Report the elapsed time from ack send to ack receive minus\n                 // the downstream ack time.\n                 long ackTimeNanos \u003d totalAckTimeNanos\n                     - ack.getDownstreamAckTimeNanos();\n                 if (ackTimeNanos \u003c 0) {\n                   if (LOG.isDebugEnabled()) {\n                     LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                         + \"ns.\");\n                   }\n                 } else {\n                   datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                 }\n               }\n               lastPacketInBlock \u003d pkt.lastPacketInBlock;\n             }\n           } catch (InterruptedException ine) {\n             isInterrupted \u003d true;\n           } catch (IOException ioe) {\n             if (Thread.interrupted()) {\n               isInterrupted \u003d true;\n             } else {\n               // continue to run even if can not read from mirror\n               // notify client of the error\n               // and wait for the client to shut down the pipeline\n               mirrorError \u003d true;\n               LOG.info(myString, ioe);\n             }\n           }\n \n           if (Thread.interrupted() || isInterrupted) {\n             /*\n              * The receiver thread cancelled this thread. We could also check\n              * any other status updates from the receiver thread (e.g. if it is\n              * ok to write to replyOut). It is prudent to not send any more\n              * status back to the client because this datanode has a problem.\n              * The upstream datanode will detect that this datanode is bad, and\n              * rightly so.\n              *\n              * The receiver thread can also interrupt this thread for sending\n              * an out-of-band response upstream.\n              */\n             LOG.info(myString + \": Thread is interrupted.\");\n             running \u003d false;\n             continue;\n           }\n \n           if (lastPacketInBlock) {\n             // Finalize the block and close the block file\n             finalizeBlock(startTime);\n           }\n \n           sendAckUpstream(ack, expected, totalAckTimeNanos,\n               (pkt !\u003d null ? pkt.offsetInBlock : 0), \n               (pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS));\n           if (pkt !\u003d null) {\n             // remove the packet from the ack queue\n             removeAckHead();\n           }\n         } catch (IOException e) {\n           LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n           if (running) {\n-            try {\n-              datanode.checkDiskError(e); // may throw an exception here\n-            } catch (IOException ioe) {\n-              LOG.warn(\"DataNode.checkDiskError failed in run() with: \", ioe);\n-            }\n+            datanode.checkDiskError();\n             LOG.info(myString, e);\n             running \u003d false;\n             if (!Thread.interrupted()) { // failure not caused by interruption\n               receiverThread.interrupt();\n             }\n           }\n         } catch (Throwable e) {\n           if (running) {\n             LOG.info(myString, e);\n             running \u003d false;\n             receiverThread.interrupt();\n           }\n         }\n       }\n       LOG.info(myString + \" terminating\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n        long totalAckTimeNanos \u003d 0;\n        boolean isInterrupted \u003d false;\n        try {\n          Packet pkt \u003d null;\n          long expected \u003d -2;\n          PipelineAck ack \u003d new PipelineAck();\n          long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n          long ackRecvNanoTime \u003d 0;\n          try {\n            if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n              // read an ack from downstream datanode\n              ack.readFields(downstreamIn);\n              ackRecvNanoTime \u003d System.nanoTime();\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(myString + \" got \" + ack);\n              }\n              // Process an OOB ACK.\n              Status oobStatus \u003d ack.getOOBStatus();\n              if (oobStatus !\u003d null) {\n                LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                    Status.SUCCESS);\n                continue;\n              }\n              seqno \u003d ack.getSeqno();\n            }\n            if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n              pkt \u003d waitForAckHead(seqno);\n              if (!isRunning()) {\n                break;\n              }\n              expected \u003d pkt.seqno;\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                  \u0026\u0026 seqno !\u003d expected) {\n                throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                    + \", received\u003d\" + seqno);\n              }\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                // The total ack time includes the ack times of downstream\n                // nodes.\n                // The value is 0 if this responder doesn\u0027t have a downstream\n                // DN in the pipeline.\n                totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                // Report the elapsed time from ack send to ack receive minus\n                // the downstream ack time.\n                long ackTimeNanos \u003d totalAckTimeNanos\n                    - ack.getDownstreamAckTimeNanos();\n                if (ackTimeNanos \u003c 0) {\n                  if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                        + \"ns.\");\n                  }\n                } else {\n                  datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                }\n              }\n              lastPacketInBlock \u003d pkt.lastPacketInBlock;\n            }\n          } catch (InterruptedException ine) {\n            isInterrupted \u003d true;\n          } catch (IOException ioe) {\n            if (Thread.interrupted()) {\n              isInterrupted \u003d true;\n            } else {\n              // continue to run even if can not read from mirror\n              // notify client of the error\n              // and wait for the client to shut down the pipeline\n              mirrorError \u003d true;\n              LOG.info(myString, ioe);\n            }\n          }\n\n          if (Thread.interrupted() || isInterrupted) {\n            /*\n             * The receiver thread cancelled this thread. We could also check\n             * any other status updates from the receiver thread (e.g. if it is\n             * ok to write to replyOut). It is prudent to not send any more\n             * status back to the client because this datanode has a problem.\n             * The upstream datanode will detect that this datanode is bad, and\n             * rightly so.\n             *\n             * The receiver thread can also interrupt this thread for sending\n             * an out-of-band response upstream.\n             */\n            LOG.info(myString + \": Thread is interrupted.\");\n            running \u003d false;\n            continue;\n          }\n\n          if (lastPacketInBlock) {\n            // Finalize the block and close the block file\n            finalizeBlock(startTime);\n          }\n\n          sendAckUpstream(ack, expected, totalAckTimeNanos,\n              (pkt !\u003d null ? pkt.offsetInBlock : 0), \n              (pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS));\n          if (pkt !\u003d null) {\n            // remove the packet from the ack queue\n            removeAckHead();\n          }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n          if (running) {\n            datanode.checkDiskError();\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "1c6b5d2b5841e5219a98937088cde4ae63869f80": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5583. Make DN send an OOB Ack on shutdown before restarting. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1571491 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/02/14 3:38 PM",
      "commitName": "1c6b5d2b5841e5219a98937088cde4ae63869f80",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "19/02/14 3:38 PM",
      "commitNameOld": "0369aff403012f8dd02486a3dd2f8e346ad23b03",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 5.0,
      "commitsBetweenForRepo": 39,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,119 +1,130 @@\n     public void run() {\n       boolean lastPacketInBlock \u003d false;\n       final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n       while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n         long totalAckTimeNanos \u003d 0;\n         boolean isInterrupted \u003d false;\n         try {\n           Packet pkt \u003d null;\n           long expected \u003d -2;\n           PipelineAck ack \u003d new PipelineAck();\n           long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n           long ackRecvNanoTime \u003d 0;\n           try {\n             if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n               // read an ack from downstream datanode\n               ack.readFields(downstreamIn);\n               ackRecvNanoTime \u003d System.nanoTime();\n               if (LOG.isDebugEnabled()) {\n                 LOG.debug(myString + \" got \" + ack);\n               }\n+              // Process an OOB ACK.\n+              Status oobStatus \u003d ack.getOOBStatus();\n+              if (oobStatus !\u003d null) {\n+                LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n+                sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n+                    Status.SUCCESS);\n+                continue;\n+              }\n               seqno \u003d ack.getSeqno();\n             }\n             if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                 || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n               pkt \u003d waitForAckHead(seqno);\n               if (!isRunning()) {\n                 break;\n               }\n               expected \u003d pkt.seqno;\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                   \u0026\u0026 seqno !\u003d expected) {\n                 throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                     + \", received\u003d\" + seqno);\n               }\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                 // The total ack time includes the ack times of downstream\n                 // nodes.\n                 // The value is 0 if this responder doesn\u0027t have a downstream\n                 // DN in the pipeline.\n                 totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                 // Report the elapsed time from ack send to ack receive minus\n                 // the downstream ack time.\n                 long ackTimeNanos \u003d totalAckTimeNanos\n                     - ack.getDownstreamAckTimeNanos();\n                 if (ackTimeNanos \u003c 0) {\n                   if (LOG.isDebugEnabled()) {\n                     LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                         + \"ns.\");\n                   }\n                 } else {\n                   datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                 }\n               }\n               lastPacketInBlock \u003d pkt.lastPacketInBlock;\n             }\n           } catch (InterruptedException ine) {\n             isInterrupted \u003d true;\n           } catch (IOException ioe) {\n             if (Thread.interrupted()) {\n               isInterrupted \u003d true;\n             } else {\n               // continue to run even if can not read from mirror\n               // notify client of the error\n               // and wait for the client to shut down the pipeline\n               mirrorError \u003d true;\n               LOG.info(myString, ioe);\n             }\n           }\n \n           if (Thread.interrupted() || isInterrupted) {\n             /*\n              * The receiver thread cancelled this thread. We could also check\n              * any other status updates from the receiver thread (e.g. if it is\n              * ok to write to replyOut). It is prudent to not send any more\n              * status back to the client because this datanode has a problem.\n              * The upstream datanode will detect that this datanode is bad, and\n              * rightly so.\n+             *\n+             * The receiver thread can also interrupt this thread for sending\n+             * an out-of-band response upstream.\n              */\n             LOG.info(myString + \": Thread is interrupted.\");\n             running \u003d false;\n             continue;\n           }\n \n           if (lastPacketInBlock) {\n             // Finalize the block and close the block file\n             finalizeBlock(startTime);\n           }\n \n           sendAckUpstream(ack, expected, totalAckTimeNanos,\n               (pkt !\u003d null ? pkt.offsetInBlock : 0), \n               (pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS));\n           if (pkt !\u003d null) {\n             // remove the packet from the ack queue\n             removeAckHead();\n           }\n         } catch (IOException e) {\n           LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n           if (running) {\n             try {\n               datanode.checkDiskError(e); // may throw an exception here\n             } catch (IOException ioe) {\n               LOG.warn(\"DataNode.checkDiskError failed in run() with: \", ioe);\n             }\n             LOG.info(myString, e);\n             running \u003d false;\n             if (!Thread.interrupted()) { // failure not caused by interruption\n               receiverThread.interrupt();\n             }\n           }\n         } catch (Throwable e) {\n           if (running) {\n             LOG.info(myString, e);\n             running \u003d false;\n             receiverThread.interrupt();\n           }\n         }\n       }\n       LOG.info(myString + \" terminating\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n        long totalAckTimeNanos \u003d 0;\n        boolean isInterrupted \u003d false;\n        try {\n          Packet pkt \u003d null;\n          long expected \u003d -2;\n          PipelineAck ack \u003d new PipelineAck();\n          long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n          long ackRecvNanoTime \u003d 0;\n          try {\n            if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n              // read an ack from downstream datanode\n              ack.readFields(downstreamIn);\n              ackRecvNanoTime \u003d System.nanoTime();\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(myString + \" got \" + ack);\n              }\n              // Process an OOB ACK.\n              Status oobStatus \u003d ack.getOOBStatus();\n              if (oobStatus !\u003d null) {\n                LOG.info(\"Relaying an out of band ack of type \" + oobStatus);\n                sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, 0L, 0L,\n                    Status.SUCCESS);\n                continue;\n              }\n              seqno \u003d ack.getSeqno();\n            }\n            if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n              pkt \u003d waitForAckHead(seqno);\n              if (!isRunning()) {\n                break;\n              }\n              expected \u003d pkt.seqno;\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                  \u0026\u0026 seqno !\u003d expected) {\n                throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                    + \", received\u003d\" + seqno);\n              }\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                // The total ack time includes the ack times of downstream\n                // nodes.\n                // The value is 0 if this responder doesn\u0027t have a downstream\n                // DN in the pipeline.\n                totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                // Report the elapsed time from ack send to ack receive minus\n                // the downstream ack time.\n                long ackTimeNanos \u003d totalAckTimeNanos\n                    - ack.getDownstreamAckTimeNanos();\n                if (ackTimeNanos \u003c 0) {\n                  if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                        + \"ns.\");\n                  }\n                } else {\n                  datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                }\n              }\n              lastPacketInBlock \u003d pkt.lastPacketInBlock;\n            }\n          } catch (InterruptedException ine) {\n            isInterrupted \u003d true;\n          } catch (IOException ioe) {\n            if (Thread.interrupted()) {\n              isInterrupted \u003d true;\n            } else {\n              // continue to run even if can not read from mirror\n              // notify client of the error\n              // and wait for the client to shut down the pipeline\n              mirrorError \u003d true;\n              LOG.info(myString, ioe);\n            }\n          }\n\n          if (Thread.interrupted() || isInterrupted) {\n            /*\n             * The receiver thread cancelled this thread. We could also check\n             * any other status updates from the receiver thread (e.g. if it is\n             * ok to write to replyOut). It is prudent to not send any more\n             * status back to the client because this datanode has a problem.\n             * The upstream datanode will detect that this datanode is bad, and\n             * rightly so.\n             *\n             * The receiver thread can also interrupt this thread for sending\n             * an out-of-band response upstream.\n             */\n            LOG.info(myString + \": Thread is interrupted.\");\n            running \u003d false;\n            continue;\n          }\n\n          if (lastPacketInBlock) {\n            // Finalize the block and close the block file\n            finalizeBlock(startTime);\n          }\n\n          sendAckUpstream(ack, expected, totalAckTimeNanos,\n              (pkt !\u003d null ? pkt.offsetInBlock : 0), \n              (pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS));\n          if (pkt !\u003d null) {\n            // remove the packet from the ack queue\n            removeAckHead();\n          }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n          if (running) {\n            try {\n              datanode.checkDiskError(e); // may throw an exception here\n            } catch (IOException ioe) {\n              LOG.warn(\"DataNode.checkDiskError failed in run() with: \", ioe);\n            }\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "98a692fd6361365db4afb9523a5d83ee32774112": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3875. Issue handling checksum errors in write pipeline. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1484808 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/05/13 6:42 AM",
      "commitName": "98a692fd6361365db4afb9523a5d83ee32774112",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "06/03/13 11:15 AM",
      "commitNameOld": "638801cce16fc1dc3259c541dc30a599faaddda1",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 75.77,
      "commitsBetweenForRepo": 469,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,118 +1,119 @@\n     public void run() {\n       boolean lastPacketInBlock \u003d false;\n       final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n       while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n         long totalAckTimeNanos \u003d 0;\n         boolean isInterrupted \u003d false;\n         try {\n           Packet pkt \u003d null;\n           long expected \u003d -2;\n           PipelineAck ack \u003d new PipelineAck();\n           long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n           long ackRecvNanoTime \u003d 0;\n           try {\n             if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n               // read an ack from downstream datanode\n               ack.readFields(downstreamIn);\n               ackRecvNanoTime \u003d System.nanoTime();\n               if (LOG.isDebugEnabled()) {\n                 LOG.debug(myString + \" got \" + ack);\n               }\n               seqno \u003d ack.getSeqno();\n             }\n             if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                 || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n               pkt \u003d waitForAckHead(seqno);\n               if (!isRunning()) {\n                 break;\n               }\n               expected \u003d pkt.seqno;\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                   \u0026\u0026 seqno !\u003d expected) {\n                 throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                     + \", received\u003d\" + seqno);\n               }\n               if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                 // The total ack time includes the ack times of downstream\n                 // nodes.\n                 // The value is 0 if this responder doesn\u0027t have a downstream\n                 // DN in the pipeline.\n                 totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                 // Report the elapsed time from ack send to ack receive minus\n                 // the downstream ack time.\n                 long ackTimeNanos \u003d totalAckTimeNanos\n                     - ack.getDownstreamAckTimeNanos();\n                 if (ackTimeNanos \u003c 0) {\n                   if (LOG.isDebugEnabled()) {\n                     LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                         + \"ns.\");\n                   }\n                 } else {\n                   datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                 }\n               }\n               lastPacketInBlock \u003d pkt.lastPacketInBlock;\n             }\n           } catch (InterruptedException ine) {\n             isInterrupted \u003d true;\n           } catch (IOException ioe) {\n             if (Thread.interrupted()) {\n               isInterrupted \u003d true;\n             } else {\n               // continue to run even if can not read from mirror\n               // notify client of the error\n               // and wait for the client to shut down the pipeline\n               mirrorError \u003d true;\n               LOG.info(myString, ioe);\n             }\n           }\n \n           if (Thread.interrupted() || isInterrupted) {\n             /*\n              * The receiver thread cancelled this thread. We could also check\n              * any other status updates from the receiver thread (e.g. if it is\n              * ok to write to replyOut). It is prudent to not send any more\n              * status back to the client because this datanode has a problem.\n              * The upstream datanode will detect that this datanode is bad, and\n              * rightly so.\n              */\n             LOG.info(myString + \": Thread is interrupted.\");\n             running \u003d false;\n             continue;\n           }\n \n           if (lastPacketInBlock) {\n             // Finalize the block and close the block file\n             finalizeBlock(startTime);\n           }\n \n           sendAckUpstream(ack, expected, totalAckTimeNanos,\n-              (pkt !\u003d null ? pkt.offsetInBlock : 0));\n+              (pkt !\u003d null ? pkt.offsetInBlock : 0), \n+              (pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS));\n           if (pkt !\u003d null) {\n             // remove the packet from the ack queue\n             removeAckHead();\n           }\n         } catch (IOException e) {\n           LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n           if (running) {\n             try {\n               datanode.checkDiskError(e); // may throw an exception here\n             } catch (IOException ioe) {\n               LOG.warn(\"DataNode.checkDiskError failed in run() with: \", ioe);\n             }\n             LOG.info(myString, e);\n             running \u003d false;\n             if (!Thread.interrupted()) { // failure not caused by interruption\n               receiverThread.interrupt();\n             }\n           }\n         } catch (Throwable e) {\n           if (running) {\n             LOG.info(myString, e);\n             running \u003d false;\n             receiverThread.interrupt();\n           }\n         }\n       }\n       LOG.info(myString + \" terminating\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n        long totalAckTimeNanos \u003d 0;\n        boolean isInterrupted \u003d false;\n        try {\n          Packet pkt \u003d null;\n          long expected \u003d -2;\n          PipelineAck ack \u003d new PipelineAck();\n          long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n          long ackRecvNanoTime \u003d 0;\n          try {\n            if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n              // read an ack from downstream datanode\n              ack.readFields(downstreamIn);\n              ackRecvNanoTime \u003d System.nanoTime();\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(myString + \" got \" + ack);\n              }\n              seqno \u003d ack.getSeqno();\n            }\n            if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n              pkt \u003d waitForAckHead(seqno);\n              if (!isRunning()) {\n                break;\n              }\n              expected \u003d pkt.seqno;\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                  \u0026\u0026 seqno !\u003d expected) {\n                throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                    + \", received\u003d\" + seqno);\n              }\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                // The total ack time includes the ack times of downstream\n                // nodes.\n                // The value is 0 if this responder doesn\u0027t have a downstream\n                // DN in the pipeline.\n                totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                // Report the elapsed time from ack send to ack receive minus\n                // the downstream ack time.\n                long ackTimeNanos \u003d totalAckTimeNanos\n                    - ack.getDownstreamAckTimeNanos();\n                if (ackTimeNanos \u003c 0) {\n                  if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                        + \"ns.\");\n                  }\n                } else {\n                  datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                }\n              }\n              lastPacketInBlock \u003d pkt.lastPacketInBlock;\n            }\n          } catch (InterruptedException ine) {\n            isInterrupted \u003d true;\n          } catch (IOException ioe) {\n            if (Thread.interrupted()) {\n              isInterrupted \u003d true;\n            } else {\n              // continue to run even if can not read from mirror\n              // notify client of the error\n              // and wait for the client to shut down the pipeline\n              mirrorError \u003d true;\n              LOG.info(myString, ioe);\n            }\n          }\n\n          if (Thread.interrupted() || isInterrupted) {\n            /*\n             * The receiver thread cancelled this thread. We could also check\n             * any other status updates from the receiver thread (e.g. if it is\n             * ok to write to replyOut). It is prudent to not send any more\n             * status back to the client because this datanode has a problem.\n             * The upstream datanode will detect that this datanode is bad, and\n             * rightly so.\n             */\n            LOG.info(myString + \": Thread is interrupted.\");\n            running \u003d false;\n            continue;\n          }\n\n          if (lastPacketInBlock) {\n            // Finalize the block and close the block file\n            finalizeBlock(startTime);\n          }\n\n          sendAckUpstream(ack, expected, totalAckTimeNanos,\n              (pkt !\u003d null ? pkt.offsetInBlock : 0), \n              (pkt !\u003d null ? pkt.ackStatus : Status.SUCCESS));\n          if (pkt !\u003d null) {\n            // remove the packet from the ack queue\n            removeAckHead();\n          }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n          if (running) {\n            try {\n              datanode.checkDiskError(e); // may throw an exception here\n            } catch (IOException ioe) {\n              LOG.warn(\"DataNode.checkDiskError failed in run() with: \", ioe);\n            }\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "7e56bfe40589a1aa9b5ef20b342e421823cd0592": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4200. Reduce the size of synchronized sections in PacketResponder. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1413826 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/11/12 12:47 PM",
      "commitName": "7e56bfe40589a1aa9b5ef20b342e421823cd0592",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "06/11/12 2:34 PM",
      "commitNameOld": "1e7010cf38115604d6fa3aa5728362c86644e66a",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 19.93,
      "commitsBetweenForRepo": 99,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,168 +1,118 @@\n     public void run() {\n       boolean lastPacketInBlock \u003d false;\n       final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n-      while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 !lastPacketInBlock) {\n-\n+      while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n         long totalAckTimeNanos \u003d 0;\n         boolean isInterrupted \u003d false;\n         try {\n-            Packet pkt \u003d null;\n-            long expected \u003d -2;\n-            PipelineAck ack \u003d new PipelineAck();\n-            long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n-            long ackRecvNanoTime \u003d 0;\n-            try {\n-              if (type !\u003d PacketResponderType.LAST_IN_PIPELINE\n-                  \u0026\u0026 !mirrorError) {\n-                // read an ack from downstream datanode\n-                ack.readFields(downstreamIn);\n-                ackRecvNanoTime \u003d System.nanoTime();\n-                if (LOG.isDebugEnabled()) {\n-                  LOG.debug(myString + \" got \" + ack);\n-                }\n-                seqno \u003d ack.getSeqno();\n+          Packet pkt \u003d null;\n+          long expected \u003d -2;\n+          PipelineAck ack \u003d new PipelineAck();\n+          long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n+          long ackRecvNanoTime \u003d 0;\n+          try {\n+            if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n+              // read an ack from downstream datanode\n+              ack.readFields(downstreamIn);\n+              ackRecvNanoTime \u003d System.nanoTime();\n+              if (LOG.isDebugEnabled()) {\n+                LOG.debug(myString + \" got \" + ack);\n               }\n-              if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n-                  || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n-                synchronized (this) {\n-                  while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 ackQueue.size() \u003d\u003d 0) {\n-                    if (LOG.isDebugEnabled()) {\n-                      LOG.debug(myString + \": seqno\u003d\" + seqno +\n-                                \" waiting for local datanode to finish write.\");\n-                    }\n-                    wait();\n+              seqno \u003d ack.getSeqno();\n+            }\n+            if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n+                || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n+              pkt \u003d waitForAckHead(seqno);\n+              if (!isRunning()) {\n+                break;\n+              }\n+              expected \u003d pkt.seqno;\n+              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n+                  \u0026\u0026 seqno !\u003d expected) {\n+                throw new IOException(myString + \"seqno: expected\u003d\" + expected\n+                    + \", received\u003d\" + seqno);\n+              }\n+              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n+                // The total ack time includes the ack times of downstream\n+                // nodes.\n+                // The value is 0 if this responder doesn\u0027t have a downstream\n+                // DN in the pipeline.\n+                totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n+                // Report the elapsed time from ack send to ack receive minus\n+                // the downstream ack time.\n+                long ackTimeNanos \u003d totalAckTimeNanos\n+                    - ack.getDownstreamAckTimeNanos();\n+                if (ackTimeNanos \u003c 0) {\n+                  if (LOG.isDebugEnabled()) {\n+                    LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n+                        + \"ns.\");\n                   }\n-                  if (!running || !datanode.shouldRun) {\n-                    break;\n-                  }\n-                  pkt \u003d ackQueue.getFirst();\n-                  expected \u003d pkt.seqno;\n-                  if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n-                      \u0026\u0026 seqno !\u003d expected) {\n-                    throw new IOException(myString + \"seqno: expected\u003d\"\n-                        + expected + \", received\u003d\" + seqno);\n-                  }\n-                  if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n-                    // The total ack time includes the ack times of downstream nodes.\n-                    // The value is 0 if this responder doesn\u0027t have a downstream\n-                    // DN in the pipeline.\n-                    totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n-                    // Report the elapsed time from ack send to ack receive minus\n-                    // the downstream ack time.\n-                    long ackTimeNanos \u003d totalAckTimeNanos - ack.getDownstreamAckTimeNanos();\n-                    if (ackTimeNanos \u003c 0) {\n-                      if (LOG.isDebugEnabled()) {\n-                        LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos + \"ns.\");\n-                      }\n-                    } else {\n-                      datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n-                    }\n-                  }\n-                  lastPacketInBlock \u003d pkt.lastPacketInBlock;\n+                } else {\n+                  datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                 }\n               }\n-            } catch (InterruptedException ine) {\n+              lastPacketInBlock \u003d pkt.lastPacketInBlock;\n+            }\n+          } catch (InterruptedException ine) {\n+            isInterrupted \u003d true;\n+          } catch (IOException ioe) {\n+            if (Thread.interrupted()) {\n               isInterrupted \u003d true;\n-            } catch (IOException ioe) {\n-              if (Thread.interrupted()) {\n-                isInterrupted \u003d true;\n-              } else {\n-                // continue to run even if can not read from mirror\n-                // notify client of the error\n-                // and wait for the client to shut down the pipeline\n-                mirrorError \u003d true;\n-                LOG.info(myString, ioe);\n-              }\n-            }\n-\n-            if (Thread.interrupted() || isInterrupted) {\n-              /* The receiver thread cancelled this thread. \n-               * We could also check any other status updates from the \n-               * receiver thread (e.g. if it is ok to write to replyOut). \n-               * It is prudent to not send any more status back to the client\n-               * because this datanode has a problem. The upstream datanode\n-               * will detect that this datanode is bad, and rightly so.\n-               */\n-              LOG.info(myString + \": Thread is interrupted.\");\n-              running \u003d false;\n-              continue;\n-            }\n-            \n-            // If this is the last packet in block, then close block\n-            // file and finalize the block before responding success\n-            if (lastPacketInBlock) {\n-              BlockReceiver.this.close();\n-              final long endTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n-              block.setNumBytes(replicaInfo.getNumBytes());\n-              datanode.data.finalizeBlock(block);\n-              datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n-              if (ClientTraceLog.isInfoEnabled() \u0026\u0026 isClient) {\n-                long offset \u003d 0;\n-                DatanodeRegistration dnR \u003d \n-                  datanode.getDNRegistrationForBP(block.getBlockPoolId());\n-                ClientTraceLog.info(String.format(DN_CLIENTTRACE_FORMAT,\n-                      inAddr, myAddr, block.getNumBytes(),\n-                      \"HDFS_WRITE\", clientname, offset,\n-                      dnR.getStorageID(), block, endTime-startTime));\n-              } else {\n-                LOG.info(\"Received \" + block + \" size \"\n-                    + block.getNumBytes() + \" from \" + inAddr);\n-              }\n-            }\n-\n-            // construct my ack message\n-            Status[] replies \u003d null;\n-            if (mirrorError) { // ack read error\n-              replies \u003d new Status[2];\n-              replies[0] \u003d Status.SUCCESS;\n-              replies[1] \u003d Status.ERROR;\n             } else {\n-              short ackLen \u003d type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE? 0\n-                  : ack.getNumOfReplies();\n-              replies \u003d new Status[1+ackLen];\n-              replies[0] \u003d Status.SUCCESS;\n-              for (int i\u003d0; i\u003cackLen; i++) {\n-                replies[i+1] \u003d ack.getReply(i);\n-              }\n+              // continue to run even if can not read from mirror\n+              // notify client of the error\n+              // and wait for the client to shut down the pipeline\n+              mirrorError \u003d true;\n+              LOG.info(myString, ioe);\n             }\n-            PipelineAck replyAck \u003d new PipelineAck(expected, replies, totalAckTimeNanos);\n-            \n-            if (replyAck.isSuccess() \u0026\u0026 \n-                 pkt.offsetInBlock \u003e replicaInfo.getBytesAcked())\n-                replicaInfo.setBytesAcked(pkt.offsetInBlock);\n+          }\n \n-            // send my ack back to upstream datanode\n-            replyAck.write(upstreamOut);\n-            upstreamOut.flush();\n-            if (LOG.isDebugEnabled()) {\n-              LOG.debug(myString + \", replyAck\u003d\" + replyAck);\n-            }\n-            if (pkt !\u003d null) {\n-              // remove the packet from the ack queue\n-              removeAckHead();\n-              // update bytes acked\n-            }\n+          if (Thread.interrupted() || isInterrupted) {\n+            /*\n+             * The receiver thread cancelled this thread. We could also check\n+             * any other status updates from the receiver thread (e.g. if it is\n+             * ok to write to replyOut). It is prudent to not send any more\n+             * status back to the client because this datanode has a problem.\n+             * The upstream datanode will detect that this datanode is bad, and\n+             * rightly so.\n+             */\n+            LOG.info(myString + \": Thread is interrupted.\");\n+            running \u003d false;\n+            continue;\n+          }\n+\n+          if (lastPacketInBlock) {\n+            // Finalize the block and close the block file\n+            finalizeBlock(startTime);\n+          }\n+\n+          sendAckUpstream(ack, expected, totalAckTimeNanos,\n+              (pkt !\u003d null ? pkt.offsetInBlock : 0));\n+          if (pkt !\u003d null) {\n+            // remove the packet from the ack queue\n+            removeAckHead();\n+          }\n         } catch (IOException e) {\n           LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n           if (running) {\n             try {\n               datanode.checkDiskError(e); // may throw an exception here\n             } catch (IOException ioe) {\n               LOG.warn(\"DataNode.checkDiskError failed in run() with: \", ioe);\n             }\n             LOG.info(myString, e);\n             running \u003d false;\n             if (!Thread.interrupted()) { // failure not caused by interruption\n               receiverThread.interrupt();\n             }\n           }\n         } catch (Throwable e) {\n           if (running) {\n             LOG.info(myString, e);\n             running \u003d false;\n             receiverThread.interrupt();\n           }\n         }\n       }\n       LOG.info(myString + \" terminating\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (isRunning() \u0026\u0026 !lastPacketInBlock) {\n        long totalAckTimeNanos \u003d 0;\n        boolean isInterrupted \u003d false;\n        try {\n          Packet pkt \u003d null;\n          long expected \u003d -2;\n          PipelineAck ack \u003d new PipelineAck();\n          long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n          long ackRecvNanoTime \u003d 0;\n          try {\n            if (type !\u003d PacketResponderType.LAST_IN_PIPELINE \u0026\u0026 !mirrorError) {\n              // read an ack from downstream datanode\n              ack.readFields(downstreamIn);\n              ackRecvNanoTime \u003d System.nanoTime();\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(myString + \" got \" + ack);\n              }\n              seqno \u003d ack.getSeqno();\n            }\n            if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n              pkt \u003d waitForAckHead(seqno);\n              if (!isRunning()) {\n                break;\n              }\n              expected \u003d pkt.seqno;\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                  \u0026\u0026 seqno !\u003d expected) {\n                throw new IOException(myString + \"seqno: expected\u003d\" + expected\n                    + \", received\u003d\" + seqno);\n              }\n              if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                // The total ack time includes the ack times of downstream\n                // nodes.\n                // The value is 0 if this responder doesn\u0027t have a downstream\n                // DN in the pipeline.\n                totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                // Report the elapsed time from ack send to ack receive minus\n                // the downstream ack time.\n                long ackTimeNanos \u003d totalAckTimeNanos\n                    - ack.getDownstreamAckTimeNanos();\n                if (ackTimeNanos \u003c 0) {\n                  if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos\n                        + \"ns.\");\n                  }\n                } else {\n                  datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                }\n              }\n              lastPacketInBlock \u003d pkt.lastPacketInBlock;\n            }\n          } catch (InterruptedException ine) {\n            isInterrupted \u003d true;\n          } catch (IOException ioe) {\n            if (Thread.interrupted()) {\n              isInterrupted \u003d true;\n            } else {\n              // continue to run even if can not read from mirror\n              // notify client of the error\n              // and wait for the client to shut down the pipeline\n              mirrorError \u003d true;\n              LOG.info(myString, ioe);\n            }\n          }\n\n          if (Thread.interrupted() || isInterrupted) {\n            /*\n             * The receiver thread cancelled this thread. We could also check\n             * any other status updates from the receiver thread (e.g. if it is\n             * ok to write to replyOut). It is prudent to not send any more\n             * status back to the client because this datanode has a problem.\n             * The upstream datanode will detect that this datanode is bad, and\n             * rightly so.\n             */\n            LOG.info(myString + \": Thread is interrupted.\");\n            running \u003d false;\n            continue;\n          }\n\n          if (lastPacketInBlock) {\n            // Finalize the block and close the block file\n            finalizeBlock(startTime);\n          }\n\n          sendAckUpstream(ack, expected, totalAckTimeNanos,\n              (pkt !\u003d null ? pkt.offsetInBlock : 0));\n          if (pkt !\u003d null) {\n            // remove the packet from the ack queue\n            removeAckHead();\n          }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n          if (running) {\n            try {\n              datanode.checkDiskError(e); // may throw an exception here\n            } catch (IOException ioe) {\n              LOG.warn(\"DataNode.checkDiskError failed in run() with: \", ioe);\n            }\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4122. Cleanup HDFS logs and reduce the size of logged messages. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1403120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/10/12 4:10 PM",
      "commitName": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "09/08/12 2:31 PM",
      "commitNameOld": "9ea7c06468d236452f03c38a31d1a45f7f09dc50",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 80.07,
      "commitsBetweenForRepo": 496,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,168 +1,168 @@\n     public void run() {\n       boolean lastPacketInBlock \u003d false;\n       final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n       while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 !lastPacketInBlock) {\n \n         long totalAckTimeNanos \u003d 0;\n         boolean isInterrupted \u003d false;\n         try {\n             Packet pkt \u003d null;\n             long expected \u003d -2;\n             PipelineAck ack \u003d new PipelineAck();\n             long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n             long ackRecvNanoTime \u003d 0;\n             try {\n               if (type !\u003d PacketResponderType.LAST_IN_PIPELINE\n                   \u0026\u0026 !mirrorError) {\n                 // read an ack from downstream datanode\n                 ack.readFields(downstreamIn);\n                 ackRecvNanoTime \u003d System.nanoTime();\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(myString + \" got \" + ack);\n                 }\n                 seqno \u003d ack.getSeqno();\n               }\n               if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                   || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n                 synchronized (this) {\n                   while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 ackQueue.size() \u003d\u003d 0) {\n                     if (LOG.isDebugEnabled()) {\n                       LOG.debug(myString + \": seqno\u003d\" + seqno +\n                                 \" waiting for local datanode to finish write.\");\n                     }\n                     wait();\n                   }\n                   if (!running || !datanode.shouldRun) {\n                     break;\n                   }\n                   pkt \u003d ackQueue.getFirst();\n                   expected \u003d pkt.seqno;\n                   if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                       \u0026\u0026 seqno !\u003d expected) {\n                     throw new IOException(myString + \"seqno: expected\u003d\"\n                         + expected + \", received\u003d\" + seqno);\n                   }\n                   if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                     // The total ack time includes the ack times of downstream nodes.\n                     // The value is 0 if this responder doesn\u0027t have a downstream\n                     // DN in the pipeline.\n                     totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                     // Report the elapsed time from ack send to ack receive minus\n                     // the downstream ack time.\n                     long ackTimeNanos \u003d totalAckTimeNanos - ack.getDownstreamAckTimeNanos();\n                     if (ackTimeNanos \u003c 0) {\n                       if (LOG.isDebugEnabled()) {\n                         LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos + \"ns.\");\n                       }\n                     } else {\n                       datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                     }\n                   }\n                   lastPacketInBlock \u003d pkt.lastPacketInBlock;\n                 }\n               }\n             } catch (InterruptedException ine) {\n               isInterrupted \u003d true;\n             } catch (IOException ioe) {\n               if (Thread.interrupted()) {\n                 isInterrupted \u003d true;\n               } else {\n                 // continue to run even if can not read from mirror\n                 // notify client of the error\n                 // and wait for the client to shut down the pipeline\n                 mirrorError \u003d true;\n                 LOG.info(myString, ioe);\n               }\n             }\n \n             if (Thread.interrupted() || isInterrupted) {\n               /* The receiver thread cancelled this thread. \n                * We could also check any other status updates from the \n                * receiver thread (e.g. if it is ok to write to replyOut). \n                * It is prudent to not send any more status back to the client\n                * because this datanode has a problem. The upstream datanode\n                * will detect that this datanode is bad, and rightly so.\n                */\n               LOG.info(myString + \": Thread is interrupted.\");\n               running \u003d false;\n               continue;\n             }\n             \n             // If this is the last packet in block, then close block\n             // file and finalize the block before responding success\n             if (lastPacketInBlock) {\n               BlockReceiver.this.close();\n               final long endTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n               block.setNumBytes(replicaInfo.getNumBytes());\n               datanode.data.finalizeBlock(block);\n               datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n               if (ClientTraceLog.isInfoEnabled() \u0026\u0026 isClient) {\n                 long offset \u003d 0;\n                 DatanodeRegistration dnR \u003d \n                   datanode.getDNRegistrationForBP(block.getBlockPoolId());\n                 ClientTraceLog.info(String.format(DN_CLIENTTRACE_FORMAT,\n                       inAddr, myAddr, block.getNumBytes(),\n                       \"HDFS_WRITE\", clientname, offset,\n                       dnR.getStorageID(), block, endTime-startTime));\n               } else {\n-                LOG.info(\"Received block \" + block + \" of size \"\n+                LOG.info(\"Received \" + block + \" size \"\n                     + block.getNumBytes() + \" from \" + inAddr);\n               }\n             }\n \n             // construct my ack message\n             Status[] replies \u003d null;\n             if (mirrorError) { // ack read error\n               replies \u003d new Status[2];\n               replies[0] \u003d Status.SUCCESS;\n               replies[1] \u003d Status.ERROR;\n             } else {\n               short ackLen \u003d type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE? 0\n                   : ack.getNumOfReplies();\n               replies \u003d new Status[1+ackLen];\n               replies[0] \u003d Status.SUCCESS;\n               for (int i\u003d0; i\u003cackLen; i++) {\n                 replies[i+1] \u003d ack.getReply(i);\n               }\n             }\n             PipelineAck replyAck \u003d new PipelineAck(expected, replies, totalAckTimeNanos);\n             \n             if (replyAck.isSuccess() \u0026\u0026 \n                  pkt.offsetInBlock \u003e replicaInfo.getBytesAcked())\n                 replicaInfo.setBytesAcked(pkt.offsetInBlock);\n \n             // send my ack back to upstream datanode\n             replyAck.write(upstreamOut);\n             upstreamOut.flush();\n             if (LOG.isDebugEnabled()) {\n               LOG.debug(myString + \", replyAck\u003d\" + replyAck);\n             }\n             if (pkt !\u003d null) {\n               // remove the packet from the ack queue\n               removeAckHead();\n               // update bytes acked\n             }\n         } catch (IOException e) {\n           LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n           if (running) {\n             try {\n               datanode.checkDiskError(e); // may throw an exception here\n             } catch (IOException ioe) {\n               LOG.warn(\"DataNode.checkDiskError failed in run() with: \", ioe);\n             }\n             LOG.info(myString, e);\n             running \u003d false;\n             if (!Thread.interrupted()) { // failure not caused by interruption\n               receiverThread.interrupt();\n             }\n           }\n         } catch (Throwable e) {\n           if (running) {\n             LOG.info(myString, e);\n             running \u003d false;\n             receiverThread.interrupt();\n           }\n         }\n       }\n       LOG.info(myString + \" terminating\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 !lastPacketInBlock) {\n\n        long totalAckTimeNanos \u003d 0;\n        boolean isInterrupted \u003d false;\n        try {\n            Packet pkt \u003d null;\n            long expected \u003d -2;\n            PipelineAck ack \u003d new PipelineAck();\n            long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n            long ackRecvNanoTime \u003d 0;\n            try {\n              if (type !\u003d PacketResponderType.LAST_IN_PIPELINE\n                  \u0026\u0026 !mirrorError) {\n                // read an ack from downstream datanode\n                ack.readFields(downstreamIn);\n                ackRecvNanoTime \u003d System.nanoTime();\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(myString + \" got \" + ack);\n                }\n                seqno \u003d ack.getSeqno();\n              }\n              if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                  || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n                synchronized (this) {\n                  while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 ackQueue.size() \u003d\u003d 0) {\n                    if (LOG.isDebugEnabled()) {\n                      LOG.debug(myString + \": seqno\u003d\" + seqno +\n                                \" waiting for local datanode to finish write.\");\n                    }\n                    wait();\n                  }\n                  if (!running || !datanode.shouldRun) {\n                    break;\n                  }\n                  pkt \u003d ackQueue.getFirst();\n                  expected \u003d pkt.seqno;\n                  if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                      \u0026\u0026 seqno !\u003d expected) {\n                    throw new IOException(myString + \"seqno: expected\u003d\"\n                        + expected + \", received\u003d\" + seqno);\n                  }\n                  if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                    // The total ack time includes the ack times of downstream nodes.\n                    // The value is 0 if this responder doesn\u0027t have a downstream\n                    // DN in the pipeline.\n                    totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                    // Report the elapsed time from ack send to ack receive minus\n                    // the downstream ack time.\n                    long ackTimeNanos \u003d totalAckTimeNanos - ack.getDownstreamAckTimeNanos();\n                    if (ackTimeNanos \u003c 0) {\n                      if (LOG.isDebugEnabled()) {\n                        LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos + \"ns.\");\n                      }\n                    } else {\n                      datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                    }\n                  }\n                  lastPacketInBlock \u003d pkt.lastPacketInBlock;\n                }\n              }\n            } catch (InterruptedException ine) {\n              isInterrupted \u003d true;\n            } catch (IOException ioe) {\n              if (Thread.interrupted()) {\n                isInterrupted \u003d true;\n              } else {\n                // continue to run even if can not read from mirror\n                // notify client of the error\n                // and wait for the client to shut down the pipeline\n                mirrorError \u003d true;\n                LOG.info(myString, ioe);\n              }\n            }\n\n            if (Thread.interrupted() || isInterrupted) {\n              /* The receiver thread cancelled this thread. \n               * We could also check any other status updates from the \n               * receiver thread (e.g. if it is ok to write to replyOut). \n               * It is prudent to not send any more status back to the client\n               * because this datanode has a problem. The upstream datanode\n               * will detect that this datanode is bad, and rightly so.\n               */\n              LOG.info(myString + \": Thread is interrupted.\");\n              running \u003d false;\n              continue;\n            }\n            \n            // If this is the last packet in block, then close block\n            // file and finalize the block before responding success\n            if (lastPacketInBlock) {\n              BlockReceiver.this.close();\n              final long endTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n              block.setNumBytes(replicaInfo.getNumBytes());\n              datanode.data.finalizeBlock(block);\n              datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n              if (ClientTraceLog.isInfoEnabled() \u0026\u0026 isClient) {\n                long offset \u003d 0;\n                DatanodeRegistration dnR \u003d \n                  datanode.getDNRegistrationForBP(block.getBlockPoolId());\n                ClientTraceLog.info(String.format(DN_CLIENTTRACE_FORMAT,\n                      inAddr, myAddr, block.getNumBytes(),\n                      \"HDFS_WRITE\", clientname, offset,\n                      dnR.getStorageID(), block, endTime-startTime));\n              } else {\n                LOG.info(\"Received \" + block + \" size \"\n                    + block.getNumBytes() + \" from \" + inAddr);\n              }\n            }\n\n            // construct my ack message\n            Status[] replies \u003d null;\n            if (mirrorError) { // ack read error\n              replies \u003d new Status[2];\n              replies[0] \u003d Status.SUCCESS;\n              replies[1] \u003d Status.ERROR;\n            } else {\n              short ackLen \u003d type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE? 0\n                  : ack.getNumOfReplies();\n              replies \u003d new Status[1+ackLen];\n              replies[0] \u003d Status.SUCCESS;\n              for (int i\u003d0; i\u003cackLen; i++) {\n                replies[i+1] \u003d ack.getReply(i);\n              }\n            }\n            PipelineAck replyAck \u003d new PipelineAck(expected, replies, totalAckTimeNanos);\n            \n            if (replyAck.isSuccess() \u0026\u0026 \n                 pkt.offsetInBlock \u003e replicaInfo.getBytesAcked())\n                replicaInfo.setBytesAcked(pkt.offsetInBlock);\n\n            // send my ack back to upstream datanode\n            replyAck.write(upstreamOut);\n            upstreamOut.flush();\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(myString + \", replyAck\u003d\" + replyAck);\n            }\n            if (pkt !\u003d null) {\n              // remove the packet from the ack queue\n              removeAckHead();\n              // update bytes acked\n            }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n          if (running) {\n            try {\n              datanode.checkDiskError(e); // may throw an exception here\n            } catch (IOException ioe) {\n              LOG.warn(\"DataNode.checkDiskError failed in run() with: \", ioe);\n            }\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "e0ef844280b98dc699ed3f9d948b83828bb8d297": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3170. Add more useful metrics for write latency. Contributed by Matthew Jacobs.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1357970 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/07/12 3:18 PM",
      "commitName": "e0ef844280b98dc699ed3f9d948b83828bb8d297",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "30/05/12 12:10 PM",
      "commitNameOld": "83cf475050dba27e72b4e399491638c670621175",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 36.13,
      "commitsBetweenForRepo": 159,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,149 +1,168 @@\n     public void run() {\n       boolean lastPacketInBlock \u003d false;\n       final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n       while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 !lastPacketInBlock) {\n \n+        long totalAckTimeNanos \u003d 0;\n         boolean isInterrupted \u003d false;\n         try {\n             Packet pkt \u003d null;\n             long expected \u003d -2;\n             PipelineAck ack \u003d new PipelineAck();\n             long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n+            long ackRecvNanoTime \u003d 0;\n             try {\n               if (type !\u003d PacketResponderType.LAST_IN_PIPELINE\n                   \u0026\u0026 !mirrorError) {\n                 // read an ack from downstream datanode\n                 ack.readFields(downstreamIn);\n+                ackRecvNanoTime \u003d System.nanoTime();\n                 if (LOG.isDebugEnabled()) {\n                   LOG.debug(myString + \" got \" + ack);\n                 }\n                 seqno \u003d ack.getSeqno();\n               }\n               if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                   || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n                 synchronized (this) {\n                   while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 ackQueue.size() \u003d\u003d 0) {\n                     if (LOG.isDebugEnabled()) {\n                       LOG.debug(myString + \": seqno\u003d\" + seqno +\n                                 \" waiting for local datanode to finish write.\");\n                     }\n                     wait();\n                   }\n                   if (!running || !datanode.shouldRun) {\n                     break;\n                   }\n                   pkt \u003d ackQueue.getFirst();\n                   expected \u003d pkt.seqno;\n                   if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                       \u0026\u0026 seqno !\u003d expected) {\n                     throw new IOException(myString + \"seqno: expected\u003d\"\n                         + expected + \", received\u003d\" + seqno);\n                   }\n+                  if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n+                    // The total ack time includes the ack times of downstream nodes.\n+                    // The value is 0 if this responder doesn\u0027t have a downstream\n+                    // DN in the pipeline.\n+                    totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n+                    // Report the elapsed time from ack send to ack receive minus\n+                    // the downstream ack time.\n+                    long ackTimeNanos \u003d totalAckTimeNanos - ack.getDownstreamAckTimeNanos();\n+                    if (ackTimeNanos \u003c 0) {\n+                      if (LOG.isDebugEnabled()) {\n+                        LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos + \"ns.\");\n+                      }\n+                    } else {\n+                      datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n+                    }\n+                  }\n                   lastPacketInBlock \u003d pkt.lastPacketInBlock;\n                 }\n               }\n             } catch (InterruptedException ine) {\n               isInterrupted \u003d true;\n             } catch (IOException ioe) {\n               if (Thread.interrupted()) {\n                 isInterrupted \u003d true;\n               } else {\n                 // continue to run even if can not read from mirror\n                 // notify client of the error\n                 // and wait for the client to shut down the pipeline\n                 mirrorError \u003d true;\n                 LOG.info(myString, ioe);\n               }\n             }\n \n             if (Thread.interrupted() || isInterrupted) {\n               /* The receiver thread cancelled this thread. \n                * We could also check any other status updates from the \n                * receiver thread (e.g. if it is ok to write to replyOut). \n                * It is prudent to not send any more status back to the client\n                * because this datanode has a problem. The upstream datanode\n                * will detect that this datanode is bad, and rightly so.\n                */\n               LOG.info(myString + \": Thread is interrupted.\");\n               running \u003d false;\n               continue;\n             }\n             \n             // If this is the last packet in block, then close block\n             // file and finalize the block before responding success\n             if (lastPacketInBlock) {\n               BlockReceiver.this.close();\n               final long endTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n               block.setNumBytes(replicaInfo.getNumBytes());\n               datanode.data.finalizeBlock(block);\n               datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n               if (ClientTraceLog.isInfoEnabled() \u0026\u0026 isClient) {\n                 long offset \u003d 0;\n                 DatanodeRegistration dnR \u003d \n                   datanode.getDNRegistrationForBP(block.getBlockPoolId());\n                 ClientTraceLog.info(String.format(DN_CLIENTTRACE_FORMAT,\n                       inAddr, myAddr, block.getNumBytes(),\n                       \"HDFS_WRITE\", clientname, offset,\n                       dnR.getStorageID(), block, endTime-startTime));\n               } else {\n                 LOG.info(\"Received block \" + block + \" of size \"\n                     + block.getNumBytes() + \" from \" + inAddr);\n               }\n             }\n \n             // construct my ack message\n             Status[] replies \u003d null;\n             if (mirrorError) { // ack read error\n               replies \u003d new Status[2];\n               replies[0] \u003d Status.SUCCESS;\n               replies[1] \u003d Status.ERROR;\n             } else {\n               short ackLen \u003d type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE? 0\n                   : ack.getNumOfReplies();\n               replies \u003d new Status[1+ackLen];\n               replies[0] \u003d Status.SUCCESS;\n               for (int i\u003d0; i\u003cackLen; i++) {\n                 replies[i+1] \u003d ack.getReply(i);\n               }\n             }\n-            PipelineAck replyAck \u003d new PipelineAck(expected, replies);\n+            PipelineAck replyAck \u003d new PipelineAck(expected, replies, totalAckTimeNanos);\n             \n             if (replyAck.isSuccess() \u0026\u0026 \n                  pkt.offsetInBlock \u003e replicaInfo.getBytesAcked())\n                 replicaInfo.setBytesAcked(pkt.offsetInBlock);\n \n             // send my ack back to upstream datanode\n             replyAck.write(upstreamOut);\n             upstreamOut.flush();\n             if (LOG.isDebugEnabled()) {\n               LOG.debug(myString + \", replyAck\u003d\" + replyAck);\n             }\n             if (pkt !\u003d null) {\n               // remove the packet from the ack queue\n               removeAckHead();\n               // update bytes acked\n             }\n         } catch (IOException e) {\n           LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n           if (running) {\n             try {\n               datanode.checkDiskError(e); // may throw an exception here\n             } catch (IOException ioe) {\n               LOG.warn(\"DataNode.checkDiskError failed in run() with: \", ioe);\n             }\n             LOG.info(myString, e);\n             running \u003d false;\n             if (!Thread.interrupted()) { // failure not caused by interruption\n               receiverThread.interrupt();\n             }\n           }\n         } catch (Throwable e) {\n           if (running) {\n             LOG.info(myString, e);\n             running \u003d false;\n             receiverThread.interrupt();\n           }\n         }\n       }\n       LOG.info(myString + \" terminating\");\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 !lastPacketInBlock) {\n\n        long totalAckTimeNanos \u003d 0;\n        boolean isInterrupted \u003d false;\n        try {\n            Packet pkt \u003d null;\n            long expected \u003d -2;\n            PipelineAck ack \u003d new PipelineAck();\n            long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n            long ackRecvNanoTime \u003d 0;\n            try {\n              if (type !\u003d PacketResponderType.LAST_IN_PIPELINE\n                  \u0026\u0026 !mirrorError) {\n                // read an ack from downstream datanode\n                ack.readFields(downstreamIn);\n                ackRecvNanoTime \u003d System.nanoTime();\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(myString + \" got \" + ack);\n                }\n                seqno \u003d ack.getSeqno();\n              }\n              if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                  || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n                synchronized (this) {\n                  while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 ackQueue.size() \u003d\u003d 0) {\n                    if (LOG.isDebugEnabled()) {\n                      LOG.debug(myString + \": seqno\u003d\" + seqno +\n                                \" waiting for local datanode to finish write.\");\n                    }\n                    wait();\n                  }\n                  if (!running || !datanode.shouldRun) {\n                    break;\n                  }\n                  pkt \u003d ackQueue.getFirst();\n                  expected \u003d pkt.seqno;\n                  if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                      \u0026\u0026 seqno !\u003d expected) {\n                    throw new IOException(myString + \"seqno: expected\u003d\"\n                        + expected + \", received\u003d\" + seqno);\n                  }\n                  if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) {\n                    // The total ack time includes the ack times of downstream nodes.\n                    // The value is 0 if this responder doesn\u0027t have a downstream\n                    // DN in the pipeline.\n                    totalAckTimeNanos \u003d ackRecvNanoTime - pkt.ackEnqueueNanoTime;\n                    // Report the elapsed time from ack send to ack receive minus\n                    // the downstream ack time.\n                    long ackTimeNanos \u003d totalAckTimeNanos - ack.getDownstreamAckTimeNanos();\n                    if (ackTimeNanos \u003c 0) {\n                      if (LOG.isDebugEnabled()) {\n                        LOG.debug(\"Calculated invalid ack time: \" + ackTimeNanos + \"ns.\");\n                      }\n                    } else {\n                      datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);\n                    }\n                  }\n                  lastPacketInBlock \u003d pkt.lastPacketInBlock;\n                }\n              }\n            } catch (InterruptedException ine) {\n              isInterrupted \u003d true;\n            } catch (IOException ioe) {\n              if (Thread.interrupted()) {\n                isInterrupted \u003d true;\n              } else {\n                // continue to run even if can not read from mirror\n                // notify client of the error\n                // and wait for the client to shut down the pipeline\n                mirrorError \u003d true;\n                LOG.info(myString, ioe);\n              }\n            }\n\n            if (Thread.interrupted() || isInterrupted) {\n              /* The receiver thread cancelled this thread. \n               * We could also check any other status updates from the \n               * receiver thread (e.g. if it is ok to write to replyOut). \n               * It is prudent to not send any more status back to the client\n               * because this datanode has a problem. The upstream datanode\n               * will detect that this datanode is bad, and rightly so.\n               */\n              LOG.info(myString + \": Thread is interrupted.\");\n              running \u003d false;\n              continue;\n            }\n            \n            // If this is the last packet in block, then close block\n            // file and finalize the block before responding success\n            if (lastPacketInBlock) {\n              BlockReceiver.this.close();\n              final long endTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n              block.setNumBytes(replicaInfo.getNumBytes());\n              datanode.data.finalizeBlock(block);\n              datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n              if (ClientTraceLog.isInfoEnabled() \u0026\u0026 isClient) {\n                long offset \u003d 0;\n                DatanodeRegistration dnR \u003d \n                  datanode.getDNRegistrationForBP(block.getBlockPoolId());\n                ClientTraceLog.info(String.format(DN_CLIENTTRACE_FORMAT,\n                      inAddr, myAddr, block.getNumBytes(),\n                      \"HDFS_WRITE\", clientname, offset,\n                      dnR.getStorageID(), block, endTime-startTime));\n              } else {\n                LOG.info(\"Received block \" + block + \" of size \"\n                    + block.getNumBytes() + \" from \" + inAddr);\n              }\n            }\n\n            // construct my ack message\n            Status[] replies \u003d null;\n            if (mirrorError) { // ack read error\n              replies \u003d new Status[2];\n              replies[0] \u003d Status.SUCCESS;\n              replies[1] \u003d Status.ERROR;\n            } else {\n              short ackLen \u003d type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE? 0\n                  : ack.getNumOfReplies();\n              replies \u003d new Status[1+ackLen];\n              replies[0] \u003d Status.SUCCESS;\n              for (int i\u003d0; i\u003cackLen; i++) {\n                replies[i+1] \u003d ack.getReply(i);\n              }\n            }\n            PipelineAck replyAck \u003d new PipelineAck(expected, replies, totalAckTimeNanos);\n            \n            if (replyAck.isSuccess() \u0026\u0026 \n                 pkt.offsetInBlock \u003e replicaInfo.getBytesAcked())\n                replicaInfo.setBytesAcked(pkt.offsetInBlock);\n\n            // send my ack back to upstream datanode\n            replyAck.write(upstreamOut);\n            upstreamOut.flush();\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(myString + \", replyAck\u003d\" + replyAck);\n            }\n            if (pkt !\u003d null) {\n              // remove the packet from the ack queue\n              removeAckHead();\n              // update bytes acked\n            }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n          if (running) {\n            try {\n              datanode.checkDiskError(e); // may throw an exception here\n            } catch (IOException ioe) {\n              LOG.warn(\"DataNode.checkDiskError failed in run() with: \", ioe);\n            }\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public void run() {\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 !lastPacketInBlock) {\n\n        boolean isInterrupted \u003d false;\n        try {\n            Packet pkt \u003d null;\n            long expected \u003d -2;\n            PipelineAck ack \u003d new PipelineAck();\n            long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n            try {\n              if (type !\u003d PacketResponderType.LAST_IN_PIPELINE\n                  \u0026\u0026 !mirrorError) {\n                // read an ack from downstream datanode\n                ack.readFields(downstreamIn);\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(myString + \" got \" + ack);\n                }\n                seqno \u003d ack.getSeqno();\n              }\n              if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                  || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n                synchronized (this) {\n                  while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 ackQueue.size() \u003d\u003d 0) {\n                    if (LOG.isDebugEnabled()) {\n                      LOG.debug(myString + \": seqno\u003d\" + seqno +\n                                \" waiting for local datanode to finish write.\");\n                    }\n                    wait();\n                  }\n                  if (!running || !datanode.shouldRun) {\n                    break;\n                  }\n                  pkt \u003d ackQueue.getFirst();\n                  expected \u003d pkt.seqno;\n                  if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                      \u0026\u0026 seqno !\u003d expected) {\n                    throw new IOException(myString + \"seqno: expected\u003d\"\n                        + expected + \", received\u003d\" + seqno);\n                  }\n                  lastPacketInBlock \u003d pkt.lastPacketInBlock;\n                }\n              }\n            } catch (InterruptedException ine) {\n              isInterrupted \u003d true;\n            } catch (IOException ioe) {\n              if (Thread.interrupted()) {\n                isInterrupted \u003d true;\n              } else {\n                // continue to run even if can not read from mirror\n                // notify client of the error\n                // and wait for the client to shut down the pipeline\n                mirrorError \u003d true;\n                LOG.info(myString, ioe);\n              }\n            }\n\n            if (Thread.interrupted() || isInterrupted) {\n              /* The receiver thread cancelled this thread. \n               * We could also check any other status updates from the \n               * receiver thread (e.g. if it is ok to write to replyOut). \n               * It is prudent to not send any more status back to the client\n               * because this datanode has a problem. The upstream datanode\n               * will detect that this datanode is bad, and rightly so.\n               */\n              LOG.info(myString + \": Thread is interrupted.\");\n              running \u003d false;\n              continue;\n            }\n            \n            // If this is the last packet in block, then close block\n            // file and finalize the block before responding success\n            if (lastPacketInBlock) {\n              BlockReceiver.this.close();\n              final long endTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n              block.setNumBytes(replicaInfo.getNumBytes());\n              datanode.data.finalizeBlock(block);\n              datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n              if (ClientTraceLog.isInfoEnabled() \u0026\u0026 isClient) {\n                long offset \u003d 0;\n                DatanodeRegistration dnR \u003d \n                  datanode.getDNRegistrationForBP(block.getBlockPoolId());\n                ClientTraceLog.info(String.format(DN_CLIENTTRACE_FORMAT,\n                      inAddr, myAddr, block.getNumBytes(),\n                      \"HDFS_WRITE\", clientname, offset,\n                      dnR.getStorageID(), block, endTime-startTime));\n              } else {\n                LOG.info(\"Received block \" + block + \" of size \"\n                    + block.getNumBytes() + \" from \" + inAddr);\n              }\n            }\n\n            // construct my ack message\n            Status[] replies \u003d null;\n            if (mirrorError) { // ack read error\n              replies \u003d new Status[2];\n              replies[0] \u003d Status.SUCCESS;\n              replies[1] \u003d Status.ERROR;\n            } else {\n              short ackLen \u003d type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE? 0\n                  : ack.getNumOfReplies();\n              replies \u003d new Status[1+ackLen];\n              replies[0] \u003d Status.SUCCESS;\n              for (int i\u003d0; i\u003cackLen; i++) {\n                replies[i+1] \u003d ack.getReply(i);\n              }\n            }\n            PipelineAck replyAck \u003d new PipelineAck(expected, replies);\n            \n            if (replyAck.isSuccess() \u0026\u0026 \n                 pkt.offsetInBlock \u003e replicaInfo.getBytesAcked())\n                replicaInfo.setBytesAcked(pkt.offsetInBlock);\n\n            // send my ack back to upstream datanode\n            replyAck.write(upstreamOut);\n            upstreamOut.flush();\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(myString + \", replyAck\u003d\" + replyAck);\n            }\n            if (pkt !\u003d null) {\n              // remove the packet from the ack queue\n              removeAckHead();\n              // update bytes acked\n            }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n          if (running) {\n            try {\n              datanode.checkDiskError(e); // may throw an exception here\n            } catch (IOException ioe) {\n              LOG.warn(\"DataNode.checkDiskError failed in run() with: \", ioe);\n            }\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public void run() {\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 !lastPacketInBlock) {\n\n        boolean isInterrupted \u003d false;\n        try {\n            Packet pkt \u003d null;\n            long expected \u003d -2;\n            PipelineAck ack \u003d new PipelineAck();\n            long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n            try {\n              if (type !\u003d PacketResponderType.LAST_IN_PIPELINE\n                  \u0026\u0026 !mirrorError) {\n                // read an ack from downstream datanode\n                ack.readFields(downstreamIn);\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(myString + \" got \" + ack);\n                }\n                seqno \u003d ack.getSeqno();\n              }\n              if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                  || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n                synchronized (this) {\n                  while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 ackQueue.size() \u003d\u003d 0) {\n                    if (LOG.isDebugEnabled()) {\n                      LOG.debug(myString + \": seqno\u003d\" + seqno +\n                                \" waiting for local datanode to finish write.\");\n                    }\n                    wait();\n                  }\n                  if (!running || !datanode.shouldRun) {\n                    break;\n                  }\n                  pkt \u003d ackQueue.getFirst();\n                  expected \u003d pkt.seqno;\n                  if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                      \u0026\u0026 seqno !\u003d expected) {\n                    throw new IOException(myString + \"seqno: expected\u003d\"\n                        + expected + \", received\u003d\" + seqno);\n                  }\n                  lastPacketInBlock \u003d pkt.lastPacketInBlock;\n                }\n              }\n            } catch (InterruptedException ine) {\n              isInterrupted \u003d true;\n            } catch (IOException ioe) {\n              if (Thread.interrupted()) {\n                isInterrupted \u003d true;\n              } else {\n                // continue to run even if can not read from mirror\n                // notify client of the error\n                // and wait for the client to shut down the pipeline\n                mirrorError \u003d true;\n                LOG.info(myString, ioe);\n              }\n            }\n\n            if (Thread.interrupted() || isInterrupted) {\n              /* The receiver thread cancelled this thread. \n               * We could also check any other status updates from the \n               * receiver thread (e.g. if it is ok to write to replyOut). \n               * It is prudent to not send any more status back to the client\n               * because this datanode has a problem. The upstream datanode\n               * will detect that this datanode is bad, and rightly so.\n               */\n              LOG.info(myString + \": Thread is interrupted.\");\n              running \u003d false;\n              continue;\n            }\n            \n            // If this is the last packet in block, then close block\n            // file and finalize the block before responding success\n            if (lastPacketInBlock) {\n              BlockReceiver.this.close();\n              final long endTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n              block.setNumBytes(replicaInfo.getNumBytes());\n              datanode.data.finalizeBlock(block);\n              datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n              if (ClientTraceLog.isInfoEnabled() \u0026\u0026 isClient) {\n                long offset \u003d 0;\n                DatanodeRegistration dnR \u003d \n                  datanode.getDNRegistrationForBP(block.getBlockPoolId());\n                ClientTraceLog.info(String.format(DN_CLIENTTRACE_FORMAT,\n                      inAddr, myAddr, block.getNumBytes(),\n                      \"HDFS_WRITE\", clientname, offset,\n                      dnR.getStorageID(), block, endTime-startTime));\n              } else {\n                LOG.info(\"Received block \" + block + \" of size \"\n                    + block.getNumBytes() + \" from \" + inAddr);\n              }\n            }\n\n            // construct my ack message\n            Status[] replies \u003d null;\n            if (mirrorError) { // ack read error\n              replies \u003d new Status[2];\n              replies[0] \u003d Status.SUCCESS;\n              replies[1] \u003d Status.ERROR;\n            } else {\n              short ackLen \u003d type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE? 0\n                  : ack.getNumOfReplies();\n              replies \u003d new Status[1+ackLen];\n              replies[0] \u003d Status.SUCCESS;\n              for (int i\u003d0; i\u003cackLen; i++) {\n                replies[i+1] \u003d ack.getReply(i);\n              }\n            }\n            PipelineAck replyAck \u003d new PipelineAck(expected, replies);\n            \n            if (replyAck.isSuccess() \u0026\u0026 \n                 pkt.offsetInBlock \u003e replicaInfo.getBytesAcked())\n                replicaInfo.setBytesAcked(pkt.offsetInBlock);\n\n            // send my ack back to upstream datanode\n            replyAck.write(upstreamOut);\n            upstreamOut.flush();\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(myString + \", replyAck\u003d\" + replyAck);\n            }\n            if (pkt !\u003d null) {\n              // remove the packet from the ack queue\n              removeAckHead();\n              // update bytes acked\n            }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n          if (running) {\n            try {\n              datanode.checkDiskError(e); // may throw an exception here\n            } catch (IOException ioe) {\n              LOG.warn(\"DataNode.checkDiskError failed in run() with: \", ioe);\n            }\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,149 @@\n+    public void run() {\n+      boolean lastPacketInBlock \u003d false;\n+      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n+      while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 !lastPacketInBlock) {\n+\n+        boolean isInterrupted \u003d false;\n+        try {\n+            Packet pkt \u003d null;\n+            long expected \u003d -2;\n+            PipelineAck ack \u003d new PipelineAck();\n+            long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n+            try {\n+              if (type !\u003d PacketResponderType.LAST_IN_PIPELINE\n+                  \u0026\u0026 !mirrorError) {\n+                // read an ack from downstream datanode\n+                ack.readFields(downstreamIn);\n+                if (LOG.isDebugEnabled()) {\n+                  LOG.debug(myString + \" got \" + ack);\n+                }\n+                seqno \u003d ack.getSeqno();\n+              }\n+              if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n+                  || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n+                synchronized (this) {\n+                  while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 ackQueue.size() \u003d\u003d 0) {\n+                    if (LOG.isDebugEnabled()) {\n+                      LOG.debug(myString + \": seqno\u003d\" + seqno +\n+                                \" waiting for local datanode to finish write.\");\n+                    }\n+                    wait();\n+                  }\n+                  if (!running || !datanode.shouldRun) {\n+                    break;\n+                  }\n+                  pkt \u003d ackQueue.getFirst();\n+                  expected \u003d pkt.seqno;\n+                  if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n+                      \u0026\u0026 seqno !\u003d expected) {\n+                    throw new IOException(myString + \"seqno: expected\u003d\"\n+                        + expected + \", received\u003d\" + seqno);\n+                  }\n+                  lastPacketInBlock \u003d pkt.lastPacketInBlock;\n+                }\n+              }\n+            } catch (InterruptedException ine) {\n+              isInterrupted \u003d true;\n+            } catch (IOException ioe) {\n+              if (Thread.interrupted()) {\n+                isInterrupted \u003d true;\n+              } else {\n+                // continue to run even if can not read from mirror\n+                // notify client of the error\n+                // and wait for the client to shut down the pipeline\n+                mirrorError \u003d true;\n+                LOG.info(myString, ioe);\n+              }\n+            }\n+\n+            if (Thread.interrupted() || isInterrupted) {\n+              /* The receiver thread cancelled this thread. \n+               * We could also check any other status updates from the \n+               * receiver thread (e.g. if it is ok to write to replyOut). \n+               * It is prudent to not send any more status back to the client\n+               * because this datanode has a problem. The upstream datanode\n+               * will detect that this datanode is bad, and rightly so.\n+               */\n+              LOG.info(myString + \": Thread is interrupted.\");\n+              running \u003d false;\n+              continue;\n+            }\n+            \n+            // If this is the last packet in block, then close block\n+            // file and finalize the block before responding success\n+            if (lastPacketInBlock) {\n+              BlockReceiver.this.close();\n+              final long endTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n+              block.setNumBytes(replicaInfo.getNumBytes());\n+              datanode.data.finalizeBlock(block);\n+              datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n+              if (ClientTraceLog.isInfoEnabled() \u0026\u0026 isClient) {\n+                long offset \u003d 0;\n+                DatanodeRegistration dnR \u003d \n+                  datanode.getDNRegistrationForBP(block.getBlockPoolId());\n+                ClientTraceLog.info(String.format(DN_CLIENTTRACE_FORMAT,\n+                      inAddr, myAddr, block.getNumBytes(),\n+                      \"HDFS_WRITE\", clientname, offset,\n+                      dnR.getStorageID(), block, endTime-startTime));\n+              } else {\n+                LOG.info(\"Received block \" + block + \" of size \"\n+                    + block.getNumBytes() + \" from \" + inAddr);\n+              }\n+            }\n+\n+            // construct my ack message\n+            Status[] replies \u003d null;\n+            if (mirrorError) { // ack read error\n+              replies \u003d new Status[2];\n+              replies[0] \u003d Status.SUCCESS;\n+              replies[1] \u003d Status.ERROR;\n+            } else {\n+              short ackLen \u003d type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE? 0\n+                  : ack.getNumOfReplies();\n+              replies \u003d new Status[1+ackLen];\n+              replies[0] \u003d Status.SUCCESS;\n+              for (int i\u003d0; i\u003cackLen; i++) {\n+                replies[i+1] \u003d ack.getReply(i);\n+              }\n+            }\n+            PipelineAck replyAck \u003d new PipelineAck(expected, replies);\n+            \n+            if (replyAck.isSuccess() \u0026\u0026 \n+                 pkt.offsetInBlock \u003e replicaInfo.getBytesAcked())\n+                replicaInfo.setBytesAcked(pkt.offsetInBlock);\n+\n+            // send my ack back to upstream datanode\n+            replyAck.write(upstreamOut);\n+            upstreamOut.flush();\n+            if (LOG.isDebugEnabled()) {\n+              LOG.debug(myString + \", replyAck\u003d\" + replyAck);\n+            }\n+            if (pkt !\u003d null) {\n+              // remove the packet from the ack queue\n+              removeAckHead();\n+              // update bytes acked\n+            }\n+        } catch (IOException e) {\n+          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n+          if (running) {\n+            try {\n+              datanode.checkDiskError(e); // may throw an exception here\n+            } catch (IOException ioe) {\n+              LOG.warn(\"DataNode.checkDiskError failed in run() with: \", ioe);\n+            }\n+            LOG.info(myString, e);\n+            running \u003d false;\n+            if (!Thread.interrupted()) { // failure not caused by interruption\n+              receiverThread.interrupt();\n+            }\n+          }\n+        } catch (Throwable e) {\n+          if (running) {\n+            LOG.info(myString, e);\n+            running \u003d false;\n+            receiverThread.interrupt();\n+          }\n+        }\n+      }\n+      LOG.info(myString + \" terminating\");\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      boolean lastPacketInBlock \u003d false;\n      final long startTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n      while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 !lastPacketInBlock) {\n\n        boolean isInterrupted \u003d false;\n        try {\n            Packet pkt \u003d null;\n            long expected \u003d -2;\n            PipelineAck ack \u003d new PipelineAck();\n            long seqno \u003d PipelineAck.UNKOWN_SEQNO;\n            try {\n              if (type !\u003d PacketResponderType.LAST_IN_PIPELINE\n                  \u0026\u0026 !mirrorError) {\n                // read an ack from downstream datanode\n                ack.readFields(downstreamIn);\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(myString + \" got \" + ack);\n                }\n                seqno \u003d ack.getSeqno();\n              }\n              if (seqno !\u003d PipelineAck.UNKOWN_SEQNO\n                  || type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE) {\n                synchronized (this) {\n                  while (running \u0026\u0026 datanode.shouldRun \u0026\u0026 ackQueue.size() \u003d\u003d 0) {\n                    if (LOG.isDebugEnabled()) {\n                      LOG.debug(myString + \": seqno\u003d\" + seqno +\n                                \" waiting for local datanode to finish write.\");\n                    }\n                    wait();\n                  }\n                  if (!running || !datanode.shouldRun) {\n                    break;\n                  }\n                  pkt \u003d ackQueue.getFirst();\n                  expected \u003d pkt.seqno;\n                  if (type \u003d\u003d PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE\n                      \u0026\u0026 seqno !\u003d expected) {\n                    throw new IOException(myString + \"seqno: expected\u003d\"\n                        + expected + \", received\u003d\" + seqno);\n                  }\n                  lastPacketInBlock \u003d pkt.lastPacketInBlock;\n                }\n              }\n            } catch (InterruptedException ine) {\n              isInterrupted \u003d true;\n            } catch (IOException ioe) {\n              if (Thread.interrupted()) {\n                isInterrupted \u003d true;\n              } else {\n                // continue to run even if can not read from mirror\n                // notify client of the error\n                // and wait for the client to shut down the pipeline\n                mirrorError \u003d true;\n                LOG.info(myString, ioe);\n              }\n            }\n\n            if (Thread.interrupted() || isInterrupted) {\n              /* The receiver thread cancelled this thread. \n               * We could also check any other status updates from the \n               * receiver thread (e.g. if it is ok to write to replyOut). \n               * It is prudent to not send any more status back to the client\n               * because this datanode has a problem. The upstream datanode\n               * will detect that this datanode is bad, and rightly so.\n               */\n              LOG.info(myString + \": Thread is interrupted.\");\n              running \u003d false;\n              continue;\n            }\n            \n            // If this is the last packet in block, then close block\n            // file and finalize the block before responding success\n            if (lastPacketInBlock) {\n              BlockReceiver.this.close();\n              final long endTime \u003d ClientTraceLog.isInfoEnabled() ? System.nanoTime() : 0;\n              block.setNumBytes(replicaInfo.getNumBytes());\n              datanode.data.finalizeBlock(block);\n              datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n              if (ClientTraceLog.isInfoEnabled() \u0026\u0026 isClient) {\n                long offset \u003d 0;\n                DatanodeRegistration dnR \u003d \n                  datanode.getDNRegistrationForBP(block.getBlockPoolId());\n                ClientTraceLog.info(String.format(DN_CLIENTTRACE_FORMAT,\n                      inAddr, myAddr, block.getNumBytes(),\n                      \"HDFS_WRITE\", clientname, offset,\n                      dnR.getStorageID(), block, endTime-startTime));\n              } else {\n                LOG.info(\"Received block \" + block + \" of size \"\n                    + block.getNumBytes() + \" from \" + inAddr);\n              }\n            }\n\n            // construct my ack message\n            Status[] replies \u003d null;\n            if (mirrorError) { // ack read error\n              replies \u003d new Status[2];\n              replies[0] \u003d Status.SUCCESS;\n              replies[1] \u003d Status.ERROR;\n            } else {\n              short ackLen \u003d type \u003d\u003d PacketResponderType.LAST_IN_PIPELINE? 0\n                  : ack.getNumOfReplies();\n              replies \u003d new Status[1+ackLen];\n              replies[0] \u003d Status.SUCCESS;\n              for (int i\u003d0; i\u003cackLen; i++) {\n                replies[i+1] \u003d ack.getReply(i);\n              }\n            }\n            PipelineAck replyAck \u003d new PipelineAck(expected, replies);\n            \n            if (replyAck.isSuccess() \u0026\u0026 \n                 pkt.offsetInBlock \u003e replicaInfo.getBytesAcked())\n                replicaInfo.setBytesAcked(pkt.offsetInBlock);\n\n            // send my ack back to upstream datanode\n            replyAck.write(upstreamOut);\n            upstreamOut.flush();\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(myString + \", replyAck\u003d\" + replyAck);\n            }\n            if (pkt !\u003d null) {\n              // remove the packet from the ack queue\n              removeAckHead();\n              // update bytes acked\n            }\n        } catch (IOException e) {\n          LOG.warn(\"IOException in BlockReceiver.run(): \", e);\n          if (running) {\n            try {\n              datanode.checkDiskError(e); // may throw an exception here\n            } catch (IOException ioe) {\n              LOG.warn(\"DataNode.checkDiskError failed in run() with: \", ioe);\n            }\n            LOG.info(myString, e);\n            running \u003d false;\n            if (!Thread.interrupted()) { // failure not caused by interruption\n              receiverThread.interrupt();\n            }\n          }\n        } catch (Throwable e) {\n          if (running) {\n            LOG.info(myString, e);\n            running \u003d false;\n            receiverThread.interrupt();\n          }\n        }\n      }\n      LOG.info(myString + \" terminating\");\n    }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java"
    }
  }
}