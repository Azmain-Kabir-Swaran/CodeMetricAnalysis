{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "StripeReader.java",
  "functionName": "readChunk",
  "functionId": "readChunk___block-LocatedBlock(modifiers-final)__chunkIndex-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/StripeReader.java",
  "functionStartLine": 294,
  "functionEndLine": 325,
  "numCommitsSeen": 19,
  "timeTaken": 2082,
  "changeHistory": [
    "08bb6c49a5aec32b7d9f29238560f947420405d6",
    "734d54c1a8950446e68098f62d8964e02ecc2890",
    "8808779db351fe444388d4acb3094766b5980718"
  ],
  "changeHistoryShort": {
    "08bb6c49a5aec32b7d9f29238560f947420405d6": "Ybodychange",
    "734d54c1a8950446e68098f62d8964e02ecc2890": "Ymultichange(Ymovefromfile,Ybodychange)",
    "8808779db351fe444388d4acb3094766b5980718": "Ybodychange"
  },
  "changeHistoryDetails": {
    "08bb6c49a5aec32b7d9f29238560f947420405d6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13926. ThreadLocal aggregations for FileSystem.Statistics are incorrect with striped reads.\nContributed by Xiao Chen, Hrishikesh Gadre.\n\nSigned-off-by: Xiao Chen \u003cxiao@apache.org\u003e\n",
      "commitDate": "08/10/18 8:31 PM",
      "commitName": "08bb6c49a5aec32b7d9f29238560f947420405d6",
      "commitAuthor": "Hrishikesh Gadre",
      "commitDateOld": "26/04/18 1:54 PM",
      "commitNameOld": "a8e428b2dc0883184b43cb776d5c7196aaa3bf56",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 165.28,
      "commitsBetweenForRepo": 1297,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,32 @@\n   boolean readChunk(final LocatedBlock block, int chunkIndex)\n       throws IOException {\n     final StripingChunk chunk \u003d alignedStripe.chunks[chunkIndex];\n     if (block \u003d\u003d null) {\n       chunk.state \u003d StripingChunk.MISSING;\n       return false;\n     }\n \n     if (readerInfos[chunkIndex] \u003d\u003d null) {\n       if (!dfsStripedInputStream.createBlockReader(block,\n           alignedStripe.getOffsetInBlock(), targetBlocks,\n           readerInfos, chunkIndex)) {\n         chunk.state \u003d StripingChunk.MISSING;\n         return false;\n       }\n     } else if (readerInfos[chunkIndex].shouldSkip) {\n       chunk.state \u003d StripingChunk.MISSING;\n       return false;\n     }\n \n     chunk.state \u003d StripingChunk.PENDING;\n-    Callable\u003cVoid\u003e readCallable \u003d readCells(readerInfos[chunkIndex].reader,\n+    Callable\u003cBlockReadStats\u003e readCallable \u003d\n+        readCells(readerInfos[chunkIndex].reader,\n         readerInfos[chunkIndex].datanode,\n         readerInfos[chunkIndex].blockReaderOffset,\n         alignedStripe.getOffsetInBlock(), getReadStrategies(chunk),\n         block.getBlock());\n \n-    Future\u003cVoid\u003e request \u003d service.submit(readCallable);\n+    Future\u003cBlockReadStats\u003e request \u003d service.submit(readCallable);\n     futures.put(request, chunkIndex);\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean readChunk(final LocatedBlock block, int chunkIndex)\n      throws IOException {\n    final StripingChunk chunk \u003d alignedStripe.chunks[chunkIndex];\n    if (block \u003d\u003d null) {\n      chunk.state \u003d StripingChunk.MISSING;\n      return false;\n    }\n\n    if (readerInfos[chunkIndex] \u003d\u003d null) {\n      if (!dfsStripedInputStream.createBlockReader(block,\n          alignedStripe.getOffsetInBlock(), targetBlocks,\n          readerInfos, chunkIndex)) {\n        chunk.state \u003d StripingChunk.MISSING;\n        return false;\n      }\n    } else if (readerInfos[chunkIndex].shouldSkip) {\n      chunk.state \u003d StripingChunk.MISSING;\n      return false;\n    }\n\n    chunk.state \u003d StripingChunk.PENDING;\n    Callable\u003cBlockReadStats\u003e readCallable \u003d\n        readCells(readerInfos[chunkIndex].reader,\n        readerInfos[chunkIndex].datanode,\n        readerInfos[chunkIndex].blockReaderOffset,\n        alignedStripe.getOffsetInBlock(), getReadStrategies(chunk),\n        block.getBlock());\n\n    Future\u003cBlockReadStats\u003e request \u003d service.submit(readCallable);\n    futures.put(request, chunkIndex);\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/StripeReader.java",
      "extendedDetails": {}
    },
    "734d54c1a8950446e68098f62d8964e02ecc2890": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-10861. Refactor StripeReaders and use ECChunk version decode API. Contributed by Sammi Chen\n",
      "commitDate": "21/09/16 6:34 AM",
      "commitName": "734d54c1a8950446e68098f62d8964e02ecc2890",
      "commitAuthor": "Kai Zheng",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-10861. Refactor StripeReaders and use ECChunk version decode API. Contributed by Sammi Chen\n",
          "commitDate": "21/09/16 6:34 AM",
          "commitName": "734d54c1a8950446e68098f62d8964e02ecc2890",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "20/09/16 12:03 AM",
          "commitNameOld": "2b66d9ec5bdaec7e6b278926fbb6f222c4e3afaa",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 1.27,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,31 @@\n-    boolean readChunk(final LocatedBlock block, int chunkIndex)\n-        throws IOException {\n-      final StripingChunk chunk \u003d alignedStripe.chunks[chunkIndex];\n-      if (block \u003d\u003d null) {\n+  boolean readChunk(final LocatedBlock block, int chunkIndex)\n+      throws IOException {\n+    final StripingChunk chunk \u003d alignedStripe.chunks[chunkIndex];\n+    if (block \u003d\u003d null) {\n+      chunk.state \u003d StripingChunk.MISSING;\n+      return false;\n+    }\n+\n+    if (readerInfos[chunkIndex] \u003d\u003d null) {\n+      if (!dfsStripedInputStream.createBlockReader(block,\n+          alignedStripe.getOffsetInBlock(), targetBlocks,\n+          readerInfos, chunkIndex)) {\n         chunk.state \u003d StripingChunk.MISSING;\n         return false;\n       }\n-      if (readerInfos[chunkIndex] \u003d\u003d null) {\n-        if (!createBlockReader(block, chunkIndex)) {\n-          chunk.state \u003d StripingChunk.MISSING;\n-          return false;\n-        }\n-      } else if (readerInfos[chunkIndex].shouldSkip) {\n-        chunk.state \u003d StripingChunk.MISSING;\n-        return false;\n-      }\n+    } else if (readerInfos[chunkIndex].shouldSkip) {\n+      chunk.state \u003d StripingChunk.MISSING;\n+      return false;\n+    }\n \n-      chunk.state \u003d StripingChunk.PENDING;\n-      Callable\u003cVoid\u003e readCallable \u003d readCells(readerInfos[chunkIndex].reader,\n-          readerInfos[chunkIndex].datanode,\n-          readerInfos[chunkIndex].blockReaderOffset,\n-          alignedStripe.getOffsetInBlock(), getReadStrategies(chunk),\n-          block.getBlock(), corruptedBlocks);\n+    chunk.state \u003d StripingChunk.PENDING;\n+    Callable\u003cVoid\u003e readCallable \u003d readCells(readerInfos[chunkIndex].reader,\n+        readerInfos[chunkIndex].datanode,\n+        readerInfos[chunkIndex].blockReaderOffset,\n+        alignedStripe.getOffsetInBlock(), getReadStrategies(chunk),\n+        block.getBlock());\n \n-      Future\u003cVoid\u003e request \u003d service.submit(readCallable);\n-      futures.put(request, chunkIndex);\n-      return true;\n-    }\n\\ No newline at end of file\n+    Future\u003cVoid\u003e request \u003d service.submit(readCallable);\n+    futures.put(request, chunkIndex);\n+    return true;\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  boolean readChunk(final LocatedBlock block, int chunkIndex)\n      throws IOException {\n    final StripingChunk chunk \u003d alignedStripe.chunks[chunkIndex];\n    if (block \u003d\u003d null) {\n      chunk.state \u003d StripingChunk.MISSING;\n      return false;\n    }\n\n    if (readerInfos[chunkIndex] \u003d\u003d null) {\n      if (!dfsStripedInputStream.createBlockReader(block,\n          alignedStripe.getOffsetInBlock(), targetBlocks,\n          readerInfos, chunkIndex)) {\n        chunk.state \u003d StripingChunk.MISSING;\n        return false;\n      }\n    } else if (readerInfos[chunkIndex].shouldSkip) {\n      chunk.state \u003d StripingChunk.MISSING;\n      return false;\n    }\n\n    chunk.state \u003d StripingChunk.PENDING;\n    Callable\u003cVoid\u003e readCallable \u003d readCells(readerInfos[chunkIndex].reader,\n        readerInfos[chunkIndex].datanode,\n        readerInfos[chunkIndex].blockReaderOffset,\n        alignedStripe.getOffsetInBlock(), getReadStrategies(chunk),\n        block.getBlock());\n\n    Future\u003cVoid\u003e request \u003d service.submit(readCallable);\n    futures.put(request, chunkIndex);\n    return true;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/StripeReader.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/StripeReader.java",
            "oldMethodName": "readChunk",
            "newMethodName": "readChunk"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10861. Refactor StripeReaders and use ECChunk version decode API. Contributed by Sammi Chen\n",
          "commitDate": "21/09/16 6:34 AM",
          "commitName": "734d54c1a8950446e68098f62d8964e02ecc2890",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "20/09/16 12:03 AM",
          "commitNameOld": "2b66d9ec5bdaec7e6b278926fbb6f222c4e3afaa",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 1.27,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,31 @@\n-    boolean readChunk(final LocatedBlock block, int chunkIndex)\n-        throws IOException {\n-      final StripingChunk chunk \u003d alignedStripe.chunks[chunkIndex];\n-      if (block \u003d\u003d null) {\n+  boolean readChunk(final LocatedBlock block, int chunkIndex)\n+      throws IOException {\n+    final StripingChunk chunk \u003d alignedStripe.chunks[chunkIndex];\n+    if (block \u003d\u003d null) {\n+      chunk.state \u003d StripingChunk.MISSING;\n+      return false;\n+    }\n+\n+    if (readerInfos[chunkIndex] \u003d\u003d null) {\n+      if (!dfsStripedInputStream.createBlockReader(block,\n+          alignedStripe.getOffsetInBlock(), targetBlocks,\n+          readerInfos, chunkIndex)) {\n         chunk.state \u003d StripingChunk.MISSING;\n         return false;\n       }\n-      if (readerInfos[chunkIndex] \u003d\u003d null) {\n-        if (!createBlockReader(block, chunkIndex)) {\n-          chunk.state \u003d StripingChunk.MISSING;\n-          return false;\n-        }\n-      } else if (readerInfos[chunkIndex].shouldSkip) {\n-        chunk.state \u003d StripingChunk.MISSING;\n-        return false;\n-      }\n+    } else if (readerInfos[chunkIndex].shouldSkip) {\n+      chunk.state \u003d StripingChunk.MISSING;\n+      return false;\n+    }\n \n-      chunk.state \u003d StripingChunk.PENDING;\n-      Callable\u003cVoid\u003e readCallable \u003d readCells(readerInfos[chunkIndex].reader,\n-          readerInfos[chunkIndex].datanode,\n-          readerInfos[chunkIndex].blockReaderOffset,\n-          alignedStripe.getOffsetInBlock(), getReadStrategies(chunk),\n-          block.getBlock(), corruptedBlocks);\n+    chunk.state \u003d StripingChunk.PENDING;\n+    Callable\u003cVoid\u003e readCallable \u003d readCells(readerInfos[chunkIndex].reader,\n+        readerInfos[chunkIndex].datanode,\n+        readerInfos[chunkIndex].blockReaderOffset,\n+        alignedStripe.getOffsetInBlock(), getReadStrategies(chunk),\n+        block.getBlock());\n \n-      Future\u003cVoid\u003e request \u003d service.submit(readCallable);\n-      futures.put(request, chunkIndex);\n-      return true;\n-    }\n\\ No newline at end of file\n+    Future\u003cVoid\u003e request \u003d service.submit(readCallable);\n+    futures.put(request, chunkIndex);\n+    return true;\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  boolean readChunk(final LocatedBlock block, int chunkIndex)\n      throws IOException {\n    final StripingChunk chunk \u003d alignedStripe.chunks[chunkIndex];\n    if (block \u003d\u003d null) {\n      chunk.state \u003d StripingChunk.MISSING;\n      return false;\n    }\n\n    if (readerInfos[chunkIndex] \u003d\u003d null) {\n      if (!dfsStripedInputStream.createBlockReader(block,\n          alignedStripe.getOffsetInBlock(), targetBlocks,\n          readerInfos, chunkIndex)) {\n        chunk.state \u003d StripingChunk.MISSING;\n        return false;\n      }\n    } else if (readerInfos[chunkIndex].shouldSkip) {\n      chunk.state \u003d StripingChunk.MISSING;\n      return false;\n    }\n\n    chunk.state \u003d StripingChunk.PENDING;\n    Callable\u003cVoid\u003e readCallable \u003d readCells(readerInfos[chunkIndex].reader,\n        readerInfos[chunkIndex].datanode,\n        readerInfos[chunkIndex].blockReaderOffset,\n        alignedStripe.getOffsetInBlock(), getReadStrategies(chunk),\n        block.getBlock());\n\n    Future\u003cVoid\u003e request \u003d service.submit(readCallable);\n    futures.put(request, chunkIndex);\n    return true;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/StripeReader.java",
          "extendedDetails": {}
        }
      ]
    },
    "8808779db351fe444388d4acb3094766b5980718": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9734. Refactoring of checksum failure report related codes. Contributed by Kai Zheng.\n\nChange-Id: Ie69a77e3498a360959f8e213c51fb2b17c28b64a\n",
      "commitDate": "25/02/16 9:55 AM",
      "commitName": "8808779db351fe444388d4acb3094766b5980718",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "19/02/16 7:02 PM",
      "commitNameOld": "e54cc2931262bf49682a8323da9811976218c03b",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 5.62,
      "commitsBetweenForRepo": 38,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n     boolean readChunk(final LocatedBlock block, int chunkIndex)\n         throws IOException {\n       final StripingChunk chunk \u003d alignedStripe.chunks[chunkIndex];\n       if (block \u003d\u003d null) {\n         chunk.state \u003d StripingChunk.MISSING;\n         return false;\n       }\n       if (readerInfos[chunkIndex] \u003d\u003d null) {\n         if (!createBlockReader(block, chunkIndex)) {\n           chunk.state \u003d StripingChunk.MISSING;\n           return false;\n         }\n       } else if (readerInfos[chunkIndex].shouldSkip) {\n         chunk.state \u003d StripingChunk.MISSING;\n         return false;\n       }\n \n       chunk.state \u003d StripingChunk.PENDING;\n       Callable\u003cVoid\u003e readCallable \u003d readCells(readerInfos[chunkIndex].reader,\n           readerInfos[chunkIndex].datanode,\n           readerInfos[chunkIndex].blockReaderOffset,\n           alignedStripe.getOffsetInBlock(), getReadStrategies(chunk),\n-          block.getBlock(), corruptedBlockMap);\n+          block.getBlock(), corruptedBlocks);\n \n       Future\u003cVoid\u003e request \u003d service.submit(readCallable);\n       futures.put(request, chunkIndex);\n       return true;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    boolean readChunk(final LocatedBlock block, int chunkIndex)\n        throws IOException {\n      final StripingChunk chunk \u003d alignedStripe.chunks[chunkIndex];\n      if (block \u003d\u003d null) {\n        chunk.state \u003d StripingChunk.MISSING;\n        return false;\n      }\n      if (readerInfos[chunkIndex] \u003d\u003d null) {\n        if (!createBlockReader(block, chunkIndex)) {\n          chunk.state \u003d StripingChunk.MISSING;\n          return false;\n        }\n      } else if (readerInfos[chunkIndex].shouldSkip) {\n        chunk.state \u003d StripingChunk.MISSING;\n        return false;\n      }\n\n      chunk.state \u003d StripingChunk.PENDING;\n      Callable\u003cVoid\u003e readCallable \u003d readCells(readerInfos[chunkIndex].reader,\n          readerInfos[chunkIndex].datanode,\n          readerInfos[chunkIndex].blockReaderOffset,\n          alignedStripe.getOffsetInBlock(), getReadStrategies(chunk),\n          block.getBlock(), corruptedBlocks);\n\n      Future\u003cVoid\u003e request \u003d service.submit(readCallable);\n      futures.put(request, chunkIndex);\n      return true;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
      "extendedDetails": {}
    }
  }
}