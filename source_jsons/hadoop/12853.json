{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPlacementPolicyRackFaultTolerant.java",
  "functionName": "chooseTargetInOrder",
  "functionId": "chooseTargetInOrder___numOfReplicas-int__writer-Node__excludedNodes-Set__Node__(modifiers-final)__blocksize-long(modifiers-final)__maxNodesPerRack-int(modifiers-final)__results-List__DatanodeStorageInfo__(modifiers-final)__avoidStaleNodes-boolean(modifiers-final)__newBlock-boolean(modifiers-final)__storageTypes-EnumMap__StorageType,Integer__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyRackFaultTolerant.java",
  "functionStartLine": 82,
  "functionEndLine": 158,
  "numCommitsSeen": 8,
  "timeTaken": 2144,
  "changeHistory": [
    "b00f828d84e4e029fd4786ebe827ce704a1b2a04",
    "644c2f6924f341f51d809c91dccfff88fc82f6f0",
    "c1d50a91f7c05e4aaf4655380c8dcd11703ff158",
    "9595cc003ca5ed3d59b6942056a4fcb9080f79c9"
  ],
  "changeHistoryShort": {
    "b00f828d84e4e029fd4786ebe827ce704a1b2a04": "Ybodychange",
    "644c2f6924f341f51d809c91dccfff88fc82f6f0": "Ybodychange",
    "c1d50a91f7c05e4aaf4655380c8dcd11703ff158": "Yfilerename",
    "9595cc003ca5ed3d59b6942056a4fcb9080f79c9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b00f828d84e4e029fd4786ebe827ce704a1b2a04": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12725. BlockPlacementPolicyRackFaultTolerant fails with very uneven racks.\n",
      "commitDate": "02/11/17 9:53 PM",
      "commitName": "b00f828d84e4e029fd4786ebe827ce704a1b2a04",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "05/10/17 4:58 PM",
      "commitNameOld": "644c2f6924f341f51d809c91dccfff88fc82f6f0",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 28.2,
      "commitsBetweenForRepo": 213,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,77 @@\n   protected Node chooseTargetInOrder(int numOfReplicas,\n                                  Node writer,\n                                  final Set\u003cNode\u003e excludedNodes,\n                                  final long blocksize,\n                                  final int maxNodesPerRack,\n                                  final List\u003cDatanodeStorageInfo\u003e results,\n                                  final boolean avoidStaleNodes,\n                                  final boolean newBlock,\n                                  EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                                  throws NotEnoughReplicasException {\n     int totalReplicaExpected \u003d results.size() + numOfReplicas;\n     int numOfRacks \u003d clusterMap.getNumOfRacks();\n     if (totalReplicaExpected \u003c numOfRacks ||\n         totalReplicaExpected % numOfRacks \u003d\u003d 0) {\n       writer \u003d chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n           maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n       return writer;\n     }\n \n     assert totalReplicaExpected \u003e (maxNodesPerRack -1) * numOfRacks;\n \n     // Calculate numOfReplicas for filling each rack exactly (maxNodesPerRack-1)\n     // replicas.\n     HashMap\u003cString, Integer\u003e rackCounts \u003d new HashMap\u003c\u003e();\n     for (DatanodeStorageInfo dsInfo : results) {\n       String rack \u003d dsInfo.getDatanodeDescriptor().getNetworkLocation();\n       Integer count \u003d rackCounts.get(rack);\n       if (count !\u003d null) {\n         rackCounts.put(rack, count + 1);\n       } else {\n         rackCounts.put(rack, 1);\n       }\n     }\n     int excess \u003d 0; // Sum of the above (maxNodesPerRack-1) part of nodes in results\n     for (int count : rackCounts.values()) {\n       if (count \u003e maxNodesPerRack -1) {\n         excess +\u003d count - (maxNodesPerRack -1);\n       }\n     }\n     numOfReplicas \u003d Math.min(totalReplicaExpected - results.size(),\n         (maxNodesPerRack -1) * numOfRacks - (results.size() - excess));\n \n     try {\n       // Try to spread the replicas as evenly as possible across racks.\n       // This is done by first placing with (maxNodesPerRack-1), then spreading\n       // the remainder by calling again with maxNodesPerRack.\n       writer \u003d chooseOnce(numOfReplicas, writer, new HashSet\u003c\u003e(excludedNodes),\n           blocksize, maxNodesPerRack - 1, results, avoidStaleNodes,\n           storageTypes);\n \n       // Exclude the chosen nodes\n       for (DatanodeStorageInfo resultStorage : results) {\n         addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n             excludedNodes);\n       }\n       LOG.trace(\"Chosen nodes: {}\", results);\n       LOG.trace(\"Excluded nodes: {}\", excludedNodes);\n \n       numOfReplicas \u003d totalReplicaExpected - results.size();\n       chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n           maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n     } catch (NotEnoughReplicasException e) {\n-      LOG.debug(\"Only able to place {} of {} (maxNodesPerRack\u003d{}) nodes \" +\n-              \"evenly across racks, falling back to uneven placement.\",\n-          results.size(), numOfReplicas, maxNodesPerRack);\n+      LOG.warn(\"Only able to place {} of total expected {}\"\n+              + \" (maxNodesPerRack\u003d{}, numOfReplicas\u003d{}) nodes \"\n+              + \"evenly across racks, falling back to evenly place on the \"\n+              + \"remaining racks. This may not guarantee rack-level fault \"\n+              + \"tolerance. Please check if the racks are configured properly.\",\n+          results.size(), totalReplicaExpected, maxNodesPerRack, numOfReplicas);\n       LOG.debug(\"Caught exception was:\", e);\n-      // Exclude the chosen nodes\n-      for (DatanodeStorageInfo resultStorage : results) {\n-        addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n-            excludedNodes);\n-      }\n+      chooseEvenlyFromRemainingRacks(writer, excludedNodes, blocksize,\n+          maxNodesPerRack, results, avoidStaleNodes, storageTypes,\n+          totalReplicaExpected, e);\n \n-      LOG.trace(\"Chosen nodes: {}\", results);\n-      LOG.trace(\"Excluded nodes: {}\", excludedNodes);\n-      numOfReplicas \u003d totalReplicaExpected - results.size();\n-      chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n-          totalReplicaExpected, results, avoidStaleNodes, storageTypes);\n     }\n \n     return writer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected Node chooseTargetInOrder(int numOfReplicas,\n                                 Node writer,\n                                 final Set\u003cNode\u003e excludedNodes,\n                                 final long blocksize,\n                                 final int maxNodesPerRack,\n                                 final List\u003cDatanodeStorageInfo\u003e results,\n                                 final boolean avoidStaleNodes,\n                                 final boolean newBlock,\n                                 EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                                 throws NotEnoughReplicasException {\n    int totalReplicaExpected \u003d results.size() + numOfReplicas;\n    int numOfRacks \u003d clusterMap.getNumOfRacks();\n    if (totalReplicaExpected \u003c numOfRacks ||\n        totalReplicaExpected % numOfRacks \u003d\u003d 0) {\n      writer \u003d chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n      return writer;\n    }\n\n    assert totalReplicaExpected \u003e (maxNodesPerRack -1) * numOfRacks;\n\n    // Calculate numOfReplicas for filling each rack exactly (maxNodesPerRack-1)\n    // replicas.\n    HashMap\u003cString, Integer\u003e rackCounts \u003d new HashMap\u003c\u003e();\n    for (DatanodeStorageInfo dsInfo : results) {\n      String rack \u003d dsInfo.getDatanodeDescriptor().getNetworkLocation();\n      Integer count \u003d rackCounts.get(rack);\n      if (count !\u003d null) {\n        rackCounts.put(rack, count + 1);\n      } else {\n        rackCounts.put(rack, 1);\n      }\n    }\n    int excess \u003d 0; // Sum of the above (maxNodesPerRack-1) part of nodes in results\n    for (int count : rackCounts.values()) {\n      if (count \u003e maxNodesPerRack -1) {\n        excess +\u003d count - (maxNodesPerRack -1);\n      }\n    }\n    numOfReplicas \u003d Math.min(totalReplicaExpected - results.size(),\n        (maxNodesPerRack -1) * numOfRacks - (results.size() - excess));\n\n    try {\n      // Try to spread the replicas as evenly as possible across racks.\n      // This is done by first placing with (maxNodesPerRack-1), then spreading\n      // the remainder by calling again with maxNodesPerRack.\n      writer \u003d chooseOnce(numOfReplicas, writer, new HashSet\u003c\u003e(excludedNodes),\n          blocksize, maxNodesPerRack - 1, results, avoidStaleNodes,\n          storageTypes);\n\n      // Exclude the chosen nodes\n      for (DatanodeStorageInfo resultStorage : results) {\n        addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n            excludedNodes);\n      }\n      LOG.trace(\"Chosen nodes: {}\", results);\n      LOG.trace(\"Excluded nodes: {}\", excludedNodes);\n\n      numOfReplicas \u003d totalReplicaExpected - results.size();\n      chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    } catch (NotEnoughReplicasException e) {\n      LOG.warn(\"Only able to place {} of total expected {}\"\n              + \" (maxNodesPerRack\u003d{}, numOfReplicas\u003d{}) nodes \"\n              + \"evenly across racks, falling back to evenly place on the \"\n              + \"remaining racks. This may not guarantee rack-level fault \"\n              + \"tolerance. Please check if the racks are configured properly.\",\n          results.size(), totalReplicaExpected, maxNodesPerRack, numOfReplicas);\n      LOG.debug(\"Caught exception was:\", e);\n      chooseEvenlyFromRemainingRacks(writer, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageTypes,\n          totalReplicaExpected, e);\n\n    }\n\n    return writer;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyRackFaultTolerant.java",
      "extendedDetails": {}
    },
    "644c2f6924f341f51d809c91dccfff88fc82f6f0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12567. BlockPlacementPolicyRackFaultTolerant fails with racks with very few nodes.\n",
      "commitDate": "05/10/17 4:58 PM",
      "commitName": "644c2f6924f341f51d809c91dccfff88fc82f6f0",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "19/02/16 7:02 PM",
      "commitNameOld": "e54cc2931262bf49682a8323da9811976218c03b",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 593.87,
      "commitsBetweenForRepo": 3935,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,57 +1,81 @@\n   protected Node chooseTargetInOrder(int numOfReplicas,\n                                  Node writer,\n                                  final Set\u003cNode\u003e excludedNodes,\n                                  final long blocksize,\n                                  final int maxNodesPerRack,\n                                  final List\u003cDatanodeStorageInfo\u003e results,\n                                  final boolean avoidStaleNodes,\n                                  final boolean newBlock,\n                                  EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                                  throws NotEnoughReplicasException {\n     int totalReplicaExpected \u003d results.size() + numOfReplicas;\n     int numOfRacks \u003d clusterMap.getNumOfRacks();\n     if (totalReplicaExpected \u003c numOfRacks ||\n         totalReplicaExpected % numOfRacks \u003d\u003d 0) {\n       writer \u003d chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n           maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n       return writer;\n     }\n \n     assert totalReplicaExpected \u003e (maxNodesPerRack -1) * numOfRacks;\n \n     // Calculate numOfReplicas for filling each rack exactly (maxNodesPerRack-1)\n     // replicas.\n     HashMap\u003cString, Integer\u003e rackCounts \u003d new HashMap\u003c\u003e();\n     for (DatanodeStorageInfo dsInfo : results) {\n       String rack \u003d dsInfo.getDatanodeDescriptor().getNetworkLocation();\n       Integer count \u003d rackCounts.get(rack);\n       if (count !\u003d null) {\n         rackCounts.put(rack, count + 1);\n       } else {\n         rackCounts.put(rack, 1);\n       }\n     }\n     int excess \u003d 0; // Sum of the above (maxNodesPerRack-1) part of nodes in results\n     for (int count : rackCounts.values()) {\n       if (count \u003e maxNodesPerRack -1) {\n         excess +\u003d count - (maxNodesPerRack -1);\n       }\n     }\n     numOfReplicas \u003d Math.min(totalReplicaExpected - results.size(),\n         (maxNodesPerRack -1) * numOfRacks - (results.size() - excess));\n \n-    // Fill each rack exactly (maxNodesPerRack-1) replicas.\n-    writer \u003d chooseOnce(numOfReplicas, writer, new HashSet\u003c\u003e(excludedNodes),\n-        blocksize, maxNodesPerRack -1, results, avoidStaleNodes, storageTypes);\n+    try {\n+      // Try to spread the replicas as evenly as possible across racks.\n+      // This is done by first placing with (maxNodesPerRack-1), then spreading\n+      // the remainder by calling again with maxNodesPerRack.\n+      writer \u003d chooseOnce(numOfReplicas, writer, new HashSet\u003c\u003e(excludedNodes),\n+          blocksize, maxNodesPerRack - 1, results, avoidStaleNodes,\n+          storageTypes);\n \n-    for (DatanodeStorageInfo resultStorage : results) {\n-      addToExcludedNodes(resultStorage.getDatanodeDescriptor(), excludedNodes);\n+      // Exclude the chosen nodes\n+      for (DatanodeStorageInfo resultStorage : results) {\n+        addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n+            excludedNodes);\n+      }\n+      LOG.trace(\"Chosen nodes: {}\", results);\n+      LOG.trace(\"Excluded nodes: {}\", excludedNodes);\n+\n+      numOfReplicas \u003d totalReplicaExpected - results.size();\n+      chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n+          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n+    } catch (NotEnoughReplicasException e) {\n+      LOG.debug(\"Only able to place {} of {} (maxNodesPerRack\u003d{}) nodes \" +\n+              \"evenly across racks, falling back to uneven placement.\",\n+          results.size(), numOfReplicas, maxNodesPerRack);\n+      LOG.debug(\"Caught exception was:\", e);\n+      // Exclude the chosen nodes\n+      for (DatanodeStorageInfo resultStorage : results) {\n+        addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n+            excludedNodes);\n+      }\n+\n+      LOG.trace(\"Chosen nodes: {}\", results);\n+      LOG.trace(\"Excluded nodes: {}\", excludedNodes);\n+      numOfReplicas \u003d totalReplicaExpected - results.size();\n+      chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n+          totalReplicaExpected, results, avoidStaleNodes, storageTypes);\n     }\n \n-    // For some racks, place one more replica to each one of them.\n-    numOfReplicas \u003d totalReplicaExpected - results.size();\n-    chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n-        maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n-\n     return writer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected Node chooseTargetInOrder(int numOfReplicas,\n                                 Node writer,\n                                 final Set\u003cNode\u003e excludedNodes,\n                                 final long blocksize,\n                                 final int maxNodesPerRack,\n                                 final List\u003cDatanodeStorageInfo\u003e results,\n                                 final boolean avoidStaleNodes,\n                                 final boolean newBlock,\n                                 EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                                 throws NotEnoughReplicasException {\n    int totalReplicaExpected \u003d results.size() + numOfReplicas;\n    int numOfRacks \u003d clusterMap.getNumOfRacks();\n    if (totalReplicaExpected \u003c numOfRacks ||\n        totalReplicaExpected % numOfRacks \u003d\u003d 0) {\n      writer \u003d chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n      return writer;\n    }\n\n    assert totalReplicaExpected \u003e (maxNodesPerRack -1) * numOfRacks;\n\n    // Calculate numOfReplicas for filling each rack exactly (maxNodesPerRack-1)\n    // replicas.\n    HashMap\u003cString, Integer\u003e rackCounts \u003d new HashMap\u003c\u003e();\n    for (DatanodeStorageInfo dsInfo : results) {\n      String rack \u003d dsInfo.getDatanodeDescriptor().getNetworkLocation();\n      Integer count \u003d rackCounts.get(rack);\n      if (count !\u003d null) {\n        rackCounts.put(rack, count + 1);\n      } else {\n        rackCounts.put(rack, 1);\n      }\n    }\n    int excess \u003d 0; // Sum of the above (maxNodesPerRack-1) part of nodes in results\n    for (int count : rackCounts.values()) {\n      if (count \u003e maxNodesPerRack -1) {\n        excess +\u003d count - (maxNodesPerRack -1);\n      }\n    }\n    numOfReplicas \u003d Math.min(totalReplicaExpected - results.size(),\n        (maxNodesPerRack -1) * numOfRacks - (results.size() - excess));\n\n    try {\n      // Try to spread the replicas as evenly as possible across racks.\n      // This is done by first placing with (maxNodesPerRack-1), then spreading\n      // the remainder by calling again with maxNodesPerRack.\n      writer \u003d chooseOnce(numOfReplicas, writer, new HashSet\u003c\u003e(excludedNodes),\n          blocksize, maxNodesPerRack - 1, results, avoidStaleNodes,\n          storageTypes);\n\n      // Exclude the chosen nodes\n      for (DatanodeStorageInfo resultStorage : results) {\n        addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n            excludedNodes);\n      }\n      LOG.trace(\"Chosen nodes: {}\", results);\n      LOG.trace(\"Excluded nodes: {}\", excludedNodes);\n\n      numOfReplicas \u003d totalReplicaExpected - results.size();\n      chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    } catch (NotEnoughReplicasException e) {\n      LOG.debug(\"Only able to place {} of {} (maxNodesPerRack\u003d{}) nodes \" +\n              \"evenly across racks, falling back to uneven placement.\",\n          results.size(), numOfReplicas, maxNodesPerRack);\n      LOG.debug(\"Caught exception was:\", e);\n      // Exclude the chosen nodes\n      for (DatanodeStorageInfo resultStorage : results) {\n        addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n            excludedNodes);\n      }\n\n      LOG.trace(\"Chosen nodes: {}\", results);\n      LOG.trace(\"Excluded nodes: {}\", excludedNodes);\n      numOfReplicas \u003d totalReplicaExpected - results.size();\n      chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n          totalReplicaExpected, results, avoidStaleNodes, storageTypes);\n    }\n\n    return writer;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyRackFaultTolerant.java",
      "extendedDetails": {}
    },
    "c1d50a91f7c05e4aaf4655380c8dcd11703ff158": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8513. Rename BlockPlacementPolicyRackFaultTolarent to BlockPlacementPolicyRackFaultTolerant. (wang)\n",
      "commitDate": "02/06/15 3:48 PM",
      "commitName": "c1d50a91f7c05e4aaf4655380c8dcd11703ff158",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "02/06/15 3:39 PM",
      "commitNameOld": "efc510a570cf880e7df1b69932aa41932658ee51",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected Node chooseTargetInOrder(int numOfReplicas,\n                                 Node writer,\n                                 final Set\u003cNode\u003e excludedNodes,\n                                 final long blocksize,\n                                 final int maxNodesPerRack,\n                                 final List\u003cDatanodeStorageInfo\u003e results,\n                                 final boolean avoidStaleNodes,\n                                 final boolean newBlock,\n                                 EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                                 throws NotEnoughReplicasException {\n    int totalReplicaExpected \u003d results.size() + numOfReplicas;\n    int numOfRacks \u003d clusterMap.getNumOfRacks();\n    if (totalReplicaExpected \u003c numOfRacks ||\n        totalReplicaExpected % numOfRacks \u003d\u003d 0) {\n      writer \u003d chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n      return writer;\n    }\n\n    assert totalReplicaExpected \u003e (maxNodesPerRack -1) * numOfRacks;\n\n    // Calculate numOfReplicas for filling each rack exactly (maxNodesPerRack-1)\n    // replicas.\n    HashMap\u003cString, Integer\u003e rackCounts \u003d new HashMap\u003c\u003e();\n    for (DatanodeStorageInfo dsInfo : results) {\n      String rack \u003d dsInfo.getDatanodeDescriptor().getNetworkLocation();\n      Integer count \u003d rackCounts.get(rack);\n      if (count !\u003d null) {\n        rackCounts.put(rack, count + 1);\n      } else {\n        rackCounts.put(rack, 1);\n      }\n    }\n    int excess \u003d 0; // Sum of the above (maxNodesPerRack-1) part of nodes in results\n    for (int count : rackCounts.values()) {\n      if (count \u003e maxNodesPerRack -1) {\n        excess +\u003d count - (maxNodesPerRack -1);\n      }\n    }\n    numOfReplicas \u003d Math.min(totalReplicaExpected - results.size(),\n        (maxNodesPerRack -1) * numOfRacks - (results.size() - excess));\n\n    // Fill each rack exactly (maxNodesPerRack-1) replicas.\n    writer \u003d chooseOnce(numOfReplicas, writer, new HashSet\u003c\u003e(excludedNodes),\n        blocksize, maxNodesPerRack -1, results, avoidStaleNodes, storageTypes);\n\n    for (DatanodeStorageInfo resultStorage : results) {\n      addToExcludedNodes(resultStorage.getDatanodeDescriptor(), excludedNodes);\n    }\n\n    // For some racks, place one more replica to each one of them.\n    numOfReplicas \u003d totalReplicaExpected - results.size();\n    chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n        maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n\n    return writer;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyRackFaultTolerant.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyRackFaultTolarent.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyRackFaultTolerant.java"
      }
    },
    "9595cc003ca5ed3d59b6942056a4fcb9080f79c9": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7891. A block placement policy with best rack failure tolerance.  Contributed by Walter Su\n",
      "commitDate": "16/04/15 6:25 PM",
      "commitName": "9595cc003ca5ed3d59b6942056a4fcb9080f79c9",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "diff": "@@ -0,0 +1,57 @@\n+  protected Node chooseTargetInOrder(int numOfReplicas,\n+                                 Node writer,\n+                                 final Set\u003cNode\u003e excludedNodes,\n+                                 final long blocksize,\n+                                 final int maxNodesPerRack,\n+                                 final List\u003cDatanodeStorageInfo\u003e results,\n+                                 final boolean avoidStaleNodes,\n+                                 final boolean newBlock,\n+                                 EnumMap\u003cStorageType, Integer\u003e storageTypes)\n+                                 throws NotEnoughReplicasException {\n+    int totalReplicaExpected \u003d results.size() + numOfReplicas;\n+    int numOfRacks \u003d clusterMap.getNumOfRacks();\n+    if (totalReplicaExpected \u003c numOfRacks ||\n+        totalReplicaExpected % numOfRacks \u003d\u003d 0) {\n+      writer \u003d chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n+          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n+      return writer;\n+    }\n+\n+    assert totalReplicaExpected \u003e (maxNodesPerRack -1) * numOfRacks;\n+\n+    // Calculate numOfReplicas for filling each rack exactly (maxNodesPerRack-1)\n+    // replicas.\n+    HashMap\u003cString, Integer\u003e rackCounts \u003d new HashMap\u003c\u003e();\n+    for (DatanodeStorageInfo dsInfo : results) {\n+      String rack \u003d dsInfo.getDatanodeDescriptor().getNetworkLocation();\n+      Integer count \u003d rackCounts.get(rack);\n+      if (count !\u003d null) {\n+        rackCounts.put(rack, count + 1);\n+      } else {\n+        rackCounts.put(rack, 1);\n+      }\n+    }\n+    int excess \u003d 0; // Sum of the above (maxNodesPerRack-1) part of nodes in results\n+    for (int count : rackCounts.values()) {\n+      if (count \u003e maxNodesPerRack -1) {\n+        excess +\u003d count - (maxNodesPerRack -1);\n+      }\n+    }\n+    numOfReplicas \u003d Math.min(totalReplicaExpected - results.size(),\n+        (maxNodesPerRack -1) * numOfRacks - (results.size() - excess));\n+\n+    // Fill each rack exactly (maxNodesPerRack-1) replicas.\n+    writer \u003d chooseOnce(numOfReplicas, writer, new HashSet\u003c\u003e(excludedNodes),\n+        blocksize, maxNodesPerRack -1, results, avoidStaleNodes, storageTypes);\n+\n+    for (DatanodeStorageInfo resultStorage : results) {\n+      addToExcludedNodes(resultStorage.getDatanodeDescriptor(), excludedNodes);\n+    }\n+\n+    // For some racks, place one more replica to each one of them.\n+    numOfReplicas \u003d totalReplicaExpected - results.size();\n+    chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n+        maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n+\n+    return writer;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected Node chooseTargetInOrder(int numOfReplicas,\n                                 Node writer,\n                                 final Set\u003cNode\u003e excludedNodes,\n                                 final long blocksize,\n                                 final int maxNodesPerRack,\n                                 final List\u003cDatanodeStorageInfo\u003e results,\n                                 final boolean avoidStaleNodes,\n                                 final boolean newBlock,\n                                 EnumMap\u003cStorageType, Integer\u003e storageTypes)\n                                 throws NotEnoughReplicasException {\n    int totalReplicaExpected \u003d results.size() + numOfReplicas;\n    int numOfRacks \u003d clusterMap.getNumOfRacks();\n    if (totalReplicaExpected \u003c numOfRacks ||\n        totalReplicaExpected % numOfRacks \u003d\u003d 0) {\n      writer \u003d chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n      return writer;\n    }\n\n    assert totalReplicaExpected \u003e (maxNodesPerRack -1) * numOfRacks;\n\n    // Calculate numOfReplicas for filling each rack exactly (maxNodesPerRack-1)\n    // replicas.\n    HashMap\u003cString, Integer\u003e rackCounts \u003d new HashMap\u003c\u003e();\n    for (DatanodeStorageInfo dsInfo : results) {\n      String rack \u003d dsInfo.getDatanodeDescriptor().getNetworkLocation();\n      Integer count \u003d rackCounts.get(rack);\n      if (count !\u003d null) {\n        rackCounts.put(rack, count + 1);\n      } else {\n        rackCounts.put(rack, 1);\n      }\n    }\n    int excess \u003d 0; // Sum of the above (maxNodesPerRack-1) part of nodes in results\n    for (int count : rackCounts.values()) {\n      if (count \u003e maxNodesPerRack -1) {\n        excess +\u003d count - (maxNodesPerRack -1);\n      }\n    }\n    numOfReplicas \u003d Math.min(totalReplicaExpected - results.size(),\n        (maxNodesPerRack -1) * numOfRacks - (results.size() - excess));\n\n    // Fill each rack exactly (maxNodesPerRack-1) replicas.\n    writer \u003d chooseOnce(numOfReplicas, writer, new HashSet\u003c\u003e(excludedNodes),\n        blocksize, maxNodesPerRack -1, results, avoidStaleNodes, storageTypes);\n\n    for (DatanodeStorageInfo resultStorage : results) {\n      addToExcludedNodes(resultStorage.getDatanodeDescriptor(), excludedNodes);\n    }\n\n    // For some racks, place one more replica to each one of them.\n    numOfReplicas \u003d totalReplicaExpected - results.size();\n    chooseOnce(numOfReplicas, writer, excludedNodes, blocksize,\n        maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n\n    return writer;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyRackFaultTolarent.java"
    }
  }
}