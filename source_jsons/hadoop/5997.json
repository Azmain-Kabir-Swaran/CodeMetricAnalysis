{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NamenodeFsck.java",
  "functionName": "getReplicaInfo",
  "functionId": "getReplicaInfo___storedBlock-BlockInfo",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
  "functionStartLine": 623,
  "functionEndLine": 699,
  "numCommitsSeen": 120,
  "timeTaken": 4756,
  "changeHistory": [
    "b6f290d5b660ad157c7076767c619d02b3d0f894",
    "b782bf2156dd9d43610c0bc47d458b2db297589f",
    "78ae2aed8f84d2d3983f81a5219e8b1f1ec59dca",
    "2f8e9b7e4b1721ed5c7db8882eff70f83164e320",
    "c18590fce283378edb09acd4e764706a9a4a8b5f",
    "7d521a29eed62c4329b16034375bd5fb747a92a9",
    "6979cbfc1f4c28440816b56f5624765872b0be49",
    "d806a5bf079bf136114520c5a3a9d1f16ecf2eda"
  ],
  "changeHistoryShort": {
    "b6f290d5b660ad157c7076767c619d02b3d0f894": "Ybodychange",
    "b782bf2156dd9d43610c0bc47d458b2db297589f": "Ybodychange",
    "78ae2aed8f84d2d3983f81a5219e8b1f1ec59dca": "Ybodychange",
    "2f8e9b7e4b1721ed5c7db8882eff70f83164e320": "Ybodychange",
    "c18590fce283378edb09acd4e764706a9a4a8b5f": "Ybodychange",
    "7d521a29eed62c4329b16034375bd5fb747a92a9": "Ybodychange",
    "6979cbfc1f4c28440816b56f5624765872b0be49": "Ybodychange",
    "d806a5bf079bf136114520c5a3a9d1f16ecf2eda": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b6f290d5b660ad157c7076767c619d02b3d0f894": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11370. Optimize NamenodeFsck#getReplicaInfo. Contributed Takanobu Asanuma.\n",
      "commitDate": "01/02/17 11:21 AM",
      "commitName": "b6f290d5b660ad157c7076767c619d02b3d0f894",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "25/01/17 11:16 AM",
      "commitNameOld": "b782bf2156dd9d43610c0bc47d458b2db297589f",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 7.0,
      "commitsBetweenForRepo": 29,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,73 +1,77 @@\n   private String getReplicaInfo(BlockInfo storedBlock) {\n     if (!(showLocations || showRacks || showReplicaDetails ||\n         showUpgradeDomains)) {\n       return \"\";\n     }\n     final boolean isComplete \u003d storedBlock.isComplete();\n-    DatanodeStorageInfo[] storages \u003d isComplete ?\n-        blockManager.getStorages(storedBlock) :\n-        storedBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n+    Iterator\u003cDatanodeStorageInfo\u003e storagesItr;\n     StringBuilder sb \u003d new StringBuilder(\" [\");\n     final boolean isStriped \u003d storedBlock.isStriped();\n     Map\u003cDatanodeStorageInfo, Long\u003e storage2Id \u003d new HashMap\u003c\u003e();\n-    if (isStriped \u0026\u0026 isComplete) {\n-      long blockId \u003d storedBlock.getBlockId();\n-      Iterable\u003cStorageAndBlockIndex\u003e sis \u003d\n-          ((BlockInfoStriped)storedBlock).getStorageAndIndexInfos();\n-      for (StorageAndBlockIndex si: sis){\n-        storage2Id.put(si.getStorage(), blockId + si.getBlockIndex());\n+    if (isComplete) {\n+      if (isStriped) {\n+        long blockId \u003d storedBlock.getBlockId();\n+        Iterable\u003cStorageAndBlockIndex\u003e sis \u003d\n+            ((BlockInfoStriped) storedBlock).getStorageAndIndexInfos();\n+        for (StorageAndBlockIndex si : sis) {\n+          storage2Id.put(si.getStorage(), blockId + si.getBlockIndex());\n+        }\n       }\n+      storagesItr \u003d storedBlock.getStorageInfos();\n+    } else {\n+      storagesItr \u003d storedBlock.getUnderConstructionFeature()\n+          .getExpectedStorageLocationsIterator();\n     }\n \n-    for (int i \u003d 0; i \u003c storages.length; i++) {\n-      DatanodeStorageInfo storage \u003d storages[i];\n+    while (storagesItr.hasNext()) {\n+      DatanodeStorageInfo storage \u003d storagesItr.next();\n       if (isStriped \u0026\u0026 isComplete) {\n         long index \u003d storage2Id.get(storage);\n         sb.append(\"blk_\" + index + \":\");\n       }\n       DatanodeDescriptor dnDesc \u003d storage.getDatanodeDescriptor();\n       if (showRacks) {\n         sb.append(NodeBase.getPath(dnDesc));\n       } else {\n         sb.append(new DatanodeInfoWithStorage(dnDesc, storage.getStorageID(),\n             storage.getStorageType()));\n       }\n       if (showUpgradeDomains) {\n         String upgradeDomain \u003d (dnDesc.getUpgradeDomain() !\u003d null) ?\n             dnDesc.getUpgradeDomain() : UNDEFINED;\n         sb.append(\"(ud\u003d\" + upgradeDomain +\")\");\n       }\n       if (showReplicaDetails) {\n         Collection\u003cDatanodeDescriptor\u003e corruptReplicas \u003d\n             blockManager.getCorruptReplicas(storedBlock);\n         sb.append(\"(\");\n         if (dnDesc.isDecommissioned()) {\n           sb.append(\"DECOMMISSIONED)\");\n         } else if (dnDesc.isDecommissionInProgress()) {\n           sb.append(\"DECOMMISSIONING)\");\n         } else if (this.showMaintenanceState \u0026\u0026\n             dnDesc.isEnteringMaintenance()) {\n           sb.append(\"ENTERING MAINTENANCE)\");\n         } else if (this.showMaintenanceState \u0026\u0026\n             dnDesc.isInMaintenance()) {\n           sb.append(\"IN MAINTENANCE)\");\n         } else if (corruptReplicas !\u003d null\n             \u0026\u0026 corruptReplicas.contains(dnDesc)) {\n           sb.append(\"CORRUPT)\");\n         } else if (blockManager.isExcess(dnDesc, storedBlock)) {\n           sb.append(\"EXCESS)\");\n         } else if (dnDesc.isStale(this.staleInterval)) {\n           sb.append(\"STALE_NODE)\");\n         } else if (storage.areBlockContentsStale()) {\n           sb.append(\"STALE_BLOCK_CONTENT)\");\n         } else {\n           sb.append(\"LIVE)\");\n         }\n       }\n-      if (i \u003c storages.length - 1) {\n+      if (storagesItr.hasNext()) {\n         sb.append(\", \");\n       }\n     }\n     sb.append(\u0027]\u0027);\n     return sb.toString();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private String getReplicaInfo(BlockInfo storedBlock) {\n    if (!(showLocations || showRacks || showReplicaDetails ||\n        showUpgradeDomains)) {\n      return \"\";\n    }\n    final boolean isComplete \u003d storedBlock.isComplete();\n    Iterator\u003cDatanodeStorageInfo\u003e storagesItr;\n    StringBuilder sb \u003d new StringBuilder(\" [\");\n    final boolean isStriped \u003d storedBlock.isStriped();\n    Map\u003cDatanodeStorageInfo, Long\u003e storage2Id \u003d new HashMap\u003c\u003e();\n    if (isComplete) {\n      if (isStriped) {\n        long blockId \u003d storedBlock.getBlockId();\n        Iterable\u003cStorageAndBlockIndex\u003e sis \u003d\n            ((BlockInfoStriped) storedBlock).getStorageAndIndexInfos();\n        for (StorageAndBlockIndex si : sis) {\n          storage2Id.put(si.getStorage(), blockId + si.getBlockIndex());\n        }\n      }\n      storagesItr \u003d storedBlock.getStorageInfos();\n    } else {\n      storagesItr \u003d storedBlock.getUnderConstructionFeature()\n          .getExpectedStorageLocationsIterator();\n    }\n\n    while (storagesItr.hasNext()) {\n      DatanodeStorageInfo storage \u003d storagesItr.next();\n      if (isStriped \u0026\u0026 isComplete) {\n        long index \u003d storage2Id.get(storage);\n        sb.append(\"blk_\" + index + \":\");\n      }\n      DatanodeDescriptor dnDesc \u003d storage.getDatanodeDescriptor();\n      if (showRacks) {\n        sb.append(NodeBase.getPath(dnDesc));\n      } else {\n        sb.append(new DatanodeInfoWithStorage(dnDesc, storage.getStorageID(),\n            storage.getStorageType()));\n      }\n      if (showUpgradeDomains) {\n        String upgradeDomain \u003d (dnDesc.getUpgradeDomain() !\u003d null) ?\n            dnDesc.getUpgradeDomain() : UNDEFINED;\n        sb.append(\"(ud\u003d\" + upgradeDomain +\")\");\n      }\n      if (showReplicaDetails) {\n        Collection\u003cDatanodeDescriptor\u003e corruptReplicas \u003d\n            blockManager.getCorruptReplicas(storedBlock);\n        sb.append(\"(\");\n        if (dnDesc.isDecommissioned()) {\n          sb.append(\"DECOMMISSIONED)\");\n        } else if (dnDesc.isDecommissionInProgress()) {\n          sb.append(\"DECOMMISSIONING)\");\n        } else if (this.showMaintenanceState \u0026\u0026\n            dnDesc.isEnteringMaintenance()) {\n          sb.append(\"ENTERING MAINTENANCE)\");\n        } else if (this.showMaintenanceState \u0026\u0026\n            dnDesc.isInMaintenance()) {\n          sb.append(\"IN MAINTENANCE)\");\n        } else if (corruptReplicas !\u003d null\n            \u0026\u0026 corruptReplicas.contains(dnDesc)) {\n          sb.append(\"CORRUPT)\");\n        } else if (blockManager.isExcess(dnDesc, storedBlock)) {\n          sb.append(\"EXCESS)\");\n        } else if (dnDesc.isStale(this.staleInterval)) {\n          sb.append(\"STALE_NODE)\");\n        } else if (storage.areBlockContentsStale()) {\n          sb.append(\"STALE_BLOCK_CONTENT)\");\n        } else {\n          sb.append(\"LIVE)\");\n        }\n      }\n      if (storagesItr.hasNext()) {\n        sb.append(\", \");\n      }\n    }\n    sb.append(\u0027]\u0027);\n    return sb.toString();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {}
    },
    "b782bf2156dd9d43610c0bc47d458b2db297589f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11124. Report blockIds of internal blocks for EC files in Fsck. Contributed by Takanobu Asanuma.\n",
      "commitDate": "25/01/17 11:16 AM",
      "commitName": "b782bf2156dd9d43610c0bc47d458b2db297589f",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "19/01/17 12:28 AM",
      "commitNameOld": "78ae2aed8f84d2d3983f81a5219e8b1f1ec59dca",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 6.45,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,59 +1,73 @@\n   private String getReplicaInfo(BlockInfo storedBlock) {\n     if (!(showLocations || showRacks || showReplicaDetails ||\n         showUpgradeDomains)) {\n       return \"\";\n     }\n     final boolean isComplete \u003d storedBlock.isComplete();\n     DatanodeStorageInfo[] storages \u003d isComplete ?\n         blockManager.getStorages(storedBlock) :\n         storedBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n     StringBuilder sb \u003d new StringBuilder(\" [\");\n+    final boolean isStriped \u003d storedBlock.isStriped();\n+    Map\u003cDatanodeStorageInfo, Long\u003e storage2Id \u003d new HashMap\u003c\u003e();\n+    if (isStriped \u0026\u0026 isComplete) {\n+      long blockId \u003d storedBlock.getBlockId();\n+      Iterable\u003cStorageAndBlockIndex\u003e sis \u003d\n+          ((BlockInfoStriped)storedBlock).getStorageAndIndexInfos();\n+      for (StorageAndBlockIndex si: sis){\n+        storage2Id.put(si.getStorage(), blockId + si.getBlockIndex());\n+      }\n+    }\n \n     for (int i \u003d 0; i \u003c storages.length; i++) {\n       DatanodeStorageInfo storage \u003d storages[i];\n+      if (isStriped \u0026\u0026 isComplete) {\n+        long index \u003d storage2Id.get(storage);\n+        sb.append(\"blk_\" + index + \":\");\n+      }\n       DatanodeDescriptor dnDesc \u003d storage.getDatanodeDescriptor();\n       if (showRacks) {\n         sb.append(NodeBase.getPath(dnDesc));\n       } else {\n         sb.append(new DatanodeInfoWithStorage(dnDesc, storage.getStorageID(),\n             storage.getStorageType()));\n       }\n       if (showUpgradeDomains) {\n         String upgradeDomain \u003d (dnDesc.getUpgradeDomain() !\u003d null) ?\n             dnDesc.getUpgradeDomain() : UNDEFINED;\n         sb.append(\"(ud\u003d\" + upgradeDomain +\")\");\n       }\n       if (showReplicaDetails) {\n         Collection\u003cDatanodeDescriptor\u003e corruptReplicas \u003d\n             blockManager.getCorruptReplicas(storedBlock);\n         sb.append(\"(\");\n         if (dnDesc.isDecommissioned()) {\n           sb.append(\"DECOMMISSIONED)\");\n         } else if (dnDesc.isDecommissionInProgress()) {\n           sb.append(\"DECOMMISSIONING)\");\n         } else if (this.showMaintenanceState \u0026\u0026\n             dnDesc.isEnteringMaintenance()) {\n           sb.append(\"ENTERING MAINTENANCE)\");\n         } else if (this.showMaintenanceState \u0026\u0026\n             dnDesc.isInMaintenance()) {\n           sb.append(\"IN MAINTENANCE)\");\n         } else if (corruptReplicas !\u003d null\n             \u0026\u0026 corruptReplicas.contains(dnDesc)) {\n           sb.append(\"CORRUPT)\");\n         } else if (blockManager.isExcess(dnDesc, storedBlock)) {\n           sb.append(\"EXCESS)\");\n         } else if (dnDesc.isStale(this.staleInterval)) {\n           sb.append(\"STALE_NODE)\");\n         } else if (storage.areBlockContentsStale()) {\n           sb.append(\"STALE_BLOCK_CONTENT)\");\n         } else {\n           sb.append(\"LIVE)\");\n         }\n       }\n       if (i \u003c storages.length - 1) {\n         sb.append(\", \");\n       }\n     }\n     sb.append(\u0027]\u0027);\n     return sb.toString();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private String getReplicaInfo(BlockInfo storedBlock) {\n    if (!(showLocations || showRacks || showReplicaDetails ||\n        showUpgradeDomains)) {\n      return \"\";\n    }\n    final boolean isComplete \u003d storedBlock.isComplete();\n    DatanodeStorageInfo[] storages \u003d isComplete ?\n        blockManager.getStorages(storedBlock) :\n        storedBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n    StringBuilder sb \u003d new StringBuilder(\" [\");\n    final boolean isStriped \u003d storedBlock.isStriped();\n    Map\u003cDatanodeStorageInfo, Long\u003e storage2Id \u003d new HashMap\u003c\u003e();\n    if (isStriped \u0026\u0026 isComplete) {\n      long blockId \u003d storedBlock.getBlockId();\n      Iterable\u003cStorageAndBlockIndex\u003e sis \u003d\n          ((BlockInfoStriped)storedBlock).getStorageAndIndexInfos();\n      for (StorageAndBlockIndex si: sis){\n        storage2Id.put(si.getStorage(), blockId + si.getBlockIndex());\n      }\n    }\n\n    for (int i \u003d 0; i \u003c storages.length; i++) {\n      DatanodeStorageInfo storage \u003d storages[i];\n      if (isStriped \u0026\u0026 isComplete) {\n        long index \u003d storage2Id.get(storage);\n        sb.append(\"blk_\" + index + \":\");\n      }\n      DatanodeDescriptor dnDesc \u003d storage.getDatanodeDescriptor();\n      if (showRacks) {\n        sb.append(NodeBase.getPath(dnDesc));\n      } else {\n        sb.append(new DatanodeInfoWithStorage(dnDesc, storage.getStorageID(),\n            storage.getStorageType()));\n      }\n      if (showUpgradeDomains) {\n        String upgradeDomain \u003d (dnDesc.getUpgradeDomain() !\u003d null) ?\n            dnDesc.getUpgradeDomain() : UNDEFINED;\n        sb.append(\"(ud\u003d\" + upgradeDomain +\")\");\n      }\n      if (showReplicaDetails) {\n        Collection\u003cDatanodeDescriptor\u003e corruptReplicas \u003d\n            blockManager.getCorruptReplicas(storedBlock);\n        sb.append(\"(\");\n        if (dnDesc.isDecommissioned()) {\n          sb.append(\"DECOMMISSIONED)\");\n        } else if (dnDesc.isDecommissionInProgress()) {\n          sb.append(\"DECOMMISSIONING)\");\n        } else if (this.showMaintenanceState \u0026\u0026\n            dnDesc.isEnteringMaintenance()) {\n          sb.append(\"ENTERING MAINTENANCE)\");\n        } else if (this.showMaintenanceState \u0026\u0026\n            dnDesc.isInMaintenance()) {\n          sb.append(\"IN MAINTENANCE)\");\n        } else if (corruptReplicas !\u003d null\n            \u0026\u0026 corruptReplicas.contains(dnDesc)) {\n          sb.append(\"CORRUPT)\");\n        } else if (blockManager.isExcess(dnDesc, storedBlock)) {\n          sb.append(\"EXCESS)\");\n        } else if (dnDesc.isStale(this.staleInterval)) {\n          sb.append(\"STALE_NODE)\");\n        } else if (storage.areBlockContentsStale()) {\n          sb.append(\"STALE_BLOCK_CONTENT)\");\n        } else {\n          sb.append(\"LIVE)\");\n        }\n      }\n      if (i \u003c storages.length - 1) {\n        sb.append(\", \");\n      }\n    }\n    sb.append(\u0027]\u0027);\n    return sb.toString();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {}
    },
    "78ae2aed8f84d2d3983f81a5219e8b1f1ec59dca": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11259. Update fsck to display maintenance state info. (Manoj Govindassamy via lei)\n",
      "commitDate": "19/01/17 12:28 AM",
      "commitName": "78ae2aed8f84d2d3983f81a5219e8b1f1ec59dca",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "18/01/17 1:31 PM",
      "commitNameOld": "a2a5d7b5bca715835d92816e7b267b59f7270708",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 0.46,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,59 @@\n   private String getReplicaInfo(BlockInfo storedBlock) {\n     if (!(showLocations || showRacks || showReplicaDetails ||\n         showUpgradeDomains)) {\n       return \"\";\n     }\n     final boolean isComplete \u003d storedBlock.isComplete();\n     DatanodeStorageInfo[] storages \u003d isComplete ?\n         blockManager.getStorages(storedBlock) :\n         storedBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n     StringBuilder sb \u003d new StringBuilder(\" [\");\n \n     for (int i \u003d 0; i \u003c storages.length; i++) {\n       DatanodeStorageInfo storage \u003d storages[i];\n       DatanodeDescriptor dnDesc \u003d storage.getDatanodeDescriptor();\n       if (showRacks) {\n         sb.append(NodeBase.getPath(dnDesc));\n       } else {\n         sb.append(new DatanodeInfoWithStorage(dnDesc, storage.getStorageID(),\n             storage.getStorageType()));\n       }\n       if (showUpgradeDomains) {\n         String upgradeDomain \u003d (dnDesc.getUpgradeDomain() !\u003d null) ?\n             dnDesc.getUpgradeDomain() : UNDEFINED;\n         sb.append(\"(ud\u003d\" + upgradeDomain +\")\");\n       }\n       if (showReplicaDetails) {\n         Collection\u003cDatanodeDescriptor\u003e corruptReplicas \u003d\n             blockManager.getCorruptReplicas(storedBlock);\n         sb.append(\"(\");\n         if (dnDesc.isDecommissioned()) {\n           sb.append(\"DECOMMISSIONED)\");\n         } else if (dnDesc.isDecommissionInProgress()) {\n           sb.append(\"DECOMMISSIONING)\");\n+        } else if (this.showMaintenanceState \u0026\u0026\n+            dnDesc.isEnteringMaintenance()) {\n+          sb.append(\"ENTERING MAINTENANCE)\");\n+        } else if (this.showMaintenanceState \u0026\u0026\n+            dnDesc.isInMaintenance()) {\n+          sb.append(\"IN MAINTENANCE)\");\n         } else if (corruptReplicas !\u003d null\n             \u0026\u0026 corruptReplicas.contains(dnDesc)) {\n           sb.append(\"CORRUPT)\");\n         } else if (blockManager.isExcess(dnDesc, storedBlock)) {\n           sb.append(\"EXCESS)\");\n         } else if (dnDesc.isStale(this.staleInterval)) {\n           sb.append(\"STALE_NODE)\");\n         } else if (storage.areBlockContentsStale()) {\n           sb.append(\"STALE_BLOCK_CONTENT)\");\n         } else {\n           sb.append(\"LIVE)\");\n         }\n       }\n       if (i \u003c storages.length - 1) {\n         sb.append(\", \");\n       }\n     }\n     sb.append(\u0027]\u0027);\n     return sb.toString();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private String getReplicaInfo(BlockInfo storedBlock) {\n    if (!(showLocations || showRacks || showReplicaDetails ||\n        showUpgradeDomains)) {\n      return \"\";\n    }\n    final boolean isComplete \u003d storedBlock.isComplete();\n    DatanodeStorageInfo[] storages \u003d isComplete ?\n        blockManager.getStorages(storedBlock) :\n        storedBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n    StringBuilder sb \u003d new StringBuilder(\" [\");\n\n    for (int i \u003d 0; i \u003c storages.length; i++) {\n      DatanodeStorageInfo storage \u003d storages[i];\n      DatanodeDescriptor dnDesc \u003d storage.getDatanodeDescriptor();\n      if (showRacks) {\n        sb.append(NodeBase.getPath(dnDesc));\n      } else {\n        sb.append(new DatanodeInfoWithStorage(dnDesc, storage.getStorageID(),\n            storage.getStorageType()));\n      }\n      if (showUpgradeDomains) {\n        String upgradeDomain \u003d (dnDesc.getUpgradeDomain() !\u003d null) ?\n            dnDesc.getUpgradeDomain() : UNDEFINED;\n        sb.append(\"(ud\u003d\" + upgradeDomain +\")\");\n      }\n      if (showReplicaDetails) {\n        Collection\u003cDatanodeDescriptor\u003e corruptReplicas \u003d\n            blockManager.getCorruptReplicas(storedBlock);\n        sb.append(\"(\");\n        if (dnDesc.isDecommissioned()) {\n          sb.append(\"DECOMMISSIONED)\");\n        } else if (dnDesc.isDecommissionInProgress()) {\n          sb.append(\"DECOMMISSIONING)\");\n        } else if (this.showMaintenanceState \u0026\u0026\n            dnDesc.isEnteringMaintenance()) {\n          sb.append(\"ENTERING MAINTENANCE)\");\n        } else if (this.showMaintenanceState \u0026\u0026\n            dnDesc.isInMaintenance()) {\n          sb.append(\"IN MAINTENANCE)\");\n        } else if (corruptReplicas !\u003d null\n            \u0026\u0026 corruptReplicas.contains(dnDesc)) {\n          sb.append(\"CORRUPT)\");\n        } else if (blockManager.isExcess(dnDesc, storedBlock)) {\n          sb.append(\"EXCESS)\");\n        } else if (dnDesc.isStale(this.staleInterval)) {\n          sb.append(\"STALE_NODE)\");\n        } else if (storage.areBlockContentsStale()) {\n          sb.append(\"STALE_BLOCK_CONTENT)\");\n        } else {\n          sb.append(\"LIVE)\");\n        }\n      }\n      if (i \u003c storages.length - 1) {\n        sb.append(\", \");\n      }\n    }\n    sb.append(\u0027]\u0027);\n    return sb.toString();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {}
    },
    "2f8e9b7e4b1721ed5c7db8882eff70f83164e320": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-11259. Update fsck to display maintenance state info. (Manoj Govindassamy via lei)\"\n\nThis reverts commit c18590fce283378edb09acd4e764706a9a4a8b5f.\n",
      "commitDate": "15/01/17 11:11 PM",
      "commitName": "2f8e9b7e4b1721ed5c7db8882eff70f83164e320",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "10/01/17 3:37 AM",
      "commitNameOld": "c18590fce283378edb09acd4e764706a9a4a8b5f",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 5.82,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,57 +1,53 @@\n   private String getReplicaInfo(BlockInfo storedBlock) {\n     if (!(showLocations || showRacks || showReplicaDetails ||\n         showUpgradeDomains)) {\n       return \"\";\n     }\n     final boolean isComplete \u003d storedBlock.isComplete();\n     DatanodeStorageInfo[] storages \u003d isComplete ?\n         blockManager.getStorages(storedBlock) :\n         storedBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n     StringBuilder sb \u003d new StringBuilder(\" [\");\n \n     for (int i \u003d 0; i \u003c storages.length; i++) {\n       DatanodeStorageInfo storage \u003d storages[i];\n       DatanodeDescriptor dnDesc \u003d storage.getDatanodeDescriptor();\n       if (showRacks) {\n         sb.append(NodeBase.getPath(dnDesc));\n       } else {\n         sb.append(new DatanodeInfoWithStorage(dnDesc, storage.getStorageID(),\n             storage.getStorageType()));\n       }\n       if (showUpgradeDomains) {\n         String upgradeDomain \u003d (dnDesc.getUpgradeDomain() !\u003d null) ?\n             dnDesc.getUpgradeDomain() : UNDEFINED;\n         sb.append(\"(ud\u003d\" + upgradeDomain +\")\");\n       }\n       if (showReplicaDetails) {\n         Collection\u003cDatanodeDescriptor\u003e corruptReplicas \u003d\n             blockManager.getCorruptReplicas(storedBlock);\n         sb.append(\"(\");\n         if (dnDesc.isDecommissioned()) {\n           sb.append(\"DECOMMISSIONED)\");\n         } else if (dnDesc.isDecommissionInProgress()) {\n           sb.append(\"DECOMMISSIONING)\");\n-        } else if (dnDesc.isEnteringMaintenance()) {\n-          sb.append(\"ENTERING MAINTENANCE)\");\n-        } else if (dnDesc.isInMaintenance()) {\n-          sb.append(\"IN MAINTENANCE)\");\n         } else if (corruptReplicas !\u003d null\n             \u0026\u0026 corruptReplicas.contains(dnDesc)) {\n           sb.append(\"CORRUPT)\");\n         } else if (blockManager.isExcess(dnDesc, storedBlock)) {\n           sb.append(\"EXCESS)\");\n         } else if (dnDesc.isStale(this.staleInterval)) {\n           sb.append(\"STALE_NODE)\");\n         } else if (storage.areBlockContentsStale()) {\n           sb.append(\"STALE_BLOCK_CONTENT)\");\n         } else {\n           sb.append(\"LIVE)\");\n         }\n       }\n       if (i \u003c storages.length - 1) {\n         sb.append(\", \");\n       }\n     }\n     sb.append(\u0027]\u0027);\n     return sb.toString();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private String getReplicaInfo(BlockInfo storedBlock) {\n    if (!(showLocations || showRacks || showReplicaDetails ||\n        showUpgradeDomains)) {\n      return \"\";\n    }\n    final boolean isComplete \u003d storedBlock.isComplete();\n    DatanodeStorageInfo[] storages \u003d isComplete ?\n        blockManager.getStorages(storedBlock) :\n        storedBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n    StringBuilder sb \u003d new StringBuilder(\" [\");\n\n    for (int i \u003d 0; i \u003c storages.length; i++) {\n      DatanodeStorageInfo storage \u003d storages[i];\n      DatanodeDescriptor dnDesc \u003d storage.getDatanodeDescriptor();\n      if (showRacks) {\n        sb.append(NodeBase.getPath(dnDesc));\n      } else {\n        sb.append(new DatanodeInfoWithStorage(dnDesc, storage.getStorageID(),\n            storage.getStorageType()));\n      }\n      if (showUpgradeDomains) {\n        String upgradeDomain \u003d (dnDesc.getUpgradeDomain() !\u003d null) ?\n            dnDesc.getUpgradeDomain() : UNDEFINED;\n        sb.append(\"(ud\u003d\" + upgradeDomain +\")\");\n      }\n      if (showReplicaDetails) {\n        Collection\u003cDatanodeDescriptor\u003e corruptReplicas \u003d\n            blockManager.getCorruptReplicas(storedBlock);\n        sb.append(\"(\");\n        if (dnDesc.isDecommissioned()) {\n          sb.append(\"DECOMMISSIONED)\");\n        } else if (dnDesc.isDecommissionInProgress()) {\n          sb.append(\"DECOMMISSIONING)\");\n        } else if (corruptReplicas !\u003d null\n            \u0026\u0026 corruptReplicas.contains(dnDesc)) {\n          sb.append(\"CORRUPT)\");\n        } else if (blockManager.isExcess(dnDesc, storedBlock)) {\n          sb.append(\"EXCESS)\");\n        } else if (dnDesc.isStale(this.staleInterval)) {\n          sb.append(\"STALE_NODE)\");\n        } else if (storage.areBlockContentsStale()) {\n          sb.append(\"STALE_BLOCK_CONTENT)\");\n        } else {\n          sb.append(\"LIVE)\");\n        }\n      }\n      if (i \u003c storages.length - 1) {\n        sb.append(\", \");\n      }\n    }\n    sb.append(\u0027]\u0027);\n    return sb.toString();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {}
    },
    "c18590fce283378edb09acd4e764706a9a4a8b5f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11259. Update fsck to display maintenance state info. (Manoj Govindassamy via lei)\n",
      "commitDate": "10/01/17 3:37 AM",
      "commitName": "c18590fce283378edb09acd4e764706a9a4a8b5f",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "14/11/16 11:05 AM",
      "commitNameOld": "ff0b99eafeda035ebe0dc82cfe689808047a8893",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 56.69,
      "commitsBetweenForRepo": 299,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,57 @@\n   private String getReplicaInfo(BlockInfo storedBlock) {\n     if (!(showLocations || showRacks || showReplicaDetails ||\n         showUpgradeDomains)) {\n       return \"\";\n     }\n     final boolean isComplete \u003d storedBlock.isComplete();\n     DatanodeStorageInfo[] storages \u003d isComplete ?\n         blockManager.getStorages(storedBlock) :\n         storedBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n     StringBuilder sb \u003d new StringBuilder(\" [\");\n \n     for (int i \u003d 0; i \u003c storages.length; i++) {\n       DatanodeStorageInfo storage \u003d storages[i];\n       DatanodeDescriptor dnDesc \u003d storage.getDatanodeDescriptor();\n       if (showRacks) {\n         sb.append(NodeBase.getPath(dnDesc));\n       } else {\n         sb.append(new DatanodeInfoWithStorage(dnDesc, storage.getStorageID(),\n             storage.getStorageType()));\n       }\n       if (showUpgradeDomains) {\n         String upgradeDomain \u003d (dnDesc.getUpgradeDomain() !\u003d null) ?\n             dnDesc.getUpgradeDomain() : UNDEFINED;\n         sb.append(\"(ud\u003d\" + upgradeDomain +\")\");\n       }\n       if (showReplicaDetails) {\n         Collection\u003cDatanodeDescriptor\u003e corruptReplicas \u003d\n             blockManager.getCorruptReplicas(storedBlock);\n         sb.append(\"(\");\n         if (dnDesc.isDecommissioned()) {\n           sb.append(\"DECOMMISSIONED)\");\n         } else if (dnDesc.isDecommissionInProgress()) {\n           sb.append(\"DECOMMISSIONING)\");\n+        } else if (dnDesc.isEnteringMaintenance()) {\n+          sb.append(\"ENTERING MAINTENANCE)\");\n+        } else if (dnDesc.isInMaintenance()) {\n+          sb.append(\"IN MAINTENANCE)\");\n         } else if (corruptReplicas !\u003d null\n             \u0026\u0026 corruptReplicas.contains(dnDesc)) {\n           sb.append(\"CORRUPT)\");\n         } else if (blockManager.isExcess(dnDesc, storedBlock)) {\n           sb.append(\"EXCESS)\");\n         } else if (dnDesc.isStale(this.staleInterval)) {\n           sb.append(\"STALE_NODE)\");\n         } else if (storage.areBlockContentsStale()) {\n           sb.append(\"STALE_BLOCK_CONTENT)\");\n         } else {\n           sb.append(\"LIVE)\");\n         }\n       }\n       if (i \u003c storages.length - 1) {\n         sb.append(\", \");\n       }\n     }\n     sb.append(\u0027]\u0027);\n     return sb.toString();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private String getReplicaInfo(BlockInfo storedBlock) {\n    if (!(showLocations || showRacks || showReplicaDetails ||\n        showUpgradeDomains)) {\n      return \"\";\n    }\n    final boolean isComplete \u003d storedBlock.isComplete();\n    DatanodeStorageInfo[] storages \u003d isComplete ?\n        blockManager.getStorages(storedBlock) :\n        storedBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n    StringBuilder sb \u003d new StringBuilder(\" [\");\n\n    for (int i \u003d 0; i \u003c storages.length; i++) {\n      DatanodeStorageInfo storage \u003d storages[i];\n      DatanodeDescriptor dnDesc \u003d storage.getDatanodeDescriptor();\n      if (showRacks) {\n        sb.append(NodeBase.getPath(dnDesc));\n      } else {\n        sb.append(new DatanodeInfoWithStorage(dnDesc, storage.getStorageID(),\n            storage.getStorageType()));\n      }\n      if (showUpgradeDomains) {\n        String upgradeDomain \u003d (dnDesc.getUpgradeDomain() !\u003d null) ?\n            dnDesc.getUpgradeDomain() : UNDEFINED;\n        sb.append(\"(ud\u003d\" + upgradeDomain +\")\");\n      }\n      if (showReplicaDetails) {\n        Collection\u003cDatanodeDescriptor\u003e corruptReplicas \u003d\n            blockManager.getCorruptReplicas(storedBlock);\n        sb.append(\"(\");\n        if (dnDesc.isDecommissioned()) {\n          sb.append(\"DECOMMISSIONED)\");\n        } else if (dnDesc.isDecommissionInProgress()) {\n          sb.append(\"DECOMMISSIONING)\");\n        } else if (dnDesc.isEnteringMaintenance()) {\n          sb.append(\"ENTERING MAINTENANCE)\");\n        } else if (dnDesc.isInMaintenance()) {\n          sb.append(\"IN MAINTENANCE)\");\n        } else if (corruptReplicas !\u003d null\n            \u0026\u0026 corruptReplicas.contains(dnDesc)) {\n          sb.append(\"CORRUPT)\");\n        } else if (blockManager.isExcess(dnDesc, storedBlock)) {\n          sb.append(\"EXCESS)\");\n        } else if (dnDesc.isStale(this.staleInterval)) {\n          sb.append(\"STALE_NODE)\");\n        } else if (storage.areBlockContentsStale()) {\n          sb.append(\"STALE_BLOCK_CONTENT)\");\n        } else {\n          sb.append(\"LIVE)\");\n        }\n      }\n      if (i \u003c storages.length - 1) {\n        sb.append(\", \");\n      }\n    }\n    sb.append(\u0027]\u0027);\n    return sb.toString();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {}
    },
    "7d521a29eed62c4329b16034375bd5fb747a92a9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9016. Display upgrade domain information in fsck. (mingma)\n",
      "commitDate": "14/06/16 8:05 PM",
      "commitName": "7d521a29eed62c4329b16034375bd5fb747a92a9",
      "commitAuthor": "Ming Ma",
      "commitDateOld": "26/05/16 4:50 PM",
      "commitNameOld": "8c84a2a93c22a93b4ff46dd917f6efb995675fbd",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 19.14,
      "commitsBetweenForRepo": 113,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,53 @@\n   private String getReplicaInfo(BlockInfo storedBlock) {\n-    if (!(showLocations || showRacks || showReplicaDetails)) {\n+    if (!(showLocations || showRacks || showReplicaDetails ||\n+        showUpgradeDomains)) {\n       return \"\";\n     }\n     final boolean isComplete \u003d storedBlock.isComplete();\n     DatanodeStorageInfo[] storages \u003d isComplete ?\n         blockManager.getStorages(storedBlock) :\n         storedBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n     StringBuilder sb \u003d new StringBuilder(\" [\");\n \n     for (int i \u003d 0; i \u003c storages.length; i++) {\n       DatanodeStorageInfo storage \u003d storages[i];\n       DatanodeDescriptor dnDesc \u003d storage.getDatanodeDescriptor();\n       if (showRacks) {\n         sb.append(NodeBase.getPath(dnDesc));\n       } else {\n         sb.append(new DatanodeInfoWithStorage(dnDesc, storage.getStorageID(),\n             storage.getStorageType()));\n       }\n+      if (showUpgradeDomains) {\n+        String upgradeDomain \u003d (dnDesc.getUpgradeDomain() !\u003d null) ?\n+            dnDesc.getUpgradeDomain() : UNDEFINED;\n+        sb.append(\"(ud\u003d\" + upgradeDomain +\")\");\n+      }\n       if (showReplicaDetails) {\n         Collection\u003cDatanodeDescriptor\u003e corruptReplicas \u003d\n             blockManager.getCorruptReplicas(storedBlock);\n         sb.append(\"(\");\n         if (dnDesc.isDecommissioned()) {\n           sb.append(\"DECOMMISSIONED)\");\n         } else if (dnDesc.isDecommissionInProgress()) {\n           sb.append(\"DECOMMISSIONING)\");\n         } else if (corruptReplicas !\u003d null\n             \u0026\u0026 corruptReplicas.contains(dnDesc)) {\n           sb.append(\"CORRUPT)\");\n         } else if (blockManager.isExcess(dnDesc, storedBlock)) {\n           sb.append(\"EXCESS)\");\n         } else if (dnDesc.isStale(this.staleInterval)) {\n           sb.append(\"STALE_NODE)\");\n         } else if (storage.areBlockContentsStale()) {\n           sb.append(\"STALE_BLOCK_CONTENT)\");\n         } else {\n           sb.append(\"LIVE)\");\n         }\n       }\n       if (i \u003c storages.length - 1) {\n         sb.append(\", \");\n       }\n     }\n     sb.append(\u0027]\u0027);\n     return sb.toString();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private String getReplicaInfo(BlockInfo storedBlock) {\n    if (!(showLocations || showRacks || showReplicaDetails ||\n        showUpgradeDomains)) {\n      return \"\";\n    }\n    final boolean isComplete \u003d storedBlock.isComplete();\n    DatanodeStorageInfo[] storages \u003d isComplete ?\n        blockManager.getStorages(storedBlock) :\n        storedBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n    StringBuilder sb \u003d new StringBuilder(\" [\");\n\n    for (int i \u003d 0; i \u003c storages.length; i++) {\n      DatanodeStorageInfo storage \u003d storages[i];\n      DatanodeDescriptor dnDesc \u003d storage.getDatanodeDescriptor();\n      if (showRacks) {\n        sb.append(NodeBase.getPath(dnDesc));\n      } else {\n        sb.append(new DatanodeInfoWithStorage(dnDesc, storage.getStorageID(),\n            storage.getStorageType()));\n      }\n      if (showUpgradeDomains) {\n        String upgradeDomain \u003d (dnDesc.getUpgradeDomain() !\u003d null) ?\n            dnDesc.getUpgradeDomain() : UNDEFINED;\n        sb.append(\"(ud\u003d\" + upgradeDomain +\")\");\n      }\n      if (showReplicaDetails) {\n        Collection\u003cDatanodeDescriptor\u003e corruptReplicas \u003d\n            blockManager.getCorruptReplicas(storedBlock);\n        sb.append(\"(\");\n        if (dnDesc.isDecommissioned()) {\n          sb.append(\"DECOMMISSIONED)\");\n        } else if (dnDesc.isDecommissionInProgress()) {\n          sb.append(\"DECOMMISSIONING)\");\n        } else if (corruptReplicas !\u003d null\n            \u0026\u0026 corruptReplicas.contains(dnDesc)) {\n          sb.append(\"CORRUPT)\");\n        } else if (blockManager.isExcess(dnDesc, storedBlock)) {\n          sb.append(\"EXCESS)\");\n        } else if (dnDesc.isStale(this.staleInterval)) {\n          sb.append(\"STALE_NODE)\");\n        } else if (storage.areBlockContentsStale()) {\n          sb.append(\"STALE_BLOCK_CONTENT)\");\n        } else {\n          sb.append(\"LIVE)\");\n        }\n      }\n      if (i \u003c storages.length - 1) {\n        sb.append(\", \");\n      }\n    }\n    sb.append(\u0027]\u0027);\n    return sb.toString();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {}
    },
    "6979cbfc1f4c28440816b56f5624765872b0be49": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9838. Refactor the excessReplicateMap to a class.\n",
      "commitDate": "24/02/16 7:42 PM",
      "commitName": "6979cbfc1f4c28440816b56f5624765872b0be49",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "11/12/15 5:57 PM",
      "commitNameOld": "796a676d18bd7cd3ed4113d002e0e69cf261d6d1",
      "commitAuthorOld": "Uma Mahesh",
      "daysBetweenCommits": 75.07,
      "commitsBetweenForRepo": 484,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,47 @@\n   private String getReplicaInfo(BlockInfo storedBlock) {\n     if (!(showLocations || showRacks || showReplicaDetails)) {\n       return \"\";\n     }\n     final boolean isComplete \u003d storedBlock.isComplete();\n     DatanodeStorageInfo[] storages \u003d isComplete ?\n         blockManager.getStorages(storedBlock) :\n         storedBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n     StringBuilder sb \u003d new StringBuilder(\" [\");\n \n     for (int i \u003d 0; i \u003c storages.length; i++) {\n       DatanodeStorageInfo storage \u003d storages[i];\n       DatanodeDescriptor dnDesc \u003d storage.getDatanodeDescriptor();\n       if (showRacks) {\n         sb.append(NodeBase.getPath(dnDesc));\n       } else {\n         sb.append(new DatanodeInfoWithStorage(dnDesc, storage.getStorageID(),\n             storage.getStorageType()));\n       }\n       if (showReplicaDetails) {\n-        LightWeightHashSet\u003cBlockInfo\u003e blocksExcess \u003d\n-            blockManager.excessReplicateMap.get(dnDesc.getDatanodeUuid());\n         Collection\u003cDatanodeDescriptor\u003e corruptReplicas \u003d\n             blockManager.getCorruptReplicas(storedBlock);\n         sb.append(\"(\");\n         if (dnDesc.isDecommissioned()) {\n           sb.append(\"DECOMMISSIONED)\");\n         } else if (dnDesc.isDecommissionInProgress()) {\n           sb.append(\"DECOMMISSIONING)\");\n         } else if (corruptReplicas !\u003d null\n             \u0026\u0026 corruptReplicas.contains(dnDesc)) {\n           sb.append(\"CORRUPT)\");\n-        } else if (blocksExcess !\u003d null\n-            \u0026\u0026 blocksExcess.contains(storedBlock)) {\n+        } else if (blockManager.isExcess(dnDesc, storedBlock)) {\n           sb.append(\"EXCESS)\");\n         } else if (dnDesc.isStale(this.staleInterval)) {\n           sb.append(\"STALE_NODE)\");\n         } else if (storage.areBlockContentsStale()) {\n           sb.append(\"STALE_BLOCK_CONTENT)\");\n         } else {\n           sb.append(\"LIVE)\");\n         }\n       }\n       if (i \u003c storages.length - 1) {\n         sb.append(\", \");\n       }\n     }\n     sb.append(\u0027]\u0027);\n     return sb.toString();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private String getReplicaInfo(BlockInfo storedBlock) {\n    if (!(showLocations || showRacks || showReplicaDetails)) {\n      return \"\";\n    }\n    final boolean isComplete \u003d storedBlock.isComplete();\n    DatanodeStorageInfo[] storages \u003d isComplete ?\n        blockManager.getStorages(storedBlock) :\n        storedBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n    StringBuilder sb \u003d new StringBuilder(\" [\");\n\n    for (int i \u003d 0; i \u003c storages.length; i++) {\n      DatanodeStorageInfo storage \u003d storages[i];\n      DatanodeDescriptor dnDesc \u003d storage.getDatanodeDescriptor();\n      if (showRacks) {\n        sb.append(NodeBase.getPath(dnDesc));\n      } else {\n        sb.append(new DatanodeInfoWithStorage(dnDesc, storage.getStorageID(),\n            storage.getStorageType()));\n      }\n      if (showReplicaDetails) {\n        Collection\u003cDatanodeDescriptor\u003e corruptReplicas \u003d\n            blockManager.getCorruptReplicas(storedBlock);\n        sb.append(\"(\");\n        if (dnDesc.isDecommissioned()) {\n          sb.append(\"DECOMMISSIONED)\");\n        } else if (dnDesc.isDecommissionInProgress()) {\n          sb.append(\"DECOMMISSIONING)\");\n        } else if (corruptReplicas !\u003d null\n            \u0026\u0026 corruptReplicas.contains(dnDesc)) {\n          sb.append(\"CORRUPT)\");\n        } else if (blockManager.isExcess(dnDesc, storedBlock)) {\n          sb.append(\"EXCESS)\");\n        } else if (dnDesc.isStale(this.staleInterval)) {\n          sb.append(\"STALE_NODE)\");\n        } else if (storage.areBlockContentsStale()) {\n          sb.append(\"STALE_BLOCK_CONTENT)\");\n        } else {\n          sb.append(\"LIVE)\");\n        }\n      }\n      if (i \u003c storages.length - 1) {\n        sb.append(\", \");\n      }\n    }\n    sb.append(\u0027]\u0027);\n    return sb.toString();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {}
    },
    "d806a5bf079bf136114520c5a3a9d1f16ecf2eda": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9070. Allow fsck display pending replica location information for being-written blocks. Contributed by Gao Rui.\n",
      "commitDate": "21/10/15 2:44 PM",
      "commitName": "d806a5bf079bf136114520c5a3a9d1f16ecf2eda",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,50 @@\n+  private String getReplicaInfo(BlockInfo storedBlock) {\n+    if (!(showLocations || showRacks || showReplicaDetails)) {\n+      return \"\";\n+    }\n+    final boolean isComplete \u003d storedBlock.isComplete();\n+    DatanodeStorageInfo[] storages \u003d isComplete ?\n+        blockManager.getStorages(storedBlock) :\n+        storedBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n+    StringBuilder sb \u003d new StringBuilder(\" [\");\n+\n+    for (int i \u003d 0; i \u003c storages.length; i++) {\n+      DatanodeStorageInfo storage \u003d storages[i];\n+      DatanodeDescriptor dnDesc \u003d storage.getDatanodeDescriptor();\n+      if (showRacks) {\n+        sb.append(NodeBase.getPath(dnDesc));\n+      } else {\n+        sb.append(new DatanodeInfoWithStorage(dnDesc, storage.getStorageID(),\n+            storage.getStorageType()));\n+      }\n+      if (showReplicaDetails) {\n+        LightWeightHashSet\u003cBlockInfo\u003e blocksExcess \u003d\n+            blockManager.excessReplicateMap.get(dnDesc.getDatanodeUuid());\n+        Collection\u003cDatanodeDescriptor\u003e corruptReplicas \u003d\n+            blockManager.getCorruptReplicas(storedBlock);\n+        sb.append(\"(\");\n+        if (dnDesc.isDecommissioned()) {\n+          sb.append(\"DECOMMISSIONED)\");\n+        } else if (dnDesc.isDecommissionInProgress()) {\n+          sb.append(\"DECOMMISSIONING)\");\n+        } else if (corruptReplicas !\u003d null\n+            \u0026\u0026 corruptReplicas.contains(dnDesc)) {\n+          sb.append(\"CORRUPT)\");\n+        } else if (blocksExcess !\u003d null\n+            \u0026\u0026 blocksExcess.contains(storedBlock)) {\n+          sb.append(\"EXCESS)\");\n+        } else if (dnDesc.isStale(this.staleInterval)) {\n+          sb.append(\"STALE_NODE)\");\n+        } else if (storage.areBlockContentsStale()) {\n+          sb.append(\"STALE_BLOCK_CONTENT)\");\n+        } else {\n+          sb.append(\"LIVE)\");\n+        }\n+      }\n+      if (i \u003c storages.length - 1) {\n+        sb.append(\", \");\n+      }\n+    }\n+    sb.append(\u0027]\u0027);\n+    return sb.toString();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private String getReplicaInfo(BlockInfo storedBlock) {\n    if (!(showLocations || showRacks || showReplicaDetails)) {\n      return \"\";\n    }\n    final boolean isComplete \u003d storedBlock.isComplete();\n    DatanodeStorageInfo[] storages \u003d isComplete ?\n        blockManager.getStorages(storedBlock) :\n        storedBlock.getUnderConstructionFeature().getExpectedStorageLocations();\n    StringBuilder sb \u003d new StringBuilder(\" [\");\n\n    for (int i \u003d 0; i \u003c storages.length; i++) {\n      DatanodeStorageInfo storage \u003d storages[i];\n      DatanodeDescriptor dnDesc \u003d storage.getDatanodeDescriptor();\n      if (showRacks) {\n        sb.append(NodeBase.getPath(dnDesc));\n      } else {\n        sb.append(new DatanodeInfoWithStorage(dnDesc, storage.getStorageID(),\n            storage.getStorageType()));\n      }\n      if (showReplicaDetails) {\n        LightWeightHashSet\u003cBlockInfo\u003e blocksExcess \u003d\n            blockManager.excessReplicateMap.get(dnDesc.getDatanodeUuid());\n        Collection\u003cDatanodeDescriptor\u003e corruptReplicas \u003d\n            blockManager.getCorruptReplicas(storedBlock);\n        sb.append(\"(\");\n        if (dnDesc.isDecommissioned()) {\n          sb.append(\"DECOMMISSIONED)\");\n        } else if (dnDesc.isDecommissionInProgress()) {\n          sb.append(\"DECOMMISSIONING)\");\n        } else if (corruptReplicas !\u003d null\n            \u0026\u0026 corruptReplicas.contains(dnDesc)) {\n          sb.append(\"CORRUPT)\");\n        } else if (blocksExcess !\u003d null\n            \u0026\u0026 blocksExcess.contains(storedBlock)) {\n          sb.append(\"EXCESS)\");\n        } else if (dnDesc.isStale(this.staleInterval)) {\n          sb.append(\"STALE_NODE)\");\n        } else if (storage.areBlockContentsStale()) {\n          sb.append(\"STALE_BLOCK_CONTENT)\");\n        } else {\n          sb.append(\"LIVE)\");\n        }\n      }\n      if (i \u003c storages.length - 1) {\n        sb.append(\", \");\n      }\n    }\n    sb.append(\u0027]\u0027);\n    return sb.toString();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java"
    }
  }
}