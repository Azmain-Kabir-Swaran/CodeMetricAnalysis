{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSEditLogLoader.java",
  "functionName": "formatEditLogReplayError",
  "functionId": "formatEditLogReplayError___in-EditLogInputStream__recentOpcodeOffsets-long[]__txid-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java",
  "functionStartLine": 1058,
  "functionEndLine": 1073,
  "numCommitsSeen": 198,
  "timeTaken": 3881,
  "changeHistory": [
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd",
    "706394d03992b394e9f907aff2155df493e4ea4e"
  ],
  "changeHistoryShort": {
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd": "Ybodychange",
    "706394d03992b394e9f907aff2155df493e4ea4e": "Ybodychange"
  },
  "changeHistoryDetails": {
    "fb8932a727f757b2e9c1c61a18145878d0eb77bd": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16029. Consecutive StringBuilder.append can be reused. Contributed by Ayush Saxena.\n",
      "commitDate": "11/01/19 10:54 AM",
      "commitName": "fb8932a727f757b2e9c1c61a18145878d0eb77bd",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "24/12/18 9:34 AM",
      "commitNameOld": "a65bb97f5d8bf2eb817923a69bbb966359f736d7",
      "commitAuthorOld": "Chen Liang",
      "daysBetweenCommits": 18.06,
      "commitsBetweenForRepo": 96,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n   private static String formatEditLogReplayError(EditLogInputStream in,\n       long recentOpcodeOffsets[], long txid) {\n     StringBuilder sb \u003d new StringBuilder();\n-    sb.append(\"Error replaying edit log at offset \" + in.getPosition());\n-    sb.append(\".  Expected transaction ID was \").append(txid);\n+    sb.append(\"Error replaying edit log at offset \" + in.getPosition())\n+        .append(\".  Expected transaction ID was \").append(txid);\n     if (recentOpcodeOffsets[0] !\u003d -1) {\n       Arrays.sort(recentOpcodeOffsets);\n       sb.append(\"\\nRecent opcode offsets:\");\n       for (long offset : recentOpcodeOffsets) {\n         if (offset !\u003d -1) {\n           sb.append(\u0027 \u0027).append(offset);\n         }\n       }\n     }\n     return sb.toString();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static String formatEditLogReplayError(EditLogInputStream in,\n      long recentOpcodeOffsets[], long txid) {\n    StringBuilder sb \u003d new StringBuilder();\n    sb.append(\"Error replaying edit log at offset \" + in.getPosition())\n        .append(\".  Expected transaction ID was \").append(txid);\n    if (recentOpcodeOffsets[0] !\u003d -1) {\n      Arrays.sort(recentOpcodeOffsets);\n      sb.append(\"\\nRecent opcode offsets:\");\n      for (long offset : recentOpcodeOffsets) {\n        if (offset !\u003d -1) {\n          sb.append(\u0027 \u0027).append(offset);\n        }\n      }\n    }\n    return sb.toString();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java",
      "extendedDetails": {}
    },
    "706394d03992b394e9f907aff2155df493e4ea4e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3004. Implement Recovery Mode. Contributed by Colin Patrick McCabe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311394 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/04/12 12:39 PM",
      "commitName": "706394d03992b394e9f907aff2155df493e4ea4e",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "29/03/12 5:11 PM",
      "commitNameOld": "64641c28b5ea8538033060452b0c45b7f2eeb60c",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 10.81,
      "commitsBetweenForRepo": 96,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n   private static String formatEditLogReplayError(EditLogInputStream in,\n       long recentOpcodeOffsets[], long txid) {\n     StringBuilder sb \u003d new StringBuilder();\n     sb.append(\"Error replaying edit log at offset \" + in.getPosition());\n-    sb.append(\" on transaction ID \").append(txid);\n+    sb.append(\".  Expected transaction ID was \").append(txid);\n     if (recentOpcodeOffsets[0] !\u003d -1) {\n       Arrays.sort(recentOpcodeOffsets);\n       sb.append(\"\\nRecent opcode offsets:\");\n       for (long offset : recentOpcodeOffsets) {\n         if (offset !\u003d -1) {\n           sb.append(\u0027 \u0027).append(offset);\n         }\n       }\n     }\n     return sb.toString();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static String formatEditLogReplayError(EditLogInputStream in,\n      long recentOpcodeOffsets[], long txid) {\n    StringBuilder sb \u003d new StringBuilder();\n    sb.append(\"Error replaying edit log at offset \" + in.getPosition());\n    sb.append(\".  Expected transaction ID was \").append(txid);\n    if (recentOpcodeOffsets[0] !\u003d -1) {\n      Arrays.sort(recentOpcodeOffsets);\n      sb.append(\"\\nRecent opcode offsets:\");\n      for (long offset : recentOpcodeOffsets) {\n        if (offset !\u003d -1) {\n          sb.append(\u0027 \u0027).append(offset);\n        }\n      }\n    }\n    return sb.toString();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java",
      "extendedDetails": {}
    }
  }
}