{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "StoragePolicySatisfier.java",
  "functionName": "analyseBlocksStorageMovementsAndAssignToDN",
  "functionId": "analyseBlocksStorageMovementsAndAssignToDN___fileInfo-HdfsLocatedFileStatus__existingStoragePolicy-BlockStoragePolicy",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
  "functionStartLine": 347,
  "functionEndLine": 457,
  "numCommitsSeen": 69,
  "timeTaken": 12950,
  "changeHistory": [
    "66e8f9b31529226309c924226a53dead3e6fcf11",
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
    "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
    "8467ec24fb74f30371d5a13e893fc56309ee9372",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
    "5845c36c16c423107183287cce3be9357dad7564",
    "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10",
    "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d",
    "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
    "78420719eb1f138c6f10558befb7bc8ebcc28a54",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
    "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
    "0b360b16ab8759e3db606ada3420f4e2f56235f3",
    "6fe6c549e8226b4893f502186f52452dcd9408a2"
  ],
  "changeHistoryShort": {
    "66e8f9b31529226309c924226a53dead3e6fcf11": "Ybodychange",
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": "Ybodychange",
    "75ccc1396b677777cdc0d4992a4af3911f9f88c2": "Ymultichange(Yparameterchange,Yexceptionschange,Ybodychange)",
    "8467ec24fb74f30371d5a13e893fc56309ee9372": "Ymultichange(Yparameterchange,Ybodychange)",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": "Ybodychange",
    "5845c36c16c423107183287cce3be9357dad7564": "Ybodychange",
    "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10": "Ybodychange",
    "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d": "Ybodychange",
    "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d": "Ymultichange(Yparameterchange,Ybodychange)",
    "78420719eb1f138c6f10558befb7bc8ebcc28a54": "Yfilerename",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": "Ymultichange(Yreturntypechange,Ybodychange)",
    "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923": "Ybodychange",
    "0b360b16ab8759e3db606ada3420f4e2f56235f3": "Ybodychange",
    "6fe6c549e8226b4893f502186f52452dcd9408a2": "Yintroduced"
  },
  "changeHistoryDetails": {
    "66e8f9b31529226309c924226a53dead3e6fcf11": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13381 : [SPS]: Use DFSUtilClient#makePathFromFileId() to prepare satisfier file path. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "66e8f9b31529226309c924226a53dead3e6fcf11",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,111 +1,111 @@\n   private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n       HdfsLocatedFileStatus fileInfo,\n       BlockStoragePolicy existingStoragePolicy) throws IOException {\n     BlocksMovingAnalysis.Status status \u003d\n         BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n     final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n     final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n     final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n     if (!lastBlkComplete) {\n       // Postpone, currently file is under construction\n       LOG.info(\"File: {} is under construction. So, postpone\"\n           + \" this to the next retry iteration\", fileInfo.getFileId());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n           new HashMap\u003c\u003e());\n     }\n \n     List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n     if (blocks.size() \u003d\u003d 0) {\n       LOG.info(\"File: {} is not having any blocks.\"\n           + \" So, skipping the analysis.\", fileInfo.getFileId());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n           new HashMap\u003c\u003e());\n     }\n     List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n     boolean hasLowRedundancyBlocks \u003d false;\n     int replication \u003d fileInfo.getReplication();\n     DatanodeMap liveDns \u003d dnCacheMgr.getLiveDatanodeStorageReport(ctxt);\n     for (int i \u003d 0; i \u003c blocks.size(); i++) {\n       LocatedBlock blockInfo \u003d blocks.get(i);\n \n       // Block is considered as low redundancy when the block locations array\n       // length is less than expected replication factor. If any of the block is\n       // low redundant, then hasLowRedundancyBlocks will be marked as true.\n       hasLowRedundancyBlocks |\u003d isLowRedundancyBlock(blockInfo, replication,\n           ecPolicy);\n \n       List\u003cStorageType\u003e expectedStorageTypes;\n       if (blockInfo.isStriped()) {\n         if (ErasureCodingPolicyManager\n             .checkStoragePolicySuitableForECStripedMode(\n                 existingStoragePolicy.getId())) {\n           expectedStorageTypes \u003d existingStoragePolicy\n               .chooseStorageTypes((short) blockInfo.getLocations().length);\n         } else {\n           // Currently we support only limited policies (HOT, COLD, ALLSSD)\n           // for EC striped mode files. SPS will ignore to move the blocks if\n           // the storage policy is not in EC Striped mode supported policies\n           LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n               + \" is not suitable for Striped EC files. \"\n               + \"So, ignoring to move the blocks\");\n           return new BlocksMovingAnalysis(\n               BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n               new HashMap\u003c\u003e());\n         }\n       } else {\n         expectedStorageTypes \u003d existingStoragePolicy\n             .chooseStorageTypes(fileInfo.getReplication());\n       }\n \n       List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n           Arrays.asList(blockInfo.getStorageTypes()));\n       if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n           existing, true)) {\n         boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n             blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n             liveDns, ecPolicy);\n         if (blocksPaired) {\n           status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n         } else if (status !\u003d\n             BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n           // Check if the previous block was successfully paired. Here the\n           // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n           // blocks of a file found its eligible targets to satisfy the storage\n           // policy.\n           status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n         }\n       }\n     }\n \n     // If there is no block paired and few blocks are low redundant, so marking\n     // the status as FEW_LOW_REDUNDANCY_BLOCKS.\n     if (hasLowRedundancyBlocks\n         \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n       status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n     }\n     Map\u003cBlock, Set\u003cStorageTypeNodePair\u003e\u003e assignedBlocks \u003d new HashMap\u003c\u003e();\n     for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n       // Check for at least one block storage movement has been chosen\n       try {\n-        blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n+        ctxt.submitMoveTask(blkMovingInfo);\n         LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n         StorageTypeNodePair nodeStorage \u003d new StorageTypeNodePair(\n             blkMovingInfo.getTargetStorageType(), blkMovingInfo.getTarget());\n         Set\u003cStorageTypeNodePair\u003e nodesWithStorage \u003d assignedBlocks\n             .get(blkMovingInfo.getBlock());\n         if (nodesWithStorage \u003d\u003d null) {\n           nodesWithStorage \u003d new HashSet\u003c\u003e();\n           assignedBlocks.put(blkMovingInfo.getBlock(), nodesWithStorage);\n         }\n         nodesWithStorage.add(nodeStorage);\n         blockCount++;\n       } catch (IOException e) {\n         LOG.warn(\"Exception while scheduling movement task\", e);\n         // failed to move the block.\n         status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n       }\n     }\n     return new BlocksMovingAnalysis(status, assignedBlocks);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n      HdfsLocatedFileStatus fileInfo,\n      BlockStoragePolicy existingStoragePolicy) throws IOException {\n    BlocksMovingAnalysis.Status status \u003d\n        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n    final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n    final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n    final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n    if (!lastBlkComplete) {\n      // Postpone, currently file is under construction\n      LOG.info(\"File: {} is under construction. So, postpone\"\n          + \" this to the next retry iteration\", fileInfo.getFileId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n          new HashMap\u003c\u003e());\n    }\n\n    List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n    if (blocks.size() \u003d\u003d 0) {\n      LOG.info(\"File: {} is not having any blocks.\"\n          + \" So, skipping the analysis.\", fileInfo.getFileId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n          new HashMap\u003c\u003e());\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n    boolean hasLowRedundancyBlocks \u003d false;\n    int replication \u003d fileInfo.getReplication();\n    DatanodeMap liveDns \u003d dnCacheMgr.getLiveDatanodeStorageReport(ctxt);\n    for (int i \u003d 0; i \u003c blocks.size(); i++) {\n      LocatedBlock blockInfo \u003d blocks.get(i);\n\n      // Block is considered as low redundancy when the block locations array\n      // length is less than expected replication factor. If any of the block is\n      // low redundant, then hasLowRedundancyBlocks will be marked as true.\n      hasLowRedundancyBlocks |\u003d isLowRedundancyBlock(blockInfo, replication,\n          ecPolicy);\n\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicy.getId())) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getLocations().length);\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return new BlocksMovingAnalysis(\n              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n              new HashMap\u003c\u003e());\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(fileInfo.getReplication());\n      }\n\n      List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n          Arrays.asList(blockInfo.getStorageTypes()));\n      if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n            liveDns, ecPolicy);\n        if (blocksPaired) {\n          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n        } else if (status !\u003d\n            BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n          // Check if the previous block was successfully paired. Here the\n          // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n          // blocks of a file found its eligible targets to satisfy the storage\n          // policy.\n          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n        }\n      }\n    }\n\n    // If there is no block paired and few blocks are low redundant, so marking\n    // the status as FEW_LOW_REDUNDANCY_BLOCKS.\n    if (hasLowRedundancyBlocks\n        \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n      status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n    }\n    Map\u003cBlock, Set\u003cStorageTypeNodePair\u003e\u003e assignedBlocks \u003d new HashMap\u003c\u003e();\n    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n      // Check for at least one block storage movement has been chosen\n      try {\n        ctxt.submitMoveTask(blkMovingInfo);\n        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n        StorageTypeNodePair nodeStorage \u003d new StorageTypeNodePair(\n            blkMovingInfo.getTargetStorageType(), blkMovingInfo.getTarget());\n        Set\u003cStorageTypeNodePair\u003e nodesWithStorage \u003d assignedBlocks\n            .get(blkMovingInfo.getBlock());\n        if (nodesWithStorage \u003d\u003d null) {\n          nodesWithStorage \u003d new HashSet\u003c\u003e();\n          assignedBlocks.put(blkMovingInfo.getBlock(), nodesWithStorage);\n        }\n        nodesWithStorage.add(nodeStorage);\n        blockCount++;\n      } catch (IOException e) {\n        LOG.warn(\"Exception while scheduling movement task\", e);\n        // failed to move the block.\n        status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n      }\n    }\n    return new BlocksMovingAnalysis(status, assignedBlocks);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,103 +1,111 @@\n   private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n       HdfsLocatedFileStatus fileInfo,\n       BlockStoragePolicy existingStoragePolicy) throws IOException {\n     BlocksMovingAnalysis.Status status \u003d\n         BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n     final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n     final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n     final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n     if (!lastBlkComplete) {\n       // Postpone, currently file is under construction\n       LOG.info(\"File: {} is under construction. So, postpone\"\n-          + \" this to the next retry iteration\", fileInfo.getPath());\n+          + \" this to the next retry iteration\", fileInfo.getFileId());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n-          new ArrayList\u003c\u003e());\n+          new HashMap\u003c\u003e());\n     }\n \n     List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n     if (blocks.size() \u003d\u003d 0) {\n       LOG.info(\"File: {} is not having any blocks.\"\n-          + \" So, skipping the analysis.\", fileInfo.getPath());\n+          + \" So, skipping the analysis.\", fileInfo.getFileId());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n-          new ArrayList\u003c\u003e());\n+          new HashMap\u003c\u003e());\n     }\n     List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n     boolean hasLowRedundancyBlocks \u003d false;\n     int replication \u003d fileInfo.getReplication();\n     DatanodeMap liveDns \u003d dnCacheMgr.getLiveDatanodeStorageReport(ctxt);\n     for (int i \u003d 0; i \u003c blocks.size(); i++) {\n       LocatedBlock blockInfo \u003d blocks.get(i);\n \n       // Block is considered as low redundancy when the block locations array\n       // length is less than expected replication factor. If any of the block is\n       // low redundant, then hasLowRedundancyBlocks will be marked as true.\n       hasLowRedundancyBlocks |\u003d isLowRedundancyBlock(blockInfo, replication,\n           ecPolicy);\n \n       List\u003cStorageType\u003e expectedStorageTypes;\n       if (blockInfo.isStriped()) {\n         if (ErasureCodingPolicyManager\n             .checkStoragePolicySuitableForECStripedMode(\n                 existingStoragePolicy.getId())) {\n           expectedStorageTypes \u003d existingStoragePolicy\n               .chooseStorageTypes((short) blockInfo.getLocations().length);\n         } else {\n           // Currently we support only limited policies (HOT, COLD, ALLSSD)\n           // for EC striped mode files. SPS will ignore to move the blocks if\n           // the storage policy is not in EC Striped mode supported policies\n           LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n               + \" is not suitable for Striped EC files. \"\n               + \"So, ignoring to move the blocks\");\n           return new BlocksMovingAnalysis(\n               BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n-              new ArrayList\u003c\u003e());\n+              new HashMap\u003c\u003e());\n         }\n       } else {\n         expectedStorageTypes \u003d existingStoragePolicy\n             .chooseStorageTypes(fileInfo.getReplication());\n       }\n \n       List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n           Arrays.asList(blockInfo.getStorageTypes()));\n       if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n           existing, true)) {\n         boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n             blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n             liveDns, ecPolicy);\n         if (blocksPaired) {\n           status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n         } else if (status !\u003d\n             BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n           // Check if the previous block was successfully paired. Here the\n           // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n           // blocks of a file found its eligible targets to satisfy the storage\n           // policy.\n           status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n         }\n       }\n     }\n \n     // If there is no block paired and few blocks are low redundant, so marking\n     // the status as FEW_LOW_REDUNDANCY_BLOCKS.\n     if (hasLowRedundancyBlocks\n         \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n       status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n     }\n-    List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n+    Map\u003cBlock, Set\u003cStorageTypeNodePair\u003e\u003e assignedBlocks \u003d new HashMap\u003c\u003e();\n     for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n       // Check for at least one block storage movement has been chosen\n       try {\n         blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n         LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n-        assignedBlockIds.add(blkMovingInfo.getBlock());\n+        StorageTypeNodePair nodeStorage \u003d new StorageTypeNodePair(\n+            blkMovingInfo.getTargetStorageType(), blkMovingInfo.getTarget());\n+        Set\u003cStorageTypeNodePair\u003e nodesWithStorage \u003d assignedBlocks\n+            .get(blkMovingInfo.getBlock());\n+        if (nodesWithStorage \u003d\u003d null) {\n+          nodesWithStorage \u003d new HashSet\u003c\u003e();\n+          assignedBlocks.put(blkMovingInfo.getBlock(), nodesWithStorage);\n+        }\n+        nodesWithStorage.add(nodeStorage);\n         blockCount++;\n       } catch (IOException e) {\n         LOG.warn(\"Exception while scheduling movement task\", e);\n         // failed to move the block.\n         status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n       }\n     }\n-    return new BlocksMovingAnalysis(status, assignedBlockIds);\n+    return new BlocksMovingAnalysis(status, assignedBlocks);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n      HdfsLocatedFileStatus fileInfo,\n      BlockStoragePolicy existingStoragePolicy) throws IOException {\n    BlocksMovingAnalysis.Status status \u003d\n        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n    final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n    final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n    final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n    if (!lastBlkComplete) {\n      // Postpone, currently file is under construction\n      LOG.info(\"File: {} is under construction. So, postpone\"\n          + \" this to the next retry iteration\", fileInfo.getFileId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n          new HashMap\u003c\u003e());\n    }\n\n    List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n    if (blocks.size() \u003d\u003d 0) {\n      LOG.info(\"File: {} is not having any blocks.\"\n          + \" So, skipping the analysis.\", fileInfo.getFileId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n          new HashMap\u003c\u003e());\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n    boolean hasLowRedundancyBlocks \u003d false;\n    int replication \u003d fileInfo.getReplication();\n    DatanodeMap liveDns \u003d dnCacheMgr.getLiveDatanodeStorageReport(ctxt);\n    for (int i \u003d 0; i \u003c blocks.size(); i++) {\n      LocatedBlock blockInfo \u003d blocks.get(i);\n\n      // Block is considered as low redundancy when the block locations array\n      // length is less than expected replication factor. If any of the block is\n      // low redundant, then hasLowRedundancyBlocks will be marked as true.\n      hasLowRedundancyBlocks |\u003d isLowRedundancyBlock(blockInfo, replication,\n          ecPolicy);\n\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicy.getId())) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getLocations().length);\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return new BlocksMovingAnalysis(\n              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n              new HashMap\u003c\u003e());\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(fileInfo.getReplication());\n      }\n\n      List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n          Arrays.asList(blockInfo.getStorageTypes()));\n      if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n            liveDns, ecPolicy);\n        if (blocksPaired) {\n          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n        } else if (status !\u003d\n            BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n          // Check if the previous block was successfully paired. Here the\n          // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n          // blocks of a file found its eligible targets to satisfy the storage\n          // policy.\n          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n        }\n      }\n    }\n\n    // If there is no block paired and few blocks are low redundant, so marking\n    // the status as FEW_LOW_REDUNDANCY_BLOCKS.\n    if (hasLowRedundancyBlocks\n        \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n      status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n    }\n    Map\u003cBlock, Set\u003cStorageTypeNodePair\u003e\u003e assignedBlocks \u003d new HashMap\u003c\u003e();\n    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n      // Check for at least one block storage movement has been chosen\n      try {\n        blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n        StorageTypeNodePair nodeStorage \u003d new StorageTypeNodePair(\n            blkMovingInfo.getTargetStorageType(), blkMovingInfo.getTarget());\n        Set\u003cStorageTypeNodePair\u003e nodesWithStorage \u003d assignedBlocks\n            .get(blkMovingInfo.getBlock());\n        if (nodesWithStorage \u003d\u003d null) {\n          nodesWithStorage \u003d new HashSet\u003c\u003e();\n          assignedBlocks.put(blkMovingInfo.getBlock(), nodesWithStorage);\n        }\n        nodesWithStorage.add(nodeStorage);\n        blockCount++;\n      } catch (IOException e) {\n        LOG.warn(\"Exception while scheduling movement task\", e);\n        // failed to move the block.\n        status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n      }\n    }\n    return new BlocksMovingAnalysis(status, assignedBlocks);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "75ccc1396b677777cdc0d4992a4af3911f9f88c2": {
      "type": "Ymultichange(Yparameterchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-13166: [SPS]: Implement caching mechanism to keep LIVE datanodes to minimize costly getLiveDatanodeStorageReport() calls. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
      "commitAuthor": "Surendra Singh Lilhore",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13166: [SPS]: Implement caching mechanism to keep LIVE datanodes to minimize costly getLiveDatanodeStorageReport() calls. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,103 +1,103 @@\n   private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n       HdfsLocatedFileStatus fileInfo,\n-      BlockStoragePolicy existingStoragePolicy,\n-      DatanodeStorageReport[] liveDns) {\n+      BlockStoragePolicy existingStoragePolicy) throws IOException {\n     BlocksMovingAnalysis.Status status \u003d\n         BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n     final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n     final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n     final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n     if (!lastBlkComplete) {\n       // Postpone, currently file is under construction\n       LOG.info(\"File: {} is under construction. So, postpone\"\n           + \" this to the next retry iteration\", fileInfo.getPath());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n           new ArrayList\u003c\u003e());\n     }\n \n     List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n     if (blocks.size() \u003d\u003d 0) {\n       LOG.info(\"File: {} is not having any blocks.\"\n           + \" So, skipping the analysis.\", fileInfo.getPath());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n           new ArrayList\u003c\u003e());\n     }\n     List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n     boolean hasLowRedundancyBlocks \u003d false;\n     int replication \u003d fileInfo.getReplication();\n+    DatanodeMap liveDns \u003d dnCacheMgr.getLiveDatanodeStorageReport(ctxt);\n     for (int i \u003d 0; i \u003c blocks.size(); i++) {\n       LocatedBlock blockInfo \u003d blocks.get(i);\n \n       // Block is considered as low redundancy when the block locations array\n       // length is less than expected replication factor. If any of the block is\n       // low redundant, then hasLowRedundancyBlocks will be marked as true.\n       hasLowRedundancyBlocks |\u003d isLowRedundancyBlock(blockInfo, replication,\n           ecPolicy);\n \n       List\u003cStorageType\u003e expectedStorageTypes;\n       if (blockInfo.isStriped()) {\n         if (ErasureCodingPolicyManager\n             .checkStoragePolicySuitableForECStripedMode(\n                 existingStoragePolicy.getId())) {\n           expectedStorageTypes \u003d existingStoragePolicy\n               .chooseStorageTypes((short) blockInfo.getLocations().length);\n         } else {\n           // Currently we support only limited policies (HOT, COLD, ALLSSD)\n           // for EC striped mode files. SPS will ignore to move the blocks if\n           // the storage policy is not in EC Striped mode supported policies\n           LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n               + \" is not suitable for Striped EC files. \"\n               + \"So, ignoring to move the blocks\");\n           return new BlocksMovingAnalysis(\n               BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n               new ArrayList\u003c\u003e());\n         }\n       } else {\n         expectedStorageTypes \u003d existingStoragePolicy\n             .chooseStorageTypes(fileInfo.getReplication());\n       }\n \n       List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n           Arrays.asList(blockInfo.getStorageTypes()));\n       if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n           existing, true)) {\n         boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n             blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n             liveDns, ecPolicy);\n         if (blocksPaired) {\n           status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n         } else if (status !\u003d\n             BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n           // Check if the previous block was successfully paired. Here the\n           // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n           // blocks of a file found its eligible targets to satisfy the storage\n           // policy.\n           status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n         }\n       }\n     }\n \n     // If there is no block paired and few blocks are low redundant, so marking\n     // the status as FEW_LOW_REDUNDANCY_BLOCKS.\n     if (hasLowRedundancyBlocks\n-        \u0026\u0026 status \u003d\u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED) {\n+        \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n       status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n     }\n     List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n     for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n       // Check for at least one block storage movement has been chosen\n       try {\n         blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n         LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n         assignedBlockIds.add(blkMovingInfo.getBlock());\n         blockCount++;\n       } catch (IOException e) {\n         LOG.warn(\"Exception while scheduling movement task\", e);\n         // failed to move the block.\n         status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n       }\n     }\n     return new BlocksMovingAnalysis(status, assignedBlockIds);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n      HdfsLocatedFileStatus fileInfo,\n      BlockStoragePolicy existingStoragePolicy) throws IOException {\n    BlocksMovingAnalysis.Status status \u003d\n        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n    final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n    final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n    final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n    if (!lastBlkComplete) {\n      // Postpone, currently file is under construction\n      LOG.info(\"File: {} is under construction. So, postpone\"\n          + \" this to the next retry iteration\", fileInfo.getPath());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n          new ArrayList\u003c\u003e());\n    }\n\n    List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n    if (blocks.size() \u003d\u003d 0) {\n      LOG.info(\"File: {} is not having any blocks.\"\n          + \" So, skipping the analysis.\", fileInfo.getPath());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n          new ArrayList\u003c\u003e());\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n    boolean hasLowRedundancyBlocks \u003d false;\n    int replication \u003d fileInfo.getReplication();\n    DatanodeMap liveDns \u003d dnCacheMgr.getLiveDatanodeStorageReport(ctxt);\n    for (int i \u003d 0; i \u003c blocks.size(); i++) {\n      LocatedBlock blockInfo \u003d blocks.get(i);\n\n      // Block is considered as low redundancy when the block locations array\n      // length is less than expected replication factor. If any of the block is\n      // low redundant, then hasLowRedundancyBlocks will be marked as true.\n      hasLowRedundancyBlocks |\u003d isLowRedundancyBlock(blockInfo, replication,\n          ecPolicy);\n\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicy.getId())) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getLocations().length);\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return new BlocksMovingAnalysis(\n              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n              new ArrayList\u003c\u003e());\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(fileInfo.getReplication());\n      }\n\n      List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n          Arrays.asList(blockInfo.getStorageTypes()));\n      if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n            liveDns, ecPolicy);\n        if (blocksPaired) {\n          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n        } else if (status !\u003d\n            BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n          // Check if the previous block was successfully paired. Here the\n          // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n          // blocks of a file found its eligible targets to satisfy the storage\n          // policy.\n          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n        }\n      }\n    }\n\n    // If there is no block paired and few blocks are low redundant, so marking\n    // the status as FEW_LOW_REDUNDANCY_BLOCKS.\n    if (hasLowRedundancyBlocks\n        \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n      status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n    }\n    List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n      // Check for at least one block storage movement has been chosen\n      try {\n        blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n        assignedBlockIds.add(blkMovingInfo.getBlock());\n        blockCount++;\n      } catch (IOException e) {\n        LOG.warn(\"Exception while scheduling movement task\", e);\n        // failed to move the block.\n        status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n      }\n    }\n    return new BlocksMovingAnalysis(status, assignedBlockIds);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
          "extendedDetails": {
            "oldValue": "[fileInfo-HdfsLocatedFileStatus, existingStoragePolicy-BlockStoragePolicy, liveDns-DatanodeStorageReport[]]",
            "newValue": "[fileInfo-HdfsLocatedFileStatus, existingStoragePolicy-BlockStoragePolicy]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-13166: [SPS]: Implement caching mechanism to keep LIVE datanodes to minimize costly getLiveDatanodeStorageReport() calls. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,103 +1,103 @@\n   private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n       HdfsLocatedFileStatus fileInfo,\n-      BlockStoragePolicy existingStoragePolicy,\n-      DatanodeStorageReport[] liveDns) {\n+      BlockStoragePolicy existingStoragePolicy) throws IOException {\n     BlocksMovingAnalysis.Status status \u003d\n         BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n     final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n     final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n     final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n     if (!lastBlkComplete) {\n       // Postpone, currently file is under construction\n       LOG.info(\"File: {} is under construction. So, postpone\"\n           + \" this to the next retry iteration\", fileInfo.getPath());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n           new ArrayList\u003c\u003e());\n     }\n \n     List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n     if (blocks.size() \u003d\u003d 0) {\n       LOG.info(\"File: {} is not having any blocks.\"\n           + \" So, skipping the analysis.\", fileInfo.getPath());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n           new ArrayList\u003c\u003e());\n     }\n     List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n     boolean hasLowRedundancyBlocks \u003d false;\n     int replication \u003d fileInfo.getReplication();\n+    DatanodeMap liveDns \u003d dnCacheMgr.getLiveDatanodeStorageReport(ctxt);\n     for (int i \u003d 0; i \u003c blocks.size(); i++) {\n       LocatedBlock blockInfo \u003d blocks.get(i);\n \n       // Block is considered as low redundancy when the block locations array\n       // length is less than expected replication factor. If any of the block is\n       // low redundant, then hasLowRedundancyBlocks will be marked as true.\n       hasLowRedundancyBlocks |\u003d isLowRedundancyBlock(blockInfo, replication,\n           ecPolicy);\n \n       List\u003cStorageType\u003e expectedStorageTypes;\n       if (blockInfo.isStriped()) {\n         if (ErasureCodingPolicyManager\n             .checkStoragePolicySuitableForECStripedMode(\n                 existingStoragePolicy.getId())) {\n           expectedStorageTypes \u003d existingStoragePolicy\n               .chooseStorageTypes((short) blockInfo.getLocations().length);\n         } else {\n           // Currently we support only limited policies (HOT, COLD, ALLSSD)\n           // for EC striped mode files. SPS will ignore to move the blocks if\n           // the storage policy is not in EC Striped mode supported policies\n           LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n               + \" is not suitable for Striped EC files. \"\n               + \"So, ignoring to move the blocks\");\n           return new BlocksMovingAnalysis(\n               BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n               new ArrayList\u003c\u003e());\n         }\n       } else {\n         expectedStorageTypes \u003d existingStoragePolicy\n             .chooseStorageTypes(fileInfo.getReplication());\n       }\n \n       List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n           Arrays.asList(blockInfo.getStorageTypes()));\n       if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n           existing, true)) {\n         boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n             blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n             liveDns, ecPolicy);\n         if (blocksPaired) {\n           status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n         } else if (status !\u003d\n             BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n           // Check if the previous block was successfully paired. Here the\n           // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n           // blocks of a file found its eligible targets to satisfy the storage\n           // policy.\n           status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n         }\n       }\n     }\n \n     // If there is no block paired and few blocks are low redundant, so marking\n     // the status as FEW_LOW_REDUNDANCY_BLOCKS.\n     if (hasLowRedundancyBlocks\n-        \u0026\u0026 status \u003d\u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED) {\n+        \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n       status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n     }\n     List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n     for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n       // Check for at least one block storage movement has been chosen\n       try {\n         blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n         LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n         assignedBlockIds.add(blkMovingInfo.getBlock());\n         blockCount++;\n       } catch (IOException e) {\n         LOG.warn(\"Exception while scheduling movement task\", e);\n         // failed to move the block.\n         status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n       }\n     }\n     return new BlocksMovingAnalysis(status, assignedBlockIds);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n      HdfsLocatedFileStatus fileInfo,\n      BlockStoragePolicy existingStoragePolicy) throws IOException {\n    BlocksMovingAnalysis.Status status \u003d\n        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n    final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n    final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n    final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n    if (!lastBlkComplete) {\n      // Postpone, currently file is under construction\n      LOG.info(\"File: {} is under construction. So, postpone\"\n          + \" this to the next retry iteration\", fileInfo.getPath());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n          new ArrayList\u003c\u003e());\n    }\n\n    List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n    if (blocks.size() \u003d\u003d 0) {\n      LOG.info(\"File: {} is not having any blocks.\"\n          + \" So, skipping the analysis.\", fileInfo.getPath());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n          new ArrayList\u003c\u003e());\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n    boolean hasLowRedundancyBlocks \u003d false;\n    int replication \u003d fileInfo.getReplication();\n    DatanodeMap liveDns \u003d dnCacheMgr.getLiveDatanodeStorageReport(ctxt);\n    for (int i \u003d 0; i \u003c blocks.size(); i++) {\n      LocatedBlock blockInfo \u003d blocks.get(i);\n\n      // Block is considered as low redundancy when the block locations array\n      // length is less than expected replication factor. If any of the block is\n      // low redundant, then hasLowRedundancyBlocks will be marked as true.\n      hasLowRedundancyBlocks |\u003d isLowRedundancyBlock(blockInfo, replication,\n          ecPolicy);\n\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicy.getId())) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getLocations().length);\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return new BlocksMovingAnalysis(\n              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n              new ArrayList\u003c\u003e());\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(fileInfo.getReplication());\n      }\n\n      List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n          Arrays.asList(blockInfo.getStorageTypes()));\n      if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n            liveDns, ecPolicy);\n        if (blocksPaired) {\n          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n        } else if (status !\u003d\n            BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n          // Check if the previous block was successfully paired. Here the\n          // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n          // blocks of a file found its eligible targets to satisfy the storage\n          // policy.\n          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n        }\n      }\n    }\n\n    // If there is no block paired and few blocks are low redundant, so marking\n    // the status as FEW_LOW_REDUNDANCY_BLOCKS.\n    if (hasLowRedundancyBlocks\n        \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n      status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n    }\n    List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n      // Check for at least one block storage movement has been chosen\n      try {\n        blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n        assignedBlockIds.add(blkMovingInfo.getBlock());\n        blockCount++;\n      } catch (IOException e) {\n        LOG.warn(\"Exception while scheduling movement task\", e);\n        // failed to move the block.\n        status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n      }\n    }\n    return new BlocksMovingAnalysis(status, assignedBlockIds);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13166: [SPS]: Implement caching mechanism to keep LIVE datanodes to minimize costly getLiveDatanodeStorageReport() calls. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "75ccc1396b677777cdc0d4992a4af3911f9f88c2",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,103 +1,103 @@\n   private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n       HdfsLocatedFileStatus fileInfo,\n-      BlockStoragePolicy existingStoragePolicy,\n-      DatanodeStorageReport[] liveDns) {\n+      BlockStoragePolicy existingStoragePolicy) throws IOException {\n     BlocksMovingAnalysis.Status status \u003d\n         BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n     final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n     final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n     final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n     if (!lastBlkComplete) {\n       // Postpone, currently file is under construction\n       LOG.info(\"File: {} is under construction. So, postpone\"\n           + \" this to the next retry iteration\", fileInfo.getPath());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n           new ArrayList\u003c\u003e());\n     }\n \n     List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n     if (blocks.size() \u003d\u003d 0) {\n       LOG.info(\"File: {} is not having any blocks.\"\n           + \" So, skipping the analysis.\", fileInfo.getPath());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n           new ArrayList\u003c\u003e());\n     }\n     List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n     boolean hasLowRedundancyBlocks \u003d false;\n     int replication \u003d fileInfo.getReplication();\n+    DatanodeMap liveDns \u003d dnCacheMgr.getLiveDatanodeStorageReport(ctxt);\n     for (int i \u003d 0; i \u003c blocks.size(); i++) {\n       LocatedBlock blockInfo \u003d blocks.get(i);\n \n       // Block is considered as low redundancy when the block locations array\n       // length is less than expected replication factor. If any of the block is\n       // low redundant, then hasLowRedundancyBlocks will be marked as true.\n       hasLowRedundancyBlocks |\u003d isLowRedundancyBlock(blockInfo, replication,\n           ecPolicy);\n \n       List\u003cStorageType\u003e expectedStorageTypes;\n       if (blockInfo.isStriped()) {\n         if (ErasureCodingPolicyManager\n             .checkStoragePolicySuitableForECStripedMode(\n                 existingStoragePolicy.getId())) {\n           expectedStorageTypes \u003d existingStoragePolicy\n               .chooseStorageTypes((short) blockInfo.getLocations().length);\n         } else {\n           // Currently we support only limited policies (HOT, COLD, ALLSSD)\n           // for EC striped mode files. SPS will ignore to move the blocks if\n           // the storage policy is not in EC Striped mode supported policies\n           LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n               + \" is not suitable for Striped EC files. \"\n               + \"So, ignoring to move the blocks\");\n           return new BlocksMovingAnalysis(\n               BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n               new ArrayList\u003c\u003e());\n         }\n       } else {\n         expectedStorageTypes \u003d existingStoragePolicy\n             .chooseStorageTypes(fileInfo.getReplication());\n       }\n \n       List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n           Arrays.asList(blockInfo.getStorageTypes()));\n       if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n           existing, true)) {\n         boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n             blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n             liveDns, ecPolicy);\n         if (blocksPaired) {\n           status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n         } else if (status !\u003d\n             BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n           // Check if the previous block was successfully paired. Here the\n           // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n           // blocks of a file found its eligible targets to satisfy the storage\n           // policy.\n           status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n         }\n       }\n     }\n \n     // If there is no block paired and few blocks are low redundant, so marking\n     // the status as FEW_LOW_REDUNDANCY_BLOCKS.\n     if (hasLowRedundancyBlocks\n-        \u0026\u0026 status \u003d\u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED) {\n+        \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n       status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n     }\n     List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n     for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n       // Check for at least one block storage movement has been chosen\n       try {\n         blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n         LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n         assignedBlockIds.add(blkMovingInfo.getBlock());\n         blockCount++;\n       } catch (IOException e) {\n         LOG.warn(\"Exception while scheduling movement task\", e);\n         // failed to move the block.\n         status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n       }\n     }\n     return new BlocksMovingAnalysis(status, assignedBlockIds);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n      HdfsLocatedFileStatus fileInfo,\n      BlockStoragePolicy existingStoragePolicy) throws IOException {\n    BlocksMovingAnalysis.Status status \u003d\n        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n    final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n    final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n    final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n    if (!lastBlkComplete) {\n      // Postpone, currently file is under construction\n      LOG.info(\"File: {} is under construction. So, postpone\"\n          + \" this to the next retry iteration\", fileInfo.getPath());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n          new ArrayList\u003c\u003e());\n    }\n\n    List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n    if (blocks.size() \u003d\u003d 0) {\n      LOG.info(\"File: {} is not having any blocks.\"\n          + \" So, skipping the analysis.\", fileInfo.getPath());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n          new ArrayList\u003c\u003e());\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n    boolean hasLowRedundancyBlocks \u003d false;\n    int replication \u003d fileInfo.getReplication();\n    DatanodeMap liveDns \u003d dnCacheMgr.getLiveDatanodeStorageReport(ctxt);\n    for (int i \u003d 0; i \u003c blocks.size(); i++) {\n      LocatedBlock blockInfo \u003d blocks.get(i);\n\n      // Block is considered as low redundancy when the block locations array\n      // length is less than expected replication factor. If any of the block is\n      // low redundant, then hasLowRedundancyBlocks will be marked as true.\n      hasLowRedundancyBlocks |\u003d isLowRedundancyBlock(blockInfo, replication,\n          ecPolicy);\n\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicy.getId())) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getLocations().length);\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return new BlocksMovingAnalysis(\n              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n              new ArrayList\u003c\u003e());\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(fileInfo.getReplication());\n      }\n\n      List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n          Arrays.asList(blockInfo.getStorageTypes()));\n      if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n            liveDns, ecPolicy);\n        if (blocksPaired) {\n          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n        } else if (status !\u003d\n            BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n          // Check if the previous block was successfully paired. Here the\n          // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n          // blocks of a file found its eligible targets to satisfy the storage\n          // policy.\n          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n        }\n      }\n    }\n\n    // If there is no block paired and few blocks are low redundant, so marking\n    // the status as FEW_LOW_REDUNDANCY_BLOCKS.\n    if (hasLowRedundancyBlocks\n        \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n      status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n    }\n    List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n      // Check for at least one block storage movement has been chosen\n      try {\n        blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n        assignedBlockIds.add(blkMovingInfo.getBlock());\n        blockCount++;\n      } catch (IOException e) {\n        LOG.warn(\"Exception while scheduling movement task\", e);\n        // failed to move the block.\n        status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n      }\n    }\n    return new BlocksMovingAnalysis(status, assignedBlockIds);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
          "extendedDetails": {}
        }
      ]
    },
    "8467ec24fb74f30371d5a13e893fc56309ee9372": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-13110: [SPS]: Reduce the number of APIs in NamenodeProtocol used by external satisfier. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "8467ec24fb74f30371d5a13e893fc56309ee9372",
      "commitAuthor": "Rakesh Radhakrishnan",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13110: [SPS]: Reduce the number of APIs in NamenodeProtocol used by external satisfier. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,93 +1,103 @@\n   private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n-      HdfsLocatedFileStatus fileInfo, boolean hasLowRedundancyBlocks,\n+      HdfsLocatedFileStatus fileInfo,\n       BlockStoragePolicy existingStoragePolicy,\n       DatanodeStorageReport[] liveDns) {\n     BlocksMovingAnalysis.Status status \u003d\n         BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n     final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n     final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n     final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n     if (!lastBlkComplete) {\n       // Postpone, currently file is under construction\n       LOG.info(\"File: {} is under construction. So, postpone\"\n           + \" this to the next retry iteration\", fileInfo.getPath());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n           new ArrayList\u003c\u003e());\n     }\n \n     List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n     if (blocks.size() \u003d\u003d 0) {\n       LOG.info(\"File: {} is not having any blocks.\"\n           + \" So, skipping the analysis.\", fileInfo.getPath());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n           new ArrayList\u003c\u003e());\n     }\n     List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n-\n+    boolean hasLowRedundancyBlocks \u003d false;\n+    int replication \u003d fileInfo.getReplication();\n     for (int i \u003d 0; i \u003c blocks.size(); i++) {\n       LocatedBlock blockInfo \u003d blocks.get(i);\n+\n+      // Block is considered as low redundancy when the block locations array\n+      // length is less than expected replication factor. If any of the block is\n+      // low redundant, then hasLowRedundancyBlocks will be marked as true.\n+      hasLowRedundancyBlocks |\u003d isLowRedundancyBlock(blockInfo, replication,\n+          ecPolicy);\n+\n       List\u003cStorageType\u003e expectedStorageTypes;\n       if (blockInfo.isStriped()) {\n         if (ErasureCodingPolicyManager\n             .checkStoragePolicySuitableForECStripedMode(\n                 existingStoragePolicy.getId())) {\n           expectedStorageTypes \u003d existingStoragePolicy\n               .chooseStorageTypes((short) blockInfo.getLocations().length);\n         } else {\n           // Currently we support only limited policies (HOT, COLD, ALLSSD)\n           // for EC striped mode files. SPS will ignore to move the blocks if\n           // the storage policy is not in EC Striped mode supported policies\n           LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n               + \" is not suitable for Striped EC files. \"\n               + \"So, ignoring to move the blocks\");\n           return new BlocksMovingAnalysis(\n               BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n               new ArrayList\u003c\u003e());\n         }\n       } else {\n         expectedStorageTypes \u003d existingStoragePolicy\n             .chooseStorageTypes(fileInfo.getReplication());\n       }\n \n       List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n           Arrays.asList(blockInfo.getStorageTypes()));\n       if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n           existing, true)) {\n         boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n             blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n             liveDns, ecPolicy);\n         if (blocksPaired) {\n           status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n         } else if (status !\u003d\n             BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n           // Check if the previous block was successfully paired. Here the\n           // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n           // blocks of a file found its eligible targets to satisfy the storage\n           // policy.\n           status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n         }\n-      } else if (hasLowRedundancyBlocks\n-          \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n-        // Check if the previous block was successfully paired.\n-        status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n       }\n     }\n \n+    // If there is no block paired and few blocks are low redundant, so marking\n+    // the status as FEW_LOW_REDUNDANCY_BLOCKS.\n+    if (hasLowRedundancyBlocks\n+        \u0026\u0026 status \u003d\u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED) {\n+      status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n+    }\n     List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n     for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n       // Check for at least one block storage movement has been chosen\n       try {\n         blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n         LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n         assignedBlockIds.add(blkMovingInfo.getBlock());\n         blockCount++;\n       } catch (IOException e) {\n         LOG.warn(\"Exception while scheduling movement task\", e);\n         // failed to move the block.\n         status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n       }\n     }\n     return new BlocksMovingAnalysis(status, assignedBlockIds);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n      HdfsLocatedFileStatus fileInfo,\n      BlockStoragePolicy existingStoragePolicy,\n      DatanodeStorageReport[] liveDns) {\n    BlocksMovingAnalysis.Status status \u003d\n        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n    final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n    final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n    final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n    if (!lastBlkComplete) {\n      // Postpone, currently file is under construction\n      LOG.info(\"File: {} is under construction. So, postpone\"\n          + \" this to the next retry iteration\", fileInfo.getPath());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n          new ArrayList\u003c\u003e());\n    }\n\n    List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n    if (blocks.size() \u003d\u003d 0) {\n      LOG.info(\"File: {} is not having any blocks.\"\n          + \" So, skipping the analysis.\", fileInfo.getPath());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n          new ArrayList\u003c\u003e());\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n    boolean hasLowRedundancyBlocks \u003d false;\n    int replication \u003d fileInfo.getReplication();\n    for (int i \u003d 0; i \u003c blocks.size(); i++) {\n      LocatedBlock blockInfo \u003d blocks.get(i);\n\n      // Block is considered as low redundancy when the block locations array\n      // length is less than expected replication factor. If any of the block is\n      // low redundant, then hasLowRedundancyBlocks will be marked as true.\n      hasLowRedundancyBlocks |\u003d isLowRedundancyBlock(blockInfo, replication,\n          ecPolicy);\n\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicy.getId())) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getLocations().length);\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return new BlocksMovingAnalysis(\n              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n              new ArrayList\u003c\u003e());\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(fileInfo.getReplication());\n      }\n\n      List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n          Arrays.asList(blockInfo.getStorageTypes()));\n      if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n            liveDns, ecPolicy);\n        if (blocksPaired) {\n          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n        } else if (status !\u003d\n            BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n          // Check if the previous block was successfully paired. Here the\n          // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n          // blocks of a file found its eligible targets to satisfy the storage\n          // policy.\n          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n        }\n      }\n    }\n\n    // If there is no block paired and few blocks are low redundant, so marking\n    // the status as FEW_LOW_REDUNDANCY_BLOCKS.\n    if (hasLowRedundancyBlocks\n        \u0026\u0026 status \u003d\u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED) {\n      status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n    }\n    List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n      // Check for at least one block storage movement has been chosen\n      try {\n        blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n        assignedBlockIds.add(blkMovingInfo.getBlock());\n        blockCount++;\n      } catch (IOException e) {\n        LOG.warn(\"Exception while scheduling movement task\", e);\n        // failed to move the block.\n        status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n      }\n    }\n    return new BlocksMovingAnalysis(status, assignedBlockIds);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
          "extendedDetails": {
            "oldValue": "[fileInfo-HdfsLocatedFileStatus, hasLowRedundancyBlocks-boolean, existingStoragePolicy-BlockStoragePolicy, liveDns-DatanodeStorageReport[]]",
            "newValue": "[fileInfo-HdfsLocatedFileStatus, existingStoragePolicy-BlockStoragePolicy, liveDns-DatanodeStorageReport[]]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13110: [SPS]: Reduce the number of APIs in NamenodeProtocol used by external satisfier. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,93 +1,103 @@\n   private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n-      HdfsLocatedFileStatus fileInfo, boolean hasLowRedundancyBlocks,\n+      HdfsLocatedFileStatus fileInfo,\n       BlockStoragePolicy existingStoragePolicy,\n       DatanodeStorageReport[] liveDns) {\n     BlocksMovingAnalysis.Status status \u003d\n         BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n     final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n     final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n     final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n     if (!lastBlkComplete) {\n       // Postpone, currently file is under construction\n       LOG.info(\"File: {} is under construction. So, postpone\"\n           + \" this to the next retry iteration\", fileInfo.getPath());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n           new ArrayList\u003c\u003e());\n     }\n \n     List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n     if (blocks.size() \u003d\u003d 0) {\n       LOG.info(\"File: {} is not having any blocks.\"\n           + \" So, skipping the analysis.\", fileInfo.getPath());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n           new ArrayList\u003c\u003e());\n     }\n     List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n-\n+    boolean hasLowRedundancyBlocks \u003d false;\n+    int replication \u003d fileInfo.getReplication();\n     for (int i \u003d 0; i \u003c blocks.size(); i++) {\n       LocatedBlock blockInfo \u003d blocks.get(i);\n+\n+      // Block is considered as low redundancy when the block locations array\n+      // length is less than expected replication factor. If any of the block is\n+      // low redundant, then hasLowRedundancyBlocks will be marked as true.\n+      hasLowRedundancyBlocks |\u003d isLowRedundancyBlock(blockInfo, replication,\n+          ecPolicy);\n+\n       List\u003cStorageType\u003e expectedStorageTypes;\n       if (blockInfo.isStriped()) {\n         if (ErasureCodingPolicyManager\n             .checkStoragePolicySuitableForECStripedMode(\n                 existingStoragePolicy.getId())) {\n           expectedStorageTypes \u003d existingStoragePolicy\n               .chooseStorageTypes((short) blockInfo.getLocations().length);\n         } else {\n           // Currently we support only limited policies (HOT, COLD, ALLSSD)\n           // for EC striped mode files. SPS will ignore to move the blocks if\n           // the storage policy is not in EC Striped mode supported policies\n           LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n               + \" is not suitable for Striped EC files. \"\n               + \"So, ignoring to move the blocks\");\n           return new BlocksMovingAnalysis(\n               BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n               new ArrayList\u003c\u003e());\n         }\n       } else {\n         expectedStorageTypes \u003d existingStoragePolicy\n             .chooseStorageTypes(fileInfo.getReplication());\n       }\n \n       List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n           Arrays.asList(blockInfo.getStorageTypes()));\n       if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n           existing, true)) {\n         boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n             blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n             liveDns, ecPolicy);\n         if (blocksPaired) {\n           status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n         } else if (status !\u003d\n             BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n           // Check if the previous block was successfully paired. Here the\n           // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n           // blocks of a file found its eligible targets to satisfy the storage\n           // policy.\n           status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n         }\n-      } else if (hasLowRedundancyBlocks\n-          \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n-        // Check if the previous block was successfully paired.\n-        status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n       }\n     }\n \n+    // If there is no block paired and few blocks are low redundant, so marking\n+    // the status as FEW_LOW_REDUNDANCY_BLOCKS.\n+    if (hasLowRedundancyBlocks\n+        \u0026\u0026 status \u003d\u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED) {\n+      status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n+    }\n     List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n     for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n       // Check for at least one block storage movement has been chosen\n       try {\n         blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n         LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n         assignedBlockIds.add(blkMovingInfo.getBlock());\n         blockCount++;\n       } catch (IOException e) {\n         LOG.warn(\"Exception while scheduling movement task\", e);\n         // failed to move the block.\n         status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n       }\n     }\n     return new BlocksMovingAnalysis(status, assignedBlockIds);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n      HdfsLocatedFileStatus fileInfo,\n      BlockStoragePolicy existingStoragePolicy,\n      DatanodeStorageReport[] liveDns) {\n    BlocksMovingAnalysis.Status status \u003d\n        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n    final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n    final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n    final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n    if (!lastBlkComplete) {\n      // Postpone, currently file is under construction\n      LOG.info(\"File: {} is under construction. So, postpone\"\n          + \" this to the next retry iteration\", fileInfo.getPath());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n          new ArrayList\u003c\u003e());\n    }\n\n    List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n    if (blocks.size() \u003d\u003d 0) {\n      LOG.info(\"File: {} is not having any blocks.\"\n          + \" So, skipping the analysis.\", fileInfo.getPath());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n          new ArrayList\u003c\u003e());\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n    boolean hasLowRedundancyBlocks \u003d false;\n    int replication \u003d fileInfo.getReplication();\n    for (int i \u003d 0; i \u003c blocks.size(); i++) {\n      LocatedBlock blockInfo \u003d blocks.get(i);\n\n      // Block is considered as low redundancy when the block locations array\n      // length is less than expected replication factor. If any of the block is\n      // low redundant, then hasLowRedundancyBlocks will be marked as true.\n      hasLowRedundancyBlocks |\u003d isLowRedundancyBlock(blockInfo, replication,\n          ecPolicy);\n\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicy.getId())) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getLocations().length);\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return new BlocksMovingAnalysis(\n              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n              new ArrayList\u003c\u003e());\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(fileInfo.getReplication());\n      }\n\n      List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n          Arrays.asList(blockInfo.getStorageTypes()));\n      if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n            liveDns, ecPolicy);\n        if (blocksPaired) {\n          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n        } else if (status !\u003d\n            BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n          // Check if the previous block was successfully paired. Here the\n          // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n          // blocks of a file found its eligible targets to satisfy the storage\n          // policy.\n          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n        }\n      }\n    }\n\n    // If there is no block paired and few blocks are low redundant, so marking\n    // the status as FEW_LOW_REDUNDANCY_BLOCKS.\n    if (hasLowRedundancyBlocks\n        \u0026\u0026 status \u003d\u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED) {\n      status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n    }\n    List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n      // Check for at least one block storage movement has been chosen\n      try {\n        blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n        assignedBlockIds.add(blkMovingInfo.getBlock());\n        blockCount++;\n      } catch (IOException e) {\n        LOG.warn(\"Exception while scheduling movement task\", e);\n        // failed to move the block.\n        status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n      }\n    }\n    return new BlocksMovingAnalysis(status, assignedBlockIds);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
          "extendedDetails": {}
        }
      ]
    },
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13097: [SPS]: Fix the branch review comments(Part1). Contributed by Surendra Singh.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "d3de4fb2a084cbadab8ef91f11aa7732d3b0f308",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,93 +1,93 @@\n   private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n       HdfsLocatedFileStatus fileInfo, boolean hasLowRedundancyBlocks,\n       BlockStoragePolicy existingStoragePolicy,\n       DatanodeStorageReport[] liveDns) {\n     BlocksMovingAnalysis.Status status \u003d\n         BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n     final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n     final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n     final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n     if (!lastBlkComplete) {\n       // Postpone, currently file is under construction\n       LOG.info(\"File: {} is under construction. So, postpone\"\n           + \" this to the next retry iteration\", fileInfo.getPath());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n           new ArrayList\u003c\u003e());\n     }\n \n     List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n     if (blocks.size() \u003d\u003d 0) {\n       LOG.info(\"File: {} is not having any blocks.\"\n           + \" So, skipping the analysis.\", fileInfo.getPath());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n           new ArrayList\u003c\u003e());\n     }\n     List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n \n     for (int i \u003d 0; i \u003c blocks.size(); i++) {\n       LocatedBlock blockInfo \u003d blocks.get(i);\n       List\u003cStorageType\u003e expectedStorageTypes;\n       if (blockInfo.isStriped()) {\n         if (ErasureCodingPolicyManager\n             .checkStoragePolicySuitableForECStripedMode(\n                 existingStoragePolicy.getId())) {\n           expectedStorageTypes \u003d existingStoragePolicy\n               .chooseStorageTypes((short) blockInfo.getLocations().length);\n         } else {\n           // Currently we support only limited policies (HOT, COLD, ALLSSD)\n           // for EC striped mode files. SPS will ignore to move the blocks if\n           // the storage policy is not in EC Striped mode supported policies\n           LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n               + \" is not suitable for Striped EC files. \"\n               + \"So, ignoring to move the blocks\");\n           return new BlocksMovingAnalysis(\n               BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n               new ArrayList\u003c\u003e());\n         }\n       } else {\n         expectedStorageTypes \u003d existingStoragePolicy\n             .chooseStorageTypes(fileInfo.getReplication());\n       }\n \n       List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n           Arrays.asList(blockInfo.getStorageTypes()));\n-      if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n+      if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n           existing, true)) {\n         boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n             blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n             liveDns, ecPolicy);\n         if (blocksPaired) {\n           status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n         } else if (status !\u003d\n             BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n           // Check if the previous block was successfully paired. Here the\n           // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n           // blocks of a file found its eligible targets to satisfy the storage\n           // policy.\n           status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n         }\n       } else if (hasLowRedundancyBlocks\n           \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n         // Check if the previous block was successfully paired.\n         status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n       }\n     }\n \n     List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n     for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n       // Check for at least one block storage movement has been chosen\n       try {\n         blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n         LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n         assignedBlockIds.add(blkMovingInfo.getBlock());\n         blockCount++;\n       } catch (IOException e) {\n         LOG.warn(\"Exception while scheduling movement task\", e);\n         // failed to move the block.\n         status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n       }\n     }\n     return new BlocksMovingAnalysis(status, assignedBlockIds);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n      HdfsLocatedFileStatus fileInfo, boolean hasLowRedundancyBlocks,\n      BlockStoragePolicy existingStoragePolicy,\n      DatanodeStorageReport[] liveDns) {\n    BlocksMovingAnalysis.Status status \u003d\n        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n    final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n    final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n    final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n    if (!lastBlkComplete) {\n      // Postpone, currently file is under construction\n      LOG.info(\"File: {} is under construction. So, postpone\"\n          + \" this to the next retry iteration\", fileInfo.getPath());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n          new ArrayList\u003c\u003e());\n    }\n\n    List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n    if (blocks.size() \u003d\u003d 0) {\n      LOG.info(\"File: {} is not having any blocks.\"\n          + \" So, skipping the analysis.\", fileInfo.getPath());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n          new ArrayList\u003c\u003e());\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n\n    for (int i \u003d 0; i \u003c blocks.size(); i++) {\n      LocatedBlock blockInfo \u003d blocks.get(i);\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicy.getId())) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getLocations().length);\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return new BlocksMovingAnalysis(\n              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n              new ArrayList\u003c\u003e());\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(fileInfo.getReplication());\n      }\n\n      List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n          Arrays.asList(blockInfo.getStorageTypes()));\n      if (!removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n            liveDns, ecPolicy);\n        if (blocksPaired) {\n          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n        } else if (status !\u003d\n            BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n          // Check if the previous block was successfully paired. Here the\n          // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n          // blocks of a file found its eligible targets to satisfy the storage\n          // policy.\n          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n        }\n      } else if (hasLowRedundancyBlocks\n          \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n        // Check if the previous block was successfully paired.\n        status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n      }\n    }\n\n    List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n      // Check for at least one block storage movement has been chosen\n      try {\n        blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n        assignedBlockIds.add(blkMovingInfo.getBlock());\n        blockCount++;\n      } catch (IOException e) {\n        LOG.warn(\"Exception while scheduling movement task\", e);\n        // failed to move the block.\n        status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n      }\n    }\n    return new BlocksMovingAnalysis(status, assignedBlockIds);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "5845c36c16c423107183287cce3be9357dad7564": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13050: [SPS]: Create start/stop script to start external SPS process. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "5845c36c16c423107183287cce3be9357dad7564",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "99594b48b8e040ab5a0939d7c3dbcfb34400e6fc",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,93 @@\n   private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n       HdfsLocatedFileStatus fileInfo, boolean hasLowRedundancyBlocks,\n       BlockStoragePolicy existingStoragePolicy,\n       DatanodeStorageReport[] liveDns) {\n     BlocksMovingAnalysis.Status status \u003d\n         BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n     final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n     final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n     final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n     if (!lastBlkComplete) {\n       // Postpone, currently file is under construction\n-      // So, should we add back? or leave it to user\n-      LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n-          + \" this to the next retry iteration\", fileInfo.getFileId());\n+      LOG.info(\"File: {} is under construction. So, postpone\"\n+          + \" this to the next retry iteration\", fileInfo.getPath());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n           new ArrayList\u003c\u003e());\n     }\n \n     List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n     if (blocks.size() \u003d\u003d 0) {\n-      LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n-          + \" So, skipping the analysis.\", fileInfo.getFileId());\n+      LOG.info(\"File: {} is not having any blocks.\"\n+          + \" So, skipping the analysis.\", fileInfo.getPath());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n           new ArrayList\u003c\u003e());\n     }\n     List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n \n     for (int i \u003d 0; i \u003c blocks.size(); i++) {\n       LocatedBlock blockInfo \u003d blocks.get(i);\n       List\u003cStorageType\u003e expectedStorageTypes;\n       if (blockInfo.isStriped()) {\n         if (ErasureCodingPolicyManager\n             .checkStoragePolicySuitableForECStripedMode(\n                 existingStoragePolicy.getId())) {\n           expectedStorageTypes \u003d existingStoragePolicy\n               .chooseStorageTypes((short) blockInfo.getLocations().length);\n         } else {\n           // Currently we support only limited policies (HOT, COLD, ALLSSD)\n           // for EC striped mode files. SPS will ignore to move the blocks if\n           // the storage policy is not in EC Striped mode supported policies\n           LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n               + \" is not suitable for Striped EC files. \"\n               + \"So, ignoring to move the blocks\");\n           return new BlocksMovingAnalysis(\n               BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n               new ArrayList\u003c\u003e());\n         }\n       } else {\n         expectedStorageTypes \u003d existingStoragePolicy\n             .chooseStorageTypes(fileInfo.getReplication());\n       }\n \n       List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n           Arrays.asList(blockInfo.getStorageTypes()));\n       if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n           existing, true)) {\n         boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n             blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n             liveDns, ecPolicy);\n         if (blocksPaired) {\n           status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n         } else\n           if (status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n           // Check if the previous block was successfully paired. Here the\n           // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n           // blocks of a file found its eligible targets to satisfy the storage\n           // policy.\n           status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n         }\n       } else if (hasLowRedundancyBlocks\n           \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n         // Check if the previous block was successfully paired.\n         status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n       }\n     }\n \n     List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n     for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n       // Check for at least one block storage movement has been chosen\n       try {\n         blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n         LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n         assignedBlockIds.add(blkMovingInfo.getBlock());\n         blockCount++;\n       } catch (IOException e) {\n         LOG.warn(\"Exception while scheduling movement task\", e);\n         // failed to move the block.\n         status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n       }\n     }\n     return new BlocksMovingAnalysis(status, assignedBlockIds);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n      HdfsLocatedFileStatus fileInfo, boolean hasLowRedundancyBlocks,\n      BlockStoragePolicy existingStoragePolicy,\n      DatanodeStorageReport[] liveDns) {\n    BlocksMovingAnalysis.Status status \u003d\n        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n    final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n    final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n    final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n    if (!lastBlkComplete) {\n      // Postpone, currently file is under construction\n      LOG.info(\"File: {} is under construction. So, postpone\"\n          + \" this to the next retry iteration\", fileInfo.getPath());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n          new ArrayList\u003c\u003e());\n    }\n\n    List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n    if (blocks.size() \u003d\u003d 0) {\n      LOG.info(\"File: {} is not having any blocks.\"\n          + \" So, skipping the analysis.\", fileInfo.getPath());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n          new ArrayList\u003c\u003e());\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n\n    for (int i \u003d 0; i \u003c blocks.size(); i++) {\n      LocatedBlock blockInfo \u003d blocks.get(i);\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicy.getId())) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getLocations().length);\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return new BlocksMovingAnalysis(\n              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n              new ArrayList\u003c\u003e());\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(fileInfo.getReplication());\n      }\n\n      List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n          Arrays.asList(blockInfo.getStorageTypes()));\n      if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n            liveDns, ecPolicy);\n        if (blocksPaired) {\n          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n        } else\n          if (status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n          // Check if the previous block was successfully paired. Here the\n          // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n          // blocks of a file found its eligible targets to satisfy the storage\n          // policy.\n          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n        }\n      } else if (hasLowRedundancyBlocks\n          \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n        // Check if the previous block was successfully paired.\n        status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n      }\n    }\n\n    List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n      // Check for at least one block storage movement has been chosen\n      try {\n        blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n        assignedBlockIds.add(blkMovingInfo.getBlock());\n        blockCount++;\n      } catch (IOException e) {\n        LOG.warn(\"Exception while scheduling movement task\", e);\n        // failed to move the block.\n        status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n      }\n    }\n    return new BlocksMovingAnalysis(status, assignedBlockIds);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13033: [SPS]: Implement a mechanism to do file block movements for external SPS. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "3159b39cf8ef704835325263154fb1a1cecc109d",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,92 +1,94 @@\n   private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n       HdfsLocatedFileStatus fileInfo, boolean hasLowRedundancyBlocks,\n       BlockStoragePolicy existingStoragePolicy,\n       DatanodeStorageReport[] liveDns) {\n     BlocksMovingAnalysis.Status status \u003d\n         BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n     final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n     final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n     final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n     if (!lastBlkComplete) {\n       // Postpone, currently file is under construction\n       // So, should we add back? or leave it to user\n       LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n           + \" this to the next retry iteration\", fileInfo.getFileId());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n           new ArrayList\u003c\u003e());\n     }\n \n     List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n     if (blocks.size() \u003d\u003d 0) {\n       LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n           + \" So, skipping the analysis.\", fileInfo.getFileId());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n           new ArrayList\u003c\u003e());\n     }\n     List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n \n     for (int i \u003d 0; i \u003c blocks.size(); i++) {\n       LocatedBlock blockInfo \u003d blocks.get(i);\n       List\u003cStorageType\u003e expectedStorageTypes;\n       if (blockInfo.isStriped()) {\n         if (ErasureCodingPolicyManager\n             .checkStoragePolicySuitableForECStripedMode(\n                 existingStoragePolicy.getId())) {\n           expectedStorageTypes \u003d existingStoragePolicy\n               .chooseStorageTypes((short) blockInfo.getLocations().length);\n         } else {\n           // Currently we support only limited policies (HOT, COLD, ALLSSD)\n           // for EC striped mode files. SPS will ignore to move the blocks if\n           // the storage policy is not in EC Striped mode supported policies\n           LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n               + \" is not suitable for Striped EC files. \"\n               + \"So, ignoring to move the blocks\");\n           return new BlocksMovingAnalysis(\n               BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n               new ArrayList\u003c\u003e());\n         }\n       } else {\n         expectedStorageTypes \u003d existingStoragePolicy\n             .chooseStorageTypes(fileInfo.getReplication());\n       }\n \n       List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n           Arrays.asList(blockInfo.getStorageTypes()));\n       if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n           existing, true)) {\n         boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n             blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n             liveDns, ecPolicy);\n         if (blocksPaired) {\n           status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n-        } else {\n-          // none of the blocks found its eligible targets for satisfying the\n-          // storage policy.\n+        } else\n+          if (status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n+          // Check if the previous block was successfully paired. Here the\n+          // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n+          // blocks of a file found its eligible targets to satisfy the storage\n+          // policy.\n           status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n         }\n-      } else {\n-        if (hasLowRedundancyBlocks) {\n-          status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n-        }\n+      } else if (hasLowRedundancyBlocks\n+          \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n+        // Check if the previous block was successfully paired.\n+        status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n       }\n     }\n \n     List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n     for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n       // Check for at least one block storage movement has been chosen\n       try {\n-        blockMoveTaskHandler.submitMoveTask(blkMovingInfo,\n-            storageMovementsMonitor);\n+        blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n         LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n         assignedBlockIds.add(blkMovingInfo.getBlock());\n         blockCount++;\n       } catch (IOException e) {\n         LOG.warn(\"Exception while scheduling movement task\", e);\n         // failed to move the block.\n         status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n       }\n     }\n     return new BlocksMovingAnalysis(status, assignedBlockIds);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n      HdfsLocatedFileStatus fileInfo, boolean hasLowRedundancyBlocks,\n      BlockStoragePolicy existingStoragePolicy,\n      DatanodeStorageReport[] liveDns) {\n    BlocksMovingAnalysis.Status status \u003d\n        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n    final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n    final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n    final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n    if (!lastBlkComplete) {\n      // Postpone, currently file is under construction\n      // So, should we add back? or leave it to user\n      LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n          + \" this to the next retry iteration\", fileInfo.getFileId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n          new ArrayList\u003c\u003e());\n    }\n\n    List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n    if (blocks.size() \u003d\u003d 0) {\n      LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n          + \" So, skipping the analysis.\", fileInfo.getFileId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n          new ArrayList\u003c\u003e());\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n\n    for (int i \u003d 0; i \u003c blocks.size(); i++) {\n      LocatedBlock blockInfo \u003d blocks.get(i);\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicy.getId())) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getLocations().length);\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return new BlocksMovingAnalysis(\n              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n              new ArrayList\u003c\u003e());\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(fileInfo.getReplication());\n      }\n\n      List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n          Arrays.asList(blockInfo.getStorageTypes()));\n      if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n            liveDns, ecPolicy);\n        if (blocksPaired) {\n          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n        } else\n          if (status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n          // Check if the previous block was successfully paired. Here the\n          // status will set to NO_BLOCKS_TARGETS_PAIRED only when none of the\n          // blocks of a file found its eligible targets to satisfy the storage\n          // policy.\n          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n        }\n      } else if (hasLowRedundancyBlocks\n          \u0026\u0026 status !\u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED) {\n        // Check if the previous block was successfully paired.\n        status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n      }\n    }\n\n    List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n      // Check for at least one block storage movement has been chosen\n      try {\n        blockMoveTaskHandler.submitMoveTask(blkMovingInfo);\n        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n        assignedBlockIds.add(blkMovingInfo.getBlock());\n        blockCount++;\n      } catch (IOException e) {\n        LOG.warn(\"Exception while scheduling movement task\", e);\n        // failed to move the block.\n        status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n      }\n    }\n    return new BlocksMovingAnalysis(status, assignedBlockIds);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12911. [SPS]: Modularize the SPS code and expose necessary interfaces for external/internal implementations. Contributed by Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,91 +1,92 @@\n   private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n       HdfsLocatedFileStatus fileInfo, boolean hasLowRedundancyBlocks,\n       BlockStoragePolicy existingStoragePolicy,\n       DatanodeStorageReport[] liveDns) {\n     BlocksMovingAnalysis.Status status \u003d\n         BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n     final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n     final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n     final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n     if (!lastBlkComplete) {\n       // Postpone, currently file is under construction\n       // So, should we add back? or leave it to user\n       LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n           + \" this to the next retry iteration\", fileInfo.getFileId());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n           new ArrayList\u003c\u003e());\n     }\n \n     List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n     if (blocks.size() \u003d\u003d 0) {\n       LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n           + \" So, skipping the analysis.\", fileInfo.getFileId());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n           new ArrayList\u003c\u003e());\n     }\n     List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n \n     for (int i \u003d 0; i \u003c blocks.size(); i++) {\n       LocatedBlock blockInfo \u003d blocks.get(i);\n       List\u003cStorageType\u003e expectedStorageTypes;\n       if (blockInfo.isStriped()) {\n         if (ErasureCodingPolicyManager\n             .checkStoragePolicySuitableForECStripedMode(\n                 existingStoragePolicy.getId())) {\n           expectedStorageTypes \u003d existingStoragePolicy\n               .chooseStorageTypes((short) blockInfo.getLocations().length);\n         } else {\n           // Currently we support only limited policies (HOT, COLD, ALLSSD)\n           // for EC striped mode files. SPS will ignore to move the blocks if\n           // the storage policy is not in EC Striped mode supported policies\n           LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n               + \" is not suitable for Striped EC files. \"\n               + \"So, ignoring to move the blocks\");\n           return new BlocksMovingAnalysis(\n               BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n               new ArrayList\u003c\u003e());\n         }\n       } else {\n         expectedStorageTypes \u003d existingStoragePolicy\n             .chooseStorageTypes(fileInfo.getReplication());\n       }\n \n       List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n           Arrays.asList(blockInfo.getStorageTypes()));\n       if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n           existing, true)) {\n         boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n             blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n             liveDns, ecPolicy);\n         if (blocksPaired) {\n           status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n         } else {\n           // none of the blocks found its eligible targets for satisfying the\n           // storage policy.\n           status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n         }\n       } else {\n         if (hasLowRedundancyBlocks) {\n           status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n         }\n       }\n     }\n \n     List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n     for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n       // Check for at least one block storage movement has been chosen\n       try {\n-        ctxt.assignBlockMoveTaskToTargetNode(blkMovingInfo);\n+        blockMoveTaskHandler.submitMoveTask(blkMovingInfo,\n+            storageMovementsMonitor);\n         LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n         assignedBlockIds.add(blkMovingInfo.getBlock());\n         blockCount++;\n       } catch (IOException e) {\n         LOG.warn(\"Exception while scheduling movement task\", e);\n         // failed to move the block.\n         status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n       }\n     }\n     return new BlocksMovingAnalysis(status, assignedBlockIds);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n      HdfsLocatedFileStatus fileInfo, boolean hasLowRedundancyBlocks,\n      BlockStoragePolicy existingStoragePolicy,\n      DatanodeStorageReport[] liveDns) {\n    BlocksMovingAnalysis.Status status \u003d\n        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n    final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n    final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n    final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n    if (!lastBlkComplete) {\n      // Postpone, currently file is under construction\n      // So, should we add back? or leave it to user\n      LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n          + \" this to the next retry iteration\", fileInfo.getFileId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n          new ArrayList\u003c\u003e());\n    }\n\n    List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n    if (blocks.size() \u003d\u003d 0) {\n      LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n          + \" So, skipping the analysis.\", fileInfo.getFileId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n          new ArrayList\u003c\u003e());\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n\n    for (int i \u003d 0; i \u003c blocks.size(); i++) {\n      LocatedBlock blockInfo \u003d blocks.get(i);\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicy.getId())) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getLocations().length);\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return new BlocksMovingAnalysis(\n              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n              new ArrayList\u003c\u003e());\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(fileInfo.getReplication());\n      }\n\n      List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n          Arrays.asList(blockInfo.getStorageTypes()));\n      if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n            liveDns, ecPolicy);\n        if (blocksPaired) {\n          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n        } else {\n          // none of the blocks found its eligible targets for satisfying the\n          // storage policy.\n          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n        }\n      } else {\n        if (hasLowRedundancyBlocks) {\n          status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n        }\n      }\n    }\n\n    List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n      // Check for at least one block storage movement has been chosen\n      try {\n        blockMoveTaskHandler.submitMoveTask(blkMovingInfo,\n            storageMovementsMonitor);\n        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n        assignedBlockIds.add(blkMovingInfo.getBlock());\n        blockCount++;\n      } catch (IOException e) {\n        LOG.warn(\"Exception while scheduling movement task\", e);\n        // failed to move the block.\n        status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n      }\n    }\n    return new BlocksMovingAnalysis(status, assignedBlockIds);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-12982 : [SPS]: Reduce the locking and cleanup the Namesystem access. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
      "commitAuthor": "Surendra Singh Lilhore",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-12982 : [SPS]: Reduce the locking and cleanup the Namesystem access. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "78420719eb1f138c6f10558befb7bc8ebcc28a54",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,93 +1,91 @@\n   private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n-      BlockCollection blockCollection) {\n+      HdfsLocatedFileStatus fileInfo, boolean hasLowRedundancyBlocks,\n+      BlockStoragePolicy existingStoragePolicy,\n+      DatanodeStorageReport[] liveDns) {\n     BlocksMovingAnalysis.Status status \u003d\n         BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n-    byte existingStoragePolicyID \u003d blockCollection.getStoragePolicyID();\n-    BlockStoragePolicy existingStoragePolicy \u003d\n-        blockManager.getStoragePolicy(existingStoragePolicyID);\n-    if (!blockCollection.getLastBlock().isComplete()) {\n+    final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n+    final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n+    final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n+    if (!lastBlkComplete) {\n       // Postpone, currently file is under construction\n       // So, should we add back? or leave it to user\n       LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n-          + \" this to the next retry iteration\", blockCollection.getId());\n+          + \" this to the next retry iteration\", fileInfo.getFileId());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n           new ArrayList\u003c\u003e());\n     }\n \n-    BlockInfo[] blocks \u003d blockCollection.getBlocks();\n-    if (blocks.length \u003d\u003d 0) {\n+    List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n+    if (blocks.size() \u003d\u003d 0) {\n       LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n-          + \" So, skipping the analysis.\", blockCollection.getId());\n+          + \" So, skipping the analysis.\", fileInfo.getFileId());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n           new ArrayList\u003c\u003e());\n     }\n     List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n \n-    for (int i \u003d 0; i \u003c blocks.length; i++) {\n-      BlockInfo blockInfo \u003d blocks[i];\n+    for (int i \u003d 0; i \u003c blocks.size(); i++) {\n+      LocatedBlock blockInfo \u003d blocks.get(i);\n       List\u003cStorageType\u003e expectedStorageTypes;\n       if (blockInfo.isStriped()) {\n         if (ErasureCodingPolicyManager\n             .checkStoragePolicySuitableForECStripedMode(\n-                existingStoragePolicyID)) {\n+                existingStoragePolicy.getId())) {\n           expectedStorageTypes \u003d existingStoragePolicy\n-              .chooseStorageTypes((short) blockInfo.getCapacity());\n+              .chooseStorageTypes((short) blockInfo.getLocations().length);\n         } else {\n           // Currently we support only limited policies (HOT, COLD, ALLSSD)\n           // for EC striped mode files. SPS will ignore to move the blocks if\n           // the storage policy is not in EC Striped mode supported policies\n           LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n               + \" is not suitable for Striped EC files. \"\n               + \"So, ignoring to move the blocks\");\n           return new BlocksMovingAnalysis(\n               BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n               new ArrayList\u003c\u003e());\n         }\n       } else {\n         expectedStorageTypes \u003d existingStoragePolicy\n-            .chooseStorageTypes(blockInfo.getReplication());\n+            .chooseStorageTypes(fileInfo.getReplication());\n       }\n \n-      DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n-      StorageType[] storageTypes \u003d new StorageType[storages.length];\n-      for (int j \u003d 0; j \u003c storages.length; j++) {\n-        DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n-        StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n-        storageTypes[j] \u003d storageType;\n-      }\n-      List\u003cStorageType\u003e existing \u003d\n-          new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n+      List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n+          Arrays.asList(blockInfo.getStorageTypes()));\n       if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n           existing, true)) {\n         boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n-            blockInfo, expectedStorageTypes, existing, storages);\n+            blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n+            liveDns, ecPolicy);\n         if (blocksPaired) {\n           status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n         } else {\n           // none of the blocks found its eligible targets for satisfying the\n           // storage policy.\n           status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n         }\n       } else {\n-        if (blockManager.hasLowRedundancyBlocks(blockCollection)) {\n+        if (hasLowRedundancyBlocks) {\n           status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n         }\n       }\n     }\n \n     List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n     for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n       // Check for at least one block storage movement has been chosen\n-      if (blkMovingInfo.getTarget() !\u003d null) {\n-        // assign block storage movement task to the target node\n-        ((DatanodeDescriptor) blkMovingInfo.getTarget())\n-            .addBlocksToMoveStorage(blkMovingInfo);\n+      try {\n+        ctxt.assignBlockMoveTaskToTargetNode(blkMovingInfo);\n         LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n         assignedBlockIds.add(blkMovingInfo.getBlock());\n         blockCount++;\n+      } catch (IOException e) {\n+        LOG.warn(\"Exception while scheduling movement task\", e);\n+        // failed to move the block.\n+        status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n       }\n     }\n     return new BlocksMovingAnalysis(status, assignedBlockIds);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n      HdfsLocatedFileStatus fileInfo, boolean hasLowRedundancyBlocks,\n      BlockStoragePolicy existingStoragePolicy,\n      DatanodeStorageReport[] liveDns) {\n    BlocksMovingAnalysis.Status status \u003d\n        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n    final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n    final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n    final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n    if (!lastBlkComplete) {\n      // Postpone, currently file is under construction\n      // So, should we add back? or leave it to user\n      LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n          + \" this to the next retry iteration\", fileInfo.getFileId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n          new ArrayList\u003c\u003e());\n    }\n\n    List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n    if (blocks.size() \u003d\u003d 0) {\n      LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n          + \" So, skipping the analysis.\", fileInfo.getFileId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n          new ArrayList\u003c\u003e());\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n\n    for (int i \u003d 0; i \u003c blocks.size(); i++) {\n      LocatedBlock blockInfo \u003d blocks.get(i);\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicy.getId())) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getLocations().length);\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return new BlocksMovingAnalysis(\n              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n              new ArrayList\u003c\u003e());\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(fileInfo.getReplication());\n      }\n\n      List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n          Arrays.asList(blockInfo.getStorageTypes()));\n      if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n            liveDns, ecPolicy);\n        if (blocksPaired) {\n          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n        } else {\n          // none of the blocks found its eligible targets for satisfying the\n          // storage policy.\n          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n        }\n      } else {\n        if (hasLowRedundancyBlocks) {\n          status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n        }\n      }\n    }\n\n    List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n      // Check for at least one block storage movement has been chosen\n      try {\n        ctxt.assignBlockMoveTaskToTargetNode(blkMovingInfo);\n        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n        assignedBlockIds.add(blkMovingInfo.getBlock());\n        blockCount++;\n      } catch (IOException e) {\n        LOG.warn(\"Exception while scheduling movement task\", e);\n        // failed to move the block.\n        status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n      }\n    }\n    return new BlocksMovingAnalysis(status, assignedBlockIds);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
          "extendedDetails": {
            "oldValue": "[blockCollection-BlockCollection]",
            "newValue": "[fileInfo-HdfsLocatedFileStatus, hasLowRedundancyBlocks-boolean, existingStoragePolicy-BlockStoragePolicy, liveDns-DatanodeStorageReport[]]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-12982 : [SPS]: Reduce the locking and cleanup the Namesystem access. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "78420719eb1f138c6f10558befb7bc8ebcc28a54",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,93 +1,91 @@\n   private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n-      BlockCollection blockCollection) {\n+      HdfsLocatedFileStatus fileInfo, boolean hasLowRedundancyBlocks,\n+      BlockStoragePolicy existingStoragePolicy,\n+      DatanodeStorageReport[] liveDns) {\n     BlocksMovingAnalysis.Status status \u003d\n         BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n-    byte existingStoragePolicyID \u003d blockCollection.getStoragePolicyID();\n-    BlockStoragePolicy existingStoragePolicy \u003d\n-        blockManager.getStoragePolicy(existingStoragePolicyID);\n-    if (!blockCollection.getLastBlock().isComplete()) {\n+    final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n+    final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n+    final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n+    if (!lastBlkComplete) {\n       // Postpone, currently file is under construction\n       // So, should we add back? or leave it to user\n       LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n-          + \" this to the next retry iteration\", blockCollection.getId());\n+          + \" this to the next retry iteration\", fileInfo.getFileId());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n           new ArrayList\u003c\u003e());\n     }\n \n-    BlockInfo[] blocks \u003d blockCollection.getBlocks();\n-    if (blocks.length \u003d\u003d 0) {\n+    List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n+    if (blocks.size() \u003d\u003d 0) {\n       LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n-          + \" So, skipping the analysis.\", blockCollection.getId());\n+          + \" So, skipping the analysis.\", fileInfo.getFileId());\n       return new BlocksMovingAnalysis(\n           BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n           new ArrayList\u003c\u003e());\n     }\n     List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n \n-    for (int i \u003d 0; i \u003c blocks.length; i++) {\n-      BlockInfo blockInfo \u003d blocks[i];\n+    for (int i \u003d 0; i \u003c blocks.size(); i++) {\n+      LocatedBlock blockInfo \u003d blocks.get(i);\n       List\u003cStorageType\u003e expectedStorageTypes;\n       if (blockInfo.isStriped()) {\n         if (ErasureCodingPolicyManager\n             .checkStoragePolicySuitableForECStripedMode(\n-                existingStoragePolicyID)) {\n+                existingStoragePolicy.getId())) {\n           expectedStorageTypes \u003d existingStoragePolicy\n-              .chooseStorageTypes((short) blockInfo.getCapacity());\n+              .chooseStorageTypes((short) blockInfo.getLocations().length);\n         } else {\n           // Currently we support only limited policies (HOT, COLD, ALLSSD)\n           // for EC striped mode files. SPS will ignore to move the blocks if\n           // the storage policy is not in EC Striped mode supported policies\n           LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n               + \" is not suitable for Striped EC files. \"\n               + \"So, ignoring to move the blocks\");\n           return new BlocksMovingAnalysis(\n               BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n               new ArrayList\u003c\u003e());\n         }\n       } else {\n         expectedStorageTypes \u003d existingStoragePolicy\n-            .chooseStorageTypes(blockInfo.getReplication());\n+            .chooseStorageTypes(fileInfo.getReplication());\n       }\n \n-      DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n-      StorageType[] storageTypes \u003d new StorageType[storages.length];\n-      for (int j \u003d 0; j \u003c storages.length; j++) {\n-        DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n-        StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n-        storageTypes[j] \u003d storageType;\n-      }\n-      List\u003cStorageType\u003e existing \u003d\n-          new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n+      List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n+          Arrays.asList(blockInfo.getStorageTypes()));\n       if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n           existing, true)) {\n         boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n-            blockInfo, expectedStorageTypes, existing, storages);\n+            blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n+            liveDns, ecPolicy);\n         if (blocksPaired) {\n           status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n         } else {\n           // none of the blocks found its eligible targets for satisfying the\n           // storage policy.\n           status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n         }\n       } else {\n-        if (blockManager.hasLowRedundancyBlocks(blockCollection)) {\n+        if (hasLowRedundancyBlocks) {\n           status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n         }\n       }\n     }\n \n     List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n     for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n       // Check for at least one block storage movement has been chosen\n-      if (blkMovingInfo.getTarget() !\u003d null) {\n-        // assign block storage movement task to the target node\n-        ((DatanodeDescriptor) blkMovingInfo.getTarget())\n-            .addBlocksToMoveStorage(blkMovingInfo);\n+      try {\n+        ctxt.assignBlockMoveTaskToTargetNode(blkMovingInfo);\n         LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n         assignedBlockIds.add(blkMovingInfo.getBlock());\n         blockCount++;\n+      } catch (IOException e) {\n+        LOG.warn(\"Exception while scheduling movement task\", e);\n+        // failed to move the block.\n+        status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n       }\n     }\n     return new BlocksMovingAnalysis(status, assignedBlockIds);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n      HdfsLocatedFileStatus fileInfo, boolean hasLowRedundancyBlocks,\n      BlockStoragePolicy existingStoragePolicy,\n      DatanodeStorageReport[] liveDns) {\n    BlocksMovingAnalysis.Status status \u003d\n        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n    final ErasureCodingPolicy ecPolicy \u003d fileInfo.getErasureCodingPolicy();\n    final LocatedBlocks locatedBlocks \u003d fileInfo.getLocatedBlocks();\n    final boolean lastBlkComplete \u003d locatedBlocks.isLastBlockComplete();\n    if (!lastBlkComplete) {\n      // Postpone, currently file is under construction\n      // So, should we add back? or leave it to user\n      LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n          + \" this to the next retry iteration\", fileInfo.getFileId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n          new ArrayList\u003c\u003e());\n    }\n\n    List\u003cLocatedBlock\u003e blocks \u003d locatedBlocks.getLocatedBlocks();\n    if (blocks.size() \u003d\u003d 0) {\n      LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n          + \" So, skipping the analysis.\", fileInfo.getFileId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n          new ArrayList\u003c\u003e());\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n\n    for (int i \u003d 0; i \u003c blocks.size(); i++) {\n      LocatedBlock blockInfo \u003d blocks.get(i);\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicy.getId())) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getLocations().length);\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return new BlocksMovingAnalysis(\n              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n              new ArrayList\u003c\u003e());\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(fileInfo.getReplication());\n      }\n\n      List\u003cStorageType\u003e existing \u003d new LinkedList\u003cStorageType\u003e(\n          Arrays.asList(blockInfo.getStorageTypes()));\n      if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, blockInfo.getLocations(),\n            liveDns, ecPolicy);\n        if (blocksPaired) {\n          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n        } else {\n          // none of the blocks found its eligible targets for satisfying the\n          // storage policy.\n          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n        }\n      } else {\n        if (hasLowRedundancyBlocks) {\n          status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n        }\n      }\n    }\n\n    List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n      // Check for at least one block storage movement has been chosen\n      try {\n        ctxt.assignBlockMoveTaskToTargetNode(blkMovingInfo);\n        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n        assignedBlockIds.add(blkMovingInfo.getBlock());\n        blockCount++;\n      } catch (IOException e) {\n        LOG.warn(\"Exception while scheduling movement task\", e);\n        // failed to move the block.\n        status \u003d BlocksMovingAnalysis.Status.BLOCKS_FAILED_TO_MOVE;\n      }\n    }\n    return new BlocksMovingAnalysis(status, assignedBlockIds);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
          "extendedDetails": {}
        }
      ]
    },
    "78420719eb1f138c6f10558befb7bc8ebcc28a54": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-12955: [SPS]: Move SPS classes to a separate package. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "78420719eb1f138c6f10558befb7bc8ebcc28a54",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "c561cb316e365ef674784cd6cf0b12c0fbc271a3",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n      BlockCollection blockCollection) {\n    BlocksMovingAnalysis.Status status \u003d\n        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n    byte existingStoragePolicyID \u003d blockCollection.getStoragePolicyID();\n    BlockStoragePolicy existingStoragePolicy \u003d\n        blockManager.getStoragePolicy(existingStoragePolicyID);\n    if (!blockCollection.getLastBlock().isComplete()) {\n      // Postpone, currently file is under construction\n      // So, should we add back? or leave it to user\n      LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n          + \" this to the next retry iteration\", blockCollection.getId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n          new ArrayList\u003c\u003e());\n    }\n\n    BlockInfo[] blocks \u003d blockCollection.getBlocks();\n    if (blocks.length \u003d\u003d 0) {\n      LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n          + \" So, skipping the analysis.\", blockCollection.getId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n          new ArrayList\u003c\u003e());\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n\n    for (int i \u003d 0; i \u003c blocks.length; i++) {\n      BlockInfo blockInfo \u003d blocks[i];\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicyID)) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getCapacity());\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return new BlocksMovingAnalysis(\n              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n              new ArrayList\u003c\u003e());\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(blockInfo.getReplication());\n      }\n\n      DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n      StorageType[] storageTypes \u003d new StorageType[storages.length];\n      for (int j \u003d 0; j \u003c storages.length; j++) {\n        DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n        StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n        storageTypes[j] \u003d storageType;\n      }\n      List\u003cStorageType\u003e existing \u003d\n          new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n      if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, storages);\n        if (blocksPaired) {\n          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n        } else {\n          // none of the blocks found its eligible targets for satisfying the\n          // storage policy.\n          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n        }\n      } else {\n        if (blockManager.hasLowRedundancyBlocks(blockCollection)) {\n          status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n        }\n      }\n    }\n\n    List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n      // Check for at least one block storage movement has been chosen\n      if (blkMovingInfo.getTarget() !\u003d null) {\n        // assign block storage movement task to the target node\n        ((DatanodeDescriptor) blkMovingInfo.getTarget())\n            .addBlocksToMoveStorage(blkMovingInfo);\n        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n        assignedBlockIds.add(blkMovingInfo.getBlock());\n        blockCount++;\n      }\n    }\n    return new BlocksMovingAnalysis(status, assignedBlockIds);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java"
      }
    },
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,85 +1,93 @@\n-  private BlocksMovingAnalysisStatus analyseBlocksStorageMovementsAndAssignToDN(\n+  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n       BlockCollection blockCollection) {\n-    BlocksMovingAnalysisStatus status \u003d\n-        BlocksMovingAnalysisStatus.BLOCKS_ALREADY_SATISFIED;\n+    BlocksMovingAnalysis.Status status \u003d\n+        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n     byte existingStoragePolicyID \u003d blockCollection.getStoragePolicyID();\n     BlockStoragePolicy existingStoragePolicy \u003d\n         blockManager.getStoragePolicy(existingStoragePolicyID);\n     if (!blockCollection.getLastBlock().isComplete()) {\n       // Postpone, currently file is under construction\n       // So, should we add back? or leave it to user\n       LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n           + \" this to the next retry iteration\", blockCollection.getId());\n-      return BlocksMovingAnalysisStatus.ANALYSIS_SKIPPED_FOR_RETRY;\n+      return new BlocksMovingAnalysis(\n+          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n+          new ArrayList\u003c\u003e());\n     }\n \n-    // First datanode will be chosen as the co-ordinator node for storage\n-    // movements. Later this can be optimized if needed.\n-    DatanodeDescriptor coordinatorNode \u003d null;\n     BlockInfo[] blocks \u003d blockCollection.getBlocks();\n     if (blocks.length \u003d\u003d 0) {\n       LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n           + \" So, skipping the analysis.\", blockCollection.getId());\n-      return BlocksMovingAnalysisStatus.BLOCKS_TARGET_PAIRING_SKIPPED;\n+      return new BlocksMovingAnalysis(\n+          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n+          new ArrayList\u003c\u003e());\n     }\n     List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n \n     for (int i \u003d 0; i \u003c blocks.length; i++) {\n       BlockInfo blockInfo \u003d blocks[i];\n       List\u003cStorageType\u003e expectedStorageTypes;\n       if (blockInfo.isStriped()) {\n         if (ErasureCodingPolicyManager\n             .checkStoragePolicySuitableForECStripedMode(\n                 existingStoragePolicyID)) {\n           expectedStorageTypes \u003d existingStoragePolicy\n               .chooseStorageTypes((short) blockInfo.getCapacity());\n         } else {\n           // Currently we support only limited policies (HOT, COLD, ALLSSD)\n           // for EC striped mode files. SPS will ignore to move the blocks if\n           // the storage policy is not in EC Striped mode supported policies\n           LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n               + \" is not suitable for Striped EC files. \"\n               + \"So, ignoring to move the blocks\");\n-          return BlocksMovingAnalysisStatus.BLOCKS_TARGET_PAIRING_SKIPPED;\n+          return new BlocksMovingAnalysis(\n+              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n+              new ArrayList\u003c\u003e());\n         }\n       } else {\n         expectedStorageTypes \u003d existingStoragePolicy\n             .chooseStorageTypes(blockInfo.getReplication());\n       }\n \n       DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n       StorageType[] storageTypes \u003d new StorageType[storages.length];\n       for (int j \u003d 0; j \u003c storages.length; j++) {\n         DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n         StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n         storageTypes[j] \u003d storageType;\n       }\n       List\u003cStorageType\u003e existing \u003d\n           new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n       if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n           existing, true)) {\n-        boolean computeStatus \u003d computeBlockMovingInfos(blockMovingInfos,\n+        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n             blockInfo, expectedStorageTypes, existing, storages);\n-        if (computeStatus\n-            \u0026\u0026 status !\u003d BlocksMovingAnalysisStatus.FEW_BLOCKS_TARGETS_PAIRED\n-            \u0026\u0026 !blockManager.hasLowRedundancyBlocks(blockCollection)) {\n-          status \u003d BlocksMovingAnalysisStatus.ALL_BLOCKS_TARGETS_PAIRED;\n+        if (blocksPaired) {\n+          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n         } else {\n-          status \u003d BlocksMovingAnalysisStatus.FEW_BLOCKS_TARGETS_PAIRED;\n+          // none of the blocks found its eligible targets for satisfying the\n+          // storage policy.\n+          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n         }\n       } else {\n         if (blockManager.hasLowRedundancyBlocks(blockCollection)) {\n-          status \u003d BlocksMovingAnalysisStatus.FEW_LOW_REDUNDANCY_BLOCKS;\n+          status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n         }\n       }\n     }\n \n-    assignBlockMovingInfosToCoordinatorDn(blockCollection.getId(),\n-        blockMovingInfos, coordinatorNode);\n-    int count \u003d 0;\n+    List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n     for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n-      count \u003d count + blkMovingInfo.getSources().length;\n+      // Check for at least one block storage movement has been chosen\n+      if (blkMovingInfo.getTarget() !\u003d null) {\n+        // assign block storage movement task to the target node\n+        ((DatanodeDescriptor) blkMovingInfo.getTarget())\n+            .addBlocksToMoveStorage(blkMovingInfo);\n+        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n+        assignedBlockIds.add(blkMovingInfo.getBlock());\n+        blockCount++;\n+      }\n     }\n-    blockCount \u003d blockCount + count;\n-    return status;\n+    return new BlocksMovingAnalysis(status, assignedBlockIds);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n      BlockCollection blockCollection) {\n    BlocksMovingAnalysis.Status status \u003d\n        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n    byte existingStoragePolicyID \u003d blockCollection.getStoragePolicyID();\n    BlockStoragePolicy existingStoragePolicy \u003d\n        blockManager.getStoragePolicy(existingStoragePolicyID);\n    if (!blockCollection.getLastBlock().isComplete()) {\n      // Postpone, currently file is under construction\n      // So, should we add back? or leave it to user\n      LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n          + \" this to the next retry iteration\", blockCollection.getId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n          new ArrayList\u003c\u003e());\n    }\n\n    BlockInfo[] blocks \u003d blockCollection.getBlocks();\n    if (blocks.length \u003d\u003d 0) {\n      LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n          + \" So, skipping the analysis.\", blockCollection.getId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n          new ArrayList\u003c\u003e());\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n\n    for (int i \u003d 0; i \u003c blocks.length; i++) {\n      BlockInfo blockInfo \u003d blocks[i];\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicyID)) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getCapacity());\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return new BlocksMovingAnalysis(\n              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n              new ArrayList\u003c\u003e());\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(blockInfo.getReplication());\n      }\n\n      DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n      StorageType[] storageTypes \u003d new StorageType[storages.length];\n      for (int j \u003d 0; j \u003c storages.length; j++) {\n        DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n        StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n        storageTypes[j] \u003d storageType;\n      }\n      List\u003cStorageType\u003e existing \u003d\n          new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n      if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, storages);\n        if (blocksPaired) {\n          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n        } else {\n          // none of the blocks found its eligible targets for satisfying the\n          // storage policy.\n          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n        }\n      } else {\n        if (blockManager.hasLowRedundancyBlocks(blockCollection)) {\n          status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n        }\n      }\n    }\n\n    List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n      // Check for at least one block storage movement has been chosen\n      if (blkMovingInfo.getTarget() !\u003d null) {\n        // assign block storage movement task to the target node\n        ((DatanodeDescriptor) blkMovingInfo.getTarget())\n            .addBlocksToMoveStorage(blkMovingInfo);\n        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n        assignedBlockIds.add(blkMovingInfo.getBlock());\n        blockCount++;\n      }\n    }\n    return new BlocksMovingAnalysis(status, assignedBlockIds);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
          "extendedDetails": {
            "oldValue": "BlocksMovingAnalysisStatus",
            "newValue": "BlocksMovingAnalysis"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,85 +1,93 @@\n-  private BlocksMovingAnalysisStatus analyseBlocksStorageMovementsAndAssignToDN(\n+  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n       BlockCollection blockCollection) {\n-    BlocksMovingAnalysisStatus status \u003d\n-        BlocksMovingAnalysisStatus.BLOCKS_ALREADY_SATISFIED;\n+    BlocksMovingAnalysis.Status status \u003d\n+        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n     byte existingStoragePolicyID \u003d blockCollection.getStoragePolicyID();\n     BlockStoragePolicy existingStoragePolicy \u003d\n         blockManager.getStoragePolicy(existingStoragePolicyID);\n     if (!blockCollection.getLastBlock().isComplete()) {\n       // Postpone, currently file is under construction\n       // So, should we add back? or leave it to user\n       LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n           + \" this to the next retry iteration\", blockCollection.getId());\n-      return BlocksMovingAnalysisStatus.ANALYSIS_SKIPPED_FOR_RETRY;\n+      return new BlocksMovingAnalysis(\n+          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n+          new ArrayList\u003c\u003e());\n     }\n \n-    // First datanode will be chosen as the co-ordinator node for storage\n-    // movements. Later this can be optimized if needed.\n-    DatanodeDescriptor coordinatorNode \u003d null;\n     BlockInfo[] blocks \u003d blockCollection.getBlocks();\n     if (blocks.length \u003d\u003d 0) {\n       LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n           + \" So, skipping the analysis.\", blockCollection.getId());\n-      return BlocksMovingAnalysisStatus.BLOCKS_TARGET_PAIRING_SKIPPED;\n+      return new BlocksMovingAnalysis(\n+          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n+          new ArrayList\u003c\u003e());\n     }\n     List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n \n     for (int i \u003d 0; i \u003c blocks.length; i++) {\n       BlockInfo blockInfo \u003d blocks[i];\n       List\u003cStorageType\u003e expectedStorageTypes;\n       if (blockInfo.isStriped()) {\n         if (ErasureCodingPolicyManager\n             .checkStoragePolicySuitableForECStripedMode(\n                 existingStoragePolicyID)) {\n           expectedStorageTypes \u003d existingStoragePolicy\n               .chooseStorageTypes((short) blockInfo.getCapacity());\n         } else {\n           // Currently we support only limited policies (HOT, COLD, ALLSSD)\n           // for EC striped mode files. SPS will ignore to move the blocks if\n           // the storage policy is not in EC Striped mode supported policies\n           LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n               + \" is not suitable for Striped EC files. \"\n               + \"So, ignoring to move the blocks\");\n-          return BlocksMovingAnalysisStatus.BLOCKS_TARGET_PAIRING_SKIPPED;\n+          return new BlocksMovingAnalysis(\n+              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n+              new ArrayList\u003c\u003e());\n         }\n       } else {\n         expectedStorageTypes \u003d existingStoragePolicy\n             .chooseStorageTypes(blockInfo.getReplication());\n       }\n \n       DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n       StorageType[] storageTypes \u003d new StorageType[storages.length];\n       for (int j \u003d 0; j \u003c storages.length; j++) {\n         DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n         StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n         storageTypes[j] \u003d storageType;\n       }\n       List\u003cStorageType\u003e existing \u003d\n           new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n       if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n           existing, true)) {\n-        boolean computeStatus \u003d computeBlockMovingInfos(blockMovingInfos,\n+        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n             blockInfo, expectedStorageTypes, existing, storages);\n-        if (computeStatus\n-            \u0026\u0026 status !\u003d BlocksMovingAnalysisStatus.FEW_BLOCKS_TARGETS_PAIRED\n-            \u0026\u0026 !blockManager.hasLowRedundancyBlocks(blockCollection)) {\n-          status \u003d BlocksMovingAnalysisStatus.ALL_BLOCKS_TARGETS_PAIRED;\n+        if (blocksPaired) {\n+          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n         } else {\n-          status \u003d BlocksMovingAnalysisStatus.FEW_BLOCKS_TARGETS_PAIRED;\n+          // none of the blocks found its eligible targets for satisfying the\n+          // storage policy.\n+          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n         }\n       } else {\n         if (blockManager.hasLowRedundancyBlocks(blockCollection)) {\n-          status \u003d BlocksMovingAnalysisStatus.FEW_LOW_REDUNDANCY_BLOCKS;\n+          status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n         }\n       }\n     }\n \n-    assignBlockMovingInfosToCoordinatorDn(blockCollection.getId(),\n-        blockMovingInfos, coordinatorNode);\n-    int count \u003d 0;\n+    List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n     for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n-      count \u003d count + blkMovingInfo.getSources().length;\n+      // Check for at least one block storage movement has been chosen\n+      if (blkMovingInfo.getTarget() !\u003d null) {\n+        // assign block storage movement task to the target node\n+        ((DatanodeDescriptor) blkMovingInfo.getTarget())\n+            .addBlocksToMoveStorage(blkMovingInfo);\n+        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n+        assignedBlockIds.add(blkMovingInfo.getBlock());\n+        blockCount++;\n+      }\n     }\n-    blockCount \u003d blockCount + count;\n-    return status;\n+    return new BlocksMovingAnalysis(status, assignedBlockIds);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private BlocksMovingAnalysis analyseBlocksStorageMovementsAndAssignToDN(\n      BlockCollection blockCollection) {\n    BlocksMovingAnalysis.Status status \u003d\n        BlocksMovingAnalysis.Status.BLOCKS_ALREADY_SATISFIED;\n    byte existingStoragePolicyID \u003d blockCollection.getStoragePolicyID();\n    BlockStoragePolicy existingStoragePolicy \u003d\n        blockManager.getStoragePolicy(existingStoragePolicyID);\n    if (!blockCollection.getLastBlock().isComplete()) {\n      // Postpone, currently file is under construction\n      // So, should we add back? or leave it to user\n      LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n          + \" this to the next retry iteration\", blockCollection.getId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.ANALYSIS_SKIPPED_FOR_RETRY,\n          new ArrayList\u003c\u003e());\n    }\n\n    BlockInfo[] blocks \u003d blockCollection.getBlocks();\n    if (blocks.length \u003d\u003d 0) {\n      LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n          + \" So, skipping the analysis.\", blockCollection.getId());\n      return new BlocksMovingAnalysis(\n          BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n          new ArrayList\u003c\u003e());\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n\n    for (int i \u003d 0; i \u003c blocks.length; i++) {\n      BlockInfo blockInfo \u003d blocks[i];\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicyID)) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getCapacity());\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return new BlocksMovingAnalysis(\n              BlocksMovingAnalysis.Status.BLOCKS_TARGET_PAIRING_SKIPPED,\n              new ArrayList\u003c\u003e());\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(blockInfo.getReplication());\n      }\n\n      DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n      StorageType[] storageTypes \u003d new StorageType[storages.length];\n      for (int j \u003d 0; j \u003c storages.length; j++) {\n        DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n        StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n        storageTypes[j] \u003d storageType;\n      }\n      List\u003cStorageType\u003e existing \u003d\n          new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n      if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean blocksPaired \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, storages);\n        if (blocksPaired) {\n          status \u003d BlocksMovingAnalysis.Status.BLOCKS_TARGETS_PAIRED;\n        } else {\n          // none of the blocks found its eligible targets for satisfying the\n          // storage policy.\n          status \u003d BlocksMovingAnalysis.Status.NO_BLOCKS_TARGETS_PAIRED;\n        }\n      } else {\n        if (blockManager.hasLowRedundancyBlocks(blockCollection)) {\n          status \u003d BlocksMovingAnalysis.Status.FEW_LOW_REDUNDANCY_BLOCKS;\n        }\n      }\n    }\n\n    List\u003cBlock\u003e assignedBlockIds \u003d new ArrayList\u003cBlock\u003e();\n    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n      // Check for at least one block storage movement has been chosen\n      if (blkMovingInfo.getTarget() !\u003d null) {\n        // assign block storage movement task to the target node\n        ((DatanodeDescriptor) blkMovingInfo.getTarget())\n            .addBlocksToMoveStorage(blkMovingInfo);\n        LOG.debug(\"BlockMovingInfo: {}\", blkMovingInfo);\n        assignedBlockIds.add(blkMovingInfo.getBlock());\n        blockCount++;\n      }\n    }\n    return new BlocksMovingAnalysis(status, assignedBlockIds);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
          "extendedDetails": {}
        }
      ]
    },
    "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12291: [SPS]: Provide a mechanism to recursively iterate and satisfy storage policy of all the files under the given dir. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,85 @@\n   private BlocksMovingAnalysisStatus analyseBlocksStorageMovementsAndAssignToDN(\n       BlockCollection blockCollection) {\n     BlocksMovingAnalysisStatus status \u003d\n         BlocksMovingAnalysisStatus.BLOCKS_ALREADY_SATISFIED;\n     byte existingStoragePolicyID \u003d blockCollection.getStoragePolicyID();\n     BlockStoragePolicy existingStoragePolicy \u003d\n         blockManager.getStoragePolicy(existingStoragePolicyID);\n     if (!blockCollection.getLastBlock().isComplete()) {\n       // Postpone, currently file is under construction\n       // So, should we add back? or leave it to user\n       LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n           + \" this to the next retry iteration\", blockCollection.getId());\n       return BlocksMovingAnalysisStatus.ANALYSIS_SKIPPED_FOR_RETRY;\n     }\n \n     // First datanode will be chosen as the co-ordinator node for storage\n     // movements. Later this can be optimized if needed.\n     DatanodeDescriptor coordinatorNode \u003d null;\n     BlockInfo[] blocks \u003d blockCollection.getBlocks();\n     if (blocks.length \u003d\u003d 0) {\n       LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n           + \" So, skipping the analysis.\", blockCollection.getId());\n       return BlocksMovingAnalysisStatus.BLOCKS_TARGET_PAIRING_SKIPPED;\n     }\n     List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n \n     for (int i \u003d 0; i \u003c blocks.length; i++) {\n       BlockInfo blockInfo \u003d blocks[i];\n       List\u003cStorageType\u003e expectedStorageTypes;\n       if (blockInfo.isStriped()) {\n         if (ErasureCodingPolicyManager\n             .checkStoragePolicySuitableForECStripedMode(\n                 existingStoragePolicyID)) {\n           expectedStorageTypes \u003d existingStoragePolicy\n               .chooseStorageTypes((short) blockInfo.getCapacity());\n         } else {\n           // Currently we support only limited policies (HOT, COLD, ALLSSD)\n           // for EC striped mode files. SPS will ignore to move the blocks if\n           // the storage policy is not in EC Striped mode supported policies\n           LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n               + \" is not suitable for Striped EC files. \"\n               + \"So, ignoring to move the blocks\");\n           return BlocksMovingAnalysisStatus.BLOCKS_TARGET_PAIRING_SKIPPED;\n         }\n       } else {\n         expectedStorageTypes \u003d existingStoragePolicy\n             .chooseStorageTypes(blockInfo.getReplication());\n       }\n \n       DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n       StorageType[] storageTypes \u003d new StorageType[storages.length];\n       for (int j \u003d 0; j \u003c storages.length; j++) {\n         DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n         StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n         storageTypes[j] \u003d storageType;\n       }\n       List\u003cStorageType\u003e existing \u003d\n           new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n       if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n           existing, true)) {\n         boolean computeStatus \u003d computeBlockMovingInfos(blockMovingInfos,\n             blockInfo, expectedStorageTypes, existing, storages);\n         if (computeStatus\n             \u0026\u0026 status !\u003d BlocksMovingAnalysisStatus.FEW_BLOCKS_TARGETS_PAIRED\n             \u0026\u0026 !blockManager.hasLowRedundancyBlocks(blockCollection)) {\n           status \u003d BlocksMovingAnalysisStatus.ALL_BLOCKS_TARGETS_PAIRED;\n         } else {\n           status \u003d BlocksMovingAnalysisStatus.FEW_BLOCKS_TARGETS_PAIRED;\n         }\n       } else {\n         if (blockManager.hasLowRedundancyBlocks(blockCollection)) {\n           status \u003d BlocksMovingAnalysisStatus.FEW_LOW_REDUNDANCY_BLOCKS;\n         }\n       }\n     }\n \n     assignBlockMovingInfosToCoordinatorDn(blockCollection.getId(),\n         blockMovingInfos, coordinatorNode);\n+    int count \u003d 0;\n+    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n+      count \u003d count + blkMovingInfo.getSources().length;\n+    }\n+    blockCount \u003d blockCount + count;\n     return status;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private BlocksMovingAnalysisStatus analyseBlocksStorageMovementsAndAssignToDN(\n      BlockCollection blockCollection) {\n    BlocksMovingAnalysisStatus status \u003d\n        BlocksMovingAnalysisStatus.BLOCKS_ALREADY_SATISFIED;\n    byte existingStoragePolicyID \u003d blockCollection.getStoragePolicyID();\n    BlockStoragePolicy existingStoragePolicy \u003d\n        blockManager.getStoragePolicy(existingStoragePolicyID);\n    if (!blockCollection.getLastBlock().isComplete()) {\n      // Postpone, currently file is under construction\n      // So, should we add back? or leave it to user\n      LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n          + \" this to the next retry iteration\", blockCollection.getId());\n      return BlocksMovingAnalysisStatus.ANALYSIS_SKIPPED_FOR_RETRY;\n    }\n\n    // First datanode will be chosen as the co-ordinator node for storage\n    // movements. Later this can be optimized if needed.\n    DatanodeDescriptor coordinatorNode \u003d null;\n    BlockInfo[] blocks \u003d blockCollection.getBlocks();\n    if (blocks.length \u003d\u003d 0) {\n      LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n          + \" So, skipping the analysis.\", blockCollection.getId());\n      return BlocksMovingAnalysisStatus.BLOCKS_TARGET_PAIRING_SKIPPED;\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n\n    for (int i \u003d 0; i \u003c blocks.length; i++) {\n      BlockInfo blockInfo \u003d blocks[i];\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicyID)) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getCapacity());\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return BlocksMovingAnalysisStatus.BLOCKS_TARGET_PAIRING_SKIPPED;\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(blockInfo.getReplication());\n      }\n\n      DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n      StorageType[] storageTypes \u003d new StorageType[storages.length];\n      for (int j \u003d 0; j \u003c storages.length; j++) {\n        DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n        StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n        storageTypes[j] \u003d storageType;\n      }\n      List\u003cStorageType\u003e existing \u003d\n          new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n      if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean computeStatus \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, storages);\n        if (computeStatus\n            \u0026\u0026 status !\u003d BlocksMovingAnalysisStatus.FEW_BLOCKS_TARGETS_PAIRED\n            \u0026\u0026 !blockManager.hasLowRedundancyBlocks(blockCollection)) {\n          status \u003d BlocksMovingAnalysisStatus.ALL_BLOCKS_TARGETS_PAIRED;\n        } else {\n          status \u003d BlocksMovingAnalysisStatus.FEW_BLOCKS_TARGETS_PAIRED;\n        }\n      } else {\n        if (blockManager.hasLowRedundancyBlocks(blockCollection)) {\n          status \u003d BlocksMovingAnalysisStatus.FEW_LOW_REDUNDANCY_BLOCKS;\n        }\n      }\n    }\n\n    assignBlockMovingInfosToCoordinatorDn(blockCollection.getId(),\n        blockMovingInfos, coordinatorNode);\n    int count \u003d 0;\n    for (BlockMovingInfo blkMovingInfo : blockMovingInfos) {\n      count \u003d count + blkMovingInfo.getSources().length;\n    }\n    blockCount \u003d blockCount + count;\n    return status;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "0b360b16ab8759e3db606ada3420f4e2f56235f3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11965: [SPS]: Should give chance to satisfy the low redundant blocks before removing the xattr. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "0b360b16ab8759e3db606ada3420f4e2f56235f3",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "20f9c623360d8ec534f8ddb0b993b4363a359e89",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,75 +1,80 @@\n   private BlocksMovingAnalysisStatus analyseBlocksStorageMovementsAndAssignToDN(\n       BlockCollection blockCollection) {\n     BlocksMovingAnalysisStatus status \u003d\n         BlocksMovingAnalysisStatus.BLOCKS_ALREADY_SATISFIED;\n     byte existingStoragePolicyID \u003d blockCollection.getStoragePolicyID();\n     BlockStoragePolicy existingStoragePolicy \u003d\n         blockManager.getStoragePolicy(existingStoragePolicyID);\n     if (!blockCollection.getLastBlock().isComplete()) {\n       // Postpone, currently file is under construction\n       // So, should we add back? or leave it to user\n       LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n           + \" this to the next retry iteration\", blockCollection.getId());\n       return BlocksMovingAnalysisStatus.ANALYSIS_SKIPPED_FOR_RETRY;\n     }\n \n     // First datanode will be chosen as the co-ordinator node for storage\n     // movements. Later this can be optimized if needed.\n     DatanodeDescriptor coordinatorNode \u003d null;\n     BlockInfo[] blocks \u003d blockCollection.getBlocks();\n     if (blocks.length \u003d\u003d 0) {\n       LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n           + \" So, skipping the analysis.\", blockCollection.getId());\n       return BlocksMovingAnalysisStatus.BLOCKS_TARGET_PAIRING_SKIPPED;\n     }\n     List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n \n     for (int i \u003d 0; i \u003c blocks.length; i++) {\n       BlockInfo blockInfo \u003d blocks[i];\n       List\u003cStorageType\u003e expectedStorageTypes;\n       if (blockInfo.isStriped()) {\n         if (ErasureCodingPolicyManager\n             .checkStoragePolicySuitableForECStripedMode(\n                 existingStoragePolicyID)) {\n           expectedStorageTypes \u003d existingStoragePolicy\n               .chooseStorageTypes((short) blockInfo.getCapacity());\n         } else {\n           // Currently we support only limited policies (HOT, COLD, ALLSSD)\n           // for EC striped mode files. SPS will ignore to move the blocks if\n           // the storage policy is not in EC Striped mode supported policies\n           LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n               + \" is not suitable for Striped EC files. \"\n               + \"So, ignoring to move the blocks\");\n           return BlocksMovingAnalysisStatus.BLOCKS_TARGET_PAIRING_SKIPPED;\n         }\n       } else {\n         expectedStorageTypes \u003d existingStoragePolicy\n             .chooseStorageTypes(blockInfo.getReplication());\n       }\n \n       DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n       StorageType[] storageTypes \u003d new StorageType[storages.length];\n       for (int j \u003d 0; j \u003c storages.length; j++) {\n         DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n         StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n         storageTypes[j] \u003d storageType;\n       }\n       List\u003cStorageType\u003e existing \u003d\n           new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n       if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n           existing, true)) {\n         boolean computeStatus \u003d computeBlockMovingInfos(blockMovingInfos,\n             blockInfo, expectedStorageTypes, existing, storages);\n         if (computeStatus\n-            \u0026\u0026 status !\u003d BlocksMovingAnalysisStatus.FEW_BLOCKS_TARGETS_PAIRED) {\n+            \u0026\u0026 status !\u003d BlocksMovingAnalysisStatus.FEW_BLOCKS_TARGETS_PAIRED\n+            \u0026\u0026 !blockManager.hasLowRedundancyBlocks(blockCollection)) {\n           status \u003d BlocksMovingAnalysisStatus.ALL_BLOCKS_TARGETS_PAIRED;\n         } else {\n           status \u003d BlocksMovingAnalysisStatus.FEW_BLOCKS_TARGETS_PAIRED;\n         }\n+      } else {\n+        if (blockManager.hasLowRedundancyBlocks(blockCollection)) {\n+          status \u003d BlocksMovingAnalysisStatus.FEW_LOW_REDUNDANCY_BLOCKS;\n+        }\n       }\n     }\n \n     assignBlockMovingInfosToCoordinatorDn(blockCollection.getId(),\n         blockMovingInfos, coordinatorNode);\n     return status;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private BlocksMovingAnalysisStatus analyseBlocksStorageMovementsAndAssignToDN(\n      BlockCollection blockCollection) {\n    BlocksMovingAnalysisStatus status \u003d\n        BlocksMovingAnalysisStatus.BLOCKS_ALREADY_SATISFIED;\n    byte existingStoragePolicyID \u003d blockCollection.getStoragePolicyID();\n    BlockStoragePolicy existingStoragePolicy \u003d\n        blockManager.getStoragePolicy(existingStoragePolicyID);\n    if (!blockCollection.getLastBlock().isComplete()) {\n      // Postpone, currently file is under construction\n      // So, should we add back? or leave it to user\n      LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n          + \" this to the next retry iteration\", blockCollection.getId());\n      return BlocksMovingAnalysisStatus.ANALYSIS_SKIPPED_FOR_RETRY;\n    }\n\n    // First datanode will be chosen as the co-ordinator node for storage\n    // movements. Later this can be optimized if needed.\n    DatanodeDescriptor coordinatorNode \u003d null;\n    BlockInfo[] blocks \u003d blockCollection.getBlocks();\n    if (blocks.length \u003d\u003d 0) {\n      LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n          + \" So, skipping the analysis.\", blockCollection.getId());\n      return BlocksMovingAnalysisStatus.BLOCKS_TARGET_PAIRING_SKIPPED;\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n\n    for (int i \u003d 0; i \u003c blocks.length; i++) {\n      BlockInfo blockInfo \u003d blocks[i];\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicyID)) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getCapacity());\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return BlocksMovingAnalysisStatus.BLOCKS_TARGET_PAIRING_SKIPPED;\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(blockInfo.getReplication());\n      }\n\n      DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n      StorageType[] storageTypes \u003d new StorageType[storages.length];\n      for (int j \u003d 0; j \u003c storages.length; j++) {\n        DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n        StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n        storageTypes[j] \u003d storageType;\n      }\n      List\u003cStorageType\u003e existing \u003d\n          new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n      if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean computeStatus \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, storages);\n        if (computeStatus\n            \u0026\u0026 status !\u003d BlocksMovingAnalysisStatus.FEW_BLOCKS_TARGETS_PAIRED\n            \u0026\u0026 !blockManager.hasLowRedundancyBlocks(blockCollection)) {\n          status \u003d BlocksMovingAnalysisStatus.ALL_BLOCKS_TARGETS_PAIRED;\n        } else {\n          status \u003d BlocksMovingAnalysisStatus.FEW_BLOCKS_TARGETS_PAIRED;\n        }\n      } else {\n        if (blockManager.hasLowRedundancyBlocks(blockCollection)) {\n          status \u003d BlocksMovingAnalysisStatus.FEW_LOW_REDUNDANCY_BLOCKS;\n        }\n      }\n    }\n\n    assignBlockMovingInfosToCoordinatorDn(blockCollection.getId(),\n        blockMovingInfos, coordinatorNode);\n    return status;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java",
      "extendedDetails": {}
    },
    "6fe6c549e8226b4893f502186f52452dcd9408a2": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11572. [SPS]: SPS should clean Xattrs when no blocks required to satisfy for a file. Contributed by Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "6fe6c549e8226b4893f502186f52452dcd9408a2",
      "commitAuthor": "Rakesh Radhakrishnan",
      "diff": "@@ -0,0 +1,75 @@\n+  private BlocksMovingAnalysisStatus analyseBlocksStorageMovementsAndAssignToDN(\n+      BlockCollection blockCollection) {\n+    BlocksMovingAnalysisStatus status \u003d\n+        BlocksMovingAnalysisStatus.BLOCKS_ALREADY_SATISFIED;\n+    byte existingStoragePolicyID \u003d blockCollection.getStoragePolicyID();\n+    BlockStoragePolicy existingStoragePolicy \u003d\n+        blockManager.getStoragePolicy(existingStoragePolicyID);\n+    if (!blockCollection.getLastBlock().isComplete()) {\n+      // Postpone, currently file is under construction\n+      // So, should we add back? or leave it to user\n+      LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n+          + \" this to the next retry iteration\", blockCollection.getId());\n+      return BlocksMovingAnalysisStatus.ANALYSIS_SKIPPED_FOR_RETRY;\n+    }\n+\n+    // First datanode will be chosen as the co-ordinator node for storage\n+    // movements. Later this can be optimized if needed.\n+    DatanodeDescriptor coordinatorNode \u003d null;\n+    BlockInfo[] blocks \u003d blockCollection.getBlocks();\n+    if (blocks.length \u003d\u003d 0) {\n+      LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n+          + \" So, skipping the analysis.\", blockCollection.getId());\n+      return BlocksMovingAnalysisStatus.BLOCKS_TARGET_PAIRING_SKIPPED;\n+    }\n+    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n+\n+    for (int i \u003d 0; i \u003c blocks.length; i++) {\n+      BlockInfo blockInfo \u003d blocks[i];\n+      List\u003cStorageType\u003e expectedStorageTypes;\n+      if (blockInfo.isStriped()) {\n+        if (ErasureCodingPolicyManager\n+            .checkStoragePolicySuitableForECStripedMode(\n+                existingStoragePolicyID)) {\n+          expectedStorageTypes \u003d existingStoragePolicy\n+              .chooseStorageTypes((short) blockInfo.getCapacity());\n+        } else {\n+          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n+          // for EC striped mode files. SPS will ignore to move the blocks if\n+          // the storage policy is not in EC Striped mode supported policies\n+          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n+              + \" is not suitable for Striped EC files. \"\n+              + \"So, ignoring to move the blocks\");\n+          return BlocksMovingAnalysisStatus.BLOCKS_TARGET_PAIRING_SKIPPED;\n+        }\n+      } else {\n+        expectedStorageTypes \u003d existingStoragePolicy\n+            .chooseStorageTypes(blockInfo.getReplication());\n+      }\n+\n+      DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n+      StorageType[] storageTypes \u003d new StorageType[storages.length];\n+      for (int j \u003d 0; j \u003c storages.length; j++) {\n+        DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n+        StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n+        storageTypes[j] \u003d storageType;\n+      }\n+      List\u003cStorageType\u003e existing \u003d\n+          new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n+      if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n+          existing, true)) {\n+        boolean computeStatus \u003d computeBlockMovingInfos(blockMovingInfos,\n+            blockInfo, expectedStorageTypes, existing, storages);\n+        if (computeStatus\n+            \u0026\u0026 status !\u003d BlocksMovingAnalysisStatus.FEW_BLOCKS_TARGETS_PAIRED) {\n+          status \u003d BlocksMovingAnalysisStatus.ALL_BLOCKS_TARGETS_PAIRED;\n+        } else {\n+          status \u003d BlocksMovingAnalysisStatus.FEW_BLOCKS_TARGETS_PAIRED;\n+        }\n+      }\n+    }\n+\n+    assignBlockMovingInfosToCoordinatorDn(blockCollection.getId(),\n+        blockMovingInfos, coordinatorNode);\n+    return status;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private BlocksMovingAnalysisStatus analyseBlocksStorageMovementsAndAssignToDN(\n      BlockCollection blockCollection) {\n    BlocksMovingAnalysisStatus status \u003d\n        BlocksMovingAnalysisStatus.BLOCKS_ALREADY_SATISFIED;\n    byte existingStoragePolicyID \u003d blockCollection.getStoragePolicyID();\n    BlockStoragePolicy existingStoragePolicy \u003d\n        blockManager.getStoragePolicy(existingStoragePolicyID);\n    if (!blockCollection.getLastBlock().isComplete()) {\n      // Postpone, currently file is under construction\n      // So, should we add back? or leave it to user\n      LOG.info(\"BlockCollectionID: {} file is under construction. So, postpone\"\n          + \" this to the next retry iteration\", blockCollection.getId());\n      return BlocksMovingAnalysisStatus.ANALYSIS_SKIPPED_FOR_RETRY;\n    }\n\n    // First datanode will be chosen as the co-ordinator node for storage\n    // movements. Later this can be optimized if needed.\n    DatanodeDescriptor coordinatorNode \u003d null;\n    BlockInfo[] blocks \u003d blockCollection.getBlocks();\n    if (blocks.length \u003d\u003d 0) {\n      LOG.info(\"BlockCollectionID: {} file is not having any blocks.\"\n          + \" So, skipping the analysis.\", blockCollection.getId());\n      return BlocksMovingAnalysisStatus.BLOCKS_TARGET_PAIRING_SKIPPED;\n    }\n    List\u003cBlockMovingInfo\u003e blockMovingInfos \u003d new ArrayList\u003cBlockMovingInfo\u003e();\n\n    for (int i \u003d 0; i \u003c blocks.length; i++) {\n      BlockInfo blockInfo \u003d blocks[i];\n      List\u003cStorageType\u003e expectedStorageTypes;\n      if (blockInfo.isStriped()) {\n        if (ErasureCodingPolicyManager\n            .checkStoragePolicySuitableForECStripedMode(\n                existingStoragePolicyID)) {\n          expectedStorageTypes \u003d existingStoragePolicy\n              .chooseStorageTypes((short) blockInfo.getCapacity());\n        } else {\n          // Currently we support only limited policies (HOT, COLD, ALLSSD)\n          // for EC striped mode files. SPS will ignore to move the blocks if\n          // the storage policy is not in EC Striped mode supported policies\n          LOG.warn(\"The storage policy \" + existingStoragePolicy.getName()\n              + \" is not suitable for Striped EC files. \"\n              + \"So, ignoring to move the blocks\");\n          return BlocksMovingAnalysisStatus.BLOCKS_TARGET_PAIRING_SKIPPED;\n        }\n      } else {\n        expectedStorageTypes \u003d existingStoragePolicy\n            .chooseStorageTypes(blockInfo.getReplication());\n      }\n\n      DatanodeStorageInfo[] storages \u003d blockManager.getStorages(blockInfo);\n      StorageType[] storageTypes \u003d new StorageType[storages.length];\n      for (int j \u003d 0; j \u003c storages.length; j++) {\n        DatanodeStorageInfo datanodeStorageInfo \u003d storages[j];\n        StorageType storageType \u003d datanodeStorageInfo.getStorageType();\n        storageTypes[j] \u003d storageType;\n      }\n      List\u003cStorageType\u003e existing \u003d\n          new LinkedList\u003cStorageType\u003e(Arrays.asList(storageTypes));\n      if (!DFSUtil.removeOverlapBetweenStorageTypes(expectedStorageTypes,\n          existing, true)) {\n        boolean computeStatus \u003d computeBlockMovingInfos(blockMovingInfos,\n            blockInfo, expectedStorageTypes, existing, storages);\n        if (computeStatus\n            \u0026\u0026 status !\u003d BlocksMovingAnalysisStatus.FEW_BLOCKS_TARGETS_PAIRED) {\n          status \u003d BlocksMovingAnalysisStatus.ALL_BLOCKS_TARGETS_PAIRED;\n        } else {\n          status \u003d BlocksMovingAnalysisStatus.FEW_BLOCKS_TARGETS_PAIRED;\n        }\n      }\n    }\n\n    assignBlockMovingInfosToCoordinatorDn(blockCollection.getId(),\n        blockMovingInfos, coordinatorNode);\n    return status;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/StoragePolicySatisfier.java"
    }
  }
}