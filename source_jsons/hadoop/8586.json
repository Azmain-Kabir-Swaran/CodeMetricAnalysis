{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImageFormatPBINode.java",
  "functionName": "loadINodeSection",
  "functionId": "loadINodeSection___in-InputStream__prog-StartupProgress__currentStep-Step",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.java",
  "functionStartLine": 330,
  "functionEndLine": 336,
  "numCommitsSeen": 63,
  "timeTaken": 1730,
  "changeHistory": [
    "b67812ea2111fa11bdd76096b923c93e1bdf2923"
  ],
  "changeHistoryShort": {
    "b67812ea2111fa11bdd76096b923c93e1bdf2923": "Ybodychange"
  },
  "changeHistoryDetails": {
    "b67812ea2111fa11bdd76096b923c93e1bdf2923": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14617. Improve fsimage load time by writing sub-sections to the fsimage index (#1028). Contributed by  Stephen O\u0027Donnell.\n\nReviewed-by: He Xiaoqiao \u003chexiaoqiao@apache.org\u003e",
      "commitDate": "22/08/19 5:09 PM",
      "commitName": "b67812ea2111fa11bdd76096b923c93e1bdf2923",
      "commitAuthor": "Stephen O\u0027Donnell",
      "commitDateOld": "22/07/19 8:07 PM",
      "commitNameOld": "377f95bbe8d2d171b5d7b0bfa7559e67ca4aae46",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 30.88,
      "commitsBetweenForRepo": 299,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,7 @@\n     void loadINodeSection(InputStream in, StartupProgress prog,\n         Step currentStep) throws IOException {\n-      INodeSection s \u003d INodeSection.parseDelimitedFrom(in);\n-      fsn.dir.resetLastInodeId(s.getLastInodeId());\n-      long numInodes \u003d s.getNumInodes();\n-      LOG.info(\"Loading \" + numInodes + \" INodes.\");\n-      prog.setTotal(Phase.LOADING_FSIMAGE, currentStep, numInodes);\n+      loadINodeSectionHeader(in, prog, currentStep);\n       Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, currentStep);\n-      for (int i \u003d 0; i \u003c numInodes; ++i) {\n-        INodeSection.INode p \u003d INodeSection.INode.parseDelimitedFrom(in);\n-        if (p.getId() \u003d\u003d INodeId.ROOT_INODE_ID) {\n-          loadRootINode(p);\n-        } else {\n-          INode n \u003d loadINode(p);\n-          dir.addToInodeMap(n);\n-        }\n-        counter.increment();\n-      }\n+      int totalLoaded \u003d loadINodesInSection(in, counter);\n+      LOG.info(\"Successfully loaded {} inodes\", totalLoaded);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void loadINodeSection(InputStream in, StartupProgress prog,\n        Step currentStep) throws IOException {\n      loadINodeSectionHeader(in, prog, currentStep);\n      Counter counter \u003d prog.getCounter(Phase.LOADING_FSIMAGE, currentStep);\n      int totalLoaded \u003d loadINodesInSection(in, counter);\n      LOG.info(\"Successfully loaded {} inodes\", totalLoaded);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.java",
      "extendedDetails": {}
    }
  }
}