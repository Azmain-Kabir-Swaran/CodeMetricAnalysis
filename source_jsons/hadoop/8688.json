{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSEditLogLoader.java",
  "functionName": "updateBlocks",
  "functionId": "updateBlocks___fsDir-FSDirectory__op-BlockListUpdatingOp__iip-INodesInPath__file-INodeFile__ecPolicy-ErasureCodingPolicy",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java",
  "functionStartLine": 1124,
  "functionEndLine": 1219,
  "numCommitsSeen": 198,
  "timeTaken": 2672,
  "changeHistory": [
    "3749152b661d0359b3b941ab1d17177230f3b8dc",
    "1b5cceaffbdde50a87ede81552dc380832db8e79",
    "b9522e86a55564c2ccb5ca3f1ca871965cbe74de"
  ],
  "changeHistoryShort": {
    "3749152b661d0359b3b941ab1d17177230f3b8dc": "Ybodychange",
    "1b5cceaffbdde50a87ede81552dc380832db8e79": "Ybodychange",
    "b9522e86a55564c2ccb5ca3f1ca871965cbe74de": "Ybodychange"
  },
  "changeHistoryDetails": {
    "3749152b661d0359b3b941ab1d17177230f3b8dc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11416. Refactor out system default erasure coding policy. Contributed by Andrew Wang.\n",
      "commitDate": "02/03/17 7:58 PM",
      "commitName": "3749152b661d0359b3b941ab1d17177230f3b8dc",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "05/12/16 10:54 AM",
      "commitNameOld": "1b5cceaffbdde50a87ede81552dc380832db8e79",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 87.38,
      "commitsBetweenForRepo": 443,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,97 +1,96 @@\n   private void updateBlocks(FSDirectory fsDir, BlockListUpdatingOp op,\n       INodesInPath iip, INodeFile file, ErasureCodingPolicy ecPolicy)\n       throws IOException {\n     // Update its block list\n     BlockInfo[] oldBlocks \u003d file.getBlocks();\n     Block[] newBlocks \u003d op.getBlocks();\n     String path \u003d op.getPath();\n     \n     // Are we only updating the last block\u0027s gen stamp.\n     boolean isGenStampUpdate \u003d oldBlocks.length \u003d\u003d newBlocks.length;\n     \n     // First, update blocks in common\n     for (int i \u003d 0; i \u003c oldBlocks.length \u0026\u0026 i \u003c newBlocks.length; i++) {\n       BlockInfo oldBlock \u003d oldBlocks[i];\n       Block newBlock \u003d newBlocks[i];\n       \n       boolean isLastBlock \u003d i \u003d\u003d newBlocks.length - 1;\n       if (oldBlock.getBlockId() !\u003d newBlock.getBlockId() ||\n           (oldBlock.getGenerationStamp() !\u003d newBlock.getGenerationStamp() \u0026\u0026 \n               !(isGenStampUpdate \u0026\u0026 isLastBlock))) {\n         throw new IOException(\"Mismatched block IDs or generation stamps, \" +\n             \"attempting to replace block \" + oldBlock + \" with \" + newBlock +\n             \" as block # \" + i + \"/\" + newBlocks.length + \" of \" +\n             path);\n       }\n       \n       oldBlock.setNumBytes(newBlock.getNumBytes());\n       boolean changeMade \u003d\n         oldBlock.getGenerationStamp() !\u003d newBlock.getGenerationStamp();\n       oldBlock.setGenerationStamp(newBlock.getGenerationStamp());\n       \n       if (!oldBlock.isComplete() \u0026\u0026\n           (!isLastBlock || op.shouldCompleteLastBlock())) {\n         changeMade \u003d true;\n         fsNamesys.getBlockManager().forceCompleteBlock(oldBlock);\n       }\n       if (changeMade) {\n         // The state or gen-stamp of the block has changed. So, we may be\n         // able to process some messages from datanodes that we previously\n         // were unable to process.\n         fsNamesys.getBlockManager().processQueuedMessagesForBlock(newBlock);\n       }\n     }\n     \n     if (newBlocks.length \u003c oldBlocks.length) {\n       // We\u0027re removing a block from the file, e.g. abandonBlock(...)\n       if (!file.isUnderConstruction()) {\n         throw new IOException(\"Trying to remove a block from file \" +\n             path + \" which is not under construction.\");\n       }\n       if (newBlocks.length !\u003d oldBlocks.length - 1) {\n         throw new IOException(\"Trying to remove more than one block from file \"\n             + path);\n       }\n       Block oldBlock \u003d oldBlocks[oldBlocks.length - 1];\n       boolean removed \u003d FSDirWriteFileOp.unprotectedRemoveBlock(\n           fsDir, path, iip, file, oldBlock);\n       if (!removed \u0026\u0026 !(op instanceof UpdateBlocksOp)) {\n         throw new IOException(\"Trying to delete non-existant block \" + oldBlock);\n       }\n     } else if (newBlocks.length \u003e oldBlocks.length) {\n       final boolean isStriped \u003d ecPolicy !\u003d null;\n       // We\u0027re adding blocks\n       for (int i \u003d oldBlocks.length; i \u003c newBlocks.length; i++) {\n         Block newBlock \u003d newBlocks[i];\n         final BlockInfo newBI;\n         if (!op.shouldCompleteLastBlock()) {\n           // TODO: shouldn\u0027t this only be true for the last block?\n           // what about an old-version fsync() where fsync isn\u0027t called\n           // until several blocks in?\n           if (isStriped) {\n             newBI \u003d new BlockInfoStriped(newBlock, ecPolicy);\n           } else {\n             newBI \u003d new BlockInfoContiguous(newBlock,\n                 file.getPreferredBlockReplication());\n           }\n           newBI.convertToBlockUnderConstruction(\n               BlockUCState.UNDER_CONSTRUCTION, null);\n         } else {\n           // OP_CLOSE should add finalized blocks. This code path\n           // is only executed when loading edits written by prior\n           // versions of Hadoop. Current versions always log\n           // OP_ADD operations as each block is allocated.\n           if (isStriped) {\n-            newBI \u003d new BlockInfoStriped(newBlock,\n-                ErasureCodingPolicyManager.getSystemDefaultPolicy());\n+            newBI \u003d new BlockInfoStriped(newBlock, ecPolicy);\n           } else {\n             newBI \u003d new BlockInfoContiguous(newBlock,\n                 file.getFileReplication());\n           }\n         }\n         fsNamesys.getBlockManager().addBlockCollectionWithCheck(newBI, file);\n         file.addBlock(newBI);\n         fsNamesys.getBlockManager().processQueuedMessagesForBlock(newBlock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void updateBlocks(FSDirectory fsDir, BlockListUpdatingOp op,\n      INodesInPath iip, INodeFile file, ErasureCodingPolicy ecPolicy)\n      throws IOException {\n    // Update its block list\n    BlockInfo[] oldBlocks \u003d file.getBlocks();\n    Block[] newBlocks \u003d op.getBlocks();\n    String path \u003d op.getPath();\n    \n    // Are we only updating the last block\u0027s gen stamp.\n    boolean isGenStampUpdate \u003d oldBlocks.length \u003d\u003d newBlocks.length;\n    \n    // First, update blocks in common\n    for (int i \u003d 0; i \u003c oldBlocks.length \u0026\u0026 i \u003c newBlocks.length; i++) {\n      BlockInfo oldBlock \u003d oldBlocks[i];\n      Block newBlock \u003d newBlocks[i];\n      \n      boolean isLastBlock \u003d i \u003d\u003d newBlocks.length - 1;\n      if (oldBlock.getBlockId() !\u003d newBlock.getBlockId() ||\n          (oldBlock.getGenerationStamp() !\u003d newBlock.getGenerationStamp() \u0026\u0026 \n              !(isGenStampUpdate \u0026\u0026 isLastBlock))) {\n        throw new IOException(\"Mismatched block IDs or generation stamps, \" +\n            \"attempting to replace block \" + oldBlock + \" with \" + newBlock +\n            \" as block # \" + i + \"/\" + newBlocks.length + \" of \" +\n            path);\n      }\n      \n      oldBlock.setNumBytes(newBlock.getNumBytes());\n      boolean changeMade \u003d\n        oldBlock.getGenerationStamp() !\u003d newBlock.getGenerationStamp();\n      oldBlock.setGenerationStamp(newBlock.getGenerationStamp());\n      \n      if (!oldBlock.isComplete() \u0026\u0026\n          (!isLastBlock || op.shouldCompleteLastBlock())) {\n        changeMade \u003d true;\n        fsNamesys.getBlockManager().forceCompleteBlock(oldBlock);\n      }\n      if (changeMade) {\n        // The state or gen-stamp of the block has changed. So, we may be\n        // able to process some messages from datanodes that we previously\n        // were unable to process.\n        fsNamesys.getBlockManager().processQueuedMessagesForBlock(newBlock);\n      }\n    }\n    \n    if (newBlocks.length \u003c oldBlocks.length) {\n      // We\u0027re removing a block from the file, e.g. abandonBlock(...)\n      if (!file.isUnderConstruction()) {\n        throw new IOException(\"Trying to remove a block from file \" +\n            path + \" which is not under construction.\");\n      }\n      if (newBlocks.length !\u003d oldBlocks.length - 1) {\n        throw new IOException(\"Trying to remove more than one block from file \"\n            + path);\n      }\n      Block oldBlock \u003d oldBlocks[oldBlocks.length - 1];\n      boolean removed \u003d FSDirWriteFileOp.unprotectedRemoveBlock(\n          fsDir, path, iip, file, oldBlock);\n      if (!removed \u0026\u0026 !(op instanceof UpdateBlocksOp)) {\n        throw new IOException(\"Trying to delete non-existant block \" + oldBlock);\n      }\n    } else if (newBlocks.length \u003e oldBlocks.length) {\n      final boolean isStriped \u003d ecPolicy !\u003d null;\n      // We\u0027re adding blocks\n      for (int i \u003d oldBlocks.length; i \u003c newBlocks.length; i++) {\n        Block newBlock \u003d newBlocks[i];\n        final BlockInfo newBI;\n        if (!op.shouldCompleteLastBlock()) {\n          // TODO: shouldn\u0027t this only be true for the last block?\n          // what about an old-version fsync() where fsync isn\u0027t called\n          // until several blocks in?\n          if (isStriped) {\n            newBI \u003d new BlockInfoStriped(newBlock, ecPolicy);\n          } else {\n            newBI \u003d new BlockInfoContiguous(newBlock,\n                file.getPreferredBlockReplication());\n          }\n          newBI.convertToBlockUnderConstruction(\n              BlockUCState.UNDER_CONSTRUCTION, null);\n        } else {\n          // OP_CLOSE should add finalized blocks. This code path\n          // is only executed when loading edits written by prior\n          // versions of Hadoop. Current versions always log\n          // OP_ADD operations as each block is allocated.\n          if (isStriped) {\n            newBI \u003d new BlockInfoStriped(newBlock, ecPolicy);\n          } else {\n            newBI \u003d new BlockInfoContiguous(newBlock,\n                file.getFileReplication());\n          }\n        }\n        fsNamesys.getBlockManager().addBlockCollectionWithCheck(newBI, file);\n        file.addBlock(newBI);\n        fsNamesys.getBlockManager().processQueuedMessagesForBlock(newBlock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java",
      "extendedDetails": {}
    },
    "1b5cceaffbdde50a87ede81552dc380832db8e79": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-11201. Spelling errors in the logging, help, assertions and exception messages. Contributed by Grant Sohn.\"\n\nThis reverts commit b9522e86a55564c2ccb5ca3f1ca871965cbe74de.\n",
      "commitDate": "05/12/16 10:54 AM",
      "commitName": "1b5cceaffbdde50a87ede81552dc380832db8e79",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "05/12/16 10:48 AM",
      "commitNameOld": "b9522e86a55564c2ccb5ca3f1ca871965cbe74de",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,97 +1,97 @@\n   private void updateBlocks(FSDirectory fsDir, BlockListUpdatingOp op,\n       INodesInPath iip, INodeFile file, ErasureCodingPolicy ecPolicy)\n       throws IOException {\n     // Update its block list\n     BlockInfo[] oldBlocks \u003d file.getBlocks();\n     Block[] newBlocks \u003d op.getBlocks();\n     String path \u003d op.getPath();\n     \n     // Are we only updating the last block\u0027s gen stamp.\n     boolean isGenStampUpdate \u003d oldBlocks.length \u003d\u003d newBlocks.length;\n     \n     // First, update blocks in common\n     for (int i \u003d 0; i \u003c oldBlocks.length \u0026\u0026 i \u003c newBlocks.length; i++) {\n       BlockInfo oldBlock \u003d oldBlocks[i];\n       Block newBlock \u003d newBlocks[i];\n       \n       boolean isLastBlock \u003d i \u003d\u003d newBlocks.length - 1;\n       if (oldBlock.getBlockId() !\u003d newBlock.getBlockId() ||\n           (oldBlock.getGenerationStamp() !\u003d newBlock.getGenerationStamp() \u0026\u0026 \n               !(isGenStampUpdate \u0026\u0026 isLastBlock))) {\n         throw new IOException(\"Mismatched block IDs or generation stamps, \" +\n             \"attempting to replace block \" + oldBlock + \" with \" + newBlock +\n             \" as block # \" + i + \"/\" + newBlocks.length + \" of \" +\n             path);\n       }\n       \n       oldBlock.setNumBytes(newBlock.getNumBytes());\n       boolean changeMade \u003d\n         oldBlock.getGenerationStamp() !\u003d newBlock.getGenerationStamp();\n       oldBlock.setGenerationStamp(newBlock.getGenerationStamp());\n       \n       if (!oldBlock.isComplete() \u0026\u0026\n           (!isLastBlock || op.shouldCompleteLastBlock())) {\n         changeMade \u003d true;\n         fsNamesys.getBlockManager().forceCompleteBlock(oldBlock);\n       }\n       if (changeMade) {\n         // The state or gen-stamp of the block has changed. So, we may be\n         // able to process some messages from datanodes that we previously\n         // were unable to process.\n         fsNamesys.getBlockManager().processQueuedMessagesForBlock(newBlock);\n       }\n     }\n     \n     if (newBlocks.length \u003c oldBlocks.length) {\n       // We\u0027re removing a block from the file, e.g. abandonBlock(...)\n       if (!file.isUnderConstruction()) {\n         throw new IOException(\"Trying to remove a block from file \" +\n             path + \" which is not under construction.\");\n       }\n       if (newBlocks.length !\u003d oldBlocks.length - 1) {\n         throw new IOException(\"Trying to remove more than one block from file \"\n             + path);\n       }\n       Block oldBlock \u003d oldBlocks[oldBlocks.length - 1];\n       boolean removed \u003d FSDirWriteFileOp.unprotectedRemoveBlock(\n           fsDir, path, iip, file, oldBlock);\n       if (!removed \u0026\u0026 !(op instanceof UpdateBlocksOp)) {\n-        throw new IOException(\"Trying to delete non-existent block \" + oldBlock);\n+        throw new IOException(\"Trying to delete non-existant block \" + oldBlock);\n       }\n     } else if (newBlocks.length \u003e oldBlocks.length) {\n       final boolean isStriped \u003d ecPolicy !\u003d null;\n       // We\u0027re adding blocks\n       for (int i \u003d oldBlocks.length; i \u003c newBlocks.length; i++) {\n         Block newBlock \u003d newBlocks[i];\n         final BlockInfo newBI;\n         if (!op.shouldCompleteLastBlock()) {\n           // TODO: shouldn\u0027t this only be true for the last block?\n           // what about an old-version fsync() where fsync isn\u0027t called\n           // until several blocks in?\n           if (isStriped) {\n             newBI \u003d new BlockInfoStriped(newBlock, ecPolicy);\n           } else {\n             newBI \u003d new BlockInfoContiguous(newBlock,\n                 file.getPreferredBlockReplication());\n           }\n           newBI.convertToBlockUnderConstruction(\n               BlockUCState.UNDER_CONSTRUCTION, null);\n         } else {\n           // OP_CLOSE should add finalized blocks. This code path\n           // is only executed when loading edits written by prior\n           // versions of Hadoop. Current versions always log\n           // OP_ADD operations as each block is allocated.\n           if (isStriped) {\n             newBI \u003d new BlockInfoStriped(newBlock,\n                 ErasureCodingPolicyManager.getSystemDefaultPolicy());\n           } else {\n             newBI \u003d new BlockInfoContiguous(newBlock,\n                 file.getFileReplication());\n           }\n         }\n         fsNamesys.getBlockManager().addBlockCollectionWithCheck(newBI, file);\n         file.addBlock(newBI);\n         fsNamesys.getBlockManager().processQueuedMessagesForBlock(newBlock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void updateBlocks(FSDirectory fsDir, BlockListUpdatingOp op,\n      INodesInPath iip, INodeFile file, ErasureCodingPolicy ecPolicy)\n      throws IOException {\n    // Update its block list\n    BlockInfo[] oldBlocks \u003d file.getBlocks();\n    Block[] newBlocks \u003d op.getBlocks();\n    String path \u003d op.getPath();\n    \n    // Are we only updating the last block\u0027s gen stamp.\n    boolean isGenStampUpdate \u003d oldBlocks.length \u003d\u003d newBlocks.length;\n    \n    // First, update blocks in common\n    for (int i \u003d 0; i \u003c oldBlocks.length \u0026\u0026 i \u003c newBlocks.length; i++) {\n      BlockInfo oldBlock \u003d oldBlocks[i];\n      Block newBlock \u003d newBlocks[i];\n      \n      boolean isLastBlock \u003d i \u003d\u003d newBlocks.length - 1;\n      if (oldBlock.getBlockId() !\u003d newBlock.getBlockId() ||\n          (oldBlock.getGenerationStamp() !\u003d newBlock.getGenerationStamp() \u0026\u0026 \n              !(isGenStampUpdate \u0026\u0026 isLastBlock))) {\n        throw new IOException(\"Mismatched block IDs or generation stamps, \" +\n            \"attempting to replace block \" + oldBlock + \" with \" + newBlock +\n            \" as block # \" + i + \"/\" + newBlocks.length + \" of \" +\n            path);\n      }\n      \n      oldBlock.setNumBytes(newBlock.getNumBytes());\n      boolean changeMade \u003d\n        oldBlock.getGenerationStamp() !\u003d newBlock.getGenerationStamp();\n      oldBlock.setGenerationStamp(newBlock.getGenerationStamp());\n      \n      if (!oldBlock.isComplete() \u0026\u0026\n          (!isLastBlock || op.shouldCompleteLastBlock())) {\n        changeMade \u003d true;\n        fsNamesys.getBlockManager().forceCompleteBlock(oldBlock);\n      }\n      if (changeMade) {\n        // The state or gen-stamp of the block has changed. So, we may be\n        // able to process some messages from datanodes that we previously\n        // were unable to process.\n        fsNamesys.getBlockManager().processQueuedMessagesForBlock(newBlock);\n      }\n    }\n    \n    if (newBlocks.length \u003c oldBlocks.length) {\n      // We\u0027re removing a block from the file, e.g. abandonBlock(...)\n      if (!file.isUnderConstruction()) {\n        throw new IOException(\"Trying to remove a block from file \" +\n            path + \" which is not under construction.\");\n      }\n      if (newBlocks.length !\u003d oldBlocks.length - 1) {\n        throw new IOException(\"Trying to remove more than one block from file \"\n            + path);\n      }\n      Block oldBlock \u003d oldBlocks[oldBlocks.length - 1];\n      boolean removed \u003d FSDirWriteFileOp.unprotectedRemoveBlock(\n          fsDir, path, iip, file, oldBlock);\n      if (!removed \u0026\u0026 !(op instanceof UpdateBlocksOp)) {\n        throw new IOException(\"Trying to delete non-existant block \" + oldBlock);\n      }\n    } else if (newBlocks.length \u003e oldBlocks.length) {\n      final boolean isStriped \u003d ecPolicy !\u003d null;\n      // We\u0027re adding blocks\n      for (int i \u003d oldBlocks.length; i \u003c newBlocks.length; i++) {\n        Block newBlock \u003d newBlocks[i];\n        final BlockInfo newBI;\n        if (!op.shouldCompleteLastBlock()) {\n          // TODO: shouldn\u0027t this only be true for the last block?\n          // what about an old-version fsync() where fsync isn\u0027t called\n          // until several blocks in?\n          if (isStriped) {\n            newBI \u003d new BlockInfoStriped(newBlock, ecPolicy);\n          } else {\n            newBI \u003d new BlockInfoContiguous(newBlock,\n                file.getPreferredBlockReplication());\n          }\n          newBI.convertToBlockUnderConstruction(\n              BlockUCState.UNDER_CONSTRUCTION, null);\n        } else {\n          // OP_CLOSE should add finalized blocks. This code path\n          // is only executed when loading edits written by prior\n          // versions of Hadoop. Current versions always log\n          // OP_ADD operations as each block is allocated.\n          if (isStriped) {\n            newBI \u003d new BlockInfoStriped(newBlock,\n                ErasureCodingPolicyManager.getSystemDefaultPolicy());\n          } else {\n            newBI \u003d new BlockInfoContiguous(newBlock,\n                file.getFileReplication());\n          }\n        }\n        fsNamesys.getBlockManager().addBlockCollectionWithCheck(newBI, file);\n        file.addBlock(newBI);\n        fsNamesys.getBlockManager().processQueuedMessagesForBlock(newBlock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java",
      "extendedDetails": {}
    },
    "b9522e86a55564c2ccb5ca3f1ca871965cbe74de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11201. Spelling errors in the logging, help, assertions and exception messages. Contributed by Grant Sohn.\n",
      "commitDate": "05/12/16 10:48 AM",
      "commitName": "b9522e86a55564c2ccb5ca3f1ca871965cbe74de",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "14/11/16 11:05 AM",
      "commitNameOld": "ff0b99eafeda035ebe0dc82cfe689808047a8893",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 20.99,
      "commitsBetweenForRepo": 120,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,97 +1,97 @@\n   private void updateBlocks(FSDirectory fsDir, BlockListUpdatingOp op,\n       INodesInPath iip, INodeFile file, ErasureCodingPolicy ecPolicy)\n       throws IOException {\n     // Update its block list\n     BlockInfo[] oldBlocks \u003d file.getBlocks();\n     Block[] newBlocks \u003d op.getBlocks();\n     String path \u003d op.getPath();\n     \n     // Are we only updating the last block\u0027s gen stamp.\n     boolean isGenStampUpdate \u003d oldBlocks.length \u003d\u003d newBlocks.length;\n     \n     // First, update blocks in common\n     for (int i \u003d 0; i \u003c oldBlocks.length \u0026\u0026 i \u003c newBlocks.length; i++) {\n       BlockInfo oldBlock \u003d oldBlocks[i];\n       Block newBlock \u003d newBlocks[i];\n       \n       boolean isLastBlock \u003d i \u003d\u003d newBlocks.length - 1;\n       if (oldBlock.getBlockId() !\u003d newBlock.getBlockId() ||\n           (oldBlock.getGenerationStamp() !\u003d newBlock.getGenerationStamp() \u0026\u0026 \n               !(isGenStampUpdate \u0026\u0026 isLastBlock))) {\n         throw new IOException(\"Mismatched block IDs or generation stamps, \" +\n             \"attempting to replace block \" + oldBlock + \" with \" + newBlock +\n             \" as block # \" + i + \"/\" + newBlocks.length + \" of \" +\n             path);\n       }\n       \n       oldBlock.setNumBytes(newBlock.getNumBytes());\n       boolean changeMade \u003d\n         oldBlock.getGenerationStamp() !\u003d newBlock.getGenerationStamp();\n       oldBlock.setGenerationStamp(newBlock.getGenerationStamp());\n       \n       if (!oldBlock.isComplete() \u0026\u0026\n           (!isLastBlock || op.shouldCompleteLastBlock())) {\n         changeMade \u003d true;\n         fsNamesys.getBlockManager().forceCompleteBlock(oldBlock);\n       }\n       if (changeMade) {\n         // The state or gen-stamp of the block has changed. So, we may be\n         // able to process some messages from datanodes that we previously\n         // were unable to process.\n         fsNamesys.getBlockManager().processQueuedMessagesForBlock(newBlock);\n       }\n     }\n     \n     if (newBlocks.length \u003c oldBlocks.length) {\n       // We\u0027re removing a block from the file, e.g. abandonBlock(...)\n       if (!file.isUnderConstruction()) {\n         throw new IOException(\"Trying to remove a block from file \" +\n             path + \" which is not under construction.\");\n       }\n       if (newBlocks.length !\u003d oldBlocks.length - 1) {\n         throw new IOException(\"Trying to remove more than one block from file \"\n             + path);\n       }\n       Block oldBlock \u003d oldBlocks[oldBlocks.length - 1];\n       boolean removed \u003d FSDirWriteFileOp.unprotectedRemoveBlock(\n           fsDir, path, iip, file, oldBlock);\n       if (!removed \u0026\u0026 !(op instanceof UpdateBlocksOp)) {\n-        throw new IOException(\"Trying to delete non-existant block \" + oldBlock);\n+        throw new IOException(\"Trying to delete non-existent block \" + oldBlock);\n       }\n     } else if (newBlocks.length \u003e oldBlocks.length) {\n       final boolean isStriped \u003d ecPolicy !\u003d null;\n       // We\u0027re adding blocks\n       for (int i \u003d oldBlocks.length; i \u003c newBlocks.length; i++) {\n         Block newBlock \u003d newBlocks[i];\n         final BlockInfo newBI;\n         if (!op.shouldCompleteLastBlock()) {\n           // TODO: shouldn\u0027t this only be true for the last block?\n           // what about an old-version fsync() where fsync isn\u0027t called\n           // until several blocks in?\n           if (isStriped) {\n             newBI \u003d new BlockInfoStriped(newBlock, ecPolicy);\n           } else {\n             newBI \u003d new BlockInfoContiguous(newBlock,\n                 file.getPreferredBlockReplication());\n           }\n           newBI.convertToBlockUnderConstruction(\n               BlockUCState.UNDER_CONSTRUCTION, null);\n         } else {\n           // OP_CLOSE should add finalized blocks. This code path\n           // is only executed when loading edits written by prior\n           // versions of Hadoop. Current versions always log\n           // OP_ADD operations as each block is allocated.\n           if (isStriped) {\n             newBI \u003d new BlockInfoStriped(newBlock,\n                 ErasureCodingPolicyManager.getSystemDefaultPolicy());\n           } else {\n             newBI \u003d new BlockInfoContiguous(newBlock,\n                 file.getFileReplication());\n           }\n         }\n         fsNamesys.getBlockManager().addBlockCollectionWithCheck(newBI, file);\n         file.addBlock(newBI);\n         fsNamesys.getBlockManager().processQueuedMessagesForBlock(newBlock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void updateBlocks(FSDirectory fsDir, BlockListUpdatingOp op,\n      INodesInPath iip, INodeFile file, ErasureCodingPolicy ecPolicy)\n      throws IOException {\n    // Update its block list\n    BlockInfo[] oldBlocks \u003d file.getBlocks();\n    Block[] newBlocks \u003d op.getBlocks();\n    String path \u003d op.getPath();\n    \n    // Are we only updating the last block\u0027s gen stamp.\n    boolean isGenStampUpdate \u003d oldBlocks.length \u003d\u003d newBlocks.length;\n    \n    // First, update blocks in common\n    for (int i \u003d 0; i \u003c oldBlocks.length \u0026\u0026 i \u003c newBlocks.length; i++) {\n      BlockInfo oldBlock \u003d oldBlocks[i];\n      Block newBlock \u003d newBlocks[i];\n      \n      boolean isLastBlock \u003d i \u003d\u003d newBlocks.length - 1;\n      if (oldBlock.getBlockId() !\u003d newBlock.getBlockId() ||\n          (oldBlock.getGenerationStamp() !\u003d newBlock.getGenerationStamp() \u0026\u0026 \n              !(isGenStampUpdate \u0026\u0026 isLastBlock))) {\n        throw new IOException(\"Mismatched block IDs or generation stamps, \" +\n            \"attempting to replace block \" + oldBlock + \" with \" + newBlock +\n            \" as block # \" + i + \"/\" + newBlocks.length + \" of \" +\n            path);\n      }\n      \n      oldBlock.setNumBytes(newBlock.getNumBytes());\n      boolean changeMade \u003d\n        oldBlock.getGenerationStamp() !\u003d newBlock.getGenerationStamp();\n      oldBlock.setGenerationStamp(newBlock.getGenerationStamp());\n      \n      if (!oldBlock.isComplete() \u0026\u0026\n          (!isLastBlock || op.shouldCompleteLastBlock())) {\n        changeMade \u003d true;\n        fsNamesys.getBlockManager().forceCompleteBlock(oldBlock);\n      }\n      if (changeMade) {\n        // The state or gen-stamp of the block has changed. So, we may be\n        // able to process some messages from datanodes that we previously\n        // were unable to process.\n        fsNamesys.getBlockManager().processQueuedMessagesForBlock(newBlock);\n      }\n    }\n    \n    if (newBlocks.length \u003c oldBlocks.length) {\n      // We\u0027re removing a block from the file, e.g. abandonBlock(...)\n      if (!file.isUnderConstruction()) {\n        throw new IOException(\"Trying to remove a block from file \" +\n            path + \" which is not under construction.\");\n      }\n      if (newBlocks.length !\u003d oldBlocks.length - 1) {\n        throw new IOException(\"Trying to remove more than one block from file \"\n            + path);\n      }\n      Block oldBlock \u003d oldBlocks[oldBlocks.length - 1];\n      boolean removed \u003d FSDirWriteFileOp.unprotectedRemoveBlock(\n          fsDir, path, iip, file, oldBlock);\n      if (!removed \u0026\u0026 !(op instanceof UpdateBlocksOp)) {\n        throw new IOException(\"Trying to delete non-existent block \" + oldBlock);\n      }\n    } else if (newBlocks.length \u003e oldBlocks.length) {\n      final boolean isStriped \u003d ecPolicy !\u003d null;\n      // We\u0027re adding blocks\n      for (int i \u003d oldBlocks.length; i \u003c newBlocks.length; i++) {\n        Block newBlock \u003d newBlocks[i];\n        final BlockInfo newBI;\n        if (!op.shouldCompleteLastBlock()) {\n          // TODO: shouldn\u0027t this only be true for the last block?\n          // what about an old-version fsync() where fsync isn\u0027t called\n          // until several blocks in?\n          if (isStriped) {\n            newBI \u003d new BlockInfoStriped(newBlock, ecPolicy);\n          } else {\n            newBI \u003d new BlockInfoContiguous(newBlock,\n                file.getPreferredBlockReplication());\n          }\n          newBI.convertToBlockUnderConstruction(\n              BlockUCState.UNDER_CONSTRUCTION, null);\n        } else {\n          // OP_CLOSE should add finalized blocks. This code path\n          // is only executed when loading edits written by prior\n          // versions of Hadoop. Current versions always log\n          // OP_ADD operations as each block is allocated.\n          if (isStriped) {\n            newBI \u003d new BlockInfoStriped(newBlock,\n                ErasureCodingPolicyManager.getSystemDefaultPolicy());\n          } else {\n            newBI \u003d new BlockInfoContiguous(newBlock,\n                file.getFileReplication());\n          }\n        }\n        fsNamesys.getBlockManager().addBlockCollectionWithCheck(newBI, file);\n        file.addBlock(newBI);\n        fsNamesys.getBlockManager().processQueuedMessagesForBlock(newBlock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java",
      "extendedDetails": {}
    }
  }
}