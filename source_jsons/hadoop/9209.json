{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSNamesystem.java",
  "functionName": "isFileDeleted",
  "functionId": "isFileDeleted___file-INodeFile",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
  "functionStartLine": 5651,
  "functionEndLine": 5688,
  "numCommitsSeen": 873,
  "timeTaken": 30228,
  "changeHistory": [
    "52b894db33bc68b46eec5cdf2735dfcf4030853a",
    "52d7bafcf49916887197436ddb0f08f021d248d9",
    "843806d03ab1a24f191782f42eb817505228eb9f",
    "bd616552cce7e46d1cc27ad9aba38f96a1f4c29c"
  ],
  "changeHistoryShort": {
    "52b894db33bc68b46eec5cdf2735dfcf4030853a": "Ybodychange",
    "52d7bafcf49916887197436ddb0f08f021d248d9": "Ymodifierchange",
    "843806d03ab1a24f191782f42eb817505228eb9f": "Ybodychange",
    "bd616552cce7e46d1cc27ad9aba38f96a1f4c29c": "Ybodychange"
  },
  "changeHistoryDetails": {
    "52b894db33bc68b46eec5cdf2735dfcf4030853a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12369. Edit log corruption due to hard lease recovery of not-closed file which has snapshots.\n",
      "commitDate": "07/09/17 4:30 PM",
      "commitName": "52b894db33bc68b46eec5cdf2735dfcf4030853a",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "07/09/17 5:38 AM",
      "commitNameOld": "2adf8bed712e6d770a0d53eea198d8911ae1a258",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 0.45,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,38 @@\n   boolean isFileDeleted(INodeFile file) {\n+    assert hasReadLock();\n     // Not in the inodeMap or in the snapshot but marked deleted.\n     if (dir.getInode(file.getId()) \u003d\u003d null) {\n       return true;\n     }\n \n     // look at the path hierarchy to see if one parent is deleted by recursive\n     // deletion\n     INode tmpChild \u003d file;\n     INodeDirectory tmpParent \u003d file.getParent();\n     while (true) {\n       if (tmpParent \u003d\u003d null) {\n         return true;\n       }\n \n       INode childINode \u003d tmpParent.getChild(tmpChild.getLocalNameBytes(),\n           Snapshot.CURRENT_STATE_ID);\n       if (childINode \u003d\u003d null || !childINode.equals(tmpChild)) {\n         // a newly created INode with the same name as an already deleted one\n         // would be a different INode than the deleted one\n         return true;\n       }\n \n       if (tmpParent.isRoot()) {\n         break;\n       }\n \n       tmpChild \u003d tmpParent;\n       tmpParent \u003d tmpParent.getParent();\n     }\n \n     if (file.isWithSnapshot() \u0026\u0026\n         file.getFileWithSnapshotFeature().isCurrentFileDeleted()) {\n       return true;\n     }\n     return false;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean isFileDeleted(INodeFile file) {\n    assert hasReadLock();\n    // Not in the inodeMap or in the snapshot but marked deleted.\n    if (dir.getInode(file.getId()) \u003d\u003d null) {\n      return true;\n    }\n\n    // look at the path hierarchy to see if one parent is deleted by recursive\n    // deletion\n    INode tmpChild \u003d file;\n    INodeDirectory tmpParent \u003d file.getParent();\n    while (true) {\n      if (tmpParent \u003d\u003d null) {\n        return true;\n      }\n\n      INode childINode \u003d tmpParent.getChild(tmpChild.getLocalNameBytes(),\n          Snapshot.CURRENT_STATE_ID);\n      if (childINode \u003d\u003d null || !childINode.equals(tmpChild)) {\n        // a newly created INode with the same name as an already deleted one\n        // would be a different INode than the deleted one\n        return true;\n      }\n\n      if (tmpParent.isRoot()) {\n        break;\n      }\n\n      tmpChild \u003d tmpParent;\n      tmpParent \u003d tmpParent.getParent();\n    }\n\n    if (file.isWithSnapshot() \u0026\u0026\n        file.getFileWithSnapshotFeature().isCurrentFileDeleted()) {\n      return true;\n    }\n    return false;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "52d7bafcf49916887197436ddb0f08f021d248d9": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-12217. HDFS snapshots doesn\u0027t capture all open files when one of the open files is deleted.\n",
      "commitDate": "01/08/17 4:28 PM",
      "commitName": "52d7bafcf49916887197436ddb0f08f021d248d9",
      "commitAuthor": "Manoj Govindassamy",
      "commitDateOld": "28/07/17 11:24 AM",
      "commitNameOld": "480c8db40c09cd0e25b4d145bc871b70a45d4f50",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 4.21,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,37 @@\n-  private boolean isFileDeleted(INodeFile file) {\n+  boolean isFileDeleted(INodeFile file) {\n     // Not in the inodeMap or in the snapshot but marked deleted.\n     if (dir.getInode(file.getId()) \u003d\u003d null) {\n       return true;\n     }\n \n     // look at the path hierarchy to see if one parent is deleted by recursive\n     // deletion\n     INode tmpChild \u003d file;\n     INodeDirectory tmpParent \u003d file.getParent();\n     while (true) {\n       if (tmpParent \u003d\u003d null) {\n         return true;\n       }\n \n       INode childINode \u003d tmpParent.getChild(tmpChild.getLocalNameBytes(),\n           Snapshot.CURRENT_STATE_ID);\n       if (childINode \u003d\u003d null || !childINode.equals(tmpChild)) {\n         // a newly created INode with the same name as an already deleted one\n         // would be a different INode than the deleted one\n         return true;\n       }\n \n       if (tmpParent.isRoot()) {\n         break;\n       }\n \n       tmpChild \u003d tmpParent;\n       tmpParent \u003d tmpParent.getParent();\n     }\n \n     if (file.isWithSnapshot() \u0026\u0026\n         file.getFileWithSnapshotFeature().isCurrentFileDeleted()) {\n       return true;\n     }\n     return false;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean isFileDeleted(INodeFile file) {\n    // Not in the inodeMap or in the snapshot but marked deleted.\n    if (dir.getInode(file.getId()) \u003d\u003d null) {\n      return true;\n    }\n\n    // look at the path hierarchy to see if one parent is deleted by recursive\n    // deletion\n    INode tmpChild \u003d file;\n    INodeDirectory tmpParent \u003d file.getParent();\n    while (true) {\n      if (tmpParent \u003d\u003d null) {\n        return true;\n      }\n\n      INode childINode \u003d tmpParent.getChild(tmpChild.getLocalNameBytes(),\n          Snapshot.CURRENT_STATE_ID);\n      if (childINode \u003d\u003d null || !childINode.equals(tmpChild)) {\n        // a newly created INode with the same name as an already deleted one\n        // would be a different INode than the deleted one\n        return true;\n      }\n\n      if (tmpParent.isRoot()) {\n        break;\n      }\n\n      tmpChild \u003d tmpParent;\n      tmpParent \u003d tmpParent.getParent();\n    }\n\n    if (file.isWithSnapshot() \u0026\u0026\n        file.getFileWithSnapshotFeature().isCurrentFileDeleted()) {\n      return true;\n    }\n    return false;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {
        "oldValue": "[private]",
        "newValue": "[]"
      }
    },
    "843806d03ab1a24f191782f42eb817505228eb9f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7707. Edit log corruption due to delayed block removal again. Contributed by Yongjun Zhang\n",
      "commitDate": "03/02/15 12:45 PM",
      "commitName": "843806d03ab1a24f191782f42eb817505228eb9f",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "27/01/15 12:58 PM",
      "commitNameOld": "2848db814a98b83e7546f65a2751e56fb5b2dbe0",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 6.99,
      "commitsBetweenForRepo": 47,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,37 @@\n   private boolean isFileDeleted(INodeFile file) {\n     // Not in the inodeMap or in the snapshot but marked deleted.\n     if (dir.getInode(file.getId()) \u003d\u003d null) {\n       return true;\n     }\n \n     // look at the path hierarchy to see if one parent is deleted by recursive\n     // deletion\n     INode tmpChild \u003d file;\n     INodeDirectory tmpParent \u003d file.getParent();\n     while (true) {\n-      if (tmpParent \u003d\u003d null ||\n-          tmpParent.searchChildren(tmpChild.getLocalNameBytes()) \u003c 0) {\n+      if (tmpParent \u003d\u003d null) {\n         return true;\n       }\n+\n+      INode childINode \u003d tmpParent.getChild(tmpChild.getLocalNameBytes(),\n+          Snapshot.CURRENT_STATE_ID);\n+      if (childINode \u003d\u003d null || !childINode.equals(tmpChild)) {\n+        // a newly created INode with the same name as an already deleted one\n+        // would be a different INode than the deleted one\n+        return true;\n+      }\n+\n       if (tmpParent.isRoot()) {\n         break;\n       }\n+\n       tmpChild \u003d tmpParent;\n       tmpParent \u003d tmpParent.getParent();\n     }\n \n     if (file.isWithSnapshot() \u0026\u0026\n         file.getFileWithSnapshotFeature().isCurrentFileDeleted()) {\n       return true;\n     }\n     return false;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean isFileDeleted(INodeFile file) {\n    // Not in the inodeMap or in the snapshot but marked deleted.\n    if (dir.getInode(file.getId()) \u003d\u003d null) {\n      return true;\n    }\n\n    // look at the path hierarchy to see if one parent is deleted by recursive\n    // deletion\n    INode tmpChild \u003d file;\n    INodeDirectory tmpParent \u003d file.getParent();\n    while (true) {\n      if (tmpParent \u003d\u003d null) {\n        return true;\n      }\n\n      INode childINode \u003d tmpParent.getChild(tmpChild.getLocalNameBytes(),\n          Snapshot.CURRENT_STATE_ID);\n      if (childINode \u003d\u003d null || !childINode.equals(tmpChild)) {\n        // a newly created INode with the same name as an already deleted one\n        // would be a different INode than the deleted one\n        return true;\n      }\n\n      if (tmpParent.isRoot()) {\n        break;\n      }\n\n      tmpChild \u003d tmpParent;\n      tmpParent \u003d tmpParent.getParent();\n    }\n\n    if (file.isWithSnapshot() \u0026\u0026\n        file.getFileWithSnapshotFeature().isCurrentFileDeleted()) {\n      return true;\n    }\n    return false;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "bd616552cce7e46d1cc27ad9aba38f96a1f4c29c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6825. Edit log corruption due to delayed block removal. Contributed by Yongjun Zhang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1618684 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/14 11:08 AM",
      "commitName": "bd616552cce7e46d1cc27ad9aba38f96a1f4c29c",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "11/08/14 2:28 PM",
      "commitNameOld": "80691b073fe7c104a8684c0a8900a1657bcdc03f",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 6.86,
      "commitsBetweenForRepo": 68,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,28 @@\n   private boolean isFileDeleted(INodeFile file) {\n     // Not in the inodeMap or in the snapshot but marked deleted.\n-    if (dir.getInode(file.getId()) \u003d\u003d null || \n-        file.getParent() \u003d\u003d null || (file.isWithSnapshot() \u0026\u0026\n-        file.getFileWithSnapshotFeature().isCurrentFileDeleted())) {\n+    if (dir.getInode(file.getId()) \u003d\u003d null) {\n+      return true;\n+    }\n+\n+    // look at the path hierarchy to see if one parent is deleted by recursive\n+    // deletion\n+    INode tmpChild \u003d file;\n+    INodeDirectory tmpParent \u003d file.getParent();\n+    while (true) {\n+      if (tmpParent \u003d\u003d null ||\n+          tmpParent.searchChildren(tmpChild.getLocalNameBytes()) \u003c 0) {\n+        return true;\n+      }\n+      if (tmpParent.isRoot()) {\n+        break;\n+      }\n+      tmpChild \u003d tmpParent;\n+      tmpParent \u003d tmpParent.getParent();\n+    }\n+\n+    if (file.isWithSnapshot() \u0026\u0026\n+        file.getFileWithSnapshotFeature().isCurrentFileDeleted()) {\n       return true;\n     }\n     return false;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean isFileDeleted(INodeFile file) {\n    // Not in the inodeMap or in the snapshot but marked deleted.\n    if (dir.getInode(file.getId()) \u003d\u003d null) {\n      return true;\n    }\n\n    // look at the path hierarchy to see if one parent is deleted by recursive\n    // deletion\n    INode tmpChild \u003d file;\n    INodeDirectory tmpParent \u003d file.getParent();\n    while (true) {\n      if (tmpParent \u003d\u003d null ||\n          tmpParent.searchChildren(tmpChild.getLocalNameBytes()) \u003c 0) {\n        return true;\n      }\n      if (tmpParent.isRoot()) {\n        break;\n      }\n      tmpChild \u003d tmpParent;\n      tmpParent \u003d tmpParent.getParent();\n    }\n\n    if (file.isWithSnapshot() \u0026\u0026\n        file.getFileWithSnapshotFeature().isCurrentFileDeleted()) {\n      return true;\n    }\n    return false;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    }
  }
}