{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSInputStream.java",
  "functionName": "releaseBuffer",
  "functionId": "releaseBuffer___buffer-ByteBuffer",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
  "functionStartLine": 1924,
  "functionEndLine": 1936,
  "numCommitsSeen": 136,
  "timeTaken": 3940,
  "changeHistory": [
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "871cb56152e6039ff56c6fabfcd45451029471c3",
    "173c1159519b6a1885c604b9891a31011b0bcc85",
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f",
    "eccdb9aa8bcdee750583d16a1253f1c5faabd036"
  ],
  "changeHistoryShort": {
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "871cb56152e6039ff56c6fabfcd45451029471c3": "Ybodychange",
    "173c1159519b6a1885c604b9891a31011b0bcc85": "Ybodychange",
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f": "Ybodychange",
    "eccdb9aa8bcdee750583d16a1253f1c5faabd036": "Yintroduced"
  },
  "changeHistoryDetails": {
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public synchronized void releaseBuffer(ByteBuffer buffer) {\n    if (buffer \u003d\u003d EMPTY_BUFFER) return;\n    Object val \u003d getExtendedReadBuffers().remove(buffer);\n    if (val \u003d\u003d null) {\n      throw new IllegalArgumentException(\"tried to release a buffer \" +\n          \"that was not created by this stream, \" + buffer);\n    }\n    if (val instanceof ClientMmap) {\n      IOUtils.closeQuietly((ClientMmap)val);\n    } else if (val instanceof ByteBufferPool) {\n      ((ByteBufferPool)val).putBuffer(buffer);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
      }
    },
    "871cb56152e6039ff56c6fabfcd45451029471c3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7790. Do not create optional fields in DFSInputStream unless they are needed (cmccabe)\n",
      "commitDate": "12/02/15 5:48 PM",
      "commitName": "871cb56152e6039ff56c6fabfcd45451029471c3",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "12/02/15 10:40 AM",
      "commitNameOld": "6b39ad0865cb2a7960dd59d68178f0bf28865ce2",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.3,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   public synchronized void releaseBuffer(ByteBuffer buffer) {\n     if (buffer \u003d\u003d EMPTY_BUFFER) return;\n-    Object val \u003d extendedReadBuffers.remove(buffer);\n+    Object val \u003d getExtendedReadBuffers().remove(buffer);\n     if (val \u003d\u003d null) {\n       throw new IllegalArgumentException(\"tried to release a buffer \" +\n           \"that was not created by this stream, \" + buffer);\n     }\n     if (val instanceof ClientMmap) {\n       IOUtils.closeQuietly((ClientMmap)val);\n     } else if (val instanceof ByteBufferPool) {\n       ((ByteBufferPool)val).putBuffer(buffer);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void releaseBuffer(ByteBuffer buffer) {\n    if (buffer \u003d\u003d EMPTY_BUFFER) return;\n    Object val \u003d getExtendedReadBuffers().remove(buffer);\n    if (val \u003d\u003d null) {\n      throw new IllegalArgumentException(\"tried to release a buffer \" +\n          \"that was not created by this stream, \" + buffer);\n    }\n    if (val instanceof ClientMmap) {\n      IOUtils.closeQuietly((ClientMmap)val);\n    } else if (val instanceof ByteBufferPool) {\n      ((ByteBufferPool)val).putBuffer(buffer);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "173c1159519b6a1885c604b9891a31011b0bcc85": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6065. HDFS zero-copy reads should return null on EOF when doing ZCR (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1575109 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/03/14 5:18 PM",
      "commitName": "173c1159519b6a1885c604b9891a31011b0bcc85",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "04/03/14 1:07 PM",
      "commitNameOld": "c0a903da22c65294b232c7530a6a684ee93daba4",
      "commitAuthorOld": "Michael Stack",
      "daysBetweenCommits": 2.17,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,13 @@\n   public synchronized void releaseBuffer(ByteBuffer buffer) {\n+    if (buffer \u003d\u003d EMPTY_BUFFER) return;\n     Object val \u003d extendedReadBuffers.remove(buffer);\n     if (val \u003d\u003d null) {\n       throw new IllegalArgumentException(\"tried to release a buffer \" +\n           \"that was not created by this stream, \" + buffer);\n     }\n     if (val instanceof ClientMmap) {\n       IOUtils.closeQuietly((ClientMmap)val);\n     } else if (val instanceof ByteBufferPool) {\n       ((ByteBufferPool)val).putBuffer(buffer);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void releaseBuffer(ByteBuffer buffer) {\n    if (buffer \u003d\u003d EMPTY_BUFFER) return;\n    Object val \u003d extendedReadBuffers.remove(buffer);\n    if (val \u003d\u003d null) {\n      throw new IllegalArgumentException(\"tried to release a buffer \" +\n          \"that was not created by this stream, \" + buffer);\n    }\n    if (val instanceof ClientMmap) {\n      IOUtils.closeQuietly((ClientMmap)val);\n    } else if (val instanceof ByteBufferPool) {\n      ((ByteBufferPool)val).putBuffer(buffer);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5950. The DFSClient and DataNode should use shared memory segments to communicate short-circuit information (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1573433 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/03/14 7:58 PM",
      "commitName": "dd049a2f6097da189ccce2f5890a2b9bc77fa73f",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "24/02/14 2:34 PM",
      "commitNameOld": "17db74a1c1972392a5aba48a3e0334dcd6c76487",
      "commitAuthorOld": "Michael Stack",
      "daysBetweenCommits": 6.22,
      "commitsBetweenForRepo": 45,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   public synchronized void releaseBuffer(ByteBuffer buffer) {\n     Object val \u003d extendedReadBuffers.remove(buffer);\n     if (val \u003d\u003d null) {\n       throw new IllegalArgumentException(\"tried to release a buffer \" +\n           \"that was not created by this stream, \" + buffer);\n     }\n     if (val instanceof ClientMmap) {\n-      ((ClientMmap)val).unref();\n+      IOUtils.closeQuietly((ClientMmap)val);\n     } else if (val instanceof ByteBufferPool) {\n       ((ByteBufferPool)val).putBuffer(buffer);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void releaseBuffer(ByteBuffer buffer) {\n    Object val \u003d extendedReadBuffers.remove(buffer);\n    if (val \u003d\u003d null) {\n      throw new IllegalArgumentException(\"tried to release a buffer \" +\n          \"that was not created by this stream, \" + buffer);\n    }\n    if (val instanceof ClientMmap) {\n      IOUtils.closeQuietly((ClientMmap)val);\n    } else if (val instanceof ByteBufferPool) {\n      ((ByteBufferPool)val).putBuffer(buffer);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",
      "extendedDetails": {}
    },
    "eccdb9aa8bcdee750583d16a1253f1c5faabd036": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5260. Merge zero-copy memory-mapped HDFS client reads to trunk and branch-2. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1527113 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/09/13 3:51 PM",
      "commitName": "eccdb9aa8bcdee750583d16a1253f1c5faabd036",
      "commitAuthor": "Chris Nauroth",
      "diff": "@@ -0,0 +1,12 @@\n+  public synchronized void releaseBuffer(ByteBuffer buffer) {\n+    Object val \u003d extendedReadBuffers.remove(buffer);\n+    if (val \u003d\u003d null) {\n+      throw new IllegalArgumentException(\"tried to release a buffer \" +\n+          \"that was not created by this stream, \" + buffer);\n+    }\n+    if (val instanceof ClientMmap) {\n+      ((ClientMmap)val).unref();\n+    } else if (val instanceof ByteBufferPool) {\n+      ((ByteBufferPool)val).putBuffer(buffer);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void releaseBuffer(ByteBuffer buffer) {\n    Object val \u003d extendedReadBuffers.remove(buffer);\n    if (val \u003d\u003d null) {\n      throw new IllegalArgumentException(\"tried to release a buffer \" +\n          \"that was not created by this stream, \" + buffer);\n    }\n    if (val instanceof ClientMmap) {\n      ((ClientMmap)val).unref();\n    } else if (val instanceof ByteBufferPool) {\n      ((ByteBufferPool)val).putBuffer(buffer);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java"
    }
  }
}