{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JobHistoryEventHandler.java",
  "functionName": "closeEventWriter",
  "functionId": "closeEventWriter___jobId-JobId",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
  "functionStartLine": 1433,
  "functionEndLine": 1453,
  "numCommitsSeen": 70,
  "timeTaken": 7861,
  "changeHistory": [
    "2d614a916cc5958b709bddbee71d2dcb9cbb2bf9",
    "015256524c0fdcf0b8ede33e0f620cb2f0fb6064",
    "fffdf661e30afd10331d2153ff052c141b7ebe4b",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "2d614a916cc5958b709bddbee71d2dcb9cbb2bf9": "Ybodychange",
    "015256524c0fdcf0b8ede33e0f620cb2f0fb6064": "Ybodychange",
    "fffdf661e30afd10331d2153ff052c141b7ebe4b": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2d614a916cc5958b709bddbee71d2dcb9cbb2bf9": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5466. Changed MR AM to not promote history files of intermediate AMs in case they are exiting because of errors and thus help history-server pick up the right history file for the last successful AM. Contributed by Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1516238 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/08/13 11:16 AM",
      "commitName": "2d614a916cc5958b709bddbee71d2dcb9cbb2bf9",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "16/06/13 11:39 PM",
      "commitNameOld": "b9efe6bd4a1277b4067ecde715a7713a85968886",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 65.48,
      "commitsBetweenForRepo": 390,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,21 @@\n   protected void closeEventWriter(JobId jobId) throws IOException {\n-\n     final MetaInfo mi \u003d fileMap.get(jobId);\n     if (mi \u003d\u003d null) {\n       throw new IOException(\"No MetaInfo found for JobId: [\" + jobId + \"]\");\n     }\n \n     if (!mi.isWriterActive()) {\n       throw new IOException(\n           \"Inactive Writer: Likely received multiple JobFinished / \" +\n           \"JobUnsuccessful events for JobId: [\"\n               + jobId + \"]\");\n     }\n \n     // Close the Writer\n     try {\n       mi.closeWriter();\n     } catch (IOException e) {\n       LOG.error(\"Error closing writer for JobID: \" + jobId);\n       throw e;\n     }\n-     \n-    if (mi.getHistoryFile() \u003d\u003d null) {\n-      LOG.warn(\"No file for job-history with \" + jobId + \" found in cache!\");\n-    }\n-    if (mi.getConfFile() \u003d\u003d null) {\n-      LOG.warn(\"No file for jobconf with \" + jobId + \" found in cache!\");\n-    }\n-      \n-    // Writing out the summary file.\n-    // TODO JH enhancement - reuse this file to store additional indexing info\n-    // like ACLs, etc. JHServer can use HDFS append to build an index file\n-    // with more info than is available via the filename.\n-    Path qualifiedSummaryDoneFile \u003d null;\n-    FSDataOutputStream summaryFileOut \u003d null;\n-    try {\n-      String doneSummaryFileName \u003d getTempFileName(JobHistoryUtils\n-          .getIntermediateSummaryFileName(jobId));\n-      qualifiedSummaryDoneFile \u003d doneDirFS.makeQualified(new Path(\n-          doneDirPrefixPath, doneSummaryFileName));\n-      summaryFileOut \u003d doneDirFS.create(qualifiedSummaryDoneFile, true);\n-      summaryFileOut.writeUTF(mi.getJobSummary().getJobSummaryString());\n-      summaryFileOut.close();\n-      doneDirFS.setPermission(qualifiedSummaryDoneFile, new FsPermission(\n-          JobHistoryUtils.HISTORY_INTERMEDIATE_FILE_PERMISSIONS));\n-    } catch (IOException e) {\n-      LOG.info(\"Unable to write out JobSummaryInfo to [\"\n-          + qualifiedSummaryDoneFile + \"]\", e);\n-      throw e;\n-    }\n-\n-    try {\n-\n-      // Move historyFile to Done Folder.\n-      Path qualifiedDoneFile \u003d null;\n-      if (mi.getHistoryFile() !\u003d null) {\n-        Path historyFile \u003d mi.getHistoryFile();\n-        Path qualifiedLogFile \u003d stagingDirFS.makeQualified(historyFile);\n-        String doneJobHistoryFileName \u003d\n-            getTempFileName(FileNameIndexUtils.getDoneFileName(mi\n-                .getJobIndexInfo()));\n-        qualifiedDoneFile \u003d\n-            doneDirFS.makeQualified(new Path(doneDirPrefixPath,\n-                doneJobHistoryFileName));\n-        moveToDoneNow(qualifiedLogFile, qualifiedDoneFile);\n-      }\n-\n-      // Move confFile to Done Folder\n-      Path qualifiedConfDoneFile \u003d null;\n-      if (mi.getConfFile() !\u003d null) {\n-        Path confFile \u003d mi.getConfFile();\n-        Path qualifiedConfFile \u003d stagingDirFS.makeQualified(confFile);\n-        String doneConfFileName \u003d\n-            getTempFileName(JobHistoryUtils\n-                .getIntermediateConfFileName(jobId));\n-        qualifiedConfDoneFile \u003d\n-            doneDirFS.makeQualified(new Path(doneDirPrefixPath,\n-                doneConfFileName));\n-        moveToDoneNow(qualifiedConfFile, qualifiedConfDoneFile);\n-      }\n-      \n-      moveTmpToDone(qualifiedSummaryDoneFile);\n-      moveTmpToDone(qualifiedConfDoneFile);\n-      moveTmpToDone(qualifiedDoneFile);\n-\n-    } catch (IOException e) {\n-      LOG.error(\"Error closing writer for JobID: \" + jobId);\n-      throw e;\n-    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void closeEventWriter(JobId jobId) throws IOException {\n    final MetaInfo mi \u003d fileMap.get(jobId);\n    if (mi \u003d\u003d null) {\n      throw new IOException(\"No MetaInfo found for JobId: [\" + jobId + \"]\");\n    }\n\n    if (!mi.isWriterActive()) {\n      throw new IOException(\n          \"Inactive Writer: Likely received multiple JobFinished / \" +\n          \"JobUnsuccessful events for JobId: [\"\n              + jobId + \"]\");\n    }\n\n    // Close the Writer\n    try {\n      mi.closeWriter();\n    } catch (IOException e) {\n      LOG.error(\"Error closing writer for JobID: \" + jobId);\n      throw e;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "015256524c0fdcf0b8ede33e0f620cb2f0fb6064": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4612. job summary file permissions not set when its created (tgraves via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1379584 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/08/12 1:25 PM",
      "commitName": "015256524c0fdcf0b8ede33e0f620cb2f0fb6064",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "10/04/12 1:36 PM",
      "commitNameOld": "2accda38a1e8d658ed1f6da4a583a81a151e17b4",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 142.99,
      "commitsBetweenForRepo": 810,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,88 +1,90 @@\n   protected void closeEventWriter(JobId jobId) throws IOException {\n \n     final MetaInfo mi \u003d fileMap.get(jobId);\n     if (mi \u003d\u003d null) {\n       throw new IOException(\"No MetaInfo found for JobId: [\" + jobId + \"]\");\n     }\n \n     if (!mi.isWriterActive()) {\n       throw new IOException(\n           \"Inactive Writer: Likely received multiple JobFinished / \" +\n           \"JobUnsuccessful events for JobId: [\"\n               + jobId + \"]\");\n     }\n \n     // Close the Writer\n     try {\n       mi.closeWriter();\n     } catch (IOException e) {\n       LOG.error(\"Error closing writer for JobID: \" + jobId);\n       throw e;\n     }\n      \n     if (mi.getHistoryFile() \u003d\u003d null) {\n       LOG.warn(\"No file for job-history with \" + jobId + \" found in cache!\");\n     }\n     if (mi.getConfFile() \u003d\u003d null) {\n       LOG.warn(\"No file for jobconf with \" + jobId + \" found in cache!\");\n     }\n       \n     // Writing out the summary file.\n     // TODO JH enhancement - reuse this file to store additional indexing info\n     // like ACLs, etc. JHServer can use HDFS append to build an index file\n     // with more info than is available via the filename.\n     Path qualifiedSummaryDoneFile \u003d null;\n     FSDataOutputStream summaryFileOut \u003d null;\n     try {\n       String doneSummaryFileName \u003d getTempFileName(JobHistoryUtils\n           .getIntermediateSummaryFileName(jobId));\n       qualifiedSummaryDoneFile \u003d doneDirFS.makeQualified(new Path(\n           doneDirPrefixPath, doneSummaryFileName));\n       summaryFileOut \u003d doneDirFS.create(qualifiedSummaryDoneFile, true);\n       summaryFileOut.writeUTF(mi.getJobSummary().getJobSummaryString());\n       summaryFileOut.close();\n+      doneDirFS.setPermission(qualifiedSummaryDoneFile, new FsPermission(\n+          JobHistoryUtils.HISTORY_INTERMEDIATE_FILE_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.info(\"Unable to write out JobSummaryInfo to [\"\n           + qualifiedSummaryDoneFile + \"]\", e);\n       throw e;\n     }\n \n     try {\n \n       // Move historyFile to Done Folder.\n       Path qualifiedDoneFile \u003d null;\n       if (mi.getHistoryFile() !\u003d null) {\n         Path historyFile \u003d mi.getHistoryFile();\n         Path qualifiedLogFile \u003d stagingDirFS.makeQualified(historyFile);\n         String doneJobHistoryFileName \u003d\n             getTempFileName(FileNameIndexUtils.getDoneFileName(mi\n                 .getJobIndexInfo()));\n         qualifiedDoneFile \u003d\n             doneDirFS.makeQualified(new Path(doneDirPrefixPath,\n                 doneJobHistoryFileName));\n         moveToDoneNow(qualifiedLogFile, qualifiedDoneFile);\n       }\n \n       // Move confFile to Done Folder\n       Path qualifiedConfDoneFile \u003d null;\n       if (mi.getConfFile() !\u003d null) {\n         Path confFile \u003d mi.getConfFile();\n         Path qualifiedConfFile \u003d stagingDirFS.makeQualified(confFile);\n         String doneConfFileName \u003d\n             getTempFileName(JobHistoryUtils\n                 .getIntermediateConfFileName(jobId));\n         qualifiedConfDoneFile \u003d\n             doneDirFS.makeQualified(new Path(doneDirPrefixPath,\n                 doneConfFileName));\n         moveToDoneNow(qualifiedConfFile, qualifiedConfDoneFile);\n       }\n       \n       moveTmpToDone(qualifiedSummaryDoneFile);\n       moveTmpToDone(qualifiedConfDoneFile);\n       moveTmpToDone(qualifiedDoneFile);\n \n     } catch (IOException e) {\n       LOG.error(\"Error closing writer for JobID: \" + jobId);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void closeEventWriter(JobId jobId) throws IOException {\n\n    final MetaInfo mi \u003d fileMap.get(jobId);\n    if (mi \u003d\u003d null) {\n      throw new IOException(\"No MetaInfo found for JobId: [\" + jobId + \"]\");\n    }\n\n    if (!mi.isWriterActive()) {\n      throw new IOException(\n          \"Inactive Writer: Likely received multiple JobFinished / \" +\n          \"JobUnsuccessful events for JobId: [\"\n              + jobId + \"]\");\n    }\n\n    // Close the Writer\n    try {\n      mi.closeWriter();\n    } catch (IOException e) {\n      LOG.error(\"Error closing writer for JobID: \" + jobId);\n      throw e;\n    }\n     \n    if (mi.getHistoryFile() \u003d\u003d null) {\n      LOG.warn(\"No file for job-history with \" + jobId + \" found in cache!\");\n    }\n    if (mi.getConfFile() \u003d\u003d null) {\n      LOG.warn(\"No file for jobconf with \" + jobId + \" found in cache!\");\n    }\n      \n    // Writing out the summary file.\n    // TODO JH enhancement - reuse this file to store additional indexing info\n    // like ACLs, etc. JHServer can use HDFS append to build an index file\n    // with more info than is available via the filename.\n    Path qualifiedSummaryDoneFile \u003d null;\n    FSDataOutputStream summaryFileOut \u003d null;\n    try {\n      String doneSummaryFileName \u003d getTempFileName(JobHistoryUtils\n          .getIntermediateSummaryFileName(jobId));\n      qualifiedSummaryDoneFile \u003d doneDirFS.makeQualified(new Path(\n          doneDirPrefixPath, doneSummaryFileName));\n      summaryFileOut \u003d doneDirFS.create(qualifiedSummaryDoneFile, true);\n      summaryFileOut.writeUTF(mi.getJobSummary().getJobSummaryString());\n      summaryFileOut.close();\n      doneDirFS.setPermission(qualifiedSummaryDoneFile, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_FILE_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.info(\"Unable to write out JobSummaryInfo to [\"\n          + qualifiedSummaryDoneFile + \"]\", e);\n      throw e;\n    }\n\n    try {\n\n      // Move historyFile to Done Folder.\n      Path qualifiedDoneFile \u003d null;\n      if (mi.getHistoryFile() !\u003d null) {\n        Path historyFile \u003d mi.getHistoryFile();\n        Path qualifiedLogFile \u003d stagingDirFS.makeQualified(historyFile);\n        String doneJobHistoryFileName \u003d\n            getTempFileName(FileNameIndexUtils.getDoneFileName(mi\n                .getJobIndexInfo()));\n        qualifiedDoneFile \u003d\n            doneDirFS.makeQualified(new Path(doneDirPrefixPath,\n                doneJobHistoryFileName));\n        moveToDoneNow(qualifiedLogFile, qualifiedDoneFile);\n      }\n\n      // Move confFile to Done Folder\n      Path qualifiedConfDoneFile \u003d null;\n      if (mi.getConfFile() !\u003d null) {\n        Path confFile \u003d mi.getConfFile();\n        Path qualifiedConfFile \u003d stagingDirFS.makeQualified(confFile);\n        String doneConfFileName \u003d\n            getTempFileName(JobHistoryUtils\n                .getIntermediateConfFileName(jobId));\n        qualifiedConfDoneFile \u003d\n            doneDirFS.makeQualified(new Path(doneDirPrefixPath,\n                doneConfFileName));\n        moveToDoneNow(qualifiedConfFile, qualifiedConfDoneFile);\n      }\n      \n      moveTmpToDone(qualifiedSummaryDoneFile);\n      moveTmpToDone(qualifiedConfDoneFile);\n      moveTmpToDone(qualifiedDoneFile);\n\n    } catch (IOException e) {\n      LOG.error(\"Error closing writer for JobID: \" + jobId);\n      throw e;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "fffdf661e30afd10331d2153ff052c141b7ebe4b": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2821. Added missing fields (resourcePerMap \u0026 resourcePerReduce) to JobSummary logs. Contributed by Mahadev Konar.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1188528 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/10/11 11:26 PM",
      "commitName": "fffdf661e30afd10331d2153ff052c141b7ebe4b",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "18/10/11 10:21 PM",
      "commitNameOld": "13e4562924a6cb3d16c262e0f595b2ffbf9e0546",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 6.05,
      "commitsBetweenForRepo": 52,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,88 @@\n   protected void closeEventWriter(JobId jobId) throws IOException {\n \n     final MetaInfo mi \u003d fileMap.get(jobId);\n     if (mi \u003d\u003d null) {\n       throw new IOException(\"No MetaInfo found for JobId: [\" + jobId + \"]\");\n     }\n \n     if (!mi.isWriterActive()) {\n       throw new IOException(\n-          \"Inactive Writer: Likely received multiple JobFinished / JobUnsuccessful events for JobId: [\"\n+          \"Inactive Writer: Likely received multiple JobFinished / \" +\n+          \"JobUnsuccessful events for JobId: [\"\n               + jobId + \"]\");\n     }\n \n     // Close the Writer\n     try {\n       mi.closeWriter();\n     } catch (IOException e) {\n       LOG.error(\"Error closing writer for JobID: \" + jobId);\n       throw e;\n     }\n      \n     if (mi.getHistoryFile() \u003d\u003d null) {\n       LOG.warn(\"No file for job-history with \" + jobId + \" found in cache!\");\n     }\n     if (mi.getConfFile() \u003d\u003d null) {\n       LOG.warn(\"No file for jobconf with \" + jobId + \" found in cache!\");\n     }\n       \n     // Writing out the summary file.\n     // TODO JH enhancement - reuse this file to store additional indexing info\n     // like ACLs, etc. JHServer can use HDFS append to build an index file\n     // with more info than is available via the filename.\n     Path qualifiedSummaryDoneFile \u003d null;\n     FSDataOutputStream summaryFileOut \u003d null;\n     try {\n       String doneSummaryFileName \u003d getTempFileName(JobHistoryUtils\n           .getIntermediateSummaryFileName(jobId));\n       qualifiedSummaryDoneFile \u003d doneDirFS.makeQualified(new Path(\n           doneDirPrefixPath, doneSummaryFileName));\n       summaryFileOut \u003d doneDirFS.create(qualifiedSummaryDoneFile, true);\n       summaryFileOut.writeUTF(mi.getJobSummary().getJobSummaryString());\n       summaryFileOut.close();\n     } catch (IOException e) {\n       LOG.info(\"Unable to write out JobSummaryInfo to [\"\n           + qualifiedSummaryDoneFile + \"]\", e);\n       throw e;\n     }\n \n     try {\n \n       // Move historyFile to Done Folder.\n       Path qualifiedDoneFile \u003d null;\n       if (mi.getHistoryFile() !\u003d null) {\n         Path historyFile \u003d mi.getHistoryFile();\n         Path qualifiedLogFile \u003d stagingDirFS.makeQualified(historyFile);\n         String doneJobHistoryFileName \u003d\n             getTempFileName(FileNameIndexUtils.getDoneFileName(mi\n                 .getJobIndexInfo()));\n         qualifiedDoneFile \u003d\n             doneDirFS.makeQualified(new Path(doneDirPrefixPath,\n                 doneJobHistoryFileName));\n         moveToDoneNow(qualifiedLogFile, qualifiedDoneFile);\n       }\n \n       // Move confFile to Done Folder\n       Path qualifiedConfDoneFile \u003d null;\n       if (mi.getConfFile() !\u003d null) {\n         Path confFile \u003d mi.getConfFile();\n         Path qualifiedConfFile \u003d stagingDirFS.makeQualified(confFile);\n         String doneConfFileName \u003d\n             getTempFileName(JobHistoryUtils\n                 .getIntermediateConfFileName(jobId));\n         qualifiedConfDoneFile \u003d\n             doneDirFS.makeQualified(new Path(doneDirPrefixPath,\n                 doneConfFileName));\n         moveToDoneNow(qualifiedConfFile, qualifiedConfDoneFile);\n       }\n       \n       moveTmpToDone(qualifiedSummaryDoneFile);\n       moveTmpToDone(qualifiedConfDoneFile);\n       moveTmpToDone(qualifiedDoneFile);\n \n     } catch (IOException e) {\n       LOG.error(\"Error closing writer for JobID: \" + jobId);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void closeEventWriter(JobId jobId) throws IOException {\n\n    final MetaInfo mi \u003d fileMap.get(jobId);\n    if (mi \u003d\u003d null) {\n      throw new IOException(\"No MetaInfo found for JobId: [\" + jobId + \"]\");\n    }\n\n    if (!mi.isWriterActive()) {\n      throw new IOException(\n          \"Inactive Writer: Likely received multiple JobFinished / \" +\n          \"JobUnsuccessful events for JobId: [\"\n              + jobId + \"]\");\n    }\n\n    // Close the Writer\n    try {\n      mi.closeWriter();\n    } catch (IOException e) {\n      LOG.error(\"Error closing writer for JobID: \" + jobId);\n      throw e;\n    }\n     \n    if (mi.getHistoryFile() \u003d\u003d null) {\n      LOG.warn(\"No file for job-history with \" + jobId + \" found in cache!\");\n    }\n    if (mi.getConfFile() \u003d\u003d null) {\n      LOG.warn(\"No file for jobconf with \" + jobId + \" found in cache!\");\n    }\n      \n    // Writing out the summary file.\n    // TODO JH enhancement - reuse this file to store additional indexing info\n    // like ACLs, etc. JHServer can use HDFS append to build an index file\n    // with more info than is available via the filename.\n    Path qualifiedSummaryDoneFile \u003d null;\n    FSDataOutputStream summaryFileOut \u003d null;\n    try {\n      String doneSummaryFileName \u003d getTempFileName(JobHistoryUtils\n          .getIntermediateSummaryFileName(jobId));\n      qualifiedSummaryDoneFile \u003d doneDirFS.makeQualified(new Path(\n          doneDirPrefixPath, doneSummaryFileName));\n      summaryFileOut \u003d doneDirFS.create(qualifiedSummaryDoneFile, true);\n      summaryFileOut.writeUTF(mi.getJobSummary().getJobSummaryString());\n      summaryFileOut.close();\n    } catch (IOException e) {\n      LOG.info(\"Unable to write out JobSummaryInfo to [\"\n          + qualifiedSummaryDoneFile + \"]\", e);\n      throw e;\n    }\n\n    try {\n\n      // Move historyFile to Done Folder.\n      Path qualifiedDoneFile \u003d null;\n      if (mi.getHistoryFile() !\u003d null) {\n        Path historyFile \u003d mi.getHistoryFile();\n        Path qualifiedLogFile \u003d stagingDirFS.makeQualified(historyFile);\n        String doneJobHistoryFileName \u003d\n            getTempFileName(FileNameIndexUtils.getDoneFileName(mi\n                .getJobIndexInfo()));\n        qualifiedDoneFile \u003d\n            doneDirFS.makeQualified(new Path(doneDirPrefixPath,\n                doneJobHistoryFileName));\n        moveToDoneNow(qualifiedLogFile, qualifiedDoneFile);\n      }\n\n      // Move confFile to Done Folder\n      Path qualifiedConfDoneFile \u003d null;\n      if (mi.getConfFile() !\u003d null) {\n        Path confFile \u003d mi.getConfFile();\n        Path qualifiedConfFile \u003d stagingDirFS.makeQualified(confFile);\n        String doneConfFileName \u003d\n            getTempFileName(JobHistoryUtils\n                .getIntermediateConfFileName(jobId));\n        qualifiedConfDoneFile \u003d\n            doneDirFS.makeQualified(new Path(doneDirPrefixPath,\n                doneConfFileName));\n        moveToDoneNow(qualifiedConfFile, qualifiedConfDoneFile);\n      }\n      \n      moveTmpToDone(qualifiedSummaryDoneFile);\n      moveTmpToDone(qualifiedConfDoneFile);\n      moveTmpToDone(qualifiedDoneFile);\n\n    } catch (IOException e) {\n      LOG.error(\"Error closing writer for JobID: \" + jobId);\n      throw e;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected void closeEventWriter(JobId jobId) throws IOException {\n\n    final MetaInfo mi \u003d fileMap.get(jobId);\n    if (mi \u003d\u003d null) {\n      throw new IOException(\"No MetaInfo found for JobId: [\" + jobId + \"]\");\n    }\n\n    if (!mi.isWriterActive()) {\n      throw new IOException(\n          \"Inactive Writer: Likely received multiple JobFinished / JobUnsuccessful events for JobId: [\"\n              + jobId + \"]\");\n    }\n\n    // Close the Writer\n    try {\n      mi.closeWriter();\n    } catch (IOException e) {\n      LOG.error(\"Error closing writer for JobID: \" + jobId);\n      throw e;\n    }\n     \n    if (mi.getHistoryFile() \u003d\u003d null) {\n      LOG.warn(\"No file for job-history with \" + jobId + \" found in cache!\");\n    }\n    if (mi.getConfFile() \u003d\u003d null) {\n      LOG.warn(\"No file for jobconf with \" + jobId + \" found in cache!\");\n    }\n      \n    // Writing out the summary file.\n    // TODO JH enhancement - reuse this file to store additional indexing info\n    // like ACLs, etc. JHServer can use HDFS append to build an index file\n    // with more info than is available via the filename.\n    Path qualifiedSummaryDoneFile \u003d null;\n    FSDataOutputStream summaryFileOut \u003d null;\n    try {\n      String doneSummaryFileName \u003d getTempFileName(JobHistoryUtils\n          .getIntermediateSummaryFileName(jobId));\n      qualifiedSummaryDoneFile \u003d doneDirFS.makeQualified(new Path(\n          doneDirPrefixPath, doneSummaryFileName));\n      summaryFileOut \u003d doneDirFS.create(qualifiedSummaryDoneFile, true);\n      summaryFileOut.writeUTF(mi.getJobSummary().getJobSummaryString());\n      summaryFileOut.close();\n    } catch (IOException e) {\n      LOG.info(\"Unable to write out JobSummaryInfo to [\"\n          + qualifiedSummaryDoneFile + \"]\", e);\n      throw e;\n    }\n\n    try {\n\n      // Move historyFile to Done Folder.\n      Path qualifiedDoneFile \u003d null;\n      if (mi.getHistoryFile() !\u003d null) {\n        Path historyFile \u003d mi.getHistoryFile();\n        Path qualifiedLogFile \u003d stagingDirFS.makeQualified(historyFile);\n        String doneJobHistoryFileName \u003d\n            getTempFileName(FileNameIndexUtils.getDoneFileName(mi\n                .getJobIndexInfo()));\n        qualifiedDoneFile \u003d\n            doneDirFS.makeQualified(new Path(doneDirPrefixPath,\n                doneJobHistoryFileName));\n        moveToDoneNow(qualifiedLogFile, qualifiedDoneFile);\n      }\n\n      // Move confFile to Done Folder\n      Path qualifiedConfDoneFile \u003d null;\n      if (mi.getConfFile() !\u003d null) {\n        Path confFile \u003d mi.getConfFile();\n        Path qualifiedConfFile \u003d stagingDirFS.makeQualified(confFile);\n        String doneConfFileName \u003d\n            getTempFileName(JobHistoryUtils\n                .getIntermediateConfFileName(jobId));\n        qualifiedConfDoneFile \u003d\n            doneDirFS.makeQualified(new Path(doneDirPrefixPath,\n                doneConfFileName));\n        moveToDoneNow(qualifiedConfFile, qualifiedConfDoneFile);\n      }\n      \n      moveTmpToDone(qualifiedSummaryDoneFile);\n      moveTmpToDone(qualifiedConfDoneFile);\n      moveTmpToDone(qualifiedDoneFile);\n\n    } catch (IOException e) {\n      LOG.error(\"Error closing writer for JobID: \" + jobId);\n      throw e;\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,87 @@\n+  protected void closeEventWriter(JobId jobId) throws IOException {\n+\n+    final MetaInfo mi \u003d fileMap.get(jobId);\n+    if (mi \u003d\u003d null) {\n+      throw new IOException(\"No MetaInfo found for JobId: [\" + jobId + \"]\");\n+    }\n+\n+    if (!mi.isWriterActive()) {\n+      throw new IOException(\n+          \"Inactive Writer: Likely received multiple JobFinished / JobUnsuccessful events for JobId: [\"\n+              + jobId + \"]\");\n+    }\n+\n+    // Close the Writer\n+    try {\n+      mi.closeWriter();\n+    } catch (IOException e) {\n+      LOG.error(\"Error closing writer for JobID: \" + jobId);\n+      throw e;\n+    }\n+     \n+    if (mi.getHistoryFile() \u003d\u003d null) {\n+      LOG.warn(\"No file for job-history with \" + jobId + \" found in cache!\");\n+    }\n+    if (mi.getConfFile() \u003d\u003d null) {\n+      LOG.warn(\"No file for jobconf with \" + jobId + \" found in cache!\");\n+    }\n+      \n+    // Writing out the summary file.\n+    // TODO JH enhancement - reuse this file to store additional indexing info\n+    // like ACLs, etc. JHServer can use HDFS append to build an index file\n+    // with more info than is available via the filename.\n+    Path qualifiedSummaryDoneFile \u003d null;\n+    FSDataOutputStream summaryFileOut \u003d null;\n+    try {\n+      String doneSummaryFileName \u003d getTempFileName(JobHistoryUtils\n+          .getIntermediateSummaryFileName(jobId));\n+      qualifiedSummaryDoneFile \u003d doneDirFS.makeQualified(new Path(\n+          doneDirPrefixPath, doneSummaryFileName));\n+      summaryFileOut \u003d doneDirFS.create(qualifiedSummaryDoneFile, true);\n+      summaryFileOut.writeUTF(mi.getJobSummary().getJobSummaryString());\n+      summaryFileOut.close();\n+    } catch (IOException e) {\n+      LOG.info(\"Unable to write out JobSummaryInfo to [\"\n+          + qualifiedSummaryDoneFile + \"]\", e);\n+      throw e;\n+    }\n+\n+    try {\n+\n+      // Move historyFile to Done Folder.\n+      Path qualifiedDoneFile \u003d null;\n+      if (mi.getHistoryFile() !\u003d null) {\n+        Path historyFile \u003d mi.getHistoryFile();\n+        Path qualifiedLogFile \u003d stagingDirFS.makeQualified(historyFile);\n+        String doneJobHistoryFileName \u003d\n+            getTempFileName(FileNameIndexUtils.getDoneFileName(mi\n+                .getJobIndexInfo()));\n+        qualifiedDoneFile \u003d\n+            doneDirFS.makeQualified(new Path(doneDirPrefixPath,\n+                doneJobHistoryFileName));\n+        moveToDoneNow(qualifiedLogFile, qualifiedDoneFile);\n+      }\n+\n+      // Move confFile to Done Folder\n+      Path qualifiedConfDoneFile \u003d null;\n+      if (mi.getConfFile() !\u003d null) {\n+        Path confFile \u003d mi.getConfFile();\n+        Path qualifiedConfFile \u003d stagingDirFS.makeQualified(confFile);\n+        String doneConfFileName \u003d\n+            getTempFileName(JobHistoryUtils\n+                .getIntermediateConfFileName(jobId));\n+        qualifiedConfDoneFile \u003d\n+            doneDirFS.makeQualified(new Path(doneDirPrefixPath,\n+                doneConfFileName));\n+        moveToDoneNow(qualifiedConfFile, qualifiedConfDoneFile);\n+      }\n+      \n+      moveTmpToDone(qualifiedSummaryDoneFile);\n+      moveTmpToDone(qualifiedConfDoneFile);\n+      moveTmpToDone(qualifiedDoneFile);\n+\n+    } catch (IOException e) {\n+      LOG.error(\"Error closing writer for JobID: \" + jobId);\n+      throw e;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected void closeEventWriter(JobId jobId) throws IOException {\n\n    final MetaInfo mi \u003d fileMap.get(jobId);\n    if (mi \u003d\u003d null) {\n      throw new IOException(\"No MetaInfo found for JobId: [\" + jobId + \"]\");\n    }\n\n    if (!mi.isWriterActive()) {\n      throw new IOException(\n          \"Inactive Writer: Likely received multiple JobFinished / JobUnsuccessful events for JobId: [\"\n              + jobId + \"]\");\n    }\n\n    // Close the Writer\n    try {\n      mi.closeWriter();\n    } catch (IOException e) {\n      LOG.error(\"Error closing writer for JobID: \" + jobId);\n      throw e;\n    }\n     \n    if (mi.getHistoryFile() \u003d\u003d null) {\n      LOG.warn(\"No file for job-history with \" + jobId + \" found in cache!\");\n    }\n    if (mi.getConfFile() \u003d\u003d null) {\n      LOG.warn(\"No file for jobconf with \" + jobId + \" found in cache!\");\n    }\n      \n    // Writing out the summary file.\n    // TODO JH enhancement - reuse this file to store additional indexing info\n    // like ACLs, etc. JHServer can use HDFS append to build an index file\n    // with more info than is available via the filename.\n    Path qualifiedSummaryDoneFile \u003d null;\n    FSDataOutputStream summaryFileOut \u003d null;\n    try {\n      String doneSummaryFileName \u003d getTempFileName(JobHistoryUtils\n          .getIntermediateSummaryFileName(jobId));\n      qualifiedSummaryDoneFile \u003d doneDirFS.makeQualified(new Path(\n          doneDirPrefixPath, doneSummaryFileName));\n      summaryFileOut \u003d doneDirFS.create(qualifiedSummaryDoneFile, true);\n      summaryFileOut.writeUTF(mi.getJobSummary().getJobSummaryString());\n      summaryFileOut.close();\n    } catch (IOException e) {\n      LOG.info(\"Unable to write out JobSummaryInfo to [\"\n          + qualifiedSummaryDoneFile + \"]\", e);\n      throw e;\n    }\n\n    try {\n\n      // Move historyFile to Done Folder.\n      Path qualifiedDoneFile \u003d null;\n      if (mi.getHistoryFile() !\u003d null) {\n        Path historyFile \u003d mi.getHistoryFile();\n        Path qualifiedLogFile \u003d stagingDirFS.makeQualified(historyFile);\n        String doneJobHistoryFileName \u003d\n            getTempFileName(FileNameIndexUtils.getDoneFileName(mi\n                .getJobIndexInfo()));\n        qualifiedDoneFile \u003d\n            doneDirFS.makeQualified(new Path(doneDirPrefixPath,\n                doneJobHistoryFileName));\n        moveToDoneNow(qualifiedLogFile, qualifiedDoneFile);\n      }\n\n      // Move confFile to Done Folder\n      Path qualifiedConfDoneFile \u003d null;\n      if (mi.getConfFile() !\u003d null) {\n        Path confFile \u003d mi.getConfFile();\n        Path qualifiedConfFile \u003d stagingDirFS.makeQualified(confFile);\n        String doneConfFileName \u003d\n            getTempFileName(JobHistoryUtils\n                .getIntermediateConfFileName(jobId));\n        qualifiedConfDoneFile \u003d\n            doneDirFS.makeQualified(new Path(doneDirPrefixPath,\n                doneConfFileName));\n        moveToDoneNow(qualifiedConfFile, qualifiedConfDoneFile);\n      }\n      \n      moveTmpToDone(qualifiedSummaryDoneFile);\n      moveTmpToDone(qualifiedConfDoneFile);\n      moveTmpToDone(qualifiedDoneFile);\n\n    } catch (IOException e) {\n      LOG.error(\"Error closing writer for JobID: \" + jobId);\n      throw e;\n    }\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java"
    }
  }
}