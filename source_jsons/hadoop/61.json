{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "OpenFileCtxCache.java",
  "functionName": "scan",
  "functionId": "scan___streamTimeout-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtxCache.java",
  "functionStartLine": 148,
  "functionEndLine": 184,
  "numCommitsSeen": 10,
  "timeTaken": 2006,
  "changeHistory": [
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
    "7b1fa5693efc687492776d43ab482601cbb30dfd",
    "d6602b5f39833611b4afa4581552f6c4c37e23a8",
    "b4564103e4709caa1135f6ccc2864d90e54f2ac9",
    "3fccdec6e0a8e9305fc75921211c3745eddb9c45"
  ],
  "changeHistoryShort": {
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568": "Ybodychange",
    "7b1fa5693efc687492776d43ab482601cbb30dfd": "Ybodychange",
    "d6602b5f39833611b4afa4581552f6c4c37e23a8": "Ybodychange",
    "b4564103e4709caa1135f6ccc2864d90e54f2ac9": "Ybodychange",
    "3fccdec6e0a8e9305fc75921211c3745eddb9c45": "Yintroduced"
  },
  "changeHistoryDetails": {
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13695. Move logging to slf4j in HDFS package. Contributed by Ian Pickering.\n",
      "commitDate": "06/09/18 2:48 PM",
      "commitName": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "27/08/18 10:18 AM",
      "commitNameOld": "7b1fa5693efc687492776d43ab482601cbb30dfd",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 10.19,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,37 @@\n   void scan(long streamTimeout) {\n     ArrayList\u003cOpenFileCtx\u003e ctxToRemove \u003d new ArrayList\u003cOpenFileCtx\u003e();\n     Iterator\u003cEntry\u003cFileHandle, OpenFileCtx\u003e\u003e it \u003d openFileMap.entrySet()\n         .iterator();\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"openFileMap size:\" + size());\n     }\n \n     while (it.hasNext()) {\n       Entry\u003cFileHandle, OpenFileCtx\u003e pairs \u003d it.next();\n       FileHandle handle \u003d pairs.getKey();\n       OpenFileCtx ctx \u003d pairs.getValue();\n       if (!ctx.streamCleanup(handle, streamTimeout)) {\n         continue;\n       }\n \n       // Check it again inside lock before removing\n       synchronized (this) {\n         OpenFileCtx ctx2 \u003d openFileMap.get(handle);\n         if (ctx2 !\u003d null) {\n           if (ctx2.streamCleanup(handle, streamTimeout)) {\n             openFileMap.remove(handle);\n             if (LOG.isDebugEnabled()) {\n               LOG.debug(\"After remove stream \" + handle.dumpFileHandle()\n                   + \", the stream number:\" + size());\n             }\n             ctxToRemove.add(ctx2);\n           }\n         }\n       }\n     }\n \n     // Invoke the cleanup outside the lock\n     for (OpenFileCtx ofc : ctxToRemove) {\n-      ofc.cleanupWithLogger();\n+      ofc.cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void scan(long streamTimeout) {\n    ArrayList\u003cOpenFileCtx\u003e ctxToRemove \u003d new ArrayList\u003cOpenFileCtx\u003e();\n    Iterator\u003cEntry\u003cFileHandle, OpenFileCtx\u003e\u003e it \u003d openFileMap.entrySet()\n        .iterator();\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"openFileMap size:\" + size());\n    }\n\n    while (it.hasNext()) {\n      Entry\u003cFileHandle, OpenFileCtx\u003e pairs \u003d it.next();\n      FileHandle handle \u003d pairs.getKey();\n      OpenFileCtx ctx \u003d pairs.getValue();\n      if (!ctx.streamCleanup(handle, streamTimeout)) {\n        continue;\n      }\n\n      // Check it again inside lock before removing\n      synchronized (this) {\n        OpenFileCtx ctx2 \u003d openFileMap.get(handle);\n        if (ctx2 !\u003d null) {\n          if (ctx2.streamCleanup(handle, streamTimeout)) {\n            openFileMap.remove(handle);\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"After remove stream \" + handle.dumpFileHandle()\n                  + \", the stream number:\" + size());\n            }\n            ctxToRemove.add(ctx2);\n          }\n        }\n      }\n    }\n\n    // Invoke the cleanup outside the lock\n    for (OpenFileCtx ofc : ctxToRemove) {\n      ofc.cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtxCache.java",
      "extendedDetails": {}
    },
    "7b1fa5693efc687492776d43ab482601cbb30dfd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13849. Migrate logging to slf4j in hadoop-hdfs-httpfs, hadoop-hdfs-nfs, hadoop-hdfs-rbf, hadoop-hdfs-native-client. Contributed by Ian Pickering.\n",
      "commitDate": "27/08/18 10:18 AM",
      "commitName": "7b1fa5693efc687492776d43ab482601cbb30dfd",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "10/10/17 10:38 AM",
      "commitNameOld": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
      "commitAuthorOld": "Jitendra Pandey",
      "daysBetweenCommits": 320.99,
      "commitsBetweenForRepo": 2846,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,37 @@\n   void scan(long streamTimeout) {\n     ArrayList\u003cOpenFileCtx\u003e ctxToRemove \u003d new ArrayList\u003cOpenFileCtx\u003e();\n     Iterator\u003cEntry\u003cFileHandle, OpenFileCtx\u003e\u003e it \u003d openFileMap.entrySet()\n         .iterator();\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"openFileMap size:\" + size());\n     }\n \n     while (it.hasNext()) {\n       Entry\u003cFileHandle, OpenFileCtx\u003e pairs \u003d it.next();\n       FileHandle handle \u003d pairs.getKey();\n       OpenFileCtx ctx \u003d pairs.getValue();\n       if (!ctx.streamCleanup(handle, streamTimeout)) {\n         continue;\n       }\n \n       // Check it again inside lock before removing\n       synchronized (this) {\n         OpenFileCtx ctx2 \u003d openFileMap.get(handle);\n         if (ctx2 !\u003d null) {\n           if (ctx2.streamCleanup(handle, streamTimeout)) {\n             openFileMap.remove(handle);\n             if (LOG.isDebugEnabled()) {\n               LOG.debug(\"After remove stream \" + handle.dumpFileHandle()\n                   + \", the stream number:\" + size());\n             }\n             ctxToRemove.add(ctx2);\n           }\n         }\n       }\n     }\n \n     // Invoke the cleanup outside the lock\n     for (OpenFileCtx ofc : ctxToRemove) {\n-      ofc.cleanup();\n+      ofc.cleanupWithLogger();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void scan(long streamTimeout) {\n    ArrayList\u003cOpenFileCtx\u003e ctxToRemove \u003d new ArrayList\u003cOpenFileCtx\u003e();\n    Iterator\u003cEntry\u003cFileHandle, OpenFileCtx\u003e\u003e it \u003d openFileMap.entrySet()\n        .iterator();\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"openFileMap size:\" + size());\n    }\n\n    while (it.hasNext()) {\n      Entry\u003cFileHandle, OpenFileCtx\u003e pairs \u003d it.next();\n      FileHandle handle \u003d pairs.getKey();\n      OpenFileCtx ctx \u003d pairs.getValue();\n      if (!ctx.streamCleanup(handle, streamTimeout)) {\n        continue;\n      }\n\n      // Check it again inside lock before removing\n      synchronized (this) {\n        OpenFileCtx ctx2 \u003d openFileMap.get(handle);\n        if (ctx2 !\u003d null) {\n          if (ctx2.streamCleanup(handle, streamTimeout)) {\n            openFileMap.remove(handle);\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"After remove stream \" + handle.dumpFileHandle()\n                  + \", the stream number:\" + size());\n            }\n            ctxToRemove.add(ctx2);\n          }\n        }\n      }\n    }\n\n    // Invoke the cleanup outside the lock\n    for (OpenFileCtx ofc : ctxToRemove) {\n      ofc.cleanupWithLogger();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtxCache.java",
      "extendedDetails": {}
    },
    "d6602b5f39833611b4afa4581552f6c4c37e23a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11575. Supporting HDFS NFS gateway with Federated HDFS. Contributed by Mukul Kumar Singh.\n",
      "commitDate": "10/10/17 10:38 AM",
      "commitName": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
      "commitAuthor": "Jitendra Pandey",
      "commitDateOld": "05/12/16 10:54 AM",
      "commitNameOld": "1b5cceaffbdde50a87ede81552dc380832db8e79",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 308.95,
      "commitsBetweenForRepo": 1916,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,37 @@\n   void scan(long streamTimeout) {\n     ArrayList\u003cOpenFileCtx\u003e ctxToRemove \u003d new ArrayList\u003cOpenFileCtx\u003e();\n     Iterator\u003cEntry\u003cFileHandle, OpenFileCtx\u003e\u003e it \u003d openFileMap.entrySet()\n         .iterator();\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"openFileMap size:\" + size());\n     }\n \n     while (it.hasNext()) {\n       Entry\u003cFileHandle, OpenFileCtx\u003e pairs \u003d it.next();\n       FileHandle handle \u003d pairs.getKey();\n       OpenFileCtx ctx \u003d pairs.getValue();\n-      if (!ctx.streamCleanup(handle.getFileId(), streamTimeout)) {\n+      if (!ctx.streamCleanup(handle, streamTimeout)) {\n         continue;\n       }\n \n       // Check it again inside lock before removing\n       synchronized (this) {\n         OpenFileCtx ctx2 \u003d openFileMap.get(handle);\n         if (ctx2 !\u003d null) {\n-          if (ctx2.streamCleanup(handle.getFileId(), streamTimeout)) {\n+          if (ctx2.streamCleanup(handle, streamTimeout)) {\n             openFileMap.remove(handle);\n             if (LOG.isDebugEnabled()) {\n-              LOG.debug(\"After remove stream \" + handle.getFileId()\n+              LOG.debug(\"After remove stream \" + handle.dumpFileHandle()\n                   + \", the stream number:\" + size());\n             }\n             ctxToRemove.add(ctx2);\n           }\n         }\n       }\n     }\n \n     // Invoke the cleanup outside the lock\n     for (OpenFileCtx ofc : ctxToRemove) {\n       ofc.cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void scan(long streamTimeout) {\n    ArrayList\u003cOpenFileCtx\u003e ctxToRemove \u003d new ArrayList\u003cOpenFileCtx\u003e();\n    Iterator\u003cEntry\u003cFileHandle, OpenFileCtx\u003e\u003e it \u003d openFileMap.entrySet()\n        .iterator();\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"openFileMap size:\" + size());\n    }\n\n    while (it.hasNext()) {\n      Entry\u003cFileHandle, OpenFileCtx\u003e pairs \u003d it.next();\n      FileHandle handle \u003d pairs.getKey();\n      OpenFileCtx ctx \u003d pairs.getValue();\n      if (!ctx.streamCleanup(handle, streamTimeout)) {\n        continue;\n      }\n\n      // Check it again inside lock before removing\n      synchronized (this) {\n        OpenFileCtx ctx2 \u003d openFileMap.get(handle);\n        if (ctx2 !\u003d null) {\n          if (ctx2.streamCleanup(handle, streamTimeout)) {\n            openFileMap.remove(handle);\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"After remove stream \" + handle.dumpFileHandle()\n                  + \", the stream number:\" + size());\n            }\n            ctxToRemove.add(ctx2);\n          }\n        }\n      }\n    }\n\n    // Invoke the cleanup outside the lock\n    for (OpenFileCtx ofc : ctxToRemove) {\n      ofc.cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtxCache.java",
      "extendedDetails": {}
    },
    "b4564103e4709caa1135f6ccc2864d90e54f2ac9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10752. Several log refactoring/improvement suggestion in HDFS. Contributed by Hanisha Koneru.\n",
      "commitDate": "19/10/16 5:20 PM",
      "commitName": "b4564103e4709caa1135f6ccc2864d90e54f2ac9",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "22/10/14 9:27 PM",
      "commitNameOld": "d71d40a63d198991077d5babd70be5e9787a53f1",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 727.83,
      "commitsBetweenForRepo": 5526,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,37 @@\n   void scan(long streamTimeout) {\n     ArrayList\u003cOpenFileCtx\u003e ctxToRemove \u003d new ArrayList\u003cOpenFileCtx\u003e();\n     Iterator\u003cEntry\u003cFileHandle, OpenFileCtx\u003e\u003e it \u003d openFileMap.entrySet()\n         .iterator();\n     if (LOG.isTraceEnabled()) {\n-      LOG.trace(\"openFileMap size:\" + openFileMap.size());\n+      LOG.trace(\"openFileMap size:\" + size());\n     }\n \n     while (it.hasNext()) {\n       Entry\u003cFileHandle, OpenFileCtx\u003e pairs \u003d it.next();\n       FileHandle handle \u003d pairs.getKey();\n       OpenFileCtx ctx \u003d pairs.getValue();\n       if (!ctx.streamCleanup(handle.getFileId(), streamTimeout)) {\n         continue;\n       }\n \n       // Check it again inside lock before removing\n       synchronized (this) {\n         OpenFileCtx ctx2 \u003d openFileMap.get(handle);\n         if (ctx2 !\u003d null) {\n           if (ctx2.streamCleanup(handle.getFileId(), streamTimeout)) {\n             openFileMap.remove(handle);\n             if (LOG.isDebugEnabled()) {\n               LOG.debug(\"After remove stream \" + handle.getFileId()\n-                  + \", the stream number:\" + openFileMap.size());\n+                  + \", the stream number:\" + size());\n             }\n             ctxToRemove.add(ctx2);\n           }\n         }\n       }\n     }\n \n     // Invoke the cleanup outside the lock\n     for (OpenFileCtx ofc : ctxToRemove) {\n       ofc.cleanup();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void scan(long streamTimeout) {\n    ArrayList\u003cOpenFileCtx\u003e ctxToRemove \u003d new ArrayList\u003cOpenFileCtx\u003e();\n    Iterator\u003cEntry\u003cFileHandle, OpenFileCtx\u003e\u003e it \u003d openFileMap.entrySet()\n        .iterator();\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"openFileMap size:\" + size());\n    }\n\n    while (it.hasNext()) {\n      Entry\u003cFileHandle, OpenFileCtx\u003e pairs \u003d it.next();\n      FileHandle handle \u003d pairs.getKey();\n      OpenFileCtx ctx \u003d pairs.getValue();\n      if (!ctx.streamCleanup(handle.getFileId(), streamTimeout)) {\n        continue;\n      }\n\n      // Check it again inside lock before removing\n      synchronized (this) {\n        OpenFileCtx ctx2 \u003d openFileMap.get(handle);\n        if (ctx2 !\u003d null) {\n          if (ctx2.streamCleanup(handle.getFileId(), streamTimeout)) {\n            openFileMap.remove(handle);\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"After remove stream \" + handle.getFileId()\n                  + \", the stream number:\" + size());\n            }\n            ctxToRemove.add(ctx2);\n          }\n        }\n      }\n    }\n\n    // Invoke the cleanup outside the lock\n    for (OpenFileCtx ofc : ctxToRemove) {\n      ofc.cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtxCache.java",
      "extendedDetails": {}
    },
    "3fccdec6e0a8e9305fc75921211c3745eddb9c45": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5364. Add OpenFileCtx cache. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1539834 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/11/13 1:49 PM",
      "commitName": "3fccdec6e0a8e9305fc75921211c3745eddb9c45",
      "commitAuthor": "Brandon Li",
      "diff": "@@ -0,0 +1,37 @@\n+  void scan(long streamTimeout) {\n+    ArrayList\u003cOpenFileCtx\u003e ctxToRemove \u003d new ArrayList\u003cOpenFileCtx\u003e();\n+    Iterator\u003cEntry\u003cFileHandle, OpenFileCtx\u003e\u003e it \u003d openFileMap.entrySet()\n+        .iterator();\n+    if (LOG.isTraceEnabled()) {\n+      LOG.trace(\"openFileMap size:\" + openFileMap.size());\n+    }\n+\n+    while (it.hasNext()) {\n+      Entry\u003cFileHandle, OpenFileCtx\u003e pairs \u003d it.next();\n+      FileHandle handle \u003d pairs.getKey();\n+      OpenFileCtx ctx \u003d pairs.getValue();\n+      if (!ctx.streamCleanup(handle.getFileId(), streamTimeout)) {\n+        continue;\n+      }\n+\n+      // Check it again inside lock before removing\n+      synchronized (this) {\n+        OpenFileCtx ctx2 \u003d openFileMap.get(handle);\n+        if (ctx2 !\u003d null) {\n+          if (ctx2.streamCleanup(handle.getFileId(), streamTimeout)) {\n+            openFileMap.remove(handle);\n+            if (LOG.isDebugEnabled()) {\n+              LOG.debug(\"After remove stream \" + handle.getFileId()\n+                  + \", the stream number:\" + openFileMap.size());\n+            }\n+            ctxToRemove.add(ctx2);\n+          }\n+        }\n+      }\n+    }\n+\n+    // Invoke the cleanup outside the lock\n+    for (OpenFileCtx ofc : ctxToRemove) {\n+      ofc.cleanup();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void scan(long streamTimeout) {\n    ArrayList\u003cOpenFileCtx\u003e ctxToRemove \u003d new ArrayList\u003cOpenFileCtx\u003e();\n    Iterator\u003cEntry\u003cFileHandle, OpenFileCtx\u003e\u003e it \u003d openFileMap.entrySet()\n        .iterator();\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"openFileMap size:\" + openFileMap.size());\n    }\n\n    while (it.hasNext()) {\n      Entry\u003cFileHandle, OpenFileCtx\u003e pairs \u003d it.next();\n      FileHandle handle \u003d pairs.getKey();\n      OpenFileCtx ctx \u003d pairs.getValue();\n      if (!ctx.streamCleanup(handle.getFileId(), streamTimeout)) {\n        continue;\n      }\n\n      // Check it again inside lock before removing\n      synchronized (this) {\n        OpenFileCtx ctx2 \u003d openFileMap.get(handle);\n        if (ctx2 !\u003d null) {\n          if (ctx2.streamCleanup(handle.getFileId(), streamTimeout)) {\n            openFileMap.remove(handle);\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"After remove stream \" + handle.getFileId()\n                  + \", the stream number:\" + openFileMap.size());\n            }\n            ctxToRemove.add(ctx2);\n          }\n        }\n      }\n    }\n\n    // Invoke the cleanup outside the lock\n    for (OpenFileCtx ofc : ctxToRemove) {\n      ofc.cleanup();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtxCache.java"
    }
  }
}