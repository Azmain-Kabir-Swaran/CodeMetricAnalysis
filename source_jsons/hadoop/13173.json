{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Host2NodesMap.java",
  "functionName": "add",
  "functionId": "add___node-DatanodeDescriptor",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/Host2NodesMap.java",
  "functionStartLine": 65,
  "functionEndLine": 92,
  "numCommitsSeen": 14,
  "timeTaken": 4795,
  "changeHistory": [
    "b2f65c276da2c4420a0974a7e2d75e081abf5d63",
    "be7dd8333a7e56e732171db0781786987de03195",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "8327e70be87990c37ac14dcc1cb1a4d209c65593",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "b2f65c276da2c4420a0974a7e2d75e081abf5d63": "Ybodychange",
    "be7dd8333a7e56e732171db0781786987de03195": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "8327e70be87990c37ac14dcc1cb1a4d209c65593": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b2f65c276da2c4420a0974a7e2d75e081abf5d63": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5168. Add cross node dependency support to BlockPlacementPolicy.  Contributed by Nikola Vujic\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1592179 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/05/14 4:02 AM",
      "commitName": "b2f65c276da2c4420a0974a7e2d75e081abf5d63",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "24/03/14 4:32 PM",
      "commitNameOld": "c2ef7e239eb0e81cf8a3e971378e9e696202de67",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 39.48,
      "commitsBetweenForRepo": 242,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,28 @@\n   boolean add(DatanodeDescriptor node) {\n     hostmapLock.writeLock().lock();\n     try {\n       if (node\u003d\u003dnull || contains(node)) {\n         return false;\n       }\n       \n       String ipAddr \u003d node.getIpAddr();\n+      String hostname \u003d node.getHostName();\n+      \n+      mapHost.put(hostname, ipAddr);\n+      \n       DatanodeDescriptor[] nodes \u003d map.get(ipAddr);\n       DatanodeDescriptor[] newNodes;\n       if (nodes\u003d\u003dnull) {\n         newNodes \u003d new DatanodeDescriptor[1];\n         newNodes[0]\u003dnode;\n       } else { // rare case: more than one datanode on the host\n         newNodes \u003d new DatanodeDescriptor[nodes.length+1];\n         System.arraycopy(nodes, 0, newNodes, 0, nodes.length);\n         newNodes[nodes.length] \u003d node;\n       }\n       map.put(ipAddr, newNodes);\n       return true;\n     } finally {\n       hostmapLock.writeLock().unlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean add(DatanodeDescriptor node) {\n    hostmapLock.writeLock().lock();\n    try {\n      if (node\u003d\u003dnull || contains(node)) {\n        return false;\n      }\n      \n      String ipAddr \u003d node.getIpAddr();\n      String hostname \u003d node.getHostName();\n      \n      mapHost.put(hostname, ipAddr);\n      \n      DatanodeDescriptor[] nodes \u003d map.get(ipAddr);\n      DatanodeDescriptor[] newNodes;\n      if (nodes\u003d\u003dnull) {\n        newNodes \u003d new DatanodeDescriptor[1];\n        newNodes[0]\u003dnode;\n      } else { // rare case: more than one datanode on the host\n        newNodes \u003d new DatanodeDescriptor[nodes.length+1];\n        System.arraycopy(nodes, 0, newNodes, 0, nodes.length);\n        newNodes[nodes.length] \u003d node;\n      }\n      map.put(ipAddr, newNodes);\n      return true;\n    } finally {\n      hostmapLock.writeLock().unlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/Host2NodesMap.java",
      "extendedDetails": {}
    },
    "be7dd8333a7e56e732171db0781786987de03195": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3144. Refactor DatanodeID#getName by use. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308205 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/04/12 3:12 PM",
      "commitName": "be7dd8333a7e56e732171db0781786987de03195",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 220.92,
      "commitsBetweenForRepo": 1555,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   boolean add(DatanodeDescriptor node) {\n     hostmapLock.writeLock().lock();\n     try {\n       if (node\u003d\u003dnull || contains(node)) {\n         return false;\n       }\n       \n-      String host \u003d node.getHost();\n-      DatanodeDescriptor[] nodes \u003d map.get(host);\n+      String ipAddr \u003d node.getIpAddr();\n+      DatanodeDescriptor[] nodes \u003d map.get(ipAddr);\n       DatanodeDescriptor[] newNodes;\n       if (nodes\u003d\u003dnull) {\n         newNodes \u003d new DatanodeDescriptor[1];\n         newNodes[0]\u003dnode;\n       } else { // rare case: more than one datanode on the host\n         newNodes \u003d new DatanodeDescriptor[nodes.length+1];\n         System.arraycopy(nodes, 0, newNodes, 0, nodes.length);\n         newNodes[nodes.length] \u003d node;\n       }\n-      map.put(host, newNodes);\n+      map.put(ipAddr, newNodes);\n       return true;\n     } finally {\n       hostmapLock.writeLock().unlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean add(DatanodeDescriptor node) {\n    hostmapLock.writeLock().lock();\n    try {\n      if (node\u003d\u003dnull || contains(node)) {\n        return false;\n      }\n      \n      String ipAddr \u003d node.getIpAddr();\n      DatanodeDescriptor[] nodes \u003d map.get(ipAddr);\n      DatanodeDescriptor[] newNodes;\n      if (nodes\u003d\u003dnull) {\n        newNodes \u003d new DatanodeDescriptor[1];\n        newNodes[0]\u003dnode;\n      } else { // rare case: more than one datanode on the host\n        newNodes \u003d new DatanodeDescriptor[nodes.length+1];\n        System.arraycopy(nodes, 0, newNodes, 0, nodes.length);\n        newNodes[nodes.length] \u003d node;\n      }\n      map.put(ipAddr, newNodes);\n      return true;\n    } finally {\n      hostmapLock.writeLock().unlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/Host2NodesMap.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  boolean add(DatanodeDescriptor node) {\n    hostmapLock.writeLock().lock();\n    try {\n      if (node\u003d\u003dnull || contains(node)) {\n        return false;\n      }\n      \n      String host \u003d node.getHost();\n      DatanodeDescriptor[] nodes \u003d map.get(host);\n      DatanodeDescriptor[] newNodes;\n      if (nodes\u003d\u003dnull) {\n        newNodes \u003d new DatanodeDescriptor[1];\n        newNodes[0]\u003dnode;\n      } else { // rare case: more than one datanode on the host\n        newNodes \u003d new DatanodeDescriptor[nodes.length+1];\n        System.arraycopy(nodes, 0, newNodes, 0, nodes.length);\n        newNodes[nodes.length] \u003d node;\n      }\n      map.put(host, newNodes);\n      return true;\n    } finally {\n      hostmapLock.writeLock().unlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/Host2NodesMap.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/Host2NodesMap.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/Host2NodesMap.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  boolean add(DatanodeDescriptor node) {\n    hostmapLock.writeLock().lock();\n    try {\n      if (node\u003d\u003dnull || contains(node)) {\n        return false;\n      }\n      \n      String host \u003d node.getHost();\n      DatanodeDescriptor[] nodes \u003d map.get(host);\n      DatanodeDescriptor[] newNodes;\n      if (nodes\u003d\u003dnull) {\n        newNodes \u003d new DatanodeDescriptor[1];\n        newNodes[0]\u003dnode;\n      } else { // rare case: more than one datanode on the host\n        newNodes \u003d new DatanodeDescriptor[nodes.length+1];\n        System.arraycopy(nodes, 0, newNodes, 0, nodes.length);\n        newNodes[nodes.length] \u003d node;\n      }\n      map.put(host, newNodes);\n      return true;\n    } finally {\n      hostmapLock.writeLock().unlock();\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/Host2NodesMap.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/Host2NodesMap.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/Host2NodesMap.java"
      }
    },
    "8327e70be87990c37ac14dcc1cb1a4d209c65593": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2140. Move Host2NodesMap to the blockmanagement package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1146514 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/07/11 4:24 PM",
      "commitName": "8327e70be87990c37ac14dcc1cb1a4d209c65593",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "13/07/11 2:17 PM",
      "commitNameOld": "422608d53ebd0eb443accf5211fc221559310434",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.09,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  boolean add(DatanodeDescriptor node) {\n    hostmapLock.writeLock().lock();\n    try {\n      if (node\u003d\u003dnull || contains(node)) {\n        return false;\n      }\n      \n      String host \u003d node.getHost();\n      DatanodeDescriptor[] nodes \u003d map.get(host);\n      DatanodeDescriptor[] newNodes;\n      if (nodes\u003d\u003dnull) {\n        newNodes \u003d new DatanodeDescriptor[1];\n        newNodes[0]\u003dnode;\n      } else { // rare case: more than one datanode on the host\n        newNodes \u003d new DatanodeDescriptor[nodes.length+1];\n        System.arraycopy(nodes, 0, newNodes, 0, nodes.length);\n        newNodes[nodes.length] \u003d node;\n      }\n      map.put(host, newNodes);\n      return true;\n    } finally {\n      hostmapLock.writeLock().unlock();\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/Host2NodesMap.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/Host2NodesMap.java",
        "newPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/Host2NodesMap.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,24 @@\n+  boolean add(DatanodeDescriptor node) {\n+    hostmapLock.writeLock().lock();\n+    try {\n+      if (node\u003d\u003dnull || contains(node)) {\n+        return false;\n+      }\n+      \n+      String host \u003d node.getHost();\n+      DatanodeDescriptor[] nodes \u003d map.get(host);\n+      DatanodeDescriptor[] newNodes;\n+      if (nodes\u003d\u003dnull) {\n+        newNodes \u003d new DatanodeDescriptor[1];\n+        newNodes[0]\u003dnode;\n+      } else { // rare case: more than one datanode on the host\n+        newNodes \u003d new DatanodeDescriptor[nodes.length+1];\n+        System.arraycopy(nodes, 0, newNodes, 0, nodes.length);\n+        newNodes[nodes.length] \u003d node;\n+      }\n+      map.put(host, newNodes);\n+      return true;\n+    } finally {\n+      hostmapLock.writeLock().unlock();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  boolean add(DatanodeDescriptor node) {\n    hostmapLock.writeLock().lock();\n    try {\n      if (node\u003d\u003dnull || contains(node)) {\n        return false;\n      }\n      \n      String host \u003d node.getHost();\n      DatanodeDescriptor[] nodes \u003d map.get(host);\n      DatanodeDescriptor[] newNodes;\n      if (nodes\u003d\u003dnull) {\n        newNodes \u003d new DatanodeDescriptor[1];\n        newNodes[0]\u003dnode;\n      } else { // rare case: more than one datanode on the host\n        newNodes \u003d new DatanodeDescriptor[nodes.length+1];\n        System.arraycopy(nodes, 0, newNodes, 0, nodes.length);\n        newNodes[nodes.length] \u003d node;\n      }\n      map.put(host, newNodes);\n      return true;\n    } finally {\n      hostmapLock.writeLock().unlock();\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/Host2NodesMap.java"
    }
  }
}