{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AbstractS3ACommitter.java",
  "functionName": "maybeCreateSuccessMarkerFromCommits",
  "functionId": "maybeCreateSuccessMarkerFromCommits___context-JobContext__pending-ActiveCommit",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/AbstractS3ACommitter.java",
  "functionStartLine": 370,
  "functionEndLine": 377,
  "numCommitsSeen": 11,
  "timeTaken": 3140,
  "changeHistory": [
    "6574f27fa348542411bff888b184cd7ce34e5d9e",
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c"
  ],
  "changeHistoryShort": {
    "6574f27fa348542411bff888b184cd7ce34e5d9e": "Ymultichange(Yparameterchange,Ybodychange)",
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6574f27fa348542411bff888b184cd7ce34e5d9e": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HADOOP-16570. S3A committers encounter scale issues.\n\nContributed by Steve Loughran.\n\nThis addresses two scale issues which has surfaced in large scale benchmarks\nof the S3A Committers.\n\n* Thread pools are not cleaned up.\n  This now happens, with tests.\n\n* OOM on job commit for jobs with many thousands of tasks,\n  each generating tens of (very large) files.\n\nInstead of loading all pending commits into memory as a single list, the list\nof files to load is the sole list which is passed around; .pendingset files are\nloaded and processed in isolation -and reloaded if necessary for any\nabort/rollback operation.\n\nThe parallel commit/abort/revert operations now work at the .pendingset level,\nrather than that of individual pending commit files. The existing parallelized\nTasks API is still used to commit those files, but with a null thread pool, so\nas to serialize the operations.\n\nChange-Id: I5c8240cd31800eaa83d112358770ca0eb2bca797\n",
      "commitDate": "04/10/19 10:54 AM",
      "commitName": "6574f27fa348542411bff888b184cd7ce34e5d9e",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-16570. S3A committers encounter scale issues.\n\nContributed by Steve Loughran.\n\nThis addresses two scale issues which has surfaced in large scale benchmarks\nof the S3A Committers.\n\n* Thread pools are not cleaned up.\n  This now happens, with tests.\n\n* OOM on job commit for jobs with many thousands of tasks,\n  each generating tens of (very large) files.\n\nInstead of loading all pending commits into memory as a single list, the list\nof files to load is the sole list which is passed around; .pendingset files are\nloaded and processed in isolation -and reloaded if necessary for any\nabort/rollback operation.\n\nThe parallel commit/abort/revert operations now work at the .pendingset level,\nrather than that of individual pending commit files. The existing parallelized\nTasks API is still used to commit those files, but with a null thread pool, so\nas to serialize the operations.\n\nChange-Id: I5c8240cd31800eaa83d112358770ca0eb2bca797\n",
          "commitDate": "04/10/19 10:54 AM",
          "commitName": "6574f27fa348542411bff888b184cd7ce34e5d9e",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "20/06/19 1:56 AM",
          "commitNameOld": "e02eb24e0a9139418120027b694492e0738df20a",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 106.37,
          "commitsBetweenForRepo": 952,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,8 @@\n   protected void maybeCreateSuccessMarkerFromCommits(JobContext context,\n-      List\u003cSinglePendingCommit\u003e pending) throws IOException {\n+      ActiveCommit pending) throws IOException {\n     List\u003cString\u003e filenames \u003d new ArrayList\u003c\u003e(pending.size());\n-    for (SinglePendingCommit commit : pending) {\n-      String key \u003d commit.getDestinationKey();\n-      if (!key.startsWith(\"/\")) {\n-        // fix up so that FS.makeQualified() sets up the path OK\n-        key \u003d \"/\" + key;\n-      }\n-      filenames.add(key);\n-    }\n+    // The list of committed objects in pending is size limited in\n+    // ActiveCommit.uploadCommitted.\n+    filenames.addAll(pending.committedObjects);\n     maybeCreateSuccessMarker(context, filenames);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void maybeCreateSuccessMarkerFromCommits(JobContext context,\n      ActiveCommit pending) throws IOException {\n    List\u003cString\u003e filenames \u003d new ArrayList\u003c\u003e(pending.size());\n    // The list of committed objects in pending is size limited in\n    // ActiveCommit.uploadCommitted.\n    filenames.addAll(pending.committedObjects);\n    maybeCreateSuccessMarker(context, filenames);\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/AbstractS3ACommitter.java",
          "extendedDetails": {
            "oldValue": "[context-JobContext, pending-List\u003cSinglePendingCommit\u003e]",
            "newValue": "[context-JobContext, pending-ActiveCommit]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-16570. S3A committers encounter scale issues.\n\nContributed by Steve Loughran.\n\nThis addresses two scale issues which has surfaced in large scale benchmarks\nof the S3A Committers.\n\n* Thread pools are not cleaned up.\n  This now happens, with tests.\n\n* OOM on job commit for jobs with many thousands of tasks,\n  each generating tens of (very large) files.\n\nInstead of loading all pending commits into memory as a single list, the list\nof files to load is the sole list which is passed around; .pendingset files are\nloaded and processed in isolation -and reloaded if necessary for any\nabort/rollback operation.\n\nThe parallel commit/abort/revert operations now work at the .pendingset level,\nrather than that of individual pending commit files. The existing parallelized\nTasks API is still used to commit those files, but with a null thread pool, so\nas to serialize the operations.\n\nChange-Id: I5c8240cd31800eaa83d112358770ca0eb2bca797\n",
          "commitDate": "04/10/19 10:54 AM",
          "commitName": "6574f27fa348542411bff888b184cd7ce34e5d9e",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "20/06/19 1:56 AM",
          "commitNameOld": "e02eb24e0a9139418120027b694492e0738df20a",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 106.37,
          "commitsBetweenForRepo": 952,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,8 @@\n   protected void maybeCreateSuccessMarkerFromCommits(JobContext context,\n-      List\u003cSinglePendingCommit\u003e pending) throws IOException {\n+      ActiveCommit pending) throws IOException {\n     List\u003cString\u003e filenames \u003d new ArrayList\u003c\u003e(pending.size());\n-    for (SinglePendingCommit commit : pending) {\n-      String key \u003d commit.getDestinationKey();\n-      if (!key.startsWith(\"/\")) {\n-        // fix up so that FS.makeQualified() sets up the path OK\n-        key \u003d \"/\" + key;\n-      }\n-      filenames.add(key);\n-    }\n+    // The list of committed objects in pending is size limited in\n+    // ActiveCommit.uploadCommitted.\n+    filenames.addAll(pending.committedObjects);\n     maybeCreateSuccessMarker(context, filenames);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void maybeCreateSuccessMarkerFromCommits(JobContext context,\n      ActiveCommit pending) throws IOException {\n    List\u003cString\u003e filenames \u003d new ArrayList\u003c\u003e(pending.size());\n    // The list of committed objects in pending is size limited in\n    // ActiveCommit.uploadCommitted.\n    filenames.addAll(pending.committedObjects);\n    maybeCreateSuccessMarker(context, filenames);\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/AbstractS3ACommitter.java",
          "extendedDetails": {}
        }
      ]
    },
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13786 Add S3A committer for zero-rename commits to S3 endpoints.\nContributed by Steve Loughran and Ryan Blue.\n",
      "commitDate": "22/11/17 7:28 AM",
      "commitName": "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,13 @@\n+  protected void maybeCreateSuccessMarkerFromCommits(JobContext context,\n+      List\u003cSinglePendingCommit\u003e pending) throws IOException {\n+    List\u003cString\u003e filenames \u003d new ArrayList\u003c\u003e(pending.size());\n+    for (SinglePendingCommit commit : pending) {\n+      String key \u003d commit.getDestinationKey();\n+      if (!key.startsWith(\"/\")) {\n+        // fix up so that FS.makeQualified() sets up the path OK\n+        key \u003d \"/\" + key;\n+      }\n+      filenames.add(key);\n+    }\n+    maybeCreateSuccessMarker(context, filenames);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected void maybeCreateSuccessMarkerFromCommits(JobContext context,\n      List\u003cSinglePendingCommit\u003e pending) throws IOException {\n    List\u003cString\u003e filenames \u003d new ArrayList\u003c\u003e(pending.size());\n    for (SinglePendingCommit commit : pending) {\n      String key \u003d commit.getDestinationKey();\n      if (!key.startsWith(\"/\")) {\n        // fix up so that FS.makeQualified() sets up the path OK\n        key \u003d \"/\" + key;\n      }\n      filenames.add(key);\n    }\n    maybeCreateSuccessMarker(context, filenames);\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/AbstractS3ACommitter.java"
    }
  }
}