{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "getDatanodeDescriptors",
  "functionId": "getDatanodeDescriptors___nodes-List__String__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 2332,
  "functionEndLine": 2344,
  "numCommitsSeen": 477,
  "timeTaken": 15286,
  "changeHistory": [
    "663eba0ab1c73b45f98e46ffc87ad8fd91584046",
    "bc99aaffe7b0ed13b1efc37b6a32cdbd344c2d75",
    "d62b63d297bff12d93de560dd50ddd48743b851d",
    "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5",
    "5d2ffde68e2c14ee33fa2ba4a34cb42fbd14b5ec"
  ],
  "changeHistoryShort": {
    "663eba0ab1c73b45f98e46ffc87ad8fd91584046": "Ybodychange",
    "bc99aaffe7b0ed13b1efc37b6a32cdbd344c2d75": "Ybodychange",
    "d62b63d297bff12d93de560dd50ddd48743b851d": "Ybodychange",
    "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5": "Ybodychange",
    "5d2ffde68e2c14ee33fa2ba4a34cb42fbd14b5ec": "Yintroduced"
  },
  "changeHistoryDetails": {
    "663eba0ab1c73b45f98e46ffc87ad8fd91584046": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-8623. Refactor NameNode handling of invalid, corrupt, and under-recovery blocks. Contributed by Zhe Zhang.\"\n\nThis reverts commit de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5.\n",
      "commitDate": "06/08/15 10:21 AM",
      "commitName": "663eba0ab1c73b45f98e46ffc87ad8fd91584046",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "31/07/15 4:15 PM",
      "commitNameOld": "d311a38a6b32bbb210bd8748cfb65463e9c0740e",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 5.75,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   List\u003cDatanodeDescriptor\u003e getDatanodeDescriptors(List\u003cString\u003e nodes) {\n     List\u003cDatanodeDescriptor\u003e datanodeDescriptors \u003d null;\n     if (nodes !\u003d null) {\n-      datanodeDescriptors \u003d new ArrayList\u003c\u003e(nodes.size());\n+      datanodeDescriptors \u003d new ArrayList\u003cDatanodeDescriptor\u003e(nodes.size());\n       for (int i \u003d 0; i \u003c nodes.size(); i++) {\n         DatanodeDescriptor node \u003d datanodeManager.getDatanodeDescriptor(nodes.get(i));\n         if (node !\u003d null) {\n           datanodeDescriptors.add(node);\n         }\n       }\n     }\n     return datanodeDescriptors;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  List\u003cDatanodeDescriptor\u003e getDatanodeDescriptors(List\u003cString\u003e nodes) {\n    List\u003cDatanodeDescriptor\u003e datanodeDescriptors \u003d null;\n    if (nodes !\u003d null) {\n      datanodeDescriptors \u003d new ArrayList\u003cDatanodeDescriptor\u003e(nodes.size());\n      for (int i \u003d 0; i \u003c nodes.size(); i++) {\n        DatanodeDescriptor node \u003d datanodeManager.getDatanodeDescriptor(nodes.get(i));\n        if (node !\u003d null) {\n          datanodeDescriptors.add(node);\n        }\n      }\n    }\n    return datanodeDescriptors;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "bc99aaffe7b0ed13b1efc37b6a32cdbd344c2d75": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-8652. Track BlockInfo instead of Block in CorruptReplicasMap. Contributed by Jing Zhao.\"\n\nThis reverts commit d62b63d297bff12d93de560dd50ddd48743b851d.\n",
      "commitDate": "07/07/15 10:13 AM",
      "commitName": "bc99aaffe7b0ed13b1efc37b6a32cdbd344c2d75",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "06/07/15 3:54 PM",
      "commitNameOld": "d62b63d297bff12d93de560dd50ddd48743b851d",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.76,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   List\u003cDatanodeDescriptor\u003e getDatanodeDescriptors(List\u003cString\u003e nodes) {\n     List\u003cDatanodeDescriptor\u003e datanodeDescriptors \u003d null;\n     if (nodes !\u003d null) {\n       datanodeDescriptors \u003d new ArrayList\u003c\u003e(nodes.size());\n-      for (String nodeStr : nodes) {\n-        DatanodeDescriptor node \u003d datanodeManager.getDatanodeDescriptor(nodeStr);\n+      for (int i \u003d 0; i \u003c nodes.size(); i++) {\n+        DatanodeDescriptor node \u003d datanodeManager.getDatanodeDescriptor(nodes.get(i));\n         if (node !\u003d null) {\n           datanodeDescriptors.add(node);\n         }\n       }\n     }\n     return datanodeDescriptors;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  List\u003cDatanodeDescriptor\u003e getDatanodeDescriptors(List\u003cString\u003e nodes) {\n    List\u003cDatanodeDescriptor\u003e datanodeDescriptors \u003d null;\n    if (nodes !\u003d null) {\n      datanodeDescriptors \u003d new ArrayList\u003c\u003e(nodes.size());\n      for (int i \u003d 0; i \u003c nodes.size(); i++) {\n        DatanodeDescriptor node \u003d datanodeManager.getDatanodeDescriptor(nodes.get(i));\n        if (node !\u003d null) {\n          datanodeDescriptors.add(node);\n        }\n      }\n    }\n    return datanodeDescriptors;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "d62b63d297bff12d93de560dd50ddd48743b851d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8652. Track BlockInfo instead of Block in CorruptReplicasMap. Contributed by Jing Zhao.\n",
      "commitDate": "06/07/15 3:54 PM",
      "commitName": "d62b63d297bff12d93de560dd50ddd48743b851d",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "29/06/15 11:00 AM",
      "commitNameOld": "d3fed8e653ed9e18d3a29a11c4b24a628ac770bb",
      "commitAuthorOld": "Benoy Antony",
      "daysBetweenCommits": 7.2,
      "commitsBetweenForRepo": 50,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   List\u003cDatanodeDescriptor\u003e getDatanodeDescriptors(List\u003cString\u003e nodes) {\n     List\u003cDatanodeDescriptor\u003e datanodeDescriptors \u003d null;\n     if (nodes !\u003d null) {\n       datanodeDescriptors \u003d new ArrayList\u003c\u003e(nodes.size());\n-      for (int i \u003d 0; i \u003c nodes.size(); i++) {\n-        DatanodeDescriptor node \u003d datanodeManager.getDatanodeDescriptor(nodes.get(i));\n+      for (String nodeStr : nodes) {\n+        DatanodeDescriptor node \u003d datanodeManager.getDatanodeDescriptor(nodeStr);\n         if (node !\u003d null) {\n           datanodeDescriptors.add(node);\n         }\n       }\n     }\n     return datanodeDescriptors;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  List\u003cDatanodeDescriptor\u003e getDatanodeDescriptors(List\u003cString\u003e nodes) {\n    List\u003cDatanodeDescriptor\u003e datanodeDescriptors \u003d null;\n    if (nodes !\u003d null) {\n      datanodeDescriptors \u003d new ArrayList\u003c\u003e(nodes.size());\n      for (String nodeStr : nodes) {\n        DatanodeDescriptor node \u003d datanodeManager.getDatanodeDescriptor(nodeStr);\n        if (node !\u003d null) {\n          datanodeDescriptors.add(node);\n        }\n      }\n    }\n    return datanodeDescriptors;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8623. Refactor NameNode handling of invalid, corrupt, and under-recovery blocks. Contributed by Zhe Zhang.\n",
      "commitDate": "26/06/15 10:49 AM",
      "commitName": "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "24/06/15 2:42 PM",
      "commitNameOld": "afe9ea3c12e1f5a71922400eadb642960bc87ca1",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 1.84,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   List\u003cDatanodeDescriptor\u003e getDatanodeDescriptors(List\u003cString\u003e nodes) {\n     List\u003cDatanodeDescriptor\u003e datanodeDescriptors \u003d null;\n     if (nodes !\u003d null) {\n-      datanodeDescriptors \u003d new ArrayList\u003cDatanodeDescriptor\u003e(nodes.size());\n+      datanodeDescriptors \u003d new ArrayList\u003c\u003e(nodes.size());\n       for (int i \u003d 0; i \u003c nodes.size(); i++) {\n         DatanodeDescriptor node \u003d datanodeManager.getDatanodeDescriptor(nodes.get(i));\n         if (node !\u003d null) {\n           datanodeDescriptors.add(node);\n         }\n       }\n     }\n     return datanodeDescriptors;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  List\u003cDatanodeDescriptor\u003e getDatanodeDescriptors(List\u003cString\u003e nodes) {\n    List\u003cDatanodeDescriptor\u003e datanodeDescriptors \u003d null;\n    if (nodes !\u003d null) {\n      datanodeDescriptors \u003d new ArrayList\u003c\u003e(nodes.size());\n      for (int i \u003d 0; i \u003c nodes.size(); i++) {\n        DatanodeDescriptor node \u003d datanodeManager.getDatanodeDescriptor(nodes.get(i));\n        if (node !\u003d null) {\n          datanodeDescriptors.add(node);\n        }\n      }\n    }\n    return datanodeDescriptors;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "5d2ffde68e2c14ee33fa2ba4a34cb42fbd14b5ec": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2576. Enhances the DistributedFileSystem\u0027s create API so that clients can specify favored datanodes for a file\u0027s blocks. Contributed by Devaraj Das and Pritam Damania.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1476395 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/04/13 1:39 PM",
      "commitName": "5d2ffde68e2c14ee33fa2ba4a34cb42fbd14b5ec",
      "commitAuthor": "Devaraj Das",
      "diff": "@@ -0,0 +1,13 @@\n+  List\u003cDatanodeDescriptor\u003e getDatanodeDescriptors(List\u003cString\u003e nodes) {\n+    List\u003cDatanodeDescriptor\u003e datanodeDescriptors \u003d null;\n+    if (nodes !\u003d null) {\n+      datanodeDescriptors \u003d new ArrayList\u003cDatanodeDescriptor\u003e(nodes.size());\n+      for (int i \u003d 0; i \u003c nodes.size(); i++) {\n+        DatanodeDescriptor node \u003d datanodeManager.getDatanodeDescriptor(nodes.get(i));\n+        if (node !\u003d null) {\n+          datanodeDescriptors.add(node);\n+        }\n+      }\n+    }\n+    return datanodeDescriptors;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  List\u003cDatanodeDescriptor\u003e getDatanodeDescriptors(List\u003cString\u003e nodes) {\n    List\u003cDatanodeDescriptor\u003e datanodeDescriptors \u003d null;\n    if (nodes !\u003d null) {\n      datanodeDescriptors \u003d new ArrayList\u003cDatanodeDescriptor\u003e(nodes.size());\n      for (int i \u003d 0; i \u003c nodes.size(); i++) {\n        DatanodeDescriptor node \u003d datanodeManager.getDatanodeDescriptor(nodes.get(i));\n        if (node !\u003d null) {\n          datanodeDescriptors.add(node);\n        }\n      }\n    }\n    return datanodeDescriptors;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
    }
  }
}