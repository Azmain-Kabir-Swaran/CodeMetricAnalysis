{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LowRedundancyBlocks.java",
  "functionName": "incrementBlockStat",
  "functionId": "incrementBlockStat___blockInfo-BlockInfo__priLevel-int__expectedReplicas-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java",
  "functionStartLine": 312,
  "functionEndLine": 334,
  "numCommitsSeen": 8,
  "timeTaken": 2583,
  "changeHistory": [
    "9499df7b81b55b488a32fd59798a543dafef4ef8",
    "999c8fcbefc876d9c26c23c5b87a64a81e4f113e"
  ],
  "changeHistoryShort": {
    "9499df7b81b55b488a32fd59798a543dafef4ef8": "Ybodychange",
    "999c8fcbefc876d9c26c23c5b87a64a81e4f113e": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9499df7b81b55b488a32fd59798a543dafef4ef8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13658. Expose HighestPriorityLowRedundancy blocks statistics. Contributed by Kitti Nanasi.\n",
      "commitDate": "08/08/18 10:40 AM",
      "commitName": "9499df7b81b55b488a32fd59798a543dafef4ef8",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "01/02/18 9:34 PM",
      "commitNameOld": "4aef8bd2efd68bf96c077ddda1538dcd5691b437",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 187.5,
      "commitsBetweenForRepo": 1899,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,23 @@\n   private void incrementBlockStat(BlockInfo blockInfo, int priLevel,\n       int expectedReplicas) {\n     if (blockInfo.isStriped()) {\n       lowRedundancyECBlockGroups.increment();\n       if (priLevel \u003d\u003d QUEUE_WITH_CORRUPT_BLOCKS) {\n         corruptECBlockGroups.increment();\n       }\n+      if (priLevel \u003d\u003d QUEUE_HIGHEST_PRIORITY) {\n+        highestPriorityLowRedundancyECBlocks.increment();\n+      }\n     } else {\n       lowRedundancyBlocks.increment();\n       if (priLevel \u003d\u003d QUEUE_WITH_CORRUPT_BLOCKS) {\n         corruptBlocks.increment();\n         if (expectedReplicas \u003d\u003d 1) {\n           corruptReplicationOneBlocks.increment();\n         }\n       }\n+      if (priLevel \u003d\u003d QUEUE_HIGHEST_PRIORITY) {\n+        highestPriorityLowRedundancyReplicatedBlocks.increment();\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void incrementBlockStat(BlockInfo blockInfo, int priLevel,\n      int expectedReplicas) {\n    if (blockInfo.isStriped()) {\n      lowRedundancyECBlockGroups.increment();\n      if (priLevel \u003d\u003d QUEUE_WITH_CORRUPT_BLOCKS) {\n        corruptECBlockGroups.increment();\n      }\n      if (priLevel \u003d\u003d QUEUE_HIGHEST_PRIORITY) {\n        highestPriorityLowRedundancyECBlocks.increment();\n      }\n    } else {\n      lowRedundancyBlocks.increment();\n      if (priLevel \u003d\u003d QUEUE_WITH_CORRUPT_BLOCKS) {\n        corruptBlocks.increment();\n        if (expectedReplicas \u003d\u003d 1) {\n          corruptReplicationOneBlocks.increment();\n        }\n      }\n      if (priLevel \u003d\u003d QUEUE_HIGHEST_PRIORITY) {\n        highestPriorityLowRedundancyReplicatedBlocks.increment();\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java",
      "extendedDetails": {}
    },
    "999c8fcbefc876d9c26c23c5b87a64a81e4f113e": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-10999. Introduce separate stats for Replicated and Erasure Coded Blocks apart from the current Aggregated stats. (Manoj Govindassamy via lei)\n",
      "commitDate": "14/06/17 10:44 AM",
      "commitName": "999c8fcbefc876d9c26c23c5b87a64a81e4f113e",
      "commitAuthor": "Lei Xu",
      "diff": "@@ -0,0 +1,17 @@\n+  private void incrementBlockStat(BlockInfo blockInfo, int priLevel,\n+      int expectedReplicas) {\n+    if (blockInfo.isStriped()) {\n+      lowRedundancyECBlockGroups.increment();\n+      if (priLevel \u003d\u003d QUEUE_WITH_CORRUPT_BLOCKS) {\n+        corruptECBlockGroups.increment();\n+      }\n+    } else {\n+      lowRedundancyBlocks.increment();\n+      if (priLevel \u003d\u003d QUEUE_WITH_CORRUPT_BLOCKS) {\n+        corruptBlocks.increment();\n+        if (expectedReplicas \u003d\u003d 1) {\n+          corruptReplicationOneBlocks.increment();\n+        }\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void incrementBlockStat(BlockInfo blockInfo, int priLevel,\n      int expectedReplicas) {\n    if (blockInfo.isStriped()) {\n      lowRedundancyECBlockGroups.increment();\n      if (priLevel \u003d\u003d QUEUE_WITH_CORRUPT_BLOCKS) {\n        corruptECBlockGroups.increment();\n      }\n    } else {\n      lowRedundancyBlocks.increment();\n      if (priLevel \u003d\u003d QUEUE_WITH_CORRUPT_BLOCKS) {\n        corruptBlocks.increment();\n        if (expectedReplicas \u003d\u003d 1) {\n          corruptReplicationOneBlocks.increment();\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java"
    }
  }
}