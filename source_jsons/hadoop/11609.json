{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPoolSlice.java",
  "functionName": "initializeAddReplicaPool",
  "functionId": "initializeAddReplicaPool___conf-Configuration__dataset-FsDatasetImpl",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
  "functionStartLine": 231,
  "functionEndLine": 244,
  "numCommitsSeen": 113,
  "timeTaken": 4165,
  "changeHistory": [
    "0384687811446a52009b96cc85bf961a3e83afc4",
    "5689355783de005ebc604f4403dc5129a286bfca"
  ],
  "changeHistoryShort": {
    "0384687811446a52009b96cc85bf961a3e83afc4": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
    "5689355783de005ebc604f4403dc5129a286bfca": "Yintroduced"
  },
  "changeHistoryDetails": {
    "0384687811446a52009b96cc85bf961a3e83afc4": {
      "type": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-15010. BlockPoolSlice#addReplicaThreadPool static pool should be initialized by static method. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "28/11/19 10:19 AM",
      "commitName": "0384687811446a52009b96cc85bf961a3e83afc4",
      "commitAuthor": "Surendra Singh Lilhore",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-15010. BlockPoolSlice#addReplicaThreadPool static pool should be initialized by static method. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "28/11/19 10:19 AM",
          "commitName": "0384687811446a52009b96cc85bf961a3e83afc4",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "20/08/19 3:55 PM",
          "commitNameOld": "3a145e2918b66b5776a22eeffba41fc000611936",
          "commitAuthorOld": "Surendra Singh Lilhore",
          "daysBetweenCommits": 99.81,
          "commitsBetweenForRepo": 639,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,14 @@\n-  private synchronized void initializeAddReplicaPool(Configuration conf) {\n+  private synchronized static void initializeAddReplicaPool(Configuration conf,\n+      FsDatasetImpl dataset) {\n     if (addReplicaThreadPool \u003d\u003d null) {\n-      FsDatasetImpl dataset \u003d (FsDatasetImpl) volume.getDataset();\n       int numberOfBlockPoolSlice \u003d dataset.getVolumeCount()\n           * dataset.getBPServiceCount();\n       int poolsize \u003d Math.max(numberOfBlockPoolSlice,\n           VOLUMES_REPLICA_ADD_THREADPOOL_SIZE);\n       // Default pool sizes is max of (volume * number of bp_service) and\n       // number of processor.\n       addReplicaThreadPool \u003d new ForkJoinPool(conf.getInt(\n           DFSConfigKeys.DFS_DATANODE_VOLUMES_REPLICA_ADD_THREADPOOL_SIZE_KEY,\n           poolsize));\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private synchronized static void initializeAddReplicaPool(Configuration conf,\n      FsDatasetImpl dataset) {\n    if (addReplicaThreadPool \u003d\u003d null) {\n      int numberOfBlockPoolSlice \u003d dataset.getVolumeCount()\n          * dataset.getBPServiceCount();\n      int poolsize \u003d Math.max(numberOfBlockPoolSlice,\n          VOLUMES_REPLICA_ADD_THREADPOOL_SIZE);\n      // Default pool sizes is max of (volume * number of bp_service) and\n      // number of processor.\n      addReplicaThreadPool \u003d new ForkJoinPool(conf.getInt(\n          DFSConfigKeys.DFS_DATANODE_VOLUMES_REPLICA_ADD_THREADPOOL_SIZE_KEY,\n          poolsize));\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
          "extendedDetails": {
            "oldValue": "[conf-Configuration]",
            "newValue": "[conf-Configuration, dataset-FsDatasetImpl]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-15010. BlockPoolSlice#addReplicaThreadPool static pool should be initialized by static method. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "28/11/19 10:19 AM",
          "commitName": "0384687811446a52009b96cc85bf961a3e83afc4",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "20/08/19 3:55 PM",
          "commitNameOld": "3a145e2918b66b5776a22eeffba41fc000611936",
          "commitAuthorOld": "Surendra Singh Lilhore",
          "daysBetweenCommits": 99.81,
          "commitsBetweenForRepo": 639,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,14 @@\n-  private synchronized void initializeAddReplicaPool(Configuration conf) {\n+  private synchronized static void initializeAddReplicaPool(Configuration conf,\n+      FsDatasetImpl dataset) {\n     if (addReplicaThreadPool \u003d\u003d null) {\n-      FsDatasetImpl dataset \u003d (FsDatasetImpl) volume.getDataset();\n       int numberOfBlockPoolSlice \u003d dataset.getVolumeCount()\n           * dataset.getBPServiceCount();\n       int poolsize \u003d Math.max(numberOfBlockPoolSlice,\n           VOLUMES_REPLICA_ADD_THREADPOOL_SIZE);\n       // Default pool sizes is max of (volume * number of bp_service) and\n       // number of processor.\n       addReplicaThreadPool \u003d new ForkJoinPool(conf.getInt(\n           DFSConfigKeys.DFS_DATANODE_VOLUMES_REPLICA_ADD_THREADPOOL_SIZE_KEY,\n           poolsize));\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private synchronized static void initializeAddReplicaPool(Configuration conf,\n      FsDatasetImpl dataset) {\n    if (addReplicaThreadPool \u003d\u003d null) {\n      int numberOfBlockPoolSlice \u003d dataset.getVolumeCount()\n          * dataset.getBPServiceCount();\n      int poolsize \u003d Math.max(numberOfBlockPoolSlice,\n          VOLUMES_REPLICA_ADD_THREADPOOL_SIZE);\n      // Default pool sizes is max of (volume * number of bp_service) and\n      // number of processor.\n      addReplicaThreadPool \u003d new ForkJoinPool(conf.getInt(\n          DFSConfigKeys.DFS_DATANODE_VOLUMES_REPLICA_ADD_THREADPOOL_SIZE_KEY,\n          poolsize));\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
          "extendedDetails": {
            "oldValue": "[private, synchronized]",
            "newValue": "[private, static, synchronized]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-15010. BlockPoolSlice#addReplicaThreadPool static pool should be initialized by static method. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "28/11/19 10:19 AM",
          "commitName": "0384687811446a52009b96cc85bf961a3e83afc4",
          "commitAuthor": "Surendra Singh Lilhore",
          "commitDateOld": "20/08/19 3:55 PM",
          "commitNameOld": "3a145e2918b66b5776a22eeffba41fc000611936",
          "commitAuthorOld": "Surendra Singh Lilhore",
          "daysBetweenCommits": 99.81,
          "commitsBetweenForRepo": 639,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,14 @@\n-  private synchronized void initializeAddReplicaPool(Configuration conf) {\n+  private synchronized static void initializeAddReplicaPool(Configuration conf,\n+      FsDatasetImpl dataset) {\n     if (addReplicaThreadPool \u003d\u003d null) {\n-      FsDatasetImpl dataset \u003d (FsDatasetImpl) volume.getDataset();\n       int numberOfBlockPoolSlice \u003d dataset.getVolumeCount()\n           * dataset.getBPServiceCount();\n       int poolsize \u003d Math.max(numberOfBlockPoolSlice,\n           VOLUMES_REPLICA_ADD_THREADPOOL_SIZE);\n       // Default pool sizes is max of (volume * number of bp_service) and\n       // number of processor.\n       addReplicaThreadPool \u003d new ForkJoinPool(conf.getInt(\n           DFSConfigKeys.DFS_DATANODE_VOLUMES_REPLICA_ADD_THREADPOOL_SIZE_KEY,\n           poolsize));\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private synchronized static void initializeAddReplicaPool(Configuration conf,\n      FsDatasetImpl dataset) {\n    if (addReplicaThreadPool \u003d\u003d null) {\n      int numberOfBlockPoolSlice \u003d dataset.getVolumeCount()\n          * dataset.getBPServiceCount();\n      int poolsize \u003d Math.max(numberOfBlockPoolSlice,\n          VOLUMES_REPLICA_ADD_THREADPOOL_SIZE);\n      // Default pool sizes is max of (volume * number of bp_service) and\n      // number of processor.\n      addReplicaThreadPool \u003d new ForkJoinPool(conf.getInt(\n          DFSConfigKeys.DFS_DATANODE_VOLUMES_REPLICA_ADD_THREADPOOL_SIZE_KEY,\n          poolsize));\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
          "extendedDetails": {}
        }
      ]
    },
    "5689355783de005ebc604f4403dc5129a286bfca": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13768. Adding replicas to volume map makes DataNode start slowly. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "01/10/18 6:43 PM",
      "commitName": "5689355783de005ebc604f4403dc5129a286bfca",
      "commitAuthor": "Yiqun Lin",
      "diff": "@@ -0,0 +1,14 @@\n+  private synchronized void initializeAddReplicaPool(Configuration conf) {\n+    if (addReplicaThreadPool \u003d\u003d null) {\n+      FsDatasetImpl dataset \u003d (FsDatasetImpl) volume.getDataset();\n+      int numberOfBlockPoolSlice \u003d dataset.getVolumeCount()\n+          * dataset.getBPServiceCount();\n+      int poolsize \u003d Math.max(numberOfBlockPoolSlice,\n+          VOLUMES_REPLICA_ADD_THREADPOOL_SIZE);\n+      // Default pool sizes is max of (volume * number of bp_service) and\n+      // number of processor.\n+      addReplicaThreadPool \u003d new ForkJoinPool(conf.getInt(\n+          DFSConfigKeys.DFS_DATANODE_VOLUMES_REPLICA_ADD_THREADPOOL_SIZE_KEY,\n+          poolsize));\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void initializeAddReplicaPool(Configuration conf) {\n    if (addReplicaThreadPool \u003d\u003d null) {\n      FsDatasetImpl dataset \u003d (FsDatasetImpl) volume.getDataset();\n      int numberOfBlockPoolSlice \u003d dataset.getVolumeCount()\n          * dataset.getBPServiceCount();\n      int poolsize \u003d Math.max(numberOfBlockPoolSlice,\n          VOLUMES_REPLICA_ADD_THREADPOOL_SIZE);\n      // Default pool sizes is max of (volume * number of bp_service) and\n      // number of processor.\n      addReplicaThreadPool \u003d new ForkJoinPool(conf.getInt(\n          DFSConfigKeys.DFS_DATANODE_VOLUMES_REPLICA_ADD_THREADPOOL_SIZE_KEY,\n          poolsize));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java"
    }
  }
}