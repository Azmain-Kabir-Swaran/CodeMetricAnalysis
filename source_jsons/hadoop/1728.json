{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PipelineAck.java",
  "functionName": "getOOBStatus",
  "functionId": "getOOBStatus",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/PipelineAck.java",
  "functionStartLine": 185,
  "functionEndLine": 199,
  "numCommitsSeen": 14,
  "timeTaken": 2014,
  "changeHistory": [
    "d16c4eee186492608ffeb1c2e83f437000cc64f6",
    "b80457158daf0dc712fbe5695625cc17d70d4bb4",
    "c4980a2f343778544ca20ebea1338651793ea0d9",
    "1c6b5d2b5841e5219a98937088cde4ae63869f80"
  ],
  "changeHistoryShort": {
    "d16c4eee186492608ffeb1c2e83f437000cc64f6": "Yfilerename",
    "b80457158daf0dc712fbe5695625cc17d70d4bb4": "Ybodychange",
    "c4980a2f343778544ca20ebea1338651793ea0d9": "Ybodychange",
    "1c6b5d2b5841e5219a98937088cde4ae63869f80": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d16c4eee186492608ffeb1c2e83f437000cc64f6": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-9012. Move o.a.h.hdfs.protocol.datatransfer.PipelineAck class to hadoop-hdfs-client module. Contributed by Mingliang Liu.\n",
      "commitDate": "04/09/15 10:41 AM",
      "commitName": "d16c4eee186492608ffeb1c2e83f437000cc64f6",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "04/09/15 8:30 AM",
      "commitNameOld": "6eaca2e3634a88dc55689e8960352d6248c424d9",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 0.09,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public Status getOOBStatus() {\n    // Normal data transfer acks will have a valid sequence number, so\n    // this will return right away in most cases.\n    if (getSeqno() !\u003d UNKOWN_SEQNO) {\n      return null;\n    }\n    for (Status s : proto.getReplyList()) {\n      // The following check is valid because protobuf guarantees to\n      // preserve the ordering of enum elements.\n      if (s.getNumber() \u003e\u003d OOB_START \u0026\u0026 s.getNumber() \u003c\u003d OOB_END) {\n        return s;\n      }\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/PipelineAck.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/PipelineAck.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/PipelineAck.java"
      }
    },
    "b80457158daf0dc712fbe5695625cc17d70d4bb4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7748. Separate ECN flags from the Status in the DataTransferPipelineAck. Contributed by Anu Engineer and Haohui Mai.\n",
      "commitDate": "30/03/15 11:59 AM",
      "commitName": "b80457158daf0dc712fbe5695625cc17d70d4bb4",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "05/02/15 10:58 AM",
      "commitNameOld": "c4980a2f343778544ca20ebea1338651793ea0d9",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 53.0,
      "commitsBetweenForRepo": 497,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,15 @@\n   public Status getOOBStatus() {\n     // Normal data transfer acks will have a valid sequence number, so\n     // this will return right away in most cases.\n     if (getSeqno() !\u003d UNKOWN_SEQNO) {\n       return null;\n     }\n-    for (int reply : proto.getReplyList()) {\n+    for (Status s : proto.getReplyList()) {\n       // The following check is valid because protobuf guarantees to\n       // preserve the ordering of enum elements.\n-      Status s \u003d StatusFormat.getStatus(reply);\n       if (s.getNumber() \u003e\u003d OOB_START \u0026\u0026 s.getNumber() \u003c\u003d OOB_END) {\n         return s;\n       }\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Status getOOBStatus() {\n    // Normal data transfer acks will have a valid sequence number, so\n    // this will return right away in most cases.\n    if (getSeqno() !\u003d UNKOWN_SEQNO) {\n      return null;\n    }\n    for (Status s : proto.getReplyList()) {\n      // The following check is valid because protobuf guarantees to\n      // preserve the ordering of enum elements.\n      if (s.getNumber() \u003e\u003d OOB_START \u0026\u0026 s.getNumber() \u003c\u003d OOB_END) {\n        return s;\n      }\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/PipelineAck.java",
      "extendedDetails": {}
    },
    "c4980a2f343778544ca20ebea1338651793ea0d9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7270. Add congestion signaling capability to DataNode write protocol. Contributed by Haohui Mai.\n",
      "commitDate": "05/02/15 10:58 AM",
      "commitName": "c4980a2f343778544ca20ebea1338651793ea0d9",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/03/14 2:27 PM",
      "commitNameOld": "14556cc5d8fee8f8a846e4f65572828553be386c",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 315.9,
      "commitsBetweenForRepo": 2442,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,16 @@\n   public Status getOOBStatus() {\n     // Normal data transfer acks will have a valid sequence number, so\n     // this will return right away in most cases.\n     if (getSeqno() !\u003d UNKOWN_SEQNO) {\n       return null;\n     }\n-    for (Status reply : proto.getStatusList()) {\n+    for (int reply : proto.getReplyList()) {\n       // The following check is valid because protobuf guarantees to\n       // preserve the ordering of enum elements.\n-      if (reply.getNumber() \u003e\u003d OOB_START \u0026\u0026 reply.getNumber() \u003c\u003d OOB_END) {\n-        return reply;\n+      Status s \u003d StatusFormat.getStatus(reply);\n+      if (s.getNumber() \u003e\u003d OOB_START \u0026\u0026 s.getNumber() \u003c\u003d OOB_END) {\n+        return s;\n       }\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Status getOOBStatus() {\n    // Normal data transfer acks will have a valid sequence number, so\n    // this will return right away in most cases.\n    if (getSeqno() !\u003d UNKOWN_SEQNO) {\n      return null;\n    }\n    for (int reply : proto.getReplyList()) {\n      // The following check is valid because protobuf guarantees to\n      // preserve the ordering of enum elements.\n      Status s \u003d StatusFormat.getStatus(reply);\n      if (s.getNumber() \u003e\u003d OOB_START \u0026\u0026 s.getNumber() \u003c\u003d OOB_END) {\n        return s;\n      }\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/PipelineAck.java",
      "extendedDetails": {}
    },
    "1c6b5d2b5841e5219a98937088cde4ae63869f80": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5583. Make DN send an OOB Ack on shutdown before restarting. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1571491 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/02/14 3:38 PM",
      "commitName": "1c6b5d2b5841e5219a98937088cde4ae63869f80",
      "commitAuthor": "Kihwal Lee",
      "diff": "@@ -0,0 +1,15 @@\n+  public Status getOOBStatus() {\n+    // Normal data transfer acks will have a valid sequence number, so\n+    // this will return right away in most cases.\n+    if (getSeqno() !\u003d UNKOWN_SEQNO) {\n+      return null;\n+    }\n+    for (Status reply : proto.getStatusList()) {\n+      // The following check is valid because protobuf guarantees to\n+      // preserve the ordering of enum elements.\n+      if (reply.getNumber() \u003e\u003d OOB_START \u0026\u0026 reply.getNumber() \u003c\u003d OOB_END) {\n+        return reply;\n+      }\n+    }\n+    return null;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public Status getOOBStatus() {\n    // Normal data transfer acks will have a valid sequence number, so\n    // this will return right away in most cases.\n    if (getSeqno() !\u003d UNKOWN_SEQNO) {\n      return null;\n    }\n    for (Status reply : proto.getStatusList()) {\n      // The following check is valid because protobuf guarantees to\n      // preserve the ordering of enum elements.\n      if (reply.getNumber() \u003e\u003d OOB_START \u0026\u0026 reply.getNumber() \u003c\u003d OOB_END) {\n        return reply;\n      }\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/PipelineAck.java"
    }
  }
}