{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3AFileSystem.java",
  "functionName": "abortOutstandingMultipartUploads",
  "functionId": "abortOutstandingMultipartUploads___seconds-long",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
  "functionStartLine": 729,
  "functionEndLine": 738,
  "numCommitsSeen": 141,
  "timeTaken": 3956,
  "changeHistory": [
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c"
  ],
  "changeHistoryShort": {
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c": "Yintroduced"
  },
  "changeHistoryDetails": {
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13786 Add S3A committer for zero-rename commits to S3 endpoints.\nContributed by Steve Loughran and Ryan Blue.\n",
      "commitDate": "22/11/17 7:28 AM",
      "commitName": "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,10 @@\n+  public void abortOutstandingMultipartUploads(long seconds)\n+      throws IOException {\n+    Preconditions.checkArgument(seconds \u003e\u003d 0);\n+    Date purgeBefore \u003d\n+        new Date(new Date().getTime() - seconds * 1000);\n+    LOG.debug(\"Purging outstanding multipart uploads older than {}\",\n+        purgeBefore);\n+    invoker.retry(\"Purging multipart uploads\", bucket, true,\n+        () -\u003e transfers.abortMultipartUploads(bucket, purgeBefore));\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void abortOutstandingMultipartUploads(long seconds)\n      throws IOException {\n    Preconditions.checkArgument(seconds \u003e\u003d 0);\n    Date purgeBefore \u003d\n        new Date(new Date().getTime() - seconds * 1000);\n    LOG.debug(\"Purging outstanding multipart uploads older than {}\",\n        purgeBefore);\n    invoker.retry(\"Purging multipart uploads\", bucket, true,\n        () -\u003e transfers.abortMultipartUploads(bucket, purgeBefore));\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java"
    }
  }
}