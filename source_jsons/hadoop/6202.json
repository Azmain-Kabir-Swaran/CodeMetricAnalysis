{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NNUpgradeUtil.java",
  "functionName": "doPreUpgrade",
  "functionId": "doPreUpgrade___conf-Configuration__sd-StorageDirectory",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNUpgradeUtil.java",
  "functionStartLine": 116,
  "functionEndLine": 147,
  "numCommitsSeen": 9,
  "timeTaken": 3900,
  "changeHistory": [
    "357b1fd0822447f9e73a20c69f37006d9a37ecbc",
    "7b424f938c3c306795d574792b086d84e4f06425",
    "fddd55279d0bdd08b3b40aba6fe2ded1d2e0d846",
    "43b41f22411439c5e23629197fb2fde45dcf0f0f",
    "56205ca7d7f3b2a7e55f48b9cf444326e1d2b1a7",
    "edb6dc5f303093c2604cd07b0c0dacf12dbce5de"
  ],
  "changeHistoryShort": {
    "357b1fd0822447f9e73a20c69f37006d9a37ecbc": "Ybodychange",
    "7b424f938c3c306795d574792b086d84e4f06425": "Ybodychange",
    "fddd55279d0bdd08b3b40aba6fe2ded1d2e0d846": "Ybodychange",
    "43b41f22411439c5e23629197fb2fde45dcf0f0f": "Ymultichange(Yparameterchange,Ybodychange)",
    "56205ca7d7f3b2a7e55f48b9cf444326e1d2b1a7": "Ybodychange",
    "edb6dc5f303093c2604cd07b0c0dacf12dbce5de": "Yintroduced"
  },
  "changeHistoryDetails": {
    "357b1fd0822447f9e73a20c69f37006d9a37ecbc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9110. Use Files.walkFileTree in NNUpgradeUtil#doPreUpgrade for better efficiency. Contributed by Charlie Helin.\n",
      "commitDate": "09/10/15 11:49 AM",
      "commitName": "357b1fd0822447f9e73a20c69f37006d9a37ecbc",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "22/06/15 2:37 PM",
      "commitNameOld": "7b424f938c3c306795d574792b086d84e4f06425",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 108.88,
      "commitsBetweenForRepo": 720,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,32 @@\n   static void doPreUpgrade(Configuration conf, StorageDirectory sd)\n       throws IOException {\n     LOG.info(\"Starting upgrade of storage directory \" + sd.getRoot());\n \n     // rename current to tmp\n     renameCurToTmp(sd);\n \n-    final File curDir \u003d sd.getCurrentDir();\n-    final File tmpDir \u003d sd.getPreviousTmp();\n-    List\u003cString\u003e fileNameList \u003d IOUtils.listDirectory(tmpDir, new FilenameFilter() {\n-      @Override\n-      public boolean accept(File dir, String name) {\n-        return dir.equals(tmpDir)\n-            \u0026\u0026 name.startsWith(NNStorage.NameNodeFile.EDITS.getName());\n-      }\n-    });\n+    final Path curDir \u003d sd.getCurrentDir().toPath();\n+    final Path tmpDir \u003d sd.getPreviousTmp().toPath();\n \n-    for (String s : fileNameList) {\n-      File prevFile \u003d new File(tmpDir, s);\n-      File newFile \u003d new File(curDir, prevFile.getName());\n-      Files.createLink(newFile.toPath(), prevFile.toPath());\n-    }\n+    Files.walkFileTree(tmpDir,\n+      /* do not follow links */ Collections.\u003cFileVisitOption\u003eemptySet(),\n+        1, new SimpleFileVisitor\u003cPath\u003e() {\n+\n+          @Override\n+          public FileVisitResult visitFile(Path file, BasicFileAttributes attrs)\n+              throws IOException {\n+\n+            String name \u003d file.getFileName().toString();\n+\n+            if (Files.isRegularFile(file)\n+                \u0026\u0026 name.startsWith(NNStorage.NameNodeFile.EDITS.getName())) {\n+\n+              Path newFile \u003d curDir.resolve(name);\n+              Files.createLink(newFile, file);\n+            }\n+\n+            return super.visitFile(file, attrs);\n+          }\n+        }\n+    );\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static void doPreUpgrade(Configuration conf, StorageDirectory sd)\n      throws IOException {\n    LOG.info(\"Starting upgrade of storage directory \" + sd.getRoot());\n\n    // rename current to tmp\n    renameCurToTmp(sd);\n\n    final Path curDir \u003d sd.getCurrentDir().toPath();\n    final Path tmpDir \u003d sd.getPreviousTmp().toPath();\n\n    Files.walkFileTree(tmpDir,\n      /* do not follow links */ Collections.\u003cFileVisitOption\u003eemptySet(),\n        1, new SimpleFileVisitor\u003cPath\u003e() {\n\n          @Override\n          public FileVisitResult visitFile(Path file, BasicFileAttributes attrs)\n              throws IOException {\n\n            String name \u003d file.getFileName().toString();\n\n            if (Files.isRegularFile(file)\n                \u0026\u0026 name.startsWith(NNStorage.NameNodeFile.EDITS.getName())) {\n\n              Path newFile \u003d curDir.resolve(name);\n              Files.createLink(newFile, file);\n            }\n\n            return super.visitFile(file, attrs);\n          }\n        }\n    );\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNUpgradeUtil.java",
      "extendedDetails": {}
    },
    "7b424f938c3c306795d574792b086d84e4f06425": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8480. Fix performance and timeout issues in HDFS-7929 by using hard-links to preserve old edit logs, instead of copying them. (Zhe Zhang via Colin P. McCabe)\n",
      "commitDate": "22/06/15 2:37 PM",
      "commitName": "7b424f938c3c306795d574792b086d84e4f06425",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "14/04/15 3:05 PM",
      "commitNameOld": "fddd55279d0bdd08b3b40aba6fe2ded1d2e0d846",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 68.98,
      "commitsBetweenForRepo": 611,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,23 @@\n   static void doPreUpgrade(Configuration conf, StorageDirectory sd)\n       throws IOException {\n     LOG.info(\"Starting upgrade of storage directory \" + sd.getRoot());\n \n     // rename current to tmp\n     renameCurToTmp(sd);\n \n     final File curDir \u003d sd.getCurrentDir();\n     final File tmpDir \u003d sd.getPreviousTmp();\n     List\u003cString\u003e fileNameList \u003d IOUtils.listDirectory(tmpDir, new FilenameFilter() {\n       @Override\n       public boolean accept(File dir, String name) {\n         return dir.equals(tmpDir)\n             \u0026\u0026 name.startsWith(NNStorage.NameNodeFile.EDITS.getName());\n       }\n     });\n \n     for (String s : fileNameList) {\n       File prevFile \u003d new File(tmpDir, s);\n-      Preconditions.checkState(prevFile.canRead(),\n-          \"Edits log file \" + s + \" is not readable.\");\n       File newFile \u003d new File(curDir, prevFile.getName());\n-      Preconditions.checkState(newFile.createNewFile(),\n-          \"Cannot create new edits log file in \" + curDir);\n-      EditLogFileInputStream in \u003d new EditLogFileInputStream(prevFile);\n-      EditLogFileOutputStream out \u003d\n-          new EditLogFileOutputStream(conf, newFile, 512*1024);\n-      FSEditLogOp logOp \u003d in.nextValidOp();\n-      while (logOp !\u003d null) {\n-        out.write(logOp);\n-        logOp \u003d in.nextOp();\n-      }\n-      out.setReadyToFlush();\n-      out.flushAndSync(true);\n-      out.close();\n-      in.close();\n+      Files.createLink(newFile.toPath(), prevFile.toPath());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static void doPreUpgrade(Configuration conf, StorageDirectory sd)\n      throws IOException {\n    LOG.info(\"Starting upgrade of storage directory \" + sd.getRoot());\n\n    // rename current to tmp\n    renameCurToTmp(sd);\n\n    final File curDir \u003d sd.getCurrentDir();\n    final File tmpDir \u003d sd.getPreviousTmp();\n    List\u003cString\u003e fileNameList \u003d IOUtils.listDirectory(tmpDir, new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return dir.equals(tmpDir)\n            \u0026\u0026 name.startsWith(NNStorage.NameNodeFile.EDITS.getName());\n      }\n    });\n\n    for (String s : fileNameList) {\n      File prevFile \u003d new File(tmpDir, s);\n      File newFile \u003d new File(curDir, prevFile.getName());\n      Files.createLink(newFile.toPath(), prevFile.toPath());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNUpgradeUtil.java",
      "extendedDetails": {}
    },
    "fddd55279d0bdd08b3b40aba6fe2ded1d2e0d846": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8127. NameNode Failover during HA upgrade can cause DataNode to finalize upgrade. Contributed by Jing Zhao.\n",
      "commitDate": "14/04/15 3:05 PM",
      "commitName": "fddd55279d0bdd08b3b40aba6fe2ded1d2e0d846",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "18/03/15 6:48 PM",
      "commitNameOld": "43b41f22411439c5e23629197fb2fde45dcf0f0f",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 26.84,
      "commitsBetweenForRepo": 242,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,38 @@\n   static void doPreUpgrade(Configuration conf, StorageDirectory sd)\n       throws IOException {\n     LOG.info(\"Starting upgrade of storage directory \" + sd.getRoot());\n-    File curDir \u003d sd.getCurrentDir();\n-    File prevDir \u003d sd.getPreviousDir();\n-    final File tmpDir \u003d sd.getPreviousTmp();\n-\n-    Preconditions.checkState(curDir.exists(),\n-        \"Current directory must exist for preupgrade.\");\n-    Preconditions.checkState(!prevDir.exists(),\n-        \"Previous directory must not exist for preupgrade.\");\n-    Preconditions.checkState(!tmpDir.exists(),\n-        \"Previous.tmp directory must not exist for preupgrade.\"\n-            + \"Consider restarting for recovery.\");\n \n     // rename current to tmp\n-    NNStorage.rename(curDir, tmpDir);\n-    \n-    if (!curDir.mkdir()) {\n-      throw new IOException(\"Cannot create directory \" + curDir);\n-    }\n+    renameCurToTmp(sd);\n \n+    final File curDir \u003d sd.getCurrentDir();\n+    final File tmpDir \u003d sd.getPreviousTmp();\n     List\u003cString\u003e fileNameList \u003d IOUtils.listDirectory(tmpDir, new FilenameFilter() {\n       @Override\n       public boolean accept(File dir, String name) {\n         return dir.equals(tmpDir)\n             \u0026\u0026 name.startsWith(NNStorage.NameNodeFile.EDITS.getName());\n       }\n     });\n \n     for (String s : fileNameList) {\n       File prevFile \u003d new File(tmpDir, s);\n       Preconditions.checkState(prevFile.canRead(),\n           \"Edits log file \" + s + \" is not readable.\");\n       File newFile \u003d new File(curDir, prevFile.getName());\n       Preconditions.checkState(newFile.createNewFile(),\n           \"Cannot create new edits log file in \" + curDir);\n       EditLogFileInputStream in \u003d new EditLogFileInputStream(prevFile);\n       EditLogFileOutputStream out \u003d\n           new EditLogFileOutputStream(conf, newFile, 512*1024);\n       FSEditLogOp logOp \u003d in.nextValidOp();\n       while (logOp !\u003d null) {\n         out.write(logOp);\n         logOp \u003d in.nextOp();\n       }\n       out.setReadyToFlush();\n       out.flushAndSync(true);\n       out.close();\n       in.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static void doPreUpgrade(Configuration conf, StorageDirectory sd)\n      throws IOException {\n    LOG.info(\"Starting upgrade of storage directory \" + sd.getRoot());\n\n    // rename current to tmp\n    renameCurToTmp(sd);\n\n    final File curDir \u003d sd.getCurrentDir();\n    final File tmpDir \u003d sd.getPreviousTmp();\n    List\u003cString\u003e fileNameList \u003d IOUtils.listDirectory(tmpDir, new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return dir.equals(tmpDir)\n            \u0026\u0026 name.startsWith(NNStorage.NameNodeFile.EDITS.getName());\n      }\n    });\n\n    for (String s : fileNameList) {\n      File prevFile \u003d new File(tmpDir, s);\n      Preconditions.checkState(prevFile.canRead(),\n          \"Edits log file \" + s + \" is not readable.\");\n      File newFile \u003d new File(curDir, prevFile.getName());\n      Preconditions.checkState(newFile.createNewFile(),\n          \"Cannot create new edits log file in \" + curDir);\n      EditLogFileInputStream in \u003d new EditLogFileInputStream(prevFile);\n      EditLogFileOutputStream out \u003d\n          new EditLogFileOutputStream(conf, newFile, 512*1024);\n      FSEditLogOp logOp \u003d in.nextValidOp();\n      while (logOp !\u003d null) {\n        out.write(logOp);\n        logOp \u003d in.nextOp();\n      }\n      out.setReadyToFlush();\n      out.flushAndSync(true);\n      out.close();\n      in.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNUpgradeUtil.java",
      "extendedDetails": {}
    },
    "43b41f22411439c5e23629197fb2fde45dcf0f0f": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7929. inotify unable fetch pre-upgrade edit log segments once upgrade starts (Zhe Zhang via Colin P. McCabe)\n",
      "commitDate": "18/03/15 6:48 PM",
      "commitName": "43b41f22411439c5e23629197fb2fde45dcf0f0f",
      "commitAuthor": "Colin Patrick Mccabe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7929. inotify unable fetch pre-upgrade edit log segments once upgrade starts (Zhe Zhang via Colin P. McCabe)\n",
          "commitDate": "18/03/15 6:48 PM",
          "commitName": "43b41f22411439c5e23629197fb2fde45dcf0f0f",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "24/03/14 11:48 PM",
          "commitNameOld": "56205ca7d7f3b2a7e55f48b9cf444326e1d2b1a7",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 358.79,
          "commitsBetweenForRepo": 2858,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,51 @@\n-  static void doPreUpgrade(StorageDirectory sd) throws IOException {\n+  static void doPreUpgrade(Configuration conf, StorageDirectory sd)\n+      throws IOException {\n     LOG.info(\"Starting upgrade of storage directory \" + sd.getRoot());\n     File curDir \u003d sd.getCurrentDir();\n     File prevDir \u003d sd.getPreviousDir();\n-    File tmpDir \u003d sd.getPreviousTmp();\n+    final File tmpDir \u003d sd.getPreviousTmp();\n \n     Preconditions.checkState(curDir.exists(),\n         \"Current directory must exist for preupgrade.\");\n     Preconditions.checkState(!prevDir.exists(),\n         \"Previous directory must not exist for preupgrade.\");\n     Preconditions.checkState(!tmpDir.exists(),\n         \"Previous.tmp directory must not exist for preupgrade.\"\n             + \"Consider restarting for recovery.\");\n \n     // rename current to tmp\n     NNStorage.rename(curDir, tmpDir);\n     \n     if (!curDir.mkdir()) {\n       throw new IOException(\"Cannot create directory \" + curDir);\n     }\n+\n+    List\u003cString\u003e fileNameList \u003d IOUtils.listDirectory(tmpDir, new FilenameFilter() {\n+      @Override\n+      public boolean accept(File dir, String name) {\n+        return dir.equals(tmpDir)\n+            \u0026\u0026 name.startsWith(NNStorage.NameNodeFile.EDITS.getName());\n+      }\n+    });\n+\n+    for (String s : fileNameList) {\n+      File prevFile \u003d new File(tmpDir, s);\n+      Preconditions.checkState(prevFile.canRead(),\n+          \"Edits log file \" + s + \" is not readable.\");\n+      File newFile \u003d new File(curDir, prevFile.getName());\n+      Preconditions.checkState(newFile.createNewFile(),\n+          \"Cannot create new edits log file in \" + curDir);\n+      EditLogFileInputStream in \u003d new EditLogFileInputStream(prevFile);\n+      EditLogFileOutputStream out \u003d\n+          new EditLogFileOutputStream(conf, newFile, 512*1024);\n+      FSEditLogOp logOp \u003d in.nextValidOp();\n+      while (logOp !\u003d null) {\n+        out.write(logOp);\n+        logOp \u003d in.nextOp();\n+      }\n+      out.setReadyToFlush();\n+      out.flushAndSync(true);\n+      out.close();\n+      in.close();\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static void doPreUpgrade(Configuration conf, StorageDirectory sd)\n      throws IOException {\n    LOG.info(\"Starting upgrade of storage directory \" + sd.getRoot());\n    File curDir \u003d sd.getCurrentDir();\n    File prevDir \u003d sd.getPreviousDir();\n    final File tmpDir \u003d sd.getPreviousTmp();\n\n    Preconditions.checkState(curDir.exists(),\n        \"Current directory must exist for preupgrade.\");\n    Preconditions.checkState(!prevDir.exists(),\n        \"Previous directory must not exist for preupgrade.\");\n    Preconditions.checkState(!tmpDir.exists(),\n        \"Previous.tmp directory must not exist for preupgrade.\"\n            + \"Consider restarting for recovery.\");\n\n    // rename current to tmp\n    NNStorage.rename(curDir, tmpDir);\n    \n    if (!curDir.mkdir()) {\n      throw new IOException(\"Cannot create directory \" + curDir);\n    }\n\n    List\u003cString\u003e fileNameList \u003d IOUtils.listDirectory(tmpDir, new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return dir.equals(tmpDir)\n            \u0026\u0026 name.startsWith(NNStorage.NameNodeFile.EDITS.getName());\n      }\n    });\n\n    for (String s : fileNameList) {\n      File prevFile \u003d new File(tmpDir, s);\n      Preconditions.checkState(prevFile.canRead(),\n          \"Edits log file \" + s + \" is not readable.\");\n      File newFile \u003d new File(curDir, prevFile.getName());\n      Preconditions.checkState(newFile.createNewFile(),\n          \"Cannot create new edits log file in \" + curDir);\n      EditLogFileInputStream in \u003d new EditLogFileInputStream(prevFile);\n      EditLogFileOutputStream out \u003d\n          new EditLogFileOutputStream(conf, newFile, 512*1024);\n      FSEditLogOp logOp \u003d in.nextValidOp();\n      while (logOp !\u003d null) {\n        out.write(logOp);\n        logOp \u003d in.nextOp();\n      }\n      out.setReadyToFlush();\n      out.flushAndSync(true);\n      out.close();\n      in.close();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNUpgradeUtil.java",
          "extendedDetails": {
            "oldValue": "[sd-StorageDirectory]",
            "newValue": "[conf-Configuration, sd-StorageDirectory]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7929. inotify unable fetch pre-upgrade edit log segments once upgrade starts (Zhe Zhang via Colin P. McCabe)\n",
          "commitDate": "18/03/15 6:48 PM",
          "commitName": "43b41f22411439c5e23629197fb2fde45dcf0f0f",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "24/03/14 11:48 PM",
          "commitNameOld": "56205ca7d7f3b2a7e55f48b9cf444326e1d2b1a7",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 358.79,
          "commitsBetweenForRepo": 2858,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,51 @@\n-  static void doPreUpgrade(StorageDirectory sd) throws IOException {\n+  static void doPreUpgrade(Configuration conf, StorageDirectory sd)\n+      throws IOException {\n     LOG.info(\"Starting upgrade of storage directory \" + sd.getRoot());\n     File curDir \u003d sd.getCurrentDir();\n     File prevDir \u003d sd.getPreviousDir();\n-    File tmpDir \u003d sd.getPreviousTmp();\n+    final File tmpDir \u003d sd.getPreviousTmp();\n \n     Preconditions.checkState(curDir.exists(),\n         \"Current directory must exist for preupgrade.\");\n     Preconditions.checkState(!prevDir.exists(),\n         \"Previous directory must not exist for preupgrade.\");\n     Preconditions.checkState(!tmpDir.exists(),\n         \"Previous.tmp directory must not exist for preupgrade.\"\n             + \"Consider restarting for recovery.\");\n \n     // rename current to tmp\n     NNStorage.rename(curDir, tmpDir);\n     \n     if (!curDir.mkdir()) {\n       throw new IOException(\"Cannot create directory \" + curDir);\n     }\n+\n+    List\u003cString\u003e fileNameList \u003d IOUtils.listDirectory(tmpDir, new FilenameFilter() {\n+      @Override\n+      public boolean accept(File dir, String name) {\n+        return dir.equals(tmpDir)\n+            \u0026\u0026 name.startsWith(NNStorage.NameNodeFile.EDITS.getName());\n+      }\n+    });\n+\n+    for (String s : fileNameList) {\n+      File prevFile \u003d new File(tmpDir, s);\n+      Preconditions.checkState(prevFile.canRead(),\n+          \"Edits log file \" + s + \" is not readable.\");\n+      File newFile \u003d new File(curDir, prevFile.getName());\n+      Preconditions.checkState(newFile.createNewFile(),\n+          \"Cannot create new edits log file in \" + curDir);\n+      EditLogFileInputStream in \u003d new EditLogFileInputStream(prevFile);\n+      EditLogFileOutputStream out \u003d\n+          new EditLogFileOutputStream(conf, newFile, 512*1024);\n+      FSEditLogOp logOp \u003d in.nextValidOp();\n+      while (logOp !\u003d null) {\n+        out.write(logOp);\n+        logOp \u003d in.nextOp();\n+      }\n+      out.setReadyToFlush();\n+      out.flushAndSync(true);\n+      out.close();\n+      in.close();\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static void doPreUpgrade(Configuration conf, StorageDirectory sd)\n      throws IOException {\n    LOG.info(\"Starting upgrade of storage directory \" + sd.getRoot());\n    File curDir \u003d sd.getCurrentDir();\n    File prevDir \u003d sd.getPreviousDir();\n    final File tmpDir \u003d sd.getPreviousTmp();\n\n    Preconditions.checkState(curDir.exists(),\n        \"Current directory must exist for preupgrade.\");\n    Preconditions.checkState(!prevDir.exists(),\n        \"Previous directory must not exist for preupgrade.\");\n    Preconditions.checkState(!tmpDir.exists(),\n        \"Previous.tmp directory must not exist for preupgrade.\"\n            + \"Consider restarting for recovery.\");\n\n    // rename current to tmp\n    NNStorage.rename(curDir, tmpDir);\n    \n    if (!curDir.mkdir()) {\n      throw new IOException(\"Cannot create directory \" + curDir);\n    }\n\n    List\u003cString\u003e fileNameList \u003d IOUtils.listDirectory(tmpDir, new FilenameFilter() {\n      @Override\n      public boolean accept(File dir, String name) {\n        return dir.equals(tmpDir)\n            \u0026\u0026 name.startsWith(NNStorage.NameNodeFile.EDITS.getName());\n      }\n    });\n\n    for (String s : fileNameList) {\n      File prevFile \u003d new File(tmpDir, s);\n      Preconditions.checkState(prevFile.canRead(),\n          \"Edits log file \" + s + \" is not readable.\");\n      File newFile \u003d new File(curDir, prevFile.getName());\n      Preconditions.checkState(newFile.createNewFile(),\n          \"Cannot create new edits log file in \" + curDir);\n      EditLogFileInputStream in \u003d new EditLogFileInputStream(prevFile);\n      EditLogFileOutputStream out \u003d\n          new EditLogFileOutputStream(conf, newFile, 512*1024);\n      FSEditLogOp logOp \u003d in.nextValidOp();\n      while (logOp !\u003d null) {\n        out.write(logOp);\n        logOp \u003d in.nextOp();\n      }\n      out.setReadyToFlush();\n      out.flushAndSync(true);\n      out.close();\n      in.close();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNUpgradeUtil.java",
          "extendedDetails": {}
        }
      ]
    },
    "56205ca7d7f3b2a7e55f48b9cf444326e1d2b1a7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5840. Follow-up to HDFS-5138 to improve error handling during partial upgrade failures. Contributed by Aaron T. Myers, Suresh Srinivas, and Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1581260 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/03/14 11:48 PM",
      "commitName": "56205ca7d7f3b2a7e55f48b9cf444326e1d2b1a7",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "25/01/14 12:01 PM",
      "commitNameOld": "edb6dc5f303093c2604cd07b0c0dacf12dbce5de",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 58.45,
      "commitsBetweenForRepo": 537,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,21 @@\n   static void doPreUpgrade(StorageDirectory sd) throws IOException {\n     LOG.info(\"Starting upgrade of storage directory \" + sd.getRoot());\n     File curDir \u003d sd.getCurrentDir();\n     File prevDir \u003d sd.getPreviousDir();\n     File tmpDir \u003d sd.getPreviousTmp();\n-    assert curDir.exists() : \"Current directory must exist.\";\n-    assert !prevDir.exists() : \"previous directory must not exist.\";\n-    assert !tmpDir.exists() : \"previous.tmp directory must not exist.\";\n+\n+    Preconditions.checkState(curDir.exists(),\n+        \"Current directory must exist for preupgrade.\");\n+    Preconditions.checkState(!prevDir.exists(),\n+        \"Previous directory must not exist for preupgrade.\");\n+    Preconditions.checkState(!tmpDir.exists(),\n+        \"Previous.tmp directory must not exist for preupgrade.\"\n+            + \"Consider restarting for recovery.\");\n \n     // rename current to tmp\n     NNStorage.rename(curDir, tmpDir);\n     \n     if (!curDir.mkdir()) {\n       throw new IOException(\"Cannot create directory \" + curDir);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static void doPreUpgrade(StorageDirectory sd) throws IOException {\n    LOG.info(\"Starting upgrade of storage directory \" + sd.getRoot());\n    File curDir \u003d sd.getCurrentDir();\n    File prevDir \u003d sd.getPreviousDir();\n    File tmpDir \u003d sd.getPreviousTmp();\n\n    Preconditions.checkState(curDir.exists(),\n        \"Current directory must exist for preupgrade.\");\n    Preconditions.checkState(!prevDir.exists(),\n        \"Previous directory must not exist for preupgrade.\");\n    Preconditions.checkState(!tmpDir.exists(),\n        \"Previous.tmp directory must not exist for preupgrade.\"\n            + \"Consider restarting for recovery.\");\n\n    // rename current to tmp\n    NNStorage.rename(curDir, tmpDir);\n    \n    if (!curDir.mkdir()) {\n      throw new IOException(\"Cannot create directory \" + curDir);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNUpgradeUtil.java",
      "extendedDetails": {}
    },
    "edb6dc5f303093c2604cd07b0c0dacf12dbce5de": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5138. Support HDFS upgrade in HA. Contributed by Aaron T. Myers.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1561381 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/01/14 12:01 PM",
      "commitName": "edb6dc5f303093c2604cd07b0c0dacf12dbce5de",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,16 @@\n+  static void doPreUpgrade(StorageDirectory sd) throws IOException {\n+    LOG.info(\"Starting upgrade of storage directory \" + sd.getRoot());\n+    File curDir \u003d sd.getCurrentDir();\n+    File prevDir \u003d sd.getPreviousDir();\n+    File tmpDir \u003d sd.getPreviousTmp();\n+    assert curDir.exists() : \"Current directory must exist.\";\n+    assert !prevDir.exists() : \"previous directory must not exist.\";\n+    assert !tmpDir.exists() : \"previous.tmp directory must not exist.\";\n+\n+    // rename current to tmp\n+    NNStorage.rename(curDir, tmpDir);\n+    \n+    if (!curDir.mkdir()) {\n+      throw new IOException(\"Cannot create directory \" + curDir);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static void doPreUpgrade(StorageDirectory sd) throws IOException {\n    LOG.info(\"Starting upgrade of storage directory \" + sd.getRoot());\n    File curDir \u003d sd.getCurrentDir();\n    File prevDir \u003d sd.getPreviousDir();\n    File tmpDir \u003d sd.getPreviousTmp();\n    assert curDir.exists() : \"Current directory must exist.\";\n    assert !prevDir.exists() : \"previous directory must not exist.\";\n    assert !tmpDir.exists() : \"previous.tmp directory must not exist.\";\n\n    // rename current to tmp\n    NNStorage.rename(curDir, tmpDir);\n    \n    if (!curDir.mkdir()) {\n      throw new IOException(\"Cannot create directory \" + curDir);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNUpgradeUtil.java"
    }
  }
}