{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Reducer.java",
  "functionName": "run",
  "functionId": "run___context-Context",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Reducer.java",
  "functionStartLine": 167,
  "functionEndLine": 181,
  "numCommitsSeen": 7,
  "timeTaken": 4417,
  "changeHistory": [
    "40e78c2ca23bcc56e7ceadd30421c05dbad17a1e",
    "9a6da7979ee035b2241c81c48ac4a4ba1e0aee48",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "40e78c2ca23bcc56e7ceadd30421c05dbad17a1e": "Ybodychange",
    "9a6da7979ee035b2241c81c48ac4a4ba1e0aee48": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "40e78c2ca23bcc56e7ceadd30421c05dbad17a1e": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4737. Ensure that mapreduce APIs are semantically consistent with mapred API w.r.t Mapper.cleanup and Reducer.cleanup; in the sense that cleanup is now called even if there is an error. The old mapred API already ensures that Mapper.close and Reducer.close are invoked during error handling. Note that it is an incompatible change, however end-users can override Mapper.run and Reducer.run to get the old (inconsistent) behaviour. Contributed by Arun C. Murthy.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1471556 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/04/13 10:38 AM",
      "commitName": "40e78c2ca23bcc56e7ceadd30421c05dbad17a1e",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "07/11/11 12:13 PM",
      "commitNameOld": "9a6da7979ee035b2241c81c48ac4a4ba1e0aee48",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 533.89,
      "commitsBetweenForRepo": 3113,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,15 @@\n   public void run(Context context) throws IOException, InterruptedException {\n     setup(context);\n-    while (context.nextKey()) {\n-      reduce(context.getCurrentKey(), context.getValues(), context);\n-      // If a back up store is used, reset it\n-      Iterator\u003cVALUEIN\u003e iter \u003d context.getValues().iterator();\n-      if(iter instanceof ReduceContext.ValueIterator) {\n-        ((ReduceContext.ValueIterator\u003cVALUEIN\u003e)iter).resetBackupStore();        \n+    try {\n+      while (context.nextKey()) {\n+        reduce(context.getCurrentKey(), context.getValues(), context);\n+        // If a back up store is used, reset it\n+        Iterator\u003cVALUEIN\u003e iter \u003d context.getValues().iterator();\n+        if(iter instanceof ReduceContext.ValueIterator) {\n+          ((ReduceContext.ValueIterator\u003cVALUEIN\u003e)iter).resetBackupStore();        \n+        }\n       }\n+    } finally {\n+      cleanup(context);\n     }\n-    cleanup(context);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run(Context context) throws IOException, InterruptedException {\n    setup(context);\n    try {\n      while (context.nextKey()) {\n        reduce(context.getCurrentKey(), context.getValues(), context);\n        // If a back up store is used, reset it\n        Iterator\u003cVALUEIN\u003e iter \u003d context.getValues().iterator();\n        if(iter instanceof ReduceContext.ValueIterator) {\n          ((ReduceContext.ValueIterator\u003cVALUEIN\u003e)iter).resetBackupStore();        \n        }\n      }\n    } finally {\n      cleanup(context);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Reducer.java",
      "extendedDetails": {}
    },
    "9a6da7979ee035b2241c81c48ac4a4ba1e0aee48": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3344. o.a.h.mapreduce.Reducer since 0.21 blindly casts to ReduceContext.ValueIterator. Contributed by Brock Noland.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1198910 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/11/11 12:13 PM",
      "commitName": "9a6da7979ee035b2241c81c48ac4a4ba1e0aee48",
      "commitAuthor": "Thomas White",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 74.83,
      "commitsBetweenForRepo": 562,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,12 @@\n   public void run(Context context) throws IOException, InterruptedException {\n     setup(context);\n     while (context.nextKey()) {\n       reduce(context.getCurrentKey(), context.getValues(), context);\n       // If a back up store is used, reset it\n-      ((ReduceContext.ValueIterator)\n-          (context.getValues().iterator())).resetBackupStore();\n+      Iterator\u003cVALUEIN\u003e iter \u003d context.getValues().iterator();\n+      if(iter instanceof ReduceContext.ValueIterator) {\n+        ((ReduceContext.ValueIterator\u003cVALUEIN\u003e)iter).resetBackupStore();        \n+      }\n     }\n     cleanup(context);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run(Context context) throws IOException, InterruptedException {\n    setup(context);\n    while (context.nextKey()) {\n      reduce(context.getCurrentKey(), context.getValues(), context);\n      // If a back up store is used, reset it\n      Iterator\u003cVALUEIN\u003e iter \u003d context.getValues().iterator();\n      if(iter instanceof ReduceContext.ValueIterator) {\n        ((ReduceContext.ValueIterator\u003cVALUEIN\u003e)iter).resetBackupStore();        \n      }\n    }\n    cleanup(context);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Reducer.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void run(Context context) throws IOException, InterruptedException {\n    setup(context);\n    while (context.nextKey()) {\n      reduce(context.getCurrentKey(), context.getValues(), context);\n      // If a back up store is used, reset it\n      ((ReduceContext.ValueIterator)\n          (context.getValues().iterator())).resetBackupStore();\n    }\n    cleanup(context);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Reducer.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Reducer.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Reducer.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void run(Context context) throws IOException, InterruptedException {\n    setup(context);\n    while (context.nextKey()) {\n      reduce(context.getCurrentKey(), context.getValues(), context);\n      // If a back up store is used, reset it\n      ((ReduceContext.ValueIterator)\n          (context.getValues().iterator())).resetBackupStore();\n    }\n    cleanup(context);\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Reducer.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/java/org/apache/hadoop/mapreduce/Reducer.java",
        "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Reducer.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,10 @@\n+  public void run(Context context) throws IOException, InterruptedException {\n+    setup(context);\n+    while (context.nextKey()) {\n+      reduce(context.getCurrentKey(), context.getValues(), context);\n+      // If a back up store is used, reset it\n+      ((ReduceContext.ValueIterator)\n+          (context.getValues().iterator())).resetBackupStore();\n+    }\n+    cleanup(context);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void run(Context context) throws IOException, InterruptedException {\n    setup(context);\n    while (context.nextKey()) {\n      reduce(context.getCurrentKey(), context.getValues(), context);\n      // If a back up store is used, reset it\n      ((ReduceContext.ValueIterator)\n          (context.getValues().iterator())).resetBackupStore();\n    }\n    cleanup(context);\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapreduce/Reducer.java"
    }
  }
}