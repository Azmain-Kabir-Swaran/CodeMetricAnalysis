{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "SLSRunner.java",
  "functionName": "startAMFromSynthGenerator",
  "functionId": "startAMFromSynthGenerator",
  "sourceFilePath": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
  "functionStartLine": 720,
  "functionEndLine": 787,
  "numCommitsSeen": 51,
  "timeTaken": 4481,
  "changeHistory": [
    "9fea5c9ee76bd36f273ae93afef5f3ef3c477a53",
    "7af4f34de54f6e667b47374e31fc9328eba869f0",
    "84cea0011ffe510d24cf9f2952944f7a6fe622cf",
    "16be42d3097c13b17d704e5b6dc8d66bd5ff6d9a",
    "147df300bf00b5f4ed250426b6ccdd69085466da",
    "3369540653a41dd0194b65f5ef1d53225fb97ba8",
    "3082552b3b991df846caf572b58e44308ddf8eeb",
    "475f933b41276b1bdeeec09e30369120f7eccdb8",
    "de69d6e81128470dd5d2fd865d4b3a79188f740b"
  ],
  "changeHistoryShort": {
    "9fea5c9ee76bd36f273ae93afef5f3ef3c477a53": "Ybodychange",
    "7af4f34de54f6e667b47374e31fc9328eba869f0": "Ybodychange",
    "84cea0011ffe510d24cf9f2952944f7a6fe622cf": "Ybodychange",
    "16be42d3097c13b17d704e5b6dc8d66bd5ff6d9a": "Ybodychange",
    "147df300bf00b5f4ed250426b6ccdd69085466da": "Ybodychange",
    "3369540653a41dd0194b65f5ef1d53225fb97ba8": "Ybodychange",
    "3082552b3b991df846caf572b58e44308ddf8eeb": "Ybodychange",
    "475f933b41276b1bdeeec09e30369120f7eccdb8": "Ymultichange(Yparameterchange,Yexceptionschange,Ybodychange)",
    "de69d6e81128470dd5d2fd865d4b3a79188f740b": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9fea5c9ee76bd36f273ae93afef5f3ef3c477a53": {
      "type": "Ybodychange",
      "commitMessage": "YARN-8175. Add support for Node Labels in SLS. Contributed by Abhishek Modi.\n",
      "commitDate": "31/07/18 9:36 AM",
      "commitName": "9fea5c9ee76bd36f273ae93afef5f3ef3c477a53",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "26/04/18 1:52 PM",
      "commitNameOld": "2adda92de1535c0472c0df33a145fa1814703f4f",
      "commitAuthorOld": "Owen O\u0027Malley",
      "daysBetweenCommits": 95.82,
      "commitsBetweenForRepo": 689,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,68 @@\n   private void startAMFromSynthGenerator() throws YarnException, IOException {\n     Configuration localConf \u003d new Configuration();\n     localConf.set(\"fs.defaultFS\", \"file:///\");\n     long baselineTimeMS \u003d 0;\n \n     // if we use the nodeFile this could have been not initialized yet.\n     if (stjp \u003d\u003d null) {\n       stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n     }\n \n     SynthJob job \u003d null;\n     // we use stjp, a reference to the job producer instantiated during node\n     // creation\n     while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n       // only support MapReduce currently\n       String user \u003d job.getUser();\n       String jobQueue \u003d job.getQueueName();\n       String oldJobId \u003d job.getJobID().toString();\n       long jobStartTimeMS \u003d job.getSubmissionTime();\n \n       // CARLO: Finish time is only used for logging, omit for now\n       long jobFinishTimeMS \u003d jobStartTimeMS + job.getDuration();\n \n       if (baselineTimeMS \u003d\u003d 0) {\n         baselineTimeMS \u003d jobStartTimeMS;\n       }\n       jobStartTimeMS -\u003d baselineTimeMS;\n       jobFinishTimeMS -\u003d baselineTimeMS;\n       if (jobStartTimeMS \u003c 0) {\n         LOG.warn(\"Warning: reset job {} start time to 0.\", oldJobId);\n         jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n         jobStartTimeMS \u003d 0;\n       }\n \n       increaseQueueAppNum(jobQueue);\n \n       List\u003cContainerSimulator\u003e containerList \u003d\n           new ArrayList\u003cContainerSimulator\u003e();\n       ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n       Random rand \u003d new Random(stjp.getSeed());\n \n       for (SynthJob.SynthTask task : job.getTasks()) {\n         RMNode node \u003d nmMap.get(keyAsArray.get(rand.nextInt(keyAsArray.size())))\n             .getNode();\n         String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n         long containerLifeTime \u003d task.getTime();\n         Resource containerResource \u003d Resource\n             .newInstance((int) task.getMemory(), (int) task.getVcores());\n         containerList.add(\n             new ContainerSimulator(containerResource, containerLifeTime,\n                 hostname, task.getPriority(), task.getType(),\n                 task.getExecutionType()));\n       }\n \n \n       ReservationId reservationId \u003d null;\n \n       if(job.hasDeadline()){\n         reservationId \u003d ReservationId\n             .newInstance(this.rm.getStartTime(), AM_ID);\n       }\n \n       runNewAM(job.getType(), user, jobQueue, oldJobId,\n           jobStartTimeMS, jobFinishTimeMS, containerList, reservationId,\n-          job.getDeadline(), getAMContainerResource(null),\n+          job.getDeadline(), getAMContainerResource(null), null,\n           job.getParams());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromSynthGenerator() throws YarnException, IOException {\n    Configuration localConf \u003d new Configuration();\n    localConf.set(\"fs.defaultFS\", \"file:///\");\n    long baselineTimeMS \u003d 0;\n\n    // if we use the nodeFile this could have been not initialized yet.\n    if (stjp \u003d\u003d null) {\n      stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n    }\n\n    SynthJob job \u003d null;\n    // we use stjp, a reference to the job producer instantiated during node\n    // creation\n    while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n      // only support MapReduce currently\n      String user \u003d job.getUser();\n      String jobQueue \u003d job.getQueueName();\n      String oldJobId \u003d job.getJobID().toString();\n      long jobStartTimeMS \u003d job.getSubmissionTime();\n\n      // CARLO: Finish time is only used for logging, omit for now\n      long jobFinishTimeMS \u003d jobStartTimeMS + job.getDuration();\n\n      if (baselineTimeMS \u003d\u003d 0) {\n        baselineTimeMS \u003d jobStartTimeMS;\n      }\n      jobStartTimeMS -\u003d baselineTimeMS;\n      jobFinishTimeMS -\u003d baselineTimeMS;\n      if (jobStartTimeMS \u003c 0) {\n        LOG.warn(\"Warning: reset job {} start time to 0.\", oldJobId);\n        jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n        jobStartTimeMS \u003d 0;\n      }\n\n      increaseQueueAppNum(jobQueue);\n\n      List\u003cContainerSimulator\u003e containerList \u003d\n          new ArrayList\u003cContainerSimulator\u003e();\n      ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n      Random rand \u003d new Random(stjp.getSeed());\n\n      for (SynthJob.SynthTask task : job.getTasks()) {\n        RMNode node \u003d nmMap.get(keyAsArray.get(rand.nextInt(keyAsArray.size())))\n            .getNode();\n        String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n        long containerLifeTime \u003d task.getTime();\n        Resource containerResource \u003d Resource\n            .newInstance((int) task.getMemory(), (int) task.getVcores());\n        containerList.add(\n            new ContainerSimulator(containerResource, containerLifeTime,\n                hostname, task.getPriority(), task.getType(),\n                task.getExecutionType()));\n      }\n\n\n      ReservationId reservationId \u003d null;\n\n      if(job.hasDeadline()){\n        reservationId \u003d ReservationId\n            .newInstance(this.rm.getStartTime(), AM_ID);\n      }\n\n      runNewAM(job.getType(), user, jobQueue, oldJobId,\n          jobStartTimeMS, jobFinishTimeMS, containerList, reservationId,\n          job.getDeadline(), getAMContainerResource(null), null,\n          job.getParams());\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "7af4f34de54f6e667b47374e31fc9328eba869f0": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7929. Support to set container execution type in SLS. (Jiandan Yang via Weiwei Yang)\n",
      "commitDate": "28/02/18 1:58 AM",
      "commitName": "7af4f34de54f6e667b47374e31fc9328eba869f0",
      "commitAuthor": "Weiwei Yang",
      "commitDateOld": "20/02/18 5:00 PM",
      "commitNameOld": "84cea0011ffe510d24cf9f2952944f7a6fe622cf",
      "commitAuthorOld": "Carlo Curino",
      "daysBetweenCommits": 7.37,
      "commitsBetweenForRepo": 48,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,68 @@\n   private void startAMFromSynthGenerator() throws YarnException, IOException {\n     Configuration localConf \u003d new Configuration();\n     localConf.set(\"fs.defaultFS\", \"file:///\");\n     long baselineTimeMS \u003d 0;\n \n     // if we use the nodeFile this could have been not initialized yet.\n     if (stjp \u003d\u003d null) {\n       stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n     }\n \n     SynthJob job \u003d null;\n     // we use stjp, a reference to the job producer instantiated during node\n     // creation\n     while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n       // only support MapReduce currently\n       String user \u003d job.getUser();\n       String jobQueue \u003d job.getQueueName();\n       String oldJobId \u003d job.getJobID().toString();\n       long jobStartTimeMS \u003d job.getSubmissionTime();\n \n       // CARLO: Finish time is only used for logging, omit for now\n       long jobFinishTimeMS \u003d jobStartTimeMS + job.getDuration();\n \n       if (baselineTimeMS \u003d\u003d 0) {\n         baselineTimeMS \u003d jobStartTimeMS;\n       }\n       jobStartTimeMS -\u003d baselineTimeMS;\n       jobFinishTimeMS -\u003d baselineTimeMS;\n       if (jobStartTimeMS \u003c 0) {\n         LOG.warn(\"Warning: reset job {} start time to 0.\", oldJobId);\n         jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n         jobStartTimeMS \u003d 0;\n       }\n \n       increaseQueueAppNum(jobQueue);\n \n       List\u003cContainerSimulator\u003e containerList \u003d\n           new ArrayList\u003cContainerSimulator\u003e();\n       ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n       Random rand \u003d new Random(stjp.getSeed());\n \n       for (SynthJob.SynthTask task : job.getTasks()) {\n         RMNode node \u003d nmMap.get(keyAsArray.get(rand.nextInt(keyAsArray.size())))\n             .getNode();\n         String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n         long containerLifeTime \u003d task.getTime();\n         Resource containerResource \u003d Resource\n             .newInstance((int) task.getMemory(), (int) task.getVcores());\n         containerList.add(\n             new ContainerSimulator(containerResource, containerLifeTime,\n-                hostname, task.getPriority(), task.getType()));\n+                hostname, task.getPriority(), task.getType(),\n+                task.getExecutionType()));\n       }\n \n \n       ReservationId reservationId \u003d null;\n \n       if(job.hasDeadline()){\n         reservationId \u003d ReservationId\n             .newInstance(this.rm.getStartTime(), AM_ID);\n       }\n \n       runNewAM(job.getType(), user, jobQueue, oldJobId,\n           jobStartTimeMS, jobFinishTimeMS, containerList, reservationId,\n           job.getDeadline(), getAMContainerResource(null),\n           job.getParams());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromSynthGenerator() throws YarnException, IOException {\n    Configuration localConf \u003d new Configuration();\n    localConf.set(\"fs.defaultFS\", \"file:///\");\n    long baselineTimeMS \u003d 0;\n\n    // if we use the nodeFile this could have been not initialized yet.\n    if (stjp \u003d\u003d null) {\n      stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n    }\n\n    SynthJob job \u003d null;\n    // we use stjp, a reference to the job producer instantiated during node\n    // creation\n    while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n      // only support MapReduce currently\n      String user \u003d job.getUser();\n      String jobQueue \u003d job.getQueueName();\n      String oldJobId \u003d job.getJobID().toString();\n      long jobStartTimeMS \u003d job.getSubmissionTime();\n\n      // CARLO: Finish time is only used for logging, omit for now\n      long jobFinishTimeMS \u003d jobStartTimeMS + job.getDuration();\n\n      if (baselineTimeMS \u003d\u003d 0) {\n        baselineTimeMS \u003d jobStartTimeMS;\n      }\n      jobStartTimeMS -\u003d baselineTimeMS;\n      jobFinishTimeMS -\u003d baselineTimeMS;\n      if (jobStartTimeMS \u003c 0) {\n        LOG.warn(\"Warning: reset job {} start time to 0.\", oldJobId);\n        jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n        jobStartTimeMS \u003d 0;\n      }\n\n      increaseQueueAppNum(jobQueue);\n\n      List\u003cContainerSimulator\u003e containerList \u003d\n          new ArrayList\u003cContainerSimulator\u003e();\n      ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n      Random rand \u003d new Random(stjp.getSeed());\n\n      for (SynthJob.SynthTask task : job.getTasks()) {\n        RMNode node \u003d nmMap.get(keyAsArray.get(rand.nextInt(keyAsArray.size())))\n            .getNode();\n        String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n        long containerLifeTime \u003d task.getTime();\n        Resource containerResource \u003d Resource\n            .newInstance((int) task.getMemory(), (int) task.getVcores());\n        containerList.add(\n            new ContainerSimulator(containerResource, containerLifeTime,\n                hostname, task.getPriority(), task.getType(),\n                task.getExecutionType()));\n      }\n\n\n      ReservationId reservationId \u003d null;\n\n      if(job.hasDeadline()){\n        reservationId \u003d ReservationId\n            .newInstance(this.rm.getStartTime(), AM_ID);\n      }\n\n      runNewAM(job.getType(), user, jobQueue, oldJobId,\n          jobStartTimeMS, jobFinishTimeMS, containerList, reservationId,\n          job.getDeadline(), getAMContainerResource(null),\n          job.getParams());\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "84cea0011ffe510d24cf9f2952944f7a6fe622cf": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7732. Support Generic AM Simulator from SynthGenerator. (Contributed by Young Chen via curino)\n",
      "commitDate": "20/02/18 5:00 PM",
      "commitName": "84cea0011ffe510d24cf9f2952944f7a6fe622cf",
      "commitAuthor": "Carlo Curino",
      "commitDateOld": "25/01/18 1:06 PM",
      "commitNameOld": "16be42d3097c13b17d704e5b6dc8d66bd5ff6d9a",
      "commitAuthorOld": "Yufei Gu",
      "daysBetweenCommits": 26.16,
      "commitsBetweenForRepo": 172,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,67 @@\n   private void startAMFromSynthGenerator() throws YarnException, IOException {\n     Configuration localConf \u003d new Configuration();\n     localConf.set(\"fs.defaultFS\", \"file:///\");\n     long baselineTimeMS \u003d 0;\n \n-    try {\n+    // if we use the nodeFile this could have been not initialized yet.\n+    if (stjp \u003d\u003d null) {\n+      stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n+    }\n \n-      // if we use the nodeFile this could have been not initialized yet.\n-      if (stjp \u003d\u003d null) {\n-        stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n+    SynthJob job \u003d null;\n+    // we use stjp, a reference to the job producer instantiated during node\n+    // creation\n+    while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n+      // only support MapReduce currently\n+      String user \u003d job.getUser();\n+      String jobQueue \u003d job.getQueueName();\n+      String oldJobId \u003d job.getJobID().toString();\n+      long jobStartTimeMS \u003d job.getSubmissionTime();\n+\n+      // CARLO: Finish time is only used for logging, omit for now\n+      long jobFinishTimeMS \u003d jobStartTimeMS + job.getDuration();\n+\n+      if (baselineTimeMS \u003d\u003d 0) {\n+        baselineTimeMS \u003d jobStartTimeMS;\n+      }\n+      jobStartTimeMS -\u003d baselineTimeMS;\n+      jobFinishTimeMS -\u003d baselineTimeMS;\n+      if (jobStartTimeMS \u003c 0) {\n+        LOG.warn(\"Warning: reset job {} start time to 0.\", oldJobId);\n+        jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n+        jobStartTimeMS \u003d 0;\n       }\n \n-      SynthJob job \u003d null;\n-      // we use stjp, a reference to the job producer instantiated during node\n-      // creation\n-      while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n-        // only support MapReduce currently\n-        String user \u003d job.getUser();\n-        String jobQueue \u003d job.getQueueName();\n-        String oldJobId \u003d job.getJobID().toString();\n-        long jobStartTimeMS \u003d job.getSubmissionTime();\n+      increaseQueueAppNum(jobQueue);\n \n-        // CARLO: Finish time is only used for logging, omit for now\n-        long jobFinishTimeMS \u003d -1L;\n+      List\u003cContainerSimulator\u003e containerList \u003d\n+          new ArrayList\u003cContainerSimulator\u003e();\n+      ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n+      Random rand \u003d new Random(stjp.getSeed());\n \n-        if (baselineTimeMS \u003d\u003d 0) {\n-          baselineTimeMS \u003d jobStartTimeMS;\n-        }\n-        jobStartTimeMS -\u003d baselineTimeMS;\n-        jobFinishTimeMS -\u003d baselineTimeMS;\n-        if (jobStartTimeMS \u003c 0) {\n-          LOG.warn(\"Warning: reset job {} start time to 0.\", oldJobId);\n-          jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n-          jobStartTimeMS \u003d 0;\n-        }\n-\n-        increaseQueueAppNum(jobQueue);\n-\n-        List\u003cContainerSimulator\u003e containerList \u003d\n-            new ArrayList\u003cContainerSimulator\u003e();\n-        ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n-        Random rand \u003d new Random(stjp.getSeed());\n-\n-        // map tasks\n-        for (int i \u003d 0; i \u003c job.getNumberMaps(); i++) {\n-          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.MAP, i, 0);\n-          RMNode node \u003d\n-              nmMap.get(keyAsArray.get(rand.nextInt(keyAsArray.size())))\n-                  .getNode();\n-          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n-          long containerLifeTime \u003d tai.getRuntime();\n-          Resource containerResource \u003d\n-              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n-                  (int) tai.getTaskInfo().getTaskVCores());\n-          containerList.add(new ContainerSimulator(containerResource,\n-              containerLifeTime, hostname, DEFAULT_MAPPER_PRIORITY, \"map\"));\n-        }\n-\n-        // reduce tasks\n-        for (int i \u003d 0; i \u003c job.getNumberReduces(); i++) {\n-          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.REDUCE, i, 0);\n-          RMNode node \u003d\n-              nmMap.get(keyAsArray.get(rand.nextInt(keyAsArray.size())))\n-                  .getNode();\n-          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n-          long containerLifeTime \u003d tai.getRuntime();\n-          Resource containerResource \u003d\n-              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n-                  (int) tai.getTaskInfo().getTaskVCores());\n-          containerList.add(\n-              new ContainerSimulator(containerResource, containerLifeTime,\n-                  hostname, DEFAULT_REDUCER_PRIORITY, \"reduce\"));\n-        }\n-\n-        ReservationId reservationId \u003d null;\n-\n-        if (job.hasDeadline()) {\n-          reservationId \u003d\n-              ReservationId.newInstance(this.rm.getStartTime(), AM_ID);\n-        }\n-\n-        runNewAM(SLSUtils.DEFAULT_JOB_TYPE, user, jobQueue, oldJobId,\n-            jobStartTimeMS, jobFinishTimeMS, containerList, reservationId,\n-            job.getDeadline(), getAMContainerResource(null));\n-\n+      for (SynthJob.SynthTask task : job.getTasks()) {\n+        RMNode node \u003d nmMap.get(keyAsArray.get(rand.nextInt(keyAsArray.size())))\n+            .getNode();\n+        String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n+        long containerLifeTime \u003d task.getTime();\n+        Resource containerResource \u003d Resource\n+            .newInstance((int) task.getMemory(), (int) task.getVcores());\n+        containerList.add(\n+            new ContainerSimulator(containerResource, containerLifeTime,\n+                hostname, task.getPriority(), task.getType()));\n       }\n-    } finally {\n-      stjp.close();\n+\n+\n+      ReservationId reservationId \u003d null;\n+\n+      if(job.hasDeadline()){\n+        reservationId \u003d ReservationId\n+            .newInstance(this.rm.getStartTime(), AM_ID);\n+      }\n+\n+      runNewAM(job.getType(), user, jobQueue, oldJobId,\n+          jobStartTimeMS, jobFinishTimeMS, containerList, reservationId,\n+          job.getDeadline(), getAMContainerResource(null),\n+          job.getParams());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromSynthGenerator() throws YarnException, IOException {\n    Configuration localConf \u003d new Configuration();\n    localConf.set(\"fs.defaultFS\", \"file:///\");\n    long baselineTimeMS \u003d 0;\n\n    // if we use the nodeFile this could have been not initialized yet.\n    if (stjp \u003d\u003d null) {\n      stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n    }\n\n    SynthJob job \u003d null;\n    // we use stjp, a reference to the job producer instantiated during node\n    // creation\n    while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n      // only support MapReduce currently\n      String user \u003d job.getUser();\n      String jobQueue \u003d job.getQueueName();\n      String oldJobId \u003d job.getJobID().toString();\n      long jobStartTimeMS \u003d job.getSubmissionTime();\n\n      // CARLO: Finish time is only used for logging, omit for now\n      long jobFinishTimeMS \u003d jobStartTimeMS + job.getDuration();\n\n      if (baselineTimeMS \u003d\u003d 0) {\n        baselineTimeMS \u003d jobStartTimeMS;\n      }\n      jobStartTimeMS -\u003d baselineTimeMS;\n      jobFinishTimeMS -\u003d baselineTimeMS;\n      if (jobStartTimeMS \u003c 0) {\n        LOG.warn(\"Warning: reset job {} start time to 0.\", oldJobId);\n        jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n        jobStartTimeMS \u003d 0;\n      }\n\n      increaseQueueAppNum(jobQueue);\n\n      List\u003cContainerSimulator\u003e containerList \u003d\n          new ArrayList\u003cContainerSimulator\u003e();\n      ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n      Random rand \u003d new Random(stjp.getSeed());\n\n      for (SynthJob.SynthTask task : job.getTasks()) {\n        RMNode node \u003d nmMap.get(keyAsArray.get(rand.nextInt(keyAsArray.size())))\n            .getNode();\n        String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n        long containerLifeTime \u003d task.getTime();\n        Resource containerResource \u003d Resource\n            .newInstance((int) task.getMemory(), (int) task.getVcores());\n        containerList.add(\n            new ContainerSimulator(containerResource, containerLifeTime,\n                hostname, task.getPriority(), task.getType()));\n      }\n\n\n      ReservationId reservationId \u003d null;\n\n      if(job.hasDeadline()){\n        reservationId \u003d ReservationId\n            .newInstance(this.rm.getStartTime(), AM_ID);\n      }\n\n      runNewAM(job.getType(), user, jobQueue, oldJobId,\n          jobStartTimeMS, jobFinishTimeMS, containerList, reservationId,\n          job.getDeadline(), getAMContainerResource(null),\n          job.getParams());\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "16be42d3097c13b17d704e5b6dc8d66bd5ff6d9a": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7798. Refactor SLS Reservation Creation. Contributed by Young Chen.\n",
      "commitDate": "25/01/18 1:06 PM",
      "commitName": "16be42d3097c13b17d704e5b6dc8d66bd5ff6d9a",
      "commitAuthor": "Yufei Gu",
      "commitDateOld": "09/11/17 12:09 PM",
      "commitNameOld": "ba8136615ab66c450884614557eddc6509d63b7c",
      "commitAuthorOld": "Daniel Templeton",
      "daysBetweenCommits": 77.04,
      "commitsBetweenForRepo": 408,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,111 +1,90 @@\n   private void startAMFromSynthGenerator() throws YarnException, IOException {\n     Configuration localConf \u003d new Configuration();\n     localConf.set(\"fs.defaultFS\", \"file:///\");\n     long baselineTimeMS \u003d 0;\n \n-    // reservations use wall clock time, so need to have a reference for that\n-    UTCClock clock \u003d new UTCClock();\n-    long now \u003d clock.getTime();\n-\n     try {\n \n       // if we use the nodeFile this could have been not initialized yet.\n       if (stjp \u003d\u003d null) {\n         stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n       }\n \n       SynthJob job \u003d null;\n       // we use stjp, a reference to the job producer instantiated during node\n       // creation\n       while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n         // only support MapReduce currently\n         String user \u003d job.getUser();\n         String jobQueue \u003d job.getQueueName();\n         String oldJobId \u003d job.getJobID().toString();\n         long jobStartTimeMS \u003d job.getSubmissionTime();\n \n         // CARLO: Finish time is only used for logging, omit for now\n         long jobFinishTimeMS \u003d -1L;\n \n         if (baselineTimeMS \u003d\u003d 0) {\n           baselineTimeMS \u003d jobStartTimeMS;\n         }\n         jobStartTimeMS -\u003d baselineTimeMS;\n         jobFinishTimeMS -\u003d baselineTimeMS;\n         if (jobStartTimeMS \u003c 0) {\n           LOG.warn(\"Warning: reset job {} start time to 0.\", oldJobId);\n           jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n           jobStartTimeMS \u003d 0;\n         }\n \n         increaseQueueAppNum(jobQueue);\n \n         List\u003cContainerSimulator\u003e containerList \u003d\n             new ArrayList\u003cContainerSimulator\u003e();\n         ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n         Random rand \u003d new Random(stjp.getSeed());\n \n-        Resource maxMapRes \u003d Resource.newInstance(0, 0);\n-        long maxMapDur \u003d 0;\n         // map tasks\n         for (int i \u003d 0; i \u003c job.getNumberMaps(); i++) {\n           TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.MAP, i, 0);\n-          RMNode node \u003d nmMap\n-              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n+          RMNode node \u003d\n+              nmMap.get(keyAsArray.get(rand.nextInt(keyAsArray.size())))\n+                  .getNode();\n           String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n           long containerLifeTime \u003d tai.getRuntime();\n           Resource containerResource \u003d\n               Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                   (int) tai.getTaskInfo().getTaskVCores());\n           containerList.add(new ContainerSimulator(containerResource,\n               containerLifeTime, hostname, DEFAULT_MAPPER_PRIORITY, \"map\"));\n-          maxMapRes \u003d Resources.componentwiseMax(maxMapRes, containerResource);\n-          maxMapDur \u003d\n-              containerLifeTime \u003e maxMapDur ? containerLifeTime : maxMapDur;\n-\n         }\n \n-        Resource maxRedRes \u003d Resource.newInstance(0, 0);\n-        long maxRedDur \u003d 0;\n         // reduce tasks\n         for (int i \u003d 0; i \u003c job.getNumberReduces(); i++) {\n           TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.REDUCE, i, 0);\n-          RMNode node \u003d nmMap\n-              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n+          RMNode node \u003d\n+              nmMap.get(keyAsArray.get(rand.nextInt(keyAsArray.size())))\n+                  .getNode();\n           String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n           long containerLifeTime \u003d tai.getRuntime();\n           Resource containerResource \u003d\n               Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                   (int) tai.getTaskInfo().getTaskVCores());\n-          containerList.add(new ContainerSimulator(containerResource,\n-              containerLifeTime, hostname, DEFAULT_REDUCER_PRIORITY, \"reduce\"));\n-          maxRedRes \u003d Resources.componentwiseMax(maxRedRes, containerResource);\n-          maxRedDur \u003d\n-              containerLifeTime \u003e maxRedDur ? containerLifeTime : maxRedDur;\n-\n+          containerList.add(\n+              new ContainerSimulator(containerResource, containerLifeTime,\n+                  hostname, DEFAULT_REDUCER_PRIORITY, \"reduce\"));\n         }\n \n-        // generating reservations for the jobs that require them\n+        ReservationId reservationId \u003d null;\n \n-        ReservationSubmissionRequest rr \u003d null;\n         if (job.hasDeadline()) {\n-          ReservationId reservationId \u003d\n+          reservationId \u003d\n               ReservationId.newInstance(this.rm.getStartTime(), AM_ID);\n-\n-          rr \u003d ReservationClientUtil.createMRReservation(reservationId,\n-              \"reservation_\" + AM_ID, maxMapRes, job.getNumberMaps(), maxMapDur,\n-              maxRedRes, job.getNumberReduces(), maxRedDur,\n-              now + jobStartTimeMS, now + job.getDeadline(),\n-              job.getQueueName());\n-\n         }\n \n         runNewAM(SLSUtils.DEFAULT_JOB_TYPE, user, jobQueue, oldJobId,\n-            jobStartTimeMS, jobFinishTimeMS, containerList, rr,\n-            getAMContainerResource(null));\n+            jobStartTimeMS, jobFinishTimeMS, containerList, reservationId,\n+            job.getDeadline(), getAMContainerResource(null));\n+\n       }\n     } finally {\n       stjp.close();\n     }\n-\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromSynthGenerator() throws YarnException, IOException {\n    Configuration localConf \u003d new Configuration();\n    localConf.set(\"fs.defaultFS\", \"file:///\");\n    long baselineTimeMS \u003d 0;\n\n    try {\n\n      // if we use the nodeFile this could have been not initialized yet.\n      if (stjp \u003d\u003d null) {\n        stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n      }\n\n      SynthJob job \u003d null;\n      // we use stjp, a reference to the job producer instantiated during node\n      // creation\n      while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n        // only support MapReduce currently\n        String user \u003d job.getUser();\n        String jobQueue \u003d job.getQueueName();\n        String oldJobId \u003d job.getJobID().toString();\n        long jobStartTimeMS \u003d job.getSubmissionTime();\n\n        // CARLO: Finish time is only used for logging, omit for now\n        long jobFinishTimeMS \u003d -1L;\n\n        if (baselineTimeMS \u003d\u003d 0) {\n          baselineTimeMS \u003d jobStartTimeMS;\n        }\n        jobStartTimeMS -\u003d baselineTimeMS;\n        jobFinishTimeMS -\u003d baselineTimeMS;\n        if (jobStartTimeMS \u003c 0) {\n          LOG.warn(\"Warning: reset job {} start time to 0.\", oldJobId);\n          jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n          jobStartTimeMS \u003d 0;\n        }\n\n        increaseQueueAppNum(jobQueue);\n\n        List\u003cContainerSimulator\u003e containerList \u003d\n            new ArrayList\u003cContainerSimulator\u003e();\n        ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n        Random rand \u003d new Random(stjp.getSeed());\n\n        // map tasks\n        for (int i \u003d 0; i \u003c job.getNumberMaps(); i++) {\n          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.MAP, i, 0);\n          RMNode node \u003d\n              nmMap.get(keyAsArray.get(rand.nextInt(keyAsArray.size())))\n                  .getNode();\n          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n          long containerLifeTime \u003d tai.getRuntime();\n          Resource containerResource \u003d\n              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                  (int) tai.getTaskInfo().getTaskVCores());\n          containerList.add(new ContainerSimulator(containerResource,\n              containerLifeTime, hostname, DEFAULT_MAPPER_PRIORITY, \"map\"));\n        }\n\n        // reduce tasks\n        for (int i \u003d 0; i \u003c job.getNumberReduces(); i++) {\n          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.REDUCE, i, 0);\n          RMNode node \u003d\n              nmMap.get(keyAsArray.get(rand.nextInt(keyAsArray.size())))\n                  .getNode();\n          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n          long containerLifeTime \u003d tai.getRuntime();\n          Resource containerResource \u003d\n              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                  (int) tai.getTaskInfo().getTaskVCores());\n          containerList.add(\n              new ContainerSimulator(containerResource, containerLifeTime,\n                  hostname, DEFAULT_REDUCER_PRIORITY, \"reduce\"));\n        }\n\n        ReservationId reservationId \u003d null;\n\n        if (job.hasDeadline()) {\n          reservationId \u003d\n              ReservationId.newInstance(this.rm.getStartTime(), AM_ID);\n        }\n\n        runNewAM(SLSUtils.DEFAULT_JOB_TYPE, user, jobQueue, oldJobId,\n            jobStartTimeMS, jobFinishTimeMS, containerList, reservationId,\n            job.getDeadline(), getAMContainerResource(null));\n\n      }\n    } finally {\n      stjp.close();\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "147df300bf00b5f4ed250426b6ccdd69085466da": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5067 Support specifying resources for AM containers in SLS. (Yufei Gu via Haibo Chen)\n",
      "commitDate": "30/06/17 5:03 PM",
      "commitName": "147df300bf00b5f4ed250426b6ccdd69085466da",
      "commitAuthor": "Haibo Chen",
      "commitDateOld": "19/06/17 9:18 PM",
      "commitNameOld": "3369540653a41dd0194b65f5ef1d53225fb97ba8",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 10.82,
      "commitsBetweenForRepo": 71,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,110 +1,111 @@\n   private void startAMFromSynthGenerator() throws YarnException, IOException {\n     Configuration localConf \u003d new Configuration();\n     localConf.set(\"fs.defaultFS\", \"file:///\");\n     long baselineTimeMS \u003d 0;\n \n     // reservations use wall clock time, so need to have a reference for that\n     UTCClock clock \u003d new UTCClock();\n     long now \u003d clock.getTime();\n \n     try {\n \n       // if we use the nodeFile this could have been not initialized yet.\n       if (stjp \u003d\u003d null) {\n         stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n       }\n \n       SynthJob job \u003d null;\n       // we use stjp, a reference to the job producer instantiated during node\n       // creation\n       while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n         // only support MapReduce currently\n         String user \u003d job.getUser();\n         String jobQueue \u003d job.getQueueName();\n         String oldJobId \u003d job.getJobID().toString();\n         long jobStartTimeMS \u003d job.getSubmissionTime();\n \n         // CARLO: Finish time is only used for logging, omit for now\n         long jobFinishTimeMS \u003d -1L;\n \n         if (baselineTimeMS \u003d\u003d 0) {\n           baselineTimeMS \u003d jobStartTimeMS;\n         }\n         jobStartTimeMS -\u003d baselineTimeMS;\n         jobFinishTimeMS -\u003d baselineTimeMS;\n         if (jobStartTimeMS \u003c 0) {\n           LOG.warn(\"Warning: reset job {} start time to 0.\", oldJobId);\n           jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n           jobStartTimeMS \u003d 0;\n         }\n \n         increaseQueueAppNum(jobQueue);\n \n         List\u003cContainerSimulator\u003e containerList \u003d\n             new ArrayList\u003cContainerSimulator\u003e();\n         ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n         Random rand \u003d new Random(stjp.getSeed());\n \n         Resource maxMapRes \u003d Resource.newInstance(0, 0);\n         long maxMapDur \u003d 0;\n         // map tasks\n         for (int i \u003d 0; i \u003c job.getNumberMaps(); i++) {\n           TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.MAP, i, 0);\n           RMNode node \u003d nmMap\n               .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n           String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n           long containerLifeTime \u003d tai.getRuntime();\n           Resource containerResource \u003d\n               Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                   (int) tai.getTaskInfo().getTaskVCores());\n           containerList.add(new ContainerSimulator(containerResource,\n               containerLifeTime, hostname, DEFAULT_MAPPER_PRIORITY, \"map\"));\n           maxMapRes \u003d Resources.componentwiseMax(maxMapRes, containerResource);\n           maxMapDur \u003d\n               containerLifeTime \u003e maxMapDur ? containerLifeTime : maxMapDur;\n \n         }\n \n         Resource maxRedRes \u003d Resource.newInstance(0, 0);\n         long maxRedDur \u003d 0;\n         // reduce tasks\n         for (int i \u003d 0; i \u003c job.getNumberReduces(); i++) {\n           TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.REDUCE, i, 0);\n           RMNode node \u003d nmMap\n               .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n           String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n           long containerLifeTime \u003d tai.getRuntime();\n           Resource containerResource \u003d\n               Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                   (int) tai.getTaskInfo().getTaskVCores());\n           containerList.add(new ContainerSimulator(containerResource,\n               containerLifeTime, hostname, DEFAULT_REDUCER_PRIORITY, \"reduce\"));\n           maxRedRes \u003d Resources.componentwiseMax(maxRedRes, containerResource);\n           maxRedDur \u003d\n               containerLifeTime \u003e maxRedDur ? containerLifeTime : maxRedDur;\n \n         }\n \n         // generating reservations for the jobs that require them\n \n         ReservationSubmissionRequest rr \u003d null;\n         if (job.hasDeadline()) {\n           ReservationId reservationId \u003d\n               ReservationId.newInstance(this.rm.getStartTime(), AM_ID);\n \n           rr \u003d ReservationClientUtil.createMRReservation(reservationId,\n               \"reservation_\" + AM_ID, maxMapRes, job.getNumberMaps(), maxMapDur,\n               maxRedRes, job.getNumberReduces(), maxRedDur,\n               now + jobStartTimeMS, now + job.getDeadline(),\n               job.getQueueName());\n \n         }\n \n         runNewAM(SLSUtils.DEFAULT_JOB_TYPE, user, jobQueue, oldJobId,\n-            jobStartTimeMS, jobFinishTimeMS, containerList, rr);\n+            jobStartTimeMS, jobFinishTimeMS, containerList, rr,\n+            getAMContainerResource(null));\n       }\n     } finally {\n       stjp.close();\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromSynthGenerator() throws YarnException, IOException {\n    Configuration localConf \u003d new Configuration();\n    localConf.set(\"fs.defaultFS\", \"file:///\");\n    long baselineTimeMS \u003d 0;\n\n    // reservations use wall clock time, so need to have a reference for that\n    UTCClock clock \u003d new UTCClock();\n    long now \u003d clock.getTime();\n\n    try {\n\n      // if we use the nodeFile this could have been not initialized yet.\n      if (stjp \u003d\u003d null) {\n        stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n      }\n\n      SynthJob job \u003d null;\n      // we use stjp, a reference to the job producer instantiated during node\n      // creation\n      while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n        // only support MapReduce currently\n        String user \u003d job.getUser();\n        String jobQueue \u003d job.getQueueName();\n        String oldJobId \u003d job.getJobID().toString();\n        long jobStartTimeMS \u003d job.getSubmissionTime();\n\n        // CARLO: Finish time is only used for logging, omit for now\n        long jobFinishTimeMS \u003d -1L;\n\n        if (baselineTimeMS \u003d\u003d 0) {\n          baselineTimeMS \u003d jobStartTimeMS;\n        }\n        jobStartTimeMS -\u003d baselineTimeMS;\n        jobFinishTimeMS -\u003d baselineTimeMS;\n        if (jobStartTimeMS \u003c 0) {\n          LOG.warn(\"Warning: reset job {} start time to 0.\", oldJobId);\n          jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n          jobStartTimeMS \u003d 0;\n        }\n\n        increaseQueueAppNum(jobQueue);\n\n        List\u003cContainerSimulator\u003e containerList \u003d\n            new ArrayList\u003cContainerSimulator\u003e();\n        ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n        Random rand \u003d new Random(stjp.getSeed());\n\n        Resource maxMapRes \u003d Resource.newInstance(0, 0);\n        long maxMapDur \u003d 0;\n        // map tasks\n        for (int i \u003d 0; i \u003c job.getNumberMaps(); i++) {\n          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.MAP, i, 0);\n          RMNode node \u003d nmMap\n              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n          long containerLifeTime \u003d tai.getRuntime();\n          Resource containerResource \u003d\n              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                  (int) tai.getTaskInfo().getTaskVCores());\n          containerList.add(new ContainerSimulator(containerResource,\n              containerLifeTime, hostname, DEFAULT_MAPPER_PRIORITY, \"map\"));\n          maxMapRes \u003d Resources.componentwiseMax(maxMapRes, containerResource);\n          maxMapDur \u003d\n              containerLifeTime \u003e maxMapDur ? containerLifeTime : maxMapDur;\n\n        }\n\n        Resource maxRedRes \u003d Resource.newInstance(0, 0);\n        long maxRedDur \u003d 0;\n        // reduce tasks\n        for (int i \u003d 0; i \u003c job.getNumberReduces(); i++) {\n          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.REDUCE, i, 0);\n          RMNode node \u003d nmMap\n              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n          long containerLifeTime \u003d tai.getRuntime();\n          Resource containerResource \u003d\n              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                  (int) tai.getTaskInfo().getTaskVCores());\n          containerList.add(new ContainerSimulator(containerResource,\n              containerLifeTime, hostname, DEFAULT_REDUCER_PRIORITY, \"reduce\"));\n          maxRedRes \u003d Resources.componentwiseMax(maxRedRes, containerResource);\n          maxRedDur \u003d\n              containerLifeTime \u003e maxRedDur ? containerLifeTime : maxRedDur;\n\n        }\n\n        // generating reservations for the jobs that require them\n\n        ReservationSubmissionRequest rr \u003d null;\n        if (job.hasDeadline()) {\n          ReservationId reservationId \u003d\n              ReservationId.newInstance(this.rm.getStartTime(), AM_ID);\n\n          rr \u003d ReservationClientUtil.createMRReservation(reservationId,\n              \"reservation_\" + AM_ID, maxMapRes, job.getNumberMaps(), maxMapDur,\n              maxRedRes, job.getNumberReduces(), maxRedDur,\n              now + jobStartTimeMS, now + job.getDeadline(),\n              job.getQueueName());\n\n        }\n\n        runNewAM(SLSUtils.DEFAULT_JOB_TYPE, user, jobQueue, oldJobId,\n            jobStartTimeMS, jobFinishTimeMS, containerList, rr,\n            getAMContainerResource(null));\n      }\n    } finally {\n      stjp.close();\n    }\n\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "3369540653a41dd0194b65f5ef1d53225fb97ba8": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14296. Move logging APIs over to slf4j in hadoop-tools.\n",
      "commitDate": "19/06/17 9:18 PM",
      "commitName": "3369540653a41dd0194b65f5ef1d53225fb97ba8",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "06/06/17 5:19 PM",
      "commitNameOld": "b65100c14bf9134de2bd8248dc62735682bee26c",
      "commitAuthorOld": "Carlo Curino",
      "daysBetweenCommits": 13.17,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,110 +1,110 @@\n   private void startAMFromSynthGenerator() throws YarnException, IOException {\n     Configuration localConf \u003d new Configuration();\n     localConf.set(\"fs.defaultFS\", \"file:///\");\n     long baselineTimeMS \u003d 0;\n \n     // reservations use wall clock time, so need to have a reference for that\n     UTCClock clock \u003d new UTCClock();\n     long now \u003d clock.getTime();\n \n     try {\n \n       // if we use the nodeFile this could have been not initialized yet.\n       if (stjp \u003d\u003d null) {\n         stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n       }\n \n       SynthJob job \u003d null;\n       // we use stjp, a reference to the job producer instantiated during node\n       // creation\n       while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n         // only support MapReduce currently\n         String user \u003d job.getUser();\n         String jobQueue \u003d job.getQueueName();\n         String oldJobId \u003d job.getJobID().toString();\n         long jobStartTimeMS \u003d job.getSubmissionTime();\n \n         // CARLO: Finish time is only used for logging, omit for now\n         long jobFinishTimeMS \u003d -1L;\n \n         if (baselineTimeMS \u003d\u003d 0) {\n           baselineTimeMS \u003d jobStartTimeMS;\n         }\n         jobStartTimeMS -\u003d baselineTimeMS;\n         jobFinishTimeMS -\u003d baselineTimeMS;\n         if (jobStartTimeMS \u003c 0) {\n-          LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n+          LOG.warn(\"Warning: reset job {} start time to 0.\", oldJobId);\n           jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n           jobStartTimeMS \u003d 0;\n         }\n \n         increaseQueueAppNum(jobQueue);\n \n         List\u003cContainerSimulator\u003e containerList \u003d\n             new ArrayList\u003cContainerSimulator\u003e();\n         ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n         Random rand \u003d new Random(stjp.getSeed());\n \n         Resource maxMapRes \u003d Resource.newInstance(0, 0);\n         long maxMapDur \u003d 0;\n         // map tasks\n         for (int i \u003d 0; i \u003c job.getNumberMaps(); i++) {\n           TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.MAP, i, 0);\n           RMNode node \u003d nmMap\n               .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n           String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n           long containerLifeTime \u003d tai.getRuntime();\n           Resource containerResource \u003d\n               Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                   (int) tai.getTaskInfo().getTaskVCores());\n           containerList.add(new ContainerSimulator(containerResource,\n               containerLifeTime, hostname, DEFAULT_MAPPER_PRIORITY, \"map\"));\n           maxMapRes \u003d Resources.componentwiseMax(maxMapRes, containerResource);\n           maxMapDur \u003d\n               containerLifeTime \u003e maxMapDur ? containerLifeTime : maxMapDur;\n \n         }\n \n         Resource maxRedRes \u003d Resource.newInstance(0, 0);\n         long maxRedDur \u003d 0;\n         // reduce tasks\n         for (int i \u003d 0; i \u003c job.getNumberReduces(); i++) {\n           TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.REDUCE, i, 0);\n           RMNode node \u003d nmMap\n               .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n           String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n           long containerLifeTime \u003d tai.getRuntime();\n           Resource containerResource \u003d\n               Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                   (int) tai.getTaskInfo().getTaskVCores());\n           containerList.add(new ContainerSimulator(containerResource,\n               containerLifeTime, hostname, DEFAULT_REDUCER_PRIORITY, \"reduce\"));\n           maxRedRes \u003d Resources.componentwiseMax(maxRedRes, containerResource);\n           maxRedDur \u003d\n               containerLifeTime \u003e maxRedDur ? containerLifeTime : maxRedDur;\n \n         }\n \n         // generating reservations for the jobs that require them\n \n         ReservationSubmissionRequest rr \u003d null;\n         if (job.hasDeadline()) {\n           ReservationId reservationId \u003d\n               ReservationId.newInstance(this.rm.getStartTime(), AM_ID);\n \n           rr \u003d ReservationClientUtil.createMRReservation(reservationId,\n               \"reservation_\" + AM_ID, maxMapRes, job.getNumberMaps(), maxMapDur,\n               maxRedRes, job.getNumberReduces(), maxRedDur,\n               now + jobStartTimeMS, now + job.getDeadline(),\n               job.getQueueName());\n \n         }\n \n         runNewAM(SLSUtils.DEFAULT_JOB_TYPE, user, jobQueue, oldJobId,\n             jobStartTimeMS, jobFinishTimeMS, containerList, rr);\n       }\n     } finally {\n       stjp.close();\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromSynthGenerator() throws YarnException, IOException {\n    Configuration localConf \u003d new Configuration();\n    localConf.set(\"fs.defaultFS\", \"file:///\");\n    long baselineTimeMS \u003d 0;\n\n    // reservations use wall clock time, so need to have a reference for that\n    UTCClock clock \u003d new UTCClock();\n    long now \u003d clock.getTime();\n\n    try {\n\n      // if we use the nodeFile this could have been not initialized yet.\n      if (stjp \u003d\u003d null) {\n        stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n      }\n\n      SynthJob job \u003d null;\n      // we use stjp, a reference to the job producer instantiated during node\n      // creation\n      while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n        // only support MapReduce currently\n        String user \u003d job.getUser();\n        String jobQueue \u003d job.getQueueName();\n        String oldJobId \u003d job.getJobID().toString();\n        long jobStartTimeMS \u003d job.getSubmissionTime();\n\n        // CARLO: Finish time is only used for logging, omit for now\n        long jobFinishTimeMS \u003d -1L;\n\n        if (baselineTimeMS \u003d\u003d 0) {\n          baselineTimeMS \u003d jobStartTimeMS;\n        }\n        jobStartTimeMS -\u003d baselineTimeMS;\n        jobFinishTimeMS -\u003d baselineTimeMS;\n        if (jobStartTimeMS \u003c 0) {\n          LOG.warn(\"Warning: reset job {} start time to 0.\", oldJobId);\n          jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n          jobStartTimeMS \u003d 0;\n        }\n\n        increaseQueueAppNum(jobQueue);\n\n        List\u003cContainerSimulator\u003e containerList \u003d\n            new ArrayList\u003cContainerSimulator\u003e();\n        ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n        Random rand \u003d new Random(stjp.getSeed());\n\n        Resource maxMapRes \u003d Resource.newInstance(0, 0);\n        long maxMapDur \u003d 0;\n        // map tasks\n        for (int i \u003d 0; i \u003c job.getNumberMaps(); i++) {\n          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.MAP, i, 0);\n          RMNode node \u003d nmMap\n              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n          long containerLifeTime \u003d tai.getRuntime();\n          Resource containerResource \u003d\n              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                  (int) tai.getTaskInfo().getTaskVCores());\n          containerList.add(new ContainerSimulator(containerResource,\n              containerLifeTime, hostname, DEFAULT_MAPPER_PRIORITY, \"map\"));\n          maxMapRes \u003d Resources.componentwiseMax(maxMapRes, containerResource);\n          maxMapDur \u003d\n              containerLifeTime \u003e maxMapDur ? containerLifeTime : maxMapDur;\n\n        }\n\n        Resource maxRedRes \u003d Resource.newInstance(0, 0);\n        long maxRedDur \u003d 0;\n        // reduce tasks\n        for (int i \u003d 0; i \u003c job.getNumberReduces(); i++) {\n          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.REDUCE, i, 0);\n          RMNode node \u003d nmMap\n              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n          long containerLifeTime \u003d tai.getRuntime();\n          Resource containerResource \u003d\n              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                  (int) tai.getTaskInfo().getTaskVCores());\n          containerList.add(new ContainerSimulator(containerResource,\n              containerLifeTime, hostname, DEFAULT_REDUCER_PRIORITY, \"reduce\"));\n          maxRedRes \u003d Resources.componentwiseMax(maxRedRes, containerResource);\n          maxRedDur \u003d\n              containerLifeTime \u003e maxRedDur ? containerLifeTime : maxRedDur;\n\n        }\n\n        // generating reservations for the jobs that require them\n\n        ReservationSubmissionRequest rr \u003d null;\n        if (job.hasDeadline()) {\n          ReservationId reservationId \u003d\n              ReservationId.newInstance(this.rm.getStartTime(), AM_ID);\n\n          rr \u003d ReservationClientUtil.createMRReservation(reservationId,\n              \"reservation_\" + AM_ID, maxMapRes, job.getNumberMaps(), maxMapDur,\n              maxRedRes, job.getNumberReduces(), maxRedDur,\n              now + jobStartTimeMS, now + job.getDeadline(),\n              job.getQueueName());\n\n        }\n\n        runNewAM(SLSUtils.DEFAULT_JOB_TYPE, user, jobQueue, oldJobId,\n            jobStartTimeMS, jobFinishTimeMS, containerList, rr);\n      }\n    } finally {\n      stjp.close();\n    }\n\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "3082552b3b991df846caf572b58e44308ddf8eeb": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6522. Make SLS JSON input file format simple and scalable (yufeigu via rkanter)\n",
      "commitDate": "04/05/17 5:21 PM",
      "commitName": "3082552b3b991df846caf572b58e44308ddf8eeb",
      "commitAuthor": "Robert Kanter",
      "commitDateOld": "25/04/17 4:26 PM",
      "commitNameOld": "475f933b41276b1bdeeec09e30369120f7eccdb8",
      "commitAuthorOld": "Robert Kanter",
      "daysBetweenCommits": 9.04,
      "commitsBetweenForRepo": 67,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,110 +1,110 @@\n   private void startAMFromSynthGenerator() throws YarnException, IOException {\n     Configuration localConf \u003d new Configuration();\n     localConf.set(\"fs.defaultFS\", \"file:///\");\n     long baselineTimeMS \u003d 0;\n \n     // reservations use wall clock time, so need to have a reference for that\n     UTCClock clock \u003d new UTCClock();\n     long now \u003d clock.getTime();\n \n     try {\n \n       // if we use the nodeFile this could have been not initialized yet.\n       if (stjp \u003d\u003d null) {\n         stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n       }\n \n       SynthJob job \u003d null;\n       // we use stjp, a reference to the job producer instantiated during node\n       // creation\n       while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n         // only support MapReduce currently\n         String user \u003d job.getUser();\n         String jobQueue \u003d job.getQueueName();\n         String oldJobId \u003d job.getJobID().toString();\n         long jobStartTimeMS \u003d job.getSubmissionTime();\n \n         // CARLO: Finish time is only used for logging, omit for now\n         long jobFinishTimeMS \u003d -1L;\n \n         if (baselineTimeMS \u003d\u003d 0) {\n           baselineTimeMS \u003d jobStartTimeMS;\n         }\n         jobStartTimeMS -\u003d baselineTimeMS;\n         jobFinishTimeMS -\u003d baselineTimeMS;\n         if (jobStartTimeMS \u003c 0) {\n           LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n           jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n           jobStartTimeMS \u003d 0;\n         }\n \n         increaseQueueAppNum(jobQueue);\n \n         List\u003cContainerSimulator\u003e containerList \u003d\n             new ArrayList\u003cContainerSimulator\u003e();\n         ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n         Random rand \u003d new Random(stjp.getSeed());\n \n         Resource maxMapRes \u003d Resource.newInstance(0, 0);\n         long maxMapDur \u003d 0;\n         // map tasks\n         for (int i \u003d 0; i \u003c job.getNumberMaps(); i++) {\n           TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.MAP, i, 0);\n           RMNode node \u003d nmMap\n               .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n           String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n           long containerLifeTime \u003d tai.getRuntime();\n           Resource containerResource \u003d\n               Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                   (int) tai.getTaskInfo().getTaskVCores());\n           containerList.add(new ContainerSimulator(containerResource,\n-              containerLifeTime, hostname, 10, \"map\"));\n+              containerLifeTime, hostname, DEFAULT_MAPPER_PRIORITY, \"map\"));\n           maxMapRes \u003d Resources.componentwiseMax(maxMapRes, containerResource);\n           maxMapDur \u003d\n               containerLifeTime \u003e maxMapDur ? containerLifeTime : maxMapDur;\n \n         }\n \n         Resource maxRedRes \u003d Resource.newInstance(0, 0);\n         long maxRedDur \u003d 0;\n         // reduce tasks\n         for (int i \u003d 0; i \u003c job.getNumberReduces(); i++) {\n           TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.REDUCE, i, 0);\n           RMNode node \u003d nmMap\n               .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n           String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n           long containerLifeTime \u003d tai.getRuntime();\n           Resource containerResource \u003d\n               Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                   (int) tai.getTaskInfo().getTaskVCores());\n           containerList.add(new ContainerSimulator(containerResource,\n-              containerLifeTime, hostname, 20, \"reduce\"));\n+              containerLifeTime, hostname, DEFAULT_REDUCER_PRIORITY, \"reduce\"));\n           maxRedRes \u003d Resources.componentwiseMax(maxRedRes, containerResource);\n           maxRedDur \u003d\n               containerLifeTime \u003e maxRedDur ? containerLifeTime : maxRedDur;\n \n         }\n \n         // generating reservations for the jobs that require them\n \n         ReservationSubmissionRequest rr \u003d null;\n         if (job.hasDeadline()) {\n           ReservationId reservationId \u003d\n               ReservationId.newInstance(this.rm.getStartTime(), AM_ID);\n \n           rr \u003d ReservationClientUtil.createMRReservation(reservationId,\n               \"reservation_\" + AM_ID, maxMapRes, job.getNumberMaps(), maxMapDur,\n               maxRedRes, job.getNumberReduces(), maxRedDur,\n               now + jobStartTimeMS, now + job.getDeadline(),\n               job.getQueueName());\n \n         }\n \n         runNewAM(SLSUtils.DEFAULT_JOB_TYPE, user, jobQueue, oldJobId,\n             jobStartTimeMS, jobFinishTimeMS, containerList, rr);\n       }\n     } finally {\n       stjp.close();\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromSynthGenerator() throws YarnException, IOException {\n    Configuration localConf \u003d new Configuration();\n    localConf.set(\"fs.defaultFS\", \"file:///\");\n    long baselineTimeMS \u003d 0;\n\n    // reservations use wall clock time, so need to have a reference for that\n    UTCClock clock \u003d new UTCClock();\n    long now \u003d clock.getTime();\n\n    try {\n\n      // if we use the nodeFile this could have been not initialized yet.\n      if (stjp \u003d\u003d null) {\n        stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n      }\n\n      SynthJob job \u003d null;\n      // we use stjp, a reference to the job producer instantiated during node\n      // creation\n      while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n        // only support MapReduce currently\n        String user \u003d job.getUser();\n        String jobQueue \u003d job.getQueueName();\n        String oldJobId \u003d job.getJobID().toString();\n        long jobStartTimeMS \u003d job.getSubmissionTime();\n\n        // CARLO: Finish time is only used for logging, omit for now\n        long jobFinishTimeMS \u003d -1L;\n\n        if (baselineTimeMS \u003d\u003d 0) {\n          baselineTimeMS \u003d jobStartTimeMS;\n        }\n        jobStartTimeMS -\u003d baselineTimeMS;\n        jobFinishTimeMS -\u003d baselineTimeMS;\n        if (jobStartTimeMS \u003c 0) {\n          LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n          jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n          jobStartTimeMS \u003d 0;\n        }\n\n        increaseQueueAppNum(jobQueue);\n\n        List\u003cContainerSimulator\u003e containerList \u003d\n            new ArrayList\u003cContainerSimulator\u003e();\n        ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n        Random rand \u003d new Random(stjp.getSeed());\n\n        Resource maxMapRes \u003d Resource.newInstance(0, 0);\n        long maxMapDur \u003d 0;\n        // map tasks\n        for (int i \u003d 0; i \u003c job.getNumberMaps(); i++) {\n          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.MAP, i, 0);\n          RMNode node \u003d nmMap\n              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n          long containerLifeTime \u003d tai.getRuntime();\n          Resource containerResource \u003d\n              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                  (int) tai.getTaskInfo().getTaskVCores());\n          containerList.add(new ContainerSimulator(containerResource,\n              containerLifeTime, hostname, DEFAULT_MAPPER_PRIORITY, \"map\"));\n          maxMapRes \u003d Resources.componentwiseMax(maxMapRes, containerResource);\n          maxMapDur \u003d\n              containerLifeTime \u003e maxMapDur ? containerLifeTime : maxMapDur;\n\n        }\n\n        Resource maxRedRes \u003d Resource.newInstance(0, 0);\n        long maxRedDur \u003d 0;\n        // reduce tasks\n        for (int i \u003d 0; i \u003c job.getNumberReduces(); i++) {\n          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.REDUCE, i, 0);\n          RMNode node \u003d nmMap\n              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n          long containerLifeTime \u003d tai.getRuntime();\n          Resource containerResource \u003d\n              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                  (int) tai.getTaskInfo().getTaskVCores());\n          containerList.add(new ContainerSimulator(containerResource,\n              containerLifeTime, hostname, DEFAULT_REDUCER_PRIORITY, \"reduce\"));\n          maxRedRes \u003d Resources.componentwiseMax(maxRedRes, containerResource);\n          maxRedDur \u003d\n              containerLifeTime \u003e maxRedDur ? containerLifeTime : maxRedDur;\n\n        }\n\n        // generating reservations for the jobs that require them\n\n        ReservationSubmissionRequest rr \u003d null;\n        if (job.hasDeadline()) {\n          ReservationId reservationId \u003d\n              ReservationId.newInstance(this.rm.getStartTime(), AM_ID);\n\n          rr \u003d ReservationClientUtil.createMRReservation(reservationId,\n              \"reservation_\" + AM_ID, maxMapRes, job.getNumberMaps(), maxMapDur,\n              maxRedRes, job.getNumberReduces(), maxRedDur,\n              now + jobStartTimeMS, now + job.getDeadline(),\n              job.getQueueName());\n\n        }\n\n        runNewAM(SLSUtils.DEFAULT_JOB_TYPE, user, jobQueue, oldJobId,\n            jobStartTimeMS, jobFinishTimeMS, containerList, rr);\n      }\n    } finally {\n      stjp.close();\n    }\n\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "475f933b41276b1bdeeec09e30369120f7eccdb8": {
      "type": "Ymultichange(Yparameterchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "YARN-6423. Queue metrics doesn\u0027t work for Fair Scheduler in SLS (yufeigu via rkanter)\n",
      "commitDate": "25/04/17 4:26 PM",
      "commitName": "475f933b41276b1bdeeec09e30369120f7eccdb8",
      "commitAuthor": "Robert Kanter",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-6423. Queue metrics doesn\u0027t work for Fair Scheduler in SLS (yufeigu via rkanter)\n",
          "commitDate": "25/04/17 4:26 PM",
          "commitName": "475f933b41276b1bdeeec09e30369120f7eccdb8",
          "commitAuthor": "Robert Kanter",
          "commitDateOld": "20/04/17 9:54 PM",
          "commitNameOld": "de69d6e81128470dd5d2fd865d4b3a79188f740b",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 4.77,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,125 +1,110 @@\n-  private void startAMFromSynthGenerator(int heartbeatInterval)\n-      throws IOException {\n+  private void startAMFromSynthGenerator() throws YarnException, IOException {\n     Configuration localConf \u003d new Configuration();\n     localConf.set(\"fs.defaultFS\", \"file:///\");\n     long baselineTimeMS \u003d 0;\n \n     // reservations use wall clock time, so need to have a reference for that\n     UTCClock clock \u003d new UTCClock();\n     long now \u003d clock.getTime();\n \n     try {\n \n       // if we use the nodeFile this could have been not initialized yet.\n       if (stjp \u003d\u003d null) {\n         stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n       }\n \n       SynthJob job \u003d null;\n       // we use stjp, a reference to the job producer instantiated during node\n       // creation\n       while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n         // only support MapReduce currently\n-        String jobType \u003d \"mapreduce\";\n         String user \u003d job.getUser();\n         String jobQueue \u003d job.getQueueName();\n         String oldJobId \u003d job.getJobID().toString();\n         long jobStartTimeMS \u003d job.getSubmissionTime();\n \n         // CARLO: Finish time is only used for logging, omit for now\n         long jobFinishTimeMS \u003d -1L;\n \n         if (baselineTimeMS \u003d\u003d 0) {\n           baselineTimeMS \u003d jobStartTimeMS;\n         }\n         jobStartTimeMS -\u003d baselineTimeMS;\n         jobFinishTimeMS -\u003d baselineTimeMS;\n         if (jobStartTimeMS \u003c 0) {\n           LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n           jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n           jobStartTimeMS \u003d 0;\n         }\n \n-        boolean isTracked \u003d trackedApps.contains(oldJobId);\n-        int queueSize \u003d queueAppNumMap.containsKey(jobQueue)\n-            ? queueAppNumMap.get(jobQueue) : 0;\n-        queueSize++;\n-        queueAppNumMap.put(jobQueue, queueSize);\n+        increaseQueueAppNum(jobQueue);\n \n         List\u003cContainerSimulator\u003e containerList \u003d\n             new ArrayList\u003cContainerSimulator\u003e();\n         ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n         Random rand \u003d new Random(stjp.getSeed());\n \n         Resource maxMapRes \u003d Resource.newInstance(0, 0);\n         long maxMapDur \u003d 0;\n         // map tasks\n         for (int i \u003d 0; i \u003c job.getNumberMaps(); i++) {\n           TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.MAP, i, 0);\n           RMNode node \u003d nmMap\n               .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n           String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n           long containerLifeTime \u003d tai.getRuntime();\n           Resource containerResource \u003d\n               Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                   (int) tai.getTaskInfo().getTaskVCores());\n           containerList.add(new ContainerSimulator(containerResource,\n               containerLifeTime, hostname, 10, \"map\"));\n           maxMapRes \u003d Resources.componentwiseMax(maxMapRes, containerResource);\n           maxMapDur \u003d\n               containerLifeTime \u003e maxMapDur ? containerLifeTime : maxMapDur;\n \n         }\n \n         Resource maxRedRes \u003d Resource.newInstance(0, 0);\n         long maxRedDur \u003d 0;\n         // reduce tasks\n         for (int i \u003d 0; i \u003c job.getNumberReduces(); i++) {\n           TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.REDUCE, i, 0);\n           RMNode node \u003d nmMap\n               .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n           String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n           long containerLifeTime \u003d tai.getRuntime();\n           Resource containerResource \u003d\n               Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                   (int) tai.getTaskInfo().getTaskVCores());\n           containerList.add(new ContainerSimulator(containerResource,\n               containerLifeTime, hostname, 20, \"reduce\"));\n           maxRedRes \u003d Resources.componentwiseMax(maxRedRes, containerResource);\n           maxRedDur \u003d\n               containerLifeTime \u003e maxRedDur ? containerLifeTime : maxRedDur;\n \n         }\n \n         // generating reservations for the jobs that require them\n \n         ReservationSubmissionRequest rr \u003d null;\n         if (job.hasDeadline()) {\n           ReservationId reservationId \u003d\n               ReservationId.newInstance(this.rm.getStartTime(), AM_ID);\n \n           rr \u003d ReservationClientUtil.createMRReservation(reservationId,\n               \"reservation_\" + AM_ID, maxMapRes, job.getNumberMaps(), maxMapDur,\n               maxRedRes, job.getNumberReduces(), maxRedDur,\n               now + jobStartTimeMS, now + job.getDeadline(),\n               job.getQueueName());\n \n         }\n-        // create a new AM\n-        AMSimulator amSim \u003d (AMSimulator) ReflectionUtils\n-            .newInstance(amClassMap.get(jobType), localConf);\n-        if (amSim !\u003d null) {\n-          amSim.init(AM_ID++, heartbeatInterval, containerList, rm, this,\n-              jobStartTimeMS, jobFinishTimeMS, user, jobQueue, isTracked,\n-              oldJobId, rr, runner.getStartTimeMS());\n-          runner.schedule(amSim);\n-          maxRuntime \u003d Math.max(maxRuntime, jobFinishTimeMS);\n-          numTasks +\u003d containerList.size();\n-          amMap.put(oldJobId, amSim);\n-        }\n+\n+        runNewAM(SLSUtils.DEFAULT_JOB_TYPE, user, jobQueue, oldJobId,\n+            jobStartTimeMS, jobFinishTimeMS, containerList, rr);\n       }\n     } finally {\n       stjp.close();\n     }\n \n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void startAMFromSynthGenerator() throws YarnException, IOException {\n    Configuration localConf \u003d new Configuration();\n    localConf.set(\"fs.defaultFS\", \"file:///\");\n    long baselineTimeMS \u003d 0;\n\n    // reservations use wall clock time, so need to have a reference for that\n    UTCClock clock \u003d new UTCClock();\n    long now \u003d clock.getTime();\n\n    try {\n\n      // if we use the nodeFile this could have been not initialized yet.\n      if (stjp \u003d\u003d null) {\n        stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n      }\n\n      SynthJob job \u003d null;\n      // we use stjp, a reference to the job producer instantiated during node\n      // creation\n      while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n        // only support MapReduce currently\n        String user \u003d job.getUser();\n        String jobQueue \u003d job.getQueueName();\n        String oldJobId \u003d job.getJobID().toString();\n        long jobStartTimeMS \u003d job.getSubmissionTime();\n\n        // CARLO: Finish time is only used for logging, omit for now\n        long jobFinishTimeMS \u003d -1L;\n\n        if (baselineTimeMS \u003d\u003d 0) {\n          baselineTimeMS \u003d jobStartTimeMS;\n        }\n        jobStartTimeMS -\u003d baselineTimeMS;\n        jobFinishTimeMS -\u003d baselineTimeMS;\n        if (jobStartTimeMS \u003c 0) {\n          LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n          jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n          jobStartTimeMS \u003d 0;\n        }\n\n        increaseQueueAppNum(jobQueue);\n\n        List\u003cContainerSimulator\u003e containerList \u003d\n            new ArrayList\u003cContainerSimulator\u003e();\n        ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n        Random rand \u003d new Random(stjp.getSeed());\n\n        Resource maxMapRes \u003d Resource.newInstance(0, 0);\n        long maxMapDur \u003d 0;\n        // map tasks\n        for (int i \u003d 0; i \u003c job.getNumberMaps(); i++) {\n          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.MAP, i, 0);\n          RMNode node \u003d nmMap\n              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n          long containerLifeTime \u003d tai.getRuntime();\n          Resource containerResource \u003d\n              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                  (int) tai.getTaskInfo().getTaskVCores());\n          containerList.add(new ContainerSimulator(containerResource,\n              containerLifeTime, hostname, 10, \"map\"));\n          maxMapRes \u003d Resources.componentwiseMax(maxMapRes, containerResource);\n          maxMapDur \u003d\n              containerLifeTime \u003e maxMapDur ? containerLifeTime : maxMapDur;\n\n        }\n\n        Resource maxRedRes \u003d Resource.newInstance(0, 0);\n        long maxRedDur \u003d 0;\n        // reduce tasks\n        for (int i \u003d 0; i \u003c job.getNumberReduces(); i++) {\n          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.REDUCE, i, 0);\n          RMNode node \u003d nmMap\n              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n          long containerLifeTime \u003d tai.getRuntime();\n          Resource containerResource \u003d\n              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                  (int) tai.getTaskInfo().getTaskVCores());\n          containerList.add(new ContainerSimulator(containerResource,\n              containerLifeTime, hostname, 20, \"reduce\"));\n          maxRedRes \u003d Resources.componentwiseMax(maxRedRes, containerResource);\n          maxRedDur \u003d\n              containerLifeTime \u003e maxRedDur ? containerLifeTime : maxRedDur;\n\n        }\n\n        // generating reservations for the jobs that require them\n\n        ReservationSubmissionRequest rr \u003d null;\n        if (job.hasDeadline()) {\n          ReservationId reservationId \u003d\n              ReservationId.newInstance(this.rm.getStartTime(), AM_ID);\n\n          rr \u003d ReservationClientUtil.createMRReservation(reservationId,\n              \"reservation_\" + AM_ID, maxMapRes, job.getNumberMaps(), maxMapDur,\n              maxRedRes, job.getNumberReduces(), maxRedDur,\n              now + jobStartTimeMS, now + job.getDeadline(),\n              job.getQueueName());\n\n        }\n\n        runNewAM(SLSUtils.DEFAULT_JOB_TYPE, user, jobQueue, oldJobId,\n            jobStartTimeMS, jobFinishTimeMS, containerList, rr);\n      }\n    } finally {\n      stjp.close();\n    }\n\n  }",
          "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
          "extendedDetails": {
            "oldValue": "[heartbeatInterval-int]",
            "newValue": "[]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "YARN-6423. Queue metrics doesn\u0027t work for Fair Scheduler in SLS (yufeigu via rkanter)\n",
          "commitDate": "25/04/17 4:26 PM",
          "commitName": "475f933b41276b1bdeeec09e30369120f7eccdb8",
          "commitAuthor": "Robert Kanter",
          "commitDateOld": "20/04/17 9:54 PM",
          "commitNameOld": "de69d6e81128470dd5d2fd865d4b3a79188f740b",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 4.77,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,125 +1,110 @@\n-  private void startAMFromSynthGenerator(int heartbeatInterval)\n-      throws IOException {\n+  private void startAMFromSynthGenerator() throws YarnException, IOException {\n     Configuration localConf \u003d new Configuration();\n     localConf.set(\"fs.defaultFS\", \"file:///\");\n     long baselineTimeMS \u003d 0;\n \n     // reservations use wall clock time, so need to have a reference for that\n     UTCClock clock \u003d new UTCClock();\n     long now \u003d clock.getTime();\n \n     try {\n \n       // if we use the nodeFile this could have been not initialized yet.\n       if (stjp \u003d\u003d null) {\n         stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n       }\n \n       SynthJob job \u003d null;\n       // we use stjp, a reference to the job producer instantiated during node\n       // creation\n       while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n         // only support MapReduce currently\n-        String jobType \u003d \"mapreduce\";\n         String user \u003d job.getUser();\n         String jobQueue \u003d job.getQueueName();\n         String oldJobId \u003d job.getJobID().toString();\n         long jobStartTimeMS \u003d job.getSubmissionTime();\n \n         // CARLO: Finish time is only used for logging, omit for now\n         long jobFinishTimeMS \u003d -1L;\n \n         if (baselineTimeMS \u003d\u003d 0) {\n           baselineTimeMS \u003d jobStartTimeMS;\n         }\n         jobStartTimeMS -\u003d baselineTimeMS;\n         jobFinishTimeMS -\u003d baselineTimeMS;\n         if (jobStartTimeMS \u003c 0) {\n           LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n           jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n           jobStartTimeMS \u003d 0;\n         }\n \n-        boolean isTracked \u003d trackedApps.contains(oldJobId);\n-        int queueSize \u003d queueAppNumMap.containsKey(jobQueue)\n-            ? queueAppNumMap.get(jobQueue) : 0;\n-        queueSize++;\n-        queueAppNumMap.put(jobQueue, queueSize);\n+        increaseQueueAppNum(jobQueue);\n \n         List\u003cContainerSimulator\u003e containerList \u003d\n             new ArrayList\u003cContainerSimulator\u003e();\n         ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n         Random rand \u003d new Random(stjp.getSeed());\n \n         Resource maxMapRes \u003d Resource.newInstance(0, 0);\n         long maxMapDur \u003d 0;\n         // map tasks\n         for (int i \u003d 0; i \u003c job.getNumberMaps(); i++) {\n           TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.MAP, i, 0);\n           RMNode node \u003d nmMap\n               .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n           String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n           long containerLifeTime \u003d tai.getRuntime();\n           Resource containerResource \u003d\n               Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                   (int) tai.getTaskInfo().getTaskVCores());\n           containerList.add(new ContainerSimulator(containerResource,\n               containerLifeTime, hostname, 10, \"map\"));\n           maxMapRes \u003d Resources.componentwiseMax(maxMapRes, containerResource);\n           maxMapDur \u003d\n               containerLifeTime \u003e maxMapDur ? containerLifeTime : maxMapDur;\n \n         }\n \n         Resource maxRedRes \u003d Resource.newInstance(0, 0);\n         long maxRedDur \u003d 0;\n         // reduce tasks\n         for (int i \u003d 0; i \u003c job.getNumberReduces(); i++) {\n           TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.REDUCE, i, 0);\n           RMNode node \u003d nmMap\n               .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n           String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n           long containerLifeTime \u003d tai.getRuntime();\n           Resource containerResource \u003d\n               Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                   (int) tai.getTaskInfo().getTaskVCores());\n           containerList.add(new ContainerSimulator(containerResource,\n               containerLifeTime, hostname, 20, \"reduce\"));\n           maxRedRes \u003d Resources.componentwiseMax(maxRedRes, containerResource);\n           maxRedDur \u003d\n               containerLifeTime \u003e maxRedDur ? containerLifeTime : maxRedDur;\n \n         }\n \n         // generating reservations for the jobs that require them\n \n         ReservationSubmissionRequest rr \u003d null;\n         if (job.hasDeadline()) {\n           ReservationId reservationId \u003d\n               ReservationId.newInstance(this.rm.getStartTime(), AM_ID);\n \n           rr \u003d ReservationClientUtil.createMRReservation(reservationId,\n               \"reservation_\" + AM_ID, maxMapRes, job.getNumberMaps(), maxMapDur,\n               maxRedRes, job.getNumberReduces(), maxRedDur,\n               now + jobStartTimeMS, now + job.getDeadline(),\n               job.getQueueName());\n \n         }\n-        // create a new AM\n-        AMSimulator amSim \u003d (AMSimulator) ReflectionUtils\n-            .newInstance(amClassMap.get(jobType), localConf);\n-        if (amSim !\u003d null) {\n-          amSim.init(AM_ID++, heartbeatInterval, containerList, rm, this,\n-              jobStartTimeMS, jobFinishTimeMS, user, jobQueue, isTracked,\n-              oldJobId, rr, runner.getStartTimeMS());\n-          runner.schedule(amSim);\n-          maxRuntime \u003d Math.max(maxRuntime, jobFinishTimeMS);\n-          numTasks +\u003d containerList.size();\n-          amMap.put(oldJobId, amSim);\n-        }\n+\n+        runNewAM(SLSUtils.DEFAULT_JOB_TYPE, user, jobQueue, oldJobId,\n+            jobStartTimeMS, jobFinishTimeMS, containerList, rr);\n       }\n     } finally {\n       stjp.close();\n     }\n \n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void startAMFromSynthGenerator() throws YarnException, IOException {\n    Configuration localConf \u003d new Configuration();\n    localConf.set(\"fs.defaultFS\", \"file:///\");\n    long baselineTimeMS \u003d 0;\n\n    // reservations use wall clock time, so need to have a reference for that\n    UTCClock clock \u003d new UTCClock();\n    long now \u003d clock.getTime();\n\n    try {\n\n      // if we use the nodeFile this could have been not initialized yet.\n      if (stjp \u003d\u003d null) {\n        stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n      }\n\n      SynthJob job \u003d null;\n      // we use stjp, a reference to the job producer instantiated during node\n      // creation\n      while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n        // only support MapReduce currently\n        String user \u003d job.getUser();\n        String jobQueue \u003d job.getQueueName();\n        String oldJobId \u003d job.getJobID().toString();\n        long jobStartTimeMS \u003d job.getSubmissionTime();\n\n        // CARLO: Finish time is only used for logging, omit for now\n        long jobFinishTimeMS \u003d -1L;\n\n        if (baselineTimeMS \u003d\u003d 0) {\n          baselineTimeMS \u003d jobStartTimeMS;\n        }\n        jobStartTimeMS -\u003d baselineTimeMS;\n        jobFinishTimeMS -\u003d baselineTimeMS;\n        if (jobStartTimeMS \u003c 0) {\n          LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n          jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n          jobStartTimeMS \u003d 0;\n        }\n\n        increaseQueueAppNum(jobQueue);\n\n        List\u003cContainerSimulator\u003e containerList \u003d\n            new ArrayList\u003cContainerSimulator\u003e();\n        ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n        Random rand \u003d new Random(stjp.getSeed());\n\n        Resource maxMapRes \u003d Resource.newInstance(0, 0);\n        long maxMapDur \u003d 0;\n        // map tasks\n        for (int i \u003d 0; i \u003c job.getNumberMaps(); i++) {\n          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.MAP, i, 0);\n          RMNode node \u003d nmMap\n              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n          long containerLifeTime \u003d tai.getRuntime();\n          Resource containerResource \u003d\n              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                  (int) tai.getTaskInfo().getTaskVCores());\n          containerList.add(new ContainerSimulator(containerResource,\n              containerLifeTime, hostname, 10, \"map\"));\n          maxMapRes \u003d Resources.componentwiseMax(maxMapRes, containerResource);\n          maxMapDur \u003d\n              containerLifeTime \u003e maxMapDur ? containerLifeTime : maxMapDur;\n\n        }\n\n        Resource maxRedRes \u003d Resource.newInstance(0, 0);\n        long maxRedDur \u003d 0;\n        // reduce tasks\n        for (int i \u003d 0; i \u003c job.getNumberReduces(); i++) {\n          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.REDUCE, i, 0);\n          RMNode node \u003d nmMap\n              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n          long containerLifeTime \u003d tai.getRuntime();\n          Resource containerResource \u003d\n              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                  (int) tai.getTaskInfo().getTaskVCores());\n          containerList.add(new ContainerSimulator(containerResource,\n              containerLifeTime, hostname, 20, \"reduce\"));\n          maxRedRes \u003d Resources.componentwiseMax(maxRedRes, containerResource);\n          maxRedDur \u003d\n              containerLifeTime \u003e maxRedDur ? containerLifeTime : maxRedDur;\n\n        }\n\n        // generating reservations for the jobs that require them\n\n        ReservationSubmissionRequest rr \u003d null;\n        if (job.hasDeadline()) {\n          ReservationId reservationId \u003d\n              ReservationId.newInstance(this.rm.getStartTime(), AM_ID);\n\n          rr \u003d ReservationClientUtil.createMRReservation(reservationId,\n              \"reservation_\" + AM_ID, maxMapRes, job.getNumberMaps(), maxMapDur,\n              maxRedRes, job.getNumberReduces(), maxRedDur,\n              now + jobStartTimeMS, now + job.getDeadline(),\n              job.getQueueName());\n\n        }\n\n        runNewAM(SLSUtils.DEFAULT_JOB_TYPE, user, jobQueue, oldJobId,\n            jobStartTimeMS, jobFinishTimeMS, containerList, rr);\n      }\n    } finally {\n      stjp.close();\n    }\n\n  }",
          "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
          "extendedDetails": {
            "oldValue": "[IOException]",
            "newValue": "[YarnException, IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-6423. Queue metrics doesn\u0027t work for Fair Scheduler in SLS (yufeigu via rkanter)\n",
          "commitDate": "25/04/17 4:26 PM",
          "commitName": "475f933b41276b1bdeeec09e30369120f7eccdb8",
          "commitAuthor": "Robert Kanter",
          "commitDateOld": "20/04/17 9:54 PM",
          "commitNameOld": "de69d6e81128470dd5d2fd865d4b3a79188f740b",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 4.77,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,125 +1,110 @@\n-  private void startAMFromSynthGenerator(int heartbeatInterval)\n-      throws IOException {\n+  private void startAMFromSynthGenerator() throws YarnException, IOException {\n     Configuration localConf \u003d new Configuration();\n     localConf.set(\"fs.defaultFS\", \"file:///\");\n     long baselineTimeMS \u003d 0;\n \n     // reservations use wall clock time, so need to have a reference for that\n     UTCClock clock \u003d new UTCClock();\n     long now \u003d clock.getTime();\n \n     try {\n \n       // if we use the nodeFile this could have been not initialized yet.\n       if (stjp \u003d\u003d null) {\n         stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n       }\n \n       SynthJob job \u003d null;\n       // we use stjp, a reference to the job producer instantiated during node\n       // creation\n       while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n         // only support MapReduce currently\n-        String jobType \u003d \"mapreduce\";\n         String user \u003d job.getUser();\n         String jobQueue \u003d job.getQueueName();\n         String oldJobId \u003d job.getJobID().toString();\n         long jobStartTimeMS \u003d job.getSubmissionTime();\n \n         // CARLO: Finish time is only used for logging, omit for now\n         long jobFinishTimeMS \u003d -1L;\n \n         if (baselineTimeMS \u003d\u003d 0) {\n           baselineTimeMS \u003d jobStartTimeMS;\n         }\n         jobStartTimeMS -\u003d baselineTimeMS;\n         jobFinishTimeMS -\u003d baselineTimeMS;\n         if (jobStartTimeMS \u003c 0) {\n           LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n           jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n           jobStartTimeMS \u003d 0;\n         }\n \n-        boolean isTracked \u003d trackedApps.contains(oldJobId);\n-        int queueSize \u003d queueAppNumMap.containsKey(jobQueue)\n-            ? queueAppNumMap.get(jobQueue) : 0;\n-        queueSize++;\n-        queueAppNumMap.put(jobQueue, queueSize);\n+        increaseQueueAppNum(jobQueue);\n \n         List\u003cContainerSimulator\u003e containerList \u003d\n             new ArrayList\u003cContainerSimulator\u003e();\n         ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n         Random rand \u003d new Random(stjp.getSeed());\n \n         Resource maxMapRes \u003d Resource.newInstance(0, 0);\n         long maxMapDur \u003d 0;\n         // map tasks\n         for (int i \u003d 0; i \u003c job.getNumberMaps(); i++) {\n           TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.MAP, i, 0);\n           RMNode node \u003d nmMap\n               .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n           String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n           long containerLifeTime \u003d tai.getRuntime();\n           Resource containerResource \u003d\n               Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                   (int) tai.getTaskInfo().getTaskVCores());\n           containerList.add(new ContainerSimulator(containerResource,\n               containerLifeTime, hostname, 10, \"map\"));\n           maxMapRes \u003d Resources.componentwiseMax(maxMapRes, containerResource);\n           maxMapDur \u003d\n               containerLifeTime \u003e maxMapDur ? containerLifeTime : maxMapDur;\n \n         }\n \n         Resource maxRedRes \u003d Resource.newInstance(0, 0);\n         long maxRedDur \u003d 0;\n         // reduce tasks\n         for (int i \u003d 0; i \u003c job.getNumberReduces(); i++) {\n           TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.REDUCE, i, 0);\n           RMNode node \u003d nmMap\n               .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n           String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n           long containerLifeTime \u003d tai.getRuntime();\n           Resource containerResource \u003d\n               Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                   (int) tai.getTaskInfo().getTaskVCores());\n           containerList.add(new ContainerSimulator(containerResource,\n               containerLifeTime, hostname, 20, \"reduce\"));\n           maxRedRes \u003d Resources.componentwiseMax(maxRedRes, containerResource);\n           maxRedDur \u003d\n               containerLifeTime \u003e maxRedDur ? containerLifeTime : maxRedDur;\n \n         }\n \n         // generating reservations for the jobs that require them\n \n         ReservationSubmissionRequest rr \u003d null;\n         if (job.hasDeadline()) {\n           ReservationId reservationId \u003d\n               ReservationId.newInstance(this.rm.getStartTime(), AM_ID);\n \n           rr \u003d ReservationClientUtil.createMRReservation(reservationId,\n               \"reservation_\" + AM_ID, maxMapRes, job.getNumberMaps(), maxMapDur,\n               maxRedRes, job.getNumberReduces(), maxRedDur,\n               now + jobStartTimeMS, now + job.getDeadline(),\n               job.getQueueName());\n \n         }\n-        // create a new AM\n-        AMSimulator amSim \u003d (AMSimulator) ReflectionUtils\n-            .newInstance(amClassMap.get(jobType), localConf);\n-        if (amSim !\u003d null) {\n-          amSim.init(AM_ID++, heartbeatInterval, containerList, rm, this,\n-              jobStartTimeMS, jobFinishTimeMS, user, jobQueue, isTracked,\n-              oldJobId, rr, runner.getStartTimeMS());\n-          runner.schedule(amSim);\n-          maxRuntime \u003d Math.max(maxRuntime, jobFinishTimeMS);\n-          numTasks +\u003d containerList.size();\n-          amMap.put(oldJobId, amSim);\n-        }\n+\n+        runNewAM(SLSUtils.DEFAULT_JOB_TYPE, user, jobQueue, oldJobId,\n+            jobStartTimeMS, jobFinishTimeMS, containerList, rr);\n       }\n     } finally {\n       stjp.close();\n     }\n \n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void startAMFromSynthGenerator() throws YarnException, IOException {\n    Configuration localConf \u003d new Configuration();\n    localConf.set(\"fs.defaultFS\", \"file:///\");\n    long baselineTimeMS \u003d 0;\n\n    // reservations use wall clock time, so need to have a reference for that\n    UTCClock clock \u003d new UTCClock();\n    long now \u003d clock.getTime();\n\n    try {\n\n      // if we use the nodeFile this could have been not initialized yet.\n      if (stjp \u003d\u003d null) {\n        stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n      }\n\n      SynthJob job \u003d null;\n      // we use stjp, a reference to the job producer instantiated during node\n      // creation\n      while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n        // only support MapReduce currently\n        String user \u003d job.getUser();\n        String jobQueue \u003d job.getQueueName();\n        String oldJobId \u003d job.getJobID().toString();\n        long jobStartTimeMS \u003d job.getSubmissionTime();\n\n        // CARLO: Finish time is only used for logging, omit for now\n        long jobFinishTimeMS \u003d -1L;\n\n        if (baselineTimeMS \u003d\u003d 0) {\n          baselineTimeMS \u003d jobStartTimeMS;\n        }\n        jobStartTimeMS -\u003d baselineTimeMS;\n        jobFinishTimeMS -\u003d baselineTimeMS;\n        if (jobStartTimeMS \u003c 0) {\n          LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n          jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n          jobStartTimeMS \u003d 0;\n        }\n\n        increaseQueueAppNum(jobQueue);\n\n        List\u003cContainerSimulator\u003e containerList \u003d\n            new ArrayList\u003cContainerSimulator\u003e();\n        ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n        Random rand \u003d new Random(stjp.getSeed());\n\n        Resource maxMapRes \u003d Resource.newInstance(0, 0);\n        long maxMapDur \u003d 0;\n        // map tasks\n        for (int i \u003d 0; i \u003c job.getNumberMaps(); i++) {\n          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.MAP, i, 0);\n          RMNode node \u003d nmMap\n              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n          long containerLifeTime \u003d tai.getRuntime();\n          Resource containerResource \u003d\n              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                  (int) tai.getTaskInfo().getTaskVCores());\n          containerList.add(new ContainerSimulator(containerResource,\n              containerLifeTime, hostname, 10, \"map\"));\n          maxMapRes \u003d Resources.componentwiseMax(maxMapRes, containerResource);\n          maxMapDur \u003d\n              containerLifeTime \u003e maxMapDur ? containerLifeTime : maxMapDur;\n\n        }\n\n        Resource maxRedRes \u003d Resource.newInstance(0, 0);\n        long maxRedDur \u003d 0;\n        // reduce tasks\n        for (int i \u003d 0; i \u003c job.getNumberReduces(); i++) {\n          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.REDUCE, i, 0);\n          RMNode node \u003d nmMap\n              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n          long containerLifeTime \u003d tai.getRuntime();\n          Resource containerResource \u003d\n              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                  (int) tai.getTaskInfo().getTaskVCores());\n          containerList.add(new ContainerSimulator(containerResource,\n              containerLifeTime, hostname, 20, \"reduce\"));\n          maxRedRes \u003d Resources.componentwiseMax(maxRedRes, containerResource);\n          maxRedDur \u003d\n              containerLifeTime \u003e maxRedDur ? containerLifeTime : maxRedDur;\n\n        }\n\n        // generating reservations for the jobs that require them\n\n        ReservationSubmissionRequest rr \u003d null;\n        if (job.hasDeadline()) {\n          ReservationId reservationId \u003d\n              ReservationId.newInstance(this.rm.getStartTime(), AM_ID);\n\n          rr \u003d ReservationClientUtil.createMRReservation(reservationId,\n              \"reservation_\" + AM_ID, maxMapRes, job.getNumberMaps(), maxMapDur,\n              maxRedRes, job.getNumberReduces(), maxRedDur,\n              now + jobStartTimeMS, now + job.getDeadline(),\n              job.getQueueName());\n\n        }\n\n        runNewAM(SLSUtils.DEFAULT_JOB_TYPE, user, jobQueue, oldJobId,\n            jobStartTimeMS, jobFinishTimeMS, containerList, rr);\n      }\n    } finally {\n      stjp.close();\n    }\n\n  }",
          "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
          "extendedDetails": {}
        }
      ]
    },
    "de69d6e81128470dd5d2fd865d4b3a79188f740b": {
      "type": "Yintroduced",
      "commitMessage": "YARN-6363. Extending SLS: Synthetic Load Generator. (Carlo Curino via wangda)\n",
      "commitDate": "20/04/17 9:54 PM",
      "commitName": "de69d6e81128470dd5d2fd865d4b3a79188f740b",
      "commitAuthor": "Wangda Tan",
      "diff": "@@ -0,0 +1,125 @@\n+  private void startAMFromSynthGenerator(int heartbeatInterval)\n+      throws IOException {\n+    Configuration localConf \u003d new Configuration();\n+    localConf.set(\"fs.defaultFS\", \"file:///\");\n+    long baselineTimeMS \u003d 0;\n+\n+    // reservations use wall clock time, so need to have a reference for that\n+    UTCClock clock \u003d new UTCClock();\n+    long now \u003d clock.getTime();\n+\n+    try {\n+\n+      // if we use the nodeFile this could have been not initialized yet.\n+      if (stjp \u003d\u003d null) {\n+        stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n+      }\n+\n+      SynthJob job \u003d null;\n+      // we use stjp, a reference to the job producer instantiated during node\n+      // creation\n+      while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n+        // only support MapReduce currently\n+        String jobType \u003d \"mapreduce\";\n+        String user \u003d job.getUser();\n+        String jobQueue \u003d job.getQueueName();\n+        String oldJobId \u003d job.getJobID().toString();\n+        long jobStartTimeMS \u003d job.getSubmissionTime();\n+\n+        // CARLO: Finish time is only used for logging, omit for now\n+        long jobFinishTimeMS \u003d -1L;\n+\n+        if (baselineTimeMS \u003d\u003d 0) {\n+          baselineTimeMS \u003d jobStartTimeMS;\n+        }\n+        jobStartTimeMS -\u003d baselineTimeMS;\n+        jobFinishTimeMS -\u003d baselineTimeMS;\n+        if (jobStartTimeMS \u003c 0) {\n+          LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n+          jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n+          jobStartTimeMS \u003d 0;\n+        }\n+\n+        boolean isTracked \u003d trackedApps.contains(oldJobId);\n+        int queueSize \u003d queueAppNumMap.containsKey(jobQueue)\n+            ? queueAppNumMap.get(jobQueue) : 0;\n+        queueSize++;\n+        queueAppNumMap.put(jobQueue, queueSize);\n+\n+        List\u003cContainerSimulator\u003e containerList \u003d\n+            new ArrayList\u003cContainerSimulator\u003e();\n+        ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n+        Random rand \u003d new Random(stjp.getSeed());\n+\n+        Resource maxMapRes \u003d Resource.newInstance(0, 0);\n+        long maxMapDur \u003d 0;\n+        // map tasks\n+        for (int i \u003d 0; i \u003c job.getNumberMaps(); i++) {\n+          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.MAP, i, 0);\n+          RMNode node \u003d nmMap\n+              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n+          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n+          long containerLifeTime \u003d tai.getRuntime();\n+          Resource containerResource \u003d\n+              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n+                  (int) tai.getTaskInfo().getTaskVCores());\n+          containerList.add(new ContainerSimulator(containerResource,\n+              containerLifeTime, hostname, 10, \"map\"));\n+          maxMapRes \u003d Resources.componentwiseMax(maxMapRes, containerResource);\n+          maxMapDur \u003d\n+              containerLifeTime \u003e maxMapDur ? containerLifeTime : maxMapDur;\n+\n+        }\n+\n+        Resource maxRedRes \u003d Resource.newInstance(0, 0);\n+        long maxRedDur \u003d 0;\n+        // reduce tasks\n+        for (int i \u003d 0; i \u003c job.getNumberReduces(); i++) {\n+          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.REDUCE, i, 0);\n+          RMNode node \u003d nmMap\n+              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n+          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n+          long containerLifeTime \u003d tai.getRuntime();\n+          Resource containerResource \u003d\n+              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n+                  (int) tai.getTaskInfo().getTaskVCores());\n+          containerList.add(new ContainerSimulator(containerResource,\n+              containerLifeTime, hostname, 20, \"reduce\"));\n+          maxRedRes \u003d Resources.componentwiseMax(maxRedRes, containerResource);\n+          maxRedDur \u003d\n+              containerLifeTime \u003e maxRedDur ? containerLifeTime : maxRedDur;\n+\n+        }\n+\n+        // generating reservations for the jobs that require them\n+\n+        ReservationSubmissionRequest rr \u003d null;\n+        if (job.hasDeadline()) {\n+          ReservationId reservationId \u003d\n+              ReservationId.newInstance(this.rm.getStartTime(), AM_ID);\n+\n+          rr \u003d ReservationClientUtil.createMRReservation(reservationId,\n+              \"reservation_\" + AM_ID, maxMapRes, job.getNumberMaps(), maxMapDur,\n+              maxRedRes, job.getNumberReduces(), maxRedDur,\n+              now + jobStartTimeMS, now + job.getDeadline(),\n+              job.getQueueName());\n+\n+        }\n+        // create a new AM\n+        AMSimulator amSim \u003d (AMSimulator) ReflectionUtils\n+            .newInstance(amClassMap.get(jobType), localConf);\n+        if (amSim !\u003d null) {\n+          amSim.init(AM_ID++, heartbeatInterval, containerList, rm, this,\n+              jobStartTimeMS, jobFinishTimeMS, user, jobQueue, isTracked,\n+              oldJobId, rr, runner.getStartTimeMS());\n+          runner.schedule(amSim);\n+          maxRuntime \u003d Math.max(maxRuntime, jobFinishTimeMS);\n+          numTasks +\u003d containerList.size();\n+          amMap.put(oldJobId, amSim);\n+        }\n+      }\n+    } finally {\n+      stjp.close();\n+    }\n+\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void startAMFromSynthGenerator(int heartbeatInterval)\n      throws IOException {\n    Configuration localConf \u003d new Configuration();\n    localConf.set(\"fs.defaultFS\", \"file:///\");\n    long baselineTimeMS \u003d 0;\n\n    // reservations use wall clock time, so need to have a reference for that\n    UTCClock clock \u003d new UTCClock();\n    long now \u003d clock.getTime();\n\n    try {\n\n      // if we use the nodeFile this could have been not initialized yet.\n      if (stjp \u003d\u003d null) {\n        stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n      }\n\n      SynthJob job \u003d null;\n      // we use stjp, a reference to the job producer instantiated during node\n      // creation\n      while ((job \u003d (SynthJob) stjp.getNextJob()) !\u003d null) {\n        // only support MapReduce currently\n        String jobType \u003d \"mapreduce\";\n        String user \u003d job.getUser();\n        String jobQueue \u003d job.getQueueName();\n        String oldJobId \u003d job.getJobID().toString();\n        long jobStartTimeMS \u003d job.getSubmissionTime();\n\n        // CARLO: Finish time is only used for logging, omit for now\n        long jobFinishTimeMS \u003d -1L;\n\n        if (baselineTimeMS \u003d\u003d 0) {\n          baselineTimeMS \u003d jobStartTimeMS;\n        }\n        jobStartTimeMS -\u003d baselineTimeMS;\n        jobFinishTimeMS -\u003d baselineTimeMS;\n        if (jobStartTimeMS \u003c 0) {\n          LOG.warn(\"Warning: reset job \" + oldJobId + \" start time to 0.\");\n          jobFinishTimeMS \u003d jobFinishTimeMS - jobStartTimeMS;\n          jobStartTimeMS \u003d 0;\n        }\n\n        boolean isTracked \u003d trackedApps.contains(oldJobId);\n        int queueSize \u003d queueAppNumMap.containsKey(jobQueue)\n            ? queueAppNumMap.get(jobQueue) : 0;\n        queueSize++;\n        queueAppNumMap.put(jobQueue, queueSize);\n\n        List\u003cContainerSimulator\u003e containerList \u003d\n            new ArrayList\u003cContainerSimulator\u003e();\n        ArrayList\u003cNodeId\u003e keyAsArray \u003d new ArrayList\u003cNodeId\u003e(nmMap.keySet());\n        Random rand \u003d new Random(stjp.getSeed());\n\n        Resource maxMapRes \u003d Resource.newInstance(0, 0);\n        long maxMapDur \u003d 0;\n        // map tasks\n        for (int i \u003d 0; i \u003c job.getNumberMaps(); i++) {\n          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.MAP, i, 0);\n          RMNode node \u003d nmMap\n              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n          long containerLifeTime \u003d tai.getRuntime();\n          Resource containerResource \u003d\n              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                  (int) tai.getTaskInfo().getTaskVCores());\n          containerList.add(new ContainerSimulator(containerResource,\n              containerLifeTime, hostname, 10, \"map\"));\n          maxMapRes \u003d Resources.componentwiseMax(maxMapRes, containerResource);\n          maxMapDur \u003d\n              containerLifeTime \u003e maxMapDur ? containerLifeTime : maxMapDur;\n\n        }\n\n        Resource maxRedRes \u003d Resource.newInstance(0, 0);\n        long maxRedDur \u003d 0;\n        // reduce tasks\n        for (int i \u003d 0; i \u003c job.getNumberReduces(); i++) {\n          TaskAttemptInfo tai \u003d job.getTaskAttemptInfo(TaskType.REDUCE, i, 0);\n          RMNode node \u003d nmMap\n              .get(keyAsArray.get(rand.nextInt(keyAsArray.size()))).getNode();\n          String hostname \u003d \"/\" + node.getRackName() + \"/\" + node.getHostName();\n          long containerLifeTime \u003d tai.getRuntime();\n          Resource containerResource \u003d\n              Resource.newInstance((int) tai.getTaskInfo().getTaskMemory(),\n                  (int) tai.getTaskInfo().getTaskVCores());\n          containerList.add(new ContainerSimulator(containerResource,\n              containerLifeTime, hostname, 20, \"reduce\"));\n          maxRedRes \u003d Resources.componentwiseMax(maxRedRes, containerResource);\n          maxRedDur \u003d\n              containerLifeTime \u003e maxRedDur ? containerLifeTime : maxRedDur;\n\n        }\n\n        // generating reservations for the jobs that require them\n\n        ReservationSubmissionRequest rr \u003d null;\n        if (job.hasDeadline()) {\n          ReservationId reservationId \u003d\n              ReservationId.newInstance(this.rm.getStartTime(), AM_ID);\n\n          rr \u003d ReservationClientUtil.createMRReservation(reservationId,\n              \"reservation_\" + AM_ID, maxMapRes, job.getNumberMaps(), maxMapDur,\n              maxRedRes, job.getNumberReduces(), maxRedDur,\n              now + jobStartTimeMS, now + job.getDeadline(),\n              job.getQueueName());\n\n        }\n        // create a new AM\n        AMSimulator amSim \u003d (AMSimulator) ReflectionUtils\n            .newInstance(amClassMap.get(jobType), localConf);\n        if (amSim !\u003d null) {\n          amSim.init(AM_ID++, heartbeatInterval, containerList, rm, this,\n              jobStartTimeMS, jobFinishTimeMS, user, jobQueue, isTracked,\n              oldJobId, rr, runner.getStartTimeMS());\n          runner.schedule(amSim);\n          maxRuntime \u003d Math.max(maxRuntime, jobFinishTimeMS);\n          numTasks +\u003d containerList.size();\n          amMap.put(oldJobId, amSim);\n        }\n      }\n    } finally {\n      stjp.close();\n    }\n\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java"
    }
  }
}