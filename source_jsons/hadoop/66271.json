{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RumenToSLSConverter.java",
  "functionName": "createSLSJob",
  "functionId": "createSLSJob___rumenJob-Map",
  "sourceFilePath": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/RumenToSLSConverter.java",
  "functionStartLine": 162,
  "functionEndLine": 198,
  "numCommitsSeen": 6,
  "timeTaken": 470,
  "changeHistory": [
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b"
  ],
  "changeHistoryShort": {
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b": "Yintroduced"
  },
  "changeHistoryDetails": {
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b": {
      "type": "Yintroduced",
      "commitMessage": "YARN-1021. Yarn Scheduler Load Simulator. (ywskycn via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1527059 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/09/13 1:23 PM",
      "commitName": "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b",
      "commitAuthor": "Alejandro Abdelnur",
      "diff": "@@ -0,0 +1,37 @@\n+  private static Map createSLSJob(Map rumenJob) {\n+    Map json \u003d new LinkedHashMap();\n+    long jobStart \u003d (Long) rumenJob.get(\"submitTime\");\n+    long jobFinish \u003d (Long) rumenJob.get(\"finishTime\");\n+    String jobId \u003d rumenJob.get(\"jobID\").toString();\n+    String queue \u003d rumenJob.get(\"queue\").toString();\n+    String user \u003d rumenJob.get(\"user\").toString();\n+    if (baseline \u003d\u003d 0) {\n+      baseline \u003d jobStart;\n+    }\n+    jobStart -\u003d baseline;\n+    jobFinish -\u003d baseline;\n+    long offset \u003d 0;\n+    if (jobStart \u003c 0) {\n+      System.out.println(\"Warning: reset job \" + jobId + \" start time to 0.\");\n+      offset \u003d -jobStart;\n+      jobFinish \u003d jobFinish - jobStart;\n+      jobStart \u003d 0;\n+    }\n+\n+    json.put(\"am.type\", \"mapreduce\");\n+    json.put(\"job.start.ms\", jobStart);\n+    json.put(\"job.end.ms\", jobFinish);\n+    json.put(\"job.queue.name\", queue);\n+    json.put(\"job.id\", jobId);\n+    json.put(\"job.user\", user);\n+\n+    List maps \u003d createSLSTasks(\"map\",\n+            (List) rumenJob.get(\"mapTasks\"), offset);\n+    List reduces \u003d createSLSTasks(\"reduce\",\n+            (List) rumenJob.get(\"reduceTasks\"), offset);\n+    List tasks \u003d new ArrayList();\n+    tasks.addAll(maps);\n+    tasks.addAll(reduces);\n+    json.put(\"job.tasks\", tasks);\n+    return json;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static Map createSLSJob(Map rumenJob) {\n    Map json \u003d new LinkedHashMap();\n    long jobStart \u003d (Long) rumenJob.get(\"submitTime\");\n    long jobFinish \u003d (Long) rumenJob.get(\"finishTime\");\n    String jobId \u003d rumenJob.get(\"jobID\").toString();\n    String queue \u003d rumenJob.get(\"queue\").toString();\n    String user \u003d rumenJob.get(\"user\").toString();\n    if (baseline \u003d\u003d 0) {\n      baseline \u003d jobStart;\n    }\n    jobStart -\u003d baseline;\n    jobFinish -\u003d baseline;\n    long offset \u003d 0;\n    if (jobStart \u003c 0) {\n      System.out.println(\"Warning: reset job \" + jobId + \" start time to 0.\");\n      offset \u003d -jobStart;\n      jobFinish \u003d jobFinish - jobStart;\n      jobStart \u003d 0;\n    }\n\n    json.put(\"am.type\", \"mapreduce\");\n    json.put(\"job.start.ms\", jobStart);\n    json.put(\"job.end.ms\", jobFinish);\n    json.put(\"job.queue.name\", queue);\n    json.put(\"job.id\", jobId);\n    json.put(\"job.user\", user);\n\n    List maps \u003d createSLSTasks(\"map\",\n            (List) rumenJob.get(\"mapTasks\"), offset);\n    List reduces \u003d createSLSTasks(\"reduce\",\n            (List) rumenJob.get(\"reduceTasks\"), offset);\n    List tasks \u003d new ArrayList();\n    tasks.addAll(maps);\n    tasks.addAll(reduces);\n    json.put(\"job.tasks\", tasks);\n    return json;\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/RumenToSLSConverter.java"
    }
  }
}