{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImageSerialization.java",
  "functionName": "readINodeUnderConstruction",
  "functionId": "readINodeUnderConstruction___in-DataInput__fsNamesys-FSNamesystem__imgVersion-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
  "functionStartLine": 120,
  "functionEndLine": 164,
  "numCommitsSeen": 62,
  "timeTaken": 5736,
  "changeHistory": [
    "164cbe643988f878f0f4100a4de51783e5b6738e",
    "e535e0f05b5fbd087c93238deb888cc985254b4c",
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
    "4fdd9abd7e43a0fb7b569982954a8f9660b9268b",
    "49d5cff49011cc0878665204e22b5c832bc914ce",
    "c17439c2ddd921b63b1635e6f1cba634b8da8557",
    "cdc13efb1af54d931585d25c5ba696a012412828",
    "4928f5473394981829e5ffd4b16ea0801baf5c45",
    "c9103e9cacc67a614940e32fa87c5dbc3daa60de",
    "f6e1160ef1e946a5f6c9503b06832e6b84c36edb",
    "d0d75a833907f6cf723a42a007ca04e0004a8e52",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
    "185e0c7b4c056b88f606362c71e4a22aae7076e0",
    "e79c98c11fa8b4ddd8c63b613698d2d508135e83",
    "042b33f20b01aadb5cd03da731ae7a3d94026aac",
    "1e89eba47d0f291b33fc26f9406231fc70b63a87",
    "00067895a01c66d53715b50bbcb3605efd6425f2",
    "ce68f410b05a58ad05965f32ad7f5b246b363a75"
  ],
  "changeHistoryShort": {
    "164cbe643988f878f0f4100a4de51783e5b6738e": "Ybodychange",
    "e535e0f05b5fbd087c93238deb888cc985254b4c": "Ybodychange",
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835": "Ybodychange",
    "4fdd9abd7e43a0fb7b569982954a8f9660b9268b": "Ybodychange",
    "49d5cff49011cc0878665204e22b5c832bc914ce": "Ybodychange",
    "c17439c2ddd921b63b1635e6f1cba634b8da8557": "Ybodychange",
    "cdc13efb1af54d931585d25c5ba696a012412828": "Ybodychange",
    "4928f5473394981829e5ffd4b16ea0801baf5c45": "Ybodychange",
    "c9103e9cacc67a614940e32fa87c5dbc3daa60de": "Ybodychange",
    "f6e1160ef1e946a5f6c9503b06832e6b84c36edb": "Ybodychange",
    "d0d75a833907f6cf723a42a007ca04e0004a8e52": "Ybodychange",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": "Ybodychange",
    "185e0c7b4c056b88f606362c71e4a22aae7076e0": "Ybodychange",
    "e79c98c11fa8b4ddd8c63b613698d2d508135e83": "Ybodychange",
    "042b33f20b01aadb5cd03da731ae7a3d94026aac": "Ybodychange",
    "1e89eba47d0f291b33fc26f9406231fc70b63a87": "Ybodychange",
    "00067895a01c66d53715b50bbcb3605efd6425f2": "Ybodychange",
    "ce68f410b05a58ad05965f32ad7f5b246b363a75": "Ymultichange(Yreturntypechange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "164cbe643988f878f0f4100a4de51783e5b6738e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8909. Erasure coding: update BlockInfoContiguousUC and BlockInfoStripedUC to use BlockUnderConstructionFeature. Contributed by Jing Zhao.\n",
      "commitDate": "27/08/15 1:02 AM",
      "commitName": "164cbe643988f878f0f4100a4de51783e5b6738e",
      "commitAuthor": "Walter Su",
      "commitDateOld": "24/08/15 12:59 PM",
      "commitNameOld": "6b6a63bbbda920315d3d24b61ed3344a78a981b6",
      "commitAuthorOld": "",
      "daysBetweenCommits": 2.5,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,45 @@\n   static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d NameNodeLayoutVersion.supports(\n         LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n         : fsNamesys.dir.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n \n     int numBlocks \u003d in.readInt();\n \n     final BlockInfoContiguous[] blocksContiguous \u003d\n         new BlockInfoContiguous[numBlocks];\n     Block blk \u003d new Block();\n     int i \u003d 0;\n     for (; i \u003c numBlocks - 1; i++) {\n       blk.readFields(in);\n       blocksContiguous[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n     }\n     // last block is UNDER_CONSTRUCTION\n     if(numBlocks \u003e 0) {\n       blk.readFields(in);\n-      blocksContiguous[i] \u003d new BlockInfoContiguousUnderConstruction(\n-          blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n+      blocksContiguous[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n+      blocksContiguous[i].convertToBlockUnderConstruction(\n+          BlockUCState.UNDER_CONSTRUCTION, null);\n     }\n \n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n     // Images in the pre-protobuf format will not have the lazyPersist flag,\n     // so it is safe to pass false always.\n     INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n         modificationTime, blocksContiguous, blockReplication, preferredBlockSize);\n     file.toUnderConstruction(clientName, clientMachine);\n     return file;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n        : fsNamesys.dir.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n\n    int numBlocks \u003d in.readInt();\n\n    final BlockInfoContiguous[] blocksContiguous \u003d\n        new BlockInfoContiguous[numBlocks];\n    Block blk \u003d new Block();\n    int i \u003d 0;\n    for (; i \u003c numBlocks - 1; i++) {\n      blk.readFields(in);\n      blocksContiguous[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n    }\n    // last block is UNDER_CONSTRUCTION\n    if(numBlocks \u003e 0) {\n      blk.readFields(in);\n      blocksContiguous[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n      blocksContiguous[i].convertToBlockUnderConstruction(\n          BlockUCState.UNDER_CONSTRUCTION, null);\n    }\n\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    // Images in the pre-protobuf format will not have the lazyPersist flag,\n    // so it is safe to pass false always.\n    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n        modificationTime, blocksContiguous, blockReplication, preferredBlockSize);\n    file.toUnderConstruction(clientName, clientMachine);\n    return file;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
      "extendedDetails": {}
    },
    "e535e0f05b5fbd087c93238deb888cc985254b4c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8801. Convert BlockInfoUnderConstruction as a feature. Contributed by Jing Zhao.\n",
      "commitDate": "17/08/15 11:28 AM",
      "commitName": "e535e0f05b5fbd087c93238deb888cc985254b4c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "06/08/15 10:21 AM",
      "commitNameOld": "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 11.05,
      "commitsBetweenForRepo": 46,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,42 @@\n   static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d NameNodeLayoutVersion.supports(\n         LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n         : fsNamesys.dir.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n   \n     int numBlocks \u003d in.readInt();\n     BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n     Block blk \u003d new Block();\n     int i \u003d 0;\n     for (; i \u003c numBlocks-1; i++) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n     }\n     // last block is UNDER_CONSTRUCTION\n     if(numBlocks \u003e 0) {\n       blk.readFields(in);\n-      blocks[i] \u003d new BlockInfoContiguousUnderConstruction(\n-        blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n+      blocks[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n+      blocks[i].convertToBlockUnderConstruction(BlockUCState.UNDER_CONSTRUCTION,\n+          null);\n     }\n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n     // Images in the pre-protobuf format will not have the lazyPersist flag,\n     // so it is safe to pass false always.\n     INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n         modificationTime, blocks, blockReplication, preferredBlockSize);\n     file.toUnderConstruction(clientName, clientMachine);\n     return file;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n        : fsNamesys.dir.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n  \n    int numBlocks \u003d in.readInt();\n    BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n    Block blk \u003d new Block();\n    int i \u003d 0;\n    for (; i \u003c numBlocks-1; i++) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n    }\n    // last block is UNDER_CONSTRUCTION\n    if(numBlocks \u003e 0) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n      blocks[i].convertToBlockUnderConstruction(BlockUCState.UNDER_CONSTRUCTION,\n          null);\n    }\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    // Images in the pre-protobuf format will not have the lazyPersist flag,\n    // so it is safe to pass false always.\n    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n        modificationTime, blocks, blockReplication, preferredBlockSize);\n    file.toUnderConstruction(clientName, clientMachine);\n    return file;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
      "extendedDetails": {}
    },
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang.\"\n\nThis reverts commit c17439c2ddd921b63b1635e6f1cba634b8da8557.\n",
      "commitDate": "06/08/15 10:21 AM",
      "commitName": "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "12/06/15 11:38 AM",
      "commitNameOld": "c17439c2ddd921b63b1635e6f1cba634b8da8557",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 54.95,
      "commitsBetweenForRepo": 341,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,41 @@\n   static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d NameNodeLayoutVersion.supports(\n         LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n         : fsNamesys.dir.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n   \n     int numBlocks \u003d in.readInt();\n     BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n     Block blk \u003d new Block();\n     int i \u003d 0;\n     for (; i \u003c numBlocks-1; i++) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n     }\n     // last block is UNDER_CONSTRUCTION\n     if(numBlocks \u003e 0) {\n       blk.readFields(in);\n-      blocks[i] \u003d new BlockInfoUnderConstructionContiguous(\n+      blocks[i] \u003d new BlockInfoContiguousUnderConstruction(\n         blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n     }\n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n     // Images in the pre-protobuf format will not have the lazyPersist flag,\n     // so it is safe to pass false always.\n     INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n         modificationTime, blocks, blockReplication, preferredBlockSize);\n     file.toUnderConstruction(clientName, clientMachine);\n     return file;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n        : fsNamesys.dir.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n  \n    int numBlocks \u003d in.readInt();\n    BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n    Block blk \u003d new Block();\n    int i \u003d 0;\n    for (; i \u003c numBlocks-1; i++) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n    }\n    // last block is UNDER_CONSTRUCTION\n    if(numBlocks \u003e 0) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoContiguousUnderConstruction(\n        blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n    }\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    // Images in the pre-protobuf format will not have the lazyPersist flag,\n    // so it is safe to pass false always.\n    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n        modificationTime, blocks, blockReplication, preferredBlockSize);\n    file.toUnderConstruction(clientName, clientMachine);\n    return file;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
      "extendedDetails": {}
    },
    "4fdd9abd7e43a0fb7b569982954a8f9660b9268b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8787. Erasure coding: rename BlockInfoContiguousUC and BlockInfoStripedUC to be consistent with trunk.\n",
      "commitDate": "15/07/15 8:13 PM",
      "commitName": "4fdd9abd7e43a0fb7b569982954a8f9660b9268b",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "14/06/15 12:39 AM",
      "commitNameOld": "49d5cff49011cc0878665204e22b5c832bc914ce",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 31.82,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n   static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d NameNodeLayoutVersion.supports(\n         LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n         : fsNamesys.dir.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n \n     int numBlocks \u003d in.readInt();\n \n     final BlockInfoContiguous[] blocksContiguous \u003d\n         new BlockInfoContiguous[numBlocks];\n     Block blk \u003d new Block();\n     int i \u003d 0;\n     for (; i \u003c numBlocks - 1; i++) {\n       blk.readFields(in);\n       blocksContiguous[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n     }\n     // last block is UNDER_CONSTRUCTION\n     if(numBlocks \u003e 0) {\n       blk.readFields(in);\n-      blocksContiguous[i] \u003d new BlockInfoContiguousUnderConstruction(\n+      blocksContiguous[i] \u003d new BlockInfoUnderConstructionContiguous(\n           blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n     }\n \n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n     // Images in the pre-protobuf format will not have the lazyPersist flag,\n     // so it is safe to pass false always.\n     INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n         modificationTime, blocksContiguous, blockReplication, preferredBlockSize);\n     file.toUnderConstruction(clientName, clientMachine);\n     return file;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n        : fsNamesys.dir.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n\n    int numBlocks \u003d in.readInt();\n\n    final BlockInfoContiguous[] blocksContiguous \u003d\n        new BlockInfoContiguous[numBlocks];\n    Block blk \u003d new Block();\n    int i \u003d 0;\n    for (; i \u003c numBlocks - 1; i++) {\n      blk.readFields(in);\n      blocksContiguous[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n    }\n    // last block is UNDER_CONSTRUCTION\n    if(numBlocks \u003e 0) {\n      blk.readFields(in);\n      blocksContiguous[i] \u003d new BlockInfoUnderConstructionContiguous(\n          blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n    }\n\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    // Images in the pre-protobuf format will not have the lazyPersist flag,\n    // so it is safe to pass false always.\n    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n        modificationTime, blocksContiguous, blockReplication, preferredBlockSize);\n    file.toUnderConstruction(clientName, clientMachine);\n    return file;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
      "extendedDetails": {}
    },
    "49d5cff49011cc0878665204e22b5c832bc914ce": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8559. Erasure Coding: fix non-protobuf fsimage for striped blocks. (Jing Zhao via yliu)\n",
      "commitDate": "14/06/15 12:39 AM",
      "commitName": "49d5cff49011cc0878665204e22b5c832bc914ce",
      "commitAuthor": "yliu",
      "commitDateOld": "26/05/15 12:02 PM",
      "commitNameOld": "c9103e9cacc67a614940e32fa87c5dbc3daa60de",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 18.53,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,44 @@\n   static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d NameNodeLayoutVersion.supports(\n         LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n         : fsNamesys.dir.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n-    final boolean isStriped \u003d NameNodeLayoutVersion.supports(\n-        NameNodeLayoutVersion.Feature.ERASURE_CODING, imgVersion)\n-        \u0026\u0026 (in.readBoolean());\n-\n-    // TODO: ECSchema can be restored from persisted file (HDFS-7859).\n-    final ECSchema schema \u003d isStriped ?\n-        ErasureCodingSchemaManager.getSystemDefaultSchema() : null;\n \n     int numBlocks \u003d in.readInt();\n \n-    final BlockInfoContiguous[] blocksContiguous;\n-    BlockInfoStriped[] blocksStriped \u003d null;\n-    if (isStriped) {\n-      blocksContiguous \u003d new BlockInfoContiguous[0];\n-      blocksStriped \u003d new BlockInfoStriped[numBlocks];\n-      int i \u003d 0;\n-      for (; i \u003c numBlocks - 1; i++) {\n-        blocksStriped[i] \u003d new BlockInfoStriped(new Block(), schema);\n-        blocksStriped[i].readFields(in);\n-      }\n-      if (numBlocks \u003e 0) {\n-        blocksStriped[i] \u003d new BlockInfoStripedUnderConstruction(new Block(),\n-            schema, BlockUCState.UNDER_CONSTRUCTION, null);\n-        blocksStriped[i].readFields(in);\n-      }\n-    } else {\n-      blocksContiguous \u003d new BlockInfoContiguous[numBlocks];\n-      Block blk \u003d new Block();\n-      int i \u003d 0;\n-      for (; i \u003c numBlocks-1; i++) {\n-        blk.readFields(in);\n-        blocksContiguous[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n-      }\n-      // last block is UNDER_CONSTRUCTION\n-      if(numBlocks \u003e 0) {\n-        blk.readFields(in);\n-        blocksContiguous[i] \u003d new BlockInfoContiguousUnderConstruction(\n-                blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n-      }\n+    final BlockInfoContiguous[] blocksContiguous \u003d\n+        new BlockInfoContiguous[numBlocks];\n+    Block blk \u003d new Block();\n+    int i \u003d 0;\n+    for (; i \u003c numBlocks - 1; i++) {\n+      blk.readFields(in);\n+      blocksContiguous[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n+    }\n+    // last block is UNDER_CONSTRUCTION\n+    if(numBlocks \u003e 0) {\n+      blk.readFields(in);\n+      blocksContiguous[i] \u003d new BlockInfoContiguousUnderConstruction(\n+          blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n     }\n \n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n     // Images in the pre-protobuf format will not have the lazyPersist flag,\n     // so it is safe to pass false always.\n-    INodeFile file;\n-    if (isStriped) {\n-      file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n-          modificationTime, blocksContiguous, (short) 0, preferredBlockSize);\n-      file.addStripedBlocksFeature();\n-      for (int i \u003d 0; i \u003c numBlocks; i++) {\n-        file.getStripedBlocksFeature().addBlock(blocksStriped[i]);\n-      }\n-    } else {\n-      file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n-          modificationTime, blocksContiguous, blockReplication,\n-          preferredBlockSize);\n-    }\n+    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n+        modificationTime, blocksContiguous, blockReplication, preferredBlockSize);\n     file.toUnderConstruction(clientName, clientMachine);\n     return file;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n        : fsNamesys.dir.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n\n    int numBlocks \u003d in.readInt();\n\n    final BlockInfoContiguous[] blocksContiguous \u003d\n        new BlockInfoContiguous[numBlocks];\n    Block blk \u003d new Block();\n    int i \u003d 0;\n    for (; i \u003c numBlocks - 1; i++) {\n      blk.readFields(in);\n      blocksContiguous[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n    }\n    // last block is UNDER_CONSTRUCTION\n    if(numBlocks \u003e 0) {\n      blk.readFields(in);\n      blocksContiguous[i] \u003d new BlockInfoContiguousUnderConstruction(\n          blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n    }\n\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    // Images in the pre-protobuf format will not have the lazyPersist flag,\n    // so it is safe to pass false always.\n    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n        modificationTime, blocksContiguous, blockReplication, preferredBlockSize);\n    file.toUnderConstruction(clientName, clientMachine);\n    return file;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
      "extendedDetails": {}
    },
    "c17439c2ddd921b63b1635e6f1cba634b8da8557": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang.\n",
      "commitDate": "12/06/15 11:38 AM",
      "commitName": "c17439c2ddd921b63b1635e6f1cba634b8da8557",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "01/06/15 11:42 AM",
      "commitNameOld": "cdc13efb1af54d931585d25c5ba696a012412828",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 11.0,
      "commitsBetweenForRepo": 80,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,41 @@\n   static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d NameNodeLayoutVersion.supports(\n         LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n         : fsNamesys.dir.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n   \n     int numBlocks \u003d in.readInt();\n     BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n     Block blk \u003d new Block();\n     int i \u003d 0;\n     for (; i \u003c numBlocks-1; i++) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n     }\n     // last block is UNDER_CONSTRUCTION\n     if(numBlocks \u003e 0) {\n       blk.readFields(in);\n-      blocks[i] \u003d new BlockInfoContiguousUnderConstruction(\n+      blocks[i] \u003d new BlockInfoUnderConstructionContiguous(\n         blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n     }\n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n     // Images in the pre-protobuf format will not have the lazyPersist flag,\n     // so it is safe to pass false always.\n     INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n         modificationTime, blocks, blockReplication, preferredBlockSize);\n     file.toUnderConstruction(clientName, clientMachine);\n     return file;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n        : fsNamesys.dir.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n  \n    int numBlocks \u003d in.readInt();\n    BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n    Block blk \u003d new Block();\n    int i \u003d 0;\n    for (; i \u003c numBlocks-1; i++) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n    }\n    // last block is UNDER_CONSTRUCTION\n    if(numBlocks \u003e 0) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoUnderConstructionContiguous(\n        blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n    }\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    // Images in the pre-protobuf format will not have the lazyPersist flag,\n    // so it is safe to pass false always.\n    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n        modificationTime, blocks, blockReplication, preferredBlockSize);\n    file.toUnderConstruction(clientName, clientMachine);\n    return file;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
      "extendedDetails": {}
    },
    "cdc13efb1af54d931585d25c5ba696a012412828": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8489. Subclass BlockInfo to represent contiguous blocks. Contributed by Zhe Zhang.\n",
      "commitDate": "01/06/15 11:42 AM",
      "commitName": "cdc13efb1af54d931585d25c5ba696a012412828",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "27/05/15 3:42 PM",
      "commitNameOld": "4928f5473394981829e5ffd4b16ea0801baf5c45",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 4.83,
      "commitsBetweenForRepo": 42,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,41 @@\n   static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d NameNodeLayoutVersion.supports(\n         LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n         : fsNamesys.dir.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n   \n     int numBlocks \u003d in.readInt();\n     BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n     Block blk \u003d new Block();\n     int i \u003d 0;\n     for (; i \u003c numBlocks-1; i++) {\n       blk.readFields(in);\n-      blocks[i] \u003d new BlockInfo(blk, blockReplication);\n+      blocks[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n     }\n     // last block is UNDER_CONSTRUCTION\n     if(numBlocks \u003e 0) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfoContiguousUnderConstruction(\n         blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n     }\n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n     // Images in the pre-protobuf format will not have the lazyPersist flag,\n     // so it is safe to pass false always.\n     INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n         modificationTime, blocks, blockReplication, preferredBlockSize);\n     file.toUnderConstruction(clientName, clientMachine);\n     return file;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n        : fsNamesys.dir.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n  \n    int numBlocks \u003d in.readInt();\n    BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n    Block blk \u003d new Block();\n    int i \u003d 0;\n    for (; i \u003c numBlocks-1; i++) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n    }\n    // last block is UNDER_CONSTRUCTION\n    if(numBlocks \u003e 0) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoContiguousUnderConstruction(\n        blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n    }\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    // Images in the pre-protobuf format will not have the lazyPersist flag,\n    // so it is safe to pass false always.\n    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n        modificationTime, blocks, blockReplication, preferredBlockSize);\n    file.toUnderConstruction(clientName, clientMachine);\n    return file;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
      "extendedDetails": {}
    },
    "4928f5473394981829e5ffd4b16ea0801baf5c45": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8482. Rename BlockInfoContiguous to BlockInfo. Contributed by Zhe Zhang.\n",
      "commitDate": "27/05/15 3:42 PM",
      "commitName": "4928f5473394981829e5ffd4b16ea0801baf5c45",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "13/02/15 9:01 PM",
      "commitNameOld": "f2231cebcddc80f0b753c4a7cb45ee4040846951",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 102.74,
      "commitsBetweenForRepo": 942,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,41 @@\n   static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d NameNodeLayoutVersion.supports(\n         LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n         : fsNamesys.dir.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n   \n     int numBlocks \u003d in.readInt();\n-    BlockInfoContiguous[] blocks \u003d new BlockInfoContiguous[numBlocks];\n+    BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n     Block blk \u003d new Block();\n     int i \u003d 0;\n     for (; i \u003c numBlocks-1; i++) {\n       blk.readFields(in);\n-      blocks[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n+      blocks[i] \u003d new BlockInfo(blk, blockReplication);\n     }\n     // last block is UNDER_CONSTRUCTION\n     if(numBlocks \u003e 0) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfoContiguousUnderConstruction(\n         blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n     }\n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n     // Images in the pre-protobuf format will not have the lazyPersist flag,\n     // so it is safe to pass false always.\n     INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n         modificationTime, blocks, blockReplication, preferredBlockSize);\n     file.toUnderConstruction(clientName, clientMachine);\n     return file;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n        : fsNamesys.dir.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n  \n    int numBlocks \u003d in.readInt();\n    BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n    Block blk \u003d new Block();\n    int i \u003d 0;\n    for (; i \u003c numBlocks-1; i++) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfo(blk, blockReplication);\n    }\n    // last block is UNDER_CONSTRUCTION\n    if(numBlocks \u003e 0) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoContiguousUnderConstruction(\n        blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n    }\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    // Images in the pre-protobuf format will not have the lazyPersist flag,\n    // so it is safe to pass false always.\n    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n        modificationTime, blocks, blockReplication, preferredBlockSize);\n    file.toUnderConstruction(clientName, clientMachine);\n    return file;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
      "extendedDetails": {}
    },
    "c9103e9cacc67a614940e32fa87c5dbc3daa60de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8367 BlockInfoStriped uses EC schema. Contributed by Kai Sasaki\n",
      "commitDate": "26/05/15 12:02 PM",
      "commitName": "c9103e9cacc67a614940e32fa87c5dbc3daa60de",
      "commitAuthor": "Kai Zheng",
      "commitDateOld": "26/05/15 11:59 AM",
      "commitNameOld": "f6e1160ef1e946a5f6c9503b06832e6b84c36edb",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 44,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,78 @@\n   static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d NameNodeLayoutVersion.supports(\n         LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n         : fsNamesys.dir.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n     final boolean isStriped \u003d NameNodeLayoutVersion.supports(\n         NameNodeLayoutVersion.Feature.ERASURE_CODING, imgVersion)\n         \u0026\u0026 (in.readBoolean());\n-  \n+\n+    // TODO: ECSchema can be restored from persisted file (HDFS-7859).\n+    final ECSchema schema \u003d isStriped ?\n+        ErasureCodingSchemaManager.getSystemDefaultSchema() : null;\n+\n     int numBlocks \u003d in.readInt();\n \n     final BlockInfoContiguous[] blocksContiguous;\n     BlockInfoStriped[] blocksStriped \u003d null;\n     if (isStriped) {\n       blocksContiguous \u003d new BlockInfoContiguous[0];\n       blocksStriped \u003d new BlockInfoStriped[numBlocks];\n       int i \u003d 0;\n       for (; i \u003c numBlocks - 1; i++) {\n-        blocksStriped[i] \u003d new BlockInfoStriped(new Block(),\n-            HdfsConstants.NUM_DATA_BLOCKS,\n-            HdfsConstants.NUM_PARITY_BLOCKS);\n+        blocksStriped[i] \u003d new BlockInfoStriped(new Block(), schema);\n         blocksStriped[i].readFields(in);\n       }\n       if (numBlocks \u003e 0) {\n         blocksStriped[i] \u003d new BlockInfoStripedUnderConstruction(new Block(),\n-            HdfsConstants.NUM_DATA_BLOCKS, HdfsConstants.NUM_PARITY_BLOCKS,\n-            BlockUCState.UNDER_CONSTRUCTION, null);\n+            schema, BlockUCState.UNDER_CONSTRUCTION, null);\n         blocksStriped[i].readFields(in);\n       }\n     } else {\n       blocksContiguous \u003d new BlockInfoContiguous[numBlocks];\n       Block blk \u003d new Block();\n       int i \u003d 0;\n       for (; i \u003c numBlocks-1; i++) {\n         blk.readFields(in);\n         blocksContiguous[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n       }\n       // last block is UNDER_CONSTRUCTION\n       if(numBlocks \u003e 0) {\n         blk.readFields(in);\n         blocksContiguous[i] \u003d new BlockInfoContiguousUnderConstruction(\n                 blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n       }\n     }\n \n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n     // Images in the pre-protobuf format will not have the lazyPersist flag,\n     // so it is safe to pass false always.\n     INodeFile file;\n     if (isStriped) {\n       file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n           modificationTime, blocksContiguous, (short) 0, preferredBlockSize);\n       file.addStripedBlocksFeature();\n       for (int i \u003d 0; i \u003c numBlocks; i++) {\n         file.getStripedBlocksFeature().addBlock(blocksStriped[i]);\n       }\n     } else {\n       file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n           modificationTime, blocksContiguous, blockReplication,\n           preferredBlockSize);\n     }\n     file.toUnderConstruction(clientName, clientMachine);\n     return file;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n        : fsNamesys.dir.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n    final boolean isStriped \u003d NameNodeLayoutVersion.supports(\n        NameNodeLayoutVersion.Feature.ERASURE_CODING, imgVersion)\n        \u0026\u0026 (in.readBoolean());\n\n    // TODO: ECSchema can be restored from persisted file (HDFS-7859).\n    final ECSchema schema \u003d isStriped ?\n        ErasureCodingSchemaManager.getSystemDefaultSchema() : null;\n\n    int numBlocks \u003d in.readInt();\n\n    final BlockInfoContiguous[] blocksContiguous;\n    BlockInfoStriped[] blocksStriped \u003d null;\n    if (isStriped) {\n      blocksContiguous \u003d new BlockInfoContiguous[0];\n      blocksStriped \u003d new BlockInfoStriped[numBlocks];\n      int i \u003d 0;\n      for (; i \u003c numBlocks - 1; i++) {\n        blocksStriped[i] \u003d new BlockInfoStriped(new Block(), schema);\n        blocksStriped[i].readFields(in);\n      }\n      if (numBlocks \u003e 0) {\n        blocksStriped[i] \u003d new BlockInfoStripedUnderConstruction(new Block(),\n            schema, BlockUCState.UNDER_CONSTRUCTION, null);\n        blocksStriped[i].readFields(in);\n      }\n    } else {\n      blocksContiguous \u003d new BlockInfoContiguous[numBlocks];\n      Block blk \u003d new Block();\n      int i \u003d 0;\n      for (; i \u003c numBlocks-1; i++) {\n        blk.readFields(in);\n        blocksContiguous[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n      }\n      // last block is UNDER_CONSTRUCTION\n      if(numBlocks \u003e 0) {\n        blk.readFields(in);\n        blocksContiguous[i] \u003d new BlockInfoContiguousUnderConstruction(\n                blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n      }\n    }\n\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    // Images in the pre-protobuf format will not have the lazyPersist flag,\n    // so it is safe to pass false always.\n    INodeFile file;\n    if (isStriped) {\n      file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n          modificationTime, blocksContiguous, (short) 0, preferredBlockSize);\n      file.addStripedBlocksFeature();\n      for (int i \u003d 0; i \u003c numBlocks; i++) {\n        file.getStripedBlocksFeature().addBlock(blocksStriped[i]);\n      }\n    } else {\n      file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n          modificationTime, blocksContiguous, blockReplication,\n          preferredBlockSize);\n    }\n    file.toUnderConstruction(clientName, clientMachine);\n    return file;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
      "extendedDetails": {}
    },
    "f6e1160ef1e946a5f6c9503b06832e6b84c36edb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8145. Fix the editlog corruption exposed by failed TestAddStripedBlocks. Contributed by Jing Zhao.\n",
      "commitDate": "26/05/15 11:59 AM",
      "commitName": "f6e1160ef1e946a5f6c9503b06832e6b84c36edb",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "26/05/15 11:58 AM",
      "commitNameOld": "4d0bc724f29b646e252f53d1c654a23e8526a4bf",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,79 +1,77 @@\n   static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d NameNodeLayoutVersion.supports(\n         LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n         : fsNamesys.dir.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n     final boolean isStriped \u003d NameNodeLayoutVersion.supports(\n         NameNodeLayoutVersion.Feature.ERASURE_CODING, imgVersion)\n         \u0026\u0026 (in.readBoolean());\n   \n     int numBlocks \u003d in.readInt();\n \n     final BlockInfoContiguous[] blocksContiguous;\n     BlockInfoStriped[] blocksStriped \u003d null;\n     if (isStriped) {\n       blocksContiguous \u003d new BlockInfoContiguous[0];\n       blocksStriped \u003d new BlockInfoStriped[numBlocks];\n       int i \u003d 0;\n       for (; i \u003c numBlocks - 1; i++) {\n-        short dataBlockNum \u003d in.readShort();\n-        short parityBlockNum \u003d in.readShort();\n-        blocksStriped[i] \u003d new BlockInfoStriped(new Block(), dataBlockNum,\n-            parityBlockNum);\n+        blocksStriped[i] \u003d new BlockInfoStriped(new Block(),\n+            HdfsConstants.NUM_DATA_BLOCKS,\n+            HdfsConstants.NUM_PARITY_BLOCKS);\n         blocksStriped[i].readFields(in);\n       }\n       if (numBlocks \u003e 0) {\n-        short dataBlockNum \u003d in.readShort();\n-        short parityBlockNum \u003d in.readShort();\n         blocksStriped[i] \u003d new BlockInfoStripedUnderConstruction(new Block(),\n-            dataBlockNum, parityBlockNum, BlockUCState.UNDER_CONSTRUCTION, null);\n+            HdfsConstants.NUM_DATA_BLOCKS, HdfsConstants.NUM_PARITY_BLOCKS,\n+            BlockUCState.UNDER_CONSTRUCTION, null);\n         blocksStriped[i].readFields(in);\n       }\n     } else {\n       blocksContiguous \u003d new BlockInfoContiguous[numBlocks];\n       Block blk \u003d new Block();\n       int i \u003d 0;\n       for (; i \u003c numBlocks-1; i++) {\n         blk.readFields(in);\n         blocksContiguous[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n       }\n       // last block is UNDER_CONSTRUCTION\n       if(numBlocks \u003e 0) {\n         blk.readFields(in);\n         blocksContiguous[i] \u003d new BlockInfoContiguousUnderConstruction(\n                 blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n       }\n     }\n \n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n     // Images in the pre-protobuf format will not have the lazyPersist flag,\n     // so it is safe to pass false always.\n     INodeFile file;\n     if (isStriped) {\n       file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n           modificationTime, blocksContiguous, (short) 0, preferredBlockSize);\n       file.addStripedBlocksFeature();\n       for (int i \u003d 0; i \u003c numBlocks; i++) {\n         file.getStripedBlocksFeature().addBlock(blocksStriped[i]);\n       }\n     } else {\n       file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n           modificationTime, blocksContiguous, blockReplication,\n           preferredBlockSize);\n     }\n     file.toUnderConstruction(clientName, clientMachine);\n     return file;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n        : fsNamesys.dir.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n    final boolean isStriped \u003d NameNodeLayoutVersion.supports(\n        NameNodeLayoutVersion.Feature.ERASURE_CODING, imgVersion)\n        \u0026\u0026 (in.readBoolean());\n  \n    int numBlocks \u003d in.readInt();\n\n    final BlockInfoContiguous[] blocksContiguous;\n    BlockInfoStriped[] blocksStriped \u003d null;\n    if (isStriped) {\n      blocksContiguous \u003d new BlockInfoContiguous[0];\n      blocksStriped \u003d new BlockInfoStriped[numBlocks];\n      int i \u003d 0;\n      for (; i \u003c numBlocks - 1; i++) {\n        blocksStriped[i] \u003d new BlockInfoStriped(new Block(),\n            HdfsConstants.NUM_DATA_BLOCKS,\n            HdfsConstants.NUM_PARITY_BLOCKS);\n        blocksStriped[i].readFields(in);\n      }\n      if (numBlocks \u003e 0) {\n        blocksStriped[i] \u003d new BlockInfoStripedUnderConstruction(new Block(),\n            HdfsConstants.NUM_DATA_BLOCKS, HdfsConstants.NUM_PARITY_BLOCKS,\n            BlockUCState.UNDER_CONSTRUCTION, null);\n        blocksStriped[i].readFields(in);\n      }\n    } else {\n      blocksContiguous \u003d new BlockInfoContiguous[numBlocks];\n      Block blk \u003d new Block();\n      int i \u003d 0;\n      for (; i \u003c numBlocks-1; i++) {\n        blk.readFields(in);\n        blocksContiguous[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n      }\n      // last block is UNDER_CONSTRUCTION\n      if(numBlocks \u003e 0) {\n        blk.readFields(in);\n        blocksContiguous[i] \u003d new BlockInfoContiguousUnderConstruction(\n                blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n      }\n    }\n\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    // Images in the pre-protobuf format will not have the lazyPersist flag,\n    // so it is safe to pass false always.\n    INodeFile file;\n    if (isStriped) {\n      file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n          modificationTime, blocksContiguous, (short) 0, preferredBlockSize);\n      file.addStripedBlocksFeature();\n      for (int i \u003d 0; i \u003c numBlocks; i++) {\n        file.getStripedBlocksFeature().addBlock(blocksStriped[i]);\n      }\n    } else {\n      file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n          modificationTime, blocksContiguous, blockReplication,\n          preferredBlockSize);\n    }\n    file.toUnderConstruction(clientName, clientMachine);\n    return file;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
      "extendedDetails": {}
    },
    "d0d75a833907f6cf723a42a007ca04e0004a8e52": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7827. Erasure Coding: support striped blocks in non-protobuf fsimage. Contributed by Hui Zheng.\n",
      "commitDate": "26/05/15 11:43 AM",
      "commitName": "d0d75a833907f6cf723a42a007ca04e0004a8e52",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "13/02/15 9:01 PM",
      "commitNameOld": "f2231cebcddc80f0b753c4a7cb45ee4040846951",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 101.57,
      "commitsBetweenForRepo": 959,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,79 @@\n   static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d NameNodeLayoutVersion.supports(\n         LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n         : fsNamesys.dir.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n+    final boolean isStriped \u003d NameNodeLayoutVersion.supports(\n+        NameNodeLayoutVersion.Feature.ERASURE_CODING, imgVersion)\n+        \u0026\u0026 (in.readBoolean());\n   \n     int numBlocks \u003d in.readInt();\n-    BlockInfoContiguous[] blocks \u003d new BlockInfoContiguous[numBlocks];\n-    Block blk \u003d new Block();\n-    int i \u003d 0;\n-    for (; i \u003c numBlocks-1; i++) {\n-      blk.readFields(in);\n-      blocks[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n+\n+    final BlockInfoContiguous[] blocksContiguous;\n+    BlockInfoStriped[] blocksStriped \u003d null;\n+    if (isStriped) {\n+      blocksContiguous \u003d new BlockInfoContiguous[0];\n+      blocksStriped \u003d new BlockInfoStriped[numBlocks];\n+      int i \u003d 0;\n+      for (; i \u003c numBlocks - 1; i++) {\n+        short dataBlockNum \u003d in.readShort();\n+        short parityBlockNum \u003d in.readShort();\n+        blocksStriped[i] \u003d new BlockInfoStriped(new Block(), dataBlockNum,\n+            parityBlockNum);\n+        blocksStriped[i].readFields(in);\n+      }\n+      if (numBlocks \u003e 0) {\n+        short dataBlockNum \u003d in.readShort();\n+        short parityBlockNum \u003d in.readShort();\n+        blocksStriped[i] \u003d new BlockInfoStripedUnderConstruction(new Block(),\n+            dataBlockNum, parityBlockNum, BlockUCState.UNDER_CONSTRUCTION, null);\n+        blocksStriped[i].readFields(in);\n+      }\n+    } else {\n+      blocksContiguous \u003d new BlockInfoContiguous[numBlocks];\n+      Block blk \u003d new Block();\n+      int i \u003d 0;\n+      for (; i \u003c numBlocks-1; i++) {\n+        blk.readFields(in);\n+        blocksContiguous[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n+      }\n+      // last block is UNDER_CONSTRUCTION\n+      if(numBlocks \u003e 0) {\n+        blk.readFields(in);\n+        blocksContiguous[i] \u003d new BlockInfoContiguousUnderConstruction(\n+                blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n+      }\n     }\n-    // last block is UNDER_CONSTRUCTION\n-    if(numBlocks \u003e 0) {\n-      blk.readFields(in);\n-      blocks[i] \u003d new BlockInfoContiguousUnderConstruction(\n-        blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n-    }\n+\n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n     // Images in the pre-protobuf format will not have the lazyPersist flag,\n     // so it is safe to pass false always.\n-    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n-        modificationTime, blocks, blockReplication, preferredBlockSize);\n+    INodeFile file;\n+    if (isStriped) {\n+      file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n+          modificationTime, blocksContiguous, (short) 0, preferredBlockSize);\n+      file.addStripedBlocksFeature();\n+      for (int i \u003d 0; i \u003c numBlocks; i++) {\n+        file.getStripedBlocksFeature().addBlock(blocksStriped[i]);\n+      }\n+    } else {\n+      file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n+          modificationTime, blocksContiguous, blockReplication,\n+          preferredBlockSize);\n+    }\n     file.toUnderConstruction(clientName, clientMachine);\n     return file;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n        : fsNamesys.dir.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n    final boolean isStriped \u003d NameNodeLayoutVersion.supports(\n        NameNodeLayoutVersion.Feature.ERASURE_CODING, imgVersion)\n        \u0026\u0026 (in.readBoolean());\n  \n    int numBlocks \u003d in.readInt();\n\n    final BlockInfoContiguous[] blocksContiguous;\n    BlockInfoStriped[] blocksStriped \u003d null;\n    if (isStriped) {\n      blocksContiguous \u003d new BlockInfoContiguous[0];\n      blocksStriped \u003d new BlockInfoStriped[numBlocks];\n      int i \u003d 0;\n      for (; i \u003c numBlocks - 1; i++) {\n        short dataBlockNum \u003d in.readShort();\n        short parityBlockNum \u003d in.readShort();\n        blocksStriped[i] \u003d new BlockInfoStriped(new Block(), dataBlockNum,\n            parityBlockNum);\n        blocksStriped[i].readFields(in);\n      }\n      if (numBlocks \u003e 0) {\n        short dataBlockNum \u003d in.readShort();\n        short parityBlockNum \u003d in.readShort();\n        blocksStriped[i] \u003d new BlockInfoStripedUnderConstruction(new Block(),\n            dataBlockNum, parityBlockNum, BlockUCState.UNDER_CONSTRUCTION, null);\n        blocksStriped[i].readFields(in);\n      }\n    } else {\n      blocksContiguous \u003d new BlockInfoContiguous[numBlocks];\n      Block blk \u003d new Block();\n      int i \u003d 0;\n      for (; i \u003c numBlocks-1; i++) {\n        blk.readFields(in);\n        blocksContiguous[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n      }\n      // last block is UNDER_CONSTRUCTION\n      if(numBlocks \u003e 0) {\n        blk.readFields(in);\n        blocksContiguous[i] \u003d new BlockInfoContiguousUnderConstruction(\n                blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n      }\n    }\n\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    // Images in the pre-protobuf format will not have the lazyPersist flag,\n    // so it is safe to pass false always.\n    INodeFile file;\n    if (isStriped) {\n      file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n          modificationTime, blocksContiguous, (short) 0, preferredBlockSize);\n      file.addStripedBlocksFeature();\n      for (int i \u003d 0; i \u003c numBlocks; i++) {\n        file.getStripedBlocksFeature().addBlock(blocksStriped[i]);\n      }\n    } else {\n      file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n          modificationTime, blocksContiguous, blockReplication,\n          preferredBlockSize);\n    }\n    file.toUnderConstruction(clientName, clientMachine);\n    return file;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
      "extendedDetails": {}
    },
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7743. Code cleanup of BlockInfo and rename BlockInfo to BlockInfoContiguous. Contributed by Jing Zhao.\n",
      "commitDate": "08/02/15 11:51 AM",
      "commitName": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "02/12/14 2:53 PM",
      "commitNameOld": "185e0c7b4c056b88f606362c71e4a22aae7076e0",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 67.87,
      "commitsBetweenForRepo": 457,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,41 @@\n   static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d NameNodeLayoutVersion.supports(\n         LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n         : fsNamesys.dir.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n   \n     int numBlocks \u003d in.readInt();\n-    BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n+    BlockInfoContiguous[] blocks \u003d new BlockInfoContiguous[numBlocks];\n     Block blk \u003d new Block();\n     int i \u003d 0;\n     for (; i \u003c numBlocks-1; i++) {\n       blk.readFields(in);\n-      blocks[i] \u003d new BlockInfo(blk, blockReplication);\n+      blocks[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n     }\n     // last block is UNDER_CONSTRUCTION\n     if(numBlocks \u003e 0) {\n       blk.readFields(in);\n-      blocks[i] \u003d new BlockInfoUnderConstruction(\n+      blocks[i] \u003d new BlockInfoContiguousUnderConstruction(\n         blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n     }\n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n     // Images in the pre-protobuf format will not have the lazyPersist flag,\n     // so it is safe to pass false always.\n     INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n         modificationTime, blocks, blockReplication, preferredBlockSize);\n     file.toUnderConstruction(clientName, clientMachine);\n     return file;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n        : fsNamesys.dir.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n  \n    int numBlocks \u003d in.readInt();\n    BlockInfoContiguous[] blocks \u003d new BlockInfoContiguous[numBlocks];\n    Block blk \u003d new Block();\n    int i \u003d 0;\n    for (; i \u003c numBlocks-1; i++) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoContiguous(blk, blockReplication);\n    }\n    // last block is UNDER_CONSTRUCTION\n    if(numBlocks \u003e 0) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoContiguousUnderConstruction(\n        blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n    }\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    // Images in the pre-protobuf format will not have the lazyPersist flag,\n    // so it is safe to pass false always.\n    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n        modificationTime, blocks, blockReplication, preferredBlockSize);\n    file.toUnderConstruction(clientName, clientMachine);\n    return file;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
      "extendedDetails": {}
    },
    "185e0c7b4c056b88f606362c71e4a22aae7076e0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7462. Consolidate implementation of mkdirs() into a single class. Contributed by Haohui Mai.\n",
      "commitDate": "02/12/14 2:53 PM",
      "commitName": "185e0c7b4c056b88f606362c71e4a22aae7076e0",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/14 12:36 PM",
      "commitNameOld": "d45e7c7e856c7103752888c0395fa94985cd7670",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 64.14,
      "commitsBetweenForRepo": 555,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,41 @@\n   static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d NameNodeLayoutVersion.supports(\n         LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n-        : fsNamesys.allocateNewInodeId();\n+        : fsNamesys.dir.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n   \n     int numBlocks \u003d in.readInt();\n     BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n     Block blk \u003d new Block();\n     int i \u003d 0;\n     for (; i \u003c numBlocks-1; i++) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfo(blk, blockReplication);\n     }\n     // last block is UNDER_CONSTRUCTION\n     if(numBlocks \u003e 0) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfoUnderConstruction(\n         blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n     }\n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n     // Images in the pre-protobuf format will not have the lazyPersist flag,\n     // so it is safe to pass false always.\n     INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n         modificationTime, blocks, blockReplication, preferredBlockSize);\n     file.toUnderConstruction(clientName, clientMachine);\n     return file;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n        : fsNamesys.dir.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n  \n    int numBlocks \u003d in.readInt();\n    BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n    Block blk \u003d new Block();\n    int i \u003d 0;\n    for (; i \u003c numBlocks-1; i++) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfo(blk, blockReplication);\n    }\n    // last block is UNDER_CONSTRUCTION\n    if(numBlocks \u003e 0) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoUnderConstruction(\n        blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n    }\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    // Images in the pre-protobuf format will not have the lazyPersist flag,\n    // so it is safe to pass false always.\n    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n        modificationTime, blocks, blockReplication, preferredBlockSize);\n    file.toUnderConstruction(clientName, clientMachine);\n    return file;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
      "extendedDetails": {}
    },
    "e79c98c11fa8b4ddd8c63b613698d2d508135e83": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7091. Add forwarding constructor for INodeFile for existing callers. (Arpit Agarwal)\n",
      "commitDate": "18/09/14 7:20 PM",
      "commitName": "e79c98c11fa8b4ddd8c63b613698d2d508135e83",
      "commitAuthor": "arp",
      "commitDateOld": "05/09/14 9:36 PM",
      "commitNameOld": "339d21f273a7c32be989c2cc2b3b1f0dd8a2ec0f",
      "commitAuthorOld": "",
      "daysBetweenCommits": 12.91,
      "commitsBetweenForRepo": 134,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,41 @@\n   static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d NameNodeLayoutVersion.supports(\n         LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n         : fsNamesys.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n   \n     int numBlocks \u003d in.readInt();\n     BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n     Block blk \u003d new Block();\n     int i \u003d 0;\n     for (; i \u003c numBlocks-1; i++) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfo(blk, blockReplication);\n     }\n     // last block is UNDER_CONSTRUCTION\n     if(numBlocks \u003e 0) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfoUnderConstruction(\n         blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n     }\n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n     // Images in the pre-protobuf format will not have the lazyPersist flag,\n     // so it is safe to pass false always.\n     INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n-        modificationTime, blocks, blockReplication, preferredBlockSize, false);\n+        modificationTime, blocks, blockReplication, preferredBlockSize);\n     file.toUnderConstruction(clientName, clientMachine);\n     return file;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n        : fsNamesys.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n  \n    int numBlocks \u003d in.readInt();\n    BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n    Block blk \u003d new Block();\n    int i \u003d 0;\n    for (; i \u003c numBlocks-1; i++) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfo(blk, blockReplication);\n    }\n    // last block is UNDER_CONSTRUCTION\n    if(numBlocks \u003e 0) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoUnderConstruction(\n        blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n    }\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    // Images in the pre-protobuf format will not have the lazyPersist flag,\n    // so it is safe to pass false always.\n    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n        modificationTime, blocks, blockReplication, preferredBlockSize);\n    file.toUnderConstruction(clientName, clientMachine);\n    return file;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
      "extendedDetails": {}
    },
    "042b33f20b01aadb5cd03da731ae7a3d94026aac": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6922. Add LazyPersist flag to INodeFile, save it in FsImage and edit logs. (Arpit Agarwal)\n",
      "commitDate": "27/08/14 9:47 PM",
      "commitName": "042b33f20b01aadb5cd03da731ae7a3d94026aac",
      "commitAuthor": "arp",
      "commitDateOld": "07/07/14 5:08 PM",
      "commitNameOld": "76a621ffd2d66bf012a554f4400091a92a5b473e",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 51.19,
      "commitsBetweenForRepo": 428,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,41 @@\n   static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d NameNodeLayoutVersion.supports(\n         LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n         : fsNamesys.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n   \n     int numBlocks \u003d in.readInt();\n     BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n     Block blk \u003d new Block();\n     int i \u003d 0;\n     for (; i \u003c numBlocks-1; i++) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfo(blk, blockReplication);\n     }\n     // last block is UNDER_CONSTRUCTION\n     if(numBlocks \u003e 0) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfoUnderConstruction(\n         blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n     }\n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n+    // Images in the pre-protobuf format will not have the lazyPersist flag,\n+    // so it is safe to pass false always.\n     INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n-        modificationTime, blocks, blockReplication, preferredBlockSize);\n+        modificationTime, blocks, blockReplication, preferredBlockSize, false);\n     file.toUnderConstruction(clientName, clientMachine);\n     return file;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n        : fsNamesys.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n  \n    int numBlocks \u003d in.readInt();\n    BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n    Block blk \u003d new Block();\n    int i \u003d 0;\n    for (; i \u003c numBlocks-1; i++) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfo(blk, blockReplication);\n    }\n    // last block is UNDER_CONSTRUCTION\n    if(numBlocks \u003e 0) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoUnderConstruction(\n        blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n    }\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    // Images in the pre-protobuf format will not have the lazyPersist flag,\n    // so it is safe to pass false always.\n    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n        modificationTime, blocks, blockReplication, preferredBlockSize, false);\n    file.toUnderConstruction(clientName, clientMachine);\n    return file;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
      "extendedDetails": {}
    },
    "1e89eba47d0f291b33fc26f9406231fc70b63a87": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6583. Remove clientNode in FileUnderConstructionFeature. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1604541 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/06/14 12:39 AM",
      "commitName": "1e89eba47d0f291b33fc26f9406231fc70b63a87",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "13/05/14 6:15 PM",
      "commitNameOld": "97f58955a6045b373ab73653bf26ab5922b00cf3",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 39.27,
      "commitsBetweenForRepo": 231,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,39 @@\n   static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d NameNodeLayoutVersion.supports(\n         LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n         : fsNamesys.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n   \n     int numBlocks \u003d in.readInt();\n     BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n     Block blk \u003d new Block();\n     int i \u003d 0;\n     for (; i \u003c numBlocks-1; i++) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfo(blk, blockReplication);\n     }\n     // last block is UNDER_CONSTRUCTION\n     if(numBlocks \u003e 0) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfoUnderConstruction(\n         blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n     }\n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n     INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n         modificationTime, blocks, blockReplication, preferredBlockSize);\n-    file.toUnderConstruction(clientName, clientMachine, null);\n+    file.toUnderConstruction(clientName, clientMachine);\n     return file;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n        : fsNamesys.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n  \n    int numBlocks \u003d in.readInt();\n    BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n    Block blk \u003d new Block();\n    int i \u003d 0;\n    for (; i \u003c numBlocks-1; i++) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfo(blk, blockReplication);\n    }\n    // last block is UNDER_CONSTRUCTION\n    if(numBlocks \u003e 0) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoUnderConstruction(\n        blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n    }\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n        modificationTime, blocks, blockReplication, preferredBlockSize);\n    file.toUnderConstruction(clientName, clientMachine);\n    return file;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
      "extendedDetails": {}
    },
    "00067895a01c66d53715b50bbcb3605efd6425f2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5754. Split LayoutVerion into NameNodeLayoutVersion and DataNodeLayoutVersion. Contributed by Brandon Li\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1563041 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/01/14 7:21 PM",
      "commitName": "00067895a01c66d53715b50bbcb3605efd6425f2",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "20/12/13 3:27 PM",
      "commitNameOld": "b9ae3087c0f83bfeeea47ded8e19932b46fd2350",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 41.16,
      "commitsBetweenForRepo": 163,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,39 @@\n   static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n-    long inodeId \u003d LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion) ? in\n-        .readLong() : fsNamesys.allocateNewInodeId();\n+    long inodeId \u003d NameNodeLayoutVersion.supports(\n+        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n+        : fsNamesys.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n   \n     int numBlocks \u003d in.readInt();\n     BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n     Block blk \u003d new Block();\n     int i \u003d 0;\n     for (; i \u003c numBlocks-1; i++) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfo(blk, blockReplication);\n     }\n     // last block is UNDER_CONSTRUCTION\n     if(numBlocks \u003e 0) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfoUnderConstruction(\n         blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n     }\n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n     INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n         modificationTime, blocks, blockReplication, preferredBlockSize);\n     file.toUnderConstruction(clientName, clientMachine, null);\n     return file;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d NameNodeLayoutVersion.supports(\n        LayoutVersion.Feature.ADD_INODE_ID, imgVersion) ? in.readLong()\n        : fsNamesys.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n  \n    int numBlocks \u003d in.readInt();\n    BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n    Block blk \u003d new Block();\n    int i \u003d 0;\n    for (; i \u003c numBlocks-1; i++) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfo(blk, blockReplication);\n    }\n    // last block is UNDER_CONSTRUCTION\n    if(numBlocks \u003e 0) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoUnderConstruction(\n        blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n    }\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n        modificationTime, blocks, blockReplication, preferredBlockSize);\n    file.toUnderConstruction(clientName, clientMachine, null);\n    return file;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
      "extendedDetails": {}
    },
    "ce68f410b05a58ad05965f32ad7f5b246b363a75": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-5285. Flatten INodeFile hierarchy: Replace INodeFileUnderConstruction and INodeFileUnderConstructionWithSnapshot with FileUnderContructionFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544389 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/11/13 5:39 PM",
      "commitName": "ce68f410b05a58ad05965f32ad7f5b246b363a75",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-5285. Flatten INodeFile hierarchy: Replace INodeFileUnderConstruction and INodeFileUnderConstructionWithSnapshot with FileUnderContructionFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544389 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/11/13 5:39 PM",
          "commitName": "ce68f410b05a58ad05965f32ad7f5b246b363a75",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "20/11/13 7:17 PM",
          "commitNameOld": "5f458ef23f097c784f12a973b326f7e1254ae0b2",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 0.93,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,38 @@\n-  static INodeFileUnderConstruction readINodeUnderConstruction(\n+  static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion) ? in\n         .readLong() : fsNamesys.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n   \n     int numBlocks \u003d in.readInt();\n     BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n     Block blk \u003d new Block();\n     int i \u003d 0;\n     for (; i \u003c numBlocks-1; i++) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfo(blk, blockReplication);\n     }\n     // last block is UNDER_CONSTRUCTION\n     if(numBlocks \u003e 0) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfoUnderConstruction(\n         blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n     }\n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n-    return new INodeFileUnderConstruction(inodeId,\n-                                          name,\n-                                          blockReplication, \n-                                          modificationTime,\n-                                          preferredBlockSize,\n-                                          blocks,\n-                                          perm,\n-                                          clientName,\n-                                          clientMachine,\n-                                          null);\n+    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n+        modificationTime, blocks, blockReplication, preferredBlockSize);\n+    file.toUnderConstruction(clientName, clientMachine, null);\n+    return file;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion) ? in\n        .readLong() : fsNamesys.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n  \n    int numBlocks \u003d in.readInt();\n    BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n    Block blk \u003d new Block();\n    int i \u003d 0;\n    for (; i \u003c numBlocks-1; i++) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfo(blk, blockReplication);\n    }\n    // last block is UNDER_CONSTRUCTION\n    if(numBlocks \u003e 0) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoUnderConstruction(\n        blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n    }\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n        modificationTime, blocks, blockReplication, preferredBlockSize);\n    file.toUnderConstruction(clientName, clientMachine, null);\n    return file;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
          "extendedDetails": {
            "oldValue": "INodeFileUnderConstruction",
            "newValue": "INodeFile"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5285. Flatten INodeFile hierarchy: Replace INodeFileUnderConstruction and INodeFileUnderConstructionWithSnapshot with FileUnderContructionFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544389 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/11/13 5:39 PM",
          "commitName": "ce68f410b05a58ad05965f32ad7f5b246b363a75",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "20/11/13 7:17 PM",
          "commitNameOld": "5f458ef23f097c784f12a973b326f7e1254ae0b2",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 0.93,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,38 @@\n-  static INodeFileUnderConstruction readINodeUnderConstruction(\n+  static INodeFile readINodeUnderConstruction(\n       DataInput in, FSNamesystem fsNamesys, int imgVersion)\n       throws IOException {\n     byte[] name \u003d readBytes(in);\n     long inodeId \u003d LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion) ? in\n         .readLong() : fsNamesys.allocateNewInodeId();\n     short blockReplication \u003d in.readShort();\n     long modificationTime \u003d in.readLong();\n     long preferredBlockSize \u003d in.readLong();\n   \n     int numBlocks \u003d in.readInt();\n     BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n     Block blk \u003d new Block();\n     int i \u003d 0;\n     for (; i \u003c numBlocks-1; i++) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfo(blk, blockReplication);\n     }\n     // last block is UNDER_CONSTRUCTION\n     if(numBlocks \u003e 0) {\n       blk.readFields(in);\n       blocks[i] \u003d new BlockInfoUnderConstruction(\n         blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n     }\n     PermissionStatus perm \u003d PermissionStatus.read(in);\n     String clientName \u003d readString(in);\n     String clientMachine \u003d readString(in);\n \n     // We previously stored locations for the last block, now we\n     // just record that there are none\n     int numLocs \u003d in.readInt();\n     assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n \n-    return new INodeFileUnderConstruction(inodeId,\n-                                          name,\n-                                          blockReplication, \n-                                          modificationTime,\n-                                          preferredBlockSize,\n-                                          blocks,\n-                                          perm,\n-                                          clientName,\n-                                          clientMachine,\n-                                          null);\n+    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n+        modificationTime, blocks, blockReplication, preferredBlockSize);\n+    file.toUnderConstruction(clientName, clientMachine, null);\n+    return file;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static INodeFile readINodeUnderConstruction(\n      DataInput in, FSNamesystem fsNamesys, int imgVersion)\n      throws IOException {\n    byte[] name \u003d readBytes(in);\n    long inodeId \u003d LayoutVersion.supports(Feature.ADD_INODE_ID, imgVersion) ? in\n        .readLong() : fsNamesys.allocateNewInodeId();\n    short blockReplication \u003d in.readShort();\n    long modificationTime \u003d in.readLong();\n    long preferredBlockSize \u003d in.readLong();\n  \n    int numBlocks \u003d in.readInt();\n    BlockInfo[] blocks \u003d new BlockInfo[numBlocks];\n    Block blk \u003d new Block();\n    int i \u003d 0;\n    for (; i \u003c numBlocks-1; i++) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfo(blk, blockReplication);\n    }\n    // last block is UNDER_CONSTRUCTION\n    if(numBlocks \u003e 0) {\n      blk.readFields(in);\n      blocks[i] \u003d new BlockInfoUnderConstruction(\n        blk, blockReplication, BlockUCState.UNDER_CONSTRUCTION, null);\n    }\n    PermissionStatus perm \u003d PermissionStatus.read(in);\n    String clientName \u003d readString(in);\n    String clientMachine \u003d readString(in);\n\n    // We previously stored locations for the last block, now we\n    // just record that there are none\n    int numLocs \u003d in.readInt();\n    assert numLocs \u003d\u003d 0 : \"Unexpected block locations\";\n\n    INodeFile file \u003d new INodeFile(inodeId, name, perm, modificationTime,\n        modificationTime, blocks, blockReplication, preferredBlockSize);\n    file.toUnderConstruction(clientName, clientMachine, null);\n    return file;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}