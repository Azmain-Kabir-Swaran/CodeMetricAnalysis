{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DecommissioningNodesWatcher.java",
  "functionName": "run",
  "functionId": "run",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/DecommissioningNodesWatcher.java",
  "functionStartLine": 271,
  "functionEndLine": 319,
  "numCommitsSeen": 7,
  "timeTaken": 1797,
  "changeHistory": [
    "2064ca015d1584263aac0cc20c60b925a3aff612",
    "0da69c324dee9baab0f0b9700db1cc5b623f8421"
  ],
  "changeHistoryShort": {
    "2064ca015d1584263aac0cc20c60b925a3aff612": "Ybodychange",
    "0da69c324dee9baab0f0b9700db1cc5b623f8421": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2064ca015d1584263aac0cc20c60b925a3aff612": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9349.  Changed logging to use slf4j api.\n            Contributed by Prabhu Joseph\n",
      "commitDate": "15/03/19 4:20 PM",
      "commitName": "2064ca015d1584263aac0cc20c60b925a3aff612",
      "commitAuthor": "Eric Yang",
      "commitDateOld": "04/03/19 9:10 PM",
      "commitNameOld": "e40e2d6ad5cbe782c3a067229270738b501ed27e",
      "commitAuthorOld": "Prabhu Joseph",
      "daysBetweenCommits": 10.76,
      "commitsBetweenForRepo": 108,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,49 @@\n     public void run() {\n       logDecommissioningNodesStatus();\n       long now \u003d mclock.getTime();\n       Set\u003cNodeId\u003e staleNodes \u003d new HashSet\u003cNodeId\u003e();\n \n       for (Iterator\u003cMap.Entry\u003cNodeId, DecommissioningNodeContext\u003e\u003e it \u003d\n           decomNodes.entrySet().iterator(); it.hasNext();) {\n         Map.Entry\u003cNodeId, DecommissioningNodeContext\u003e e \u003d it.next();\n         DecommissioningNodeContext d \u003d e.getValue();\n         // Skip node recently updated (NM usually updates every second).\n         if (now - d.lastUpdateTime \u003c 5000L) {\n           continue;\n         }\n         // Remove stale non-DECOMMISSIONING node\n         if (d.nodeState !\u003d NodeState.DECOMMISSIONING) {\n-          LOG.debug(\"remove \" + d.nodeState + \" \" + d.nodeId);\n+          LOG.debug(\"remove {} {}\", d.nodeState, d.nodeId);\n           it.remove();\n           continue;\n         } else if (now - d.lastUpdateTime \u003e 60000L) {\n           // Node DECOMMISSIONED could become stale, remove as necessary.\n           RMNode rmNode \u003d getRmNode(d.nodeId);\n           if (rmNode !\u003d null \u0026\u0026\n               rmNode.getState() \u003d\u003d NodeState.DECOMMISSIONED) {\n-            LOG.debug(\"remove \" + rmNode.getState() + \" \" + d.nodeId);\n+            LOG.debug(\"remove {} {}\", rmNode.getState(), d.nodeId);\n             it.remove();\n             continue;\n           }\n         }\n         if (d.timeoutMs \u003e\u003d 0 \u0026\u0026\n             d.decommissioningStartTime + d.timeoutMs \u003c now) {\n           staleNodes.add(d.nodeId);\n-          LOG.debug(\"Identified stale and timeout node \" + d.nodeId);\n+          LOG.debug(\"Identified stale and timeout node {}\", d.nodeId);\n         }\n       }\n \n       for (NodeId nodeId : staleNodes) {\n         RMNode rmNode \u003d this.rmContext.getRMNodes().get(nodeId);\n         if (rmNode \u003d\u003d null || rmNode.getState() !\u003d NodeState.DECOMMISSIONING) {\n           remove(nodeId);\n           continue;\n         }\n         if (rmNode.getState() \u003d\u003d NodeState.DECOMMISSIONING \u0026\u0026\n             checkReadyToBeDecommissioned(rmNode.getNodeID())) {\n           LOG.info(\"DECOMMISSIONING \" + nodeId + \" timeout\");\n           this.rmContext.getDispatcher().getEventHandler().handle(\n               new RMNodeEvent(nodeId, RMNodeEventType.DECOMMISSION));\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      logDecommissioningNodesStatus();\n      long now \u003d mclock.getTime();\n      Set\u003cNodeId\u003e staleNodes \u003d new HashSet\u003cNodeId\u003e();\n\n      for (Iterator\u003cMap.Entry\u003cNodeId, DecommissioningNodeContext\u003e\u003e it \u003d\n          decomNodes.entrySet().iterator(); it.hasNext();) {\n        Map.Entry\u003cNodeId, DecommissioningNodeContext\u003e e \u003d it.next();\n        DecommissioningNodeContext d \u003d e.getValue();\n        // Skip node recently updated (NM usually updates every second).\n        if (now - d.lastUpdateTime \u003c 5000L) {\n          continue;\n        }\n        // Remove stale non-DECOMMISSIONING node\n        if (d.nodeState !\u003d NodeState.DECOMMISSIONING) {\n          LOG.debug(\"remove {} {}\", d.nodeState, d.nodeId);\n          it.remove();\n          continue;\n        } else if (now - d.lastUpdateTime \u003e 60000L) {\n          // Node DECOMMISSIONED could become stale, remove as necessary.\n          RMNode rmNode \u003d getRmNode(d.nodeId);\n          if (rmNode !\u003d null \u0026\u0026\n              rmNode.getState() \u003d\u003d NodeState.DECOMMISSIONED) {\n            LOG.debug(\"remove {} {}\", rmNode.getState(), d.nodeId);\n            it.remove();\n            continue;\n          }\n        }\n        if (d.timeoutMs \u003e\u003d 0 \u0026\u0026\n            d.decommissioningStartTime + d.timeoutMs \u003c now) {\n          staleNodes.add(d.nodeId);\n          LOG.debug(\"Identified stale and timeout node {}\", d.nodeId);\n        }\n      }\n\n      for (NodeId nodeId : staleNodes) {\n        RMNode rmNode \u003d this.rmContext.getRMNodes().get(nodeId);\n        if (rmNode \u003d\u003d null || rmNode.getState() !\u003d NodeState.DECOMMISSIONING) {\n          remove(nodeId);\n          continue;\n        }\n        if (rmNode.getState() \u003d\u003d NodeState.DECOMMISSIONING \u0026\u0026\n            checkReadyToBeDecommissioned(rmNode.getNodeID())) {\n          LOG.info(\"DECOMMISSIONING \" + nodeId + \" timeout\");\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMNodeEvent(nodeId, RMNodeEventType.DECOMMISSION));\n        }\n      }\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/DecommissioningNodesWatcher.java",
      "extendedDetails": {}
    },
    "0da69c324dee9baab0f0b9700db1cc5b623f8421": {
      "type": "Yintroduced",
      "commitMessage": "YARN-4676. Automatic and Asynchronous Decommissioning Nodes Status Tracking. Contributed by Diniel Zhi.\n(cherry picked from commit d464483bf7f0b3e3be3ba32cd6c3eee546747ab5)\n\nConflicts:\n\n\thadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ResourceTrackerService.java\n\thadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmnode/RMNode.java\n\thadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmnode/RMNodeImpl.java\n",
      "commitDate": "18/08/16 7:27 AM",
      "commitName": "0da69c324dee9baab0f0b9700db1cc5b623f8421",
      "commitAuthor": "Junping Du",
      "diff": "@@ -0,0 +1,49 @@\n+    public void run() {\n+      logDecommissioningNodesStatus();\n+      long now \u003d mclock.getTime();\n+      Set\u003cNodeId\u003e staleNodes \u003d new HashSet\u003cNodeId\u003e();\n+\n+      for (Iterator\u003cMap.Entry\u003cNodeId, DecommissioningNodeContext\u003e\u003e it \u003d\n+          decomNodes.entrySet().iterator(); it.hasNext();) {\n+        Map.Entry\u003cNodeId, DecommissioningNodeContext\u003e e \u003d it.next();\n+        DecommissioningNodeContext d \u003d e.getValue();\n+        // Skip node recently updated (NM usually updates every second).\n+        if (now - d.lastUpdateTime \u003c 5000L) {\n+          continue;\n+        }\n+        // Remove stale non-DECOMMISSIONING node\n+        if (d.nodeState !\u003d NodeState.DECOMMISSIONING) {\n+          LOG.debug(\"remove \" + d.nodeState + \" \" + d.nodeId);\n+          it.remove();\n+          continue;\n+        } else if (now - d.lastUpdateTime \u003e 60000L) {\n+          // Node DECOMMISSIONED could become stale, remove as necessary.\n+          RMNode rmNode \u003d getRmNode(d.nodeId);\n+          if (rmNode !\u003d null \u0026\u0026\n+              rmNode.getState() \u003d\u003d NodeState.DECOMMISSIONED) {\n+            LOG.debug(\"remove \" + rmNode.getState() + \" \" + d.nodeId);\n+            it.remove();\n+            continue;\n+          }\n+        }\n+        if (d.timeoutMs \u003e\u003d 0 \u0026\u0026\n+            d.decommissioningStartTime + d.timeoutMs \u003c now) {\n+          staleNodes.add(d.nodeId);\n+          LOG.debug(\"Identified stale and timeout node \" + d.nodeId);\n+        }\n+      }\n+\n+      for (NodeId nodeId : staleNodes) {\n+        RMNode rmNode \u003d this.rmContext.getRMNodes().get(nodeId);\n+        if (rmNode \u003d\u003d null || rmNode.getState() !\u003d NodeState.DECOMMISSIONING) {\n+          remove(nodeId);\n+          continue;\n+        }\n+        if (rmNode.getState() \u003d\u003d NodeState.DECOMMISSIONING \u0026\u0026\n+            checkReadyToBeDecommissioned(rmNode.getNodeID())) {\n+          LOG.info(\"DECOMMISSIONING \" + nodeId + \" timeout\");\n+          this.rmContext.getDispatcher().getEventHandler().handle(\n+              new RMNodeEvent(nodeId, RMNodeEventType.DECOMMISSION));\n+        }\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      logDecommissioningNodesStatus();\n      long now \u003d mclock.getTime();\n      Set\u003cNodeId\u003e staleNodes \u003d new HashSet\u003cNodeId\u003e();\n\n      for (Iterator\u003cMap.Entry\u003cNodeId, DecommissioningNodeContext\u003e\u003e it \u003d\n          decomNodes.entrySet().iterator(); it.hasNext();) {\n        Map.Entry\u003cNodeId, DecommissioningNodeContext\u003e e \u003d it.next();\n        DecommissioningNodeContext d \u003d e.getValue();\n        // Skip node recently updated (NM usually updates every second).\n        if (now - d.lastUpdateTime \u003c 5000L) {\n          continue;\n        }\n        // Remove stale non-DECOMMISSIONING node\n        if (d.nodeState !\u003d NodeState.DECOMMISSIONING) {\n          LOG.debug(\"remove \" + d.nodeState + \" \" + d.nodeId);\n          it.remove();\n          continue;\n        } else if (now - d.lastUpdateTime \u003e 60000L) {\n          // Node DECOMMISSIONED could become stale, remove as necessary.\n          RMNode rmNode \u003d getRmNode(d.nodeId);\n          if (rmNode !\u003d null \u0026\u0026\n              rmNode.getState() \u003d\u003d NodeState.DECOMMISSIONED) {\n            LOG.debug(\"remove \" + rmNode.getState() + \" \" + d.nodeId);\n            it.remove();\n            continue;\n          }\n        }\n        if (d.timeoutMs \u003e\u003d 0 \u0026\u0026\n            d.decommissioningStartTime + d.timeoutMs \u003c now) {\n          staleNodes.add(d.nodeId);\n          LOG.debug(\"Identified stale and timeout node \" + d.nodeId);\n        }\n      }\n\n      for (NodeId nodeId : staleNodes) {\n        RMNode rmNode \u003d this.rmContext.getRMNodes().get(nodeId);\n        if (rmNode \u003d\u003d null || rmNode.getState() !\u003d NodeState.DECOMMISSIONING) {\n          remove(nodeId);\n          continue;\n        }\n        if (rmNode.getState() \u003d\u003d NodeState.DECOMMISSIONING \u0026\u0026\n            checkReadyToBeDecommissioned(rmNode.getNodeID())) {\n          LOG.info(\"DECOMMISSIONING \" + nodeId + \" timeout\");\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMNodeEvent(nodeId, RMNodeEventType.DECOMMISSION));\n        }\n      }\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/DecommissioningNodesWatcher.java"
    }
  }
}