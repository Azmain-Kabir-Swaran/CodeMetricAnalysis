{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ShortCircuitCache.java",
  "functionName": "run",
  "functionId": "run",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java",
  "functionStartLine": 184,
  "functionEndLine": 246,
  "numCommitsSeen": 35,
  "timeTaken": 5303,
  "changeHistory": [
    "be374faf429d28561dd9c582f5c55451213d89a4",
    "28a848412c8239dfc6bd3e42dbbfe711e19bc8eb",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8",
    "6ee0539ede78b640f01c5eac18ded161182a7835",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
    "c992bcf9c136d3df686655a80e636bb7bb0664da",
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
    "f93d99990a9a02ce693cd74466c2e5f127c1f560",
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f",
    "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
    "9fdb11747628f2fd010bcda4398043eb4eb380ce",
    "9a4030e0e84a688c12daa21fe9a165808c3eca70"
  ],
  "changeHistoryShort": {
    "be374faf429d28561dd9c582f5c55451213d89a4": "Ybodychange",
    "28a848412c8239dfc6bd3e42dbbfe711e19bc8eb": "Ybodychange",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": "Ybodychange",
    "6ee0539ede78b640f01c5eac18ded161182a7835": "Ybodychange",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": "Ybodychange",
    "c992bcf9c136d3df686655a80e636bb7bb0664da": "Ymultichange(Yfilerename,Ybodychange)",
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": "Ybodychange",
    "f93d99990a9a02ce693cd74466c2e5f127c1f560": "Yfilerename",
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f": "Ybodychange",
    "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be": "Ymultichange(Ymovefromfile,Ybodychange)",
    "9fdb11747628f2fd010bcda4398043eb4eb380ce": "Ybodychange",
    "9a4030e0e84a688c12daa21fe9a165808c3eca70": "Yintroduced"
  },
  "changeHistoryDetails": {
    "be374faf429d28561dd9c582f5c55451213d89a4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13639. SlotReleaser is not fast enough (#1885)\n\n",
      "commitDate": "21/05/20 1:21 PM",
      "commitName": "be374faf429d28561dd9c582f5c55451213d89a4",
      "commitAuthor": "leosunli",
      "commitDateOld": "12/02/20 6:59 AM",
      "commitNameOld": "f09710bbb8e56d066f9d7a2e70a41ed82d5aa781",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 99.22,
      "commitsBetweenForRepo": 343,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,63 @@\n     public void run() {\n+      if (slot \u003d\u003d null) {\n+        return;\n+      }\n       LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n       final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n       final String path \u003d shmSock.getPath();\n+      DataOutputStream out \u003d null;\n       boolean success \u003d false;\n-      try (DomainSocket sock \u003d DomainSocket.connect(path);\n-           DataOutputStream out \u003d new DataOutputStream(\n-               new BufferedOutputStream(sock.getOutputStream()))) {\n-        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n-        DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n-        ReleaseShortCircuitAccessResponseProto resp \u003d\n-            ReleaseShortCircuitAccessResponseProto.parseFrom(\n-                PBHelperClient.vintPrefixed(in));\n-        if (resp.getStatus() !\u003d Status.SUCCESS) {\n-          String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n-          throw new IOException(resp.getStatus().toString() + \": \" + error);\n+      int retries \u003d 2;\n+      try {\n+        while (retries \u003e 0) {\n+          try {\n+            if (domainSocket \u003d\u003d null || !domainSocket.isOpen()) {\n+              // we are running in single thread mode, no protection needed for\n+              // domainSocket\n+              domainSocket \u003d DomainSocket.connect(path);\n+            }\n+\n+            out \u003d new DataOutputStream(\n+                new BufferedOutputStream(domainSocket.getOutputStream()));\n+            new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n+            DataInputStream in \u003d\n+                new DataInputStream(domainSocket.getInputStream());\n+            ReleaseShortCircuitAccessResponseProto resp \u003d\n+                ReleaseShortCircuitAccessResponseProto\n+                    .parseFrom(PBHelperClient.vintPrefixed(in));\n+            if (resp.getStatus() !\u003d Status.SUCCESS) {\n+              String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n+              throw new IOException(resp.getStatus().toString() + \": \" + error);\n+            }\n+\n+            LOG.trace(\"{}: released {}\", this, slot);\n+            success \u003d true;\n+            break;\n+\n+          } catch (SocketException se) {\n+            // the domain socket on datanode may be timed out, we retry once\n+            retries--;\n+            domainSocket.close();\n+            domainSocket \u003d null;\n+            if (retries \u003d\u003d 0) {\n+              throw new SocketException(\"Create domain socket failed\");\n+            }\n+          }\n         }\n-        LOG.trace(\"{}: released {}\", this, slot);\n-        success \u003d true;\n       } catch (IOException e) {\n         LOG.warn(ShortCircuitCache.this + \": failed to release \"\n             + \"short-circuit shared memory slot \" + slot + \" by sending \"\n             + \"ReleaseShortCircuitAccessRequestProto to \" + path\n             + \".  Closing shared memory segment. \"\n             + \"DataNode may have been stopped or restarted\", e);\n       } finally {\n         if (success) {\n           shmManager.freeSlot(slot);\n         } else {\n           shm.getEndpointShmManager().shutdown(shm);\n+          IOUtilsClient.cleanupWithLogger(LOG, domainSocket, out);\n+          domainSocket \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      if (slot \u003d\u003d null) {\n        return;\n      }\n      LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n      final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n      final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n      final String path \u003d shmSock.getPath();\n      DataOutputStream out \u003d null;\n      boolean success \u003d false;\n      int retries \u003d 2;\n      try {\n        while (retries \u003e 0) {\n          try {\n            if (domainSocket \u003d\u003d null || !domainSocket.isOpen()) {\n              // we are running in single thread mode, no protection needed for\n              // domainSocket\n              domainSocket \u003d DomainSocket.connect(path);\n            }\n\n            out \u003d new DataOutputStream(\n                new BufferedOutputStream(domainSocket.getOutputStream()));\n            new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n            DataInputStream in \u003d\n                new DataInputStream(domainSocket.getInputStream());\n            ReleaseShortCircuitAccessResponseProto resp \u003d\n                ReleaseShortCircuitAccessResponseProto\n                    .parseFrom(PBHelperClient.vintPrefixed(in));\n            if (resp.getStatus() !\u003d Status.SUCCESS) {\n              String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n              throw new IOException(resp.getStatus().toString() + \": \" + error);\n            }\n\n            LOG.trace(\"{}: released {}\", this, slot);\n            success \u003d true;\n            break;\n\n          } catch (SocketException se) {\n            // the domain socket on datanode may be timed out, we retry once\n            retries--;\n            domainSocket.close();\n            domainSocket \u003d null;\n            if (retries \u003d\u003d 0) {\n              throw new SocketException(\"Create domain socket failed\");\n            }\n          }\n        }\n      } catch (IOException e) {\n        LOG.warn(ShortCircuitCache.this + \": failed to release \"\n            + \"short-circuit shared memory slot \" + slot + \" by sending \"\n            + \"ReleaseShortCircuitAccessRequestProto to \" + path\n            + \".  Closing shared memory segment. \"\n            + \"DataNode may have been stopped or restarted\", e);\n      } finally {\n        if (success) {\n          shmManager.freeSlot(slot);\n        } else {\n          shm.getEndpointShmManager().shutdown(shm);\n          IOUtilsClient.cleanupWithLogger(LOG, domainSocket, out);\n          domainSocket \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java",
      "extendedDetails": {}
    },
    "28a848412c8239dfc6bd3e42dbbfe711e19bc8eb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14701. Change Log Level to warn in SlotReleaser. Contributed by Lisheng Sun.\n",
      "commitDate": "08/08/19 1:46 PM",
      "commitName": "28a848412c8239dfc6bd3e42dbbfe711e19bc8eb",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "24/06/19 5:44 PM",
      "commitNameOld": "38a560c6f1651138b0344aaf059039b2447a4fff",
      "commitAuthorOld": "",
      "daysBetweenCommits": 44.83,
      "commitsBetweenForRepo": 314,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,34 @@\n     public void run() {\n       LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n       final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n       final String path \u003d shmSock.getPath();\n       boolean success \u003d false;\n       try (DomainSocket sock \u003d DomainSocket.connect(path);\n            DataOutputStream out \u003d new DataOutputStream(\n                new BufferedOutputStream(sock.getOutputStream()))) {\n         new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n         DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n         ReleaseShortCircuitAccessResponseProto resp \u003d\n             ReleaseShortCircuitAccessResponseProto.parseFrom(\n                 PBHelperClient.vintPrefixed(in));\n         if (resp.getStatus() !\u003d Status.SUCCESS) {\n           String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n           throw new IOException(resp.getStatus().toString() + \": \" + error);\n         }\n         LOG.trace(\"{}: released {}\", this, slot);\n         success \u003d true;\n       } catch (IOException e) {\n-        LOG.error(ShortCircuitCache.this + \": failed to release \" +\n-            \"short-circuit shared memory slot \" + slot + \" by sending \" +\n-            \"ReleaseShortCircuitAccessRequestProto to \" + path +\n-            \".  Closing shared memory segment.\", e);\n+        LOG.warn(ShortCircuitCache.this + \": failed to release \"\n+            + \"short-circuit shared memory slot \" + slot + \" by sending \"\n+            + \"ReleaseShortCircuitAccessRequestProto to \" + path\n+            + \".  Closing shared memory segment. \"\n+            + \"DataNode may have been stopped or restarted\", e);\n       } finally {\n         if (success) {\n           shmManager.freeSlot(slot);\n         } else {\n           shm.getEndpointShmManager().shutdown(shm);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n      final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n      final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n      final String path \u003d shmSock.getPath();\n      boolean success \u003d false;\n      try (DomainSocket sock \u003d DomainSocket.connect(path);\n           DataOutputStream out \u003d new DataOutputStream(\n               new BufferedOutputStream(sock.getOutputStream()))) {\n        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n        DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n        ReleaseShortCircuitAccessResponseProto resp \u003d\n            ReleaseShortCircuitAccessResponseProto.parseFrom(\n                PBHelperClient.vintPrefixed(in));\n        if (resp.getStatus() !\u003d Status.SUCCESS) {\n          String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n          throw new IOException(resp.getStatus().toString() + \": \" + error);\n        }\n        LOG.trace(\"{}: released {}\", this, slot);\n        success \u003d true;\n      } catch (IOException e) {\n        LOG.warn(ShortCircuitCache.this + \": failed to release \"\n            + \"short-circuit shared memory slot \" + slot + \" by sending \"\n            + \"ReleaseShortCircuitAccessRequestProto to \" + path\n            + \".  Closing shared memory segment. \"\n            + \"DataNode may have been stopped or restarted\", e);\n      } finally {\n        if (success) {\n          shmManager.freeSlot(slot);\n        } else {\n          shm.getEndpointShmManager().shutdown(shm);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java",
      "extendedDetails": {}
    },
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8971. Remove guards when calling LOG.debug() and LOG.trace() in client package. Contributed by Mingliang Liu.\n",
      "commitDate": "29/09/15 5:52 PM",
      "commitName": "39285e6a1978ea5e53bdc1b0aef62421382124a8",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:51 PM",
      "commitNameOld": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,33 @@\n     public void run() {\n-      if (LOG.isTraceEnabled()) {\n-        LOG.trace(ShortCircuitCache.this + \": about to release \" + slot);\n-      }\n+      LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n       final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n       final String path \u003d shmSock.getPath();\n       boolean success \u003d false;\n       try (DomainSocket sock \u003d DomainSocket.connect(path);\n            DataOutputStream out \u003d new DataOutputStream(\n                new BufferedOutputStream(sock.getOutputStream()))) {\n         new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n         DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n         ReleaseShortCircuitAccessResponseProto resp \u003d\n             ReleaseShortCircuitAccessResponseProto.parseFrom(\n                 PBHelperClient.vintPrefixed(in));\n         if (resp.getStatus() !\u003d Status.SUCCESS) {\n           String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n           throw new IOException(resp.getStatus().toString() + \": \" + error);\n         }\n-        if (LOG.isTraceEnabled()) {\n-          LOG.trace(ShortCircuitCache.this + \": released \" + slot);\n-        }\n+        LOG.trace(\"{}: released {}\", this, slot);\n         success \u003d true;\n       } catch (IOException e) {\n         LOG.error(ShortCircuitCache.this + \": failed to release \" +\n             \"short-circuit shared memory slot \" + slot + \" by sending \" +\n             \"ReleaseShortCircuitAccessRequestProto to \" + path +\n             \".  Closing shared memory segment.\", e);\n       } finally {\n         if (success) {\n           shmManager.freeSlot(slot);\n         } else {\n           shm.getEndpointShmManager().shutdown(shm);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n      final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n      final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n      final String path \u003d shmSock.getPath();\n      boolean success \u003d false;\n      try (DomainSocket sock \u003d DomainSocket.connect(path);\n           DataOutputStream out \u003d new DataOutputStream(\n               new BufferedOutputStream(sock.getOutputStream()))) {\n        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n        DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n        ReleaseShortCircuitAccessResponseProto resp \u003d\n            ReleaseShortCircuitAccessResponseProto.parseFrom(\n                PBHelperClient.vintPrefixed(in));\n        if (resp.getStatus() !\u003d Status.SUCCESS) {\n          String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n          throw new IOException(resp.getStatus().toString() + \": \" + error);\n        }\n        LOG.trace(\"{}: released {}\", this, slot);\n        success \u003d true;\n      } catch (IOException e) {\n        LOG.error(ShortCircuitCache.this + \": failed to release \" +\n            \"short-circuit shared memory slot \" + slot + \" by sending \" +\n            \"ReleaseShortCircuitAccessRequestProto to \" + path +\n            \".  Closing shared memory segment.\", e);\n      } finally {\n        if (success) {\n          shmManager.freeSlot(slot);\n        } else {\n          shm.getEndpointShmManager().shutdown(shm);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java",
      "extendedDetails": {}
    },
    "6ee0539ede78b640f01c5eac18ded161182a7835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\"\n\nThis reverts commit d5a9a3daa0224249221ffa7b8bd5751ab2feca56.\n",
      "commitDate": "29/09/15 5:51 PM",
      "commitName": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:48 PM",
      "commitNameOld": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,37 @@\n     public void run() {\n-      LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n+      if (LOG.isTraceEnabled()) {\n+        LOG.trace(ShortCircuitCache.this + \": about to release \" + slot);\n+      }\n       final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n       final String path \u003d shmSock.getPath();\n       boolean success \u003d false;\n       try (DomainSocket sock \u003d DomainSocket.connect(path);\n            DataOutputStream out \u003d new DataOutputStream(\n                new BufferedOutputStream(sock.getOutputStream()))) {\n         new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n         DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n         ReleaseShortCircuitAccessResponseProto resp \u003d\n             ReleaseShortCircuitAccessResponseProto.parseFrom(\n                 PBHelperClient.vintPrefixed(in));\n         if (resp.getStatus() !\u003d Status.SUCCESS) {\n           String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n           throw new IOException(resp.getStatus().toString() + \": \" + error);\n         }\n-        LOG.trace(\"{}: released {}\", this, slot);\n+        if (LOG.isTraceEnabled()) {\n+          LOG.trace(ShortCircuitCache.this + \": released \" + slot);\n+        }\n         success \u003d true;\n       } catch (IOException e) {\n         LOG.error(ShortCircuitCache.this + \": failed to release \" +\n             \"short-circuit shared memory slot \" + slot + \" by sending \" +\n             \"ReleaseShortCircuitAccessRequestProto to \" + path +\n             \".  Closing shared memory segment.\", e);\n       } finally {\n         if (success) {\n           shmManager.freeSlot(slot);\n         } else {\n           shm.getEndpointShmManager().shutdown(shm);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(ShortCircuitCache.this + \": about to release \" + slot);\n      }\n      final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n      final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n      final String path \u003d shmSock.getPath();\n      boolean success \u003d false;\n      try (DomainSocket sock \u003d DomainSocket.connect(path);\n           DataOutputStream out \u003d new DataOutputStream(\n               new BufferedOutputStream(sock.getOutputStream()))) {\n        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n        DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n        ReleaseShortCircuitAccessResponseProto resp \u003d\n            ReleaseShortCircuitAccessResponseProto.parseFrom(\n                PBHelperClient.vintPrefixed(in));\n        if (resp.getStatus() !\u003d Status.SUCCESS) {\n          String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n          throw new IOException(resp.getStatus().toString() + \": \" + error);\n        }\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(ShortCircuitCache.this + \": released \" + slot);\n        }\n        success \u003d true;\n      } catch (IOException e) {\n        LOG.error(ShortCircuitCache.this + \": failed to release \" +\n            \"short-circuit shared memory slot \" + slot + \" by sending \" +\n            \"ReleaseShortCircuitAccessRequestProto to \" + path +\n            \".  Closing shared memory segment.\", e);\n      } finally {\n        if (success) {\n          shmManager.freeSlot(slot);\n        } else {\n          shm.getEndpointShmManager().shutdown(shm);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java",
      "extendedDetails": {}
    },
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "29/09/15 5:48 PM",
      "commitName": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/08/15 2:02 PM",
      "commitNameOld": "c992bcf9c136d3df686655a80e636bb7bb0664da",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 34.16,
      "commitsBetweenForRepo": 233,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,33 @@\n     public void run() {\n-      if (LOG.isTraceEnabled()) {\n-        LOG.trace(ShortCircuitCache.this + \": about to release \" + slot);\n-      }\n+      LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n       final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n       final String path \u003d shmSock.getPath();\n       boolean success \u003d false;\n       try (DomainSocket sock \u003d DomainSocket.connect(path);\n            DataOutputStream out \u003d new DataOutputStream(\n                new BufferedOutputStream(sock.getOutputStream()))) {\n         new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n         DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n         ReleaseShortCircuitAccessResponseProto resp \u003d\n             ReleaseShortCircuitAccessResponseProto.parseFrom(\n                 PBHelperClient.vintPrefixed(in));\n         if (resp.getStatus() !\u003d Status.SUCCESS) {\n           String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n           throw new IOException(resp.getStatus().toString() + \": \" + error);\n         }\n-        if (LOG.isTraceEnabled()) {\n-          LOG.trace(ShortCircuitCache.this + \": released \" + slot);\n-        }\n+        LOG.trace(\"{}: released {}\", this, slot);\n         success \u003d true;\n       } catch (IOException e) {\n         LOG.error(ShortCircuitCache.this + \": failed to release \" +\n             \"short-circuit shared memory slot \" + slot + \" by sending \" +\n             \"ReleaseShortCircuitAccessRequestProto to \" + path +\n             \".  Closing shared memory segment.\", e);\n       } finally {\n         if (success) {\n           shmManager.freeSlot(slot);\n         } else {\n           shm.getEndpointShmManager().shutdown(shm);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n      final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n      final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n      final String path \u003d shmSock.getPath();\n      boolean success \u003d false;\n      try (DomainSocket sock \u003d DomainSocket.connect(path);\n           DataOutputStream out \u003d new DataOutputStream(\n               new BufferedOutputStream(sock.getOutputStream()))) {\n        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n        DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n        ReleaseShortCircuitAccessResponseProto resp \u003d\n            ReleaseShortCircuitAccessResponseProto.parseFrom(\n                PBHelperClient.vintPrefixed(in));\n        if (resp.getStatus() !\u003d Status.SUCCESS) {\n          String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n          throw new IOException(resp.getStatus().toString() + \": \" + error);\n        }\n        LOG.trace(\"{}: released {}\", this, slot);\n        success \u003d true;\n      } catch (IOException e) {\n        LOG.error(ShortCircuitCache.this + \": failed to release \" +\n            \"short-circuit shared memory slot \" + slot + \" by sending \" +\n            \"ReleaseShortCircuitAccessRequestProto to \" + path +\n            \".  Closing shared memory segment.\", e);\n      } finally {\n        if (success) {\n          shmManager.freeSlot(slot);\n        } else {\n          shm.getEndpointShmManager().shutdown(shm);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java",
      "extendedDetails": {}
    },
    "c992bcf9c136d3df686655a80e636bb7bb0664da": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "HDFS-8951. Move the shortcircuit package to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/08/15 2:02 PM",
      "commitName": "c992bcf9c136d3df686655a80e636bb7bb0664da",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "HDFS-8951. Move the shortcircuit package to hdfs-client. Contributed by Mingliang Liu.\n",
          "commitDate": "26/08/15 2:02 PM",
          "commitName": "c992bcf9c136d3df686655a80e636bb7bb0664da",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "25/08/15 2:29 PM",
          "commitNameOld": "a4d9acc51d1a977bc333da17780c00c72e8546f1",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 0.98,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,37 @@\n     public void run() {\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(ShortCircuitCache.this + \": about to release \" + slot);\n       }\n       final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n-      DomainSocket sock \u003d null;\n-      DataOutputStream out \u003d null;\n       final String path \u003d shmSock.getPath();\n       boolean success \u003d false;\n-      try {\n-        sock \u003d DomainSocket.connect(path);\n-        out \u003d new DataOutputStream(\n-            new BufferedOutputStream(sock.getOutputStream()));\n+      try (DomainSocket sock \u003d DomainSocket.connect(path);\n+           DataOutputStream out \u003d new DataOutputStream(\n+               new BufferedOutputStream(sock.getOutputStream()))) {\n         new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n         DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n         ReleaseShortCircuitAccessResponseProto resp \u003d\n             ReleaseShortCircuitAccessResponseProto.parseFrom(\n                 PBHelperClient.vintPrefixed(in));\n         if (resp.getStatus() !\u003d Status.SUCCESS) {\n           String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n           throw new IOException(resp.getStatus().toString() + \": \" + error);\n         }\n         if (LOG.isTraceEnabled()) {\n           LOG.trace(ShortCircuitCache.this + \": released \" + slot);\n         }\n         success \u003d true;\n       } catch (IOException e) {\n         LOG.error(ShortCircuitCache.this + \": failed to release \" +\n             \"short-circuit shared memory slot \" + slot + \" by sending \" +\n             \"ReleaseShortCircuitAccessRequestProto to \" + path +\n             \".  Closing shared memory segment.\", e);\n       } finally {\n         if (success) {\n           shmManager.freeSlot(slot);\n         } else {\n           shm.getEndpointShmManager().shutdown(shm);\n         }\n-        IOUtils.cleanup(LOG, sock, out);\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    public void run() {\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(ShortCircuitCache.this + \": about to release \" + slot);\n      }\n      final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n      final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n      final String path \u003d shmSock.getPath();\n      boolean success \u003d false;\n      try (DomainSocket sock \u003d DomainSocket.connect(path);\n           DataOutputStream out \u003d new DataOutputStream(\n               new BufferedOutputStream(sock.getOutputStream()))) {\n        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n        DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n        ReleaseShortCircuitAccessResponseProto resp \u003d\n            ReleaseShortCircuitAccessResponseProto.parseFrom(\n                PBHelperClient.vintPrefixed(in));\n        if (resp.getStatus() !\u003d Status.SUCCESS) {\n          String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n          throw new IOException(resp.getStatus().toString() + \": \" + error);\n        }\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(ShortCircuitCache.this + \": released \" + slot);\n        }\n        success \u003d true;\n      } catch (IOException e) {\n        LOG.error(ShortCircuitCache.this + \": failed to release \" +\n            \"short-circuit shared memory slot \" + slot + \" by sending \" +\n            \"ReleaseShortCircuitAccessRequestProto to \" + path +\n            \".  Closing shared memory segment.\", e);\n      } finally {\n        if (success) {\n          shmManager.freeSlot(slot);\n        } else {\n          shm.getEndpointShmManager().shutdown(shm);\n        }\n      }\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8951. Move the shortcircuit package to hdfs-client. Contributed by Mingliang Liu.\n",
          "commitDate": "26/08/15 2:02 PM",
          "commitName": "c992bcf9c136d3df686655a80e636bb7bb0664da",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "25/08/15 2:29 PM",
          "commitNameOld": "a4d9acc51d1a977bc333da17780c00c72e8546f1",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 0.98,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,37 @@\n     public void run() {\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(ShortCircuitCache.this + \": about to release \" + slot);\n       }\n       final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n-      DomainSocket sock \u003d null;\n-      DataOutputStream out \u003d null;\n       final String path \u003d shmSock.getPath();\n       boolean success \u003d false;\n-      try {\n-        sock \u003d DomainSocket.connect(path);\n-        out \u003d new DataOutputStream(\n-            new BufferedOutputStream(sock.getOutputStream()));\n+      try (DomainSocket sock \u003d DomainSocket.connect(path);\n+           DataOutputStream out \u003d new DataOutputStream(\n+               new BufferedOutputStream(sock.getOutputStream()))) {\n         new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n         DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n         ReleaseShortCircuitAccessResponseProto resp \u003d\n             ReleaseShortCircuitAccessResponseProto.parseFrom(\n                 PBHelperClient.vintPrefixed(in));\n         if (resp.getStatus() !\u003d Status.SUCCESS) {\n           String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n           throw new IOException(resp.getStatus().toString() + \": \" + error);\n         }\n         if (LOG.isTraceEnabled()) {\n           LOG.trace(ShortCircuitCache.this + \": released \" + slot);\n         }\n         success \u003d true;\n       } catch (IOException e) {\n         LOG.error(ShortCircuitCache.this + \": failed to release \" +\n             \"short-circuit shared memory slot \" + slot + \" by sending \" +\n             \"ReleaseShortCircuitAccessRequestProto to \" + path +\n             \".  Closing shared memory segment.\", e);\n       } finally {\n         if (success) {\n           shmManager.freeSlot(slot);\n         } else {\n           shm.getEndpointShmManager().shutdown(shm);\n         }\n-        IOUtils.cleanup(LOG, sock, out);\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    public void run() {\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(ShortCircuitCache.this + \": about to release \" + slot);\n      }\n      final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n      final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n      final String path \u003d shmSock.getPath();\n      boolean success \u003d false;\n      try (DomainSocket sock \u003d DomainSocket.connect(path);\n           DataOutputStream out \u003d new DataOutputStream(\n               new BufferedOutputStream(sock.getOutputStream()))) {\n        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n        DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n        ReleaseShortCircuitAccessResponseProto resp \u003d\n            ReleaseShortCircuitAccessResponseProto.parseFrom(\n                PBHelperClient.vintPrefixed(in));\n        if (resp.getStatus() !\u003d Status.SUCCESS) {\n          String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n          throw new IOException(resp.getStatus().toString() + \": \" + error);\n        }\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(ShortCircuitCache.this + \": released \" + slot);\n        }\n        success \u003d true;\n      } catch (IOException e) {\n        LOG.error(ShortCircuitCache.this + \": failed to release \" +\n            \"short-circuit shared memory slot \" + slot + \" by sending \" +\n            \"ReleaseShortCircuitAccessRequestProto to \" + path +\n            \".  Closing shared memory segment.\", e);\n      } finally {\n        if (success) {\n          shmManager.freeSlot(slot);\n        } else {\n          shm.getEndpointShmManager().shutdown(shm);\n        }\n      }\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java",
          "extendedDetails": {}
        }
      ]
    },
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8934. Move ShortCircuitShm to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "22/08/15 1:31 PM",
      "commitName": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "16/04/15 1:22 PM",
      "commitNameOld": "75bbcc8bf3fa1daf54f56868dae737f6da12ab1f",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 128.01,
      "commitsBetweenForRepo": 962,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,41 @@\n     public void run() {\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(ShortCircuitCache.this + \": about to release \" + slot);\n       }\n       final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n       DomainSocket sock \u003d null;\n       DataOutputStream out \u003d null;\n       final String path \u003d shmSock.getPath();\n       boolean success \u003d false;\n       try {\n         sock \u003d DomainSocket.connect(path);\n         out \u003d new DataOutputStream(\n             new BufferedOutputStream(sock.getOutputStream()));\n         new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n         DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n         ReleaseShortCircuitAccessResponseProto resp \u003d\n             ReleaseShortCircuitAccessResponseProto.parseFrom(\n-                PBHelper.vintPrefixed(in));\n+                PBHelperClient.vintPrefixed(in));\n         if (resp.getStatus() !\u003d Status.SUCCESS) {\n           String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n           throw new IOException(resp.getStatus().toString() + \": \" + error);\n         }\n         if (LOG.isTraceEnabled()) {\n           LOG.trace(ShortCircuitCache.this + \": released \" + slot);\n         }\n         success \u003d true;\n       } catch (IOException e) {\n         LOG.error(ShortCircuitCache.this + \": failed to release \" +\n             \"short-circuit shared memory slot \" + slot + \" by sending \" +\n             \"ReleaseShortCircuitAccessRequestProto to \" + path +\n             \".  Closing shared memory segment.\", e);\n       } finally {\n         if (success) {\n           shmManager.freeSlot(slot);\n         } else {\n           shm.getEndpointShmManager().shutdown(shm);\n         }\n         IOUtils.cleanup(LOG, sock, out);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(ShortCircuitCache.this + \": about to release \" + slot);\n      }\n      final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n      final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n      DomainSocket sock \u003d null;\n      DataOutputStream out \u003d null;\n      final String path \u003d shmSock.getPath();\n      boolean success \u003d false;\n      try {\n        sock \u003d DomainSocket.connect(path);\n        out \u003d new DataOutputStream(\n            new BufferedOutputStream(sock.getOutputStream()));\n        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n        DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n        ReleaseShortCircuitAccessResponseProto resp \u003d\n            ReleaseShortCircuitAccessResponseProto.parseFrom(\n                PBHelperClient.vintPrefixed(in));\n        if (resp.getStatus() !\u003d Status.SUCCESS) {\n          String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n          throw new IOException(resp.getStatus().toString() + \": \" + error);\n        }\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(ShortCircuitCache.this + \": released \" + slot);\n        }\n        success \u003d true;\n      } catch (IOException e) {\n        LOG.error(ShortCircuitCache.this + \": failed to release \" +\n            \"short-circuit shared memory slot \" + slot + \" by sending \" +\n            \"ReleaseShortCircuitAccessRequestProto to \" + path +\n            \".  Closing shared memory segment.\", e);\n      } finally {\n        if (success) {\n          shmManager.freeSlot(slot);\n        } else {\n          shm.getEndpointShmManager().shutdown(shm);\n        }\n        IOUtils.cleanup(LOG, sock, out);\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java",
      "extendedDetails": {}
    },
    "f93d99990a9a02ce693cd74466c2e5f127c1f560": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-6167. Relocate the non-public API classes in the hdfs.client package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1583878 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/04/14 10:09 PM",
      "commitName": "f93d99990a9a02ce693cd74466c2e5f127c1f560",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "01/04/14 6:00 PM",
      "commitNameOld": "5c7cb51775bd3d4a6e3e1bd501b3a8d747733fe3",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.17,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public void run() {\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(ShortCircuitCache.this + \": about to release \" + slot);\n      }\n      final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n      final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n      DomainSocket sock \u003d null;\n      DataOutputStream out \u003d null;\n      final String path \u003d shmSock.getPath();\n      boolean success \u003d false;\n      try {\n        sock \u003d DomainSocket.connect(path);\n        out \u003d new DataOutputStream(\n            new BufferedOutputStream(sock.getOutputStream()));\n        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n        DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n        ReleaseShortCircuitAccessResponseProto resp \u003d\n            ReleaseShortCircuitAccessResponseProto.parseFrom(\n                PBHelper.vintPrefixed(in));\n        if (resp.getStatus() !\u003d Status.SUCCESS) {\n          String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n          throw new IOException(resp.getStatus().toString() + \": \" + error);\n        }\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(ShortCircuitCache.this + \": released \" + slot);\n        }\n        success \u003d true;\n      } catch (IOException e) {\n        LOG.error(ShortCircuitCache.this + \": failed to release \" +\n            \"short-circuit shared memory slot \" + slot + \" by sending \" +\n            \"ReleaseShortCircuitAccessRequestProto to \" + path +\n            \".  Closing shared memory segment.\", e);\n      } finally {\n        if (success) {\n          shmManager.freeSlot(slot);\n        } else {\n          shm.getEndpointShmManager().shutdown(shm);\n        }\n        IOUtils.cleanup(LOG, sock, out);\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/client/ShortCircuitCache.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java"
      }
    },
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5950. The DFSClient and DataNode should use shared memory segments to communicate short-circuit information (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1573433 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/03/14 7:58 PM",
      "commitName": "dd049a2f6097da189ccce2f5890a2b9bc77fa73f",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "12/02/14 7:10 PM",
      "commitNameOld": "f0d64a078da7e932b9509734f75170e3e525e68c",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 18.03,
      "commitsBetweenForRepo": 129,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,41 @@\n     public void run() {\n-      ShortCircuitCache.this.lock.lock();\n+      if (LOG.isTraceEnabled()) {\n+        LOG.trace(ShortCircuitCache.this + \": about to release \" + slot);\n+      }\n+      final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n+      final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n+      DomainSocket sock \u003d null;\n+      DataOutputStream out \u003d null;\n+      final String path \u003d shmSock.getPath();\n+      boolean success \u003d false;\n       try {\n-        if (ShortCircuitCache.this.closed) return;\n-        long curMs \u003d Time.monotonicNow();\n-\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(this + \": cache cleaner running at \" + curMs);\n+        sock \u003d DomainSocket.connect(path);\n+        out \u003d new DataOutputStream(\n+            new BufferedOutputStream(sock.getOutputStream()));\n+        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n+        DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n+        ReleaseShortCircuitAccessResponseProto resp \u003d\n+            ReleaseShortCircuitAccessResponseProto.parseFrom(\n+                PBHelper.vintPrefixed(in));\n+        if (resp.getStatus() !\u003d Status.SUCCESS) {\n+          String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n+          throw new IOException(resp.getStatus().toString() + \": \" + error);\n         }\n-\n-        int numDemoted \u003d demoteOldEvictableMmaped(curMs);\n-        int numPurged \u003d 0;\n-        Long evictionTimeNs \u003d Long.valueOf(0);\n-        while (true) {\n-          Entry\u003cLong, ShortCircuitReplica\u003e entry \u003d \n-              evictableMmapped.ceilingEntry(evictionTimeNs);\n-          if (entry \u003d\u003d null) break;\n-          evictionTimeNs \u003d entry.getKey();\n-          long evictionTimeMs \u003d \n-              TimeUnit.MILLISECONDS.convert(evictionTimeNs, TimeUnit.NANOSECONDS);\n-          if (evictionTimeMs + maxNonMmappedEvictableLifespanMs \u003e\u003d curMs) break;\n-          ShortCircuitReplica replica \u003d entry.getValue();\n-          if (LOG.isTraceEnabled()) {\n-            LOG.trace(\"CacheCleaner: purging \" + replica + \": \" + \n-                  StringUtils.getStackTrace(Thread.currentThread()));\n-          }\n-          purge(replica);\n-          numPurged++;\n+        if (LOG.isTraceEnabled()) {\n+          LOG.trace(ShortCircuitCache.this + \": released \" + slot);\n         }\n-\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(this + \": finishing cache cleaner run started at \" +\n-            curMs + \".  Demoted \" + numDemoted + \" mmapped replicas; \" +\n-            \"purged \" + numPurged + \" replicas.\");\n-        }\n+        success \u003d true;\n+      } catch (IOException e) {\n+        LOG.error(ShortCircuitCache.this + \": failed to release \" +\n+            \"short-circuit shared memory slot \" + slot + \" by sending \" +\n+            \"ReleaseShortCircuitAccessRequestProto to \" + path +\n+            \".  Closing shared memory segment.\", e);\n       } finally {\n-        ShortCircuitCache.this.lock.unlock();\n+        if (success) {\n+          shmManager.freeSlot(slot);\n+        } else {\n+          shm.getEndpointShmManager().shutdown(shm);\n+        }\n+        IOUtils.cleanup(LOG, sock, out);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(ShortCircuitCache.this + \": about to release \" + slot);\n      }\n      final DfsClientShm shm \u003d (DfsClientShm)slot.getShm();\n      final DomainSocket shmSock \u003d shm.getPeer().getDomainSocket();\n      DomainSocket sock \u003d null;\n      DataOutputStream out \u003d null;\n      final String path \u003d shmSock.getPath();\n      boolean success \u003d false;\n      try {\n        sock \u003d DomainSocket.connect(path);\n        out \u003d new DataOutputStream(\n            new BufferedOutputStream(sock.getOutputStream()));\n        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n        DataInputStream in \u003d new DataInputStream(sock.getInputStream());\n        ReleaseShortCircuitAccessResponseProto resp \u003d\n            ReleaseShortCircuitAccessResponseProto.parseFrom(\n                PBHelper.vintPrefixed(in));\n        if (resp.getStatus() !\u003d Status.SUCCESS) {\n          String error \u003d resp.hasError() ? resp.getError() : \"(unknown)\";\n          throw new IOException(resp.getStatus().toString() + \": \" + error);\n        }\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(ShortCircuitCache.this + \": released \" + slot);\n        }\n        success \u003d true;\n      } catch (IOException e) {\n        LOG.error(ShortCircuitCache.this + \": failed to release \" +\n            \"short-circuit shared memory slot \" + slot + \" by sending \" +\n            \"ReleaseShortCircuitAccessRequestProto to \" + path +\n            \".  Closing shared memory segment.\", e);\n      } finally {\n        if (success) {\n          shmManager.freeSlot(slot);\n        } else {\n          shm.getEndpointShmManager().shutdown(shm);\n        }\n        IOUtils.cleanup(LOG, sock, out);\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/client/ShortCircuitCache.java",
      "extendedDetails": {}
    },
    "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-5810. Unify mmap cache and short-circuit file descriptor cache (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1567720 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/02/14 11:08 AM",
      "commitName": "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-5810. Unify mmap cache and short-circuit file descriptor cache (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1567720 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "12/02/14 11:08 AM",
          "commitName": "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "12/02/14 10:02 AM",
          "commitNameOld": "5efc9978ddf35f8f4e194e34a102a729dae69992",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 0.05,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,39 @@\n     public void run() {\n-      FileInputStreamCache cache \u003d cacheRef.get();\n-      if (cache \u003d\u003d null) return;\n-      synchronized(cache) {\n-        if (cache.closed) return;\n-        long curTime \u003d Time.monotonicNow();\n-        for (Iterator\u003cEntry\u003cKey, Value\u003e\u003e iter \u003d\n-                  cache.map.entries().iterator(); iter.hasNext();\n-              iter \u003d cache.map.entries().iterator()) {\n-          Entry\u003cKey, Value\u003e entry \u003d iter.next();\n-          if (entry.getValue().getTime() + cache.expiryTimeMs \u003e\u003d curTime) {\n-            break;\n-          }\n-          entry.getValue().close();\n-          iter.remove();\n+      ShortCircuitCache.this.lock.lock();\n+      try {\n+        if (ShortCircuitCache.this.closed) return;\n+        long curMs \u003d Time.monotonicNow();\n+\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(this + \": cache cleaner running at \" + curMs);\n         }\n+\n+        int numDemoted \u003d demoteOldEvictableMmaped(curMs);\n+        int numPurged \u003d 0;\n+        Long evictionTimeNs \u003d Long.valueOf(0);\n+        while (true) {\n+          Entry\u003cLong, ShortCircuitReplica\u003e entry \u003d \n+              evictableMmapped.ceilingEntry(evictionTimeNs);\n+          if (entry \u003d\u003d null) break;\n+          evictionTimeNs \u003d entry.getKey();\n+          long evictionTimeMs \u003d \n+              TimeUnit.MILLISECONDS.convert(evictionTimeNs, TimeUnit.NANOSECONDS);\n+          if (evictionTimeMs + maxNonMmappedEvictableLifespanMs \u003e\u003d curMs) break;\n+          ShortCircuitReplica replica \u003d entry.getValue();\n+          if (LOG.isTraceEnabled()) {\n+            LOG.trace(\"CacheCleaner: purging \" + replica + \": \" + \n+                  StringUtils.getStackTrace(Thread.currentThread()));\n+          }\n+          purge(replica);\n+          numPurged++;\n+        }\n+\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(this + \": finishing cache cleaner run started at \" +\n+            curMs + \".  Demoted \" + numDemoted + \" mmapped replicas; \" +\n+            \"purged \" + numPurged + \" replicas.\");\n+        }\n+      } finally {\n+        ShortCircuitCache.this.lock.unlock();\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    public void run() {\n      ShortCircuitCache.this.lock.lock();\n      try {\n        if (ShortCircuitCache.this.closed) return;\n        long curMs \u003d Time.monotonicNow();\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(this + \": cache cleaner running at \" + curMs);\n        }\n\n        int numDemoted \u003d demoteOldEvictableMmaped(curMs);\n        int numPurged \u003d 0;\n        Long evictionTimeNs \u003d Long.valueOf(0);\n        while (true) {\n          Entry\u003cLong, ShortCircuitReplica\u003e entry \u003d \n              evictableMmapped.ceilingEntry(evictionTimeNs);\n          if (entry \u003d\u003d null) break;\n          evictionTimeNs \u003d entry.getKey();\n          long evictionTimeMs \u003d \n              TimeUnit.MILLISECONDS.convert(evictionTimeNs, TimeUnit.NANOSECONDS);\n          if (evictionTimeMs + maxNonMmappedEvictableLifespanMs \u003e\u003d curMs) break;\n          ShortCircuitReplica replica \u003d entry.getValue();\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"CacheCleaner: purging \" + replica + \": \" + \n                  StringUtils.getStackTrace(Thread.currentThread()));\n          }\n          purge(replica);\n          numPurged++;\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(this + \": finishing cache cleaner run started at \" +\n            curMs + \".  Demoted \" + numDemoted + \" mmapped replicas; \" +\n            \"purged \" + numPurged + \" replicas.\");\n        }\n      } finally {\n        ShortCircuitCache.this.lock.unlock();\n      }\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/client/ShortCircuitCache.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/FileInputStreamCache.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/client/ShortCircuitCache.java",
            "oldMethodName": "run",
            "newMethodName": "run"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5810. Unify mmap cache and short-circuit file descriptor cache (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1567720 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "12/02/14 11:08 AM",
          "commitName": "beb0d25d2a7ba5004c6aabd105546ba9a9fec9be",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "12/02/14 10:02 AM",
          "commitNameOld": "5efc9978ddf35f8f4e194e34a102a729dae69992",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 0.05,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,39 @@\n     public void run() {\n-      FileInputStreamCache cache \u003d cacheRef.get();\n-      if (cache \u003d\u003d null) return;\n-      synchronized(cache) {\n-        if (cache.closed) return;\n-        long curTime \u003d Time.monotonicNow();\n-        for (Iterator\u003cEntry\u003cKey, Value\u003e\u003e iter \u003d\n-                  cache.map.entries().iterator(); iter.hasNext();\n-              iter \u003d cache.map.entries().iterator()) {\n-          Entry\u003cKey, Value\u003e entry \u003d iter.next();\n-          if (entry.getValue().getTime() + cache.expiryTimeMs \u003e\u003d curTime) {\n-            break;\n-          }\n-          entry.getValue().close();\n-          iter.remove();\n+      ShortCircuitCache.this.lock.lock();\n+      try {\n+        if (ShortCircuitCache.this.closed) return;\n+        long curMs \u003d Time.monotonicNow();\n+\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(this + \": cache cleaner running at \" + curMs);\n         }\n+\n+        int numDemoted \u003d demoteOldEvictableMmaped(curMs);\n+        int numPurged \u003d 0;\n+        Long evictionTimeNs \u003d Long.valueOf(0);\n+        while (true) {\n+          Entry\u003cLong, ShortCircuitReplica\u003e entry \u003d \n+              evictableMmapped.ceilingEntry(evictionTimeNs);\n+          if (entry \u003d\u003d null) break;\n+          evictionTimeNs \u003d entry.getKey();\n+          long evictionTimeMs \u003d \n+              TimeUnit.MILLISECONDS.convert(evictionTimeNs, TimeUnit.NANOSECONDS);\n+          if (evictionTimeMs + maxNonMmappedEvictableLifespanMs \u003e\u003d curMs) break;\n+          ShortCircuitReplica replica \u003d entry.getValue();\n+          if (LOG.isTraceEnabled()) {\n+            LOG.trace(\"CacheCleaner: purging \" + replica + \": \" + \n+                  StringUtils.getStackTrace(Thread.currentThread()));\n+          }\n+          purge(replica);\n+          numPurged++;\n+        }\n+\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(this + \": finishing cache cleaner run started at \" +\n+            curMs + \".  Demoted \" + numDemoted + \" mmapped replicas; \" +\n+            \"purged \" + numPurged + \" replicas.\");\n+        }\n+      } finally {\n+        ShortCircuitCache.this.lock.unlock();\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    public void run() {\n      ShortCircuitCache.this.lock.lock();\n      try {\n        if (ShortCircuitCache.this.closed) return;\n        long curMs \u003d Time.monotonicNow();\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(this + \": cache cleaner running at \" + curMs);\n        }\n\n        int numDemoted \u003d demoteOldEvictableMmaped(curMs);\n        int numPurged \u003d 0;\n        Long evictionTimeNs \u003d Long.valueOf(0);\n        while (true) {\n          Entry\u003cLong, ShortCircuitReplica\u003e entry \u003d \n              evictableMmapped.ceilingEntry(evictionTimeNs);\n          if (entry \u003d\u003d null) break;\n          evictionTimeNs \u003d entry.getKey();\n          long evictionTimeMs \u003d \n              TimeUnit.MILLISECONDS.convert(evictionTimeNs, TimeUnit.NANOSECONDS);\n          if (evictionTimeMs + maxNonMmappedEvictableLifespanMs \u003e\u003d curMs) break;\n          ShortCircuitReplica replica \u003d entry.getValue();\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"CacheCleaner: purging \" + replica + \": \" + \n                  StringUtils.getStackTrace(Thread.currentThread()));\n          }\n          purge(replica);\n          numPurged++;\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(this + \": finishing cache cleaner run started at \" +\n            curMs + \".  Demoted \" + numDemoted + \" mmapped replicas; \" +\n            \"purged \" + numPurged + \" replicas.\");\n        }\n      } finally {\n        ShortCircuitCache.this.lock.unlock();\n      }\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/client/ShortCircuitCache.java",
          "extendedDetails": {}
        }
      ]
    },
    "9fdb11747628f2fd010bcda4398043eb4eb380ce": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4824. FileInputStreamCache.close leaves dangling reference to FileInputStreamCache.cacheCleaner. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1483641 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/05/13 8:39 PM",
      "commitName": "9fdb11747628f2fd010bcda4398043eb4eb380ce",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "09/05/13 5:03 PM",
      "commitNameOld": "a18fd620d070cf8e84aaf80d93807ac9ee207a0f",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 7.15,
      "commitsBetweenForRepo": 41,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,18 @@\n     public void run() {\n-      synchronized(FileInputStreamCache.this) {\n-        if (closed) return;\n+      FileInputStreamCache cache \u003d cacheRef.get();\n+      if (cache \u003d\u003d null) return;\n+      synchronized(cache) {\n+        if (cache.closed) return;\n         long curTime \u003d Time.monotonicNow();\n-        for (Iterator\u003cEntry\u003cKey, Value\u003e\u003e iter \u003d map.entries().iterator();\n-              iter.hasNext();\n-              iter \u003d map.entries().iterator()) {\n+        for (Iterator\u003cEntry\u003cKey, Value\u003e\u003e iter \u003d\n+                  cache.map.entries().iterator(); iter.hasNext();\n+              iter \u003d cache.map.entries().iterator()) {\n           Entry\u003cKey, Value\u003e entry \u003d iter.next();\n-          if (entry.getValue().getTime() + expiryTimeMs \u003e\u003d curTime) {\n+          if (entry.getValue().getTime() + cache.expiryTimeMs \u003e\u003d curTime) {\n             break;\n           }\n           entry.getValue().close();\n           iter.remove();\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      FileInputStreamCache cache \u003d cacheRef.get();\n      if (cache \u003d\u003d null) return;\n      synchronized(cache) {\n        if (cache.closed) return;\n        long curTime \u003d Time.monotonicNow();\n        for (Iterator\u003cEntry\u003cKey, Value\u003e\u003e iter \u003d\n                  cache.map.entries().iterator(); iter.hasNext();\n              iter \u003d cache.map.entries().iterator()) {\n          Entry\u003cKey, Value\u003e entry \u003d iter.next();\n          if (entry.getValue().getTime() + cache.expiryTimeMs \u003e\u003d curTime) {\n            break;\n          }\n          entry.getValue().close();\n          iter.remove();\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/FileInputStreamCache.java",
      "extendedDetails": {}
    },
    "9a4030e0e84a688c12daa21fe9a165808c3eca70": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4356. BlockReaderLocal should use passed file descriptors rather than paths. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1432335 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/01/13 3:52 PM",
      "commitName": "9a4030e0e84a688c12daa21fe9a165808c3eca70",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,16 @@\n+    public void run() {\n+      synchronized(FileInputStreamCache.this) {\n+        if (closed) return;\n+        long curTime \u003d Time.monotonicNow();\n+        for (Iterator\u003cEntry\u003cKey, Value\u003e\u003e iter \u003d map.entries().iterator();\n+              iter.hasNext();\n+              iter \u003d map.entries().iterator()) {\n+          Entry\u003cKey, Value\u003e entry \u003d iter.next();\n+          if (entry.getValue().getTime() + expiryTimeMs \u003e\u003d curTime) {\n+            break;\n+          }\n+          entry.getValue().close();\n+          iter.remove();\n+        }\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      synchronized(FileInputStreamCache.this) {\n        if (closed) return;\n        long curTime \u003d Time.monotonicNow();\n        for (Iterator\u003cEntry\u003cKey, Value\u003e\u003e iter \u003d map.entries().iterator();\n              iter.hasNext();\n              iter \u003d map.entries().iterator()) {\n          Entry\u003cKey, Value\u003e entry \u003d iter.next();\n          if (entry.getValue().getTime() + expiryTimeMs \u003e\u003d curTime) {\n            break;\n          }\n          entry.getValue().close();\n          iter.remove();\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/FileInputStreamCache.java"
    }
  }
}