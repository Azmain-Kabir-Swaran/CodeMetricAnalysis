{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSNamesystem.java",
  "functionName": "getFileInfo",
  "functionId": "getFileInfo___src-String(modifiers-final)__resolveLink-boolean__needLocation-boolean__needBlockToken-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
  "functionStartLine": 3372,
  "functionEndLine": 3397,
  "numCommitsSeen": 2122,
  "timeTaken": 32782,
  "changeHistory": [
    "1824aee9da4056de0fb638906b2172e486bbebe7",
    "4b95c242eca540455a4d5d0899aaf73b6064b5ea",
    "f600fbb6c4987c69292faea6b5abf022bb213ffd",
    "84a1321f6aa0af6895564a7c47f8f264656f0294",
    "693169ef34f856a27dc09d90a45fb4ec5b66ed2c",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893",
    "0af44ea8462437f8e7a8271b15a19677fd7f05a1",
    "c95b878abf313507666ea018f9e6033c4c166e10",
    "185200e7096d15a5c2c2d59b7c7705362820aebf"
  ],
  "changeHistoryShort": {
    "1824aee9da4056de0fb638906b2172e486bbebe7": "Ybodychange",
    "4b95c242eca540455a4d5d0899aaf73b6064b5ea": "Ybodychange",
    "f600fbb6c4987c69292faea6b5abf022bb213ffd": "Ybodychange",
    "84a1321f6aa0af6895564a7c47f8f264656f0294": "Ybodychange",
    "693169ef34f856a27dc09d90a45fb4ec5b66ed2c": "Ymultichange(Yparameterchange,Ybodychange)",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": "Ybodychange",
    "0af44ea8462437f8e7a8271b15a19677fd7f05a1": "Ymultichange(Yparameterchange,Yexceptionschange,Ybodychange)",
    "c95b878abf313507666ea018f9e6033c4c166e10": "Ybodychange",
    "185200e7096d15a5c2c2d59b7c7705362820aebf": "Ybodychange"
  },
  "changeHistoryDetails": {
    "1824aee9da4056de0fb638906b2172e486bbebe7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15217 Add more information to longest write/read lock held log\n\n",
      "commitDate": "18/04/20 1:52 PM",
      "commitName": "1824aee9da4056de0fb638906b2172e486bbebe7",
      "commitAuthor": "Toshihiro Suzuki",
      "commitDateOld": "25/03/20 10:28 AM",
      "commitNameOld": "a700803a18fb957d2799001a2ce1dcb70f75c080",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 24.14,
      "commitsBetweenForRepo": 78,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,26 @@\n   HdfsFileStatus getFileInfo(final String src, boolean resolveLink,\n       boolean needLocation, boolean needBlockToken) throws IOException {\n     // if the client requests block tokens, then it can read data blocks\n     // and should appear in the audit log as if getBlockLocations had been\n     // called\n     final String operationName \u003d needBlockToken ? \"open\" : \"getfileinfo\";\n     checkOperation(OperationCategory.READ);\n     HdfsFileStatus stat \u003d null;\n     final FSPermissionChecker pc \u003d getPermissionChecker();\n     FSPermissionChecker.setOperationType(operationName);\n     try {\n       readLock();\n       try {\n         checkOperation(OperationCategory.READ);\n         stat \u003d FSDirStatAndListingOp.getFileInfo(\n             dir, pc, src, resolveLink, needLocation, needBlockToken);\n       } finally {\n-        readUnlock(operationName);\n+        readUnlock(operationName, getLockReportInfoSupplier(src));\n       }\n     } catch (AccessControlException e) {\n       logAuditEvent(false, operationName, src);\n       throw e;\n     }\n     logAuditEvent(true, operationName, src);\n     return stat;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HdfsFileStatus getFileInfo(final String src, boolean resolveLink,\n      boolean needLocation, boolean needBlockToken) throws IOException {\n    // if the client requests block tokens, then it can read data blocks\n    // and should appear in the audit log as if getBlockLocations had been\n    // called\n    final String operationName \u003d needBlockToken ? \"open\" : \"getfileinfo\";\n    checkOperation(OperationCategory.READ);\n    HdfsFileStatus stat \u003d null;\n    final FSPermissionChecker pc \u003d getPermissionChecker();\n    FSPermissionChecker.setOperationType(operationName);\n    try {\n      readLock();\n      try {\n        checkOperation(OperationCategory.READ);\n        stat \u003d FSDirStatAndListingOp.getFileInfo(\n            dir, pc, src, resolveLink, needLocation, needBlockToken);\n      } finally {\n        readUnlock(operationName, getLockReportInfoSupplier(src));\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, src);\n      throw e;\n    }\n    logAuditEvent(true, operationName, src);\n    return stat;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "4b95c242eca540455a4d5d0899aaf73b6064b5ea": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14743. Enhance INodeAttributeProvider/ AccessControlEnforcer Interface in HDFS to support Authorization of mkdir, rm, rmdir, copy, move etc... (#1829)\n\nReviewed-by: Xiaoyu Yao \u003cxyao@apache.org\u003e",
      "commitDate": "13/03/20 11:29 AM",
      "commitName": "4b95c242eca540455a4d5d0899aaf73b6064b5ea",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "27/02/20 8:49 AM",
      "commitNameOld": "cd2c6b1aac470991b9b90339ce2721ba179e7c48",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 15.07,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,26 @@\n   HdfsFileStatus getFileInfo(final String src, boolean resolveLink,\n       boolean needLocation, boolean needBlockToken) throws IOException {\n     // if the client requests block tokens, then it can read data blocks\n     // and should appear in the audit log as if getBlockLocations had been\n     // called\n     final String operationName \u003d needBlockToken ? \"open\" : \"getfileinfo\";\n     checkOperation(OperationCategory.READ);\n     HdfsFileStatus stat \u003d null;\n     final FSPermissionChecker pc \u003d getPermissionChecker();\n+    FSPermissionChecker.setOperationType(operationName);\n     try {\n       readLock();\n       try {\n         checkOperation(OperationCategory.READ);\n         stat \u003d FSDirStatAndListingOp.getFileInfo(\n             dir, pc, src, resolveLink, needLocation, needBlockToken);\n       } finally {\n         readUnlock(operationName);\n       }\n     } catch (AccessControlException e) {\n       logAuditEvent(false, operationName, src);\n       throw e;\n     }\n     logAuditEvent(true, operationName, src);\n     return stat;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HdfsFileStatus getFileInfo(final String src, boolean resolveLink,\n      boolean needLocation, boolean needBlockToken) throws IOException {\n    // if the client requests block tokens, then it can read data blocks\n    // and should appear in the audit log as if getBlockLocations had been\n    // called\n    final String operationName \u003d needBlockToken ? \"open\" : \"getfileinfo\";\n    checkOperation(OperationCategory.READ);\n    HdfsFileStatus stat \u003d null;\n    final FSPermissionChecker pc \u003d getPermissionChecker();\n    FSPermissionChecker.setOperationType(operationName);\n    try {\n      readLock();\n      try {\n        checkOperation(OperationCategory.READ);\n        stat \u003d FSDirStatAndListingOp.getFileInfo(\n            dir, pc, src, resolveLink, needLocation, needBlockToken);\n      } finally {\n        readUnlock(operationName);\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, src);\n      throw e;\n    }\n    logAuditEvent(true, operationName, src);\n    return stat;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "f600fbb6c4987c69292faea6b5abf022bb213ffd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11246. FSNameSystem#logAuditEvent should be called outside the read or write locks. Contributed by He Xiaoqiao, Kuhu Shukla.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\nCo-authored-by: Kuhu Shukla \u003ckshukla@apache.org\u003e\n",
      "commitDate": "29/08/19 10:10 AM",
      "commitName": "f600fbb6c4987c69292faea6b5abf022bb213ffd",
      "commitAuthor": "He Xiaoqiao",
      "commitDateOld": "27/08/19 3:26 PM",
      "commitNameOld": "dde9399b37bffb77da17c025f0b9b673d7088bc6",
      "commitAuthorOld": "He Xiaoqiao",
      "daysBetweenCommits": 1.78,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,25 @@\n   HdfsFileStatus getFileInfo(final String src, boolean resolveLink,\n       boolean needLocation, boolean needBlockToken) throws IOException {\n     // if the client requests block tokens, then it can read data blocks\n     // and should appear in the audit log as if getBlockLocations had been\n     // called\n     final String operationName \u003d needBlockToken ? \"open\" : \"getfileinfo\";\n     checkOperation(OperationCategory.READ);\n     HdfsFileStatus stat \u003d null;\n     final FSPermissionChecker pc \u003d getPermissionChecker();\n-    readLock();\n     try {\n-      checkOperation(OperationCategory.READ);\n-      stat \u003d FSDirStatAndListingOp.getFileInfo(\n-          dir, pc, src, resolveLink, needLocation, needBlockToken);\n+      readLock();\n+      try {\n+        checkOperation(OperationCategory.READ);\n+        stat \u003d FSDirStatAndListingOp.getFileInfo(\n+            dir, pc, src, resolveLink, needLocation, needBlockToken);\n+      } finally {\n+        readUnlock(operationName);\n+      }\n     } catch (AccessControlException e) {\n       logAuditEvent(false, operationName, src);\n       throw e;\n-    } finally {\n-      readUnlock(operationName);\n     }\n     logAuditEvent(true, operationName, src);\n     return stat;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HdfsFileStatus getFileInfo(final String src, boolean resolveLink,\n      boolean needLocation, boolean needBlockToken) throws IOException {\n    // if the client requests block tokens, then it can read data blocks\n    // and should appear in the audit log as if getBlockLocations had been\n    // called\n    final String operationName \u003d needBlockToken ? \"open\" : \"getfileinfo\";\n    checkOperation(OperationCategory.READ);\n    HdfsFileStatus stat \u003d null;\n    final FSPermissionChecker pc \u003d getPermissionChecker();\n    try {\n      readLock();\n      try {\n        checkOperation(OperationCategory.READ);\n        stat \u003d FSDirStatAndListingOp.getFileInfo(\n            dir, pc, src, resolveLink, needLocation, needBlockToken);\n      } finally {\n        readUnlock(operationName);\n      }\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, src);\n      throw e;\n    }\n    logAuditEvent(true, operationName, src);\n    return stat;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "84a1321f6aa0af6895564a7c47f8f264656f0294": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13136. Avoid taking FSN lock while doing group member lookup for FSD permission check. Contributed by Xiaoyu Yao.\n",
      "commitDate": "22/02/18 11:32 AM",
      "commitName": "84a1321f6aa0af6895564a7c47f8f264656f0294",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "15/02/18 1:32 PM",
      "commitNameOld": "47473952e56b0380147d42f4110ad03c2276c961",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 6.92,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,23 @@\n   HdfsFileStatus getFileInfo(final String src, boolean resolveLink,\n       boolean needLocation, boolean needBlockToken) throws IOException {\n     // if the client requests block tokens, then it can read data blocks\n     // and should appear in the audit log as if getBlockLocations had been\n     // called\n     final String operationName \u003d needBlockToken ? \"open\" : \"getfileinfo\";\n     checkOperation(OperationCategory.READ);\n     HdfsFileStatus stat \u003d null;\n+    final FSPermissionChecker pc \u003d getPermissionChecker();\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       stat \u003d FSDirStatAndListingOp.getFileInfo(\n-          dir, src, resolveLink, needLocation, needBlockToken);\n+          dir, pc, src, resolveLink, needLocation, needBlockToken);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, operationName, src);\n       throw e;\n     } finally {\n       readUnlock(operationName);\n     }\n     logAuditEvent(true, operationName, src);\n     return stat;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HdfsFileStatus getFileInfo(final String src, boolean resolveLink,\n      boolean needLocation, boolean needBlockToken) throws IOException {\n    // if the client requests block tokens, then it can read data blocks\n    // and should appear in the audit log as if getBlockLocations had been\n    // called\n    final String operationName \u003d needBlockToken ? \"open\" : \"getfileinfo\";\n    checkOperation(OperationCategory.READ);\n    HdfsFileStatus stat \u003d null;\n    final FSPermissionChecker pc \u003d getPermissionChecker();\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      stat \u003d FSDirStatAndListingOp.getFileInfo(\n          dir, pc, src, resolveLink, needLocation, needBlockToken);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, src);\n      throw e;\n    } finally {\n      readUnlock(operationName);\n    }\n    logAuditEvent(true, operationName, src);\n    return stat;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "693169ef34f856a27dc09d90a45fb4ec5b66ed2c": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-12882. Support full open(PathHandle) contract in HDFS\n",
      "commitDate": "11/12/17 8:14 PM",
      "commitName": "693169ef34f856a27dc09d90a45fb4ec5b66ed2c",
      "commitAuthor": "Chris Douglas",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-12882. Support full open(PathHandle) contract in HDFS\n",
          "commitDate": "11/12/17 8:14 PM",
          "commitName": "693169ef34f856a27dc09d90a45fb4ec5b66ed2c",
          "commitAuthor": "Chris Douglas",
          "commitDateOld": "01/12/17 10:34 PM",
          "commitNameOld": "42307e3c3abbfe0b83d9a2581deba327435b910f",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 9.9,
          "commitsBetweenForRepo": 58,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,22 @@\n-  HdfsFileStatus getFileInfo(final String src, boolean resolveLink)\n-    throws IOException {\n-    final String operationName \u003d \"getfileinfo\";\n+  HdfsFileStatus getFileInfo(final String src, boolean resolveLink,\n+      boolean needLocation, boolean needBlockToken) throws IOException {\n+    // if the client requests block tokens, then it can read data blocks\n+    // and should appear in the audit log as if getBlockLocations had been\n+    // called\n+    final String operationName \u003d needBlockToken ? \"open\" : \"getfileinfo\";\n     checkOperation(OperationCategory.READ);\n     HdfsFileStatus stat \u003d null;\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n-      stat \u003d FSDirStatAndListingOp.getFileInfo(dir, src, resolveLink);\n+      stat \u003d FSDirStatAndListingOp.getFileInfo(\n+          dir, src, resolveLink, needLocation, needBlockToken);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, operationName, src);\n       throw e;\n     } finally {\n       readUnlock(operationName);\n     }\n     logAuditEvent(true, operationName, src);\n     return stat;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HdfsFileStatus getFileInfo(final String src, boolean resolveLink,\n      boolean needLocation, boolean needBlockToken) throws IOException {\n    // if the client requests block tokens, then it can read data blocks\n    // and should appear in the audit log as if getBlockLocations had been\n    // called\n    final String operationName \u003d needBlockToken ? \"open\" : \"getfileinfo\";\n    checkOperation(OperationCategory.READ);\n    HdfsFileStatus stat \u003d null;\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      stat \u003d FSDirStatAndListingOp.getFileInfo(\n          dir, src, resolveLink, needLocation, needBlockToken);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, src);\n      throw e;\n    } finally {\n      readUnlock(operationName);\n    }\n    logAuditEvent(true, operationName, src);\n    return stat;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[src-String(modifiers-final), resolveLink-boolean]",
            "newValue": "[src-String(modifiers-final), resolveLink-boolean, needLocation-boolean, needBlockToken-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-12882. Support full open(PathHandle) contract in HDFS\n",
          "commitDate": "11/12/17 8:14 PM",
          "commitName": "693169ef34f856a27dc09d90a45fb4ec5b66ed2c",
          "commitAuthor": "Chris Douglas",
          "commitDateOld": "01/12/17 10:34 PM",
          "commitNameOld": "42307e3c3abbfe0b83d9a2581deba327435b910f",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 9.9,
          "commitsBetweenForRepo": 58,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,22 @@\n-  HdfsFileStatus getFileInfo(final String src, boolean resolveLink)\n-    throws IOException {\n-    final String operationName \u003d \"getfileinfo\";\n+  HdfsFileStatus getFileInfo(final String src, boolean resolveLink,\n+      boolean needLocation, boolean needBlockToken) throws IOException {\n+    // if the client requests block tokens, then it can read data blocks\n+    // and should appear in the audit log as if getBlockLocations had been\n+    // called\n+    final String operationName \u003d needBlockToken ? \"open\" : \"getfileinfo\";\n     checkOperation(OperationCategory.READ);\n     HdfsFileStatus stat \u003d null;\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n-      stat \u003d FSDirStatAndListingOp.getFileInfo(dir, src, resolveLink);\n+      stat \u003d FSDirStatAndListingOp.getFileInfo(\n+          dir, src, resolveLink, needLocation, needBlockToken);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, operationName, src);\n       throw e;\n     } finally {\n       readUnlock(operationName);\n     }\n     logAuditEvent(true, operationName, src);\n     return stat;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HdfsFileStatus getFileInfo(final String src, boolean resolveLink,\n      boolean needLocation, boolean needBlockToken) throws IOException {\n    // if the client requests block tokens, then it can read data blocks\n    // and should appear in the audit log as if getBlockLocations had been\n    // called\n    final String operationName \u003d needBlockToken ? \"open\" : \"getfileinfo\";\n    checkOperation(OperationCategory.READ);\n    HdfsFileStatus stat \u003d null;\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      stat \u003d FSDirStatAndListingOp.getFileInfo(\n          dir, src, resolveLink, needLocation, needBlockToken);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, src);\n      throw e;\n    } finally {\n      readUnlock(operationName);\n    }\n    logAuditEvent(true, operationName, src);\n    return stat;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10872. Add MutableRate metrics for FSNamesystemLock operations. Contributed by Erik Krogen.\n",
      "commitDate": "14/11/16 11:05 AM",
      "commitName": "ff0b99eafeda035ebe0dc82cfe689808047a8893",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "08/11/16 6:17 PM",
      "commitNameOld": "ed0bebabaaf27cd730f7f8eb002d92c9c7db327d",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 5.7,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,18 @@\n   HdfsFileStatus getFileInfo(final String src, boolean resolveLink)\n     throws IOException {\n+    final String operationName \u003d \"getfileinfo\";\n     checkOperation(OperationCategory.READ);\n     HdfsFileStatus stat \u003d null;\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       stat \u003d FSDirStatAndListingOp.getFileInfo(dir, src, resolveLink);\n     } catch (AccessControlException e) {\n-      logAuditEvent(false, \"getfileinfo\", src);\n+      logAuditEvent(false, operationName, src);\n       throw e;\n     } finally {\n-      readUnlock();\n+      readUnlock(operationName);\n     }\n-    logAuditEvent(true, \"getfileinfo\", src);\n+    logAuditEvent(true, operationName, src);\n     return stat;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HdfsFileStatus getFileInfo(final String src, boolean resolveLink)\n    throws IOException {\n    final String operationName \u003d \"getfileinfo\";\n    checkOperation(OperationCategory.READ);\n    HdfsFileStatus stat \u003d null;\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      stat \u003d FSDirStatAndListingOp.getFileInfo(dir, src, resolveLink);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, src);\n      throw e;\n    } finally {\n      readUnlock(operationName);\n    }\n    logAuditEvent(true, operationName, src);\n    return stat;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "0af44ea8462437f8e7a8271b15a19677fd7f05a1": {
      "type": "Ymultichange(Yparameterchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-7450. Consolidate the implementation of GetFileInfo(), GetListings() and GetContentSummary() into a single class. Contributed by Haohui Mai.\n",
      "commitDate": "01/12/14 9:36 PM",
      "commitName": "0af44ea8462437f8e7a8271b15a19677fd7f05a1",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7450. Consolidate the implementation of GetFileInfo(), GetListings() and GetContentSummary() into a single class. Contributed by Haohui Mai.\n",
          "commitDate": "01/12/14 9:36 PM",
          "commitName": "0af44ea8462437f8e7a8271b15a19677fd7f05a1",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "28/11/14 7:39 AM",
          "commitNameOld": "1556f86a31a54733d6550363aa0e027acca7823b",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 3.58,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,32 +1,17 @@\n-  HdfsFileStatus getFileInfo(final String srcArg, boolean resolveLink)\n-    throws AccessControlException, UnresolvedLinkException,\n-           StandbyException, IOException {\n-    String src \u003d srcArg;\n-    if (!DFSUtil.isValidName(src)) {\n-      throw new InvalidPathException(\"Invalid file name: \" + src);\n-    }\n-    HdfsFileStatus stat \u003d null;\n-    FSPermissionChecker pc \u003d getPermissionChecker();\n+  HdfsFileStatus getFileInfo(final String src, boolean resolveLink)\n+    throws IOException {\n     checkOperation(OperationCategory.READ);\n-    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n+    HdfsFileStatus stat \u003d null;\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n-      src \u003d dir.resolvePath(pc, src, pathComponents);\n-      boolean isSuperUser \u003d true;\n-      if (isPermissionEnabled) {\n-        checkPermission(pc, src, false, null, null, null, null, false,\n-            resolveLink);\n-        isSuperUser \u003d pc.isSuperUser();\n-      }\n-      stat \u003d dir.getFileInfo(src, resolveLink,\n-          FSDirectory.isReservedRawName(srcArg), isSuperUser);\n+      stat \u003d FSDirStatAndListingOp.getFileInfo(dir, src, resolveLink);\n     } catch (AccessControlException e) {\n-      logAuditEvent(false, \"getfileinfo\", srcArg);\n+      logAuditEvent(false, \"getfileinfo\", src);\n       throw e;\n     } finally {\n       readUnlock();\n     }\n-    logAuditEvent(true, \"getfileinfo\", srcArg);\n+    logAuditEvent(true, \"getfileinfo\", src);\n     return stat;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HdfsFileStatus getFileInfo(final String src, boolean resolveLink)\n    throws IOException {\n    checkOperation(OperationCategory.READ);\n    HdfsFileStatus stat \u003d null;\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      stat \u003d FSDirStatAndListingOp.getFileInfo(dir, src, resolveLink);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"getfileinfo\", src);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n    logAuditEvent(true, \"getfileinfo\", src);\n    return stat;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[srcArg-String(modifiers-final), resolveLink-boolean]",
            "newValue": "[src-String(modifiers-final), resolveLink-boolean]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-7450. Consolidate the implementation of GetFileInfo(), GetListings() and GetContentSummary() into a single class. Contributed by Haohui Mai.\n",
          "commitDate": "01/12/14 9:36 PM",
          "commitName": "0af44ea8462437f8e7a8271b15a19677fd7f05a1",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "28/11/14 7:39 AM",
          "commitNameOld": "1556f86a31a54733d6550363aa0e027acca7823b",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 3.58,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,32 +1,17 @@\n-  HdfsFileStatus getFileInfo(final String srcArg, boolean resolveLink)\n-    throws AccessControlException, UnresolvedLinkException,\n-           StandbyException, IOException {\n-    String src \u003d srcArg;\n-    if (!DFSUtil.isValidName(src)) {\n-      throw new InvalidPathException(\"Invalid file name: \" + src);\n-    }\n-    HdfsFileStatus stat \u003d null;\n-    FSPermissionChecker pc \u003d getPermissionChecker();\n+  HdfsFileStatus getFileInfo(final String src, boolean resolveLink)\n+    throws IOException {\n     checkOperation(OperationCategory.READ);\n-    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n+    HdfsFileStatus stat \u003d null;\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n-      src \u003d dir.resolvePath(pc, src, pathComponents);\n-      boolean isSuperUser \u003d true;\n-      if (isPermissionEnabled) {\n-        checkPermission(pc, src, false, null, null, null, null, false,\n-            resolveLink);\n-        isSuperUser \u003d pc.isSuperUser();\n-      }\n-      stat \u003d dir.getFileInfo(src, resolveLink,\n-          FSDirectory.isReservedRawName(srcArg), isSuperUser);\n+      stat \u003d FSDirStatAndListingOp.getFileInfo(dir, src, resolveLink);\n     } catch (AccessControlException e) {\n-      logAuditEvent(false, \"getfileinfo\", srcArg);\n+      logAuditEvent(false, \"getfileinfo\", src);\n       throw e;\n     } finally {\n       readUnlock();\n     }\n-    logAuditEvent(true, \"getfileinfo\", srcArg);\n+    logAuditEvent(true, \"getfileinfo\", src);\n     return stat;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HdfsFileStatus getFileInfo(final String src, boolean resolveLink)\n    throws IOException {\n    checkOperation(OperationCategory.READ);\n    HdfsFileStatus stat \u003d null;\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      stat \u003d FSDirStatAndListingOp.getFileInfo(dir, src, resolveLink);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"getfileinfo\", src);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n    logAuditEvent(true, \"getfileinfo\", src);\n    return stat;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[AccessControlException, UnresolvedLinkException, StandbyException, IOException]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7450. Consolidate the implementation of GetFileInfo(), GetListings() and GetContentSummary() into a single class. Contributed by Haohui Mai.\n",
          "commitDate": "01/12/14 9:36 PM",
          "commitName": "0af44ea8462437f8e7a8271b15a19677fd7f05a1",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "28/11/14 7:39 AM",
          "commitNameOld": "1556f86a31a54733d6550363aa0e027acca7823b",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 3.58,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,32 +1,17 @@\n-  HdfsFileStatus getFileInfo(final String srcArg, boolean resolveLink)\n-    throws AccessControlException, UnresolvedLinkException,\n-           StandbyException, IOException {\n-    String src \u003d srcArg;\n-    if (!DFSUtil.isValidName(src)) {\n-      throw new InvalidPathException(\"Invalid file name: \" + src);\n-    }\n-    HdfsFileStatus stat \u003d null;\n-    FSPermissionChecker pc \u003d getPermissionChecker();\n+  HdfsFileStatus getFileInfo(final String src, boolean resolveLink)\n+    throws IOException {\n     checkOperation(OperationCategory.READ);\n-    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n+    HdfsFileStatus stat \u003d null;\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n-      src \u003d dir.resolvePath(pc, src, pathComponents);\n-      boolean isSuperUser \u003d true;\n-      if (isPermissionEnabled) {\n-        checkPermission(pc, src, false, null, null, null, null, false,\n-            resolveLink);\n-        isSuperUser \u003d pc.isSuperUser();\n-      }\n-      stat \u003d dir.getFileInfo(src, resolveLink,\n-          FSDirectory.isReservedRawName(srcArg), isSuperUser);\n+      stat \u003d FSDirStatAndListingOp.getFileInfo(dir, src, resolveLink);\n     } catch (AccessControlException e) {\n-      logAuditEvent(false, \"getfileinfo\", srcArg);\n+      logAuditEvent(false, \"getfileinfo\", src);\n       throw e;\n     } finally {\n       readUnlock();\n     }\n-    logAuditEvent(true, \"getfileinfo\", srcArg);\n+    logAuditEvent(true, \"getfileinfo\", src);\n     return stat;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HdfsFileStatus getFileInfo(final String src, boolean resolveLink)\n    throws IOException {\n    checkOperation(OperationCategory.READ);\n    HdfsFileStatus stat \u003d null;\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      stat \u003d FSDirStatAndListingOp.getFileInfo(dir, src, resolveLink);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"getfileinfo\", src);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n    logAuditEvent(true, \"getfileinfo\", src);\n    return stat;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "c95b878abf313507666ea018f9e6033c4c166e10": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7415. Move FSNameSystem.resolvePath() to FSDirectory. Contributed by Haohui Mai.\n",
      "commitDate": "20/11/14 7:23 PM",
      "commitName": "c95b878abf313507666ea018f9e6033c4c166e10",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "17/11/14 5:33 PM",
      "commitNameOld": "dcb8e24427b02e2f3ff9a12d2eb1eb878e3443bb",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 3.08,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,32 @@\n   HdfsFileStatus getFileInfo(final String srcArg, boolean resolveLink)\n     throws AccessControlException, UnresolvedLinkException,\n            StandbyException, IOException {\n     String src \u003d srcArg;\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(\"Invalid file name: \" + src);\n     }\n     HdfsFileStatus stat \u003d null;\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n-      src \u003d resolvePath(src, pathComponents);\n+      src \u003d dir.resolvePath(pc, src, pathComponents);\n       boolean isSuperUser \u003d true;\n       if (isPermissionEnabled) {\n         checkPermission(pc, src, false, null, null, null, null, false,\n             resolveLink);\n         isSuperUser \u003d pc.isSuperUser();\n       }\n       stat \u003d dir.getFileInfo(src, resolveLink,\n           FSDirectory.isReservedRawName(srcArg), isSuperUser);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"getfileinfo\", srcArg);\n       throw e;\n     } finally {\n       readUnlock();\n     }\n     logAuditEvent(true, \"getfileinfo\", srcArg);\n     return stat;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HdfsFileStatus getFileInfo(final String srcArg, boolean resolveLink)\n    throws AccessControlException, UnresolvedLinkException,\n           StandbyException, IOException {\n    String src \u003d srcArg;\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(\"Invalid file name: \" + src);\n    }\n    HdfsFileStatus stat \u003d null;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d dir.resolvePath(pc, src, pathComponents);\n      boolean isSuperUser \u003d true;\n      if (isPermissionEnabled) {\n        checkPermission(pc, src, false, null, null, null, null, false,\n            resolveLink);\n        isSuperUser \u003d pc.isSuperUser();\n      }\n      stat \u003d dir.getFileInfo(src, resolveLink,\n          FSDirectory.isReservedRawName(srcArg), isSuperUser);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"getfileinfo\", srcArg);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n    logAuditEvent(true, \"getfileinfo\", srcArg);\n    return stat;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "185200e7096d15a5c2c2d59b7c7705362820aebf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6876. Archival Storage: support set/get storage policy in DFSAdmin. Contributed by Jing Zhao.\n",
      "commitDate": "04/09/14 8:14 PM",
      "commitName": "185200e7096d15a5c2c2d59b7c7705362820aebf",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "03/09/14 3:36 PM",
      "commitNameOld": "45d5b132562990d91724c03358096c3a5dd97146",
      "commitAuthorOld": "",
      "daysBetweenCommits": 1.19,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,32 @@\n   HdfsFileStatus getFileInfo(final String srcArg, boolean resolveLink)\n     throws AccessControlException, UnresolvedLinkException,\n            StandbyException, IOException {\n     String src \u003d srcArg;\n     if (!DFSUtil.isValidName(src)) {\n       throw new InvalidPathException(\"Invalid file name: \" + src);\n     }\n     HdfsFileStatus stat \u003d null;\n     FSPermissionChecker pc \u003d getPermissionChecker();\n     checkOperation(OperationCategory.READ);\n     byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n     readLock();\n     try {\n       checkOperation(OperationCategory.READ);\n       src \u003d resolvePath(src, pathComponents);\n+      boolean isSuperUser \u003d true;\n       if (isPermissionEnabled) {\n         checkPermission(pc, src, false, null, null, null, null, false,\n             resolveLink);\n+        isSuperUser \u003d pc.isSuperUser();\n       }\n       stat \u003d dir.getFileInfo(src, resolveLink,\n-          FSDirectory.isReservedRawName(srcArg));\n+          FSDirectory.isReservedRawName(srcArg), isSuperUser);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"getfileinfo\", srcArg);\n       throw e;\n     } finally {\n       readUnlock();\n     }\n     logAuditEvent(true, \"getfileinfo\", srcArg);\n     return stat;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HdfsFileStatus getFileInfo(final String srcArg, boolean resolveLink)\n    throws AccessControlException, UnresolvedLinkException,\n           StandbyException, IOException {\n    String src \u003d srcArg;\n    if (!DFSUtil.isValidName(src)) {\n      throw new InvalidPathException(\"Invalid file name: \" + src);\n    }\n    HdfsFileStatus stat \u003d null;\n    FSPermissionChecker pc \u003d getPermissionChecker();\n    checkOperation(OperationCategory.READ);\n    byte[][] pathComponents \u003d FSDirectory.getPathComponentsForReservedPath(src);\n    readLock();\n    try {\n      checkOperation(OperationCategory.READ);\n      src \u003d resolvePath(src, pathComponents);\n      boolean isSuperUser \u003d true;\n      if (isPermissionEnabled) {\n        checkPermission(pc, src, false, null, null, null, null, false,\n            resolveLink);\n        isSuperUser \u003d pc.isSuperUser();\n      }\n      stat \u003d dir.getFileInfo(src, resolveLink,\n          FSDirectory.isReservedRawName(srcArg), isSuperUser);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"getfileinfo\", srcArg);\n      throw e;\n    } finally {\n      readUnlock();\n    }\n    logAuditEvent(true, \"getfileinfo\", srcArg);\n    return stat;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    }
  }
}