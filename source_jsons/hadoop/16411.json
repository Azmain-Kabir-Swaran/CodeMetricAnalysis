{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RouterClientProtocol.java",
  "functionName": "aggregateContentSummary",
  "functionId": "aggregateContentSummary___summaries-Collection__ContentSummary__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
  "functionStartLine": 1863,
  "functionEndLine": 1901,
  "numCommitsSeen": 64,
  "timeTaken": 2908,
  "changeHistory": [
    "acdf911c014e6820866f3451c7ae09163119337c",
    "6425ed27ea638da75f656204d6df4adad1d91fe1",
    "fb5b3dce6192265bce9b9d93ab663bdc5be8048e"
  ],
  "changeHistoryShort": {
    "acdf911c014e6820866f3451c7ae09163119337c": "Ybodychange",
    "6425ed27ea638da75f656204d6df4adad1d91fe1": "Ymovefromfile",
    "fb5b3dce6192265bce9b9d93ab663bdc5be8048e": "Yintroduced"
  },
  "changeHistoryDetails": {
    "acdf911c014e6820866f3451c7ae09163119337c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14224. RBF: NPE in getContentSummary() for getEcPolicy() in case of multiple destinations. Contributed by Ayush Saxena.\n",
      "commitDate": "24/06/19 9:33 AM",
      "commitName": "acdf911c014e6820866f3451c7ae09163119337c",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "24/06/19 9:33 AM",
      "commitNameOld": "235406d9047af2039090ad48fc708368046df008",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,39 @@\n   private ContentSummary aggregateContentSummary(\n       Collection\u003cContentSummary\u003e summaries) {\n     if (summaries.size() \u003d\u003d 1) {\n       return summaries.iterator().next();\n     }\n \n     long length \u003d 0;\n     long fileCount \u003d 0;\n     long directoryCount \u003d 0;\n     long quota \u003d 0;\n     long spaceConsumed \u003d 0;\n     long spaceQuota \u003d 0;\n+    String ecPolicy \u003d \"\";\n \n     for (ContentSummary summary : summaries) {\n       length +\u003d summary.getLength();\n       fileCount +\u003d summary.getFileCount();\n       directoryCount +\u003d summary.getDirectoryCount();\n       quota +\u003d summary.getQuota();\n       spaceConsumed +\u003d summary.getSpaceConsumed();\n       spaceQuota +\u003d summary.getSpaceQuota();\n+      // We return from the first response as we assume that the EC policy\n+      // of each sub-cluster is same.\n+      if (ecPolicy.isEmpty()) {\n+        ecPolicy \u003d summary.getErasureCodingPolicy();\n+      }\n     }\n \n     ContentSummary ret \u003d new ContentSummary.Builder()\n         .length(length)\n         .fileCount(fileCount)\n         .directoryCount(directoryCount)\n         .quota(quota)\n         .spaceConsumed(spaceConsumed)\n         .spaceQuota(spaceQuota)\n+        .erasureCodingPolicy(ecPolicy)\n         .build();\n     return ret;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private ContentSummary aggregateContentSummary(\n      Collection\u003cContentSummary\u003e summaries) {\n    if (summaries.size() \u003d\u003d 1) {\n      return summaries.iterator().next();\n    }\n\n    long length \u003d 0;\n    long fileCount \u003d 0;\n    long directoryCount \u003d 0;\n    long quota \u003d 0;\n    long spaceConsumed \u003d 0;\n    long spaceQuota \u003d 0;\n    String ecPolicy \u003d \"\";\n\n    for (ContentSummary summary : summaries) {\n      length +\u003d summary.getLength();\n      fileCount +\u003d summary.getFileCount();\n      directoryCount +\u003d summary.getDirectoryCount();\n      quota +\u003d summary.getQuota();\n      spaceConsumed +\u003d summary.getSpaceConsumed();\n      spaceQuota +\u003d summary.getSpaceQuota();\n      // We return from the first response as we assume that the EC policy\n      // of each sub-cluster is same.\n      if (ecPolicy.isEmpty()) {\n        ecPolicy \u003d summary.getErasureCodingPolicy();\n      }\n    }\n\n    ContentSummary ret \u003d new ContentSummary.Builder()\n        .length(length)\n        .fileCount(fileCount)\n        .directoryCount(directoryCount)\n        .quota(quota)\n        .spaceConsumed(spaceConsumed)\n        .spaceQuota(spaceQuota)\n        .erasureCodingPolicy(ecPolicy)\n        .build();\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
      "extendedDetails": {}
    },
    "6425ed27ea638da75f656204d6df4adad1d91fe1": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-13790. RBF: Move ClientProtocol APIs to its own module. Contributed by Chao Sun.\n",
      "commitDate": "19/08/18 11:50 PM",
      "commitName": "6425ed27ea638da75f656204d6df4adad1d91fe1",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "17/08/18 9:56 PM",
      "commitNameOld": "4aacbfff605262aaf3dbd926258afcadc86c72c0",
      "commitAuthorOld": "Rohith Sharma K S",
      "daysBetweenCommits": 2.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private ContentSummary aggregateContentSummary(\n      Collection\u003cContentSummary\u003e summaries) {\n    if (summaries.size() \u003d\u003d 1) {\n      return summaries.iterator().next();\n    }\n\n    long length \u003d 0;\n    long fileCount \u003d 0;\n    long directoryCount \u003d 0;\n    long quota \u003d 0;\n    long spaceConsumed \u003d 0;\n    long spaceQuota \u003d 0;\n\n    for (ContentSummary summary : summaries) {\n      length +\u003d summary.getLength();\n      fileCount +\u003d summary.getFileCount();\n      directoryCount +\u003d summary.getDirectoryCount();\n      quota +\u003d summary.getQuota();\n      spaceConsumed +\u003d summary.getSpaceConsumed();\n      spaceQuota +\u003d summary.getSpaceQuota();\n    }\n\n    ContentSummary ret \u003d new ContentSummary.Builder()\n        .length(length)\n        .fileCount(fileCount)\n        .directoryCount(directoryCount)\n        .quota(quota)\n        .spaceConsumed(spaceConsumed)\n        .spaceQuota(spaceQuota)\n        .build();\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java",
        "oldMethodName": "aggregateContentSummary",
        "newMethodName": "aggregateContentSummary"
      }
    },
    "fb5b3dce6192265bce9b9d93ab663bdc5be8048e": {
      "type": "Yintroduced",
      "commitMessage": "Revert \"HDFS-13790. RBF: Move ClientProtocol APIs to its own module. Contributed by Chao Sun.\"\n\nThis reverts commit fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a.\n",
      "commitDate": "17/08/18 8:01 AM",
      "commitName": "fb5b3dce6192265bce9b9d93ab663bdc5be8048e",
      "commitAuthor": "Xiaoyu Yao",
      "diff": "@@ -0,0 +1,32 @@\n+  private ContentSummary aggregateContentSummary(\n+      Collection\u003cContentSummary\u003e summaries) {\n+    if (summaries.size() \u003d\u003d 1) {\n+      return summaries.iterator().next();\n+    }\n+\n+    long length \u003d 0;\n+    long fileCount \u003d 0;\n+    long directoryCount \u003d 0;\n+    long quota \u003d 0;\n+    long spaceConsumed \u003d 0;\n+    long spaceQuota \u003d 0;\n+\n+    for (ContentSummary summary : summaries) {\n+      length +\u003d summary.getLength();\n+      fileCount +\u003d summary.getFileCount();\n+      directoryCount +\u003d summary.getDirectoryCount();\n+      quota +\u003d summary.getQuota();\n+      spaceConsumed +\u003d summary.getSpaceConsumed();\n+      spaceQuota +\u003d summary.getSpaceQuota();\n+    }\n+\n+    ContentSummary ret \u003d new ContentSummary.Builder()\n+        .length(length)\n+        .fileCount(fileCount)\n+        .directoryCount(directoryCount)\n+        .quota(quota)\n+        .spaceConsumed(spaceConsumed)\n+        .spaceQuota(spaceQuota)\n+        .build();\n+    return ret;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private ContentSummary aggregateContentSummary(\n      Collection\u003cContentSummary\u003e summaries) {\n    if (summaries.size() \u003d\u003d 1) {\n      return summaries.iterator().next();\n    }\n\n    long length \u003d 0;\n    long fileCount \u003d 0;\n    long directoryCount \u003d 0;\n    long quota \u003d 0;\n    long spaceConsumed \u003d 0;\n    long spaceQuota \u003d 0;\n\n    for (ContentSummary summary : summaries) {\n      length +\u003d summary.getLength();\n      fileCount +\u003d summary.getFileCount();\n      directoryCount +\u003d summary.getDirectoryCount();\n      quota +\u003d summary.getQuota();\n      spaceConsumed +\u003d summary.getSpaceConsumed();\n      spaceQuota +\u003d summary.getSpaceQuota();\n    }\n\n    ContentSummary ret \u003d new ContentSummary.Builder()\n        .length(length)\n        .fileCount(fileCount)\n        .directoryCount(directoryCount)\n        .quota(quota)\n        .spaceConsumed(spaceConsumed)\n        .spaceQuota(spaceQuota)\n        .build();\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java"
    }
  }
}