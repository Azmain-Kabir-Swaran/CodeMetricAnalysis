{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HeartbeatManager.java",
  "functionName": "heartbeatCheck",
  "functionId": "heartbeatCheck",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
  "functionStartLine": 425,
  "functionEndLine": 513,
  "numCommitsSeen": 54,
  "timeTaken": 8739,
  "changeHistory": [
    "bd03053ea2f32ef982e37fbf2ffd679cb7dda797",
    "51950f149ecc0b6f03849865031b12cdb5eecd5d",
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
    "be7a0add8b6561d3c566237cc0370b06e7f32bb4",
    "4e7c6a653f108d44589f84d78a03d92ee0e8a3c3",
    "41980c56d3c01d7a0ddc7deea2d89b7f28026722",
    "d3a2fe280775e9320181b671d5951f06837bddad",
    "2a76cddcd53ab10a79372b09595bb6df4bb44e01",
    "8590564dc56195cb2caa245e3ee1c06eca3938d3",
    "2887bbb33cefaac0c548eb2450a1f8e3e60f5ea7",
    "8d724dd8b97cc4c10c03742eb359796c2f51b7a9",
    "9692cfc9ae2ac86c9a2d2b3ac9ca8f8b3bfc7c42",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "7fac946ac983e31613fd62836c8ac9c4a579210a",
    "969a263188f7015261719fe45fa1505121ebb80e",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "bd03053ea2f32ef982e37fbf2ffd679cb7dda797": "Ybodychange",
    "51950f149ecc0b6f03849865031b12cdb5eecd5d": "Ybodychange",
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": "Ybodychange",
    "be7a0add8b6561d3c566237cc0370b06e7f32bb4": "Ybodychange",
    "4e7c6a653f108d44589f84d78a03d92ee0e8a3c3": "Ybodychange",
    "41980c56d3c01d7a0ddc7deea2d89b7f28026722": "Ybodychange",
    "d3a2fe280775e9320181b671d5951f06837bddad": "Ybodychange",
    "2a76cddcd53ab10a79372b09595bb6df4bb44e01": "Ybodychange",
    "8590564dc56195cb2caa245e3ee1c06eca3938d3": "Ybodychange",
    "2887bbb33cefaac0c548eb2450a1f8e3e60f5ea7": "Ybodychange",
    "8d724dd8b97cc4c10c03742eb359796c2f51b7a9": "Ybodychange",
    "9692cfc9ae2ac86c9a2d2b3ac9ca8f8b3bfc7c42": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "7fac946ac983e31613fd62836c8ac9c4a579210a": "Ymultichange(Ymovefromfile,Ybodychange)",
    "969a263188f7015261719fe45fa1505121ebb80e": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "bd03053ea2f32ef982e37fbf2ffd679cb7dda797": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14968. Add ability to log stale datanodes. Contributed by Ahmed Hussein.\n",
      "commitDate": "22/01/20 7:14 AM",
      "commitName": "bd03053ea2f32ef982e37fbf2ffd679cb7dda797",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "19/02/19 5:01 PM",
      "commitNameOld": "51950f149ecc0b6f03849865031b12cdb5eecd5d",
      "commitAuthorOld": "Bharat Viswanadham",
      "daysBetweenCommits": 336.59,
      "commitsBetweenForRepo": 2222,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,89 @@\n   void heartbeatCheck() {\n     final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n     // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n     // for safe mode after taking the lock before removing a datanode.\n     if (namesystem.isInStartupSafeMode()) {\n       return;\n     }\n     boolean allAlive \u003d false;\n     while (!allAlive) {\n       // locate the first dead node.\n       DatanodeDescriptor dead \u003d null;\n \n       // locate the first failed storage that isn\u0027t on a dead node.\n       DatanodeStorageInfo failedStorage \u003d null;\n \n-      // check the number of stale nodes\n-      int numOfStaleNodes \u003d 0;\n+      // check the number of stale storages\n       int numOfStaleStorages \u003d 0;\n+      List\u003cDatanodeDescriptor\u003e staleNodes \u003d new ArrayList\u003c\u003e();\n       synchronized(this) {\n         for (DatanodeDescriptor d : datanodes) {\n           // check if an excessive GC pause has occurred\n           if (shouldAbortHeartbeatCheck(0)) {\n             return;\n           }\n           if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n             stats.incrExpiredHeartbeats();\n             dead \u003d d;\n+            // remove the node from stale list to adjust the stale list size\n+            // before setting the stale count of the DatanodeManager\n+            removeNodeFromStaleList(d);\n+          } else {\n+            if (d.isStale(dm.getStaleInterval())) {\n+              if (staleDataNodes.add(d)) {\n+                // the node is n\n+                staleNodes.add(d);\n+              }\n+            } else {\n+              // remove the node if it is no longer stale\n+              removeNodeFromStaleList(d, false);\n+            }\n           }\n-          if (d.isStale(dm.getStaleInterval())) {\n-            LOG.warn(String.format(\"Stale datanode {}.\"\n-                    + \" No heartbeat received since last {} milliseconds\"),\n-                    d.getName(), dm.getStaleInterval());\n-            numOfStaleNodes++;\n-          }\n+\n           DatanodeStorageInfo[] storageInfos \u003d d.getStorageInfos();\n           for(DatanodeStorageInfo storageInfo : storageInfos) {\n             if (storageInfo.areBlockContentsStale()) {\n               numOfStaleStorages++;\n             }\n \n             if (failedStorage \u003d\u003d null \u0026\u0026\n                 storageInfo.areBlocksOnFailedStorage() \u0026\u0026\n                 d !\u003d dead) {\n               failedStorage \u003d storageInfo;\n             }\n           }\n-\n         }\n         \n         // Set the number of stale nodes in the DatanodeManager\n-        dm.setNumStaleNodes(numOfStaleNodes);\n+        dm.setNumStaleNodes(staleDataNodes.size());\n         dm.setNumStaleStorages(numOfStaleStorages);\n       }\n \n+      // log nodes detected as stale since last heartBeat\n+      dumpStaleNodes(staleNodes);\n+\n       allAlive \u003d dead \u003d\u003d null \u0026\u0026 failedStorage \u003d\u003d null;\n       if (!allAlive \u0026\u0026 namesystem.isInStartupSafeMode()) {\n         return;\n       }\n+\n       if (dead !\u003d null) {\n         // acquire the fsnamesystem lock, and then remove the dead node.\n         namesystem.writeLock();\n         try {\n           dm.removeDeadDatanode(dead, !dead.isMaintenance());\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n       if (failedStorage !\u003d null) {\n         // acquire the fsnamesystem lock, and remove blocks on the storage.\n         namesystem.writeLock();\n         try {\n           blockManager.removeBlocksAssociatedTo(failedStorage);\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void heartbeatCheck() {\n    final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (namesystem.isInStartupSafeMode()) {\n      return;\n    }\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      // locate the first dead node.\n      DatanodeDescriptor dead \u003d null;\n\n      // locate the first failed storage that isn\u0027t on a dead node.\n      DatanodeStorageInfo failedStorage \u003d null;\n\n      // check the number of stale storages\n      int numOfStaleStorages \u003d 0;\n      List\u003cDatanodeDescriptor\u003e staleNodes \u003d new ArrayList\u003c\u003e();\n      synchronized(this) {\n        for (DatanodeDescriptor d : datanodes) {\n          // check if an excessive GC pause has occurred\n          if (shouldAbortHeartbeatCheck(0)) {\n            return;\n          }\n          if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n            stats.incrExpiredHeartbeats();\n            dead \u003d d;\n            // remove the node from stale list to adjust the stale list size\n            // before setting the stale count of the DatanodeManager\n            removeNodeFromStaleList(d);\n          } else {\n            if (d.isStale(dm.getStaleInterval())) {\n              if (staleDataNodes.add(d)) {\n                // the node is n\n                staleNodes.add(d);\n              }\n            } else {\n              // remove the node if it is no longer stale\n              removeNodeFromStaleList(d, false);\n            }\n          }\n\n          DatanodeStorageInfo[] storageInfos \u003d d.getStorageInfos();\n          for(DatanodeStorageInfo storageInfo : storageInfos) {\n            if (storageInfo.areBlockContentsStale()) {\n              numOfStaleStorages++;\n            }\n\n            if (failedStorage \u003d\u003d null \u0026\u0026\n                storageInfo.areBlocksOnFailedStorage() \u0026\u0026\n                d !\u003d dead) {\n              failedStorage \u003d storageInfo;\n            }\n          }\n        }\n        \n        // Set the number of stale nodes in the DatanodeManager\n        dm.setNumStaleNodes(staleDataNodes.size());\n        dm.setNumStaleStorages(numOfStaleStorages);\n      }\n\n      // log nodes detected as stale since last heartBeat\n      dumpStaleNodes(staleNodes);\n\n      allAlive \u003d dead \u003d\u003d null \u0026\u0026 failedStorage \u003d\u003d null;\n      if (!allAlive \u0026\u0026 namesystem.isInStartupSafeMode()) {\n        return;\n      }\n\n      if (dead !\u003d null) {\n        // acquire the fsnamesystem lock, and then remove the dead node.\n        namesystem.writeLock();\n        try {\n          dm.removeDeadDatanode(dead, !dead.isMaintenance());\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n      if (failedStorage !\u003d null) {\n        // acquire the fsnamesystem lock, and remove blocks on the storage.\n        namesystem.writeLock();\n        try {\n          blockManager.removeBlocksAssociatedTo(failedStorage);\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
      "extendedDetails": {}
    },
    "51950f149ecc0b6f03849865031b12cdb5eecd5d": {
      "type": "Ybodychange",
      "commitMessage": "Logging stale datanode information. Contributed by  Karthik Palanisamy.\n",
      "commitDate": "19/02/19 5:01 PM",
      "commitName": "51950f149ecc0b6f03849865031b12cdb5eecd5d",
      "commitAuthor": "Bharat Viswanadham",
      "commitDateOld": "05/11/18 11:02 AM",
      "commitNameOld": "f3f5e7ad005a88afad6fa09602073eaa450e21ed",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 106.25,
      "commitsBetweenForRepo": 720,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,75 +1,78 @@\n   void heartbeatCheck() {\n     final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n     // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n     // for safe mode after taking the lock before removing a datanode.\n     if (namesystem.isInStartupSafeMode()) {\n       return;\n     }\n     boolean allAlive \u003d false;\n     while (!allAlive) {\n       // locate the first dead node.\n       DatanodeDescriptor dead \u003d null;\n \n       // locate the first failed storage that isn\u0027t on a dead node.\n       DatanodeStorageInfo failedStorage \u003d null;\n \n       // check the number of stale nodes\n       int numOfStaleNodes \u003d 0;\n       int numOfStaleStorages \u003d 0;\n       synchronized(this) {\n         for (DatanodeDescriptor d : datanodes) {\n           // check if an excessive GC pause has occurred\n           if (shouldAbortHeartbeatCheck(0)) {\n             return;\n           }\n           if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n             stats.incrExpiredHeartbeats();\n             dead \u003d d;\n           }\n           if (d.isStale(dm.getStaleInterval())) {\n+            LOG.warn(String.format(\"Stale datanode {}.\"\n+                    + \" No heartbeat received since last {} milliseconds\"),\n+                    d.getName(), dm.getStaleInterval());\n             numOfStaleNodes++;\n           }\n           DatanodeStorageInfo[] storageInfos \u003d d.getStorageInfos();\n           for(DatanodeStorageInfo storageInfo : storageInfos) {\n             if (storageInfo.areBlockContentsStale()) {\n               numOfStaleStorages++;\n             }\n \n             if (failedStorage \u003d\u003d null \u0026\u0026\n                 storageInfo.areBlocksOnFailedStorage() \u0026\u0026\n                 d !\u003d dead) {\n               failedStorage \u003d storageInfo;\n             }\n           }\n \n         }\n         \n         // Set the number of stale nodes in the DatanodeManager\n         dm.setNumStaleNodes(numOfStaleNodes);\n         dm.setNumStaleStorages(numOfStaleStorages);\n       }\n \n       allAlive \u003d dead \u003d\u003d null \u0026\u0026 failedStorage \u003d\u003d null;\n       if (!allAlive \u0026\u0026 namesystem.isInStartupSafeMode()) {\n         return;\n       }\n       if (dead !\u003d null) {\n         // acquire the fsnamesystem lock, and then remove the dead node.\n         namesystem.writeLock();\n         try {\n           dm.removeDeadDatanode(dead, !dead.isMaintenance());\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n       if (failedStorage !\u003d null) {\n         // acquire the fsnamesystem lock, and remove blocks on the storage.\n         namesystem.writeLock();\n         try {\n           blockManager.removeBlocksAssociatedTo(failedStorage);\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void heartbeatCheck() {\n    final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (namesystem.isInStartupSafeMode()) {\n      return;\n    }\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      // locate the first dead node.\n      DatanodeDescriptor dead \u003d null;\n\n      // locate the first failed storage that isn\u0027t on a dead node.\n      DatanodeStorageInfo failedStorage \u003d null;\n\n      // check the number of stale nodes\n      int numOfStaleNodes \u003d 0;\n      int numOfStaleStorages \u003d 0;\n      synchronized(this) {\n        for (DatanodeDescriptor d : datanodes) {\n          // check if an excessive GC pause has occurred\n          if (shouldAbortHeartbeatCheck(0)) {\n            return;\n          }\n          if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n            stats.incrExpiredHeartbeats();\n            dead \u003d d;\n          }\n          if (d.isStale(dm.getStaleInterval())) {\n            LOG.warn(String.format(\"Stale datanode {}.\"\n                    + \" No heartbeat received since last {} milliseconds\"),\n                    d.getName(), dm.getStaleInterval());\n            numOfStaleNodes++;\n          }\n          DatanodeStorageInfo[] storageInfos \u003d d.getStorageInfos();\n          for(DatanodeStorageInfo storageInfo : storageInfos) {\n            if (storageInfo.areBlockContentsStale()) {\n              numOfStaleStorages++;\n            }\n\n            if (failedStorage \u003d\u003d null \u0026\u0026\n                storageInfo.areBlocksOnFailedStorage() \u0026\u0026\n                d !\u003d dead) {\n              failedStorage \u003d storageInfo;\n            }\n          }\n\n        }\n        \n        // Set the number of stale nodes in the DatanodeManager\n        dm.setNumStaleNodes(numOfStaleNodes);\n        dm.setNumStaleStorages(numOfStaleStorages);\n      }\n\n      allAlive \u003d dead \u003d\u003d null \u0026\u0026 failedStorage \u003d\u003d null;\n      if (!allAlive \u0026\u0026 namesystem.isInStartupSafeMode()) {\n        return;\n      }\n      if (dead !\u003d null) {\n        // acquire the fsnamesystem lock, and then remove the dead node.\n        namesystem.writeLock();\n        try {\n          dm.removeDeadDatanode(dead, !dead.isMaintenance());\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n      if (failedStorage !\u003d null) {\n        // acquire the fsnamesystem lock, and remove blocks on the storage.\n        namesystem.writeLock();\n        try {\n          blockManager.removeBlocksAssociatedTo(failedStorage);\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
      "extendedDetails": {}
    },
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
      "commitDate": "17/10/16 5:45 PM",
      "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
      "commitAuthor": "Ming Ma",
      "commitDateOld": "30/08/16 2:00 PM",
      "commitNameOld": "9dcbdbdb5a34d85910707f81ebc1bb1f81c99978",
      "commitAuthorOld": "Ming Ma",
      "daysBetweenCommits": 48.16,
      "commitsBetweenForRepo": 304,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,75 +1,75 @@\n   void heartbeatCheck() {\n     final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n     // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n     // for safe mode after taking the lock before removing a datanode.\n     if (namesystem.isInStartupSafeMode()) {\n       return;\n     }\n     boolean allAlive \u003d false;\n     while (!allAlive) {\n       // locate the first dead node.\n-      DatanodeID dead \u003d null;\n+      DatanodeDescriptor dead \u003d null;\n \n       // locate the first failed storage that isn\u0027t on a dead node.\n       DatanodeStorageInfo failedStorage \u003d null;\n \n       // check the number of stale nodes\n       int numOfStaleNodes \u003d 0;\n       int numOfStaleStorages \u003d 0;\n       synchronized(this) {\n         for (DatanodeDescriptor d : datanodes) {\n           // check if an excessive GC pause has occurred\n           if (shouldAbortHeartbeatCheck(0)) {\n             return;\n           }\n           if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n             stats.incrExpiredHeartbeats();\n             dead \u003d d;\n           }\n           if (d.isStale(dm.getStaleInterval())) {\n             numOfStaleNodes++;\n           }\n           DatanodeStorageInfo[] storageInfos \u003d d.getStorageInfos();\n           for(DatanodeStorageInfo storageInfo : storageInfos) {\n             if (storageInfo.areBlockContentsStale()) {\n               numOfStaleStorages++;\n             }\n \n             if (failedStorage \u003d\u003d null \u0026\u0026\n                 storageInfo.areBlocksOnFailedStorage() \u0026\u0026\n                 d !\u003d dead) {\n               failedStorage \u003d storageInfo;\n             }\n           }\n \n         }\n         \n         // Set the number of stale nodes in the DatanodeManager\n         dm.setNumStaleNodes(numOfStaleNodes);\n         dm.setNumStaleStorages(numOfStaleStorages);\n       }\n \n       allAlive \u003d dead \u003d\u003d null \u0026\u0026 failedStorage \u003d\u003d null;\n       if (!allAlive \u0026\u0026 namesystem.isInStartupSafeMode()) {\n         return;\n       }\n       if (dead !\u003d null) {\n         // acquire the fsnamesystem lock, and then remove the dead node.\n         namesystem.writeLock();\n         try {\n-          dm.removeDeadDatanode(dead);\n+          dm.removeDeadDatanode(dead, !dead.isMaintenance());\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n       if (failedStorage !\u003d null) {\n         // acquire the fsnamesystem lock, and remove blocks on the storage.\n         namesystem.writeLock();\n         try {\n           blockManager.removeBlocksAssociatedTo(failedStorage);\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void heartbeatCheck() {\n    final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (namesystem.isInStartupSafeMode()) {\n      return;\n    }\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      // locate the first dead node.\n      DatanodeDescriptor dead \u003d null;\n\n      // locate the first failed storage that isn\u0027t on a dead node.\n      DatanodeStorageInfo failedStorage \u003d null;\n\n      // check the number of stale nodes\n      int numOfStaleNodes \u003d 0;\n      int numOfStaleStorages \u003d 0;\n      synchronized(this) {\n        for (DatanodeDescriptor d : datanodes) {\n          // check if an excessive GC pause has occurred\n          if (shouldAbortHeartbeatCheck(0)) {\n            return;\n          }\n          if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n            stats.incrExpiredHeartbeats();\n            dead \u003d d;\n          }\n          if (d.isStale(dm.getStaleInterval())) {\n            numOfStaleNodes++;\n          }\n          DatanodeStorageInfo[] storageInfos \u003d d.getStorageInfos();\n          for(DatanodeStorageInfo storageInfo : storageInfos) {\n            if (storageInfo.areBlockContentsStale()) {\n              numOfStaleStorages++;\n            }\n\n            if (failedStorage \u003d\u003d null \u0026\u0026\n                storageInfo.areBlocksOnFailedStorage() \u0026\u0026\n                d !\u003d dead) {\n              failedStorage \u003d storageInfo;\n            }\n          }\n\n        }\n        \n        // Set the number of stale nodes in the DatanodeManager\n        dm.setNumStaleNodes(numOfStaleNodes);\n        dm.setNumStaleStorages(numOfStaleStorages);\n      }\n\n      allAlive \u003d dead \u003d\u003d null \u0026\u0026 failedStorage \u003d\u003d null;\n      if (!allAlive \u0026\u0026 namesystem.isInStartupSafeMode()) {\n        return;\n      }\n      if (dead !\u003d null) {\n        // acquire the fsnamesystem lock, and then remove the dead node.\n        namesystem.writeLock();\n        try {\n          dm.removeDeadDatanode(dead, !dead.isMaintenance());\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n      if (failedStorage !\u003d null) {\n        // acquire the fsnamesystem lock, and remove blocks on the storage.\n        namesystem.writeLock();\n        try {\n          blockManager.removeBlocksAssociatedTo(failedStorage);\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
      "extendedDetails": {}
    },
    "be7a0add8b6561d3c566237cc0370b06e7f32bb4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9223. Code cleanup for DatanodeDescriptor and HeartbeatManager. Contributed by Jing Zhao.\n",
      "commitDate": "14/10/15 4:17 PM",
      "commitName": "be7a0add8b6561d3c566237cc0370b06e7f32bb4",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "25/09/15 3:25 PM",
      "commitNameOld": "4e7c6a653f108d44589f84d78a03d92ee0e8a3c3",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 19.04,
      "commitsBetweenForRepo": 140,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,82 +1,75 @@\n   void heartbeatCheck() {\n     final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n     // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n     // for safe mode after taking the lock before removing a datanode.\n     if (namesystem.isInStartupSafeMode()) {\n       return;\n     }\n     boolean allAlive \u003d false;\n     while (!allAlive) {\n       // locate the first dead node.\n       DatanodeID dead \u003d null;\n \n       // locate the first failed storage that isn\u0027t on a dead node.\n       DatanodeStorageInfo failedStorage \u003d null;\n \n       // check the number of stale nodes\n       int numOfStaleNodes \u003d 0;\n       int numOfStaleStorages \u003d 0;\n       synchronized(this) {\n         for (DatanodeDescriptor d : datanodes) {\n           // check if an excessive GC pause has occurred\n           if (shouldAbortHeartbeatCheck(0)) {\n             return;\n           }\n           if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n             stats.incrExpiredHeartbeats();\n             dead \u003d d;\n           }\n           if (d.isStale(dm.getStaleInterval())) {\n             numOfStaleNodes++;\n           }\n           DatanodeStorageInfo[] storageInfos \u003d d.getStorageInfos();\n           for(DatanodeStorageInfo storageInfo : storageInfos) {\n             if (storageInfo.areBlockContentsStale()) {\n               numOfStaleStorages++;\n             }\n \n             if (failedStorage \u003d\u003d null \u0026\u0026\n                 storageInfo.areBlocksOnFailedStorage() \u0026\u0026\n                 d !\u003d dead) {\n               failedStorage \u003d storageInfo;\n             }\n           }\n \n         }\n         \n         // Set the number of stale nodes in the DatanodeManager\n         dm.setNumStaleNodes(numOfStaleNodes);\n         dm.setNumStaleStorages(numOfStaleStorages);\n       }\n \n       allAlive \u003d dead \u003d\u003d null \u0026\u0026 failedStorage \u003d\u003d null;\n+      if (!allAlive \u0026\u0026 namesystem.isInStartupSafeMode()) {\n+        return;\n+      }\n       if (dead !\u003d null) {\n         // acquire the fsnamesystem lock, and then remove the dead node.\n         namesystem.writeLock();\n         try {\n-          if (namesystem.isInStartupSafeMode()) {\n-            return;\n-          }\n-          synchronized(this) {\n-            dm.removeDeadDatanode(dead);\n-          }\n+          dm.removeDeadDatanode(dead);\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n       if (failedStorage !\u003d null) {\n         // acquire the fsnamesystem lock, and remove blocks on the storage.\n         namesystem.writeLock();\n         try {\n-          if (namesystem.isInStartupSafeMode()) {\n-            return;\n-          }\n-          synchronized(this) {\n-            blockManager.removeBlocksAssociatedTo(failedStorage);\n-          }\n+          blockManager.removeBlocksAssociatedTo(failedStorage);\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void heartbeatCheck() {\n    final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (namesystem.isInStartupSafeMode()) {\n      return;\n    }\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      // locate the first dead node.\n      DatanodeID dead \u003d null;\n\n      // locate the first failed storage that isn\u0027t on a dead node.\n      DatanodeStorageInfo failedStorage \u003d null;\n\n      // check the number of stale nodes\n      int numOfStaleNodes \u003d 0;\n      int numOfStaleStorages \u003d 0;\n      synchronized(this) {\n        for (DatanodeDescriptor d : datanodes) {\n          // check if an excessive GC pause has occurred\n          if (shouldAbortHeartbeatCheck(0)) {\n            return;\n          }\n          if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n            stats.incrExpiredHeartbeats();\n            dead \u003d d;\n          }\n          if (d.isStale(dm.getStaleInterval())) {\n            numOfStaleNodes++;\n          }\n          DatanodeStorageInfo[] storageInfos \u003d d.getStorageInfos();\n          for(DatanodeStorageInfo storageInfo : storageInfos) {\n            if (storageInfo.areBlockContentsStale()) {\n              numOfStaleStorages++;\n            }\n\n            if (failedStorage \u003d\u003d null \u0026\u0026\n                storageInfo.areBlocksOnFailedStorage() \u0026\u0026\n                d !\u003d dead) {\n              failedStorage \u003d storageInfo;\n            }\n          }\n\n        }\n        \n        // Set the number of stale nodes in the DatanodeManager\n        dm.setNumStaleNodes(numOfStaleNodes);\n        dm.setNumStaleStorages(numOfStaleStorages);\n      }\n\n      allAlive \u003d dead \u003d\u003d null \u0026\u0026 failedStorage \u003d\u003d null;\n      if (!allAlive \u0026\u0026 namesystem.isInStartupSafeMode()) {\n        return;\n      }\n      if (dead !\u003d null) {\n        // acquire the fsnamesystem lock, and then remove the dead node.\n        namesystem.writeLock();\n        try {\n          dm.removeDeadDatanode(dead);\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n      if (failedStorage !\u003d null) {\n        // acquire the fsnamesystem lock, and remove blocks on the storage.\n        namesystem.writeLock();\n        try {\n          blockManager.removeBlocksAssociatedTo(failedStorage);\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
      "extendedDetails": {}
    },
    "4e7c6a653f108d44589f84d78a03d92ee0e8a3c3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9107. Prevent NN\u0027s unrecoverable death spiral after full GC (Daryn Sharp via Colin P. McCabe)\n\nChange-Id: Ib8420310e515bb98091de86ea5c4be354878d43c\n",
      "commitDate": "25/09/15 3:25 PM",
      "commitName": "4e7c6a653f108d44589f84d78a03d92ee0e8a3c3",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "29/06/15 11:00 AM",
      "commitNameOld": "d3fed8e653ed9e18d3a29a11c4b24a628ac770bb",
      "commitAuthorOld": "Benoy Antony",
      "daysBetweenCommits": 88.18,
      "commitsBetweenForRepo": 536,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,82 @@\n   void heartbeatCheck() {\n     final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n     // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n     // for safe mode after taking the lock before removing a datanode.\n     if (namesystem.isInStartupSafeMode()) {\n       return;\n     }\n     boolean allAlive \u003d false;\n     while (!allAlive) {\n       // locate the first dead node.\n       DatanodeID dead \u003d null;\n \n       // locate the first failed storage that isn\u0027t on a dead node.\n       DatanodeStorageInfo failedStorage \u003d null;\n \n       // check the number of stale nodes\n       int numOfStaleNodes \u003d 0;\n       int numOfStaleStorages \u003d 0;\n       synchronized(this) {\n         for (DatanodeDescriptor d : datanodes) {\n+          // check if an excessive GC pause has occurred\n+          if (shouldAbortHeartbeatCheck(0)) {\n+            return;\n+          }\n           if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n             stats.incrExpiredHeartbeats();\n             dead \u003d d;\n           }\n           if (d.isStale(dm.getStaleInterval())) {\n             numOfStaleNodes++;\n           }\n           DatanodeStorageInfo[] storageInfos \u003d d.getStorageInfos();\n           for(DatanodeStorageInfo storageInfo : storageInfos) {\n             if (storageInfo.areBlockContentsStale()) {\n               numOfStaleStorages++;\n             }\n \n             if (failedStorage \u003d\u003d null \u0026\u0026\n                 storageInfo.areBlocksOnFailedStorage() \u0026\u0026\n                 d !\u003d dead) {\n               failedStorage \u003d storageInfo;\n             }\n           }\n \n         }\n         \n         // Set the number of stale nodes in the DatanodeManager\n         dm.setNumStaleNodes(numOfStaleNodes);\n         dm.setNumStaleStorages(numOfStaleStorages);\n       }\n \n       allAlive \u003d dead \u003d\u003d null \u0026\u0026 failedStorage \u003d\u003d null;\n       if (dead !\u003d null) {\n         // acquire the fsnamesystem lock, and then remove the dead node.\n         namesystem.writeLock();\n         try {\n           if (namesystem.isInStartupSafeMode()) {\n             return;\n           }\n           synchronized(this) {\n             dm.removeDeadDatanode(dead);\n           }\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n       if (failedStorage !\u003d null) {\n         // acquire the fsnamesystem lock, and remove blocks on the storage.\n         namesystem.writeLock();\n         try {\n           if (namesystem.isInStartupSafeMode()) {\n             return;\n           }\n           synchronized(this) {\n             blockManager.removeBlocksAssociatedTo(failedStorage);\n           }\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void heartbeatCheck() {\n    final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (namesystem.isInStartupSafeMode()) {\n      return;\n    }\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      // locate the first dead node.\n      DatanodeID dead \u003d null;\n\n      // locate the first failed storage that isn\u0027t on a dead node.\n      DatanodeStorageInfo failedStorage \u003d null;\n\n      // check the number of stale nodes\n      int numOfStaleNodes \u003d 0;\n      int numOfStaleStorages \u003d 0;\n      synchronized(this) {\n        for (DatanodeDescriptor d : datanodes) {\n          // check if an excessive GC pause has occurred\n          if (shouldAbortHeartbeatCheck(0)) {\n            return;\n          }\n          if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n            stats.incrExpiredHeartbeats();\n            dead \u003d d;\n          }\n          if (d.isStale(dm.getStaleInterval())) {\n            numOfStaleNodes++;\n          }\n          DatanodeStorageInfo[] storageInfos \u003d d.getStorageInfos();\n          for(DatanodeStorageInfo storageInfo : storageInfos) {\n            if (storageInfo.areBlockContentsStale()) {\n              numOfStaleStorages++;\n            }\n\n            if (failedStorage \u003d\u003d null \u0026\u0026\n                storageInfo.areBlocksOnFailedStorage() \u0026\u0026\n                d !\u003d dead) {\n              failedStorage \u003d storageInfo;\n            }\n          }\n\n        }\n        \n        // Set the number of stale nodes in the DatanodeManager\n        dm.setNumStaleNodes(numOfStaleNodes);\n        dm.setNumStaleStorages(numOfStaleStorages);\n      }\n\n      allAlive \u003d dead \u003d\u003d null \u0026\u0026 failedStorage \u003d\u003d null;\n      if (dead !\u003d null) {\n        // acquire the fsnamesystem lock, and then remove the dead node.\n        namesystem.writeLock();\n        try {\n          if (namesystem.isInStartupSafeMode()) {\n            return;\n          }\n          synchronized(this) {\n            dm.removeDeadDatanode(dead);\n          }\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n      if (failedStorage !\u003d null) {\n        // acquire the fsnamesystem lock, and remove blocks on the storage.\n        namesystem.writeLock();\n        try {\n          if (namesystem.isInStartupSafeMode()) {\n            return;\n          }\n          synchronized(this) {\n            blockManager.removeBlocksAssociatedTo(failedStorage);\n          }\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
      "extendedDetails": {}
    },
    "41980c56d3c01d7a0ddc7deea2d89b7f28026722": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7208. NN doesn\u0027t schedule replication when a DN storage fails.  Contributed by Ming Ma\n",
      "commitDate": "15/10/14 8:44 PM",
      "commitName": "41980c56d3c01d7a0ddc7deea2d89b7f28026722",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "07/08/14 10:41 PM",
      "commitNameOld": "d3a2fe280775e9320181b671d5951f06837bddad",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 68.92,
      "commitsBetweenForRepo": 692,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,78 @@\n   void heartbeatCheck() {\n     final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n     // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n     // for safe mode after taking the lock before removing a datanode.\n     if (namesystem.isInStartupSafeMode()) {\n       return;\n     }\n     boolean allAlive \u003d false;\n     while (!allAlive) {\n       // locate the first dead node.\n       DatanodeID dead \u003d null;\n+\n+      // locate the first failed storage that isn\u0027t on a dead node.\n+      DatanodeStorageInfo failedStorage \u003d null;\n+\n       // check the number of stale nodes\n       int numOfStaleNodes \u003d 0;\n       int numOfStaleStorages \u003d 0;\n       synchronized(this) {\n         for (DatanodeDescriptor d : datanodes) {\n           if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n             stats.incrExpiredHeartbeats();\n             dead \u003d d;\n           }\n           if (d.isStale(dm.getStaleInterval())) {\n             numOfStaleNodes++;\n           }\n           DatanodeStorageInfo[] storageInfos \u003d d.getStorageInfos();\n           for(DatanodeStorageInfo storageInfo : storageInfos) {\n             if (storageInfo.areBlockContentsStale()) {\n               numOfStaleStorages++;\n             }\n+\n+            if (failedStorage \u003d\u003d null \u0026\u0026\n+                storageInfo.areBlocksOnFailedStorage() \u0026\u0026\n+                d !\u003d dead) {\n+              failedStorage \u003d storageInfo;\n+            }\n           }\n+\n         }\n         \n         // Set the number of stale nodes in the DatanodeManager\n         dm.setNumStaleNodes(numOfStaleNodes);\n         dm.setNumStaleStorages(numOfStaleStorages);\n       }\n \n-      allAlive \u003d dead \u003d\u003d null;\n-      if (!allAlive) {\n+      allAlive \u003d dead \u003d\u003d null \u0026\u0026 failedStorage \u003d\u003d null;\n+      if (dead !\u003d null) {\n         // acquire the fsnamesystem lock, and then remove the dead node.\n         namesystem.writeLock();\n         try {\n           if (namesystem.isInStartupSafeMode()) {\n             return;\n           }\n           synchronized(this) {\n             dm.removeDeadDatanode(dead);\n           }\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n+      if (failedStorage !\u003d null) {\n+        // acquire the fsnamesystem lock, and remove blocks on the storage.\n+        namesystem.writeLock();\n+        try {\n+          if (namesystem.isInStartupSafeMode()) {\n+            return;\n+          }\n+          synchronized(this) {\n+            blockManager.removeBlocksAssociatedTo(failedStorage);\n+          }\n+        } finally {\n+          namesystem.writeUnlock();\n+        }\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void heartbeatCheck() {\n    final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (namesystem.isInStartupSafeMode()) {\n      return;\n    }\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      // locate the first dead node.\n      DatanodeID dead \u003d null;\n\n      // locate the first failed storage that isn\u0027t on a dead node.\n      DatanodeStorageInfo failedStorage \u003d null;\n\n      // check the number of stale nodes\n      int numOfStaleNodes \u003d 0;\n      int numOfStaleStorages \u003d 0;\n      synchronized(this) {\n        for (DatanodeDescriptor d : datanodes) {\n          if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n            stats.incrExpiredHeartbeats();\n            dead \u003d d;\n          }\n          if (d.isStale(dm.getStaleInterval())) {\n            numOfStaleNodes++;\n          }\n          DatanodeStorageInfo[] storageInfos \u003d d.getStorageInfos();\n          for(DatanodeStorageInfo storageInfo : storageInfos) {\n            if (storageInfo.areBlockContentsStale()) {\n              numOfStaleStorages++;\n            }\n\n            if (failedStorage \u003d\u003d null \u0026\u0026\n                storageInfo.areBlocksOnFailedStorage() \u0026\u0026\n                d !\u003d dead) {\n              failedStorage \u003d storageInfo;\n            }\n          }\n\n        }\n        \n        // Set the number of stale nodes in the DatanodeManager\n        dm.setNumStaleNodes(numOfStaleNodes);\n        dm.setNumStaleStorages(numOfStaleStorages);\n      }\n\n      allAlive \u003d dead \u003d\u003d null \u0026\u0026 failedStorage \u003d\u003d null;\n      if (dead !\u003d null) {\n        // acquire the fsnamesystem lock, and then remove the dead node.\n        namesystem.writeLock();\n        try {\n          if (namesystem.isInStartupSafeMode()) {\n            return;\n          }\n          synchronized(this) {\n            dm.removeDeadDatanode(dead);\n          }\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n      if (failedStorage !\u003d null) {\n        // acquire the fsnamesystem lock, and remove blocks on the storage.\n        namesystem.writeLock();\n        try {\n          if (namesystem.isInStartupSafeMode()) {\n            return;\n          }\n          synchronized(this) {\n            blockManager.removeBlocksAssociatedTo(failedStorage);\n          }\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
      "extendedDetails": {}
    },
    "d3a2fe280775e9320181b671d5951f06837bddad": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6772. Get DN storages out of blockContentsStale state faster after NN restarts. (Contributed by Ming Ma)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616680 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/14 10:41 PM",
      "commitName": "d3a2fe280775e9320181b671d5951f06837bddad",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "18/07/14 10:58 AM",
      "commitNameOld": "551024915d487957d9e829493ab319c8e31dfa81",
      "commitAuthorOld": "Daryn Sharp",
      "daysBetweenCommits": 20.49,
      "commitsBetweenForRepo": 147,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,45 +1,53 @@\n   void heartbeatCheck() {\n     final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n     // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n     // for safe mode after taking the lock before removing a datanode.\n     if (namesystem.isInStartupSafeMode()) {\n       return;\n     }\n     boolean allAlive \u003d false;\n     while (!allAlive) {\n       // locate the first dead node.\n       DatanodeID dead \u003d null;\n       // check the number of stale nodes\n       int numOfStaleNodes \u003d 0;\n+      int numOfStaleStorages \u003d 0;\n       synchronized(this) {\n         for (DatanodeDescriptor d : datanodes) {\n           if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n             stats.incrExpiredHeartbeats();\n             dead \u003d d;\n           }\n           if (d.isStale(dm.getStaleInterval())) {\n             numOfStaleNodes++;\n           }\n+          DatanodeStorageInfo[] storageInfos \u003d d.getStorageInfos();\n+          for(DatanodeStorageInfo storageInfo : storageInfos) {\n+            if (storageInfo.areBlockContentsStale()) {\n+              numOfStaleStorages++;\n+            }\n+          }\n         }\n         \n         // Set the number of stale nodes in the DatanodeManager\n         dm.setNumStaleNodes(numOfStaleNodes);\n+        dm.setNumStaleStorages(numOfStaleStorages);\n       }\n \n       allAlive \u003d dead \u003d\u003d null;\n       if (!allAlive) {\n         // acquire the fsnamesystem lock, and then remove the dead node.\n         namesystem.writeLock();\n         try {\n           if (namesystem.isInStartupSafeMode()) {\n             return;\n           }\n           synchronized(this) {\n             dm.removeDeadDatanode(dead);\n           }\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void heartbeatCheck() {\n    final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (namesystem.isInStartupSafeMode()) {\n      return;\n    }\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      // locate the first dead node.\n      DatanodeID dead \u003d null;\n      // check the number of stale nodes\n      int numOfStaleNodes \u003d 0;\n      int numOfStaleStorages \u003d 0;\n      synchronized(this) {\n        for (DatanodeDescriptor d : datanodes) {\n          if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n            stats.incrExpiredHeartbeats();\n            dead \u003d d;\n          }\n          if (d.isStale(dm.getStaleInterval())) {\n            numOfStaleNodes++;\n          }\n          DatanodeStorageInfo[] storageInfos \u003d d.getStorageInfos();\n          for(DatanodeStorageInfo storageInfo : storageInfos) {\n            if (storageInfo.areBlockContentsStale()) {\n              numOfStaleStorages++;\n            }\n          }\n        }\n        \n        // Set the number of stale nodes in the DatanodeManager\n        dm.setNumStaleNodes(numOfStaleNodes);\n        dm.setNumStaleStorages(numOfStaleStorages);\n      }\n\n      allAlive \u003d dead \u003d\u003d null;\n      if (!allAlive) {\n        // acquire the fsnamesystem lock, and then remove the dead node.\n        namesystem.writeLock();\n        try {\n          if (namesystem.isInStartupSafeMode()) {\n            return;\n          }\n          synchronized(this) {\n            dm.removeDeadDatanode(dead);\n          }\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
      "extendedDetails": {}
    },
    "2a76cddcd53ab10a79372b09595bb6df4bb44e01": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4832. Namenode doesn\u0027t change the number of missing blocks in safemode when DNs rejoin or leave. Contributed by Ravi Prakash.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1490803 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/06/13 1:01 PM",
      "commitName": "2a76cddcd53ab10a79372b09595bb6df4bb44e01",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "02/02/13 2:18 PM",
      "commitNameOld": "8590564dc56195cb2caa245e3ee1c06eca3938d3",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 124.9,
      "commitsBetweenForRepo": 724,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,45 +1,45 @@\n   void heartbeatCheck() {\n     final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n     // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n     // for safe mode after taking the lock before removing a datanode.\n-    if (namesystem.isInSafeMode()) {\n+    if (namesystem.isInStartupSafeMode()) {\n       return;\n     }\n     boolean allAlive \u003d false;\n     while (!allAlive) {\n       // locate the first dead node.\n       DatanodeID dead \u003d null;\n       // check the number of stale nodes\n       int numOfStaleNodes \u003d 0;\n       synchronized(this) {\n         for (DatanodeDescriptor d : datanodes) {\n           if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n             stats.incrExpiredHeartbeats();\n             dead \u003d d;\n           }\n           if (d.isStale(dm.getStaleInterval())) {\n             numOfStaleNodes++;\n           }\n         }\n         \n         // Set the number of stale nodes in the DatanodeManager\n         dm.setNumStaleNodes(numOfStaleNodes);\n       }\n \n       allAlive \u003d dead \u003d\u003d null;\n       if (!allAlive) {\n         // acquire the fsnamesystem lock, and then remove the dead node.\n         namesystem.writeLock();\n         try {\n-          if (namesystem.isInSafeMode()) {\n+          if (namesystem.isInStartupSafeMode()) {\n             return;\n           }\n           synchronized(this) {\n             dm.removeDeadDatanode(dead);\n           }\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void heartbeatCheck() {\n    final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (namesystem.isInStartupSafeMode()) {\n      return;\n    }\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      // locate the first dead node.\n      DatanodeID dead \u003d null;\n      // check the number of stale nodes\n      int numOfStaleNodes \u003d 0;\n      synchronized(this) {\n        for (DatanodeDescriptor d : datanodes) {\n          if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n            stats.incrExpiredHeartbeats();\n            dead \u003d d;\n          }\n          if (d.isStale(dm.getStaleInterval())) {\n            numOfStaleNodes++;\n          }\n        }\n        \n        // Set the number of stale nodes in the DatanodeManager\n        dm.setNumStaleNodes(numOfStaleNodes);\n      }\n\n      allAlive \u003d dead \u003d\u003d null;\n      if (!allAlive) {\n        // acquire the fsnamesystem lock, and then remove the dead node.\n        namesystem.writeLock();\n        try {\n          if (namesystem.isInStartupSafeMode()) {\n            return;\n          }\n          synchronized(this) {\n            dm.removeDeadDatanode(dead);\n          }\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
      "extendedDetails": {}
    },
    "8590564dc56195cb2caa245e3ee1c06eca3938d3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4350. Make enabling of stale marking on read and write paths independent. Contributed by Andrew Wang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1441819 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/02/13 2:18 PM",
      "commitName": "8590564dc56195cb2caa245e3ee1c06eca3938d3",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "11/10/12 11:08 AM",
      "commitNameOld": "2887bbb33cefaac0c548eb2450a1f8e3e60f5ea7",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 114.17,
      "commitsBetweenForRepo": 542,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,61 +1,45 @@\n   void heartbeatCheck() {\n     final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n     // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n     // for safe mode after taking the lock before removing a datanode.\n     if (namesystem.isInSafeMode()) {\n       return;\n     }\n-    boolean checkStaleNodes \u003d dm.isCheckingForStaleDataNodes();\n     boolean allAlive \u003d false;\n     while (!allAlive) {\n       // locate the first dead node.\n       DatanodeID dead \u003d null;\n       // check the number of stale nodes\n       int numOfStaleNodes \u003d 0;\n       synchronized(this) {\n         for (DatanodeDescriptor d : datanodes) {\n           if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n             stats.incrExpiredHeartbeats();\n             dead \u003d d;\n-            if (!checkStaleNodes) {\n-              break;\n-            }\n           }\n-          if (checkStaleNodes \u0026\u0026 \n-              d.isStale(dm.getStaleInterval())) {\n+          if (d.isStale(dm.getStaleInterval())) {\n             numOfStaleNodes++;\n           }\n         }\n         \n-        // Change whether to avoid using stale datanodes for writing\n-        // based on proportion of stale datanodes\n-        if (checkStaleNodes) {\n-          dm.setNumStaleNodes(numOfStaleNodes);\n-          if (numOfStaleNodes \u003e \n-                datanodes.size() * ratioUseStaleDataNodesForWrite) {\n-            dm.setAvoidStaleDataNodesForWrite(false);\n-          } else {\n-            if (this.initialAvoidWriteStaleNodes) {\n-              dm.setAvoidStaleDataNodesForWrite(true);\n-            }\n-          }\n-        }\n+        // Set the number of stale nodes in the DatanodeManager\n+        dm.setNumStaleNodes(numOfStaleNodes);\n       }\n \n       allAlive \u003d dead \u003d\u003d null;\n       if (!allAlive) {\n         // acquire the fsnamesystem lock, and then remove the dead node.\n         namesystem.writeLock();\n         try {\n           if (namesystem.isInSafeMode()) {\n             return;\n           }\n           synchronized(this) {\n             dm.removeDeadDatanode(dead);\n           }\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void heartbeatCheck() {\n    final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (namesystem.isInSafeMode()) {\n      return;\n    }\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      // locate the first dead node.\n      DatanodeID dead \u003d null;\n      // check the number of stale nodes\n      int numOfStaleNodes \u003d 0;\n      synchronized(this) {\n        for (DatanodeDescriptor d : datanodes) {\n          if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n            stats.incrExpiredHeartbeats();\n            dead \u003d d;\n          }\n          if (d.isStale(dm.getStaleInterval())) {\n            numOfStaleNodes++;\n          }\n        }\n        \n        // Set the number of stale nodes in the DatanodeManager\n        dm.setNumStaleNodes(numOfStaleNodes);\n      }\n\n      allAlive \u003d dead \u003d\u003d null;\n      if (!allAlive) {\n        // acquire the fsnamesystem lock, and then remove the dead node.\n        namesystem.writeLock();\n        try {\n          if (namesystem.isInSafeMode()) {\n            return;\n          }\n          synchronized(this) {\n            dm.removeDeadDatanode(dead);\n          }\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
      "extendedDetails": {}
    },
    "2887bbb33cefaac0c548eb2450a1f8e3e60f5ea7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3912. Detect and avoid stale datanodes for writes. Contributed by Jing Zhao\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1397211 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/10/12 11:08 AM",
      "commitName": "2887bbb33cefaac0c548eb2450a1f8e3e60f5ea7",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "11/09/12 9:10 PM",
      "commitNameOld": "414abe69183a39b38c8f8936785dce3e4774f4ca",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 29.58,
      "commitsBetweenForRepo": 158,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,61 @@\n   void heartbeatCheck() {\n     final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n     // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n     // for safe mode after taking the lock before removing a datanode.\n     if (namesystem.isInSafeMode()) {\n       return;\n     }\n+    boolean checkStaleNodes \u003d dm.isCheckingForStaleDataNodes();\n     boolean allAlive \u003d false;\n     while (!allAlive) {\n       // locate the first dead node.\n       DatanodeID dead \u003d null;\n+      // check the number of stale nodes\n+      int numOfStaleNodes \u003d 0;\n       synchronized(this) {\n         for (DatanodeDescriptor d : datanodes) {\n-          if (dm.isDatanodeDead(d)) {\n+          if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n             stats.incrExpiredHeartbeats();\n             dead \u003d d;\n-            break;\n+            if (!checkStaleNodes) {\n+              break;\n+            }\n+          }\n+          if (checkStaleNodes \u0026\u0026 \n+              d.isStale(dm.getStaleInterval())) {\n+            numOfStaleNodes++;\n+          }\n+        }\n+        \n+        // Change whether to avoid using stale datanodes for writing\n+        // based on proportion of stale datanodes\n+        if (checkStaleNodes) {\n+          dm.setNumStaleNodes(numOfStaleNodes);\n+          if (numOfStaleNodes \u003e \n+                datanodes.size() * ratioUseStaleDataNodesForWrite) {\n+            dm.setAvoidStaleDataNodesForWrite(false);\n+          } else {\n+            if (this.initialAvoidWriteStaleNodes) {\n+              dm.setAvoidStaleDataNodesForWrite(true);\n+            }\n           }\n         }\n       }\n \n       allAlive \u003d dead \u003d\u003d null;\n       if (!allAlive) {\n         // acquire the fsnamesystem lock, and then remove the dead node.\n         namesystem.writeLock();\n         try {\n           if (namesystem.isInSafeMode()) {\n             return;\n           }\n           synchronized(this) {\n             dm.removeDeadDatanode(dead);\n           }\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void heartbeatCheck() {\n    final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (namesystem.isInSafeMode()) {\n      return;\n    }\n    boolean checkStaleNodes \u003d dm.isCheckingForStaleDataNodes();\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      // locate the first dead node.\n      DatanodeID dead \u003d null;\n      // check the number of stale nodes\n      int numOfStaleNodes \u003d 0;\n      synchronized(this) {\n        for (DatanodeDescriptor d : datanodes) {\n          if (dead \u003d\u003d null \u0026\u0026 dm.isDatanodeDead(d)) {\n            stats.incrExpiredHeartbeats();\n            dead \u003d d;\n            if (!checkStaleNodes) {\n              break;\n            }\n          }\n          if (checkStaleNodes \u0026\u0026 \n              d.isStale(dm.getStaleInterval())) {\n            numOfStaleNodes++;\n          }\n        }\n        \n        // Change whether to avoid using stale datanodes for writing\n        // based on proportion of stale datanodes\n        if (checkStaleNodes) {\n          dm.setNumStaleNodes(numOfStaleNodes);\n          if (numOfStaleNodes \u003e \n                datanodes.size() * ratioUseStaleDataNodesForWrite) {\n            dm.setAvoidStaleDataNodesForWrite(false);\n          } else {\n            if (this.initialAvoidWriteStaleNodes) {\n              dm.setAvoidStaleDataNodesForWrite(true);\n            }\n          }\n        }\n      }\n\n      allAlive \u003d dead \u003d\u003d null;\n      if (!allAlive) {\n        // acquire the fsnamesystem lock, and then remove the dead node.\n        namesystem.writeLock();\n        try {\n          if (namesystem.isInSafeMode()) {\n            return;\n          }\n          synchronized(this) {\n            dm.removeDeadDatanode(dead);\n          }\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
      "extendedDetails": {}
    },
    "8d724dd8b97cc4c10c03742eb359796c2f51b7a9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3860. HeartbeatManager#Monitor may wrongly hold the writelock of namesystem. Contributed by Jing Zhao.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1378228 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/08/12 10:01 AM",
      "commitName": "8d724dd8b97cc4c10c03742eb359796c2f51b7a9",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "24/08/12 6:03 PM",
      "commitNameOld": "deead78e35b0cb81af875b5a8032cbd06c9a2dae",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 3.67,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,38 @@\n   void heartbeatCheck() {\n     final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n     // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n     // for safe mode after taking the lock before removing a datanode.\n     if (namesystem.isInSafeMode()) {\n       return;\n     }\n     boolean allAlive \u003d false;\n     while (!allAlive) {\n       // locate the first dead node.\n       DatanodeID dead \u003d null;\n       synchronized(this) {\n         for (DatanodeDescriptor d : datanodes) {\n           if (dm.isDatanodeDead(d)) {\n             stats.incrExpiredHeartbeats();\n             dead \u003d d;\n             break;\n           }\n         }\n       }\n \n       allAlive \u003d dead \u003d\u003d null;\n       if (!allAlive) {\n         // acquire the fsnamesystem lock, and then remove the dead node.\n         namesystem.writeLock();\n-        if (namesystem.isInSafeMode()) {\n-          return;\n-        }\n         try {\n+          if (namesystem.isInSafeMode()) {\n+            return;\n+          }\n           synchronized(this) {\n             dm.removeDeadDatanode(dead);\n           }\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void heartbeatCheck() {\n    final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (namesystem.isInSafeMode()) {\n      return;\n    }\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      // locate the first dead node.\n      DatanodeID dead \u003d null;\n      synchronized(this) {\n        for (DatanodeDescriptor d : datanodes) {\n          if (dm.isDatanodeDead(d)) {\n            stats.incrExpiredHeartbeats();\n            dead \u003d d;\n            break;\n          }\n        }\n      }\n\n      allAlive \u003d dead \u003d\u003d null;\n      if (!allAlive) {\n        // acquire the fsnamesystem lock, and then remove the dead node.\n        namesystem.writeLock();\n        try {\n          if (namesystem.isInSafeMode()) {\n            return;\n          }\n          synchronized(this) {\n            dm.removeDeadDatanode(dead);\n          }\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
      "extendedDetails": {}
    },
    "9692cfc9ae2ac86c9a2d2b3ac9ca8f8b3bfc7c42": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2493. Remove reference to FSNamesystem in blockmanagement classes.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1190491 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/10/11 11:28 AM",
      "commitName": "9692cfc9ae2ac86c9a2d2b3ac9ca8f8b3bfc7c42",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 64.76,
      "commitsBetweenForRepo": 485,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,38 @@\n   void heartbeatCheck() {\n-    final DatanodeManager dm \u003d namesystem.getBlockManager().getDatanodeManager();\n+    final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n     // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n     // for safe mode after taking the lock before removing a datanode.\n     if (namesystem.isInSafeMode()) {\n       return;\n     }\n     boolean allAlive \u003d false;\n     while (!allAlive) {\n       // locate the first dead node.\n       DatanodeID dead \u003d null;\n       synchronized(this) {\n         for (DatanodeDescriptor d : datanodes) {\n           if (dm.isDatanodeDead(d)) {\n-            namesystem.incrExpiredHeartbeats();\n+            stats.incrExpiredHeartbeats();\n             dead \u003d d;\n             break;\n           }\n         }\n       }\n \n       allAlive \u003d dead \u003d\u003d null;\n       if (!allAlive) {\n         // acquire the fsnamesystem lock, and then remove the dead node.\n         namesystem.writeLock();\n         if (namesystem.isInSafeMode()) {\n           return;\n         }\n         try {\n           synchronized(this) {\n             dm.removeDeadDatanode(dead);\n           }\n         } finally {\n           namesystem.writeUnlock();\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void heartbeatCheck() {\n    final DatanodeManager dm \u003d blockManager.getDatanodeManager();\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (namesystem.isInSafeMode()) {\n      return;\n    }\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      // locate the first dead node.\n      DatanodeID dead \u003d null;\n      synchronized(this) {\n        for (DatanodeDescriptor d : datanodes) {\n          if (dm.isDatanodeDead(d)) {\n            stats.incrExpiredHeartbeats();\n            dead \u003d d;\n            break;\n          }\n        }\n      }\n\n      allAlive \u003d dead \u003d\u003d null;\n      if (!allAlive) {\n        // acquire the fsnamesystem lock, and then remove the dead node.\n        namesystem.writeLock();\n        if (namesystem.isInSafeMode()) {\n          return;\n        }\n        try {\n          synchronized(this) {\n            dm.removeDeadDatanode(dead);\n          }\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  void heartbeatCheck() {\n    final DatanodeManager dm \u003d namesystem.getBlockManager().getDatanodeManager();\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (namesystem.isInSafeMode()) {\n      return;\n    }\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      // locate the first dead node.\n      DatanodeID dead \u003d null;\n      synchronized(this) {\n        for (DatanodeDescriptor d : datanodes) {\n          if (dm.isDatanodeDead(d)) {\n            namesystem.incrExpiredHeartbeats();\n            dead \u003d d;\n            break;\n          }\n        }\n      }\n\n      allAlive \u003d dead \u003d\u003d null;\n      if (!allAlive) {\n        // acquire the fsnamesystem lock, and then remove the dead node.\n        namesystem.writeLock();\n        if (namesystem.isInSafeMode()) {\n          return;\n        }\n        try {\n          synchronized(this) {\n            dm.removeDeadDatanode(dead);\n          }\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  void heartbeatCheck() {\n    final DatanodeManager dm \u003d namesystem.getBlockManager().getDatanodeManager();\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (namesystem.isInSafeMode()) {\n      return;\n    }\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      // locate the first dead node.\n      DatanodeID dead \u003d null;\n      synchronized(this) {\n        for (DatanodeDescriptor d : datanodes) {\n          if (dm.isDatanodeDead(d)) {\n            namesystem.incrExpiredHeartbeats();\n            dead \u003d d;\n            break;\n          }\n        }\n      }\n\n      allAlive \u003d dead \u003d\u003d null;\n      if (!allAlive) {\n        // acquire the fsnamesystem lock, and then remove the dead node.\n        namesystem.writeLock();\n        if (namesystem.isInSafeMode()) {\n          return;\n        }\n        try {\n          synchronized(this) {\n            dm.removeDeadDatanode(dead);\n          }\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java"
      }
    },
    "7fac946ac983e31613fd62836c8ac9c4a579210a": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-2108. Move datanode heartbeat handling from namenode package to blockmanagement package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154042 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/08/11 3:55 PM",
      "commitName": "7fac946ac983e31613fd62836c8ac9c4a579210a",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-2108. Move datanode heartbeat handling from namenode package to blockmanagement package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154042 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/08/11 3:55 PM",
          "commitName": "7fac946ac983e31613fd62836c8ac9c4a579210a",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "04/08/11 2:56 PM",
          "commitNameOld": "23762da4fa17ce6ea7b70722147977123a28a7e6",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,38 @@\n   void heartbeatCheck() {\n-    final DatanodeManager datanodeManager \u003d getBlockManager().getDatanodeManager();\n+    final DatanodeManager dm \u003d namesystem.getBlockManager().getDatanodeManager();\n     // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n     // for safe mode after taking the lock before removing a datanode.\n-    if (isInSafeMode()) {\n+    if (namesystem.isInSafeMode()) {\n       return;\n     }\n     boolean allAlive \u003d false;\n     while (!allAlive) {\n-      boolean foundDead \u003d false;\n-      DatanodeID nodeID \u003d null;\n-\n       // locate the first dead node.\n-      synchronized(heartbeats) {\n-        for (Iterator\u003cDatanodeDescriptor\u003e it \u003d heartbeats.iterator();\n-             it.hasNext();) {\n-          DatanodeDescriptor nodeInfo \u003d it.next();\n-          if (datanodeManager.isDatanodeDead(nodeInfo)) {\n-            expiredHeartbeats.incr();\n-            foundDead \u003d true;\n-            nodeID \u003d nodeInfo;\n+      DatanodeID dead \u003d null;\n+      synchronized(this) {\n+        for (DatanodeDescriptor d : datanodes) {\n+          if (dm.isDatanodeDead(d)) {\n+            namesystem.incrExpiredHeartbeats();\n+            dead \u003d d;\n             break;\n           }\n         }\n       }\n \n-      // acquire the fsnamesystem lock, and then remove the dead node.\n-      if (foundDead) {\n-        writeLock();\n-        if (isInSafeMode()) {\n+      allAlive \u003d dead \u003d\u003d null;\n+      if (!allAlive) {\n+        // acquire the fsnamesystem lock, and then remove the dead node.\n+        namesystem.writeLock();\n+        if (namesystem.isInSafeMode()) {\n           return;\n         }\n         try {\n-          datanodeManager.removeDeadDatanode(nodeID);\n+          synchronized(this) {\n+            dm.removeDeadDatanode(dead);\n+          }\n         } finally {\n-          writeUnlock();\n+          namesystem.writeUnlock();\n         }\n       }\n-      allAlive \u003d !foundDead;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void heartbeatCheck() {\n    final DatanodeManager dm \u003d namesystem.getBlockManager().getDatanodeManager();\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (namesystem.isInSafeMode()) {\n      return;\n    }\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      // locate the first dead node.\n      DatanodeID dead \u003d null;\n      synchronized(this) {\n        for (DatanodeDescriptor d : datanodes) {\n          if (dm.isDatanodeDead(d)) {\n            namesystem.incrExpiredHeartbeats();\n            dead \u003d d;\n            break;\n          }\n        }\n      }\n\n      allAlive \u003d dead \u003d\u003d null;\n      if (!allAlive) {\n        // acquire the fsnamesystem lock, and then remove the dead node.\n        namesystem.writeLock();\n        if (namesystem.isInSafeMode()) {\n          return;\n        }\n        try {\n          synchronized(this) {\n            dm.removeDeadDatanode(dead);\n          }\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
          "extendedDetails": {
            "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
            "newPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
            "oldMethodName": "heartbeatCheck",
            "newMethodName": "heartbeatCheck"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2108. Move datanode heartbeat handling from namenode package to blockmanagement package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154042 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/08/11 3:55 PM",
          "commitName": "7fac946ac983e31613fd62836c8ac9c4a579210a",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "04/08/11 2:56 PM",
          "commitNameOld": "23762da4fa17ce6ea7b70722147977123a28a7e6",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,38 @@\n   void heartbeatCheck() {\n-    final DatanodeManager datanodeManager \u003d getBlockManager().getDatanodeManager();\n+    final DatanodeManager dm \u003d namesystem.getBlockManager().getDatanodeManager();\n     // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n     // for safe mode after taking the lock before removing a datanode.\n-    if (isInSafeMode()) {\n+    if (namesystem.isInSafeMode()) {\n       return;\n     }\n     boolean allAlive \u003d false;\n     while (!allAlive) {\n-      boolean foundDead \u003d false;\n-      DatanodeID nodeID \u003d null;\n-\n       // locate the first dead node.\n-      synchronized(heartbeats) {\n-        for (Iterator\u003cDatanodeDescriptor\u003e it \u003d heartbeats.iterator();\n-             it.hasNext();) {\n-          DatanodeDescriptor nodeInfo \u003d it.next();\n-          if (datanodeManager.isDatanodeDead(nodeInfo)) {\n-            expiredHeartbeats.incr();\n-            foundDead \u003d true;\n-            nodeID \u003d nodeInfo;\n+      DatanodeID dead \u003d null;\n+      synchronized(this) {\n+        for (DatanodeDescriptor d : datanodes) {\n+          if (dm.isDatanodeDead(d)) {\n+            namesystem.incrExpiredHeartbeats();\n+            dead \u003d d;\n             break;\n           }\n         }\n       }\n \n-      // acquire the fsnamesystem lock, and then remove the dead node.\n-      if (foundDead) {\n-        writeLock();\n-        if (isInSafeMode()) {\n+      allAlive \u003d dead \u003d\u003d null;\n+      if (!allAlive) {\n+        // acquire the fsnamesystem lock, and then remove the dead node.\n+        namesystem.writeLock();\n+        if (namesystem.isInSafeMode()) {\n           return;\n         }\n         try {\n-          datanodeManager.removeDeadDatanode(nodeID);\n+          synchronized(this) {\n+            dm.removeDeadDatanode(dead);\n+          }\n         } finally {\n-          writeUnlock();\n+          namesystem.writeUnlock();\n         }\n       }\n-      allAlive \u003d !foundDead;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void heartbeatCheck() {\n    final DatanodeManager dm \u003d namesystem.getBlockManager().getDatanodeManager();\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (namesystem.isInSafeMode()) {\n      return;\n    }\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      // locate the first dead node.\n      DatanodeID dead \u003d null;\n      synchronized(this) {\n        for (DatanodeDescriptor d : datanodes) {\n          if (dm.isDatanodeDead(d)) {\n            namesystem.incrExpiredHeartbeats();\n            dead \u003d d;\n            break;\n          }\n        }\n      }\n\n      allAlive \u003d dead \u003d\u003d null;\n      if (!allAlive) {\n        // acquire the fsnamesystem lock, and then remove the dead node.\n        namesystem.writeLock();\n        if (namesystem.isInSafeMode()) {\n          return;\n        }\n        try {\n          synchronized(this) {\n            dm.removeDeadDatanode(dead);\n          }\n        } finally {\n          namesystem.writeUnlock();\n        }\n      }\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/HeartbeatManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "969a263188f7015261719fe45fa1505121ebb80e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2191.  Move datanodeMap from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1151339 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/07/11 10:46 PM",
      "commitName": "969a263188f7015261719fe45fa1505121ebb80e",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "22/07/11 6:01 PM",
      "commitNameOld": "89537b7710b23db7abcd2a77f03818c06a5f5fa7",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 4.2,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,41 @@\n   void heartbeatCheck() {\n+    final DatanodeManager datanodeManager \u003d getBlockManager().getDatanodeManager();\n     // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n     // for safe mode after taking the lock before removing a datanode.\n     if (isInSafeMode()) {\n       return;\n     }\n     boolean allAlive \u003d false;\n     while (!allAlive) {\n       boolean foundDead \u003d false;\n       DatanodeID nodeID \u003d null;\n \n       // locate the first dead node.\n       synchronized(heartbeats) {\n         for (Iterator\u003cDatanodeDescriptor\u003e it \u003d heartbeats.iterator();\n              it.hasNext();) {\n           DatanodeDescriptor nodeInfo \u003d it.next();\n-          if (isDatanodeDead(nodeInfo)) {\n+          if (datanodeManager.isDatanodeDead(nodeInfo)) {\n             expiredHeartbeats.incr();\n             foundDead \u003d true;\n             nodeID \u003d nodeInfo;\n             break;\n           }\n         }\n       }\n \n       // acquire the fsnamesystem lock, and then remove the dead node.\n       if (foundDead) {\n         writeLock();\n         if (isInSafeMode()) {\n           return;\n         }\n         try {\n-          synchronized(heartbeats) {\n-            synchronized (datanodeMap) {\n-              DatanodeDescriptor nodeInfo \u003d null;\n-              try {\n-                nodeInfo \u003d getDatanode(nodeID);\n-              } catch (IOException e) {\n-                nodeInfo \u003d null;\n-              }\n-              if (nodeInfo !\u003d null \u0026\u0026 isDatanodeDead(nodeInfo)) {\n-                NameNode.stateChangeLog.info(\"BLOCK* NameSystem.heartbeatCheck: \"\n-                                             + \"lost heartbeat from \" + nodeInfo.getName());\n-                removeDatanode(nodeInfo);\n-              }\n-            }\n-          }\n+          datanodeManager.removeDeadDatanode(nodeID);\n         } finally {\n           writeUnlock();\n         }\n       }\n       allAlive \u003d !foundDead;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void heartbeatCheck() {\n    final DatanodeManager datanodeManager \u003d getBlockManager().getDatanodeManager();\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (isInSafeMode()) {\n      return;\n    }\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      boolean foundDead \u003d false;\n      DatanodeID nodeID \u003d null;\n\n      // locate the first dead node.\n      synchronized(heartbeats) {\n        for (Iterator\u003cDatanodeDescriptor\u003e it \u003d heartbeats.iterator();\n             it.hasNext();) {\n          DatanodeDescriptor nodeInfo \u003d it.next();\n          if (datanodeManager.isDatanodeDead(nodeInfo)) {\n            expiredHeartbeats.incr();\n            foundDead \u003d true;\n            nodeID \u003d nodeInfo;\n            break;\n          }\n        }\n      }\n\n      // acquire the fsnamesystem lock, and then remove the dead node.\n      if (foundDead) {\n        writeLock();\n        if (isInSafeMode()) {\n          return;\n        }\n        try {\n          datanodeManager.removeDeadDatanode(nodeID);\n        } finally {\n          writeUnlock();\n        }\n      }\n      allAlive \u003d !foundDead;\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,54 @@\n+  void heartbeatCheck() {\n+    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n+    // for safe mode after taking the lock before removing a datanode.\n+    if (isInSafeMode()) {\n+      return;\n+    }\n+    boolean allAlive \u003d false;\n+    while (!allAlive) {\n+      boolean foundDead \u003d false;\n+      DatanodeID nodeID \u003d null;\n+\n+      // locate the first dead node.\n+      synchronized(heartbeats) {\n+        for (Iterator\u003cDatanodeDescriptor\u003e it \u003d heartbeats.iterator();\n+             it.hasNext();) {\n+          DatanodeDescriptor nodeInfo \u003d it.next();\n+          if (isDatanodeDead(nodeInfo)) {\n+            expiredHeartbeats.incr();\n+            foundDead \u003d true;\n+            nodeID \u003d nodeInfo;\n+            break;\n+          }\n+        }\n+      }\n+\n+      // acquire the fsnamesystem lock, and then remove the dead node.\n+      if (foundDead) {\n+        writeLock();\n+        if (isInSafeMode()) {\n+          return;\n+        }\n+        try {\n+          synchronized(heartbeats) {\n+            synchronized (datanodeMap) {\n+              DatanodeDescriptor nodeInfo \u003d null;\n+              try {\n+                nodeInfo \u003d getDatanode(nodeID);\n+              } catch (IOException e) {\n+                nodeInfo \u003d null;\n+              }\n+              if (nodeInfo !\u003d null \u0026\u0026 isDatanodeDead(nodeInfo)) {\n+                NameNode.stateChangeLog.info(\"BLOCK* NameSystem.heartbeatCheck: \"\n+                                             + \"lost heartbeat from \" + nodeInfo.getName());\n+                removeDatanode(nodeInfo);\n+              }\n+            }\n+          }\n+        } finally {\n+          writeUnlock();\n+        }\n+      }\n+      allAlive \u003d !foundDead;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void heartbeatCheck() {\n    // It\u0027s OK to check safe mode w/o taking the lock here, we re-check\n    // for safe mode after taking the lock before removing a datanode.\n    if (isInSafeMode()) {\n      return;\n    }\n    boolean allAlive \u003d false;\n    while (!allAlive) {\n      boolean foundDead \u003d false;\n      DatanodeID nodeID \u003d null;\n\n      // locate the first dead node.\n      synchronized(heartbeats) {\n        for (Iterator\u003cDatanodeDescriptor\u003e it \u003d heartbeats.iterator();\n             it.hasNext();) {\n          DatanodeDescriptor nodeInfo \u003d it.next();\n          if (isDatanodeDead(nodeInfo)) {\n            expiredHeartbeats.incr();\n            foundDead \u003d true;\n            nodeID \u003d nodeInfo;\n            break;\n          }\n        }\n      }\n\n      // acquire the fsnamesystem lock, and then remove the dead node.\n      if (foundDead) {\n        writeLock();\n        if (isInSafeMode()) {\n          return;\n        }\n        try {\n          synchronized(heartbeats) {\n            synchronized (datanodeMap) {\n              DatanodeDescriptor nodeInfo \u003d null;\n              try {\n                nodeInfo \u003d getDatanode(nodeID);\n              } catch (IOException e) {\n                nodeInfo \u003d null;\n              }\n              if (nodeInfo !\u003d null \u0026\u0026 isDatanodeDead(nodeInfo)) {\n                NameNode.stateChangeLog.info(\"BLOCK* NameSystem.heartbeatCheck: \"\n                                             + \"lost heartbeat from \" + nodeInfo.getName());\n                removeDatanode(nodeInfo);\n              }\n            }\n          }\n        } finally {\n          writeUnlock();\n        }\n      }\n      allAlive \u003d !foundDead;\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}