{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "SlowDiskTracker.java",
  "functionName": "addSlowDiskReport",
  "functionId": "addSlowDiskReport___dataNodeID-String__dnSlowDiskReport-SlowDiskReports",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/SlowDiskTracker.java",
  "functionStartLine": 119,
  "functionEndLine": 138,
  "numCommitsSeen": 5,
  "timeTaken": 1433,
  "changeHistory": [
    "0695f7a538fb81cc5e36d0b9187df39822bb24f4",
    "28cdc5a8dc37ade1f45bda3aede589ee8593945e"
  ],
  "changeHistoryShort": {
    "0695f7a538fb81cc5e36d0b9187df39822bb24f4": "Ybodychange",
    "28cdc5a8dc37ade1f45bda3aede589ee8593945e": "Yintroduced"
  },
  "changeHistoryDetails": {
    "0695f7a538fb81cc5e36d0b9187df39822bb24f4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14612. SlowDiskReport won\u0027t update when SlowDisks is always empty in heartbeat. Contributed by Haibin Huang.\n",
      "commitDate": "12/03/20 5:22 PM",
      "commitName": "0695f7a538fb81cc5e36d0b9187df39822bb24f4",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "10/02/18 8:02 PM",
      "commitNameOld": "25fbec67d1c01cc3531b51d9e2ec03e5c3591a7e",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 760.85,
      "commitsBetweenForRepo": 5809,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,20 @@\n   public void addSlowDiskReport(String dataNodeID,\n       SlowDiskReports dnSlowDiskReport) {\n     Map\u003cString, Map\u003cDiskOp, Double\u003e\u003e slowDisks \u003d\n         dnSlowDiskReport.getSlowDisks();\n \n     long now \u003d timer.monotonicNow();\n \n     for (Map.Entry\u003cString, Map\u003cDiskOp, Double\u003e\u003e slowDiskEntry :\n         slowDisks.entrySet()) {\n \n       String diskID \u003d getSlowDiskIDForReport(dataNodeID,\n           slowDiskEntry.getKey());\n \n       Map\u003cDiskOp, Double\u003e latencies \u003d slowDiskEntry.getValue();\n \n       DiskLatency diskLatency \u003d new DiskLatency(diskID, latencies, now);\n       diskIDLatencyMap.put(diskID, diskLatency);\n     }\n \n-    checkAndUpdateReportIfNecessary();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void addSlowDiskReport(String dataNodeID,\n      SlowDiskReports dnSlowDiskReport) {\n    Map\u003cString, Map\u003cDiskOp, Double\u003e\u003e slowDisks \u003d\n        dnSlowDiskReport.getSlowDisks();\n\n    long now \u003d timer.monotonicNow();\n\n    for (Map.Entry\u003cString, Map\u003cDiskOp, Double\u003e\u003e slowDiskEntry :\n        slowDisks.entrySet()) {\n\n      String diskID \u003d getSlowDiskIDForReport(dataNodeID,\n          slowDiskEntry.getKey());\n\n      Map\u003cDiskOp, Double\u003e latencies \u003d slowDiskEntry.getValue();\n\n      DiskLatency diskLatency \u003d new DiskLatency(diskID, latencies, now);\n      diskIDLatencyMap.put(diskID, diskLatency);\n    }\n\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/SlowDiskTracker.java",
      "extendedDetails": {}
    },
    "28cdc5a8dc37ade1f45bda3aede589ee8593945e": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11551. Handle SlowDiskReport from DataNode at the NameNode. Contributed by Hanisha Koneru.\n",
      "commitDate": "30/03/17 10:41 PM",
      "commitName": "28cdc5a8dc37ade1f45bda3aede589ee8593945e",
      "commitAuthor": "Hanisha Koneru",
      "diff": "@@ -0,0 +1,21 @@\n+  public void addSlowDiskReport(String dataNodeID,\n+      SlowDiskReports dnSlowDiskReport) {\n+    Map\u003cString, Map\u003cDiskOp, Double\u003e\u003e slowDisks \u003d\n+        dnSlowDiskReport.getSlowDisks();\n+\n+    long now \u003d timer.monotonicNow();\n+\n+    for (Map.Entry\u003cString, Map\u003cDiskOp, Double\u003e\u003e slowDiskEntry :\n+        slowDisks.entrySet()) {\n+\n+      String diskID \u003d getSlowDiskIDForReport(dataNodeID,\n+          slowDiskEntry.getKey());\n+\n+      Map\u003cDiskOp, Double\u003e latencies \u003d slowDiskEntry.getValue();\n+\n+      DiskLatency diskLatency \u003d new DiskLatency(diskID, latencies, now);\n+      diskIDLatencyMap.put(diskID, diskLatency);\n+    }\n+\n+    checkAndUpdateReportIfNecessary();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void addSlowDiskReport(String dataNodeID,\n      SlowDiskReports dnSlowDiskReport) {\n    Map\u003cString, Map\u003cDiskOp, Double\u003e\u003e slowDisks \u003d\n        dnSlowDiskReport.getSlowDisks();\n\n    long now \u003d timer.monotonicNow();\n\n    for (Map.Entry\u003cString, Map\u003cDiskOp, Double\u003e\u003e slowDiskEntry :\n        slowDisks.entrySet()) {\n\n      String diskID \u003d getSlowDiskIDForReport(dataNodeID,\n          slowDiskEntry.getKey());\n\n      Map\u003cDiskOp, Double\u003e latencies \u003d slowDiskEntry.getValue();\n\n      DiskLatency diskLatency \u003d new DiskLatency(diskID, latencies, now);\n      diskIDLatencyMap.put(diskID, diskLatency);\n    }\n\n    checkAndUpdateReportIfNecessary();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/SlowDiskTracker.java"
    }
  }
}