{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ParsedJob.java",
  "functionName": "dumpParsedJob",
  "functionId": "dumpParsedJob",
  "sourceFilePath": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/ParsedJob.java",
  "functionStartLine": 161,
  "functionEndLine": 178,
  "numCommitsSeen": 3,
  "timeTaken": 782,
  "changeHistory": [
    "10325d97329c214bb3899c8535df5a366bc86d2f",
    "1dcc4b57ee29c372934b72511302b689cd93c1cf"
  ],
  "changeHistoryShort": {
    "10325d97329c214bb3899c8535df5a366bc86d2f": "Yfilerename",
    "1dcc4b57ee29c372934b72511302b689cd93c1cf": "Yintroduced"
  },
  "changeHistoryDetails": {
    "10325d97329c214bb3899c8535df5a366bc86d2f": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-3582. Move successfully passing MR1 tests to MR2 maven tree.(ahmed via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1233090 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/01/12 2:10 PM",
      "commitName": "10325d97329c214bb3899c8535df5a366bc86d2f",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "18/01/12 10:20 AM",
      "commitNameOld": "8b2f6909ec7df5cffb5ef417f5c9cffdee43e38a",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.16,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  void dumpParsedJob() {\n    LOG.info(\"ParsedJob details:\" + obtainTotalCounters() + \";\"\n        + obtainMapCounters() + \";\" + obtainReduceCounters()\n        + \"\\n\" + obtainJobConfpath() + \"\\n\" + obtainJobAcls()\n        + \";Q\u003d\" + (getQueue() \u003d\u003d null ? \"null\" : getQueue().getValue()));\n    List\u003cParsedTask\u003e maps \u003d obtainMapTasks();\n    for (ParsedTask task : maps) {\n      task.dumpParsedTask();\n    }\n    List\u003cParsedTask\u003e reduces \u003d obtainReduceTasks();\n    for (ParsedTask task : reduces) {\n      task.dumpParsedTask();\n    }\n    List\u003cParsedTask\u003e others \u003d obtainOtherTasks();\n    for (ParsedTask task : others) {\n      task.dumpParsedTask();\n    }\n  }",
      "path": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/ParsedJob.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/ParsedJob.java",
        "newPath": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/ParsedJob.java"
      }
    },
    "1dcc4b57ee29c372934b72511302b689cd93c1cf": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-3597. [Rumen] Rumen should provide APIs to access all the job-history related information.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1222695 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/12/11 6:47 AM",
      "commitName": "1dcc4b57ee29c372934b72511302b689cd93c1cf",
      "commitAuthor": "Amar Kamat",
      "diff": "@@ -0,0 +1,18 @@\n+  void dumpParsedJob() {\n+    LOG.info(\"ParsedJob details:\" + obtainTotalCounters() + \";\"\n+        + obtainMapCounters() + \";\" + obtainReduceCounters()\n+        + \"\\n\" + obtainJobConfpath() + \"\\n\" + obtainJobAcls()\n+        + \";Q\u003d\" + (getQueue() \u003d\u003d null ? \"null\" : getQueue().getValue()));\n+    List\u003cParsedTask\u003e maps \u003d obtainMapTasks();\n+    for (ParsedTask task : maps) {\n+      task.dumpParsedTask();\n+    }\n+    List\u003cParsedTask\u003e reduces \u003d obtainReduceTasks();\n+    for (ParsedTask task : reduces) {\n+      task.dumpParsedTask();\n+    }\n+    List\u003cParsedTask\u003e others \u003d obtainOtherTasks();\n+    for (ParsedTask task : others) {\n+      task.dumpParsedTask();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void dumpParsedJob() {\n    LOG.info(\"ParsedJob details:\" + obtainTotalCounters() + \";\"\n        + obtainMapCounters() + \";\" + obtainReduceCounters()\n        + \"\\n\" + obtainJobConfpath() + \"\\n\" + obtainJobAcls()\n        + \";Q\u003d\" + (getQueue() \u003d\u003d null ? \"null\" : getQueue().getValue()));\n    List\u003cParsedTask\u003e maps \u003d obtainMapTasks();\n    for (ParsedTask task : maps) {\n      task.dumpParsedTask();\n    }\n    List\u003cParsedTask\u003e reduces \u003d obtainReduceTasks();\n    for (ParsedTask task : reduces) {\n      task.dumpParsedTask();\n    }\n    List\u003cParsedTask\u003e others \u003d obtainOtherTasks();\n    for (ParsedTask task : others) {\n      task.dumpParsedTask();\n    }\n  }",
      "path": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/ParsedJob.java"
    }
  }
}