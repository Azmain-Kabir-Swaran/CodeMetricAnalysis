{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockReaderLocalLegacy.java",
  "functionName": "skip",
  "functionId": "skip___n-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java",
  "functionStartLine": 622,
  "functionEndLine": 685,
  "numCommitsSeen": 30,
  "timeTaken": 2774,
  "changeHistory": [
    "f308561f1d885491b88db73ac63003202056d661",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8",
    "6ee0539ede78b640f01c5eac18ded161182a7835",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
    "e2c9b288b223b9fd82dc12018936e13128413492",
    "ab96a0838dafbfea77382135914feadbfd03cf53",
    "694a6721316aea14c1244447974231abc8dff0cb"
  ],
  "changeHistoryShort": {
    "f308561f1d885491b88db73ac63003202056d661": "Yfilerename",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": "Ybodychange",
    "6ee0539ede78b640f01c5eac18ded161182a7835": "Ybodychange",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": "Ybodychange",
    "e2c9b288b223b9fd82dc12018936e13128413492": "Yfilerename",
    "ab96a0838dafbfea77382135914feadbfd03cf53": "Ybodychange",
    "694a6721316aea14c1244447974231abc8dff0cb": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f308561f1d885491b88db73ac63003202056d661": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8057 Move BlockReader implementation to the client implementation package.  Contributed by Takanobu Asanuma\n",
      "commitDate": "25/04/16 12:01 PM",
      "commitName": "f308561f1d885491b88db73ac63003202056d661",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "25/04/16 9:38 AM",
      "commitNameOld": "10f0f7851a3255caab775777e8fb6c2781d97062",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public synchronized long skip(long n) throws IOException {\n    LOG.debug(\"skip {}\", n);\n    if (n \u003c\u003d 0) {\n      return 0;\n    }\n    if (!verifyChecksum) {\n      return dataIn.skip(n);\n    }\n\n    // caller made sure newPosition is not beyond EOF.\n    int remaining \u003d slowReadBuff.remaining();\n    int position \u003d slowReadBuff.position();\n    int newPosition \u003d position + (int)n;\n\n    // if the new offset is already read into dataBuff, just reposition\n    if (n \u003c\u003d remaining) {\n      assert offsetFromChunkBoundary \u003d\u003d 0;\n      slowReadBuff.position(newPosition);\n      return n;\n    }\n\n    // for small gap, read through to keep the data/checksum in sync\n    if (n - remaining \u003c\u003d bytesPerChecksum) {\n      slowReadBuff.position(position + remaining);\n      if (skipBuf \u003d\u003d null) {\n        skipBuf \u003d new byte[bytesPerChecksum];\n      }\n      int ret \u003d read(skipBuf, 0, (int)(n - remaining));\n      return (remaining + ret);\n    }\n\n    // optimize for big gap: discard the current buffer, skip to\n    // the beginning of the appropriate checksum chunk and then\n    // read to the middle of that chunk to be in sync with checksums.\n\n    // We can\u0027t use this.offsetFromChunkBoundary because we need to know how\n    // many bytes of the offset were really read. Calling read(..) with a\n    // positive this.offsetFromChunkBoundary causes that many bytes to get\n    // silently skipped.\n    int myOffsetFromChunkBoundary \u003d newPosition % bytesPerChecksum;\n    long toskip \u003d n - remaining - myOffsetFromChunkBoundary;\n\n    slowReadBuff.position(slowReadBuff.limit());\n    checksumBuff.position(checksumBuff.limit());\n\n    IOUtils.skipFully(dataIn, toskip);\n    long checkSumOffset \u003d (toskip / bytesPerChecksum) * checksumSize;\n    IOUtils.skipFully(checksumIn, checkSumOffset);\n\n    // read into the middle of the chunk\n    if (skipBuf \u003d\u003d null) {\n      skipBuf \u003d new byte[bytesPerChecksum];\n    }\n    assert skipBuf.length \u003d\u003d bytesPerChecksum;\n    assert myOffsetFromChunkBoundary \u003c bytesPerChecksum;\n\n    int ret \u003d read(skipBuf, 0, myOffsetFromChunkBoundary);\n\n    if (ret \u003d\u003d -1) {  // EOS\n      return (toskip + remaining);\n    } else {\n      return (toskip + remaining + ret);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java"
      }
    },
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8971. Remove guards when calling LOG.debug() and LOG.trace() in client package. Contributed by Mingliang Liu.\n",
      "commitDate": "29/09/15 5:52 PM",
      "commitName": "39285e6a1978ea5e53bdc1b0aef62421382124a8",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:51 PM",
      "commitNameOld": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,64 @@\n   public synchronized long skip(long n) throws IOException {\n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"skip \" + n);\n-    }\n+    LOG.debug(\"skip {}\", n);\n     if (n \u003c\u003d 0) {\n       return 0;\n     }\n     if (!verifyChecksum) {\n       return dataIn.skip(n);\n     }\n   \n     // caller made sure newPosition is not beyond EOF.\n     int remaining \u003d slowReadBuff.remaining();\n     int position \u003d slowReadBuff.position();\n     int newPosition \u003d position + (int)n;\n   \n     // if the new offset is already read into dataBuff, just reposition\n     if (n \u003c\u003d remaining) {\n       assert offsetFromChunkBoundary \u003d\u003d 0;\n       slowReadBuff.position(newPosition);\n       return n;\n     }\n   \n     // for small gap, read through to keep the data/checksum in sync\n     if (n - remaining \u003c\u003d bytesPerChecksum) {\n       slowReadBuff.position(position + remaining);\n       if (skipBuf \u003d\u003d null) {\n         skipBuf \u003d new byte[bytesPerChecksum];\n       }\n       int ret \u003d read(skipBuf, 0, (int)(n - remaining));\n       return (remaining + ret);\n     }\n   \n     // optimize for big gap: discard the current buffer, skip to\n     // the beginning of the appropriate checksum chunk and then\n     // read to the middle of that chunk to be in sync with checksums.\n   \n     // We can\u0027t use this.offsetFromChunkBoundary because we need to know how\n     // many bytes of the offset were really read. Calling read(..) with a\n     // positive this.offsetFromChunkBoundary causes that many bytes to get\n     // silently skipped.\n     int myOffsetFromChunkBoundary \u003d newPosition % bytesPerChecksum;\n     long toskip \u003d n - remaining - myOffsetFromChunkBoundary;\n \n     slowReadBuff.position(slowReadBuff.limit());\n     checksumBuff.position(checksumBuff.limit());\n   \n     IOUtils.skipFully(dataIn, toskip);\n     long checkSumOffset \u003d (toskip / bytesPerChecksum) * checksumSize;\n     IOUtils.skipFully(checksumIn, checkSumOffset);\n \n     // read into the middle of the chunk\n     if (skipBuf \u003d\u003d null) {\n       skipBuf \u003d new byte[bytesPerChecksum];\n     }\n     assert skipBuf.length \u003d\u003d bytesPerChecksum;\n     assert myOffsetFromChunkBoundary \u003c bytesPerChecksum;\n \n     int ret \u003d read(skipBuf, 0, myOffsetFromChunkBoundary);\n \n     if (ret \u003d\u003d -1) {  // EOS\n       return (toskip + remaining);\n     } else {\n       return (toskip + remaining + ret);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized long skip(long n) throws IOException {\n    LOG.debug(\"skip {}\", n);\n    if (n \u003c\u003d 0) {\n      return 0;\n    }\n    if (!verifyChecksum) {\n      return dataIn.skip(n);\n    }\n  \n    // caller made sure newPosition is not beyond EOF.\n    int remaining \u003d slowReadBuff.remaining();\n    int position \u003d slowReadBuff.position();\n    int newPosition \u003d position + (int)n;\n  \n    // if the new offset is already read into dataBuff, just reposition\n    if (n \u003c\u003d remaining) {\n      assert offsetFromChunkBoundary \u003d\u003d 0;\n      slowReadBuff.position(newPosition);\n      return n;\n    }\n  \n    // for small gap, read through to keep the data/checksum in sync\n    if (n - remaining \u003c\u003d bytesPerChecksum) {\n      slowReadBuff.position(position + remaining);\n      if (skipBuf \u003d\u003d null) {\n        skipBuf \u003d new byte[bytesPerChecksum];\n      }\n      int ret \u003d read(skipBuf, 0, (int)(n - remaining));\n      return (remaining + ret);\n    }\n  \n    // optimize for big gap: discard the current buffer, skip to\n    // the beginning of the appropriate checksum chunk and then\n    // read to the middle of that chunk to be in sync with checksums.\n  \n    // We can\u0027t use this.offsetFromChunkBoundary because we need to know how\n    // many bytes of the offset were really read. Calling read(..) with a\n    // positive this.offsetFromChunkBoundary causes that many bytes to get\n    // silently skipped.\n    int myOffsetFromChunkBoundary \u003d newPosition % bytesPerChecksum;\n    long toskip \u003d n - remaining - myOffsetFromChunkBoundary;\n\n    slowReadBuff.position(slowReadBuff.limit());\n    checksumBuff.position(checksumBuff.limit());\n  \n    IOUtils.skipFully(dataIn, toskip);\n    long checkSumOffset \u003d (toskip / bytesPerChecksum) * checksumSize;\n    IOUtils.skipFully(checksumIn, checkSumOffset);\n\n    // read into the middle of the chunk\n    if (skipBuf \u003d\u003d null) {\n      skipBuf \u003d new byte[bytesPerChecksum];\n    }\n    assert skipBuf.length \u003d\u003d bytesPerChecksum;\n    assert myOffsetFromChunkBoundary \u003c bytesPerChecksum;\n\n    int ret \u003d read(skipBuf, 0, myOffsetFromChunkBoundary);\n\n    if (ret \u003d\u003d -1) {  // EOS\n      return (toskip + remaining);\n    } else {\n      return (toskip + remaining + ret);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
      "extendedDetails": {}
    },
    "6ee0539ede78b640f01c5eac18ded161182a7835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\"\n\nThis reverts commit d5a9a3daa0224249221ffa7b8bd5751ab2feca56.\n",
      "commitDate": "29/09/15 5:51 PM",
      "commitName": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:48 PM",
      "commitNameOld": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,64 +1,66 @@\n   public synchronized long skip(long n) throws IOException {\n-    LOG.debug(\"skip {}\", n);\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"skip \" + n);\n+    }\n     if (n \u003c\u003d 0) {\n       return 0;\n     }\n     if (!verifyChecksum) {\n       return dataIn.skip(n);\n     }\n   \n     // caller made sure newPosition is not beyond EOF.\n     int remaining \u003d slowReadBuff.remaining();\n     int position \u003d slowReadBuff.position();\n     int newPosition \u003d position + (int)n;\n   \n     // if the new offset is already read into dataBuff, just reposition\n     if (n \u003c\u003d remaining) {\n       assert offsetFromChunkBoundary \u003d\u003d 0;\n       slowReadBuff.position(newPosition);\n       return n;\n     }\n   \n     // for small gap, read through to keep the data/checksum in sync\n     if (n - remaining \u003c\u003d bytesPerChecksum) {\n       slowReadBuff.position(position + remaining);\n       if (skipBuf \u003d\u003d null) {\n         skipBuf \u003d new byte[bytesPerChecksum];\n       }\n       int ret \u003d read(skipBuf, 0, (int)(n - remaining));\n       return (remaining + ret);\n     }\n   \n     // optimize for big gap: discard the current buffer, skip to\n     // the beginning of the appropriate checksum chunk and then\n     // read to the middle of that chunk to be in sync with checksums.\n   \n     // We can\u0027t use this.offsetFromChunkBoundary because we need to know how\n     // many bytes of the offset were really read. Calling read(..) with a\n     // positive this.offsetFromChunkBoundary causes that many bytes to get\n     // silently skipped.\n     int myOffsetFromChunkBoundary \u003d newPosition % bytesPerChecksum;\n     long toskip \u003d n - remaining - myOffsetFromChunkBoundary;\n \n     slowReadBuff.position(slowReadBuff.limit());\n     checksumBuff.position(checksumBuff.limit());\n   \n     IOUtils.skipFully(dataIn, toskip);\n     long checkSumOffset \u003d (toskip / bytesPerChecksum) * checksumSize;\n     IOUtils.skipFully(checksumIn, checkSumOffset);\n \n     // read into the middle of the chunk\n     if (skipBuf \u003d\u003d null) {\n       skipBuf \u003d new byte[bytesPerChecksum];\n     }\n     assert skipBuf.length \u003d\u003d bytesPerChecksum;\n     assert myOffsetFromChunkBoundary \u003c bytesPerChecksum;\n \n     int ret \u003d read(skipBuf, 0, myOffsetFromChunkBoundary);\n \n     if (ret \u003d\u003d -1) {  // EOS\n       return (toskip + remaining);\n     } else {\n       return (toskip + remaining + ret);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized long skip(long n) throws IOException {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"skip \" + n);\n    }\n    if (n \u003c\u003d 0) {\n      return 0;\n    }\n    if (!verifyChecksum) {\n      return dataIn.skip(n);\n    }\n  \n    // caller made sure newPosition is not beyond EOF.\n    int remaining \u003d slowReadBuff.remaining();\n    int position \u003d slowReadBuff.position();\n    int newPosition \u003d position + (int)n;\n  \n    // if the new offset is already read into dataBuff, just reposition\n    if (n \u003c\u003d remaining) {\n      assert offsetFromChunkBoundary \u003d\u003d 0;\n      slowReadBuff.position(newPosition);\n      return n;\n    }\n  \n    // for small gap, read through to keep the data/checksum in sync\n    if (n - remaining \u003c\u003d bytesPerChecksum) {\n      slowReadBuff.position(position + remaining);\n      if (skipBuf \u003d\u003d null) {\n        skipBuf \u003d new byte[bytesPerChecksum];\n      }\n      int ret \u003d read(skipBuf, 0, (int)(n - remaining));\n      return (remaining + ret);\n    }\n  \n    // optimize for big gap: discard the current buffer, skip to\n    // the beginning of the appropriate checksum chunk and then\n    // read to the middle of that chunk to be in sync with checksums.\n  \n    // We can\u0027t use this.offsetFromChunkBoundary because we need to know how\n    // many bytes of the offset were really read. Calling read(..) with a\n    // positive this.offsetFromChunkBoundary causes that many bytes to get\n    // silently skipped.\n    int myOffsetFromChunkBoundary \u003d newPosition % bytesPerChecksum;\n    long toskip \u003d n - remaining - myOffsetFromChunkBoundary;\n\n    slowReadBuff.position(slowReadBuff.limit());\n    checksumBuff.position(checksumBuff.limit());\n  \n    IOUtils.skipFully(dataIn, toskip);\n    long checkSumOffset \u003d (toskip / bytesPerChecksum) * checksumSize;\n    IOUtils.skipFully(checksumIn, checkSumOffset);\n\n    // read into the middle of the chunk\n    if (skipBuf \u003d\u003d null) {\n      skipBuf \u003d new byte[bytesPerChecksum];\n    }\n    assert skipBuf.length \u003d\u003d bytesPerChecksum;\n    assert myOffsetFromChunkBoundary \u003c bytesPerChecksum;\n\n    int ret \u003d read(skipBuf, 0, myOffsetFromChunkBoundary);\n\n    if (ret \u003d\u003d -1) {  // EOS\n      return (toskip + remaining);\n    } else {\n      return (toskip + remaining + ret);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
      "extendedDetails": {}
    },
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "29/09/15 5:48 PM",
      "commitName": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/09/15 7:42 AM",
      "commitNameOld": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 1.42,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,64 @@\n   public synchronized long skip(long n) throws IOException {\n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"skip \" + n);\n-    }\n+    LOG.debug(\"skip {}\", n);\n     if (n \u003c\u003d 0) {\n       return 0;\n     }\n     if (!verifyChecksum) {\n       return dataIn.skip(n);\n     }\n   \n     // caller made sure newPosition is not beyond EOF.\n     int remaining \u003d slowReadBuff.remaining();\n     int position \u003d slowReadBuff.position();\n     int newPosition \u003d position + (int)n;\n   \n     // if the new offset is already read into dataBuff, just reposition\n     if (n \u003c\u003d remaining) {\n       assert offsetFromChunkBoundary \u003d\u003d 0;\n       slowReadBuff.position(newPosition);\n       return n;\n     }\n   \n     // for small gap, read through to keep the data/checksum in sync\n     if (n - remaining \u003c\u003d bytesPerChecksum) {\n       slowReadBuff.position(position + remaining);\n       if (skipBuf \u003d\u003d null) {\n         skipBuf \u003d new byte[bytesPerChecksum];\n       }\n       int ret \u003d read(skipBuf, 0, (int)(n - remaining));\n       return (remaining + ret);\n     }\n   \n     // optimize for big gap: discard the current buffer, skip to\n     // the beginning of the appropriate checksum chunk and then\n     // read to the middle of that chunk to be in sync with checksums.\n   \n     // We can\u0027t use this.offsetFromChunkBoundary because we need to know how\n     // many bytes of the offset were really read. Calling read(..) with a\n     // positive this.offsetFromChunkBoundary causes that many bytes to get\n     // silently skipped.\n     int myOffsetFromChunkBoundary \u003d newPosition % bytesPerChecksum;\n     long toskip \u003d n - remaining - myOffsetFromChunkBoundary;\n \n     slowReadBuff.position(slowReadBuff.limit());\n     checksumBuff.position(checksumBuff.limit());\n   \n     IOUtils.skipFully(dataIn, toskip);\n     long checkSumOffset \u003d (toskip / bytesPerChecksum) * checksumSize;\n     IOUtils.skipFully(checksumIn, checkSumOffset);\n \n     // read into the middle of the chunk\n     if (skipBuf \u003d\u003d null) {\n       skipBuf \u003d new byte[bytesPerChecksum];\n     }\n     assert skipBuf.length \u003d\u003d bytesPerChecksum;\n     assert myOffsetFromChunkBoundary \u003c bytesPerChecksum;\n \n     int ret \u003d read(skipBuf, 0, myOffsetFromChunkBoundary);\n \n     if (ret \u003d\u003d -1) {  // EOS\n       return (toskip + remaining);\n     } else {\n       return (toskip + remaining + ret);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized long skip(long n) throws IOException {\n    LOG.debug(\"skip {}\", n);\n    if (n \u003c\u003d 0) {\n      return 0;\n    }\n    if (!verifyChecksum) {\n      return dataIn.skip(n);\n    }\n  \n    // caller made sure newPosition is not beyond EOF.\n    int remaining \u003d slowReadBuff.remaining();\n    int position \u003d slowReadBuff.position();\n    int newPosition \u003d position + (int)n;\n  \n    // if the new offset is already read into dataBuff, just reposition\n    if (n \u003c\u003d remaining) {\n      assert offsetFromChunkBoundary \u003d\u003d 0;\n      slowReadBuff.position(newPosition);\n      return n;\n    }\n  \n    // for small gap, read through to keep the data/checksum in sync\n    if (n - remaining \u003c\u003d bytesPerChecksum) {\n      slowReadBuff.position(position + remaining);\n      if (skipBuf \u003d\u003d null) {\n        skipBuf \u003d new byte[bytesPerChecksum];\n      }\n      int ret \u003d read(skipBuf, 0, (int)(n - remaining));\n      return (remaining + ret);\n    }\n  \n    // optimize for big gap: discard the current buffer, skip to\n    // the beginning of the appropriate checksum chunk and then\n    // read to the middle of that chunk to be in sync with checksums.\n  \n    // We can\u0027t use this.offsetFromChunkBoundary because we need to know how\n    // many bytes of the offset were really read. Calling read(..) with a\n    // positive this.offsetFromChunkBoundary causes that many bytes to get\n    // silently skipped.\n    int myOffsetFromChunkBoundary \u003d newPosition % bytesPerChecksum;\n    long toskip \u003d n - remaining - myOffsetFromChunkBoundary;\n\n    slowReadBuff.position(slowReadBuff.limit());\n    checksumBuff.position(checksumBuff.limit());\n  \n    IOUtils.skipFully(dataIn, toskip);\n    long checkSumOffset \u003d (toskip / bytesPerChecksum) * checksumSize;\n    IOUtils.skipFully(checksumIn, checkSumOffset);\n\n    // read into the middle of the chunk\n    if (skipBuf \u003d\u003d null) {\n      skipBuf \u003d new byte[bytesPerChecksum];\n    }\n    assert skipBuf.length \u003d\u003d bytesPerChecksum;\n    assert myOffsetFromChunkBoundary \u003c bytesPerChecksum;\n\n    int ret \u003d read(skipBuf, 0, myOffsetFromChunkBoundary);\n\n    if (ret \u003d\u003d -1) {  // EOS\n      return (toskip + remaining);\n    } else {\n      return (toskip + remaining + ret);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
      "extendedDetails": {}
    },
    "e2c9b288b223b9fd82dc12018936e13128413492": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8925. Move BlockReaderLocal to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "28/08/15 2:38 PM",
      "commitName": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/08/15 2:21 PM",
      "commitNameOld": "b94b56806d3d6e04984e229b479f7ac15b62bbfa",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public synchronized long skip(long n) throws IOException {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"skip \" + n);\n    }\n    if (n \u003c\u003d 0) {\n      return 0;\n    }\n    if (!verifyChecksum) {\n      return dataIn.skip(n);\n    }\n  \n    // caller made sure newPosition is not beyond EOF.\n    int remaining \u003d slowReadBuff.remaining();\n    int position \u003d slowReadBuff.position();\n    int newPosition \u003d position + (int)n;\n  \n    // if the new offset is already read into dataBuff, just reposition\n    if (n \u003c\u003d remaining) {\n      assert offsetFromChunkBoundary \u003d\u003d 0;\n      slowReadBuff.position(newPosition);\n      return n;\n    }\n  \n    // for small gap, read through to keep the data/checksum in sync\n    if (n - remaining \u003c\u003d bytesPerChecksum) {\n      slowReadBuff.position(position + remaining);\n      if (skipBuf \u003d\u003d null) {\n        skipBuf \u003d new byte[bytesPerChecksum];\n      }\n      int ret \u003d read(skipBuf, 0, (int)(n - remaining));\n      return (remaining + ret);\n    }\n  \n    // optimize for big gap: discard the current buffer, skip to\n    // the beginning of the appropriate checksum chunk and then\n    // read to the middle of that chunk to be in sync with checksums.\n  \n    // We can\u0027t use this.offsetFromChunkBoundary because we need to know how\n    // many bytes of the offset were really read. Calling read(..) with a\n    // positive this.offsetFromChunkBoundary causes that many bytes to get\n    // silently skipped.\n    int myOffsetFromChunkBoundary \u003d newPosition % bytesPerChecksum;\n    long toskip \u003d n - remaining - myOffsetFromChunkBoundary;\n\n    slowReadBuff.position(slowReadBuff.limit());\n    checksumBuff.position(checksumBuff.limit());\n  \n    IOUtils.skipFully(dataIn, toskip);\n    long checkSumOffset \u003d (toskip / bytesPerChecksum) * checksumSize;\n    IOUtils.skipFully(checksumIn, checkSumOffset);\n\n    // read into the middle of the chunk\n    if (skipBuf \u003d\u003d null) {\n      skipBuf \u003d new byte[bytesPerChecksum];\n    }\n    assert skipBuf.length \u003d\u003d bytesPerChecksum;\n    assert myOffsetFromChunkBoundary \u003c bytesPerChecksum;\n\n    int ret \u003d read(skipBuf, 0, myOffsetFromChunkBoundary);\n\n    if (ret \u003d\u003d -1) {  // EOS\n      return (toskip + remaining);\n    } else {\n      return (toskip + remaining + ret);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java"
      }
    },
    "ab96a0838dafbfea77382135914feadbfd03cf53": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5881. Fix skip() of the short-circuit local reader(legacy). Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1565310 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/02/14 7:45 AM",
      "commitName": "ab96a0838dafbfea77382135914feadbfd03cf53",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "17/12/13 12:57 PM",
      "commitNameOld": "124e507674c0d396f8494585e64226957199097b",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 50.78,
      "commitsBetweenForRepo": 263,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,66 @@\n   public synchronized long skip(long n) throws IOException {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"skip \" + n);\n     }\n     if (n \u003c\u003d 0) {\n       return 0;\n     }\n     if (!verifyChecksum) {\n       return dataIn.skip(n);\n     }\n   \n     // caller made sure newPosition is not beyond EOF.\n     int remaining \u003d slowReadBuff.remaining();\n     int position \u003d slowReadBuff.position();\n     int newPosition \u003d position + (int)n;\n   \n     // if the new offset is already read into dataBuff, just reposition\n     if (n \u003c\u003d remaining) {\n       assert offsetFromChunkBoundary \u003d\u003d 0;\n       slowReadBuff.position(newPosition);\n       return n;\n     }\n   \n     // for small gap, read through to keep the data/checksum in sync\n     if (n - remaining \u003c\u003d bytesPerChecksum) {\n       slowReadBuff.position(position + remaining);\n       if (skipBuf \u003d\u003d null) {\n         skipBuf \u003d new byte[bytesPerChecksum];\n       }\n       int ret \u003d read(skipBuf, 0, (int)(n - remaining));\n-      return ret;\n+      return (remaining + ret);\n     }\n   \n     // optimize for big gap: discard the current buffer, skip to\n     // the beginning of the appropriate checksum chunk and then\n     // read to the middle of that chunk to be in sync with checksums.\n   \n     // We can\u0027t use this.offsetFromChunkBoundary because we need to know how\n     // many bytes of the offset were really read. Calling read(..) with a\n     // positive this.offsetFromChunkBoundary causes that many bytes to get\n     // silently skipped.\n     int myOffsetFromChunkBoundary \u003d newPosition % bytesPerChecksum;\n     long toskip \u003d n - remaining - myOffsetFromChunkBoundary;\n \n     slowReadBuff.position(slowReadBuff.limit());\n     checksumBuff.position(checksumBuff.limit());\n   \n     IOUtils.skipFully(dataIn, toskip);\n     long checkSumOffset \u003d (toskip / bytesPerChecksum) * checksumSize;\n     IOUtils.skipFully(checksumIn, checkSumOffset);\n \n     // read into the middle of the chunk\n     if (skipBuf \u003d\u003d null) {\n       skipBuf \u003d new byte[bytesPerChecksum];\n     }\n     assert skipBuf.length \u003d\u003d bytesPerChecksum;\n     assert myOffsetFromChunkBoundary \u003c bytesPerChecksum;\n \n     int ret \u003d read(skipBuf, 0, myOffsetFromChunkBoundary);\n \n     if (ret \u003d\u003d -1) {  // EOS\n-      return toskip;\n+      return (toskip + remaining);\n     } else {\n-      return (toskip + ret);\n+      return (toskip + remaining + ret);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized long skip(long n) throws IOException {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"skip \" + n);\n    }\n    if (n \u003c\u003d 0) {\n      return 0;\n    }\n    if (!verifyChecksum) {\n      return dataIn.skip(n);\n    }\n  \n    // caller made sure newPosition is not beyond EOF.\n    int remaining \u003d slowReadBuff.remaining();\n    int position \u003d slowReadBuff.position();\n    int newPosition \u003d position + (int)n;\n  \n    // if the new offset is already read into dataBuff, just reposition\n    if (n \u003c\u003d remaining) {\n      assert offsetFromChunkBoundary \u003d\u003d 0;\n      slowReadBuff.position(newPosition);\n      return n;\n    }\n  \n    // for small gap, read through to keep the data/checksum in sync\n    if (n - remaining \u003c\u003d bytesPerChecksum) {\n      slowReadBuff.position(position + remaining);\n      if (skipBuf \u003d\u003d null) {\n        skipBuf \u003d new byte[bytesPerChecksum];\n      }\n      int ret \u003d read(skipBuf, 0, (int)(n - remaining));\n      return (remaining + ret);\n    }\n  \n    // optimize for big gap: discard the current buffer, skip to\n    // the beginning of the appropriate checksum chunk and then\n    // read to the middle of that chunk to be in sync with checksums.\n  \n    // We can\u0027t use this.offsetFromChunkBoundary because we need to know how\n    // many bytes of the offset were really read. Calling read(..) with a\n    // positive this.offsetFromChunkBoundary causes that many bytes to get\n    // silently skipped.\n    int myOffsetFromChunkBoundary \u003d newPosition % bytesPerChecksum;\n    long toskip \u003d n - remaining - myOffsetFromChunkBoundary;\n\n    slowReadBuff.position(slowReadBuff.limit());\n    checksumBuff.position(checksumBuff.limit());\n  \n    IOUtils.skipFully(dataIn, toskip);\n    long checkSumOffset \u003d (toskip / bytesPerChecksum) * checksumSize;\n    IOUtils.skipFully(checksumIn, checkSumOffset);\n\n    // read into the middle of the chunk\n    if (skipBuf \u003d\u003d null) {\n      skipBuf \u003d new byte[bytesPerChecksum];\n    }\n    assert skipBuf.length \u003d\u003d bytesPerChecksum;\n    assert myOffsetFromChunkBoundary \u003c bytesPerChecksum;\n\n    int ret \u003d read(skipBuf, 0, myOffsetFromChunkBoundary);\n\n    if (ret \u003d\u003d -1) {  // EOS\n      return (toskip + remaining);\n    } else {\n      return (toskip + remaining + ret);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
      "extendedDetails": {}
    },
    "694a6721316aea14c1244447974231abc8dff0cb": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4538. Allow use of legacy blockreader. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1461818 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/03/13 12:28 PM",
      "commitName": "694a6721316aea14c1244447974231abc8dff0cb",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,66 @@\n+  public synchronized long skip(long n) throws IOException {\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"skip \" + n);\n+    }\n+    if (n \u003c\u003d 0) {\n+      return 0;\n+    }\n+    if (!verifyChecksum) {\n+      return dataIn.skip(n);\n+    }\n+  \n+    // caller made sure newPosition is not beyond EOF.\n+    int remaining \u003d slowReadBuff.remaining();\n+    int position \u003d slowReadBuff.position();\n+    int newPosition \u003d position + (int)n;\n+  \n+    // if the new offset is already read into dataBuff, just reposition\n+    if (n \u003c\u003d remaining) {\n+      assert offsetFromChunkBoundary \u003d\u003d 0;\n+      slowReadBuff.position(newPosition);\n+      return n;\n+    }\n+  \n+    // for small gap, read through to keep the data/checksum in sync\n+    if (n - remaining \u003c\u003d bytesPerChecksum) {\n+      slowReadBuff.position(position + remaining);\n+      if (skipBuf \u003d\u003d null) {\n+        skipBuf \u003d new byte[bytesPerChecksum];\n+      }\n+      int ret \u003d read(skipBuf, 0, (int)(n - remaining));\n+      return ret;\n+    }\n+  \n+    // optimize for big gap: discard the current buffer, skip to\n+    // the beginning of the appropriate checksum chunk and then\n+    // read to the middle of that chunk to be in sync with checksums.\n+  \n+    // We can\u0027t use this.offsetFromChunkBoundary because we need to know how\n+    // many bytes of the offset were really read. Calling read(..) with a\n+    // positive this.offsetFromChunkBoundary causes that many bytes to get\n+    // silently skipped.\n+    int myOffsetFromChunkBoundary \u003d newPosition % bytesPerChecksum;\n+    long toskip \u003d n - remaining - myOffsetFromChunkBoundary;\n+\n+    slowReadBuff.position(slowReadBuff.limit());\n+    checksumBuff.position(checksumBuff.limit());\n+  \n+    IOUtils.skipFully(dataIn, toskip);\n+    long checkSumOffset \u003d (toskip / bytesPerChecksum) * checksumSize;\n+    IOUtils.skipFully(checksumIn, checkSumOffset);\n+\n+    // read into the middle of the chunk\n+    if (skipBuf \u003d\u003d null) {\n+      skipBuf \u003d new byte[bytesPerChecksum];\n+    }\n+    assert skipBuf.length \u003d\u003d bytesPerChecksum;\n+    assert myOffsetFromChunkBoundary \u003c bytesPerChecksum;\n+\n+    int ret \u003d read(skipBuf, 0, myOffsetFromChunkBoundary);\n+\n+    if (ret \u003d\u003d -1) {  // EOS\n+      return toskip;\n+    } else {\n+      return (toskip + ret);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized long skip(long n) throws IOException {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"skip \" + n);\n    }\n    if (n \u003c\u003d 0) {\n      return 0;\n    }\n    if (!verifyChecksum) {\n      return dataIn.skip(n);\n    }\n  \n    // caller made sure newPosition is not beyond EOF.\n    int remaining \u003d slowReadBuff.remaining();\n    int position \u003d slowReadBuff.position();\n    int newPosition \u003d position + (int)n;\n  \n    // if the new offset is already read into dataBuff, just reposition\n    if (n \u003c\u003d remaining) {\n      assert offsetFromChunkBoundary \u003d\u003d 0;\n      slowReadBuff.position(newPosition);\n      return n;\n    }\n  \n    // for small gap, read through to keep the data/checksum in sync\n    if (n - remaining \u003c\u003d bytesPerChecksum) {\n      slowReadBuff.position(position + remaining);\n      if (skipBuf \u003d\u003d null) {\n        skipBuf \u003d new byte[bytesPerChecksum];\n      }\n      int ret \u003d read(skipBuf, 0, (int)(n - remaining));\n      return ret;\n    }\n  \n    // optimize for big gap: discard the current buffer, skip to\n    // the beginning of the appropriate checksum chunk and then\n    // read to the middle of that chunk to be in sync with checksums.\n  \n    // We can\u0027t use this.offsetFromChunkBoundary because we need to know how\n    // many bytes of the offset were really read. Calling read(..) with a\n    // positive this.offsetFromChunkBoundary causes that many bytes to get\n    // silently skipped.\n    int myOffsetFromChunkBoundary \u003d newPosition % bytesPerChecksum;\n    long toskip \u003d n - remaining - myOffsetFromChunkBoundary;\n\n    slowReadBuff.position(slowReadBuff.limit());\n    checksumBuff.position(checksumBuff.limit());\n  \n    IOUtils.skipFully(dataIn, toskip);\n    long checkSumOffset \u003d (toskip / bytesPerChecksum) * checksumSize;\n    IOUtils.skipFully(checksumIn, checkSumOffset);\n\n    // read into the middle of the chunk\n    if (skipBuf \u003d\u003d null) {\n      skipBuf \u003d new byte[bytesPerChecksum];\n    }\n    assert skipBuf.length \u003d\u003d bytesPerChecksum;\n    assert myOffsetFromChunkBoundary \u003c bytesPerChecksum;\n\n    int ret \u003d read(skipBuf, 0, myOffsetFromChunkBoundary);\n\n    if (ret \u003d\u003d -1) {  // EOS\n      return toskip;\n    } else {\n      return (toskip + ret);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java"
    }
  }
}