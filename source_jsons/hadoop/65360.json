{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3AMultipartUploader.java",
  "functionName": "abort",
  "functionId": "abort___filePath-Path__uploadId-UploadHandle",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AMultipartUploader.java",
  "functionStartLine": 143,
  "functionEndLine": 151,
  "numCommitsSeen": 5,
  "timeTaken": 1270,
  "changeHistory": [
    "2ec97abb2e93c1a8127e7a146c08e26454b583fa",
    "980031bb043dd026a6bf42b0e71d304ac89294a5"
  ],
  "changeHistoryShort": {
    "2ec97abb2e93c1a8127e7a146c08e26454b583fa": "Ymultichange(Yexceptionschange,Ybodychange)",
    "980031bb043dd026a6bf42b0e71d304ac89294a5": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2ec97abb2e93c1a8127e7a146c08e26454b583fa": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HADOOP-15576. S3A Multipart Uploader to work with S3Guard and encryption Originally contributed by Ewan Higgs with refinements by Steve Loughran.\n",
      "commitDate": "08/08/18 4:50 AM",
      "commitName": "2ec97abb2e93c1a8127e7a146c08e26454b583fa",
      "commitAuthor": "Ewan Higgs",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HADOOP-15576. S3A Multipart Uploader to work with S3Guard and encryption Originally contributed by Ewan Higgs with refinements by Steve Loughran.\n",
          "commitDate": "08/08/18 4:50 AM",
          "commitName": "2ec97abb2e93c1a8127e7a146c08e26454b583fa",
          "commitAuthor": "Ewan Higgs",
          "commitDateOld": "17/06/18 11:54 AM",
          "commitNameOld": "980031bb043dd026a6bf42b0e71d304ac89294a5",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 51.71,
          "commitsBetweenForRepo": 308,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,10 +1,9 @@\n-  public void abort(Path filePath, UploadHandle uploadId) {\n+  public void abort(Path filePath, UploadHandle uploadId) throws IOException {\n+    final byte[] uploadIdBytes \u003d uploadId.toByteArray();\n+    checkUploadId(uploadIdBytes);\n+    final WriteOperationHelper writeHelper \u003d s3a.getWriteOperationHelper();\n     String key \u003d s3a.pathToKey(filePath);\n-    byte[] uploadIdBytes \u003d uploadId.toByteArray();\n     String uploadIdString \u003d new String(uploadIdBytes, 0, uploadIdBytes.length,\n         Charsets.UTF_8);\n-    AbortMultipartUploadRequest request \u003d new AbortMultipartUploadRequest(s3a\n-        .getBucket(), key, uploadIdString);\n-    LOG.debug(\"Abort request: {}\", request);\n-    s3a.getAmazonS3Client().abortMultipartUpload(request);\n+    writeHelper.abortMultipartCommit(key, uploadIdString);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void abort(Path filePath, UploadHandle uploadId) throws IOException {\n    final byte[] uploadIdBytes \u003d uploadId.toByteArray();\n    checkUploadId(uploadIdBytes);\n    final WriteOperationHelper writeHelper \u003d s3a.getWriteOperationHelper();\n    String key \u003d s3a.pathToKey(filePath);\n    String uploadIdString \u003d new String(uploadIdBytes, 0, uploadIdBytes.length,\n        Charsets.UTF_8);\n    writeHelper.abortMultipartCommit(key, uploadIdString);\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AMultipartUploader.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-15576. S3A Multipart Uploader to work with S3Guard and encryption Originally contributed by Ewan Higgs with refinements by Steve Loughran.\n",
          "commitDate": "08/08/18 4:50 AM",
          "commitName": "2ec97abb2e93c1a8127e7a146c08e26454b583fa",
          "commitAuthor": "Ewan Higgs",
          "commitDateOld": "17/06/18 11:54 AM",
          "commitNameOld": "980031bb043dd026a6bf42b0e71d304ac89294a5",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 51.71,
          "commitsBetweenForRepo": 308,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,10 +1,9 @@\n-  public void abort(Path filePath, UploadHandle uploadId) {\n+  public void abort(Path filePath, UploadHandle uploadId) throws IOException {\n+    final byte[] uploadIdBytes \u003d uploadId.toByteArray();\n+    checkUploadId(uploadIdBytes);\n+    final WriteOperationHelper writeHelper \u003d s3a.getWriteOperationHelper();\n     String key \u003d s3a.pathToKey(filePath);\n-    byte[] uploadIdBytes \u003d uploadId.toByteArray();\n     String uploadIdString \u003d new String(uploadIdBytes, 0, uploadIdBytes.length,\n         Charsets.UTF_8);\n-    AbortMultipartUploadRequest request \u003d new AbortMultipartUploadRequest(s3a\n-        .getBucket(), key, uploadIdString);\n-    LOG.debug(\"Abort request: {}\", request);\n-    s3a.getAmazonS3Client().abortMultipartUpload(request);\n+    writeHelper.abortMultipartCommit(key, uploadIdString);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void abort(Path filePath, UploadHandle uploadId) throws IOException {\n    final byte[] uploadIdBytes \u003d uploadId.toByteArray();\n    checkUploadId(uploadIdBytes);\n    final WriteOperationHelper writeHelper \u003d s3a.getWriteOperationHelper();\n    String key \u003d s3a.pathToKey(filePath);\n    String uploadIdString \u003d new String(uploadIdBytes, 0, uploadIdBytes.length,\n        Charsets.UTF_8);\n    writeHelper.abortMultipartCommit(key, uploadIdString);\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AMultipartUploader.java",
          "extendedDetails": {}
        }
      ]
    },
    "980031bb043dd026a6bf42b0e71d304ac89294a5": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13186. Multipart Uploader API. Contributed by Ewan Higgs\n",
      "commitDate": "17/06/18 11:54 AM",
      "commitName": "980031bb043dd026a6bf42b0e71d304ac89294a5",
      "commitAuthor": "Chris Douglas",
      "diff": "@@ -0,0 +1,10 @@\n+  public void abort(Path filePath, UploadHandle uploadId) {\n+    String key \u003d s3a.pathToKey(filePath);\n+    byte[] uploadIdBytes \u003d uploadId.toByteArray();\n+    String uploadIdString \u003d new String(uploadIdBytes, 0, uploadIdBytes.length,\n+        Charsets.UTF_8);\n+    AbortMultipartUploadRequest request \u003d new AbortMultipartUploadRequest(s3a\n+        .getBucket(), key, uploadIdString);\n+    LOG.debug(\"Abort request: {}\", request);\n+    s3a.getAmazonS3Client().abortMultipartUpload(request);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void abort(Path filePath, UploadHandle uploadId) {\n    String key \u003d s3a.pathToKey(filePath);\n    byte[] uploadIdBytes \u003d uploadId.toByteArray();\n    String uploadIdString \u003d new String(uploadIdBytes, 0, uploadIdBytes.length,\n        Charsets.UTF_8);\n    AbortMultipartUploadRequest request \u003d new AbortMultipartUploadRequest(s3a\n        .getBucket(), key, uploadIdString);\n    LOG.debug(\"Abort request: {}\", request);\n    s3a.getAmazonS3Client().abortMultipartUpload(request);\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AMultipartUploader.java"
    }
  }
}