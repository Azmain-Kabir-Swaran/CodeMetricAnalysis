{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSClient.java",
  "functionName": "getKeyProviderUri",
  "functionId": "getKeyProviderUri",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
  "functionStartLine": 3116,
  "functionEndLine": 3119,
  "numCommitsSeen": 363,
  "timeTaken": 8388,
  "changeHistory": [
    "5ec86b445cc492f52c33639efb6a09a0d2f27475",
    "404eab4dc0582e0384b93664ea6ee77ccd5eeebc",
    "cef2815cf48154fe82f44082dcbdce6373c81284",
    "18432130a7f580f206adf023507678c534487f2e",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "02340a24f211212b91dc7380c1e5b54ddb5e82eb",
    "d2d5a0ea03b0d461a4d376c7b9de8cd5c147effa",
    "3b35f81603bbfae119762b50bcb46de70a421368"
  ],
  "changeHistoryShort": {
    "5ec86b445cc492f52c33639efb6a09a0d2f27475": "Ymodifierchange",
    "404eab4dc0582e0384b93664ea6ee77ccd5eeebc": "Ybodychange",
    "cef2815cf48154fe82f44082dcbdce6373c81284": "Ybodychange",
    "18432130a7f580f206adf023507678c534487f2e": "Ymultichange(Yrename,Yreturntypechange,Ymodifierchange,Yexceptionschange,Ybodychange)",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "02340a24f211212b91dc7380c1e5b54ddb5e82eb": "Ybodychange",
    "d2d5a0ea03b0d461a4d376c7b9de8cd5c147effa": "Yreturntypechange",
    "3b35f81603bbfae119762b50bcb46de70a421368": "Yintroduced"
  },
  "changeHistoryDetails": {
    "5ec86b445cc492f52c33639efb6a09a0d2f27475": {
      "type": "Ymodifierchange",
      "commitMessage": "HADOOP-14445. Use DelegationTokenIssuer to create KMS delegation tokens that can authenticate to all KMS instances.\nContributed by Daryn Sharp, Xiao Chen, Rushabh S Shah.\n",
      "commitDate": "12/10/18 9:35 AM",
      "commitName": "5ec86b445cc492f52c33639efb6a09a0d2f27475",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "01/10/18 5:49 PM",
      "commitNameOld": "f6c5ef9903dba5eb268997110ef169125327c2c8",
      "commitAuthorOld": "Takanobu Asanuma",
      "daysBetweenCommits": 10.66,
      "commitsBetweenForRepo": 124,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,4 @@\n-  URI getKeyProviderUri() throws IOException {\n+  public URI getKeyProviderUri() throws IOException {\n     return HdfsKMSUtil.getKeyProviderUri(ugi, namenodeUri,\n         getServerDefaults().getKeyProviderUri(), conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public URI getKeyProviderUri() throws IOException {\n    return HdfsKMSUtil.getKeyProviderUri(ugi, namenodeUri,\n        getServerDefaults().getKeyProviderUri(), conf);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[public]"
      }
    },
    "404eab4dc0582e0384b93664ea6ee77ccd5eeebc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12396. Webhdfs file system should get delegation token from kms provider. Contributed by Rushabh S Shah.\n",
      "commitDate": "04/12/17 10:40 AM",
      "commitName": "404eab4dc0582e0384b93664ea6ee77ccd5eeebc",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "30/11/17 12:18 PM",
      "commitNameOld": "b1c7654ee40b372ed777525a42981c7cf55b5c72",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 3.93,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,4 @@\n   URI getKeyProviderUri() throws IOException {\n-    URI keyProviderUri \u003d null;\n-    // Lookup the secret in credentials object for namenodeuri.\n-    Credentials credentials \u003d ugi.getCredentials();\n-    byte[] keyProviderUriBytes \u003d credentials.getSecretKey(getKeyProviderMapKey());\n-    if(keyProviderUriBytes !\u003d null) {\n-      keyProviderUri \u003d\n-          URI.create(DFSUtilClient.bytes2String(keyProviderUriBytes));\n-      return keyProviderUri;\n-    }\n-\n-    // Query the namenode for the key provider uri.\n-    FsServerDefaults serverDefaults \u003d getServerDefaults();\n-    if (serverDefaults.getKeyProviderUri() !\u003d null) {\n-      if (!serverDefaults.getKeyProviderUri().isEmpty()) {\n-        keyProviderUri \u003d URI.create(serverDefaults.getKeyProviderUri());\n-      }\n-      return keyProviderUri;\n-    }\n-\n-    // Last thing is to trust its own conf to be backwards compatible.\n-    String keyProviderUriStr \u003d conf.getTrimmed(\n-        CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH);\n-    if (keyProviderUriStr !\u003d null \u0026\u0026 !keyProviderUriStr.isEmpty()) {\n-      keyProviderUri \u003d URI.create(keyProviderUriStr);\n-    }\n-    return keyProviderUri;\n+    return HdfsKMSUtil.getKeyProviderUri(ugi, namenodeUri,\n+        getServerDefaults().getKeyProviderUri(), conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URI getKeyProviderUri() throws IOException {\n    return HdfsKMSUtil.getKeyProviderUri(ugi, namenodeUri,\n        getServerDefaults().getKeyProviderUri(), conf);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {}
    },
    "cef2815cf48154fe82f44082dcbdce6373c81284": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11702. Remove indefinite caching of key provider uri in DFSClient. Contributed by Rushabh S Shah.\n",
      "commitDate": "08/05/17 6:27 AM",
      "commitName": "cef2815cf48154fe82f44082dcbdce6373c81284",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "04/05/17 12:06 PM",
      "commitNameOld": "25f5d9ad5ee5ead349d259a99b49541a70b1604d",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 3.76,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,28 @@\n   URI getKeyProviderUri() throws IOException {\n-    if (keyProviderUri !\u003d null) {\n-      return keyProviderUri;\n-    }\n-\n+    URI keyProviderUri \u003d null;\n     // Lookup the secret in credentials object for namenodeuri.\n     Credentials credentials \u003d ugi.getCredentials();\n     byte[] keyProviderUriBytes \u003d credentials.getSecretKey(getKeyProviderMapKey());\n     if(keyProviderUriBytes !\u003d null) {\n       keyProviderUri \u003d\n           URI.create(DFSUtilClient.bytes2String(keyProviderUriBytes));\n       return keyProviderUri;\n     }\n \n     // Query the namenode for the key provider uri.\n     FsServerDefaults serverDefaults \u003d getServerDefaults();\n     if (serverDefaults.getKeyProviderUri() !\u003d null) {\n       if (!serverDefaults.getKeyProviderUri().isEmpty()) {\n         keyProviderUri \u003d URI.create(serverDefaults.getKeyProviderUri());\n       }\n       return keyProviderUri;\n     }\n \n     // Last thing is to trust its own conf to be backwards compatible.\n     String keyProviderUriStr \u003d conf.getTrimmed(\n         CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH);\n     if (keyProviderUriStr !\u003d null \u0026\u0026 !keyProviderUriStr.isEmpty()) {\n       keyProviderUri \u003d URI.create(keyProviderUriStr);\n     }\n     return keyProviderUri;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  URI getKeyProviderUri() throws IOException {\n    URI keyProviderUri \u003d null;\n    // Lookup the secret in credentials object for namenodeuri.\n    Credentials credentials \u003d ugi.getCredentials();\n    byte[] keyProviderUriBytes \u003d credentials.getSecretKey(getKeyProviderMapKey());\n    if(keyProviderUriBytes !\u003d null) {\n      keyProviderUri \u003d\n          URI.create(DFSUtilClient.bytes2String(keyProviderUriBytes));\n      return keyProviderUri;\n    }\n\n    // Query the namenode for the key provider uri.\n    FsServerDefaults serverDefaults \u003d getServerDefaults();\n    if (serverDefaults.getKeyProviderUri() !\u003d null) {\n      if (!serverDefaults.getKeyProviderUri().isEmpty()) {\n        keyProviderUri \u003d URI.create(serverDefaults.getKeyProviderUri());\n      }\n      return keyProviderUri;\n    }\n\n    // Last thing is to trust its own conf to be backwards compatible.\n    String keyProviderUriStr \u003d conf.getTrimmed(\n        CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH);\n    if (keyProviderUriStr !\u003d null \u0026\u0026 !keyProviderUriStr.isEmpty()) {\n      keyProviderUri \u003d URI.create(keyProviderUriStr);\n    }\n    return keyProviderUri;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {}
    },
    "18432130a7f580f206adf023507678c534487f2e": {
      "type": "Ymultichange(Yrename,Yreturntypechange,Ymodifierchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "HADOOP-14104. Client should always ask namenode for kms provider path. Contributed by Rushabh S Shah.\n",
      "commitDate": "04/04/17 1:38 PM",
      "commitName": "18432130a7f580f206adf023507678c534487f2e",
      "commitAuthor": "Andrew Wang",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HADOOP-14104. Client should always ask namenode for kms provider path. Contributed by Rushabh S Shah.\n",
          "commitDate": "04/04/17 1:38 PM",
          "commitName": "18432130a7f580f206adf023507678c534487f2e",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "14/03/17 4:41 PM",
          "commitNameOld": "cc1292e73acd39c1f1023ad4841ffe30176f7daf",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 20.87,
          "commitsBetweenForRepo": 116,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,3 +1,31 @@\n-  public KeyProvider getKeyProvider() {\n-    return clientContext.getKeyProviderCache().get(conf);\n+  URI getKeyProviderUri() throws IOException {\n+    if (keyProviderUri !\u003d null) {\n+      return keyProviderUri;\n+    }\n+\n+    // Lookup the secret in credentials object for namenodeuri.\n+    Credentials credentials \u003d ugi.getCredentials();\n+    byte[] keyProviderUriBytes \u003d credentials.getSecretKey(getKeyProviderMapKey());\n+    if(keyProviderUriBytes !\u003d null) {\n+      keyProviderUri \u003d\n+          URI.create(DFSUtilClient.bytes2String(keyProviderUriBytes));\n+      return keyProviderUri;\n+    }\n+\n+    // Query the namenode for the key provider uri.\n+    FsServerDefaults serverDefaults \u003d getServerDefaults();\n+    if (serverDefaults.getKeyProviderUri() !\u003d null) {\n+      if (!serverDefaults.getKeyProviderUri().isEmpty()) {\n+        keyProviderUri \u003d URI.create(serverDefaults.getKeyProviderUri());\n+      }\n+      return keyProviderUri;\n+    }\n+\n+    // Last thing is to trust its own conf to be backwards compatible.\n+    String keyProviderUriStr \u003d conf.getTrimmed(\n+        CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH);\n+    if (keyProviderUriStr !\u003d null \u0026\u0026 !keyProviderUriStr.isEmpty()) {\n+      keyProviderUri \u003d URI.create(keyProviderUriStr);\n+    }\n+    return keyProviderUri;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  URI getKeyProviderUri() throws IOException {\n    if (keyProviderUri !\u003d null) {\n      return keyProviderUri;\n    }\n\n    // Lookup the secret in credentials object for namenodeuri.\n    Credentials credentials \u003d ugi.getCredentials();\n    byte[] keyProviderUriBytes \u003d credentials.getSecretKey(getKeyProviderMapKey());\n    if(keyProviderUriBytes !\u003d null) {\n      keyProviderUri \u003d\n          URI.create(DFSUtilClient.bytes2String(keyProviderUriBytes));\n      return keyProviderUri;\n    }\n\n    // Query the namenode for the key provider uri.\n    FsServerDefaults serverDefaults \u003d getServerDefaults();\n    if (serverDefaults.getKeyProviderUri() !\u003d null) {\n      if (!serverDefaults.getKeyProviderUri().isEmpty()) {\n        keyProviderUri \u003d URI.create(serverDefaults.getKeyProviderUri());\n      }\n      return keyProviderUri;\n    }\n\n    // Last thing is to trust its own conf to be backwards compatible.\n    String keyProviderUriStr \u003d conf.getTrimmed(\n        CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH);\n    if (keyProviderUriStr !\u003d null \u0026\u0026 !keyProviderUriStr.isEmpty()) {\n      keyProviderUri \u003d URI.create(keyProviderUriStr);\n    }\n    return keyProviderUri;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {
            "oldValue": "getKeyProvider",
            "newValue": "getKeyProviderUri"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HADOOP-14104. Client should always ask namenode for kms provider path. Contributed by Rushabh S Shah.\n",
          "commitDate": "04/04/17 1:38 PM",
          "commitName": "18432130a7f580f206adf023507678c534487f2e",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "14/03/17 4:41 PM",
          "commitNameOld": "cc1292e73acd39c1f1023ad4841ffe30176f7daf",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 20.87,
          "commitsBetweenForRepo": 116,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,3 +1,31 @@\n-  public KeyProvider getKeyProvider() {\n-    return clientContext.getKeyProviderCache().get(conf);\n+  URI getKeyProviderUri() throws IOException {\n+    if (keyProviderUri !\u003d null) {\n+      return keyProviderUri;\n+    }\n+\n+    // Lookup the secret in credentials object for namenodeuri.\n+    Credentials credentials \u003d ugi.getCredentials();\n+    byte[] keyProviderUriBytes \u003d credentials.getSecretKey(getKeyProviderMapKey());\n+    if(keyProviderUriBytes !\u003d null) {\n+      keyProviderUri \u003d\n+          URI.create(DFSUtilClient.bytes2String(keyProviderUriBytes));\n+      return keyProviderUri;\n+    }\n+\n+    // Query the namenode for the key provider uri.\n+    FsServerDefaults serverDefaults \u003d getServerDefaults();\n+    if (serverDefaults.getKeyProviderUri() !\u003d null) {\n+      if (!serverDefaults.getKeyProviderUri().isEmpty()) {\n+        keyProviderUri \u003d URI.create(serverDefaults.getKeyProviderUri());\n+      }\n+      return keyProviderUri;\n+    }\n+\n+    // Last thing is to trust its own conf to be backwards compatible.\n+    String keyProviderUriStr \u003d conf.getTrimmed(\n+        CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH);\n+    if (keyProviderUriStr !\u003d null \u0026\u0026 !keyProviderUriStr.isEmpty()) {\n+      keyProviderUri \u003d URI.create(keyProviderUriStr);\n+    }\n+    return keyProviderUri;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  URI getKeyProviderUri() throws IOException {\n    if (keyProviderUri !\u003d null) {\n      return keyProviderUri;\n    }\n\n    // Lookup the secret in credentials object for namenodeuri.\n    Credentials credentials \u003d ugi.getCredentials();\n    byte[] keyProviderUriBytes \u003d credentials.getSecretKey(getKeyProviderMapKey());\n    if(keyProviderUriBytes !\u003d null) {\n      keyProviderUri \u003d\n          URI.create(DFSUtilClient.bytes2String(keyProviderUriBytes));\n      return keyProviderUri;\n    }\n\n    // Query the namenode for the key provider uri.\n    FsServerDefaults serverDefaults \u003d getServerDefaults();\n    if (serverDefaults.getKeyProviderUri() !\u003d null) {\n      if (!serverDefaults.getKeyProviderUri().isEmpty()) {\n        keyProviderUri \u003d URI.create(serverDefaults.getKeyProviderUri());\n      }\n      return keyProviderUri;\n    }\n\n    // Last thing is to trust its own conf to be backwards compatible.\n    String keyProviderUriStr \u003d conf.getTrimmed(\n        CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH);\n    if (keyProviderUriStr !\u003d null \u0026\u0026 !keyProviderUriStr.isEmpty()) {\n      keyProviderUri \u003d URI.create(keyProviderUriStr);\n    }\n    return keyProviderUri;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {
            "oldValue": "KeyProvider",
            "newValue": "URI"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HADOOP-14104. Client should always ask namenode for kms provider path. Contributed by Rushabh S Shah.\n",
          "commitDate": "04/04/17 1:38 PM",
          "commitName": "18432130a7f580f206adf023507678c534487f2e",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "14/03/17 4:41 PM",
          "commitNameOld": "cc1292e73acd39c1f1023ad4841ffe30176f7daf",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 20.87,
          "commitsBetweenForRepo": 116,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,3 +1,31 @@\n-  public KeyProvider getKeyProvider() {\n-    return clientContext.getKeyProviderCache().get(conf);\n+  URI getKeyProviderUri() throws IOException {\n+    if (keyProviderUri !\u003d null) {\n+      return keyProviderUri;\n+    }\n+\n+    // Lookup the secret in credentials object for namenodeuri.\n+    Credentials credentials \u003d ugi.getCredentials();\n+    byte[] keyProviderUriBytes \u003d credentials.getSecretKey(getKeyProviderMapKey());\n+    if(keyProviderUriBytes !\u003d null) {\n+      keyProviderUri \u003d\n+          URI.create(DFSUtilClient.bytes2String(keyProviderUriBytes));\n+      return keyProviderUri;\n+    }\n+\n+    // Query the namenode for the key provider uri.\n+    FsServerDefaults serverDefaults \u003d getServerDefaults();\n+    if (serverDefaults.getKeyProviderUri() !\u003d null) {\n+      if (!serverDefaults.getKeyProviderUri().isEmpty()) {\n+        keyProviderUri \u003d URI.create(serverDefaults.getKeyProviderUri());\n+      }\n+      return keyProviderUri;\n+    }\n+\n+    // Last thing is to trust its own conf to be backwards compatible.\n+    String keyProviderUriStr \u003d conf.getTrimmed(\n+        CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH);\n+    if (keyProviderUriStr !\u003d null \u0026\u0026 !keyProviderUriStr.isEmpty()) {\n+      keyProviderUri \u003d URI.create(keyProviderUriStr);\n+    }\n+    return keyProviderUri;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  URI getKeyProviderUri() throws IOException {\n    if (keyProviderUri !\u003d null) {\n      return keyProviderUri;\n    }\n\n    // Lookup the secret in credentials object for namenodeuri.\n    Credentials credentials \u003d ugi.getCredentials();\n    byte[] keyProviderUriBytes \u003d credentials.getSecretKey(getKeyProviderMapKey());\n    if(keyProviderUriBytes !\u003d null) {\n      keyProviderUri \u003d\n          URI.create(DFSUtilClient.bytes2String(keyProviderUriBytes));\n      return keyProviderUri;\n    }\n\n    // Query the namenode for the key provider uri.\n    FsServerDefaults serverDefaults \u003d getServerDefaults();\n    if (serverDefaults.getKeyProviderUri() !\u003d null) {\n      if (!serverDefaults.getKeyProviderUri().isEmpty()) {\n        keyProviderUri \u003d URI.create(serverDefaults.getKeyProviderUri());\n      }\n      return keyProviderUri;\n    }\n\n    // Last thing is to trust its own conf to be backwards compatible.\n    String keyProviderUriStr \u003d conf.getTrimmed(\n        CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH);\n    if (keyProviderUriStr !\u003d null \u0026\u0026 !keyProviderUriStr.isEmpty()) {\n      keyProviderUri \u003d URI.create(keyProviderUriStr);\n    }\n    return keyProviderUri;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "HADOOP-14104. Client should always ask namenode for kms provider path. Contributed by Rushabh S Shah.\n",
          "commitDate": "04/04/17 1:38 PM",
          "commitName": "18432130a7f580f206adf023507678c534487f2e",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "14/03/17 4:41 PM",
          "commitNameOld": "cc1292e73acd39c1f1023ad4841ffe30176f7daf",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 20.87,
          "commitsBetweenForRepo": 116,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,3 +1,31 @@\n-  public KeyProvider getKeyProvider() {\n-    return clientContext.getKeyProviderCache().get(conf);\n+  URI getKeyProviderUri() throws IOException {\n+    if (keyProviderUri !\u003d null) {\n+      return keyProviderUri;\n+    }\n+\n+    // Lookup the secret in credentials object for namenodeuri.\n+    Credentials credentials \u003d ugi.getCredentials();\n+    byte[] keyProviderUriBytes \u003d credentials.getSecretKey(getKeyProviderMapKey());\n+    if(keyProviderUriBytes !\u003d null) {\n+      keyProviderUri \u003d\n+          URI.create(DFSUtilClient.bytes2String(keyProviderUriBytes));\n+      return keyProviderUri;\n+    }\n+\n+    // Query the namenode for the key provider uri.\n+    FsServerDefaults serverDefaults \u003d getServerDefaults();\n+    if (serverDefaults.getKeyProviderUri() !\u003d null) {\n+      if (!serverDefaults.getKeyProviderUri().isEmpty()) {\n+        keyProviderUri \u003d URI.create(serverDefaults.getKeyProviderUri());\n+      }\n+      return keyProviderUri;\n+    }\n+\n+    // Last thing is to trust its own conf to be backwards compatible.\n+    String keyProviderUriStr \u003d conf.getTrimmed(\n+        CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH);\n+    if (keyProviderUriStr !\u003d null \u0026\u0026 !keyProviderUriStr.isEmpty()) {\n+      keyProviderUri \u003d URI.create(keyProviderUriStr);\n+    }\n+    return keyProviderUri;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  URI getKeyProviderUri() throws IOException {\n    if (keyProviderUri !\u003d null) {\n      return keyProviderUri;\n    }\n\n    // Lookup the secret in credentials object for namenodeuri.\n    Credentials credentials \u003d ugi.getCredentials();\n    byte[] keyProviderUriBytes \u003d credentials.getSecretKey(getKeyProviderMapKey());\n    if(keyProviderUriBytes !\u003d null) {\n      keyProviderUri \u003d\n          URI.create(DFSUtilClient.bytes2String(keyProviderUriBytes));\n      return keyProviderUri;\n    }\n\n    // Query the namenode for the key provider uri.\n    FsServerDefaults serverDefaults \u003d getServerDefaults();\n    if (serverDefaults.getKeyProviderUri() !\u003d null) {\n      if (!serverDefaults.getKeyProviderUri().isEmpty()) {\n        keyProviderUri \u003d URI.create(serverDefaults.getKeyProviderUri());\n      }\n      return keyProviderUri;\n    }\n\n    // Last thing is to trust its own conf to be backwards compatible.\n    String keyProviderUriStr \u003d conf.getTrimmed(\n        CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH);\n    if (keyProviderUriStr !\u003d null \u0026\u0026 !keyProviderUriStr.isEmpty()) {\n      keyProviderUri \u003d URI.create(keyProviderUriStr);\n    }\n    return keyProviderUri;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-14104. Client should always ask namenode for kms provider path. Contributed by Rushabh S Shah.\n",
          "commitDate": "04/04/17 1:38 PM",
          "commitName": "18432130a7f580f206adf023507678c534487f2e",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "14/03/17 4:41 PM",
          "commitNameOld": "cc1292e73acd39c1f1023ad4841ffe30176f7daf",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 20.87,
          "commitsBetweenForRepo": 116,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,3 +1,31 @@\n-  public KeyProvider getKeyProvider() {\n-    return clientContext.getKeyProviderCache().get(conf);\n+  URI getKeyProviderUri() throws IOException {\n+    if (keyProviderUri !\u003d null) {\n+      return keyProviderUri;\n+    }\n+\n+    // Lookup the secret in credentials object for namenodeuri.\n+    Credentials credentials \u003d ugi.getCredentials();\n+    byte[] keyProviderUriBytes \u003d credentials.getSecretKey(getKeyProviderMapKey());\n+    if(keyProviderUriBytes !\u003d null) {\n+      keyProviderUri \u003d\n+          URI.create(DFSUtilClient.bytes2String(keyProviderUriBytes));\n+      return keyProviderUri;\n+    }\n+\n+    // Query the namenode for the key provider uri.\n+    FsServerDefaults serverDefaults \u003d getServerDefaults();\n+    if (serverDefaults.getKeyProviderUri() !\u003d null) {\n+      if (!serverDefaults.getKeyProviderUri().isEmpty()) {\n+        keyProviderUri \u003d URI.create(serverDefaults.getKeyProviderUri());\n+      }\n+      return keyProviderUri;\n+    }\n+\n+    // Last thing is to trust its own conf to be backwards compatible.\n+    String keyProviderUriStr \u003d conf.getTrimmed(\n+        CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH);\n+    if (keyProviderUriStr !\u003d null \u0026\u0026 !keyProviderUriStr.isEmpty()) {\n+      keyProviderUri \u003d URI.create(keyProviderUriStr);\n+    }\n+    return keyProviderUri;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  URI getKeyProviderUri() throws IOException {\n    if (keyProviderUri !\u003d null) {\n      return keyProviderUri;\n    }\n\n    // Lookup the secret in credentials object for namenodeuri.\n    Credentials credentials \u003d ugi.getCredentials();\n    byte[] keyProviderUriBytes \u003d credentials.getSecretKey(getKeyProviderMapKey());\n    if(keyProviderUriBytes !\u003d null) {\n      keyProviderUri \u003d\n          URI.create(DFSUtilClient.bytes2String(keyProviderUriBytes));\n      return keyProviderUri;\n    }\n\n    // Query the namenode for the key provider uri.\n    FsServerDefaults serverDefaults \u003d getServerDefaults();\n    if (serverDefaults.getKeyProviderUri() !\u003d null) {\n      if (!serverDefaults.getKeyProviderUri().isEmpty()) {\n        keyProviderUri \u003d URI.create(serverDefaults.getKeyProviderUri());\n      }\n      return keyProviderUri;\n    }\n\n    // Last thing is to trust its own conf to be backwards compatible.\n    String keyProviderUriStr \u003d conf.getTrimmed(\n        CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH);\n    if (keyProviderUriStr !\u003d null \u0026\u0026 !keyProviderUriStr.isEmpty()) {\n      keyProviderUri \u003d URI.create(keyProviderUriStr);\n    }\n    return keyProviderUri;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {}
        }
      ]
    },
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public KeyProvider getKeyProvider() {\n    return clientContext.getKeyProviderCache().get(conf);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java"
      }
    },
    "02340a24f211212b91dc7380c1e5b54ddb5e82eb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7718. Store KeyProvider in ClientContext to avoid leaking key provider threads when using FileContext (Arun Suresh via Colin P. McCabe)\n",
      "commitDate": "09/02/15 8:23 PM",
      "commitName": "02340a24f211212b91dc7380c1e5b54ddb5e82eb",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "06/02/15 5:01 PM",
      "commitNameOld": "8de80ff71234f8fb005f297f1ce6d4755633d5e4",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 3.14,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,3 @@\n   public KeyProvider getKeyProvider() {\n-    return provider;\n+    return clientContext.getKeyProviderCache().get(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public KeyProvider getKeyProvider() {\n    return clientContext.getKeyProviderCache().get(conf);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {}
    },
    "d2d5a0ea03b0d461a4d376c7b9de8cd5c147effa": {
      "type": "Yreturntypechange",
      "commitMessage": "HDFS-7179. DFSClient should instantiate a KeyProvider, not a KeyProviderCryptoExtension. (wang)\n",
      "commitDate": "02/10/14 1:50 PM",
      "commitName": "d2d5a0ea03b0d461a4d376c7b9de8cd5c147effa",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "29/09/14 2:14 PM",
      "commitNameOld": "7f0efe96f85704e39349f20ab6a11bfaa81c6a75",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 2.98,
      "commitsBetweenForRepo": 42,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,3 @@\n-  public KeyProviderCryptoExtension getKeyProvider() {\n+  public KeyProvider getKeyProvider() {\n     return provider;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public KeyProvider getKeyProvider() {\n    return provider;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {
        "oldValue": "KeyProviderCryptoExtension",
        "newValue": "KeyProvider"
      }
    },
    "3b35f81603bbfae119762b50bcb46de70a421368": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6986. DistributedFileSystem must get delegation tokens from configured KeyProvider. (zhz via tucu)\n",
      "commitDate": "05/09/14 10:33 PM",
      "commitName": "3b35f81603bbfae119762b50bcb46de70a421368",
      "commitAuthor": "Alejandro Abdelnur",
      "diff": "@@ -0,0 +1,3 @@\n+  public KeyProviderCryptoExtension getKeyProvider() {\n+    return provider;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public KeyProviderCryptoExtension getKeyProvider() {\n    return provider;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java"
    }
  }
}