{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RpcProgramNfs3.java",
  "functionName": "fsstat",
  "functionId": "fsstat___xdr-XDR__securityHandler-SecurityHandler__remoteAddress-SocketAddress",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
  "functionStartLine": 1876,
  "functionEndLine": 1945,
  "numCommitsSeen": 140,
  "timeTaken": 5624,
  "changeHistory": [
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
    "d6602b5f39833611b4afa4581552f6c4c37e23a8",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f",
    "5e5e35b1856293503124b77d5d4998a4d8e83082",
    "d71d40a63d198991077d5babd70be5e9787a53f1",
    "cd9182d8b5f60428f6c91b0eb0b2e61d52a07020",
    "c9aa74743773c61be938cc1a6ea811ae1404bca2",
    "2ecab65e3e290a1ee192b39ec70868863853543a",
    "c55947343e0a629f71d69b49ba87997573fe48a2",
    "0ec6fc9e3c59c474f45e0fa68bb511778070a13c",
    "05f35518f19d48890770128727289582cca3457b",
    "613979c8fdacf25fd563395ecc399c4de94d3ee7",
    "15632cd76f12c2f7df50d0df4865fbe3d8261597",
    "37f587563a943a827fbff865f5302bac6d202415"
  ],
  "changeHistoryShort": {
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": "Ybodychange",
    "d6602b5f39833611b4afa4581552f6c4c37e23a8": "Ybodychange",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": "Ybodychange",
    "5e5e35b1856293503124b77d5d4998a4d8e83082": "Ybodychange",
    "d71d40a63d198991077d5babd70be5e9787a53f1": "Ybodychange",
    "cd9182d8b5f60428f6c91b0eb0b2e61d52a07020": "Ybodychange",
    "c9aa74743773c61be938cc1a6ea811ae1404bca2": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
    "2ecab65e3e290a1ee192b39ec70868863853543a": "Ymultichange(Yparameterchange,Ybodychange)",
    "c55947343e0a629f71d69b49ba87997573fe48a2": "Ybodychange",
    "0ec6fc9e3c59c474f45e0fa68bb511778070a13c": "Ybodychange",
    "05f35518f19d48890770128727289582cca3457b": "Ybodychange",
    "613979c8fdacf25fd563395ecc399c4de94d3ee7": "Ymultichange(Yparameterchange,Ybodychange)",
    "15632cd76f12c2f7df50d0df4865fbe3d8261597": "Ymultichange(Yparameterchange,Ybodychange)",
    "37f587563a943a827fbff865f5302bac6d202415": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10571. Use Log.*(Object, Throwable) overload to log exceptions.\nContributed by Andras Bokor.\n",
      "commitDate": "14/02/18 8:20 AM",
      "commitName": "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "10/10/17 10:38 AM",
      "commitNameOld": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
      "commitAuthorOld": "Jitendra Pandey",
      "daysBetweenCommits": 126.95,
      "commitsBetweenForRepo": 833,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,71 +1,70 @@\n   FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n \n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n \n \n     FSSTAT3Request request;\n     try {\n       request \u003d FSSTAT3Request.deserialize(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     int namenodeId \u003d handle.getNamenodeId();\n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"NFS FSSTAT fileHandle: \" + handle.dumpFileHandle()\n-          + \" client: \" + remoteAddress);\n+      LOG.debug(\"NFS FSSTAT fileHandle: {} client: {}\",\n+          handle.dumpFileHandle(), remoteAddress);\n     }\n-\n     DFSClient dfsClient \u003d\n         clientCache.getDfsClient(securityHandler.getUser(), namenodeId);\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n \n     try {\n       FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n \n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n-        LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n+        LOG.info(\"Can\u0027t get path for fileId: {}\", handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n \n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n \n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n     } catch (RemoteException r) {\n-      LOG.warn(\"Exception \", r);\n+      LOG.warn(\"Exception\", r);\n       IOException io \u003d r.unwrapRemoteException();\n       /**\n        * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n        */\n       if (io instanceof AuthorizationException) {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n       } else {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n       }\n     } catch (IOException e) {\n-      LOG.warn(\"Exception \", e);\n+      LOG.warn(\"Exception\", e);\n       int status \u003d mapErrorStatus(e);\n       return new FSSTAT3Response(status);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n\n\n    FSSTAT3Request request;\n    try {\n      request \u003d FSSTAT3Request.deserialize(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    int namenodeId \u003d handle.getNamenodeId();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileHandle: {} client: {}\",\n          handle.dumpFileHandle(), remoteAddress);\n    }\n    DFSClient dfsClient \u003d\n        clientCache.getDfsClient(securityHandler.getUser(), namenodeId);\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n\n    try {\n      FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n\n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId: {}\", handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n\n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n\n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (RemoteException r) {\n      LOG.warn(\"Exception\", r);\n      IOException io \u003d r.unwrapRemoteException();\n      /**\n       * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n       */\n      if (io instanceof AuthorizationException) {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n      } else {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception\", e);\n      int status \u003d mapErrorStatus(e);\n      return new FSSTAT3Response(status);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "d6602b5f39833611b4afa4581552f6c4c37e23a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11575. Supporting HDFS NFS gateway with Federated HDFS. Contributed by Mukul Kumar Singh.\n",
      "commitDate": "10/10/17 10:38 AM",
      "commitName": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
      "commitAuthor": "Jitendra Pandey",
      "commitDateOld": "14/08/17 9:57 PM",
      "commitNameOld": "645a8f2a4d09acb5a21820f52ee78784d9e4cc8a",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 56.53,
      "commitsBetweenForRepo": 520,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,71 @@\n   FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n \n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n \n-    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n-    if (dfsClient \u003d\u003d null) {\n-      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n-      return response;\n-    }\n \n     FSSTAT3Request request;\n     try {\n       request \u003d FSSTAT3Request.deserialize(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n+    int namenodeId \u003d handle.getNamenodeId();\n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId() + \" client: \"\n-          + remoteAddress);\n+      LOG.debug(\"NFS FSSTAT fileHandle: \" + handle.dumpFileHandle()\n+          + \" client: \" + remoteAddress);\n+    }\n+\n+    DFSClient dfsClient \u003d\n+        clientCache.getDfsClient(securityHandler.getUser(), namenodeId);\n+    if (dfsClient \u003d\u003d null) {\n+      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n+      return response;\n     }\n \n     try {\n       FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n \n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n \n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n \n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n     } catch (RemoteException r) {\n       LOG.warn(\"Exception \", r);\n       IOException io \u003d r.unwrapRemoteException();\n       /**\n        * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n        */\n       if (io instanceof AuthorizationException) {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n       } else {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       int status \u003d mapErrorStatus(e);\n       return new FSSTAT3Response(status);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n\n\n    FSSTAT3Request request;\n    try {\n      request \u003d FSSTAT3Request.deserialize(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    int namenodeId \u003d handle.getNamenodeId();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileHandle: \" + handle.dumpFileHandle()\n          + \" client: \" + remoteAddress);\n    }\n\n    DFSClient dfsClient \u003d\n        clientCache.getDfsClient(securityHandler.getUser(), namenodeId);\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n\n    try {\n      FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n\n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n\n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n\n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (RemoteException r) {\n      LOG.warn(\"Exception \", r);\n      IOException io \u003d r.unwrapRemoteException();\n      /**\n       * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n       */\n      if (io instanceof AuthorizationException) {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n      } else {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new FSSTAT3Response(status);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7423. various typos and message formatting fixes in nfs daemon and doc. (Charles Lamb via yliu)\n",
      "commitDate": "28/01/15 12:56 PM",
      "commitName": "f37849188b05a6251584de1aed5e66d5dfa7da4f",
      "commitAuthor": "yliu",
      "commitDateOld": "19/01/15 5:29 PM",
      "commitNameOld": "5e5e35b1856293503124b77d5d4998a4d8e83082",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 8.81,
      "commitsBetweenForRepo": 76,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,68 @@\n   FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n \n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n \n     FSSTAT3Request request;\n     try {\n       request \u003d FSSTAT3Request.deserialize(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId() + \" client:\"\n+      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId() + \" client: \"\n           + remoteAddress);\n     }\n \n     try {\n       FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n \n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n-        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n+        LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n \n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n \n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n     } catch (RemoteException r) {\n       LOG.warn(\"Exception \", r);\n       IOException io \u003d r.unwrapRemoteException();\n       /**\n        * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n        */\n       if (io instanceof AuthorizationException) {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n       } else {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       int status \u003d mapErrorStatus(e);\n       return new FSSTAT3Response(status);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n\n    FSSTAT3Request request;\n    try {\n      request \u003d FSSTAT3Request.deserialize(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId() + \" client: \"\n          + remoteAddress);\n    }\n\n    try {\n      FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n\n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n\n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n\n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (RemoteException r) {\n      LOG.warn(\"Exception \", r);\n      IOException io \u003d r.unwrapRemoteException();\n      /**\n       * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n       */\n      if (io instanceof AuthorizationException) {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n      } else {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new FSSTAT3Response(status);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "5e5e35b1856293503124b77d5d4998a4d8e83082": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7640. print NFS Client in the NFS log. Contributed by Brandon Li.\n",
      "commitDate": "19/01/15 5:29 PM",
      "commitName": "5e5e35b1856293503124b77d5d4998a4d8e83082",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "11/12/14 3:40 PM",
      "commitNameOld": "f6f2a3f1c73266bfedd802eacde60d8b19b81015",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 39.08,
      "commitsBetweenForRepo": 202,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,68 @@\n   FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n \n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n \n     FSSTAT3Request request;\n     try {\n       request \u003d FSSTAT3Request.deserialize(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n+      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId() + \" client:\"\n+          + remoteAddress);\n     }\n \n     try {\n       FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n \n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n \n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n \n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n     } catch (RemoteException r) {\n       LOG.warn(\"Exception \", r);\n       IOException io \u003d r.unwrapRemoteException();\n       /**\n        * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n        */\n       if (io instanceof AuthorizationException) {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n       } else {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       int status \u003d mapErrorStatus(e);\n       return new FSSTAT3Response(status);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n\n    FSSTAT3Request request;\n    try {\n      request \u003d FSSTAT3Request.deserialize(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId() + \" client:\"\n          + remoteAddress);\n    }\n\n    try {\n      FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n\n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n\n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n\n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (RemoteException r) {\n      LOG.warn(\"Exception \", r);\n      IOException io \u003d r.unwrapRemoteException();\n      /**\n       * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n       */\n      if (io instanceof AuthorizationException) {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n      } else {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new FSSTAT3Response(status);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "d71d40a63d198991077d5babd70be5e9787a53f1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7180. NFSv3 gateway frequently gets stuck due to GC. Contributed by Brandon Li\n",
      "commitDate": "22/10/14 9:27 PM",
      "commitName": "d71d40a63d198991077d5babd70be5e9787a53f1",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "21/10/14 11:49 AM",
      "commitNameOld": "4e134a02a4b6f30704b99dfb166dc361daf426ea",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 1.4,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,67 @@\n   FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n \n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n \n-    FSSTAT3Request request \u003d null;\n+    FSSTAT3Request request;\n     try {\n       request \u003d FSSTAT3Request.deserialize(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n     }\n \n     try {\n       FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n \n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n \n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n \n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n     } catch (RemoteException r) {\n       LOG.warn(\"Exception \", r);\n       IOException io \u003d r.unwrapRemoteException();\n       /**\n        * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n        */\n       if (io instanceof AuthorizationException) {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n       } else {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       int status \u003d mapErrorStatus(e);\n       return new FSSTAT3Response(status);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n\n    FSSTAT3Request request;\n    try {\n      request \u003d FSSTAT3Request.deserialize(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n    }\n\n    try {\n      FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n\n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n\n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n\n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (RemoteException r) {\n      LOG.warn(\"Exception \", r);\n      IOException io \u003d r.unwrapRemoteException();\n      /**\n       * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n       */\n      if (io instanceof AuthorizationException) {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n      } else {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new FSSTAT3Response(status);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "cd9182d8b5f60428f6c91b0eb0b2e61d52a07020": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6892. Add XDR packaging method for each NFS request. Contributed by Brandon Li\n",
      "commitDate": "27/08/14 11:06 AM",
      "commitName": "cd9182d8b5f60428f6c91b0eb0b2e61d52a07020",
      "commitAuthor": "brandonli",
      "commitDateOld": "21/08/14 10:53 AM",
      "commitNameOld": "7b28f363b1b3f12cecc92d0bba8eb3021b67b48e",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 6.01,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,67 @@\n   FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n \n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n \n     FSSTAT3Request request \u003d null;\n     try {\n-      request \u003d new FSSTAT3Request(xdr);\n+      request \u003d FSSTAT3Request.deserialize(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n     }\n \n     try {\n       FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n \n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n \n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n \n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n     } catch (RemoteException r) {\n       LOG.warn(\"Exception \", r);\n       IOException io \u003d r.unwrapRemoteException();\n       /**\n        * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n        */\n       if (io instanceof AuthorizationException) {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n       } else {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       int status \u003d mapErrorStatus(e);\n       return new FSSTAT3Response(status);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n\n    FSSTAT3Request request \u003d null;\n    try {\n      request \u003d FSSTAT3Request.deserialize(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n    }\n\n    try {\n      FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n\n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n\n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n\n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (RemoteException r) {\n      LOG.warn(\"Exception \", r);\n      IOException io \u003d r.unwrapRemoteException();\n      /**\n       * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n       */\n      if (io instanceof AuthorizationException) {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n      } else {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new FSSTAT3Response(status);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "c9aa74743773c61be938cc1a6ea811ae1404bca2": {
      "type": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-6451. NFS should not return NFS3ERR_IO for AccessControlException. Contributed by Abhiraj Butala\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1615702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/08/14 10:40 AM",
      "commitName": "c9aa74743773c61be938cc1a6ea811ae1404bca2",
      "commitAuthor": "Brandon Li",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6451. NFS should not return NFS3ERR_IO for AccessControlException. Contributed by Abhiraj Butala\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1615702 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/08/14 10:40 AM",
          "commitName": "c9aa74743773c61be938cc1a6ea811ae1404bca2",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "23/07/14 2:22 PM",
          "commitNameOld": "2a5f1029a5221c42ab61b22f99d79251ed069ca4",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 11.85,
          "commitsBetweenForRepo": 69,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,66 +1,67 @@\n-  public FSSTAT3Response fsstat(XDR xdr, RpcInfo info) {\n+  FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n+      SocketAddress remoteAddress) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n-    \n-    if (!checkAccessPrivilege(info, AccessPrivilege.READ_ONLY)) {\n+\n+    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n-    \n-    SecurityHandler securityHandler \u003d getSecurityHandler(info);\n+\n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n-    \n+\n     FSSTAT3Request request \u003d null;\n     try {\n       request \u003d new FSSTAT3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n     }\n \n     try {\n       FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n-      \n+\n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n-      \n+\n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n-      \n+\n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n     } catch (RemoteException r) {\n       LOG.warn(\"Exception \", r);\n       IOException io \u003d r.unwrapRemoteException();\n       /**\n        * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n        */\n       if (io instanceof AuthorizationException) {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n       } else {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n-      return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n+      int status \u003d mapErrorStatus(e);\n+      return new FSSTAT3Response(status);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n\n    FSSTAT3Request request \u003d null;\n    try {\n      request \u003d new FSSTAT3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n    }\n\n    try {\n      FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n\n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n\n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n\n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (RemoteException r) {\n      LOG.warn(\"Exception \", r);\n      IOException io \u003d r.unwrapRemoteException();\n      /**\n       * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n       */\n      if (io instanceof AuthorizationException) {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n      } else {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new FSSTAT3Response(status);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {
            "oldValue": "[xdr-XDR, info-RpcInfo]",
            "newValue": "[xdr-XDR, securityHandler-SecurityHandler, remoteAddress-SocketAddress]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-6451. NFS should not return NFS3ERR_IO for AccessControlException. Contributed by Abhiraj Butala\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1615702 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/08/14 10:40 AM",
          "commitName": "c9aa74743773c61be938cc1a6ea811ae1404bca2",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "23/07/14 2:22 PM",
          "commitNameOld": "2a5f1029a5221c42ab61b22f99d79251ed069ca4",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 11.85,
          "commitsBetweenForRepo": 69,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,66 +1,67 @@\n-  public FSSTAT3Response fsstat(XDR xdr, RpcInfo info) {\n+  FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n+      SocketAddress remoteAddress) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n-    \n-    if (!checkAccessPrivilege(info, AccessPrivilege.READ_ONLY)) {\n+\n+    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n-    \n-    SecurityHandler securityHandler \u003d getSecurityHandler(info);\n+\n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n-    \n+\n     FSSTAT3Request request \u003d null;\n     try {\n       request \u003d new FSSTAT3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n     }\n \n     try {\n       FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n-      \n+\n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n-      \n+\n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n-      \n+\n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n     } catch (RemoteException r) {\n       LOG.warn(\"Exception \", r);\n       IOException io \u003d r.unwrapRemoteException();\n       /**\n        * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n        */\n       if (io instanceof AuthorizationException) {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n       } else {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n-      return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n+      int status \u003d mapErrorStatus(e);\n+      return new FSSTAT3Response(status);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n\n    FSSTAT3Request request \u003d null;\n    try {\n      request \u003d new FSSTAT3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n    }\n\n    try {\n      FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n\n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n\n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n\n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (RemoteException r) {\n      LOG.warn(\"Exception \", r);\n      IOException io \u003d r.unwrapRemoteException();\n      /**\n       * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n       */\n      if (io instanceof AuthorizationException) {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n      } else {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new FSSTAT3Response(status);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6451. NFS should not return NFS3ERR_IO for AccessControlException. Contributed by Abhiraj Butala\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1615702 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/08/14 10:40 AM",
          "commitName": "c9aa74743773c61be938cc1a6ea811ae1404bca2",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "23/07/14 2:22 PM",
          "commitNameOld": "2a5f1029a5221c42ab61b22f99d79251ed069ca4",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 11.85,
          "commitsBetweenForRepo": 69,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,66 +1,67 @@\n-  public FSSTAT3Response fsstat(XDR xdr, RpcInfo info) {\n+  FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n+      SocketAddress remoteAddress) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n-    \n-    if (!checkAccessPrivilege(info, AccessPrivilege.READ_ONLY)) {\n+\n+    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n-    \n-    SecurityHandler securityHandler \u003d getSecurityHandler(info);\n+\n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n-    \n+\n     FSSTAT3Request request \u003d null;\n     try {\n       request \u003d new FSSTAT3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n     }\n \n     try {\n       FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n-      \n+\n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n-      \n+\n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n-      \n+\n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n     } catch (RemoteException r) {\n       LOG.warn(\"Exception \", r);\n       IOException io \u003d r.unwrapRemoteException();\n       /**\n        * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n        */\n       if (io instanceof AuthorizationException) {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n       } else {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n-      return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n+      int status \u003d mapErrorStatus(e);\n+      return new FSSTAT3Response(status);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n\n    FSSTAT3Request request \u003d null;\n    try {\n      request \u003d new FSSTAT3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n    }\n\n    try {\n      FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n\n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n\n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n\n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (RemoteException r) {\n      LOG.warn(\"Exception \", r);\n      IOException io \u003d r.unwrapRemoteException();\n      /**\n       * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n       */\n      if (io instanceof AuthorizationException) {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n      } else {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new FSSTAT3Response(status);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {}
        }
      ]
    },
    "2ecab65e3e290a1ee192b39ec70868863853543a": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6439. NFS should not reject NFS requests to the NULL procedure whether port monitoring is enabled or not. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603622 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/06/14 1:45 PM",
      "commitName": "2ecab65e3e290a1ee192b39ec70868863853543a",
      "commitAuthor": "Brandon Li",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6439. NFS should not reject NFS requests to the NULL procedure whether port monitoring is enabled or not. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603622 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/06/14 1:45 PM",
          "commitName": "2ecab65e3e290a1ee192b39ec70868863853543a",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "30/05/14 4:53 PM",
          "commitNameOld": "42391d260da400593812396c1ffd45d1a371d3cb",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 18.87,
          "commitsBetweenForRepo": 106,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,66 +1,66 @@\n-  public FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n-      InetAddress client) {\n+  public FSSTAT3Response fsstat(XDR xdr, RpcInfo info) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n     \n-    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n+    if (!checkAccessPrivilege(info, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n     \n+    SecurityHandler securityHandler \u003d getSecurityHandler(info);\n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n     \n     FSSTAT3Request request \u003d null;\n     try {\n       request \u003d new FSSTAT3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n     }\n \n     try {\n       FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n       \n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       \n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n       \n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n     } catch (RemoteException r) {\n       LOG.warn(\"Exception \", r);\n       IOException io \u003d r.unwrapRemoteException();\n       /**\n        * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n        */\n       if (io instanceof AuthorizationException) {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n       } else {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public FSSTAT3Response fsstat(XDR xdr, RpcInfo info) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n    \n    if (!checkAccessPrivilege(info, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n    \n    SecurityHandler securityHandler \u003d getSecurityHandler(info);\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n    \n    FSSTAT3Request request \u003d null;\n    try {\n      request \u003d new FSSTAT3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n    }\n\n    try {\n      FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n      \n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      \n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n      \n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (RemoteException r) {\n      LOG.warn(\"Exception \", r);\n      IOException io \u003d r.unwrapRemoteException();\n      /**\n       * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n       */\n      if (io instanceof AuthorizationException) {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n      } else {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {
            "oldValue": "[xdr-XDR, securityHandler-SecurityHandler, client-InetAddress]",
            "newValue": "[xdr-XDR, info-RpcInfo]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6439. NFS should not reject NFS requests to the NULL procedure whether port monitoring is enabled or not. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603622 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/06/14 1:45 PM",
          "commitName": "2ecab65e3e290a1ee192b39ec70868863853543a",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "30/05/14 4:53 PM",
          "commitNameOld": "42391d260da400593812396c1ffd45d1a371d3cb",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 18.87,
          "commitsBetweenForRepo": 106,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,66 +1,66 @@\n-  public FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n-      InetAddress client) {\n+  public FSSTAT3Response fsstat(XDR xdr, RpcInfo info) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n     \n-    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n+    if (!checkAccessPrivilege(info, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n     \n+    SecurityHandler securityHandler \u003d getSecurityHandler(info);\n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n     \n     FSSTAT3Request request \u003d null;\n     try {\n       request \u003d new FSSTAT3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n     }\n \n     try {\n       FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n       \n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       \n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n       \n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n     } catch (RemoteException r) {\n       LOG.warn(\"Exception \", r);\n       IOException io \u003d r.unwrapRemoteException();\n       /**\n        * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n        */\n       if (io instanceof AuthorizationException) {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n       } else {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public FSSTAT3Response fsstat(XDR xdr, RpcInfo info) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n    \n    if (!checkAccessPrivilege(info, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n    \n    SecurityHandler securityHandler \u003d getSecurityHandler(info);\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n    \n    FSSTAT3Request request \u003d null;\n    try {\n      request \u003d new FSSTAT3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n    }\n\n    try {\n      FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n      \n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      \n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n      \n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (RemoteException r) {\n      LOG.warn(\"Exception \", r);\n      IOException io \u003d r.unwrapRemoteException();\n      /**\n       * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n       */\n      if (io instanceof AuthorizationException) {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n      } else {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {}
        }
      ]
    },
    "c55947343e0a629f71d69b49ba87997573fe48a2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6462. NFS: fsstat request fails with the secure hdfs. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1598405 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/05/14 2:16 PM",
      "commitName": "c55947343e0a629f71d69b49ba87997573fe48a2",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "27/05/14 3:58 PM",
      "commitNameOld": "0ec6fc9e3c59c474f45e0fa68bb511778070a13c",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 1.93,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,66 @@\n   public FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n       InetAddress client) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n     \n     if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n     \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n     \n     FSSTAT3Request request \u003d null;\n     try {\n       request \u003d new FSSTAT3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n     }\n \n     try {\n-      // Use superUserClient to get file system status\n-      FsStatus fsStatus \u003d superUserClient.getDiskStatus();\n+      FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n       \n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       \n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n       \n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n     } catch (RemoteException r) {\n       LOG.warn(\"Exception \", r);\n       IOException io \u003d r.unwrapRemoteException();\n       /**\n        * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n        */\n       if (io instanceof AuthorizationException) {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n       } else {\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n      InetAddress client) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n    \n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n    \n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n    \n    FSSTAT3Request request \u003d null;\n    try {\n      request \u003d new FSSTAT3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n    }\n\n    try {\n      FsStatus fsStatus \u003d dfsClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n      \n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      \n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n      \n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (RemoteException r) {\n      LOG.warn(\"Exception \", r);\n      IOException io \u003d r.unwrapRemoteException();\n      /**\n       * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n       */\n      if (io instanceof AuthorizationException) {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n      } else {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "0ec6fc9e3c59c474f45e0fa68bb511778070a13c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6411. nfs-hdfs-gateway mount raises I/O error and hangs when a unauthorized user attempts to access it. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1597895 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/05/14 3:58 PM",
      "commitName": "0ec6fc9e3c59c474f45e0fa68bb511778070a13c",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "16/05/14 2:23 PM",
      "commitNameOld": "da3992b4e39019cd02e95460518b5d13d0e4eecd",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 11.07,
      "commitsBetweenForRepo": 45,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,56 +1,67 @@\n   public FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n       InetAddress client) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n     \n     if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n     \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n     \n     FSSTAT3Request request \u003d null;\n     try {\n       request \u003d new FSSTAT3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n     }\n \n     try {\n       // Use superUserClient to get file system status\n       FsStatus fsStatus \u003d superUserClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n       \n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       \n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n       \n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n+    } catch (RemoteException r) {\n+      LOG.warn(\"Exception \", r);\n+      IOException io \u003d r.unwrapRemoteException();\n+      /**\n+       * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n+       */\n+      if (io instanceof AuthorizationException) {\n+        return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n+      } else {\n+        return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n+      }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n      InetAddress client) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n    \n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n    \n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n    \n    FSSTAT3Request request \u003d null;\n    try {\n      request \u003d new FSSTAT3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n    }\n\n    try {\n      // Use superUserClient to get file system status\n      FsStatus fsStatus \u003d superUserClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n      \n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      \n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n      \n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (RemoteException r) {\n      LOG.warn(\"Exception \", r);\n      IOException io \u003d r.unwrapRemoteException();\n      /**\n       * AuthorizationException can be thrown if the user can\u0027t be proxy\u0027ed.\n       */\n      if (io instanceof AuthorizationException) {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_ACCES);\n      } else {\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "05f35518f19d48890770128727289582cca3457b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5171. NFS should create input stream for a file and try to share it with multiple read requests. Contributed by Haohui Mai\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1535586 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/10/13 4:40 PM",
      "commitName": "05f35518f19d48890770128727289582cca3457b",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "15/10/13 2:23 PM",
      "commitNameOld": "a9befa6f0a8a27b49b1e6483e749661f493f06cf",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 9.1,
      "commitsBetweenForRepo": 50,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,56 +1,56 @@\n   public FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n       InetAddress client) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n     \n     if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n     \n-    DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n+    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n     \n     FSSTAT3Request request \u003d null;\n     try {\n       request \u003d new FSSTAT3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n     }\n \n     try {\n       // Use superUserClient to get file system status\n       FsStatus fsStatus \u003d superUserClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n       \n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       \n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n       \n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public FSSTAT3Response fsstat(XDR xdr, SecurityHandler securityHandler,\n      InetAddress client) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n    \n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n    \n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n    \n    FSSTAT3Request request \u003d null;\n    try {\n      request \u003d new FSSTAT3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n    }\n\n    try {\n      // Use superUserClient to get file system status\n      FsStatus fsStatus \u003d superUserClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n      \n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      \n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n      \n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "613979c8fdacf25fd563395ecc399c4de94d3ee7": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5085. Refactor o.a.h.nfs to support different types of authentications. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1521601 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/09/13 12:29 PM",
      "commitName": "613979c8fdacf25fd563395ecc399c4de94d3ee7",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5085. Refactor o.a.h.nfs to support different types of authentications. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1521601 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/09/13 12:29 PM",
          "commitName": "613979c8fdacf25fd563395ecc399c4de94d3ee7",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "31/08/13 2:12 PM",
          "commitNameOld": "cbca1668317f3f2d295eea53d7bd020bda4a810f",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 9.93,
          "commitsBetweenForRepo": 38,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,56 +1,56 @@\n-  public FSSTAT3Response fsstat(XDR xdr, RpcAuthSys authSys, InetAddress client) {\n+  public FSSTAT3Response fsstat(XDR xdr,\n+      SecurityHandler securityHandler, InetAddress client) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n     \n     if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n     \n-    String uname \u003d authSysCheck(authSys);\n-    DFSClient dfsClient \u003d clientCache.get(uname);\n+    DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n     \n     FSSTAT3Request request \u003d null;\n     try {\n       request \u003d new FSSTAT3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n     }\n \n     try {\n       // Use superUserClient to get file system status\n       FsStatus fsStatus \u003d superUserClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n       \n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       \n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n       \n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public FSSTAT3Response fsstat(XDR xdr,\n      SecurityHandler securityHandler, InetAddress client) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n    \n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n    \n    DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n    \n    FSSTAT3Request request \u003d null;\n    try {\n      request \u003d new FSSTAT3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n    }\n\n    try {\n      // Use superUserClient to get file system status\n      FsStatus fsStatus \u003d superUserClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n      \n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      \n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n      \n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {
            "oldValue": "[xdr-XDR, authSys-RpcAuthSys, client-InetAddress]",
            "newValue": "[xdr-XDR, securityHandler-SecurityHandler, client-InetAddress]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5085. Refactor o.a.h.nfs to support different types of authentications. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1521601 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/09/13 12:29 PM",
          "commitName": "613979c8fdacf25fd563395ecc399c4de94d3ee7",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "31/08/13 2:12 PM",
          "commitNameOld": "cbca1668317f3f2d295eea53d7bd020bda4a810f",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 9.93,
          "commitsBetweenForRepo": 38,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,56 +1,56 @@\n-  public FSSTAT3Response fsstat(XDR xdr, RpcAuthSys authSys, InetAddress client) {\n+  public FSSTAT3Response fsstat(XDR xdr,\n+      SecurityHandler securityHandler, InetAddress client) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n     \n     if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n       response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n       return response;\n     }\n     \n-    String uname \u003d authSysCheck(authSys);\n-    DFSClient dfsClient \u003d clientCache.get(uname);\n+    DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n     \n     FSSTAT3Request request \u003d null;\n     try {\n       request \u003d new FSSTAT3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n     }\n \n     try {\n       // Use superUserClient to get file system status\n       FsStatus fsStatus \u003d superUserClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n       \n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       \n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n       \n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public FSSTAT3Response fsstat(XDR xdr,\n      SecurityHandler securityHandler, InetAddress client) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n    \n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n    \n    DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n    \n    FSSTAT3Request request \u003d null;\n    try {\n      request \u003d new FSSTAT3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n    }\n\n    try {\n      // Use superUserClient to get file system status\n      FsStatus fsStatus \u003d superUserClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n      \n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      \n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n      \n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {}
        }
      ]
    },
    "15632cd76f12c2f7df50d0df4865fbe3d8261597": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-4947 Add NFS server export table to control export by hostname or IP range. Contributed by Jing Zhao\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1517040 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/08/13 2:14 PM",
      "commitName": "15632cd76f12c2f7df50d0df4865fbe3d8261597",
      "commitAuthor": "Brandon Li",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4947 Add NFS server export table to control export by hostname or IP range. Contributed by Jing Zhao\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1517040 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/08/13 2:14 PM",
          "commitName": "15632cd76f12c2f7df50d0df4865fbe3d8261597",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "19/08/13 2:54 PM",
          "commitNameOld": "c9b89de0eacf15f21faa3a7ba30d4773f571c9a4",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 3.97,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,50 +1,56 @@\n-  public FSSTAT3Response fsstat(XDR xdr, RpcAuthSys authSys) {\n+  public FSSTAT3Response fsstat(XDR xdr, RpcAuthSys authSys, InetAddress client) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n+    \n+    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n+      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n+      return response;\n+    }\n+    \n     String uname \u003d authSysCheck(authSys);\n     DFSClient dfsClient \u003d clientCache.get(uname);\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n     \n     FSSTAT3Request request \u003d null;\n     try {\n       request \u003d new FSSTAT3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n     }\n \n     try {\n       // Use superUserClient to get file system status\n       FsStatus fsStatus \u003d superUserClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n       \n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       \n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n       \n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public FSSTAT3Response fsstat(XDR xdr, RpcAuthSys authSys, InetAddress client) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n    \n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n    \n    String uname \u003d authSysCheck(authSys);\n    DFSClient dfsClient \u003d clientCache.get(uname);\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n    \n    FSSTAT3Request request \u003d null;\n    try {\n      request \u003d new FSSTAT3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n    }\n\n    try {\n      // Use superUserClient to get file system status\n      FsStatus fsStatus \u003d superUserClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n      \n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      \n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n      \n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {
            "oldValue": "[xdr-XDR, authSys-RpcAuthSys]",
            "newValue": "[xdr-XDR, authSys-RpcAuthSys, client-InetAddress]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4947 Add NFS server export table to control export by hostname or IP range. Contributed by Jing Zhao\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1517040 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/08/13 2:14 PM",
          "commitName": "15632cd76f12c2f7df50d0df4865fbe3d8261597",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "19/08/13 2:54 PM",
          "commitNameOld": "c9b89de0eacf15f21faa3a7ba30d4773f571c9a4",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 3.97,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,50 +1,56 @@\n-  public FSSTAT3Response fsstat(XDR xdr, RpcAuthSys authSys) {\n+  public FSSTAT3Response fsstat(XDR xdr, RpcAuthSys authSys, InetAddress client) {\n     FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n+    \n+    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n+      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n+      return response;\n+    }\n+    \n     String uname \u003d authSysCheck(authSys);\n     DFSClient dfsClient \u003d clientCache.get(uname);\n     if (dfsClient \u003d\u003d null) {\n       response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n       return response;\n     }\n     \n     FSSTAT3Request request \u003d null;\n     try {\n       request \u003d new FSSTAT3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid FSSTAT request\");\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n     }\n \n     try {\n       // Use superUserClient to get file system status\n       FsStatus fsStatus \u003d superUserClient.getDiskStatus();\n       long totalBytes \u003d fsStatus.getCapacity();\n       long freeBytes \u003d fsStatus.getRemaining();\n       \n       Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n           iug);\n       if (attrs \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       \n       long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n       if (maxFsObjects \u003d\u003d 0) {\n         // A value of zero in HDFS indicates no limit to the number\n         // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n         // Long.MAX_VALUE so 32bit client won\u0027t complain.\n         maxFsObjects \u003d Integer.MAX_VALUE;\n       }\n       \n       return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n           freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public FSSTAT3Response fsstat(XDR xdr, RpcAuthSys authSys, InetAddress client) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n    \n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      response.setStatus(Nfs3Status.NFS3ERR_ACCES);\n      return response;\n    }\n    \n    String uname \u003d authSysCheck(authSys);\n    DFSClient dfsClient \u003d clientCache.get(uname);\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n    \n    FSSTAT3Request request \u003d null;\n    try {\n      request \u003d new FSSTAT3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n    }\n\n    try {\n      // Use superUserClient to get file system status\n      FsStatus fsStatus \u003d superUserClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n      \n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      \n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n      \n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {}
        }
      ]
    },
    "37f587563a943a827fbff865f5302bac6d202415": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4762 Provide HDFS based NFSv3 and Mountd implementation. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1499029 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/07/13 10:31 AM",
      "commitName": "37f587563a943a827fbff865f5302bac6d202415",
      "commitAuthor": "Brandon Li",
      "diff": "@@ -0,0 +1,50 @@\n+  public FSSTAT3Response fsstat(XDR xdr, RpcAuthSys authSys) {\n+    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n+    String uname \u003d authSysCheck(authSys);\n+    DFSClient dfsClient \u003d clientCache.get(uname);\n+    if (dfsClient \u003d\u003d null) {\n+      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n+      return response;\n+    }\n+    \n+    FSSTAT3Request request \u003d null;\n+    try {\n+      request \u003d new FSSTAT3Request(xdr);\n+    } catch (IOException e) {\n+      LOG.error(\"Invalid FSSTAT request\");\n+      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n+    }\n+\n+    FileHandle handle \u003d request.getHandle();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n+    }\n+\n+    try {\n+      // Use superUserClient to get file system status\n+      FsStatus fsStatus \u003d superUserClient.getDiskStatus();\n+      long totalBytes \u003d fsStatus.getCapacity();\n+      long freeBytes \u003d fsStatus.getRemaining();\n+      \n+      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n+          iug);\n+      if (attrs \u003d\u003d null) {\n+        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n+        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n+      }\n+      \n+      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n+      if (maxFsObjects \u003d\u003d 0) {\n+        // A value of zero in HDFS indicates no limit to the number\n+        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n+        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n+        maxFsObjects \u003d Integer.MAX_VALUE;\n+      }\n+      \n+      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n+          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n+    } catch (IOException e) {\n+      LOG.warn(\"Exception \", e);\n+      return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public FSSTAT3Response fsstat(XDR xdr, RpcAuthSys authSys) {\n    FSSTAT3Response response \u003d new FSSTAT3Response(Nfs3Status.NFS3_OK);\n    String uname \u003d authSysCheck(authSys);\n    DFSClient dfsClient \u003d clientCache.get(uname);\n    if (dfsClient \u003d\u003d null) {\n      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);\n      return response;\n    }\n    \n    FSSTAT3Request request \u003d null;\n    try {\n      request \u003d new FSSTAT3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid FSSTAT request\");\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS FSSTAT fileId: \" + handle.getFileId());\n    }\n\n    try {\n      // Use superUserClient to get file system status\n      FsStatus fsStatus \u003d superUserClient.getDiskStatus();\n      long totalBytes \u003d fsStatus.getCapacity();\n      long freeBytes \u003d fsStatus.getRemaining();\n      \n      Nfs3FileAttributes attrs \u003d writeManager.getFileAttr(dfsClient, handle,\n          iug);\n      if (attrs \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new FSSTAT3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      \n      long maxFsObjects \u003d config.getLong(\"dfs.max.objects\", 0);\n      if (maxFsObjects \u003d\u003d 0) {\n        // A value of zero in HDFS indicates no limit to the number\n        // of objects that dfs supports. Using Integer.MAX_VALUE instead of\n        // Long.MAX_VALUE so 32bit client won\u0027t complain.\n        maxFsObjects \u003d Integer.MAX_VALUE;\n      }\n      \n      return new FSSTAT3Response(Nfs3Status.NFS3_OK, attrs, totalBytes,\n          freeBytes, freeBytes, maxFsObjects, maxFsObjects, maxFsObjects, 0);\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new FSSTAT3Response(Nfs3Status.NFS3ERR_IO);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java"
    }
  }
}