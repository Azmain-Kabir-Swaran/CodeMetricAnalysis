{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSAppAttempt.java",
  "functionName": "getAllowedLocalityLevel",
  "functionId": "getAllowedLocalityLevel___schedulerKey-SchedulerRequestKey__numNodes-int__nodeLocalityThreshold-double__rackLocalityThreshold-double",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
  "functionStartLine": 274,
  "functionEndLine": 340,
  "numCommitsSeen": 106,
  "timeTaken": 4577,
  "changeHistory": [
    "39b4a37e02e929a698fcf9e32f1f71bb6b977635",
    "2528bea67ff80fae597f10e26c5f70d601af9fb1",
    "b8a30f2f170ffbd590e7366c3c944ab4919e40df",
    "5aace38b748ba71aaadd2c4d64eba8dc1f816828",
    "486e718fc1f5befd231494e2ec06bb360484f191"
  ],
  "changeHistoryShort": {
    "39b4a37e02e929a698fcf9e32f1f71bb6b977635": "Ybodychange",
    "2528bea67ff80fae597f10e26c5f70d601af9fb1": "Ybodychange",
    "b8a30f2f170ffbd590e7366c3c944ab4919e40df": "Ymultichange(Ymodifierchange,Ybodychange)",
    "5aace38b748ba71aaadd2c4d64eba8dc1f816828": "Ymultichange(Yparameterchange,Ybodychange)",
    "486e718fc1f5befd231494e2ec06bb360484f191": "Yintroduced"
  },
  "changeHistoryDetails": {
    "39b4a37e02e929a698fcf9e32f1f71bb6b977635": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9341.  Fixed enentrant lock usage in YARN project.\n            Contributed by Prabhu Joseph\n",
      "commitDate": "07/03/19 1:47 PM",
      "commitName": "39b4a37e02e929a698fcf9e32f1f71bb6b977635",
      "commitAuthor": "Eric Yang",
      "commitDateOld": "04/03/19 9:10 PM",
      "commitNameOld": "e40e2d6ad5cbe782c3a067229270738b501ed27e",
      "commitAuthorOld": "Prabhu Joseph",
      "daysBetweenCommits": 2.69,
      "commitsBetweenForRepo": 39,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,67 @@\n   NodeType getAllowedLocalityLevel(\n       SchedulerRequestKey schedulerKey, int numNodes,\n       double nodeLocalityThreshold, double rackLocalityThreshold) {\n     // upper limit on threshold\n     if (nodeLocalityThreshold \u003e 1.0) {\n       nodeLocalityThreshold \u003d 1.0;\n     }\n     if (rackLocalityThreshold \u003e 1.0) {\n       rackLocalityThreshold \u003d 1.0;\n     }\n \n     // If delay scheduling is not being used, can schedule anywhere\n     if (nodeLocalityThreshold \u003c 0.0 || rackLocalityThreshold \u003c 0.0) {\n       return NodeType.OFF_SWITCH;\n     }\n \n+    writeLock.lock();\n     try {\n-      writeLock.lock();\n \n       // Default level is NODE_LOCAL\n       if (!allowedLocalityLevel.containsKey(schedulerKey)) {\n         allowedLocalityLevel.put(schedulerKey, NodeType.NODE_LOCAL);\n         return NodeType.NODE_LOCAL;\n       }\n \n       NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n \n       // If level is already most liberal, we\u0027re done\n       if (allowed.equals(NodeType.OFF_SWITCH)) {\n         return NodeType.OFF_SWITCH;\n       }\n \n       double threshold \u003d allowed.equals(NodeType.NODE_LOCAL) ?\n           nodeLocalityThreshold :\n           rackLocalityThreshold;\n \n       // Relax locality constraints once we\u0027ve surpassed threshold.\n       int schedulingOpportunities \u003d getSchedulingOpportunities(schedulerKey);\n       double thresholdNum \u003d numNodes * threshold;\n       if (schedulingOpportunities \u003e thresholdNum) {\n         if (allowed.equals(NodeType.NODE_LOCAL)) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"SchedulingOpportunities: \" + schedulingOpportunities\n                 + \", nodeLocalityThreshold: \" + thresholdNum\n                 + \", change allowedLocality from NODE_LOCAL to RACK_LOCAL\"\n                 + \", priority: \" + schedulerKey.getPriority()\n                 + \", app attempt id: \" + this.attemptId);\n           }\n           allowedLocalityLevel.put(schedulerKey, NodeType.RACK_LOCAL);\n           resetSchedulingOpportunities(schedulerKey);\n         } else if (allowed.equals(NodeType.RACK_LOCAL)) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"SchedulingOpportunities: \" + schedulingOpportunities\n                 + \", rackLocalityThreshold: \" + thresholdNum\n                 + \", change allowedLocality from RACK_LOCAL to OFF_SWITCH\"\n                 + \", priority: \" + schedulerKey.getPriority()\n                 + \", app attempt id: \" + this.attemptId);\n           }\n           allowedLocalityLevel.put(schedulerKey, NodeType.OFF_SWITCH);\n           resetSchedulingOpportunities(schedulerKey);\n         }\n       }\n       return allowedLocalityLevel.get(schedulerKey);\n     } finally {\n       writeLock.unlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  NodeType getAllowedLocalityLevel(\n      SchedulerRequestKey schedulerKey, int numNodes,\n      double nodeLocalityThreshold, double rackLocalityThreshold) {\n    // upper limit on threshold\n    if (nodeLocalityThreshold \u003e 1.0) {\n      nodeLocalityThreshold \u003d 1.0;\n    }\n    if (rackLocalityThreshold \u003e 1.0) {\n      rackLocalityThreshold \u003d 1.0;\n    }\n\n    // If delay scheduling is not being used, can schedule anywhere\n    if (nodeLocalityThreshold \u003c 0.0 || rackLocalityThreshold \u003c 0.0) {\n      return NodeType.OFF_SWITCH;\n    }\n\n    writeLock.lock();\n    try {\n\n      // Default level is NODE_LOCAL\n      if (!allowedLocalityLevel.containsKey(schedulerKey)) {\n        allowedLocalityLevel.put(schedulerKey, NodeType.NODE_LOCAL);\n        return NodeType.NODE_LOCAL;\n      }\n\n      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n\n      // If level is already most liberal, we\u0027re done\n      if (allowed.equals(NodeType.OFF_SWITCH)) {\n        return NodeType.OFF_SWITCH;\n      }\n\n      double threshold \u003d allowed.equals(NodeType.NODE_LOCAL) ?\n          nodeLocalityThreshold :\n          rackLocalityThreshold;\n\n      // Relax locality constraints once we\u0027ve surpassed threshold.\n      int schedulingOpportunities \u003d getSchedulingOpportunities(schedulerKey);\n      double thresholdNum \u003d numNodes * threshold;\n      if (schedulingOpportunities \u003e thresholdNum) {\n        if (allowed.equals(NodeType.NODE_LOCAL)) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"SchedulingOpportunities: \" + schedulingOpportunities\n                + \", nodeLocalityThreshold: \" + thresholdNum\n                + \", change allowedLocality from NODE_LOCAL to RACK_LOCAL\"\n                + \", priority: \" + schedulerKey.getPriority()\n                + \", app attempt id: \" + this.attemptId);\n          }\n          allowedLocalityLevel.put(schedulerKey, NodeType.RACK_LOCAL);\n          resetSchedulingOpportunities(schedulerKey);\n        } else if (allowed.equals(NodeType.RACK_LOCAL)) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"SchedulingOpportunities: \" + schedulingOpportunities\n                + \", rackLocalityThreshold: \" + thresholdNum\n                + \", change allowedLocality from RACK_LOCAL to OFF_SWITCH\"\n                + \", priority: \" + schedulerKey.getPriority()\n                + \", app attempt id: \" + this.attemptId);\n          }\n          allowedLocalityLevel.put(schedulerKey, NodeType.OFF_SWITCH);\n          resetSchedulingOpportunities(schedulerKey);\n        }\n      }\n      return allowedLocalityLevel.get(schedulerKey);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
      "extendedDetails": {}
    },
    "2528bea67ff80fae597f10e26c5f70d601af9fb1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4396. Log the trace information on FSAppAttempt#assignContainer (Contributed by Yiqun Li via Daniel Templeton)\n",
      "commitDate": "31/10/16 1:34 PM",
      "commitName": "2528bea67ff80fae597f10e26c5f70d601af9fb1",
      "commitAuthor": "Daniel Templeton",
      "commitDateOld": "27/10/16 2:42 PM",
      "commitNameOld": "b98fc8249f0576e7b4e230ffc3cec5a20eefc543",
      "commitAuthorOld": "Daniel Templeton",
      "daysBetweenCommits": 3.95,
      "commitsBetweenForRepo": 30,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,67 @@\n   NodeType getAllowedLocalityLevel(\n       SchedulerRequestKey schedulerKey, int numNodes,\n       double nodeLocalityThreshold, double rackLocalityThreshold) {\n     // upper limit on threshold\n     if (nodeLocalityThreshold \u003e 1.0) {\n       nodeLocalityThreshold \u003d 1.0;\n     }\n     if (rackLocalityThreshold \u003e 1.0) {\n       rackLocalityThreshold \u003d 1.0;\n     }\n \n     // If delay scheduling is not being used, can schedule anywhere\n     if (nodeLocalityThreshold \u003c 0.0 || rackLocalityThreshold \u003c 0.0) {\n       return NodeType.OFF_SWITCH;\n     }\n \n     try {\n       writeLock.lock();\n \n       // Default level is NODE_LOCAL\n       if (!allowedLocalityLevel.containsKey(schedulerKey)) {\n         allowedLocalityLevel.put(schedulerKey, NodeType.NODE_LOCAL);\n         return NodeType.NODE_LOCAL;\n       }\n \n       NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n \n       // If level is already most liberal, we\u0027re done\n       if (allowed.equals(NodeType.OFF_SWITCH)) {\n         return NodeType.OFF_SWITCH;\n       }\n \n       double threshold \u003d allowed.equals(NodeType.NODE_LOCAL) ?\n           nodeLocalityThreshold :\n           rackLocalityThreshold;\n \n       // Relax locality constraints once we\u0027ve surpassed threshold.\n-      if (getSchedulingOpportunities(schedulerKey) \u003e (numNodes * threshold)) {\n+      int schedulingOpportunities \u003d getSchedulingOpportunities(schedulerKey);\n+      double thresholdNum \u003d numNodes * threshold;\n+      if (schedulingOpportunities \u003e thresholdNum) {\n         if (allowed.equals(NodeType.NODE_LOCAL)) {\n+          if (LOG.isTraceEnabled()) {\n+            LOG.trace(\"SchedulingOpportunities: \" + schedulingOpportunities\n+                + \", nodeLocalityThreshold: \" + thresholdNum\n+                + \", change allowedLocality from NODE_LOCAL to RACK_LOCAL\"\n+                + \", priority: \" + schedulerKey.getPriority()\n+                + \", app attempt id: \" + this.attemptId);\n+          }\n           allowedLocalityLevel.put(schedulerKey, NodeType.RACK_LOCAL);\n           resetSchedulingOpportunities(schedulerKey);\n         } else if (allowed.equals(NodeType.RACK_LOCAL)) {\n+          if (LOG.isTraceEnabled()) {\n+            LOG.trace(\"SchedulingOpportunities: \" + schedulingOpportunities\n+                + \", rackLocalityThreshold: \" + thresholdNum\n+                + \", change allowedLocality from RACK_LOCAL to OFF_SWITCH\"\n+                + \", priority: \" + schedulerKey.getPriority()\n+                + \", app attempt id: \" + this.attemptId);\n+          }\n           allowedLocalityLevel.put(schedulerKey, NodeType.OFF_SWITCH);\n           resetSchedulingOpportunities(schedulerKey);\n         }\n       }\n       return allowedLocalityLevel.get(schedulerKey);\n     } finally {\n       writeLock.unlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  NodeType getAllowedLocalityLevel(\n      SchedulerRequestKey schedulerKey, int numNodes,\n      double nodeLocalityThreshold, double rackLocalityThreshold) {\n    // upper limit on threshold\n    if (nodeLocalityThreshold \u003e 1.0) {\n      nodeLocalityThreshold \u003d 1.0;\n    }\n    if (rackLocalityThreshold \u003e 1.0) {\n      rackLocalityThreshold \u003d 1.0;\n    }\n\n    // If delay scheduling is not being used, can schedule anywhere\n    if (nodeLocalityThreshold \u003c 0.0 || rackLocalityThreshold \u003c 0.0) {\n      return NodeType.OFF_SWITCH;\n    }\n\n    try {\n      writeLock.lock();\n\n      // Default level is NODE_LOCAL\n      if (!allowedLocalityLevel.containsKey(schedulerKey)) {\n        allowedLocalityLevel.put(schedulerKey, NodeType.NODE_LOCAL);\n        return NodeType.NODE_LOCAL;\n      }\n\n      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n\n      // If level is already most liberal, we\u0027re done\n      if (allowed.equals(NodeType.OFF_SWITCH)) {\n        return NodeType.OFF_SWITCH;\n      }\n\n      double threshold \u003d allowed.equals(NodeType.NODE_LOCAL) ?\n          nodeLocalityThreshold :\n          rackLocalityThreshold;\n\n      // Relax locality constraints once we\u0027ve surpassed threshold.\n      int schedulingOpportunities \u003d getSchedulingOpportunities(schedulerKey);\n      double thresholdNum \u003d numNodes * threshold;\n      if (schedulingOpportunities \u003e thresholdNum) {\n        if (allowed.equals(NodeType.NODE_LOCAL)) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"SchedulingOpportunities: \" + schedulingOpportunities\n                + \", nodeLocalityThreshold: \" + thresholdNum\n                + \", change allowedLocality from NODE_LOCAL to RACK_LOCAL\"\n                + \", priority: \" + schedulerKey.getPriority()\n                + \", app attempt id: \" + this.attemptId);\n          }\n          allowedLocalityLevel.put(schedulerKey, NodeType.RACK_LOCAL);\n          resetSchedulingOpportunities(schedulerKey);\n        } else if (allowed.equals(NodeType.RACK_LOCAL)) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"SchedulingOpportunities: \" + schedulingOpportunities\n                + \", rackLocalityThreshold: \" + thresholdNum\n                + \", change allowedLocality from RACK_LOCAL to OFF_SWITCH\"\n                + \", priority: \" + schedulerKey.getPriority()\n                + \", app attempt id: \" + this.attemptId);\n          }\n          allowedLocalityLevel.put(schedulerKey, NodeType.OFF_SWITCH);\n          resetSchedulingOpportunities(schedulerKey);\n        }\n      }\n      return allowedLocalityLevel.get(schedulerKey);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
      "extendedDetails": {}
    },
    "b8a30f2f170ffbd590e7366c3c944ab4919e40df": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "YARN-3141. Improve locks in SchedulerApplicationAttempt/FSAppAttempt/FiCaSchedulerApp. Contributed by Wangda Tan\n",
      "commitDate": "19/09/16 2:08 AM",
      "commitName": "b8a30f2f170ffbd590e7366c3c944ab4919e40df",
      "commitAuthor": "Jian He",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-3141. Improve locks in SchedulerApplicationAttempt/FSAppAttempt/FiCaSchedulerApp. Contributed by Wangda Tan\n",
          "commitDate": "19/09/16 2:08 AM",
          "commitName": "b8a30f2f170ffbd590e7366c3c944ab4919e40df",
          "commitAuthor": "Jian He",
          "commitDateOld": "05/08/16 10:43 AM",
          "commitNameOld": "3f100d76ff5df020dbb8ecd4f5b4f9736a0a8270",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 44.64,
          "commitsBetweenForRepo": 264,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,39 +1,51 @@\n-  public synchronized NodeType getAllowedLocalityLevel(\n+  NodeType getAllowedLocalityLevel(\n       SchedulerRequestKey schedulerKey, int numNodes,\n       double nodeLocalityThreshold, double rackLocalityThreshold) {\n     // upper limit on threshold\n-    if (nodeLocalityThreshold \u003e 1.0) { nodeLocalityThreshold \u003d 1.0; }\n-    if (rackLocalityThreshold \u003e 1.0) { rackLocalityThreshold \u003d 1.0; }\n+    if (nodeLocalityThreshold \u003e 1.0) {\n+      nodeLocalityThreshold \u003d 1.0;\n+    }\n+    if (rackLocalityThreshold \u003e 1.0) {\n+      rackLocalityThreshold \u003d 1.0;\n+    }\n \n     // If delay scheduling is not being used, can schedule anywhere\n     if (nodeLocalityThreshold \u003c 0.0 || rackLocalityThreshold \u003c 0.0) {\n       return NodeType.OFF_SWITCH;\n     }\n \n-    // Default level is NODE_LOCAL\n-    if (!allowedLocalityLevel.containsKey(schedulerKey)) {\n-      allowedLocalityLevel.put(schedulerKey, NodeType.NODE_LOCAL);\n-      return NodeType.NODE_LOCAL;\n-    }\n+    try {\n+      writeLock.lock();\n \n-    NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n-\n-    // If level is already most liberal, we\u0027re done\n-    if (allowed.equals(NodeType.OFF_SWITCH)) return NodeType.OFF_SWITCH;\n-\n-    double threshold \u003d allowed.equals(NodeType.NODE_LOCAL) ? nodeLocalityThreshold :\n-      rackLocalityThreshold;\n-\n-    // Relax locality constraints once we\u0027ve surpassed threshold.\n-    if (getSchedulingOpportunities(schedulerKey) \u003e (numNodes * threshold)) {\n-      if (allowed.equals(NodeType.NODE_LOCAL)) {\n-        allowedLocalityLevel.put(schedulerKey, NodeType.RACK_LOCAL);\n-        resetSchedulingOpportunities(schedulerKey);\n+      // Default level is NODE_LOCAL\n+      if (!allowedLocalityLevel.containsKey(schedulerKey)) {\n+        allowedLocalityLevel.put(schedulerKey, NodeType.NODE_LOCAL);\n+        return NodeType.NODE_LOCAL;\n       }\n-      else if (allowed.equals(NodeType.RACK_LOCAL)) {\n-        allowedLocalityLevel.put(schedulerKey, NodeType.OFF_SWITCH);\n-        resetSchedulingOpportunities(schedulerKey);\n+\n+      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n+\n+      // If level is already most liberal, we\u0027re done\n+      if (allowed.equals(NodeType.OFF_SWITCH)) {\n+        return NodeType.OFF_SWITCH;\n       }\n+\n+      double threshold \u003d allowed.equals(NodeType.NODE_LOCAL) ?\n+          nodeLocalityThreshold :\n+          rackLocalityThreshold;\n+\n+      // Relax locality constraints once we\u0027ve surpassed threshold.\n+      if (getSchedulingOpportunities(schedulerKey) \u003e (numNodes * threshold)) {\n+        if (allowed.equals(NodeType.NODE_LOCAL)) {\n+          allowedLocalityLevel.put(schedulerKey, NodeType.RACK_LOCAL);\n+          resetSchedulingOpportunities(schedulerKey);\n+        } else if (allowed.equals(NodeType.RACK_LOCAL)) {\n+          allowedLocalityLevel.put(schedulerKey, NodeType.OFF_SWITCH);\n+          resetSchedulingOpportunities(schedulerKey);\n+        }\n+      }\n+      return allowedLocalityLevel.get(schedulerKey);\n+    } finally {\n+      writeLock.unlock();\n     }\n-    return allowedLocalityLevel.get(schedulerKey);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  NodeType getAllowedLocalityLevel(\n      SchedulerRequestKey schedulerKey, int numNodes,\n      double nodeLocalityThreshold, double rackLocalityThreshold) {\n    // upper limit on threshold\n    if (nodeLocalityThreshold \u003e 1.0) {\n      nodeLocalityThreshold \u003d 1.0;\n    }\n    if (rackLocalityThreshold \u003e 1.0) {\n      rackLocalityThreshold \u003d 1.0;\n    }\n\n    // If delay scheduling is not being used, can schedule anywhere\n    if (nodeLocalityThreshold \u003c 0.0 || rackLocalityThreshold \u003c 0.0) {\n      return NodeType.OFF_SWITCH;\n    }\n\n    try {\n      writeLock.lock();\n\n      // Default level is NODE_LOCAL\n      if (!allowedLocalityLevel.containsKey(schedulerKey)) {\n        allowedLocalityLevel.put(schedulerKey, NodeType.NODE_LOCAL);\n        return NodeType.NODE_LOCAL;\n      }\n\n      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n\n      // If level is already most liberal, we\u0027re done\n      if (allowed.equals(NodeType.OFF_SWITCH)) {\n        return NodeType.OFF_SWITCH;\n      }\n\n      double threshold \u003d allowed.equals(NodeType.NODE_LOCAL) ?\n          nodeLocalityThreshold :\n          rackLocalityThreshold;\n\n      // Relax locality constraints once we\u0027ve surpassed threshold.\n      if (getSchedulingOpportunities(schedulerKey) \u003e (numNodes * threshold)) {\n        if (allowed.equals(NodeType.NODE_LOCAL)) {\n          allowedLocalityLevel.put(schedulerKey, NodeType.RACK_LOCAL);\n          resetSchedulingOpportunities(schedulerKey);\n        } else if (allowed.equals(NodeType.RACK_LOCAL)) {\n          allowedLocalityLevel.put(schedulerKey, NodeType.OFF_SWITCH);\n          resetSchedulingOpportunities(schedulerKey);\n        }\n      }\n      return allowedLocalityLevel.get(schedulerKey);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
          "extendedDetails": {
            "oldValue": "[public, synchronized]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-3141. Improve locks in SchedulerApplicationAttempt/FSAppAttempt/FiCaSchedulerApp. Contributed by Wangda Tan\n",
          "commitDate": "19/09/16 2:08 AM",
          "commitName": "b8a30f2f170ffbd590e7366c3c944ab4919e40df",
          "commitAuthor": "Jian He",
          "commitDateOld": "05/08/16 10:43 AM",
          "commitNameOld": "3f100d76ff5df020dbb8ecd4f5b4f9736a0a8270",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 44.64,
          "commitsBetweenForRepo": 264,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,39 +1,51 @@\n-  public synchronized NodeType getAllowedLocalityLevel(\n+  NodeType getAllowedLocalityLevel(\n       SchedulerRequestKey schedulerKey, int numNodes,\n       double nodeLocalityThreshold, double rackLocalityThreshold) {\n     // upper limit on threshold\n-    if (nodeLocalityThreshold \u003e 1.0) { nodeLocalityThreshold \u003d 1.0; }\n-    if (rackLocalityThreshold \u003e 1.0) { rackLocalityThreshold \u003d 1.0; }\n+    if (nodeLocalityThreshold \u003e 1.0) {\n+      nodeLocalityThreshold \u003d 1.0;\n+    }\n+    if (rackLocalityThreshold \u003e 1.0) {\n+      rackLocalityThreshold \u003d 1.0;\n+    }\n \n     // If delay scheduling is not being used, can schedule anywhere\n     if (nodeLocalityThreshold \u003c 0.0 || rackLocalityThreshold \u003c 0.0) {\n       return NodeType.OFF_SWITCH;\n     }\n \n-    // Default level is NODE_LOCAL\n-    if (!allowedLocalityLevel.containsKey(schedulerKey)) {\n-      allowedLocalityLevel.put(schedulerKey, NodeType.NODE_LOCAL);\n-      return NodeType.NODE_LOCAL;\n-    }\n+    try {\n+      writeLock.lock();\n \n-    NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n-\n-    // If level is already most liberal, we\u0027re done\n-    if (allowed.equals(NodeType.OFF_SWITCH)) return NodeType.OFF_SWITCH;\n-\n-    double threshold \u003d allowed.equals(NodeType.NODE_LOCAL) ? nodeLocalityThreshold :\n-      rackLocalityThreshold;\n-\n-    // Relax locality constraints once we\u0027ve surpassed threshold.\n-    if (getSchedulingOpportunities(schedulerKey) \u003e (numNodes * threshold)) {\n-      if (allowed.equals(NodeType.NODE_LOCAL)) {\n-        allowedLocalityLevel.put(schedulerKey, NodeType.RACK_LOCAL);\n-        resetSchedulingOpportunities(schedulerKey);\n+      // Default level is NODE_LOCAL\n+      if (!allowedLocalityLevel.containsKey(schedulerKey)) {\n+        allowedLocalityLevel.put(schedulerKey, NodeType.NODE_LOCAL);\n+        return NodeType.NODE_LOCAL;\n       }\n-      else if (allowed.equals(NodeType.RACK_LOCAL)) {\n-        allowedLocalityLevel.put(schedulerKey, NodeType.OFF_SWITCH);\n-        resetSchedulingOpportunities(schedulerKey);\n+\n+      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n+\n+      // If level is already most liberal, we\u0027re done\n+      if (allowed.equals(NodeType.OFF_SWITCH)) {\n+        return NodeType.OFF_SWITCH;\n       }\n+\n+      double threshold \u003d allowed.equals(NodeType.NODE_LOCAL) ?\n+          nodeLocalityThreshold :\n+          rackLocalityThreshold;\n+\n+      // Relax locality constraints once we\u0027ve surpassed threshold.\n+      if (getSchedulingOpportunities(schedulerKey) \u003e (numNodes * threshold)) {\n+        if (allowed.equals(NodeType.NODE_LOCAL)) {\n+          allowedLocalityLevel.put(schedulerKey, NodeType.RACK_LOCAL);\n+          resetSchedulingOpportunities(schedulerKey);\n+        } else if (allowed.equals(NodeType.RACK_LOCAL)) {\n+          allowedLocalityLevel.put(schedulerKey, NodeType.OFF_SWITCH);\n+          resetSchedulingOpportunities(schedulerKey);\n+        }\n+      }\n+      return allowedLocalityLevel.get(schedulerKey);\n+    } finally {\n+      writeLock.unlock();\n     }\n-    return allowedLocalityLevel.get(schedulerKey);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  NodeType getAllowedLocalityLevel(\n      SchedulerRequestKey schedulerKey, int numNodes,\n      double nodeLocalityThreshold, double rackLocalityThreshold) {\n    // upper limit on threshold\n    if (nodeLocalityThreshold \u003e 1.0) {\n      nodeLocalityThreshold \u003d 1.0;\n    }\n    if (rackLocalityThreshold \u003e 1.0) {\n      rackLocalityThreshold \u003d 1.0;\n    }\n\n    // If delay scheduling is not being used, can schedule anywhere\n    if (nodeLocalityThreshold \u003c 0.0 || rackLocalityThreshold \u003c 0.0) {\n      return NodeType.OFF_SWITCH;\n    }\n\n    try {\n      writeLock.lock();\n\n      // Default level is NODE_LOCAL\n      if (!allowedLocalityLevel.containsKey(schedulerKey)) {\n        allowedLocalityLevel.put(schedulerKey, NodeType.NODE_LOCAL);\n        return NodeType.NODE_LOCAL;\n      }\n\n      NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n\n      // If level is already most liberal, we\u0027re done\n      if (allowed.equals(NodeType.OFF_SWITCH)) {\n        return NodeType.OFF_SWITCH;\n      }\n\n      double threshold \u003d allowed.equals(NodeType.NODE_LOCAL) ?\n          nodeLocalityThreshold :\n          rackLocalityThreshold;\n\n      // Relax locality constraints once we\u0027ve surpassed threshold.\n      if (getSchedulingOpportunities(schedulerKey) \u003e (numNodes * threshold)) {\n        if (allowed.equals(NodeType.NODE_LOCAL)) {\n          allowedLocalityLevel.put(schedulerKey, NodeType.RACK_LOCAL);\n          resetSchedulingOpportunities(schedulerKey);\n        } else if (allowed.equals(NodeType.RACK_LOCAL)) {\n          allowedLocalityLevel.put(schedulerKey, NodeType.OFF_SWITCH);\n          resetSchedulingOpportunities(schedulerKey);\n        }\n      }\n      return allowedLocalityLevel.get(schedulerKey);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
          "extendedDetails": {}
        }
      ]
    },
    "5aace38b748ba71aaadd2c4d64eba8dc1f816828": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-5392. Replace use of Priority in the Scheduling infrastructure with an opaque ShedulerRequestKey. (asuresh and subru)\n",
      "commitDate": "26/07/16 2:54 PM",
      "commitName": "5aace38b748ba71aaadd2c4d64eba8dc1f816828",
      "commitAuthor": "Arun Suresh",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-5392. Replace use of Priority in the Scheduling infrastructure with an opaque ShedulerRequestKey. (asuresh and subru)\n",
          "commitDate": "26/07/16 2:54 PM",
          "commitName": "5aace38b748ba71aaadd2c4d64eba8dc1f816828",
          "commitAuthor": "Arun Suresh",
          "commitDateOld": "11/07/16 10:36 PM",
          "commitNameOld": "819224dcf9c683aa52f58633ac8e13663f1916d8",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 14.68,
          "commitsBetweenForRepo": 98,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,39 @@\n-  public synchronized NodeType getAllowedLocalityLevel(Priority priority,\n-      int numNodes, double nodeLocalityThreshold, double rackLocalityThreshold) {\n+  public synchronized NodeType getAllowedLocalityLevel(\n+      SchedulerRequestKey schedulerKey, int numNodes,\n+      double nodeLocalityThreshold, double rackLocalityThreshold) {\n     // upper limit on threshold\n     if (nodeLocalityThreshold \u003e 1.0) { nodeLocalityThreshold \u003d 1.0; }\n     if (rackLocalityThreshold \u003e 1.0) { rackLocalityThreshold \u003d 1.0; }\n \n     // If delay scheduling is not being used, can schedule anywhere\n     if (nodeLocalityThreshold \u003c 0.0 || rackLocalityThreshold \u003c 0.0) {\n       return NodeType.OFF_SWITCH;\n     }\n \n     // Default level is NODE_LOCAL\n-    if (!allowedLocalityLevel.containsKey(priority)) {\n-      allowedLocalityLevel.put(priority, NodeType.NODE_LOCAL);\n+    if (!allowedLocalityLevel.containsKey(schedulerKey)) {\n+      allowedLocalityLevel.put(schedulerKey, NodeType.NODE_LOCAL);\n       return NodeType.NODE_LOCAL;\n     }\n \n-    NodeType allowed \u003d allowedLocalityLevel.get(priority);\n+    NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n \n     // If level is already most liberal, we\u0027re done\n     if (allowed.equals(NodeType.OFF_SWITCH)) return NodeType.OFF_SWITCH;\n \n     double threshold \u003d allowed.equals(NodeType.NODE_LOCAL) ? nodeLocalityThreshold :\n       rackLocalityThreshold;\n \n     // Relax locality constraints once we\u0027ve surpassed threshold.\n-    if (getSchedulingOpportunities(priority) \u003e (numNodes * threshold)) {\n+    if (getSchedulingOpportunities(schedulerKey) \u003e (numNodes * threshold)) {\n       if (allowed.equals(NodeType.NODE_LOCAL)) {\n-        allowedLocalityLevel.put(priority, NodeType.RACK_LOCAL);\n-        resetSchedulingOpportunities(priority);\n+        allowedLocalityLevel.put(schedulerKey, NodeType.RACK_LOCAL);\n+        resetSchedulingOpportunities(schedulerKey);\n       }\n       else if (allowed.equals(NodeType.RACK_LOCAL)) {\n-        allowedLocalityLevel.put(priority, NodeType.OFF_SWITCH);\n-        resetSchedulingOpportunities(priority);\n+        allowedLocalityLevel.put(schedulerKey, NodeType.OFF_SWITCH);\n+        resetSchedulingOpportunities(schedulerKey);\n       }\n     }\n-    return allowedLocalityLevel.get(priority);\n+    return allowedLocalityLevel.get(schedulerKey);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized NodeType getAllowedLocalityLevel(\n      SchedulerRequestKey schedulerKey, int numNodes,\n      double nodeLocalityThreshold, double rackLocalityThreshold) {\n    // upper limit on threshold\n    if (nodeLocalityThreshold \u003e 1.0) { nodeLocalityThreshold \u003d 1.0; }\n    if (rackLocalityThreshold \u003e 1.0) { rackLocalityThreshold \u003d 1.0; }\n\n    // If delay scheduling is not being used, can schedule anywhere\n    if (nodeLocalityThreshold \u003c 0.0 || rackLocalityThreshold \u003c 0.0) {\n      return NodeType.OFF_SWITCH;\n    }\n\n    // Default level is NODE_LOCAL\n    if (!allowedLocalityLevel.containsKey(schedulerKey)) {\n      allowedLocalityLevel.put(schedulerKey, NodeType.NODE_LOCAL);\n      return NodeType.NODE_LOCAL;\n    }\n\n    NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n\n    // If level is already most liberal, we\u0027re done\n    if (allowed.equals(NodeType.OFF_SWITCH)) return NodeType.OFF_SWITCH;\n\n    double threshold \u003d allowed.equals(NodeType.NODE_LOCAL) ? nodeLocalityThreshold :\n      rackLocalityThreshold;\n\n    // Relax locality constraints once we\u0027ve surpassed threshold.\n    if (getSchedulingOpportunities(schedulerKey) \u003e (numNodes * threshold)) {\n      if (allowed.equals(NodeType.NODE_LOCAL)) {\n        allowedLocalityLevel.put(schedulerKey, NodeType.RACK_LOCAL);\n        resetSchedulingOpportunities(schedulerKey);\n      }\n      else if (allowed.equals(NodeType.RACK_LOCAL)) {\n        allowedLocalityLevel.put(schedulerKey, NodeType.OFF_SWITCH);\n        resetSchedulingOpportunities(schedulerKey);\n      }\n    }\n    return allowedLocalityLevel.get(schedulerKey);\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
          "extendedDetails": {
            "oldValue": "[priority-Priority, numNodes-int, nodeLocalityThreshold-double, rackLocalityThreshold-double]",
            "newValue": "[schedulerKey-SchedulerRequestKey, numNodes-int, nodeLocalityThreshold-double, rackLocalityThreshold-double]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-5392. Replace use of Priority in the Scheduling infrastructure with an opaque ShedulerRequestKey. (asuresh and subru)\n",
          "commitDate": "26/07/16 2:54 PM",
          "commitName": "5aace38b748ba71aaadd2c4d64eba8dc1f816828",
          "commitAuthor": "Arun Suresh",
          "commitDateOld": "11/07/16 10:36 PM",
          "commitNameOld": "819224dcf9c683aa52f58633ac8e13663f1916d8",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 14.68,
          "commitsBetweenForRepo": 98,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,39 @@\n-  public synchronized NodeType getAllowedLocalityLevel(Priority priority,\n-      int numNodes, double nodeLocalityThreshold, double rackLocalityThreshold) {\n+  public synchronized NodeType getAllowedLocalityLevel(\n+      SchedulerRequestKey schedulerKey, int numNodes,\n+      double nodeLocalityThreshold, double rackLocalityThreshold) {\n     // upper limit on threshold\n     if (nodeLocalityThreshold \u003e 1.0) { nodeLocalityThreshold \u003d 1.0; }\n     if (rackLocalityThreshold \u003e 1.0) { rackLocalityThreshold \u003d 1.0; }\n \n     // If delay scheduling is not being used, can schedule anywhere\n     if (nodeLocalityThreshold \u003c 0.0 || rackLocalityThreshold \u003c 0.0) {\n       return NodeType.OFF_SWITCH;\n     }\n \n     // Default level is NODE_LOCAL\n-    if (!allowedLocalityLevel.containsKey(priority)) {\n-      allowedLocalityLevel.put(priority, NodeType.NODE_LOCAL);\n+    if (!allowedLocalityLevel.containsKey(schedulerKey)) {\n+      allowedLocalityLevel.put(schedulerKey, NodeType.NODE_LOCAL);\n       return NodeType.NODE_LOCAL;\n     }\n \n-    NodeType allowed \u003d allowedLocalityLevel.get(priority);\n+    NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n \n     // If level is already most liberal, we\u0027re done\n     if (allowed.equals(NodeType.OFF_SWITCH)) return NodeType.OFF_SWITCH;\n \n     double threshold \u003d allowed.equals(NodeType.NODE_LOCAL) ? nodeLocalityThreshold :\n       rackLocalityThreshold;\n \n     // Relax locality constraints once we\u0027ve surpassed threshold.\n-    if (getSchedulingOpportunities(priority) \u003e (numNodes * threshold)) {\n+    if (getSchedulingOpportunities(schedulerKey) \u003e (numNodes * threshold)) {\n       if (allowed.equals(NodeType.NODE_LOCAL)) {\n-        allowedLocalityLevel.put(priority, NodeType.RACK_LOCAL);\n-        resetSchedulingOpportunities(priority);\n+        allowedLocalityLevel.put(schedulerKey, NodeType.RACK_LOCAL);\n+        resetSchedulingOpportunities(schedulerKey);\n       }\n       else if (allowed.equals(NodeType.RACK_LOCAL)) {\n-        allowedLocalityLevel.put(priority, NodeType.OFF_SWITCH);\n-        resetSchedulingOpportunities(priority);\n+        allowedLocalityLevel.put(schedulerKey, NodeType.OFF_SWITCH);\n+        resetSchedulingOpportunities(schedulerKey);\n       }\n     }\n-    return allowedLocalityLevel.get(priority);\n+    return allowedLocalityLevel.get(schedulerKey);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized NodeType getAllowedLocalityLevel(\n      SchedulerRequestKey schedulerKey, int numNodes,\n      double nodeLocalityThreshold, double rackLocalityThreshold) {\n    // upper limit on threshold\n    if (nodeLocalityThreshold \u003e 1.0) { nodeLocalityThreshold \u003d 1.0; }\n    if (rackLocalityThreshold \u003e 1.0) { rackLocalityThreshold \u003d 1.0; }\n\n    // If delay scheduling is not being used, can schedule anywhere\n    if (nodeLocalityThreshold \u003c 0.0 || rackLocalityThreshold \u003c 0.0) {\n      return NodeType.OFF_SWITCH;\n    }\n\n    // Default level is NODE_LOCAL\n    if (!allowedLocalityLevel.containsKey(schedulerKey)) {\n      allowedLocalityLevel.put(schedulerKey, NodeType.NODE_LOCAL);\n      return NodeType.NODE_LOCAL;\n    }\n\n    NodeType allowed \u003d allowedLocalityLevel.get(schedulerKey);\n\n    // If level is already most liberal, we\u0027re done\n    if (allowed.equals(NodeType.OFF_SWITCH)) return NodeType.OFF_SWITCH;\n\n    double threshold \u003d allowed.equals(NodeType.NODE_LOCAL) ? nodeLocalityThreshold :\n      rackLocalityThreshold;\n\n    // Relax locality constraints once we\u0027ve surpassed threshold.\n    if (getSchedulingOpportunities(schedulerKey) \u003e (numNodes * threshold)) {\n      if (allowed.equals(NodeType.NODE_LOCAL)) {\n        allowedLocalityLevel.put(schedulerKey, NodeType.RACK_LOCAL);\n        resetSchedulingOpportunities(schedulerKey);\n      }\n      else if (allowed.equals(NodeType.RACK_LOCAL)) {\n        allowedLocalityLevel.put(schedulerKey, NodeType.OFF_SWITCH);\n        resetSchedulingOpportunities(schedulerKey);\n      }\n    }\n    return allowedLocalityLevel.get(schedulerKey);\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java",
          "extendedDetails": {}
        }
      ]
    },
    "486e718fc1f5befd231494e2ec06bb360484f191": {
      "type": "Yintroduced",
      "commitMessage": "YARN-2399. FairScheduler: Merge AppSchedulable and FSSchedulerApp into FSAppAttempt. (kasha)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1617600 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/08/14 2:43 PM",
      "commitName": "486e718fc1f5befd231494e2ec06bb360484f191",
      "commitAuthor": "Karthik Kambatla",
      "diff": "@@ -0,0 +1,38 @@\n+  public synchronized NodeType getAllowedLocalityLevel(Priority priority,\n+      int numNodes, double nodeLocalityThreshold, double rackLocalityThreshold) {\n+    // upper limit on threshold\n+    if (nodeLocalityThreshold \u003e 1.0) { nodeLocalityThreshold \u003d 1.0; }\n+    if (rackLocalityThreshold \u003e 1.0) { rackLocalityThreshold \u003d 1.0; }\n+\n+    // If delay scheduling is not being used, can schedule anywhere\n+    if (nodeLocalityThreshold \u003c 0.0 || rackLocalityThreshold \u003c 0.0) {\n+      return NodeType.OFF_SWITCH;\n+    }\n+\n+    // Default level is NODE_LOCAL\n+    if (!allowedLocalityLevel.containsKey(priority)) {\n+      allowedLocalityLevel.put(priority, NodeType.NODE_LOCAL);\n+      return NodeType.NODE_LOCAL;\n+    }\n+\n+    NodeType allowed \u003d allowedLocalityLevel.get(priority);\n+\n+    // If level is already most liberal, we\u0027re done\n+    if (allowed.equals(NodeType.OFF_SWITCH)) return NodeType.OFF_SWITCH;\n+\n+    double threshold \u003d allowed.equals(NodeType.NODE_LOCAL) ? nodeLocalityThreshold :\n+      rackLocalityThreshold;\n+\n+    // Relax locality constraints once we\u0027ve surpassed threshold.\n+    if (getSchedulingOpportunities(priority) \u003e (numNodes * threshold)) {\n+      if (allowed.equals(NodeType.NODE_LOCAL)) {\n+        allowedLocalityLevel.put(priority, NodeType.RACK_LOCAL);\n+        resetSchedulingOpportunities(priority);\n+      }\n+      else if (allowed.equals(NodeType.RACK_LOCAL)) {\n+        allowedLocalityLevel.put(priority, NodeType.OFF_SWITCH);\n+        resetSchedulingOpportunities(priority);\n+      }\n+    }\n+    return allowedLocalityLevel.get(priority);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized NodeType getAllowedLocalityLevel(Priority priority,\n      int numNodes, double nodeLocalityThreshold, double rackLocalityThreshold) {\n    // upper limit on threshold\n    if (nodeLocalityThreshold \u003e 1.0) { nodeLocalityThreshold \u003d 1.0; }\n    if (rackLocalityThreshold \u003e 1.0) { rackLocalityThreshold \u003d 1.0; }\n\n    // If delay scheduling is not being used, can schedule anywhere\n    if (nodeLocalityThreshold \u003c 0.0 || rackLocalityThreshold \u003c 0.0) {\n      return NodeType.OFF_SWITCH;\n    }\n\n    // Default level is NODE_LOCAL\n    if (!allowedLocalityLevel.containsKey(priority)) {\n      allowedLocalityLevel.put(priority, NodeType.NODE_LOCAL);\n      return NodeType.NODE_LOCAL;\n    }\n\n    NodeType allowed \u003d allowedLocalityLevel.get(priority);\n\n    // If level is already most liberal, we\u0027re done\n    if (allowed.equals(NodeType.OFF_SWITCH)) return NodeType.OFF_SWITCH;\n\n    double threshold \u003d allowed.equals(NodeType.NODE_LOCAL) ? nodeLocalityThreshold :\n      rackLocalityThreshold;\n\n    // Relax locality constraints once we\u0027ve surpassed threshold.\n    if (getSchedulingOpportunities(priority) \u003e (numNodes * threshold)) {\n      if (allowed.equals(NodeType.NODE_LOCAL)) {\n        allowedLocalityLevel.put(priority, NodeType.RACK_LOCAL);\n        resetSchedulingOpportunities(priority);\n      }\n      else if (allowed.equals(NodeType.RACK_LOCAL)) {\n        allowedLocalityLevel.put(priority, NodeType.OFF_SWITCH);\n        resetSchedulingOpportunities(priority);\n      }\n    }\n    return allowedLocalityLevel.get(priority);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java"
    }
  }
}