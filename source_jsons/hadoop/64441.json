{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3AInputStream.java",
  "functionName": "read",
  "functionId": "read___buf-byte[]__off-int__len-int",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
  "functionStartLine": 450,
  "functionEndLine": 502,
  "numCommitsSeen": 28,
  "timeTaken": 2417,
  "changeHistory": [
    "d503f65b6689b19278ec2a0cf9da5a8762539de8",
    "8110d6a0d59e7dc2ddb25fa424fab188c5e9ce35",
    "4ee3543625c77c06d566fe81644d21c607d6d74d",
    "39ec1515a205952eda7e171408a8b83eceb4abde",
    "27c4e90efce04e1b1302f668b5eb22412e00d033",
    "b9e3eff62a7415d8666656a75db69ff3e43f8e7e",
    "6ba52d88ec11444cbac946ffadbc645acd0657de",
    "24d920b80eb3626073925a1d0b6dcf148add8cc0"
  ],
  "changeHistoryShort": {
    "d503f65b6689b19278ec2a0cf9da5a8762539de8": "Ybodychange",
    "8110d6a0d59e7dc2ddb25fa424fab188c5e9ce35": "Ybodychange",
    "4ee3543625c77c06d566fe81644d21c607d6d74d": "Ybodychange",
    "39ec1515a205952eda7e171408a8b83eceb4abde": "Ybodychange",
    "27c4e90efce04e1b1302f668b5eb22412e00d033": "Ybodychange",
    "b9e3eff62a7415d8666656a75db69ff3e43f8e7e": "Ybodychange",
    "6ba52d88ec11444cbac946ffadbc645acd0657de": "Ybodychange",
    "24d920b80eb3626073925a1d0b6dcf148add8cc0": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d503f65b6689b19278ec2a0cf9da5a8762539de8": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15541. [s3a] Shouldn\u0027t try to drain stream before aborting\nconnection in case of timeout.\n",
      "commitDate": "10/07/18 8:52 AM",
      "commitName": "d503f65b6689b19278ec2a0cf9da5a8762539de8",
      "commitAuthor": "Sean Mackrory",
      "commitDateOld": "27/06/18 10:37 PM",
      "commitNameOld": "2b2399d623539ab68e71a38fa9fbfc9a405bddb8",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 12.43,
      "commitsBetweenForRepo": 75,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,53 @@\n   public synchronized int read(byte[] buf, int off, int len)\n       throws IOException {\n     checkNotClosed();\n \n     validatePositionedReadArgs(nextReadPos, buf, off, len);\n     if (len \u003d\u003d 0) {\n       return 0;\n     }\n \n     if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n       return -1;\n     }\n \n     try {\n       lazySeek(nextReadPos, len);\n     } catch (EOFException e) {\n       // the end of the file has moved\n       return -1;\n     }\n \n     // With S3Guard, the metadatastore gave us metadata for the file in\n     // open(), so we use a slightly different retry policy.\n     // read() may not be likely to fail, but reopen() does a GET which\n     // certainly could.\n     Invoker invoker \u003d context.getReadInvoker();\n \n     streamStatistics.readOperationStarted(nextReadPos, len);\n     int bytesRead \u003d invoker.retry(\"read\", pathStr, true,\n         () -\u003e {\n           int bytes;\n           try {\n             bytes \u003d wrappedStream.read(buf, off, len);\n           } catch (EOFException e) {\n             // the base implementation swallows EOFs.\n             return -1;\n+          } catch (SocketTimeoutException e) {\n+            onReadFailure(e, len, true);\n+            bytes \u003d wrappedStream.read(buf, off, len);\n           } catch (IOException e) {\n-            onReadFailure(e, len);\n+            onReadFailure(e, len, false);\n             bytes\u003d wrappedStream.read(buf, off, len);\n           }\n           return bytes;\n         });\n \n     if (bytesRead \u003e 0) {\n       pos +\u003d bytesRead;\n       nextReadPos +\u003d bytesRead;\n     }\n     incrementBytesRead(bytesRead);\n     streamStatistics.readOperationCompleted(len, bytesRead);\n     return bytesRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read(byte[] buf, int off, int len)\n      throws IOException {\n    checkNotClosed();\n\n    validatePositionedReadArgs(nextReadPos, buf, off, len);\n    if (len \u003d\u003d 0) {\n      return 0;\n    }\n\n    if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n      return -1;\n    }\n\n    try {\n      lazySeek(nextReadPos, len);\n    } catch (EOFException e) {\n      // the end of the file has moved\n      return -1;\n    }\n\n    // With S3Guard, the metadatastore gave us metadata for the file in\n    // open(), so we use a slightly different retry policy.\n    // read() may not be likely to fail, but reopen() does a GET which\n    // certainly could.\n    Invoker invoker \u003d context.getReadInvoker();\n\n    streamStatistics.readOperationStarted(nextReadPos, len);\n    int bytesRead \u003d invoker.retry(\"read\", pathStr, true,\n        () -\u003e {\n          int bytes;\n          try {\n            bytes \u003d wrappedStream.read(buf, off, len);\n          } catch (EOFException e) {\n            // the base implementation swallows EOFs.\n            return -1;\n          } catch (SocketTimeoutException e) {\n            onReadFailure(e, len, true);\n            bytes \u003d wrappedStream.read(buf, off, len);\n          } catch (IOException e) {\n            onReadFailure(e, len, false);\n            bytes\u003d wrappedStream.read(buf, off, len);\n          }\n          return bytes;\n        });\n\n    if (bytesRead \u003e 0) {\n      pos +\u003d bytesRead;\n      nextReadPos +\u003d bytesRead;\n    }\n    incrementBytesRead(bytesRead);\n    streamStatistics.readOperationCompleted(len, bytesRead);\n    return bytesRead;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
      "extendedDetails": {}
    },
    "8110d6a0d59e7dc2ddb25fa424fab188c5e9ce35": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13761. S3Guard: implement retries for DDB failures and throttling; translate exceptions.\nContributed by Aaron Fabbri.\n",
      "commitDate": "05/03/18 6:06 AM",
      "commitName": "8110d6a0d59e7dc2ddb25fa424fab188c5e9ce35",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "20/12/17 10:25 AM",
      "commitNameOld": "1ba491ff907fc5d2618add980734a3534e2be098",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 74.82,
      "commitsBetweenForRepo": 402,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,50 @@\n   public synchronized int read(byte[] buf, int off, int len)\n       throws IOException {\n     checkNotClosed();\n \n     validatePositionedReadArgs(nextReadPos, buf, off, len);\n     if (len \u003d\u003d 0) {\n       return 0;\n     }\n \n     if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n       return -1;\n     }\n \n     try {\n       lazySeek(nextReadPos, len);\n     } catch (EOFException e) {\n       // the end of the file has moved\n       return -1;\n     }\n \n-    int bytesRead;\n-    try {\n-      streamStatistics.readOperationStarted(nextReadPos, len);\n-      bytesRead \u003d wrappedStream.read(buf, off, len);\n-    } catch (EOFException e) {\n-      onReadFailure(e, len);\n-      // the base implementation swallows EOFs.\n-      return -1;\n-    } catch (IOException e) {\n-      onReadFailure(e, len);\n-      bytesRead \u003d wrappedStream.read(buf, off, len);\n-    }\n+    // With S3Guard, the metadatastore gave us metadata for the file in\n+    // open(), so we use a slightly different retry policy.\n+    // read() may not be likely to fail, but reopen() does a GET which\n+    // certainly could.\n+    Invoker invoker \u003d context.getReadInvoker();\n+\n+    streamStatistics.readOperationStarted(nextReadPos, len);\n+    int bytesRead \u003d invoker.retry(\"read\", pathStr, true,\n+        () -\u003e {\n+          int bytes;\n+          try {\n+            bytes \u003d wrappedStream.read(buf, off, len);\n+          } catch (EOFException e) {\n+            // the base implementation swallows EOFs.\n+            return -1;\n+          } catch (IOException e) {\n+            onReadFailure(e, len);\n+            bytes\u003d wrappedStream.read(buf, off, len);\n+          }\n+          return bytes;\n+        });\n \n     if (bytesRead \u003e 0) {\n       pos +\u003d bytesRead;\n       nextReadPos +\u003d bytesRead;\n     }\n     incrementBytesRead(bytesRead);\n     streamStatistics.readOperationCompleted(len, bytesRead);\n     return bytesRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read(byte[] buf, int off, int len)\n      throws IOException {\n    checkNotClosed();\n\n    validatePositionedReadArgs(nextReadPos, buf, off, len);\n    if (len \u003d\u003d 0) {\n      return 0;\n    }\n\n    if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n      return -1;\n    }\n\n    try {\n      lazySeek(nextReadPos, len);\n    } catch (EOFException e) {\n      // the end of the file has moved\n      return -1;\n    }\n\n    // With S3Guard, the metadatastore gave us metadata for the file in\n    // open(), so we use a slightly different retry policy.\n    // read() may not be likely to fail, but reopen() does a GET which\n    // certainly could.\n    Invoker invoker \u003d context.getReadInvoker();\n\n    streamStatistics.readOperationStarted(nextReadPos, len);\n    int bytesRead \u003d invoker.retry(\"read\", pathStr, true,\n        () -\u003e {\n          int bytes;\n          try {\n            bytes \u003d wrappedStream.read(buf, off, len);\n          } catch (EOFException e) {\n            // the base implementation swallows EOFs.\n            return -1;\n          } catch (IOException e) {\n            onReadFailure(e, len);\n            bytes\u003d wrappedStream.read(buf, off, len);\n          }\n          return bytes;\n        });\n\n    if (bytesRead \u003e 0) {\n      pos +\u003d bytesRead;\n      nextReadPos +\u003d bytesRead;\n    }\n    incrementBytesRead(bytesRead);\n    streamStatistics.readOperationCompleted(len, bytesRead);\n    return bytesRead;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
      "extendedDetails": {}
    },
    "4ee3543625c77c06d566fe81644d21c607d6d74d": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13203 S3A: Support fadvise \"random\" mode for high performance readPositioned() reads. Contributed by Rajesh Balamohan and stevel.\n",
      "commitDate": "22/06/16 7:45 AM",
      "commitName": "4ee3543625c77c06d566fe81644d21c607d6d74d",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "21/05/16 8:39 AM",
      "commitNameOld": "39ec1515a205952eda7e171408a8b83eceb4abde",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 31.96,
      "commitsBetweenForRepo": 198,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,41 @@\n   public synchronized int read(byte[] buf, int off, int len)\n       throws IOException {\n     checkNotClosed();\n \n     validatePositionedReadArgs(nextReadPos, buf, off, len);\n     if (len \u003d\u003d 0) {\n       return 0;\n     }\n \n     if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n       return -1;\n     }\n \n     try {\n       lazySeek(nextReadPos, len);\n     } catch (EOFException e) {\n       // the end of the file has moved\n       return -1;\n     }\n \n     int bytesRead;\n     try {\n       streamStatistics.readOperationStarted(nextReadPos, len);\n       bytesRead \u003d wrappedStream.read(buf, off, len);\n     } catch (EOFException e) {\n-      throw e;\n+      onReadFailure(e, len);\n+      // the base implementation swallows EOFs.\n+      return -1;\n     } catch (IOException e) {\n       onReadFailure(e, len);\n       bytesRead \u003d wrappedStream.read(buf, off, len);\n     }\n \n     if (bytesRead \u003e 0) {\n       pos +\u003d bytesRead;\n       nextReadPos +\u003d bytesRead;\n     }\n     incrementBytesRead(bytesRead);\n     streamStatistics.readOperationCompleted(len, bytesRead);\n     return bytesRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read(byte[] buf, int off, int len)\n      throws IOException {\n    checkNotClosed();\n\n    validatePositionedReadArgs(nextReadPos, buf, off, len);\n    if (len \u003d\u003d 0) {\n      return 0;\n    }\n\n    if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n      return -1;\n    }\n\n    try {\n      lazySeek(nextReadPos, len);\n    } catch (EOFException e) {\n      // the end of the file has moved\n      return -1;\n    }\n\n    int bytesRead;\n    try {\n      streamStatistics.readOperationStarted(nextReadPos, len);\n      bytesRead \u003d wrappedStream.read(buf, off, len);\n    } catch (EOFException e) {\n      onReadFailure(e, len);\n      // the base implementation swallows EOFs.\n      return -1;\n    } catch (IOException e) {\n      onReadFailure(e, len);\n      bytesRead \u003d wrappedStream.read(buf, off, len);\n    }\n\n    if (bytesRead \u003e 0) {\n      pos +\u003d bytesRead;\n      nextReadPos +\u003d bytesRead;\n    }\n    incrementBytesRead(bytesRead);\n    streamStatistics.readOperationCompleted(len, bytesRead);\n    return bytesRead;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
      "extendedDetails": {}
    },
    "39ec1515a205952eda7e171408a8b83eceb4abde": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13130. s3a failures can surface as RTEs, not IOEs. (Steve Loughran)\n",
      "commitDate": "21/05/16 8:39 AM",
      "commitName": "39ec1515a205952eda7e171408a8b83eceb4abde",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "12/05/16 11:24 AM",
      "commitNameOld": "27c4e90efce04e1b1302f668b5eb22412e00d033",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 8.89,
      "commitsBetweenForRepo": 74,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,39 @@\n   public synchronized int read(byte[] buf, int off, int len)\n       throws IOException {\n     checkNotClosed();\n \n     validatePositionedReadArgs(nextReadPos, buf, off, len);\n     if (len \u003d\u003d 0) {\n       return 0;\n     }\n \n     if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n       return -1;\n     }\n \n-    lazySeek(nextReadPos, len);\n-    streamStatistics.readOperationStarted(nextReadPos, len);\n+    try {\n+      lazySeek(nextReadPos, len);\n+    } catch (EOFException e) {\n+      // the end of the file has moved\n+      return -1;\n+    }\n \n     int bytesRead;\n     try {\n+      streamStatistics.readOperationStarted(nextReadPos, len);\n       bytesRead \u003d wrappedStream.read(buf, off, len);\n     } catch (EOFException e) {\n       throw e;\n     } catch (IOException e) {\n       onReadFailure(e, len);\n       bytesRead \u003d wrappedStream.read(buf, off, len);\n     }\n \n     if (bytesRead \u003e 0) {\n       pos +\u003d bytesRead;\n       nextReadPos +\u003d bytesRead;\n     }\n     incrementBytesRead(bytesRead);\n     streamStatistics.readOperationCompleted(len, bytesRead);\n     return bytesRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read(byte[] buf, int off, int len)\n      throws IOException {\n    checkNotClosed();\n\n    validatePositionedReadArgs(nextReadPos, buf, off, len);\n    if (len \u003d\u003d 0) {\n      return 0;\n    }\n\n    if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n      return -1;\n    }\n\n    try {\n      lazySeek(nextReadPos, len);\n    } catch (EOFException e) {\n      // the end of the file has moved\n      return -1;\n    }\n\n    int bytesRead;\n    try {\n      streamStatistics.readOperationStarted(nextReadPos, len);\n      bytesRead \u003d wrappedStream.read(buf, off, len);\n    } catch (EOFException e) {\n      throw e;\n    } catch (IOException e) {\n      onReadFailure(e, len);\n      bytesRead \u003d wrappedStream.read(buf, off, len);\n    }\n\n    if (bytesRead \u003e 0) {\n      pos +\u003d bytesRead;\n      nextReadPos +\u003d bytesRead;\n    }\n    incrementBytesRead(bytesRead);\n    streamStatistics.readOperationCompleted(len, bytesRead);\n    return bytesRead;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
      "extendedDetails": {}
    },
    "27c4e90efce04e1b1302f668b5eb22412e00d033": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13028 add low level counter metrics for S3A; use in read performance tests. contributed by: stevel\npatch includes\nHADOOP-12844 Recover when S3A fails on IOException in read()\nHADOOP-13058 S3A FS fails during init against a read-only FS if multipart purge\nHADOOP-13047 S3a Forward seek in stream length to be configurable\n",
      "commitDate": "12/05/16 11:24 AM",
      "commitName": "27c4e90efce04e1b1302f668b5eb22412e00d033",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "09/04/16 3:25 AM",
      "commitNameOld": "b9e3eff62a7415d8666656a75db69ff3e43f8e7e",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 33.33,
      "commitsBetweenForRepo": 203,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,34 @@\n   public synchronized int read(byte[] buf, int off, int len)\n       throws IOException {\n     checkNotClosed();\n \n     validatePositionedReadArgs(nextReadPos, buf, off, len);\n     if (len \u003d\u003d 0) {\n       return 0;\n     }\n \n     if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n       return -1;\n     }\n \n     lazySeek(nextReadPos, len);\n+    streamStatistics.readOperationStarted(nextReadPos, len);\n \n-    int byteRead;\n+    int bytesRead;\n     try {\n-      byteRead \u003d wrappedStream.read(buf, off, len);\n-    } catch (SocketTimeoutException | SocketException e) {\n-      LOG.info(\"Got exception while trying to read from stream,\"\n-          + \" trying to recover \" + e);\n-      reopen(pos, len);\n-      byteRead \u003d wrappedStream.read(buf, off, len);\n+      bytesRead \u003d wrappedStream.read(buf, off, len);\n+    } catch (EOFException e) {\n+      throw e;\n+    } catch (IOException e) {\n+      onReadFailure(e, len);\n+      bytesRead \u003d wrappedStream.read(buf, off, len);\n     }\n \n-    if (byteRead \u003e 0) {\n-      pos +\u003d byteRead;\n-      nextReadPos +\u003d byteRead;\n+    if (bytesRead \u003e 0) {\n+      pos +\u003d bytesRead;\n+      nextReadPos +\u003d bytesRead;\n     }\n-\n-    if (stats !\u003d null \u0026\u0026 byteRead \u003e 0) {\n-      stats.incrementBytesRead(byteRead);\n-    }\n-\n-    return byteRead;\n+    incrementBytesRead(bytesRead);\n+    streamStatistics.readOperationCompleted(len, bytesRead);\n+    return bytesRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read(byte[] buf, int off, int len)\n      throws IOException {\n    checkNotClosed();\n\n    validatePositionedReadArgs(nextReadPos, buf, off, len);\n    if (len \u003d\u003d 0) {\n      return 0;\n    }\n\n    if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n      return -1;\n    }\n\n    lazySeek(nextReadPos, len);\n    streamStatistics.readOperationStarted(nextReadPos, len);\n\n    int bytesRead;\n    try {\n      bytesRead \u003d wrappedStream.read(buf, off, len);\n    } catch (EOFException e) {\n      throw e;\n    } catch (IOException e) {\n      onReadFailure(e, len);\n      bytesRead \u003d wrappedStream.read(buf, off, len);\n    }\n\n    if (bytesRead \u003e 0) {\n      pos +\u003d bytesRead;\n      nextReadPos +\u003d bytesRead;\n    }\n    incrementBytesRead(bytesRead);\n    streamStatistics.readOperationCompleted(len, bytesRead);\n    return bytesRead;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
      "extendedDetails": {}
    },
    "b9e3eff62a7415d8666656a75db69ff3e43f8e7e": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12444 Support lazy seek in S3AInputStream. Rajesh Balamohan via stevel\n",
      "commitDate": "09/04/16 3:25 AM",
      "commitName": "b9e3eff62a7415d8666656a75db69ff3e43f8e7e",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "08/04/16 1:36 PM",
      "commitNameOld": "843ee8d59d8bacbca0d87ccf0790772e39d16138",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 0.58,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,36 @@\n-  public synchronized int read(byte[] buf, int off, int len) throws IOException {\n+  public synchronized int read(byte[] buf, int off, int len)\n+      throws IOException {\n     checkNotClosed();\n \n-    openIfNeeded();\n+    validatePositionedReadArgs(nextReadPos, buf, off, len);\n+    if (len \u003d\u003d 0) {\n+      return 0;\n+    }\n+\n+    if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n+      return -1;\n+    }\n+\n+    lazySeek(nextReadPos, len);\n \n     int byteRead;\n     try {\n       byteRead \u003d wrappedStream.read(buf, off, len);\n-    } catch (SocketTimeoutException e) {\n-      LOG.info(\"Got timeout while trying to read from stream, trying to recover \" + e);\n-      reopen(pos);\n-      byteRead \u003d wrappedStream.read(buf, off, len);\n-    } catch (SocketException e) {\n-      LOG.info(\"Got socket exception while trying to read from stream, trying to recover \" + e);\n-      reopen(pos);\n+    } catch (SocketTimeoutException | SocketException e) {\n+      LOG.info(\"Got exception while trying to read from stream,\"\n+          + \" trying to recover \" + e);\n+      reopen(pos, len);\n       byteRead \u003d wrappedStream.read(buf, off, len);\n     }\n \n     if (byteRead \u003e 0) {\n       pos +\u003d byteRead;\n+      nextReadPos +\u003d byteRead;\n     }\n \n     if (stats !\u003d null \u0026\u0026 byteRead \u003e 0) {\n       stats.incrementBytesRead(byteRead);\n     }\n \n     return byteRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read(byte[] buf, int off, int len)\n      throws IOException {\n    checkNotClosed();\n\n    validatePositionedReadArgs(nextReadPos, buf, off, len);\n    if (len \u003d\u003d 0) {\n      return 0;\n    }\n\n    if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n      return -1;\n    }\n\n    lazySeek(nextReadPos, len);\n\n    int byteRead;\n    try {\n      byteRead \u003d wrappedStream.read(buf, off, len);\n    } catch (SocketTimeoutException | SocketException e) {\n      LOG.info(\"Got exception while trying to read from stream,\"\n          + \" trying to recover \" + e);\n      reopen(pos, len);\n      byteRead \u003d wrappedStream.read(buf, off, len);\n    }\n\n    if (byteRead \u003e 0) {\n      pos +\u003d byteRead;\n      nextReadPos +\u003d byteRead;\n    }\n\n    if (stats !\u003d null \u0026\u0026 byteRead \u003e 0) {\n      stats.incrementBytesRead(byteRead);\n    }\n\n    return byteRead;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
      "extendedDetails": {}
    },
    "6ba52d88ec11444cbac946ffadbc645acd0657de": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10714. AmazonS3Client.deleteObjects() need to be limited to 1000 entries per call. Contributed by Juan Yu.\n",
      "commitDate": "05/11/14 5:17 PM",
      "commitName": "6ba52d88ec11444cbac946ffadbc645acd0657de",
      "commitAuthor": "Aaron T. Myers",
      "commitDateOld": "15/09/14 8:27 AM",
      "commitNameOld": "24d920b80eb3626073925a1d0b6dcf148add8cc0",
      "commitAuthorOld": "Aaron T. Myers",
      "daysBetweenCommits": 51.41,
      "commitsBetweenForRepo": 545,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,28 @@\n-  public synchronized int read(byte buf[], int off, int len) throws IOException {\n-    if (closed) {\n-      throw new IOException(\"Stream closed\");\n-    }\n+  public synchronized int read(byte[] buf, int off, int len) throws IOException {\n+    checkNotClosed();\n \n     openIfNeeded();\n \n     int byteRead;\n     try {\n       byteRead \u003d wrappedStream.read(buf, off, len);\n     } catch (SocketTimeoutException e) {\n       LOG.info(\"Got timeout while trying to read from stream, trying to recover \" + e);\n       reopen(pos);\n       byteRead \u003d wrappedStream.read(buf, off, len);\n     } catch (SocketException e) {\n       LOG.info(\"Got socket exception while trying to read from stream, trying to recover \" + e);\n       reopen(pos);\n       byteRead \u003d wrappedStream.read(buf, off, len);\n     }\n \n     if (byteRead \u003e 0) {\n       pos +\u003d byteRead;\n     }\n \n     if (stats !\u003d null \u0026\u0026 byteRead \u003e 0) {\n       stats.incrementBytesRead(byteRead);\n     }\n \n     return byteRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read(byte[] buf, int off, int len) throws IOException {\n    checkNotClosed();\n\n    openIfNeeded();\n\n    int byteRead;\n    try {\n      byteRead \u003d wrappedStream.read(buf, off, len);\n    } catch (SocketTimeoutException e) {\n      LOG.info(\"Got timeout while trying to read from stream, trying to recover \" + e);\n      reopen(pos);\n      byteRead \u003d wrappedStream.read(buf, off, len);\n    } catch (SocketException e) {\n      LOG.info(\"Got socket exception while trying to read from stream, trying to recover \" + e);\n      reopen(pos);\n      byteRead \u003d wrappedStream.read(buf, off, len);\n    }\n\n    if (byteRead \u003e 0) {\n      pos +\u003d byteRead;\n    }\n\n    if (stats !\u003d null \u0026\u0026 byteRead \u003e 0) {\n      stats.incrementBytesRead(byteRead);\n    }\n\n    return byteRead;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
      "extendedDetails": {}
    },
    "24d920b80eb3626073925a1d0b6dcf148add8cc0": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-10400. Incorporate new S3A FileSystem implementation. Contributed by Jordan Mendelson and Dave Wang.\n",
      "commitDate": "15/09/14 8:27 AM",
      "commitName": "24d920b80eb3626073925a1d0b6dcf148add8cc0",
      "commitAuthor": "Aaron T. Myers",
      "diff": "@@ -0,0 +1,30 @@\n+  public synchronized int read(byte buf[], int off, int len) throws IOException {\n+    if (closed) {\n+      throw new IOException(\"Stream closed\");\n+    }\n+\n+    openIfNeeded();\n+\n+    int byteRead;\n+    try {\n+      byteRead \u003d wrappedStream.read(buf, off, len);\n+    } catch (SocketTimeoutException e) {\n+      LOG.info(\"Got timeout while trying to read from stream, trying to recover \" + e);\n+      reopen(pos);\n+      byteRead \u003d wrappedStream.read(buf, off, len);\n+    } catch (SocketException e) {\n+      LOG.info(\"Got socket exception while trying to read from stream, trying to recover \" + e);\n+      reopen(pos);\n+      byteRead \u003d wrappedStream.read(buf, off, len);\n+    }\n+\n+    if (byteRead \u003e 0) {\n+      pos +\u003d byteRead;\n+    }\n+\n+    if (stats !\u003d null \u0026\u0026 byteRead \u003e 0) {\n+      stats.incrementBytesRead(byteRead);\n+    }\n+\n+    return byteRead;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read(byte buf[], int off, int len) throws IOException {\n    if (closed) {\n      throw new IOException(\"Stream closed\");\n    }\n\n    openIfNeeded();\n\n    int byteRead;\n    try {\n      byteRead \u003d wrappedStream.read(buf, off, len);\n    } catch (SocketTimeoutException e) {\n      LOG.info(\"Got timeout while trying to read from stream, trying to recover \" + e);\n      reopen(pos);\n      byteRead \u003d wrappedStream.read(buf, off, len);\n    } catch (SocketException e) {\n      LOG.info(\"Got socket exception while trying to read from stream, trying to recover \" + e);\n      reopen(pos);\n      byteRead \u003d wrappedStream.read(buf, off, len);\n    }\n\n    if (byteRead \u003e 0) {\n      pos +\u003d byteRead;\n    }\n\n    if (stats !\u003d null \u0026\u0026 byteRead \u003e 0) {\n      stats.incrementBytesRead(byteRead);\n    }\n\n    return byteRead;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java"
    }
  }
}