{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSNetworkTopology.java",
  "functionName": "getEligibleChildren",
  "functionId": "getEligibleChildren___root-DFSTopologyNodeImpl__excludeRoot-Node__type-StorageType__excludedNodes-Collection__Node__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/net/DFSNetworkTopology.java",
  "functionStartLine": 343,
  "functionEndLine": 395,
  "numCommitsSeen": 21,
  "timeTaken": 2555,
  "changeHistory": [
    "c84e6beada4e604175f7f138c9878a29665a8c47",
    "9832ae0ed8853d29072c9ea7031cd2373e6b16f9"
  ],
  "changeHistoryShort": {
    "c84e6beada4e604175f7f138c9878a29665a8c47": "Ymultichange(Yparameterchange,Ybodychange)",
    "9832ae0ed8853d29072c9ea7031cd2373e6b16f9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c84e6beada4e604175f7f138c9878a29665a8c47": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-14999. Avoid Potential Infinite Loop in DFSNetworkTopology. Contributed by Ayush Saxena.\n",
      "commitDate": "18/05/20 9:54 AM",
      "commitName": "c84e6beada4e604175f7f138c9878a29665a8c47",
      "commitAuthor": "Ayush Saxena",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-14999. Avoid Potential Infinite Loop in DFSNetworkTopology. Contributed by Ayush Saxena.\n",
          "commitDate": "18/05/20 9:54 AM",
          "commitName": "c84e6beada4e604175f7f138c9878a29665a8c47",
          "commitAuthor": "Ayush Saxena",
          "commitDateOld": "08/04/20 3:25 AM",
          "commitNameOld": "1189af4746919774035f5d64ccb4d2ce21905aaa",
          "commitAuthorOld": "Ayush Saxena",
          "daysBetweenCommits": 40.27,
          "commitsBetweenForRepo": 144,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,34 +1,53 @@\n   private ArrayList\u003cDFSTopologyNodeImpl\u003e getEligibleChildren(\n-      DFSTopologyNodeImpl root, Node excludeRoot, StorageType type) {\n+      DFSTopologyNodeImpl root, Node excludeRoot, StorageType type,\n+      Collection\u003cNode\u003e excludedNodes) {\n     ArrayList\u003cDFSTopologyNodeImpl\u003e candidates \u003d new ArrayList\u003c\u003e();\n     int excludeCount \u003d 0;\n     if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n       // the subtree to be excluded is under the given root,\n       // find out the number of nodes to be excluded.\n       if (excludeRoot instanceof DFSTopologyNodeImpl) {\n         // if excludedRoot is an inner node, get the counts of all nodes on\n         // this subtree of that storage type.\n         excludeCount \u003d ((DFSTopologyNodeImpl) excludeRoot)\n             .getSubtreeStorageCount(type);\n       } else {\n         // if excludedRoot is a datanode, simply ignore this one node\n         if (((DatanodeDescriptor) excludeRoot).hasStorageType(type)) {\n           excludeCount \u003d 1;\n         }\n       }\n     }\n     // have calculated the number of storage counts to be excluded.\n     // walk through all children to check eligibility.\n     for (Node node : root.getChildren()) {\n       DFSTopologyNodeImpl dfsNode \u003d (DFSTopologyNodeImpl) node;\n       int storageCount \u003d dfsNode.getSubtreeStorageCount(type);\n       if (excludeRoot !\u003d null \u0026\u0026 excludeCount !\u003d 0 \u0026\u0026\n           (dfsNode.isAncestor(excludeRoot) || dfsNode.equals(excludeRoot))) {\n         storageCount -\u003d excludeCount;\n       }\n+      if (excludedNodes !\u003d null) {\n+        for (Node excludedNode : excludedNodes) {\n+          if (excludeRoot !\u003d null \u0026\u0026 isNodeInScope(excludedNode,\n+              NodeBase.getPath(excludeRoot))) {\n+            continue;\n+          }\n+          if (isNodeInScope(excludedNode, NodeBase.getPath(node))) {\n+            if (excludedNode instanceof DatanodeDescriptor) {\n+              storageCount -\u003d\n+                  ((DatanodeDescriptor) excludedNode).hasStorageType(type) ?\n+                      1 : 0;\n+            } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n+              storageCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n+                  .getSubtreeStorageCount(type);\n+            }\n+          }\n+        }\n+      }\n       if (storageCount \u003e 0) {\n         candidates.add(dfsNode);\n       }\n     }\n     return candidates;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private ArrayList\u003cDFSTopologyNodeImpl\u003e getEligibleChildren(\n      DFSTopologyNodeImpl root, Node excludeRoot, StorageType type,\n      Collection\u003cNode\u003e excludedNodes) {\n    ArrayList\u003cDFSTopologyNodeImpl\u003e candidates \u003d new ArrayList\u003c\u003e();\n    int excludeCount \u003d 0;\n    if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n      // the subtree to be excluded is under the given root,\n      // find out the number of nodes to be excluded.\n      if (excludeRoot instanceof DFSTopologyNodeImpl) {\n        // if excludedRoot is an inner node, get the counts of all nodes on\n        // this subtree of that storage type.\n        excludeCount \u003d ((DFSTopologyNodeImpl) excludeRoot)\n            .getSubtreeStorageCount(type);\n      } else {\n        // if excludedRoot is a datanode, simply ignore this one node\n        if (((DatanodeDescriptor) excludeRoot).hasStorageType(type)) {\n          excludeCount \u003d 1;\n        }\n      }\n    }\n    // have calculated the number of storage counts to be excluded.\n    // walk through all children to check eligibility.\n    for (Node node : root.getChildren()) {\n      DFSTopologyNodeImpl dfsNode \u003d (DFSTopologyNodeImpl) node;\n      int storageCount \u003d dfsNode.getSubtreeStorageCount(type);\n      if (excludeRoot !\u003d null \u0026\u0026 excludeCount !\u003d 0 \u0026\u0026\n          (dfsNode.isAncestor(excludeRoot) || dfsNode.equals(excludeRoot))) {\n        storageCount -\u003d excludeCount;\n      }\n      if (excludedNodes !\u003d null) {\n        for (Node excludedNode : excludedNodes) {\n          if (excludeRoot !\u003d null \u0026\u0026 isNodeInScope(excludedNode,\n              NodeBase.getPath(excludeRoot))) {\n            continue;\n          }\n          if (isNodeInScope(excludedNode, NodeBase.getPath(node))) {\n            if (excludedNode instanceof DatanodeDescriptor) {\n              storageCount -\u003d\n                  ((DatanodeDescriptor) excludedNode).hasStorageType(type) ?\n                      1 : 0;\n            } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n              storageCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n                  .getSubtreeStorageCount(type);\n            }\n          }\n        }\n      }\n      if (storageCount \u003e 0) {\n        candidates.add(dfsNode);\n      }\n    }\n    return candidates;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/net/DFSNetworkTopology.java",
          "extendedDetails": {
            "oldValue": "[root-DFSTopologyNodeImpl, excludeRoot-Node, type-StorageType]",
            "newValue": "[root-DFSTopologyNodeImpl, excludeRoot-Node, type-StorageType, excludedNodes-Collection\u003cNode\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-14999. Avoid Potential Infinite Loop in DFSNetworkTopology. Contributed by Ayush Saxena.\n",
          "commitDate": "18/05/20 9:54 AM",
          "commitName": "c84e6beada4e604175f7f138c9878a29665a8c47",
          "commitAuthor": "Ayush Saxena",
          "commitDateOld": "08/04/20 3:25 AM",
          "commitNameOld": "1189af4746919774035f5d64ccb4d2ce21905aaa",
          "commitAuthorOld": "Ayush Saxena",
          "daysBetweenCommits": 40.27,
          "commitsBetweenForRepo": 144,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,34 +1,53 @@\n   private ArrayList\u003cDFSTopologyNodeImpl\u003e getEligibleChildren(\n-      DFSTopologyNodeImpl root, Node excludeRoot, StorageType type) {\n+      DFSTopologyNodeImpl root, Node excludeRoot, StorageType type,\n+      Collection\u003cNode\u003e excludedNodes) {\n     ArrayList\u003cDFSTopologyNodeImpl\u003e candidates \u003d new ArrayList\u003c\u003e();\n     int excludeCount \u003d 0;\n     if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n       // the subtree to be excluded is under the given root,\n       // find out the number of nodes to be excluded.\n       if (excludeRoot instanceof DFSTopologyNodeImpl) {\n         // if excludedRoot is an inner node, get the counts of all nodes on\n         // this subtree of that storage type.\n         excludeCount \u003d ((DFSTopologyNodeImpl) excludeRoot)\n             .getSubtreeStorageCount(type);\n       } else {\n         // if excludedRoot is a datanode, simply ignore this one node\n         if (((DatanodeDescriptor) excludeRoot).hasStorageType(type)) {\n           excludeCount \u003d 1;\n         }\n       }\n     }\n     // have calculated the number of storage counts to be excluded.\n     // walk through all children to check eligibility.\n     for (Node node : root.getChildren()) {\n       DFSTopologyNodeImpl dfsNode \u003d (DFSTopologyNodeImpl) node;\n       int storageCount \u003d dfsNode.getSubtreeStorageCount(type);\n       if (excludeRoot !\u003d null \u0026\u0026 excludeCount !\u003d 0 \u0026\u0026\n           (dfsNode.isAncestor(excludeRoot) || dfsNode.equals(excludeRoot))) {\n         storageCount -\u003d excludeCount;\n       }\n+      if (excludedNodes !\u003d null) {\n+        for (Node excludedNode : excludedNodes) {\n+          if (excludeRoot !\u003d null \u0026\u0026 isNodeInScope(excludedNode,\n+              NodeBase.getPath(excludeRoot))) {\n+            continue;\n+          }\n+          if (isNodeInScope(excludedNode, NodeBase.getPath(node))) {\n+            if (excludedNode instanceof DatanodeDescriptor) {\n+              storageCount -\u003d\n+                  ((DatanodeDescriptor) excludedNode).hasStorageType(type) ?\n+                      1 : 0;\n+            } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n+              storageCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n+                  .getSubtreeStorageCount(type);\n+            }\n+          }\n+        }\n+      }\n       if (storageCount \u003e 0) {\n         candidates.add(dfsNode);\n       }\n     }\n     return candidates;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private ArrayList\u003cDFSTopologyNodeImpl\u003e getEligibleChildren(\n      DFSTopologyNodeImpl root, Node excludeRoot, StorageType type,\n      Collection\u003cNode\u003e excludedNodes) {\n    ArrayList\u003cDFSTopologyNodeImpl\u003e candidates \u003d new ArrayList\u003c\u003e();\n    int excludeCount \u003d 0;\n    if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n      // the subtree to be excluded is under the given root,\n      // find out the number of nodes to be excluded.\n      if (excludeRoot instanceof DFSTopologyNodeImpl) {\n        // if excludedRoot is an inner node, get the counts of all nodes on\n        // this subtree of that storage type.\n        excludeCount \u003d ((DFSTopologyNodeImpl) excludeRoot)\n            .getSubtreeStorageCount(type);\n      } else {\n        // if excludedRoot is a datanode, simply ignore this one node\n        if (((DatanodeDescriptor) excludeRoot).hasStorageType(type)) {\n          excludeCount \u003d 1;\n        }\n      }\n    }\n    // have calculated the number of storage counts to be excluded.\n    // walk through all children to check eligibility.\n    for (Node node : root.getChildren()) {\n      DFSTopologyNodeImpl dfsNode \u003d (DFSTopologyNodeImpl) node;\n      int storageCount \u003d dfsNode.getSubtreeStorageCount(type);\n      if (excludeRoot !\u003d null \u0026\u0026 excludeCount !\u003d 0 \u0026\u0026\n          (dfsNode.isAncestor(excludeRoot) || dfsNode.equals(excludeRoot))) {\n        storageCount -\u003d excludeCount;\n      }\n      if (excludedNodes !\u003d null) {\n        for (Node excludedNode : excludedNodes) {\n          if (excludeRoot !\u003d null \u0026\u0026 isNodeInScope(excludedNode,\n              NodeBase.getPath(excludeRoot))) {\n            continue;\n          }\n          if (isNodeInScope(excludedNode, NodeBase.getPath(node))) {\n            if (excludedNode instanceof DatanodeDescriptor) {\n              storageCount -\u003d\n                  ((DatanodeDescriptor) excludedNode).hasStorageType(type) ?\n                      1 : 0;\n            } else if (excludedNode instanceof DFSTopologyNodeImpl) {\n              storageCount -\u003d ((DFSTopologyNodeImpl) excludedNode)\n                  .getSubtreeStorageCount(type);\n            }\n          }\n        }\n      }\n      if (storageCount \u003e 0) {\n        candidates.add(dfsNode);\n      }\n    }\n    return candidates;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/net/DFSNetworkTopology.java",
          "extendedDetails": {}
        }
      ]
    },
    "9832ae0ed8853d29072c9ea7031cd2373e6b16f9": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11482. Add storage type demand to into DFSNetworkTopology#chooseRandom. Contributed by Chen Liang.\n",
      "commitDate": "13/03/17 5:30 PM",
      "commitName": "9832ae0ed8853d29072c9ea7031cd2373e6b16f9",
      "commitAuthor": "Chen Liang",
      "diff": "@@ -0,0 +1,34 @@\n+  private ArrayList\u003cDFSTopologyNodeImpl\u003e getEligibleChildren(\n+      DFSTopologyNodeImpl root, Node excludeRoot, StorageType type) {\n+    ArrayList\u003cDFSTopologyNodeImpl\u003e candidates \u003d new ArrayList\u003c\u003e();\n+    int excludeCount \u003d 0;\n+    if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n+      // the subtree to be excluded is under the given root,\n+      // find out the number of nodes to be excluded.\n+      if (excludeRoot instanceof DFSTopologyNodeImpl) {\n+        // if excludedRoot is an inner node, get the counts of all nodes on\n+        // this subtree of that storage type.\n+        excludeCount \u003d ((DFSTopologyNodeImpl) excludeRoot)\n+            .getSubtreeStorageCount(type);\n+      } else {\n+        // if excludedRoot is a datanode, simply ignore this one node\n+        if (((DatanodeDescriptor) excludeRoot).hasStorageType(type)) {\n+          excludeCount \u003d 1;\n+        }\n+      }\n+    }\n+    // have calculated the number of storage counts to be excluded.\n+    // walk through all children to check eligibility.\n+    for (Node node : root.getChildren()) {\n+      DFSTopologyNodeImpl dfsNode \u003d (DFSTopologyNodeImpl) node;\n+      int storageCount \u003d dfsNode.getSubtreeStorageCount(type);\n+      if (excludeRoot !\u003d null \u0026\u0026 excludeCount !\u003d 0 \u0026\u0026\n+          (dfsNode.isAncestor(excludeRoot) || dfsNode.equals(excludeRoot))) {\n+        storageCount -\u003d excludeCount;\n+      }\n+      if (storageCount \u003e 0) {\n+        candidates.add(dfsNode);\n+      }\n+    }\n+    return candidates;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private ArrayList\u003cDFSTopologyNodeImpl\u003e getEligibleChildren(\n      DFSTopologyNodeImpl root, Node excludeRoot, StorageType type) {\n    ArrayList\u003cDFSTopologyNodeImpl\u003e candidates \u003d new ArrayList\u003c\u003e();\n    int excludeCount \u003d 0;\n    if (excludeRoot !\u003d null \u0026\u0026 root.isAncestor(excludeRoot)) {\n      // the subtree to be excluded is under the given root,\n      // find out the number of nodes to be excluded.\n      if (excludeRoot instanceof DFSTopologyNodeImpl) {\n        // if excludedRoot is an inner node, get the counts of all nodes on\n        // this subtree of that storage type.\n        excludeCount \u003d ((DFSTopologyNodeImpl) excludeRoot)\n            .getSubtreeStorageCount(type);\n      } else {\n        // if excludedRoot is a datanode, simply ignore this one node\n        if (((DatanodeDescriptor) excludeRoot).hasStorageType(type)) {\n          excludeCount \u003d 1;\n        }\n      }\n    }\n    // have calculated the number of storage counts to be excluded.\n    // walk through all children to check eligibility.\n    for (Node node : root.getChildren()) {\n      DFSTopologyNodeImpl dfsNode \u003d (DFSTopologyNodeImpl) node;\n      int storageCount \u003d dfsNode.getSubtreeStorageCount(type);\n      if (excludeRoot !\u003d null \u0026\u0026 excludeCount !\u003d 0 \u0026\u0026\n          (dfsNode.isAncestor(excludeRoot) || dfsNode.equals(excludeRoot))) {\n        storageCount -\u003d excludeCount;\n      }\n      if (storageCount \u003e 0) {\n        candidates.add(dfsNode);\n      }\n    }\n    return candidates;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/net/DFSNetworkTopology.java"
    }
  }
}