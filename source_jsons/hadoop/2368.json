{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PBHelperClient.java",
  "functionName": "convertLocatedBlockProto",
  "functionId": "convertLocatedBlockProto___proto-LocatedBlockProto",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
  "functionStartLine": 630,
  "functionEndLine": 683,
  "numCommitsSeen": 80,
  "timeTaken": 3901,
  "changeHistory": [
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
    "a337ceb74e984991dbf976236d2e785cf5921b16",
    "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
    "70d6f201260086a3f12beaa317fede2a99639fef",
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93"
  ],
  "changeHistoryShort": {
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720": "Ybodychange",
    "a337ceb74e984991dbf976236d2e785cf5921b16": "Ybodychange",
    "e5ff0ea7ba087984262f1f27200ae5bb40d9b838": "Ybodychange",
    "70d6f201260086a3f12beaa317fede2a99639fef": "Ybodychange",
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": "Ybodychange"
  },
  "changeHistoryDetails": {
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\n",
      "commitDate": "26/03/16 7:58 PM",
      "commitName": "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "26/03/16 9:20 AM",
      "commitNameOld": "a337ceb74e984991dbf976236d2e785cf5921b16",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.44,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,56 +1,54 @@\n   public static LocatedBlock convertLocatedBlockProto(LocatedBlockProto proto) {\n     if (proto \u003d\u003d null) return null;\n     List\u003cDatanodeInfoProto\u003e locs \u003d proto.getLocsList();\n     DatanodeInfo[] targets \u003d new DatanodeInfo[locs.size()];\n     for (int i \u003d 0; i \u003c locs.size(); i++) {\n       targets[i] \u003d convert(locs.get(i));\n     }\n \n     final StorageType[] storageTypes \u003d convertStorageTypes(\n         proto.getStorageTypesList(), locs.size());\n \n     final int storageIDsCount \u003d proto.getStorageIDsCount();\n     final String[] storageIDs;\n     if (storageIDsCount \u003d\u003d 0) {\n       storageIDs \u003d null;\n     } else {\n       Preconditions.checkState(storageIDsCount \u003d\u003d locs.size());\n       storageIDs \u003d proto.getStorageIDsList()\n           .toArray(new String[storageIDsCount]);\n     }\n \n     byte[] indices \u003d null;\n     if (proto.hasBlockIndices()) {\n       indices \u003d proto.getBlockIndices().toByteArray();\n     }\n \n     // Set values from the isCached list, re-using references from loc\n     List\u003cDatanodeInfo\u003e cachedLocs \u003d new ArrayList\u003c\u003e(locs.size());\n     List\u003cBoolean\u003e isCachedList \u003d proto.getIsCachedList();\n     for (int i\u003d0; i\u003cisCachedList.size(); i++) {\n       if (isCachedList.get(i)) {\n         cachedLocs.add(targets[i]);\n       }\n     }\n \n     final LocatedBlock lb;\n     if (indices \u003d\u003d null) {\n       lb \u003d new LocatedBlock(PBHelperClient.convert(proto.getB()), targets,\n           storageIDs, storageTypes, proto.getOffset(), proto.getCorrupt(),\n           cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n     } else {\n       lb \u003d new LocatedStripedBlock(PBHelperClient.convert(proto.getB()),\n           targets, storageIDs, storageTypes, indices, proto.getOffset(),\n           proto.getCorrupt(),\n           cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n       List\u003cTokenProto\u003e tokenProtos \u003d proto.getBlockTokensList();\n-      Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d new Token[indices.length];\n-      for (int i \u003d 0; i \u003c indices.length; i++) {\n-        blockTokens[i] \u003d convert(tokenProtos.get(i));\n-      }\n+      Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d\n+          convertTokens(tokenProtos);\n       ((LocatedStripedBlock) lb).setBlockTokens(blockTokens);\n     }\n     lb.setBlockToken(convert(proto.getBlockToken()));\n \n     return lb;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static LocatedBlock convertLocatedBlockProto(LocatedBlockProto proto) {\n    if (proto \u003d\u003d null) return null;\n    List\u003cDatanodeInfoProto\u003e locs \u003d proto.getLocsList();\n    DatanodeInfo[] targets \u003d new DatanodeInfo[locs.size()];\n    for (int i \u003d 0; i \u003c locs.size(); i++) {\n      targets[i] \u003d convert(locs.get(i));\n    }\n\n    final StorageType[] storageTypes \u003d convertStorageTypes(\n        proto.getStorageTypesList(), locs.size());\n\n    final int storageIDsCount \u003d proto.getStorageIDsCount();\n    final String[] storageIDs;\n    if (storageIDsCount \u003d\u003d 0) {\n      storageIDs \u003d null;\n    } else {\n      Preconditions.checkState(storageIDsCount \u003d\u003d locs.size());\n      storageIDs \u003d proto.getStorageIDsList()\n          .toArray(new String[storageIDsCount]);\n    }\n\n    byte[] indices \u003d null;\n    if (proto.hasBlockIndices()) {\n      indices \u003d proto.getBlockIndices().toByteArray();\n    }\n\n    // Set values from the isCached list, re-using references from loc\n    List\u003cDatanodeInfo\u003e cachedLocs \u003d new ArrayList\u003c\u003e(locs.size());\n    List\u003cBoolean\u003e isCachedList \u003d proto.getIsCachedList();\n    for (int i\u003d0; i\u003cisCachedList.size(); i++) {\n      if (isCachedList.get(i)) {\n        cachedLocs.add(targets[i]);\n      }\n    }\n\n    final LocatedBlock lb;\n    if (indices \u003d\u003d null) {\n      lb \u003d new LocatedBlock(PBHelperClient.convert(proto.getB()), targets,\n          storageIDs, storageTypes, proto.getOffset(), proto.getCorrupt(),\n          cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n    } else {\n      lb \u003d new LocatedStripedBlock(PBHelperClient.convert(proto.getB()),\n          targets, storageIDs, storageTypes, indices, proto.getOffset(),\n          proto.getCorrupt(),\n          cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n      List\u003cTokenProto\u003e tokenProtos \u003d proto.getBlockTokensList();\n      Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d\n          convertTokens(tokenProtos);\n      ((LocatedStripedBlock) lb).setBlockTokens(blockTokens);\n    }\n    lb.setBlockToken(convert(proto.getBlockToken()));\n\n    return lb;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "a337ceb74e984991dbf976236d2e785cf5921b16": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\"\n\nThis reverts commit e5ff0ea7ba087984262f1f27200ae5bb40d9b838.\n",
      "commitDate": "26/03/16 9:20 AM",
      "commitName": "a337ceb74e984991dbf976236d2e785cf5921b16",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "26/03/16 12:52 AM",
      "commitNameOld": "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.35,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,56 @@\n   public static LocatedBlock convertLocatedBlockProto(LocatedBlockProto proto) {\n     if (proto \u003d\u003d null) return null;\n     List\u003cDatanodeInfoProto\u003e locs \u003d proto.getLocsList();\n     DatanodeInfo[] targets \u003d new DatanodeInfo[locs.size()];\n     for (int i \u003d 0; i \u003c locs.size(); i++) {\n       targets[i] \u003d convert(locs.get(i));\n     }\n \n     final StorageType[] storageTypes \u003d convertStorageTypes(\n         proto.getStorageTypesList(), locs.size());\n \n     final int storageIDsCount \u003d proto.getStorageIDsCount();\n     final String[] storageIDs;\n     if (storageIDsCount \u003d\u003d 0) {\n       storageIDs \u003d null;\n     } else {\n       Preconditions.checkState(storageIDsCount \u003d\u003d locs.size());\n       storageIDs \u003d proto.getStorageIDsList()\n           .toArray(new String[storageIDsCount]);\n     }\n \n     byte[] indices \u003d null;\n     if (proto.hasBlockIndices()) {\n       indices \u003d proto.getBlockIndices().toByteArray();\n     }\n \n     // Set values from the isCached list, re-using references from loc\n     List\u003cDatanodeInfo\u003e cachedLocs \u003d new ArrayList\u003c\u003e(locs.size());\n     List\u003cBoolean\u003e isCachedList \u003d proto.getIsCachedList();\n     for (int i\u003d0; i\u003cisCachedList.size(); i++) {\n       if (isCachedList.get(i)) {\n         cachedLocs.add(targets[i]);\n       }\n     }\n \n     final LocatedBlock lb;\n     if (indices \u003d\u003d null) {\n       lb \u003d new LocatedBlock(PBHelperClient.convert(proto.getB()), targets,\n           storageIDs, storageTypes, proto.getOffset(), proto.getCorrupt(),\n           cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n     } else {\n       lb \u003d new LocatedStripedBlock(PBHelperClient.convert(proto.getB()),\n           targets, storageIDs, storageTypes, indices, proto.getOffset(),\n           proto.getCorrupt(),\n           cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n       List\u003cTokenProto\u003e tokenProtos \u003d proto.getBlockTokensList();\n-      Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d\n-          convertTokens(tokenProtos);\n+      Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d new Token[indices.length];\n+      for (int i \u003d 0; i \u003c indices.length; i++) {\n+        blockTokens[i] \u003d convert(tokenProtos.get(i));\n+      }\n       ((LocatedStripedBlock) lb).setBlockTokens(blockTokens);\n     }\n     lb.setBlockToken(convert(proto.getBlockToken()));\n \n     return lb;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static LocatedBlock convertLocatedBlockProto(LocatedBlockProto proto) {\n    if (proto \u003d\u003d null) return null;\n    List\u003cDatanodeInfoProto\u003e locs \u003d proto.getLocsList();\n    DatanodeInfo[] targets \u003d new DatanodeInfo[locs.size()];\n    for (int i \u003d 0; i \u003c locs.size(); i++) {\n      targets[i] \u003d convert(locs.get(i));\n    }\n\n    final StorageType[] storageTypes \u003d convertStorageTypes(\n        proto.getStorageTypesList(), locs.size());\n\n    final int storageIDsCount \u003d proto.getStorageIDsCount();\n    final String[] storageIDs;\n    if (storageIDsCount \u003d\u003d 0) {\n      storageIDs \u003d null;\n    } else {\n      Preconditions.checkState(storageIDsCount \u003d\u003d locs.size());\n      storageIDs \u003d proto.getStorageIDsList()\n          .toArray(new String[storageIDsCount]);\n    }\n\n    byte[] indices \u003d null;\n    if (proto.hasBlockIndices()) {\n      indices \u003d proto.getBlockIndices().toByteArray();\n    }\n\n    // Set values from the isCached list, re-using references from loc\n    List\u003cDatanodeInfo\u003e cachedLocs \u003d new ArrayList\u003c\u003e(locs.size());\n    List\u003cBoolean\u003e isCachedList \u003d proto.getIsCachedList();\n    for (int i\u003d0; i\u003cisCachedList.size(); i++) {\n      if (isCachedList.get(i)) {\n        cachedLocs.add(targets[i]);\n      }\n    }\n\n    final LocatedBlock lb;\n    if (indices \u003d\u003d null) {\n      lb \u003d new LocatedBlock(PBHelperClient.convert(proto.getB()), targets,\n          storageIDs, storageTypes, proto.getOffset(), proto.getCorrupt(),\n          cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n    } else {\n      lb \u003d new LocatedStripedBlock(PBHelperClient.convert(proto.getB()),\n          targets, storageIDs, storageTypes, indices, proto.getOffset(),\n          proto.getCorrupt(),\n          cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n      List\u003cTokenProto\u003e tokenProtos \u003d proto.getBlockTokensList();\n      Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d new Token[indices.length];\n      for (int i \u003d 0; i \u003c indices.length; i++) {\n        blockTokens[i] \u003d convert(tokenProtos.get(i));\n      }\n      ((LocatedStripedBlock) lb).setBlockTokens(blockTokens);\n    }\n    lb.setBlockToken(convert(proto.getBlockToken()));\n\n    return lb;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "e5ff0ea7ba087984262f1f27200ae5bb40d9b838": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\n",
      "commitDate": "26/03/16 12:52 AM",
      "commitName": "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "08/03/16 10:30 PM",
      "commitNameOld": "7600e3c48ff2043654dbe9f415a186a336b5ea6c",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 17.06,
      "commitsBetweenForRepo": 81,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,56 +1,54 @@\n   public static LocatedBlock convertLocatedBlockProto(LocatedBlockProto proto) {\n     if (proto \u003d\u003d null) return null;\n     List\u003cDatanodeInfoProto\u003e locs \u003d proto.getLocsList();\n     DatanodeInfo[] targets \u003d new DatanodeInfo[locs.size()];\n     for (int i \u003d 0; i \u003c locs.size(); i++) {\n       targets[i] \u003d convert(locs.get(i));\n     }\n \n     final StorageType[] storageTypes \u003d convertStorageTypes(\n         proto.getStorageTypesList(), locs.size());\n \n     final int storageIDsCount \u003d proto.getStorageIDsCount();\n     final String[] storageIDs;\n     if (storageIDsCount \u003d\u003d 0) {\n       storageIDs \u003d null;\n     } else {\n       Preconditions.checkState(storageIDsCount \u003d\u003d locs.size());\n       storageIDs \u003d proto.getStorageIDsList()\n           .toArray(new String[storageIDsCount]);\n     }\n \n     byte[] indices \u003d null;\n     if (proto.hasBlockIndices()) {\n       indices \u003d proto.getBlockIndices().toByteArray();\n     }\n \n     // Set values from the isCached list, re-using references from loc\n     List\u003cDatanodeInfo\u003e cachedLocs \u003d new ArrayList\u003c\u003e(locs.size());\n     List\u003cBoolean\u003e isCachedList \u003d proto.getIsCachedList();\n     for (int i\u003d0; i\u003cisCachedList.size(); i++) {\n       if (isCachedList.get(i)) {\n         cachedLocs.add(targets[i]);\n       }\n     }\n \n     final LocatedBlock lb;\n     if (indices \u003d\u003d null) {\n       lb \u003d new LocatedBlock(PBHelperClient.convert(proto.getB()), targets,\n           storageIDs, storageTypes, proto.getOffset(), proto.getCorrupt(),\n           cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n     } else {\n       lb \u003d new LocatedStripedBlock(PBHelperClient.convert(proto.getB()),\n           targets, storageIDs, storageTypes, indices, proto.getOffset(),\n           proto.getCorrupt(),\n           cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n       List\u003cTokenProto\u003e tokenProtos \u003d proto.getBlockTokensList();\n-      Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d new Token[indices.length];\n-      for (int i \u003d 0; i \u003c indices.length; i++) {\n-        blockTokens[i] \u003d convert(tokenProtos.get(i));\n-      }\n+      Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d\n+          convertTokens(tokenProtos);\n       ((LocatedStripedBlock) lb).setBlockTokens(blockTokens);\n     }\n     lb.setBlockToken(convert(proto.getBlockToken()));\n \n     return lb;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static LocatedBlock convertLocatedBlockProto(LocatedBlockProto proto) {\n    if (proto \u003d\u003d null) return null;\n    List\u003cDatanodeInfoProto\u003e locs \u003d proto.getLocsList();\n    DatanodeInfo[] targets \u003d new DatanodeInfo[locs.size()];\n    for (int i \u003d 0; i \u003c locs.size(); i++) {\n      targets[i] \u003d convert(locs.get(i));\n    }\n\n    final StorageType[] storageTypes \u003d convertStorageTypes(\n        proto.getStorageTypesList(), locs.size());\n\n    final int storageIDsCount \u003d proto.getStorageIDsCount();\n    final String[] storageIDs;\n    if (storageIDsCount \u003d\u003d 0) {\n      storageIDs \u003d null;\n    } else {\n      Preconditions.checkState(storageIDsCount \u003d\u003d locs.size());\n      storageIDs \u003d proto.getStorageIDsList()\n          .toArray(new String[storageIDsCount]);\n    }\n\n    byte[] indices \u003d null;\n    if (proto.hasBlockIndices()) {\n      indices \u003d proto.getBlockIndices().toByteArray();\n    }\n\n    // Set values from the isCached list, re-using references from loc\n    List\u003cDatanodeInfo\u003e cachedLocs \u003d new ArrayList\u003c\u003e(locs.size());\n    List\u003cBoolean\u003e isCachedList \u003d proto.getIsCachedList();\n    for (int i\u003d0; i\u003cisCachedList.size(); i++) {\n      if (isCachedList.get(i)) {\n        cachedLocs.add(targets[i]);\n      }\n    }\n\n    final LocatedBlock lb;\n    if (indices \u003d\u003d null) {\n      lb \u003d new LocatedBlock(PBHelperClient.convert(proto.getB()), targets,\n          storageIDs, storageTypes, proto.getOffset(), proto.getCorrupt(),\n          cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n    } else {\n      lb \u003d new LocatedStripedBlock(PBHelperClient.convert(proto.getB()),\n          targets, storageIDs, storageTypes, indices, proto.getOffset(),\n          proto.getCorrupt(),\n          cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n      List\u003cTokenProto\u003e tokenProtos \u003d proto.getBlockTokensList();\n      Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d\n          convertTokens(tokenProtos);\n      ((LocatedStripedBlock) lb).setBlockTokens(blockTokens);\n    }\n    lb.setBlockToken(convert(proto.getBlockToken()));\n\n    return lb;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "70d6f201260086a3f12beaa317fede2a99639fef": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9575. Use byte array for internal block indices in a striped block.  Contributed by jing9\n",
      "commitDate": "21/12/15 10:47 PM",
      "commitName": "70d6f201260086a3f12beaa317fede2a99639fef",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "16/12/15 11:10 AM",
      "commitNameOld": "c470c8953d4927043b6383fad8e792289c634c09",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 5.48,
      "commitsBetweenForRepo": 48,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,60 +1,56 @@\n   public static LocatedBlock convertLocatedBlockProto(LocatedBlockProto proto) {\n     if (proto \u003d\u003d null) return null;\n     List\u003cDatanodeInfoProto\u003e locs \u003d proto.getLocsList();\n     DatanodeInfo[] targets \u003d new DatanodeInfo[locs.size()];\n     for (int i \u003d 0; i \u003c locs.size(); i++) {\n       targets[i] \u003d convert(locs.get(i));\n     }\n \n     final StorageType[] storageTypes \u003d convertStorageTypes(\n         proto.getStorageTypesList(), locs.size());\n \n     final int storageIDsCount \u003d proto.getStorageIDsCount();\n     final String[] storageIDs;\n     if (storageIDsCount \u003d\u003d 0) {\n       storageIDs \u003d null;\n     } else {\n       Preconditions.checkState(storageIDsCount \u003d\u003d locs.size());\n       storageIDs \u003d proto.getStorageIDsList()\n           .toArray(new String[storageIDsCount]);\n     }\n \n-    int[] indices \u003d null;\n-    final int indexCount \u003d proto.getBlockIndexCount();\n-    if (indexCount \u003e 0) {\n-      indices \u003d new int[indexCount];\n-      for (int i \u003d 0; i \u003c indexCount; i++) {\n-        indices[i] \u003d proto.getBlockIndex(i);\n-      }\n+    byte[] indices \u003d null;\n+    if (proto.hasBlockIndices()) {\n+      indices \u003d proto.getBlockIndices().toByteArray();\n     }\n \n     // Set values from the isCached list, re-using references from loc\n     List\u003cDatanodeInfo\u003e cachedLocs \u003d new ArrayList\u003c\u003e(locs.size());\n     List\u003cBoolean\u003e isCachedList \u003d proto.getIsCachedList();\n     for (int i\u003d0; i\u003cisCachedList.size(); i++) {\n       if (isCachedList.get(i)) {\n         cachedLocs.add(targets[i]);\n       }\n     }\n \n     final LocatedBlock lb;\n     if (indices \u003d\u003d null) {\n       lb \u003d new LocatedBlock(PBHelperClient.convert(proto.getB()), targets,\n           storageIDs, storageTypes, proto.getOffset(), proto.getCorrupt(),\n           cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n     } else {\n       lb \u003d new LocatedStripedBlock(PBHelperClient.convert(proto.getB()),\n           targets, storageIDs, storageTypes, indices, proto.getOffset(),\n           proto.getCorrupt(),\n           cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n       List\u003cTokenProto\u003e tokenProtos \u003d proto.getBlockTokensList();\n       Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d new Token[indices.length];\n       for (int i \u003d 0; i \u003c indices.length; i++) {\n         blockTokens[i] \u003d convert(tokenProtos.get(i));\n       }\n       ((LocatedStripedBlock) lb).setBlockTokens(blockTokens);\n     }\n     lb.setBlockToken(convert(proto.getBlockToken()));\n \n     return lb;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static LocatedBlock convertLocatedBlockProto(LocatedBlockProto proto) {\n    if (proto \u003d\u003d null) return null;\n    List\u003cDatanodeInfoProto\u003e locs \u003d proto.getLocsList();\n    DatanodeInfo[] targets \u003d new DatanodeInfo[locs.size()];\n    for (int i \u003d 0; i \u003c locs.size(); i++) {\n      targets[i] \u003d convert(locs.get(i));\n    }\n\n    final StorageType[] storageTypes \u003d convertStorageTypes(\n        proto.getStorageTypesList(), locs.size());\n\n    final int storageIDsCount \u003d proto.getStorageIDsCount();\n    final String[] storageIDs;\n    if (storageIDsCount \u003d\u003d 0) {\n      storageIDs \u003d null;\n    } else {\n      Preconditions.checkState(storageIDsCount \u003d\u003d locs.size());\n      storageIDs \u003d proto.getStorageIDsList()\n          .toArray(new String[storageIDsCount]);\n    }\n\n    byte[] indices \u003d null;\n    if (proto.hasBlockIndices()) {\n      indices \u003d proto.getBlockIndices().toByteArray();\n    }\n\n    // Set values from the isCached list, re-using references from loc\n    List\u003cDatanodeInfo\u003e cachedLocs \u003d new ArrayList\u003c\u003e(locs.size());\n    List\u003cBoolean\u003e isCachedList \u003d proto.getIsCachedList();\n    for (int i\u003d0; i\u003cisCachedList.size(); i++) {\n      if (isCachedList.get(i)) {\n        cachedLocs.add(targets[i]);\n      }\n    }\n\n    final LocatedBlock lb;\n    if (indices \u003d\u003d null) {\n      lb \u003d new LocatedBlock(PBHelperClient.convert(proto.getB()), targets,\n          storageIDs, storageTypes, proto.getOffset(), proto.getCorrupt(),\n          cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n    } else {\n      lb \u003d new LocatedStripedBlock(PBHelperClient.convert(proto.getB()),\n          targets, storageIDs, storageTypes, indices, proto.getOffset(),\n          proto.getCorrupt(),\n          cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n      List\u003cTokenProto\u003e tokenProtos \u003d proto.getBlockTokensList();\n      Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d new Token[indices.length];\n      for (int i \u003d 0; i \u003c indices.length; i++) {\n        blockTokens[i] \u003d convert(tokenProtos.get(i));\n      }\n      ((LocatedStripedBlock) lb).setBlockTokens(blockTokens);\n    }\n    lb.setBlockToken(convert(proto.getBlockToken()));\n\n    return lb;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8979. Clean up checkstyle warnings in hadoop-hdfs-client module. Contributed by Mingliang Liu.\n",
      "commitDate": "03/10/15 11:38 AM",
      "commitName": "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "22/09/15 1:27 PM",
      "commitNameOld": "1080c3730068177ddd10dc313890ac1f5dc58f1a",
      "commitAuthorOld": "",
      "daysBetweenCommits": 10.92,
      "commitsBetweenForRepo": 91,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,59 +1,60 @@\n   public static LocatedBlock convertLocatedBlockProto(LocatedBlockProto proto) {\n     if (proto \u003d\u003d null) return null;\n     List\u003cDatanodeInfoProto\u003e locs \u003d proto.getLocsList();\n     DatanodeInfo[] targets \u003d new DatanodeInfo[locs.size()];\n     for (int i \u003d 0; i \u003c locs.size(); i++) {\n       targets[i] \u003d convert(locs.get(i));\n     }\n \n     final StorageType[] storageTypes \u003d convertStorageTypes(\n         proto.getStorageTypesList(), locs.size());\n \n     final int storageIDsCount \u003d proto.getStorageIDsCount();\n     final String[] storageIDs;\n     if (storageIDsCount \u003d\u003d 0) {\n       storageIDs \u003d null;\n     } else {\n       Preconditions.checkState(storageIDsCount \u003d\u003d locs.size());\n-      storageIDs \u003d proto.getStorageIDsList().toArray(new String[storageIDsCount]);\n+      storageIDs \u003d proto.getStorageIDsList()\n+          .toArray(new String[storageIDsCount]);\n     }\n \n     int[] indices \u003d null;\n     final int indexCount \u003d proto.getBlockIndexCount();\n     if (indexCount \u003e 0) {\n       indices \u003d new int[indexCount];\n       for (int i \u003d 0; i \u003c indexCount; i++) {\n         indices[i] \u003d proto.getBlockIndex(i);\n       }\n     }\n \n     // Set values from the isCached list, re-using references from loc\n-    List\u003cDatanodeInfo\u003e cachedLocs \u003d new ArrayList\u003cDatanodeInfo\u003e(locs.size());\n+    List\u003cDatanodeInfo\u003e cachedLocs \u003d new ArrayList\u003c\u003e(locs.size());\n     List\u003cBoolean\u003e isCachedList \u003d proto.getIsCachedList();\n     for (int i\u003d0; i\u003cisCachedList.size(); i++) {\n       if (isCachedList.get(i)) {\n         cachedLocs.add(targets[i]);\n       }\n     }\n \n     final LocatedBlock lb;\n     if (indices \u003d\u003d null) {\n       lb \u003d new LocatedBlock(PBHelperClient.convert(proto.getB()), targets,\n           storageIDs, storageTypes, proto.getOffset(), proto.getCorrupt(),\n           cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n     } else {\n-      lb \u003d new LocatedStripedBlock(PBHelperClient.convert(proto.getB()), targets,\n-          storageIDs, storageTypes, indices, proto.getOffset(),\n+      lb \u003d new LocatedStripedBlock(PBHelperClient.convert(proto.getB()),\n+          targets, storageIDs, storageTypes, indices, proto.getOffset(),\n           proto.getCorrupt(),\n           cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n       List\u003cTokenProto\u003e tokenProtos \u003d proto.getBlockTokensList();\n       Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d new Token[indices.length];\n       for (int i \u003d 0; i \u003c indices.length; i++) {\n         blockTokens[i] \u003d convert(tokenProtos.get(i));\n       }\n       ((LocatedStripedBlock) lb).setBlockTokens(blockTokens);\n     }\n     lb.setBlockToken(convert(proto.getBlockToken()));\n \n     return lb;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static LocatedBlock convertLocatedBlockProto(LocatedBlockProto proto) {\n    if (proto \u003d\u003d null) return null;\n    List\u003cDatanodeInfoProto\u003e locs \u003d proto.getLocsList();\n    DatanodeInfo[] targets \u003d new DatanodeInfo[locs.size()];\n    for (int i \u003d 0; i \u003c locs.size(); i++) {\n      targets[i] \u003d convert(locs.get(i));\n    }\n\n    final StorageType[] storageTypes \u003d convertStorageTypes(\n        proto.getStorageTypesList(), locs.size());\n\n    final int storageIDsCount \u003d proto.getStorageIDsCount();\n    final String[] storageIDs;\n    if (storageIDsCount \u003d\u003d 0) {\n      storageIDs \u003d null;\n    } else {\n      Preconditions.checkState(storageIDsCount \u003d\u003d locs.size());\n      storageIDs \u003d proto.getStorageIDsList()\n          .toArray(new String[storageIDsCount]);\n    }\n\n    int[] indices \u003d null;\n    final int indexCount \u003d proto.getBlockIndexCount();\n    if (indexCount \u003e 0) {\n      indices \u003d new int[indexCount];\n      for (int i \u003d 0; i \u003c indexCount; i++) {\n        indices[i] \u003d proto.getBlockIndex(i);\n      }\n    }\n\n    // Set values from the isCached list, re-using references from loc\n    List\u003cDatanodeInfo\u003e cachedLocs \u003d new ArrayList\u003c\u003e(locs.size());\n    List\u003cBoolean\u003e isCachedList \u003d proto.getIsCachedList();\n    for (int i\u003d0; i\u003cisCachedList.size(); i++) {\n      if (isCachedList.get(i)) {\n        cachedLocs.add(targets[i]);\n      }\n    }\n\n    final LocatedBlock lb;\n    if (indices \u003d\u003d null) {\n      lb \u003d new LocatedBlock(PBHelperClient.convert(proto.getB()), targets,\n          storageIDs, storageTypes, proto.getOffset(), proto.getCorrupt(),\n          cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n    } else {\n      lb \u003d new LocatedStripedBlock(PBHelperClient.convert(proto.getB()),\n          targets, storageIDs, storageTypes, indices, proto.getOffset(),\n          proto.getCorrupt(),\n          cachedLocs.toArray(new DatanodeInfo[cachedLocs.size()]));\n      List\u003cTokenProto\u003e tokenProtos \u003d proto.getBlockTokensList();\n      Token\u003cBlockTokenIdentifier\u003e[] blockTokens \u003d new Token[indices.length];\n      for (int i \u003d 0; i \u003c indices.length; i++) {\n        blockTokens[i] \u003d convert(tokenProtos.get(i));\n      }\n      ((LocatedStripedBlock) lb).setBlockTokens(blockTokens);\n    }\n    lb.setBlockToken(convert(proto.getBlockToken()));\n\n    return lb;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    }
  }
}