{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CommitterEventHandler.java",
  "functionName": "serviceStart",
  "functionId": "serviceStart",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/commit/CommitterEventHandler.java",
  "functionStartLine": 119,
  "functionEndLine": 160,
  "numCommitsSeen": 21,
  "timeTaken": 8187,
  "changeHistory": [
    "2440671a117f165dcda5056404bc898df3c50803",
    "9e62bcca4e2ee4aaa3844d1d975dc0adc93ab602",
    "0928502029ef141759008997335ea2cd836a7154",
    "402eb1851341fce72c8e46266a2578bb67b5b684",
    "1e45b1f1fd38543b0b1233f57fdee1ac4a365332",
    "1650a49993fb4c5400bb893cacae39c5cc29844b",
    "68328ae92632afc9cdd6e75b7a8d832723ddbe3b",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "2440671a117f165dcda5056404bc898df3c50803": "Ybodychange",
    "9e62bcca4e2ee4aaa3844d1d975dc0adc93ab602": "Ybodychange",
    "0928502029ef141759008997335ea2cd836a7154": "Ymultichange(Yrename,Ymodifierchange,Yexceptionschange,Ybodychange)",
    "402eb1851341fce72c8e46266a2578bb67b5b684": "Ymultichange(Ymovefromfile,Ybodychange)",
    "1e45b1f1fd38543b0b1233f57fdee1ac4a365332": "Ybodychange",
    "1650a49993fb4c5400bb893cacae39c5cc29844b": "Ybodychange",
    "68328ae92632afc9cdd6e75b7a8d832723ddbe3b": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2440671a117f165dcda5056404bc898df3c50803": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6634. Log uncaught exceptions/errors in various thread pools in mapreduce. Contributed by Sidharta Seethana.\n",
      "commitDate": "18/02/16 12:48 AM",
      "commitName": "2440671a117f165dcda5056404bc898df3c50803",
      "commitAuthor": "Varun Vasudev",
      "commitDateOld": "16/11/15 5:06 PM",
      "commitNameOld": "6502d59e73cd6f3f3a358fce58d398ca38a61fba",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 93.32,
      "commitsBetweenForRepo": 603,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,42 +1,42 @@\n   protected void serviceStart() throws Exception {\n     ThreadFactoryBuilder tfBuilder \u003d new ThreadFactoryBuilder()\n         .setNameFormat(\"CommitterEvent Processor #%d\");\n     if (jobClassLoader !\u003d null) {\n       // if the job classloader is enabled, we need to use the job classloader\n       // as the thread context classloader (TCCL) of these threads in case the\n       // committer needs to load another class via TCCL\n       ThreadFactory backingTf \u003d new ThreadFactory() {\n         @Override\n         public Thread newThread(Runnable r) {\n           Thread thread \u003d new Thread(r);\n           thread.setContextClassLoader(jobClassLoader);\n           return thread;\n         }\n       };\n       tfBuilder.setThreadFactory(backingTf);\n     }\n     ThreadFactory tf \u003d tfBuilder.build();\n-    launcherPool \u003d new ThreadPoolExecutor(5, 5, 1,\n+    launcherPool \u003d new HadoopThreadPoolExecutor(5, 5, 1,\n         TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n         CommitterEvent event \u003d null;\n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, interrupted : \" + e);\n             }\n             return;\n           }\n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(new EventProcessor(event));        }\n       }\n     });\n     eventHandlingThread.setName(\"CommitterEvent Handler\");\n     eventHandlingThread.start();\n     super.serviceStart();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStart() throws Exception {\n    ThreadFactoryBuilder tfBuilder \u003d new ThreadFactoryBuilder()\n        .setNameFormat(\"CommitterEvent Processor #%d\");\n    if (jobClassLoader !\u003d null) {\n      // if the job classloader is enabled, we need to use the job classloader\n      // as the thread context classloader (TCCL) of these threads in case the\n      // committer needs to load another class via TCCL\n      ThreadFactory backingTf \u003d new ThreadFactory() {\n        @Override\n        public Thread newThread(Runnable r) {\n          Thread thread \u003d new Thread(r);\n          thread.setContextClassLoader(jobClassLoader);\n          return thread;\n        }\n      };\n      tfBuilder.setThreadFactory(backingTf);\n    }\n    ThreadFactory tf \u003d tfBuilder.build();\n    launcherPool \u003d new HadoopThreadPoolExecutor(5, 5, 1,\n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        CommitterEvent event \u003d null;\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, interrupted : \" + e);\n            }\n            return;\n          }\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));        }\n      }\n    });\n    eventHandlingThread.setName(\"CommitterEvent Handler\");\n    eventHandlingThread.start();\n    super.serviceStart();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/commit/CommitterEventHandler.java",
      "extendedDetails": {}
    },
    "9e62bcca4e2ee4aaa3844d1d975dc0adc93ab602": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5957. AM throws ClassNotFoundException with job classloader enabled if custom output format/committer is used. Contributed by Sangjin Lee\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1612358 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/07/14 10:54 AM",
      "commitName": "9e62bcca4e2ee4aaa3844d1d975dc0adc93ab602",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "16/06/13 11:39 PM",
      "commitNameOld": "b9efe6bd4a1277b4067ecde715a7713a85968886",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 399.47,
      "commitsBetweenForRepo": 2618,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,42 @@\n   protected void serviceStart() throws Exception {\n-    ThreadFactory tf \u003d new ThreadFactoryBuilder()\n-      .setNameFormat(\"CommitterEvent Processor #%d\")\n-      .build();\n+    ThreadFactoryBuilder tfBuilder \u003d new ThreadFactoryBuilder()\n+        .setNameFormat(\"CommitterEvent Processor #%d\");\n+    if (jobClassLoader !\u003d null) {\n+      // if the job classloader is enabled, we need to use the job classloader\n+      // as the thread context classloader (TCCL) of these threads in case the\n+      // committer needs to load another class via TCCL\n+      ThreadFactory backingTf \u003d new ThreadFactory() {\n+        @Override\n+        public Thread newThread(Runnable r) {\n+          Thread thread \u003d new Thread(r);\n+          thread.setContextClassLoader(jobClassLoader);\n+          return thread;\n+        }\n+      };\n+      tfBuilder.setThreadFactory(backingTf);\n+    }\n+    ThreadFactory tf \u003d tfBuilder.build();\n     launcherPool \u003d new ThreadPoolExecutor(5, 5, 1,\n         TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n         CommitterEvent event \u003d null;\n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, interrupted : \" + e);\n             }\n             return;\n           }\n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(new EventProcessor(event));        }\n       }\n     });\n     eventHandlingThread.setName(\"CommitterEvent Handler\");\n     eventHandlingThread.start();\n     super.serviceStart();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStart() throws Exception {\n    ThreadFactoryBuilder tfBuilder \u003d new ThreadFactoryBuilder()\n        .setNameFormat(\"CommitterEvent Processor #%d\");\n    if (jobClassLoader !\u003d null) {\n      // if the job classloader is enabled, we need to use the job classloader\n      // as the thread context classloader (TCCL) of these threads in case the\n      // committer needs to load another class via TCCL\n      ThreadFactory backingTf \u003d new ThreadFactory() {\n        @Override\n        public Thread newThread(Runnable r) {\n          Thread thread \u003d new Thread(r);\n          thread.setContextClassLoader(jobClassLoader);\n          return thread;\n        }\n      };\n      tfBuilder.setThreadFactory(backingTf);\n    }\n    ThreadFactory tf \u003d tfBuilder.build();\n    launcherPool \u003d new ThreadPoolExecutor(5, 5, 1,\n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        CommitterEvent event \u003d null;\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, interrupted : \" + e);\n            }\n            return;\n          }\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));        }\n      }\n    });\n    eventHandlingThread.setName(\"CommitterEvent Handler\");\n    eventHandlingThread.start();\n    super.serviceStart();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/commit/CommitterEventHandler.java",
      "extendedDetails": {}
    },
    "0928502029ef141759008997335ea2cd836a7154": {
      "type": "Ymultichange(Yrename,Ymodifierchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/06/13 8:54 AM",
      "commitName": "0928502029ef141759008997335ea2cd836a7154",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,28 @@\n-  public void start() {    \n+  protected void serviceStart() throws Exception {\n     ThreadFactory tf \u003d new ThreadFactoryBuilder()\n       .setNameFormat(\"CommitterEvent Processor #%d\")\n       .build();\n     launcherPool \u003d new ThreadPoolExecutor(5, 5, 1,\n         TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n         CommitterEvent event \u003d null;\n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, interrupted : \" + e);\n             }\n             return;\n           }\n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(new EventProcessor(event));        }\n       }\n     });\n     eventHandlingThread.setName(\"CommitterEvent Handler\");\n     eventHandlingThread.start();\n-    super.start();\n+    super.serviceStart();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceStart() throws Exception {\n    ThreadFactory tf \u003d new ThreadFactoryBuilder()\n      .setNameFormat(\"CommitterEvent Processor #%d\")\n      .build();\n    launcherPool \u003d new ThreadPoolExecutor(5, 5, 1,\n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        CommitterEvent event \u003d null;\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, interrupted : \" + e);\n            }\n            return;\n          }\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));        }\n      }\n    });\n    eventHandlingThread.setName(\"CommitterEvent Handler\");\n    eventHandlingThread.start();\n    super.serviceStart();\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/commit/CommitterEventHandler.java",
          "extendedDetails": {
            "oldValue": "start",
            "newValue": "serviceStart"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,28 @@\n-  public void start() {    \n+  protected void serviceStart() throws Exception {\n     ThreadFactory tf \u003d new ThreadFactoryBuilder()\n       .setNameFormat(\"CommitterEvent Processor #%d\")\n       .build();\n     launcherPool \u003d new ThreadPoolExecutor(5, 5, 1,\n         TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n         CommitterEvent event \u003d null;\n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, interrupted : \" + e);\n             }\n             return;\n           }\n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(new EventProcessor(event));        }\n       }\n     });\n     eventHandlingThread.setName(\"CommitterEvent Handler\");\n     eventHandlingThread.start();\n-    super.start();\n+    super.serviceStart();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceStart() throws Exception {\n    ThreadFactory tf \u003d new ThreadFactoryBuilder()\n      .setNameFormat(\"CommitterEvent Processor #%d\")\n      .build();\n    launcherPool \u003d new ThreadPoolExecutor(5, 5, 1,\n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        CommitterEvent event \u003d null;\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, interrupted : \" + e);\n            }\n            return;\n          }\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));        }\n      }\n    });\n    eventHandlingThread.setName(\"CommitterEvent Handler\");\n    eventHandlingThread.start();\n    super.serviceStart();\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/commit/CommitterEventHandler.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[protected]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,28 @@\n-  public void start() {    \n+  protected void serviceStart() throws Exception {\n     ThreadFactory tf \u003d new ThreadFactoryBuilder()\n       .setNameFormat(\"CommitterEvent Processor #%d\")\n       .build();\n     launcherPool \u003d new ThreadPoolExecutor(5, 5, 1,\n         TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n         CommitterEvent event \u003d null;\n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, interrupted : \" + e);\n             }\n             return;\n           }\n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(new EventProcessor(event));        }\n       }\n     });\n     eventHandlingThread.setName(\"CommitterEvent Handler\");\n     eventHandlingThread.start();\n-    super.start();\n+    super.serviceStart();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceStart() throws Exception {\n    ThreadFactory tf \u003d new ThreadFactoryBuilder()\n      .setNameFormat(\"CommitterEvent Processor #%d\")\n      .build();\n    launcherPool \u003d new ThreadPoolExecutor(5, 5, 1,\n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        CommitterEvent event \u003d null;\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, interrupted : \" + e);\n            }\n            return;\n          }\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));        }\n      }\n    });\n    eventHandlingThread.setName(\"CommitterEvent Handler\");\n    eventHandlingThread.start();\n    super.serviceStart();\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/commit/CommitterEventHandler.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[Exception]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,28 @@\n-  public void start() {    \n+  protected void serviceStart() throws Exception {\n     ThreadFactory tf \u003d new ThreadFactoryBuilder()\n       .setNameFormat(\"CommitterEvent Processor #%d\")\n       .build();\n     launcherPool \u003d new ThreadPoolExecutor(5, 5, 1,\n         TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n         CommitterEvent event \u003d null;\n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, interrupted : \" + e);\n             }\n             return;\n           }\n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(new EventProcessor(event));        }\n       }\n     });\n     eventHandlingThread.setName(\"CommitterEvent Handler\");\n     eventHandlingThread.start();\n-    super.start();\n+    super.serviceStart();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceStart() throws Exception {\n    ThreadFactory tf \u003d new ThreadFactoryBuilder()\n      .setNameFormat(\"CommitterEvent Processor #%d\")\n      .build();\n    launcherPool \u003d new ThreadPoolExecutor(5, 5, 1,\n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        CommitterEvent event \u003d null;\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, interrupted : \" + e);\n            }\n            return;\n          }\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));        }\n      }\n    });\n    eventHandlingThread.setName(\"CommitterEvent Handler\");\n    eventHandlingThread.start();\n    super.serviceStart();\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/commit/CommitterEventHandler.java",
          "extendedDetails": {}
        }
      ]
    },
    "402eb1851341fce72c8e46266a2578bb67b5b684": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "MAPREDUCE-4813. AM timing out during job commit (jlowe via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1426536 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/12/12 7:01 AM",
      "commitName": "402eb1851341fce72c8e46266a2578bb67b5b684",
      "commitAuthor": "Robert Joseph Evans",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "MAPREDUCE-4813. AM timing out during job commit (jlowe via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1426536 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "28/12/12 7:01 AM",
          "commitName": "402eb1851341fce72c8e46266a2578bb67b5b684",
          "commitAuthor": "Robert Joseph Evans",
          "commitDateOld": "28/12/12 6:21 AM",
          "commitNameOld": "4b9f0443cb0e35747e0c4ec5f416175b42164a60",
          "commitAuthorOld": "Robert Joseph Evans",
          "daysBetweenCommits": 0.03,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,28 @@\n   public void start() {\n     ThreadFactory tf \u003d new ThreadFactoryBuilder()\n-      .setNameFormat(\"TaskCleaner #%d\")\n+      .setNameFormat(\"CommitterEvent Processor #%d\")\n       .build();\n-    launcherPool \u003d new ThreadPoolExecutor(5, 5, 1, \n+    launcherPool \u003d new ThreadPoolExecutor(5, 5, 1,\n         TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n-        TaskCleanupEvent event \u003d null;\n+        CommitterEvent event \u003d null;\n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, interrupted : \" + e);\n             }\n             return;\n           }\n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(new EventProcessor(event));        }\n       }\n     });\n-    eventHandlingThread.setName(\"TaskCleaner Event Handler\");\n+    eventHandlingThread.setName(\"CommitterEvent Handler\");\n     eventHandlingThread.start();\n     super.start();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void start() {\n    ThreadFactory tf \u003d new ThreadFactoryBuilder()\n      .setNameFormat(\"CommitterEvent Processor #%d\")\n      .build();\n    launcherPool \u003d new ThreadPoolExecutor(5, 5, 1,\n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        CommitterEvent event \u003d null;\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, interrupted : \" + e);\n            }\n            return;\n          }\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));        }\n      }\n    });\n    eventHandlingThread.setName(\"CommitterEvent Handler\");\n    eventHandlingThread.start();\n    super.start();\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/commit/CommitterEventHandler.java",
          "extendedDetails": {
            "oldPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/taskclean/TaskCleanerImpl.java",
            "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/commit/CommitterEventHandler.java",
            "oldMethodName": "start",
            "newMethodName": "start"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-4813. AM timing out during job commit (jlowe via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1426536 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "28/12/12 7:01 AM",
          "commitName": "402eb1851341fce72c8e46266a2578bb67b5b684",
          "commitAuthor": "Robert Joseph Evans",
          "commitDateOld": "28/12/12 6:21 AM",
          "commitNameOld": "4b9f0443cb0e35747e0c4ec5f416175b42164a60",
          "commitAuthorOld": "Robert Joseph Evans",
          "daysBetweenCommits": 0.03,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,28 @@\n   public void start() {\n     ThreadFactory tf \u003d new ThreadFactoryBuilder()\n-      .setNameFormat(\"TaskCleaner #%d\")\n+      .setNameFormat(\"CommitterEvent Processor #%d\")\n       .build();\n-    launcherPool \u003d new ThreadPoolExecutor(5, 5, 1, \n+    launcherPool \u003d new ThreadPoolExecutor(5, 5, 1,\n         TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n-        TaskCleanupEvent event \u003d null;\n+        CommitterEvent event \u003d null;\n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, interrupted : \" + e);\n             }\n             return;\n           }\n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(new EventProcessor(event));        }\n       }\n     });\n-    eventHandlingThread.setName(\"TaskCleaner Event Handler\");\n+    eventHandlingThread.setName(\"CommitterEvent Handler\");\n     eventHandlingThread.start();\n     super.start();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void start() {\n    ThreadFactory tf \u003d new ThreadFactoryBuilder()\n      .setNameFormat(\"CommitterEvent Processor #%d\")\n      .build();\n    launcherPool \u003d new ThreadPoolExecutor(5, 5, 1,\n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        CommitterEvent event \u003d null;\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, interrupted : \" + e);\n            }\n            return;\n          }\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));        }\n      }\n    });\n    eventHandlingThread.setName(\"CommitterEvent Handler\");\n    eventHandlingThread.start();\n    super.start();\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/commit/CommitterEventHandler.java",
          "extendedDetails": {}
        }
      ]
    },
    "1e45b1f1fd38543b0b1233f57fdee1ac4a365332": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4741. WARN and ERROR messages logged during normal AM shutdown. Contributed by Vinod Kumar Vavilapalli\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1401738 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/10/12 8:45 AM",
      "commitName": "1e45b1f1fd38543b0b1233f57fdee1ac4a365332",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "26/03/12 2:23 PM",
      "commitNameOld": "1650a49993fb4c5400bb893cacae39c5cc29844b",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 211.77,
      "commitsBetweenForRepo": 1310,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,28 @@\n   public void start() {\n     ThreadFactory tf \u003d new ThreadFactoryBuilder()\n       .setNameFormat(\"TaskCleaner #%d\")\n       .build();\n     launcherPool \u003d new ThreadPoolExecutor(5, 5, 1, \n         TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n         TaskCleanupEvent event \u003d null;\n-        while (!Thread.currentThread().isInterrupted()) {\n+        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n-            LOG.error(\"Returning, interrupted : \" + e);\n+            if (!stopped.get()) {\n+              LOG.error(\"Returning, interrupted : \" + e);\n+            }\n             return;\n           }\n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(new EventProcessor(event));        }\n       }\n     });\n     eventHandlingThread.setName(\"TaskCleaner Event Handler\");\n     eventHandlingThread.start();\n     super.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n    ThreadFactory tf \u003d new ThreadFactoryBuilder()\n      .setNameFormat(\"TaskCleaner #%d\")\n      .build();\n    launcherPool \u003d new ThreadPoolExecutor(5, 5, 1, \n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        TaskCleanupEvent event \u003d null;\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, interrupted : \" + e);\n            }\n            return;\n          }\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));        }\n      }\n    });\n    eventHandlingThread.setName(\"TaskCleaner Event Handler\");\n    eventHandlingThread.start();\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/taskclean/TaskCleanerImpl.java",
      "extendedDetails": {}
    },
    "1650a49993fb4c5400bb893cacae39c5cc29844b": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4061. RM only has 1 AM launcher thread (tgraves via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1305607 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/03/12 2:23 PM",
      "commitName": "1650a49993fb4c5400bb893cacae39c5cc29844b",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "16/10/11 12:27 PM",
      "commitNameOld": "68328ae92632afc9cdd6e75b7a8d832723ddbe3b",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 162.08,
      "commitsBetweenForRepo": 1153,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,26 @@\n   public void start() {\n     ThreadFactory tf \u003d new ThreadFactoryBuilder()\n       .setNameFormat(\"TaskCleaner #%d\")\n       .build();\n-    launcherPool \u003d new ThreadPoolExecutor(1, 5, 1, \n+    launcherPool \u003d new ThreadPoolExecutor(5, 5, 1, \n         TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n         TaskCleanupEvent event \u003d null;\n         while (!Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             LOG.error(\"Returning, interrupted : \" + e);\n             return;\n           }\n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(new EventProcessor(event));        }\n       }\n     });\n     eventHandlingThread.setName(\"TaskCleaner Event Handler\");\n     eventHandlingThread.start();\n     super.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n    ThreadFactory tf \u003d new ThreadFactoryBuilder()\n      .setNameFormat(\"TaskCleaner #%d\")\n      .build();\n    launcherPool \u003d new ThreadPoolExecutor(5, 5, 1, \n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        TaskCleanupEvent event \u003d null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));        }\n      }\n    });\n    eventHandlingThread.setName(\"TaskCleaner Event Handler\");\n    eventHandlingThread.start();\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/taskclean/TaskCleanerImpl.java",
      "extendedDetails": {}
    },
    "68328ae92632afc9cdd6e75b7a8d832723ddbe3b": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3187. Add names for various unnamed threads in MR2. (Todd Lipcon and Siddharth Seth via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1184904 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/11 12:27 PM",
      "commitName": "68328ae92632afc9cdd6e75b7a8d832723ddbe3b",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 52.8,
      "commitsBetweenForRepo": 354,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,26 @@\n   public void start() {\n+    ThreadFactory tf \u003d new ThreadFactoryBuilder()\n+      .setNameFormat(\"TaskCleaner #%d\")\n+      .build();\n     launcherPool \u003d new ThreadPoolExecutor(1, 5, 1, \n-        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e());\n+        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n     eventHandlingThread \u003d new Thread(new Runnable() {\n       @Override\n       public void run() {\n         TaskCleanupEvent event \u003d null;\n         while (!Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             LOG.error(\"Returning, interrupted : \" + e);\n             return;\n           }\n           // the events from the queue are handled in parallel\n           // using a thread pool\n           launcherPool.execute(new EventProcessor(event));        }\n       }\n     });\n+    eventHandlingThread.setName(\"TaskCleaner Event Handler\");\n     eventHandlingThread.start();\n     super.start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n    ThreadFactory tf \u003d new ThreadFactoryBuilder()\n      .setNameFormat(\"TaskCleaner #%d\")\n      .build();\n    launcherPool \u003d new ThreadPoolExecutor(1, 5, 1, \n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        TaskCleanupEvent event \u003d null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));        }\n      }\n    });\n    eventHandlingThread.setName(\"TaskCleaner Event Handler\");\n    eventHandlingThread.start();\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/taskclean/TaskCleanerImpl.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void start() {\n    launcherPool \u003d new ThreadPoolExecutor(1, 5, 1, \n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e());\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        TaskCleanupEvent event \u003d null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));        }\n      }\n    });\n    eventHandlingThread.start();\n    super.start();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/taskclean/TaskCleanerImpl.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/taskclean/TaskCleanerImpl.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/taskclean/TaskCleanerImpl.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,22 @@\n+  public void start() {\n+    launcherPool \u003d new ThreadPoolExecutor(1, 5, 1, \n+        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e());\n+    eventHandlingThread \u003d new Thread(new Runnable() {\n+      @Override\n+      public void run() {\n+        TaskCleanupEvent event \u003d null;\n+        while (!Thread.currentThread().isInterrupted()) {\n+          try {\n+            event \u003d eventQueue.take();\n+          } catch (InterruptedException e) {\n+            LOG.error(\"Returning, interrupted : \" + e);\n+            return;\n+          }\n+          // the events from the queue are handled in parallel\n+          // using a thread pool\n+          launcherPool.execute(new EventProcessor(event));        }\n+      }\n+    });\n+    eventHandlingThread.start();\n+    super.start();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n    launcherPool \u003d new ThreadPoolExecutor(1, 5, 1, \n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e());\n    eventHandlingThread \u003d new Thread(new Runnable() {\n      @Override\n      public void run() {\n        TaskCleanupEvent event \u003d null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));        }\n      }\n    });\n    eventHandlingThread.start();\n    super.start();\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/taskclean/TaskCleanerImpl.java"
    }
  }
}