{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "StripedBlockReader.java",
  "functionName": "newConnectedPeer",
  "functionId": "newConnectedPeer___b-ExtendedBlock__addr-InetSocketAddress__blockToken-Token__BlockTokenIdentifier____datanodeId-DatanodeID",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockReader.java",
  "functionStartLine": 141,
  "functionEndLine": 163,
  "numCommitsSeen": 42,
  "timeTaken": 2874,
  "changeHistory": [
    "3c18a53cbd2efabb2ad108d63a0b0b558424115f",
    "37e23ce45c592f3c9c48a08a52a5f46787f6c0e9",
    "176ff5ce90f2cbcd8342016d0f5570337d2ff79f",
    "6616de24cb14f1c2d0d6568fd4382062618834bd"
  ],
  "changeHistoryShort": {
    "3c18a53cbd2efabb2ad108d63a0b0b558424115f": "Ymovefromfile",
    "37e23ce45c592f3c9c48a08a52a5f46787f6c0e9": "Ybodychange",
    "176ff5ce90f2cbcd8342016d0f5570337d2ff79f": "Ybodychange",
    "6616de24cb14f1c2d0d6568fd4382062618834bd": "Yintroduced"
  },
  "changeHistoryDetails": {
    "3c18a53cbd2efabb2ad108d63a0b0b558424115f": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-9719. Refactoring ErasureCodingWorker into smaller reusable constructs. Contributed by Kai Zheng.\n",
      "commitDate": "06/04/16 10:50 PM",
      "commitName": "3c18a53cbd2efabb2ad108d63a0b0b558424115f",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "06/04/16 9:45 PM",
      "commitNameOld": "8d29e2451f5ca60f864c7ece16722c0abdd1c657",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.05,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,23 @@\n-    private Peer newConnectedPeer(ExtendedBlock b, InetSocketAddress addr,\n-        Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n-        throws IOException {\n-      Peer peer \u003d null;\n-      boolean success \u003d false;\n-      Socket sock \u003d null;\n-      final int socketTimeout \u003d datanode.getDnConf().getSocketTimeout(); \n-      try {\n-        sock \u003d NetUtils.getDefaultSocketFactory(conf).createSocket();\n-        NetUtils.connect(sock, addr, socketTimeout);\n-        peer \u003d DFSUtilClient.peerFromSocketAndKey(datanode.getSaslClient(),\n-            sock, datanode.getDataEncryptionKeyFactoryForBlock(b),\n-            blockToken, datanodeId, socketTimeout);\n-        success \u003d true;\n-        return peer;\n-      } finally {\n-        if (!success) {\n-          IOUtils.cleanup(null, peer);\n-          IOUtils.closeSocket(sock);\n-        }\n+  private Peer newConnectedPeer(ExtendedBlock b, InetSocketAddress addr,\n+                                Token\u003cBlockTokenIdentifier\u003e blockToken,\n+                                DatanodeID datanodeId)\n+      throws IOException {\n+    Peer peer \u003d null;\n+    boolean success \u003d false;\n+    Socket sock \u003d null;\n+    final int socketTimeout \u003d datanode.getDnConf().getSocketTimeout();\n+    try {\n+      sock \u003d NetUtils.getDefaultSocketFactory(conf).createSocket();\n+      NetUtils.connect(sock, addr, socketTimeout);\n+      peer \u003d DFSUtilClient.peerFromSocketAndKey(datanode.getSaslClient(),\n+          sock, datanode.getDataEncryptionKeyFactoryForBlock(b),\n+          blockToken, datanodeId, socketTimeout);\n+      success \u003d true;\n+      return peer;\n+    } finally {\n+      if (!success) {\n+        IOUtils.cleanup(null, peer);\n+        IOUtils.closeSocket(sock);\n       }\n-    }\n\\ No newline at end of file\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private Peer newConnectedPeer(ExtendedBlock b, InetSocketAddress addr,\n                                Token\u003cBlockTokenIdentifier\u003e blockToken,\n                                DatanodeID datanodeId)\n      throws IOException {\n    Peer peer \u003d null;\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    final int socketTimeout \u003d datanode.getDnConf().getSocketTimeout();\n    try {\n      sock \u003d NetUtils.getDefaultSocketFactory(conf).createSocket();\n      NetUtils.connect(sock, addr, socketTimeout);\n      peer \u003d DFSUtilClient.peerFromSocketAndKey(datanode.getSaslClient(),\n          sock, datanode.getDataEncryptionKeyFactoryForBlock(b),\n          blockToken, datanodeId, socketTimeout);\n      success \u003d true;\n      return peer;\n    } finally {\n      if (!success) {\n        IOUtils.cleanup(null, peer);\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockReader.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockReader.java",
        "oldMethodName": "newConnectedPeer",
        "newMethodName": "newConnectedPeer"
      }
    },
    "37e23ce45c592f3c9c48a08a52a5f46787f6c0e9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10223. peerFromSocketAndKey performs SASL exchange before setting connection timeouts (cmccabe)\n",
      "commitDate": "30/03/16 1:37 PM",
      "commitName": "37e23ce45c592f3c9c48a08a52a5f46787f6c0e9",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "19/03/16 2:02 PM",
      "commitNameOld": "cd8b6889a74a949e37f4b2eb664cdf3b59bfb93b",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 10.98,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,22 @@\n     private Peer newConnectedPeer(ExtendedBlock b, InetSocketAddress addr,\n         Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n         throws IOException {\n       Peer peer \u003d null;\n       boolean success \u003d false;\n       Socket sock \u003d null;\n       final int socketTimeout \u003d datanode.getDnConf().getSocketTimeout(); \n       try {\n         sock \u003d NetUtils.getDefaultSocketFactory(conf).createSocket();\n         NetUtils.connect(sock, addr, socketTimeout);\n         peer \u003d DFSUtilClient.peerFromSocketAndKey(datanode.getSaslClient(),\n             sock, datanode.getDataEncryptionKeyFactoryForBlock(b),\n-            blockToken, datanodeId);\n-        peer.setReadTimeout(socketTimeout);\n+            blockToken, datanodeId, socketTimeout);\n         success \u003d true;\n         return peer;\n       } finally {\n         if (!success) {\n           IOUtils.cleanup(null, peer);\n           IOUtils.closeSocket(sock);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private Peer newConnectedPeer(ExtendedBlock b, InetSocketAddress addr,\n        Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n        throws IOException {\n      Peer peer \u003d null;\n      boolean success \u003d false;\n      Socket sock \u003d null;\n      final int socketTimeout \u003d datanode.getDnConf().getSocketTimeout(); \n      try {\n        sock \u003d NetUtils.getDefaultSocketFactory(conf).createSocket();\n        NetUtils.connect(sock, addr, socketTimeout);\n        peer \u003d DFSUtilClient.peerFromSocketAndKey(datanode.getSaslClient(),\n            sock, datanode.getDataEncryptionKeyFactoryForBlock(b),\n            blockToken, datanodeId, socketTimeout);\n        success \u003d true;\n        return peer;\n      } finally {\n        if (!success) {\n          IOUtils.cleanup(null, peer);\n          IOUtils.closeSocket(sock);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java",
      "extendedDetails": {}
    },
    "176ff5ce90f2cbcd8342016d0f5570337d2ff79f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9402. Switch DataNode.LOG to use slf4j. Contributed by Walter Su.\n",
      "commitDate": "22/11/15 3:54 PM",
      "commitName": "176ff5ce90f2cbcd8342016d0f5570337d2ff79f",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/10/15 12:04 AM",
      "commitNameOld": "5eca6dece67620f990f3306b6caaf09f317b38f6",
      "commitAuthorOld": "Walter Su",
      "daysBetweenCommits": 24.7,
      "commitsBetweenForRepo": 147,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,23 @@\n     private Peer newConnectedPeer(ExtendedBlock b, InetSocketAddress addr,\n         Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n         throws IOException {\n       Peer peer \u003d null;\n       boolean success \u003d false;\n       Socket sock \u003d null;\n       final int socketTimeout \u003d datanode.getDnConf().getSocketTimeout(); \n       try {\n         sock \u003d NetUtils.getDefaultSocketFactory(conf).createSocket();\n         NetUtils.connect(sock, addr, socketTimeout);\n         peer \u003d DFSUtilClient.peerFromSocketAndKey(datanode.getSaslClient(),\n             sock, datanode.getDataEncryptionKeyFactoryForBlock(b),\n             blockToken, datanodeId);\n         peer.setReadTimeout(socketTimeout);\n         success \u003d true;\n         return peer;\n       } finally {\n         if (!success) {\n-          IOUtils.cleanup(LOG, peer);\n+          IOUtils.cleanup(null, peer);\n           IOUtils.closeSocket(sock);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private Peer newConnectedPeer(ExtendedBlock b, InetSocketAddress addr,\n        Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n        throws IOException {\n      Peer peer \u003d null;\n      boolean success \u003d false;\n      Socket sock \u003d null;\n      final int socketTimeout \u003d datanode.getDnConf().getSocketTimeout(); \n      try {\n        sock \u003d NetUtils.getDefaultSocketFactory(conf).createSocket();\n        NetUtils.connect(sock, addr, socketTimeout);\n        peer \u003d DFSUtilClient.peerFromSocketAndKey(datanode.getSaslClient(),\n            sock, datanode.getDataEncryptionKeyFactoryForBlock(b),\n            blockToken, datanodeId);\n        peer.setReadTimeout(socketTimeout);\n        success \u003d true;\n        return peer;\n      } finally {\n        if (!success) {\n          IOUtils.cleanup(null, peer);\n          IOUtils.closeSocket(sock);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java",
      "extendedDetails": {}
    },
    "6616de24cb14f1c2d0d6568fd4382062618834bd": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7348. Erasure Coding: DataNode reconstruct striped blocks. Contributed by Yi Liu.\n",
      "commitDate": "26/05/15 12:01 PM",
      "commitName": "6616de24cb14f1c2d0d6568fd4382062618834bd",
      "commitAuthor": "Zhe Zhang",
      "diff": "@@ -0,0 +1,23 @@\n+    private Peer newConnectedPeer(ExtendedBlock b, InetSocketAddress addr,\n+        Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n+        throws IOException {\n+      Peer peer \u003d null;\n+      boolean success \u003d false;\n+      Socket sock \u003d null;\n+      final int socketTimeout \u003d datanode.getDnConf().getSocketTimeout(); \n+      try {\n+        sock \u003d NetUtils.getDefaultSocketFactory(conf).createSocket();\n+        NetUtils.connect(sock, addr, socketTimeout);\n+        peer \u003d TcpPeerServer.peerFromSocketAndKey(datanode.getSaslClient(), \n+            sock, datanode.getDataEncryptionKeyFactoryForBlock(b),\n+            blockToken, datanodeId);\n+        peer.setReadTimeout(socketTimeout);\n+        success \u003d true;\n+        return peer;\n+      } finally {\n+        if (!success) {\n+          IOUtils.cleanup(LOG, peer);\n+          IOUtils.closeSocket(sock);\n+        }\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private Peer newConnectedPeer(ExtendedBlock b, InetSocketAddress addr,\n        Token\u003cBlockTokenIdentifier\u003e blockToken, DatanodeID datanodeId)\n        throws IOException {\n      Peer peer \u003d null;\n      boolean success \u003d false;\n      Socket sock \u003d null;\n      final int socketTimeout \u003d datanode.getDnConf().getSocketTimeout(); \n      try {\n        sock \u003d NetUtils.getDefaultSocketFactory(conf).createSocket();\n        NetUtils.connect(sock, addr, socketTimeout);\n        peer \u003d TcpPeerServer.peerFromSocketAndKey(datanode.getSaslClient(), \n            sock, datanode.getDataEncryptionKeyFactoryForBlock(b),\n            blockToken, datanodeId);\n        peer.setReadTimeout(socketTimeout);\n        success \u003d true;\n        return peer;\n      } finally {\n        if (!success) {\n          IOUtils.cleanup(LOG, peer);\n          IOUtils.closeSocket(sock);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/ErasureCodingWorker.java"
    }
  }
}