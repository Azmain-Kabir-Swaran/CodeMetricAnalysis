{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HadoopLogsAnalyzer.java",
  "functionName": "initializeHadoopLogsAnalyzer",
  "functionId": "initializeHadoopLogsAnalyzer___args-String[]",
  "sourceFilePath": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
  "functionStartLine": 311,
  "functionEndLine": 510,
  "numCommitsSeen": 13,
  "timeTaken": 5350,
  "changeHistory": [
    "d1c6accb6f87b08975175580e15f1ff1fe29ab04",
    "9cedad11d8d2197a54732667a15344983de5c437",
    "946456c6d88780abe0251b098dd771e9e1e93ab3",
    "10325d97329c214bb3899c8535df5a366bc86d2f",
    "a238f931ea7dce0ca620d1798156c84ff77097ff",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "d1c6accb6f87b08975175580e15f1ff1fe29ab04": "Ybodychange",
    "9cedad11d8d2197a54732667a15344983de5c437": "Ybodychange",
    "946456c6d88780abe0251b098dd771e9e1e93ab3": "Ybodychange",
    "10325d97329c214bb3899c8535df5a366bc86d2f": "Yfilerename",
    "a238f931ea7dce0ca620d1798156c84ff77097ff": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d1c6accb6f87b08975175580e15f1ff1fe29ab04": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11602. Fix toUpperCase/toLowerCase to use Locale.ENGLISH. (ozawa)\n",
      "commitDate": "02/03/15 9:17 PM",
      "commitName": "d1c6accb6f87b08975175580e15f1ff1fe29ab04",
      "commitAuthor": "Tsuyoshi Ozawa",
      "commitDateOld": "24/02/15 7:32 AM",
      "commitNameOld": "9cedad11d8d2197a54732667a15344983de5c437",
      "commitAuthorOld": "Tsuyoshi Ozawa",
      "daysBetweenCommits": 6.57,
      "commitsBetweenForRepo": 57,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,200 +1,200 @@\n   private int initializeHadoopLogsAnalyzer(String[] args)\n       throws FileNotFoundException, IOException {\n     Path jobTraceFilename \u003d null;\n     Path topologyFilename \u003d null;\n     if (args.length \u003d\u003d 0 || args[args.length - 1].charAt(0) \u003d\u003d \u0027-\u0027) {\n       throw new IllegalArgumentException(\"No input specified.\");\n     } else {\n       inputFilename \u003d args[args.length - 1];\n     }\n \n     for (int i \u003d 0; i \u003c args.length - (inputFilename \u003d\u003d null ? 0 : 1); ++i) {\n-      if (\"-h\".equals(args[i].toLowerCase())\n-          || \"-help\".equals(args[i].toLowerCase())) {\n+      if (StringUtils.equalsIgnoreCase(\"-h\", args[i])\n+          || StringUtils.equalsIgnoreCase(\"-help\", args[i])) {\n         usage();\n         return 0;\n       }\n \n-      if (\"-c\".equals(args[i].toLowerCase())\n-          || \"-collect-prefixes\".equals(args[i].toLowerCase())) {\n+      if (StringUtils.equalsIgnoreCase(\"-c\", args[i])\n+          || StringUtils.equalsIgnoreCase(\"-collect-prefixes\", args[i])) {\n         collecting \u003d true;\n         continue;\n       }\n \n       // these control the job digest\n-      if (\"-write-job-trace\".equals(args[i].toLowerCase())) {\n+      if (StringUtils.equalsIgnoreCase(\"-write-job-trace\", args[i])) {\n         ++i;\n         jobTraceFilename \u003d new Path(args[i]);\n         continue;\n       }\n \n-      if (\"-single-line-job-traces\".equals(args[i].toLowerCase())) {\n+      if (StringUtils.equalsIgnoreCase(\"-single-line-job-traces\", args[i])) {\n         prettyprintTrace \u003d false;\n         continue;\n       }\n \n-      if (\"-omit-task-details\".equals(args[i].toLowerCase())) {\n+      if (StringUtils.equalsIgnoreCase(\"-omit-task-details\", args[i])) {\n         omitTaskDetails \u003d true;\n         continue;\n       }\n \n-      if (\"-write-topology\".equals(args[i].toLowerCase())) {\n+      if (StringUtils.equalsIgnoreCase(\"-write-topology\", args[i])) {\n         ++i;\n         topologyFilename \u003d new Path(args[i]);\n         continue;\n       }\n \n-      if (\"-job-digest-spectra\".equals(args[i].toLowerCase())) {\n+      if (StringUtils.equalsIgnoreCase(\"-job-digest-spectra\", args[i])) {\n         ArrayList\u003cInteger\u003e values \u003d new ArrayList\u003cInteger\u003e();\n \n         ++i;\n \n         while (i \u003c args.length \u0026\u0026 Character.isDigit(args[i].charAt(0))) {\n           values.add(Integer.parseInt(args[i]));\n           ++i;\n         }\n \n         if (values.size() \u003d\u003d 0) {\n           throw new IllegalArgumentException(\"Empty -job-digest-spectra list\");\n         }\n \n         attemptTimesPercentiles \u003d new int[values.size()];\n \n         int lastValue \u003d 0;\n \n         for (int j \u003d 0; j \u003c attemptTimesPercentiles.length; ++j) {\n           if (values.get(j) \u003c\u003d lastValue || values.get(j) \u003e\u003d 100) {\n             throw new IllegalArgumentException(\n                 \"Bad -job-digest-spectra percentiles list\");\n           }\n           attemptTimesPercentiles[j] \u003d values.get(j);\n         }\n \n         --i;\n         continue;\n       }\n \n-      if (\"-d\".equals(args[i].toLowerCase())\n-          || \"-debug\".equals(args[i].toLowerCase())) {\n+      if (StringUtils.equalsIgnoreCase(\"-d\", args[i])\n+          || StringUtils.equalsIgnoreCase(\"-debug\", args[i])) {\n         debug \u003d true;\n         continue;\n       }\n \n-      if (\"-spreads\".equals(args[i].toLowerCase())) {\n+      if (StringUtils.equalsIgnoreCase(\"-spreads\", args[i])) {\n         int min \u003d Integer.parseInt(args[i + 1]);\n         int max \u003d Integer.parseInt(args[i + 2]);\n \n         if (min \u003c max \u0026\u0026 min \u003c 1000 \u0026\u0026 max \u003c 1000) {\n           spreadMin \u003d min;\n           spreadMax \u003d max;\n           spreading \u003d true;\n           i +\u003d 2;\n         }\n         continue;\n       }\n \n       // These control log-wide CDF outputs\n-      if (\"-delays\".equals(args[i].toLowerCase())) {\n+      if (StringUtils.equalsIgnoreCase(\"-delays\", args[i])) {\n         delays \u003d true;\n         continue;\n       }\n \n-      if (\"-runtimes\".equals(args[i].toLowerCase())) {\n+      if (StringUtils.equalsIgnoreCase(\"-runtimes\", args[i])) {\n         runtimes \u003d true;\n         continue;\n       }\n \n-      if (\"-tasktimes\".equals(args[i].toLowerCase())) {\n+      if (StringUtils.equalsIgnoreCase(\"-tasktimes\", args[i])) {\n         collectTaskTimes \u003d true;\n         continue;\n       }\n \n-      if (\"-v1\".equals(args[i].toLowerCase())) {\n+      if (StringUtils.equalsIgnoreCase(\"-v1\", args[i])) {\n         version \u003d 1;\n         continue;\n       }\n \n       throw new IllegalArgumentException(\"Unrecognized argument: \" + args[i]);\n     }\n \n     runTimeDists \u003d newDistributionBlock();\n     delayTimeDists \u003d newDistributionBlock();\n     mapTimeSpreadDists \u003d newDistributionBlock(\"map-time-spreads\");\n     shuffleTimeSpreadDists \u003d newDistributionBlock();\n     sortTimeSpreadDists \u003d newDistributionBlock();\n     reduceTimeSpreadDists \u003d newDistributionBlock();\n \n     mapTimeDists \u003d newDistributionBlock();\n     shuffleTimeDists \u003d newDistributionBlock();\n     sortTimeDists \u003d newDistributionBlock();\n     reduceTimeDists \u003d newDistributionBlock();\n \n     taskAttemptStartTimes \u003d new HashMap\u003cString, Long\u003e();\n     taskReduceAttemptShuffleEndTimes \u003d new HashMap\u003cString, Long\u003e();\n     taskReduceAttemptSortEndTimes \u003d new HashMap\u003cString, Long\u003e();\n     taskMapAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n     taskReduceAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n \n     final Path inputPath \u003d new Path(inputFilename);\n \n     inputIsDirectory \u003d pathIsDirectory(inputPath);\n \n     if (jobTraceFilename !\u003d null \u0026\u0026 attemptTimesPercentiles \u003d\u003d null) {\n       attemptTimesPercentiles \u003d new int[19];\n \n       for (int i \u003d 0; i \u003c 19; ++i) {\n         attemptTimesPercentiles[i] \u003d (i + 1) * 5;\n       }\n     }\n \n     if (!inputIsDirectory) {\n       input \u003d maybeUncompressedPath(inputPath);\n     } else {\n       inputDirectoryPath \u003d inputPath;\n       FileSystem fs \u003d inputPath.getFileSystem(getConf());\n       FileStatus[] statuses \u003d fs.listStatus(inputPath);\n       inputDirectoryFiles \u003d new String[statuses.length];\n \n       for (int i \u003d 0; i \u003c statuses.length; ++i) {\n         inputDirectoryFiles[i] \u003d statuses[i].getPath().getName();\n       }\n \n       // filter out the .crc files, if any\n       int dropPoint \u003d 0;\n \n       for (int i \u003d 0; i \u003c inputDirectoryFiles.length; ++i) {\n         String name \u003d inputDirectoryFiles[i];\n \n         if (!(name.length() \u003e\u003d 4 \u0026\u0026 \".crc\".equals(name\n             .substring(name.length() - 4)))) {\n           inputDirectoryFiles[dropPoint++] \u003d name;\n         }\n       }\n \n       LOG.info(\"We dropped \" + (inputDirectoryFiles.length - dropPoint)\n           + \" crc files.\");\n \n       String[] new_inputDirectoryFiles \u003d new String[dropPoint];\n       System.arraycopy(inputDirectoryFiles, 0, new_inputDirectoryFiles, 0,\n           dropPoint);\n       inputDirectoryFiles \u003d new_inputDirectoryFiles;\n \n       Arrays.sort(inputDirectoryFiles);\n \n       if (!setNextDirectoryInputStream()) {\n         throw new FileNotFoundException(\"Empty directory specified.\");\n       }\n     }\n \n     if (jobTraceFilename !\u003d null) {\n       jobTraceGen \u003d new DefaultOutputter\u003cLoggedJob\u003e();\n       jobTraceGen.init(jobTraceFilename, getConf());\n \n       if (topologyFilename !\u003d null) {\n         topologyGen \u003d new DefaultOutputter\u003cLoggedNetworkTopology\u003e();\n         topologyGen.init(topologyFilename, getConf());\n       }\n     }\n \n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int initializeHadoopLogsAnalyzer(String[] args)\n      throws FileNotFoundException, IOException {\n    Path jobTraceFilename \u003d null;\n    Path topologyFilename \u003d null;\n    if (args.length \u003d\u003d 0 || args[args.length - 1].charAt(0) \u003d\u003d \u0027-\u0027) {\n      throw new IllegalArgumentException(\"No input specified.\");\n    } else {\n      inputFilename \u003d args[args.length - 1];\n    }\n\n    for (int i \u003d 0; i \u003c args.length - (inputFilename \u003d\u003d null ? 0 : 1); ++i) {\n      if (StringUtils.equalsIgnoreCase(\"-h\", args[i])\n          || StringUtils.equalsIgnoreCase(\"-help\", args[i])) {\n        usage();\n        return 0;\n      }\n\n      if (StringUtils.equalsIgnoreCase(\"-c\", args[i])\n          || StringUtils.equalsIgnoreCase(\"-collect-prefixes\", args[i])) {\n        collecting \u003d true;\n        continue;\n      }\n\n      // these control the job digest\n      if (StringUtils.equalsIgnoreCase(\"-write-job-trace\", args[i])) {\n        ++i;\n        jobTraceFilename \u003d new Path(args[i]);\n        continue;\n      }\n\n      if (StringUtils.equalsIgnoreCase(\"-single-line-job-traces\", args[i])) {\n        prettyprintTrace \u003d false;\n        continue;\n      }\n\n      if (StringUtils.equalsIgnoreCase(\"-omit-task-details\", args[i])) {\n        omitTaskDetails \u003d true;\n        continue;\n      }\n\n      if (StringUtils.equalsIgnoreCase(\"-write-topology\", args[i])) {\n        ++i;\n        topologyFilename \u003d new Path(args[i]);\n        continue;\n      }\n\n      if (StringUtils.equalsIgnoreCase(\"-job-digest-spectra\", args[i])) {\n        ArrayList\u003cInteger\u003e values \u003d new ArrayList\u003cInteger\u003e();\n\n        ++i;\n\n        while (i \u003c args.length \u0026\u0026 Character.isDigit(args[i].charAt(0))) {\n          values.add(Integer.parseInt(args[i]));\n          ++i;\n        }\n\n        if (values.size() \u003d\u003d 0) {\n          throw new IllegalArgumentException(\"Empty -job-digest-spectra list\");\n        }\n\n        attemptTimesPercentiles \u003d new int[values.size()];\n\n        int lastValue \u003d 0;\n\n        for (int j \u003d 0; j \u003c attemptTimesPercentiles.length; ++j) {\n          if (values.get(j) \u003c\u003d lastValue || values.get(j) \u003e\u003d 100) {\n            throw new IllegalArgumentException(\n                \"Bad -job-digest-spectra percentiles list\");\n          }\n          attemptTimesPercentiles[j] \u003d values.get(j);\n        }\n\n        --i;\n        continue;\n      }\n\n      if (StringUtils.equalsIgnoreCase(\"-d\", args[i])\n          || StringUtils.equalsIgnoreCase(\"-debug\", args[i])) {\n        debug \u003d true;\n        continue;\n      }\n\n      if (StringUtils.equalsIgnoreCase(\"-spreads\", args[i])) {\n        int min \u003d Integer.parseInt(args[i + 1]);\n        int max \u003d Integer.parseInt(args[i + 2]);\n\n        if (min \u003c max \u0026\u0026 min \u003c 1000 \u0026\u0026 max \u003c 1000) {\n          spreadMin \u003d min;\n          spreadMax \u003d max;\n          spreading \u003d true;\n          i +\u003d 2;\n        }\n        continue;\n      }\n\n      // These control log-wide CDF outputs\n      if (StringUtils.equalsIgnoreCase(\"-delays\", args[i])) {\n        delays \u003d true;\n        continue;\n      }\n\n      if (StringUtils.equalsIgnoreCase(\"-runtimes\", args[i])) {\n        runtimes \u003d true;\n        continue;\n      }\n\n      if (StringUtils.equalsIgnoreCase(\"-tasktimes\", args[i])) {\n        collectTaskTimes \u003d true;\n        continue;\n      }\n\n      if (StringUtils.equalsIgnoreCase(\"-v1\", args[i])) {\n        version \u003d 1;\n        continue;\n      }\n\n      throw new IllegalArgumentException(\"Unrecognized argument: \" + args[i]);\n    }\n\n    runTimeDists \u003d newDistributionBlock();\n    delayTimeDists \u003d newDistributionBlock();\n    mapTimeSpreadDists \u003d newDistributionBlock(\"map-time-spreads\");\n    shuffleTimeSpreadDists \u003d newDistributionBlock();\n    sortTimeSpreadDists \u003d newDistributionBlock();\n    reduceTimeSpreadDists \u003d newDistributionBlock();\n\n    mapTimeDists \u003d newDistributionBlock();\n    shuffleTimeDists \u003d newDistributionBlock();\n    sortTimeDists \u003d newDistributionBlock();\n    reduceTimeDists \u003d newDistributionBlock();\n\n    taskAttemptStartTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptShuffleEndTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptSortEndTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskMapAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n\n    final Path inputPath \u003d new Path(inputFilename);\n\n    inputIsDirectory \u003d pathIsDirectory(inputPath);\n\n    if (jobTraceFilename !\u003d null \u0026\u0026 attemptTimesPercentiles \u003d\u003d null) {\n      attemptTimesPercentiles \u003d new int[19];\n\n      for (int i \u003d 0; i \u003c 19; ++i) {\n        attemptTimesPercentiles[i] \u003d (i + 1) * 5;\n      }\n    }\n\n    if (!inputIsDirectory) {\n      input \u003d maybeUncompressedPath(inputPath);\n    } else {\n      inputDirectoryPath \u003d inputPath;\n      FileSystem fs \u003d inputPath.getFileSystem(getConf());\n      FileStatus[] statuses \u003d fs.listStatus(inputPath);\n      inputDirectoryFiles \u003d new String[statuses.length];\n\n      for (int i \u003d 0; i \u003c statuses.length; ++i) {\n        inputDirectoryFiles[i] \u003d statuses[i].getPath().getName();\n      }\n\n      // filter out the .crc files, if any\n      int dropPoint \u003d 0;\n\n      for (int i \u003d 0; i \u003c inputDirectoryFiles.length; ++i) {\n        String name \u003d inputDirectoryFiles[i];\n\n        if (!(name.length() \u003e\u003d 4 \u0026\u0026 \".crc\".equals(name\n            .substring(name.length() - 4)))) {\n          inputDirectoryFiles[dropPoint++] \u003d name;\n        }\n      }\n\n      LOG.info(\"We dropped \" + (inputDirectoryFiles.length - dropPoint)\n          + \" crc files.\");\n\n      String[] new_inputDirectoryFiles \u003d new String[dropPoint];\n      System.arraycopy(inputDirectoryFiles, 0, new_inputDirectoryFiles, 0,\n          dropPoint);\n      inputDirectoryFiles \u003d new_inputDirectoryFiles;\n\n      Arrays.sort(inputDirectoryFiles);\n\n      if (!setNextDirectoryInputStream()) {\n        throw new FileNotFoundException(\"Empty directory specified.\");\n      }\n    }\n\n    if (jobTraceFilename !\u003d null) {\n      jobTraceGen \u003d new DefaultOutputter\u003cLoggedJob\u003e();\n      jobTraceGen.init(jobTraceFilename, getConf());\n\n      if (topologyFilename !\u003d null) {\n        topologyGen \u003d new DefaultOutputter\u003cLoggedNetworkTopology\u003e();\n        topologyGen.init(topologyFilename, getConf());\n      }\n    }\n\n    return 0;\n  }",
      "path": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
      "extendedDetails": {}
    },
    "9cedad11d8d2197a54732667a15344983de5c437": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HADOOP-11602. Fix toUpperCase/toLowerCase to use Locale.ENGLISH. (ozawa)\"\n\nThis reverts commit 946456c6d88780abe0251b098dd771e9e1e93ab3.\n\nConflicts:\n\thadoop-common-project/hadoop-common/CHANGES.txt\n\thadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/QuotaByStorageTypeEntry.java\n",
      "commitDate": "24/02/15 7:32 AM",
      "commitName": "9cedad11d8d2197a54732667a15344983de5c437",
      "commitAuthor": "Tsuyoshi Ozawa",
      "commitDateOld": "18/02/15 8:06 PM",
      "commitNameOld": "946456c6d88780abe0251b098dd771e9e1e93ab3",
      "commitAuthorOld": "Tsuyoshi Ozawa",
      "daysBetweenCommits": 5.48,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,201 +1,200 @@\n   private int initializeHadoopLogsAnalyzer(String[] args)\n       throws FileNotFoundException, IOException {\n     Path jobTraceFilename \u003d null;\n     Path topologyFilename \u003d null;\n     if (args.length \u003d\u003d 0 || args[args.length - 1].charAt(0) \u003d\u003d \u0027-\u0027) {\n       throw new IllegalArgumentException(\"No input specified.\");\n     } else {\n       inputFilename \u003d args[args.length - 1];\n     }\n \n     for (int i \u003d 0; i \u003c args.length - (inputFilename \u003d\u003d null ? 0 : 1); ++i) {\n-      if (\"-h\".equals(args[i].toLowerCase(Locale.ENGLISH))\n-          || \"-help\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n+      if (\"-h\".equals(args[i].toLowerCase())\n+          || \"-help\".equals(args[i].toLowerCase())) {\n         usage();\n         return 0;\n       }\n \n-      if (\"-c\".equals(args[i].toLowerCase(Locale.ENGLISH))\n-          || \"-collect-prefixes\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n+      if (\"-c\".equals(args[i].toLowerCase())\n+          || \"-collect-prefixes\".equals(args[i].toLowerCase())) {\n         collecting \u003d true;\n         continue;\n       }\n \n       // these control the job digest\n-      if (\"-write-job-trace\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n+      if (\"-write-job-trace\".equals(args[i].toLowerCase())) {\n         ++i;\n         jobTraceFilename \u003d new Path(args[i]);\n         continue;\n       }\n \n-      if (\"-single-line-job-traces\".equals(\n-          args[i].toLowerCase(Locale.ENGLISH))) {\n+      if (\"-single-line-job-traces\".equals(args[i].toLowerCase())) {\n         prettyprintTrace \u003d false;\n         continue;\n       }\n \n-      if (\"-omit-task-details\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n+      if (\"-omit-task-details\".equals(args[i].toLowerCase())) {\n         omitTaskDetails \u003d true;\n         continue;\n       }\n \n-      if (\"-write-topology\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n+      if (\"-write-topology\".equals(args[i].toLowerCase())) {\n         ++i;\n         topologyFilename \u003d new Path(args[i]);\n         continue;\n       }\n \n-      if (\"-job-digest-spectra\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n+      if (\"-job-digest-spectra\".equals(args[i].toLowerCase())) {\n         ArrayList\u003cInteger\u003e values \u003d new ArrayList\u003cInteger\u003e();\n \n         ++i;\n \n         while (i \u003c args.length \u0026\u0026 Character.isDigit(args[i].charAt(0))) {\n           values.add(Integer.parseInt(args[i]));\n           ++i;\n         }\n \n         if (values.size() \u003d\u003d 0) {\n           throw new IllegalArgumentException(\"Empty -job-digest-spectra list\");\n         }\n \n         attemptTimesPercentiles \u003d new int[values.size()];\n \n         int lastValue \u003d 0;\n \n         for (int j \u003d 0; j \u003c attemptTimesPercentiles.length; ++j) {\n           if (values.get(j) \u003c\u003d lastValue || values.get(j) \u003e\u003d 100) {\n             throw new IllegalArgumentException(\n                 \"Bad -job-digest-spectra percentiles list\");\n           }\n           attemptTimesPercentiles[j] \u003d values.get(j);\n         }\n \n         --i;\n         continue;\n       }\n \n-      if (\"-d\".equals(args[i].toLowerCase(Locale.ENGLISH))\n-          || \"-debug\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n+      if (\"-d\".equals(args[i].toLowerCase())\n+          || \"-debug\".equals(args[i].toLowerCase())) {\n         debug \u003d true;\n         continue;\n       }\n \n-      if (\"-spreads\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n+      if (\"-spreads\".equals(args[i].toLowerCase())) {\n         int min \u003d Integer.parseInt(args[i + 1]);\n         int max \u003d Integer.parseInt(args[i + 2]);\n \n         if (min \u003c max \u0026\u0026 min \u003c 1000 \u0026\u0026 max \u003c 1000) {\n           spreadMin \u003d min;\n           spreadMax \u003d max;\n           spreading \u003d true;\n           i +\u003d 2;\n         }\n         continue;\n       }\n \n       // These control log-wide CDF outputs\n-      if (\"-delays\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n+      if (\"-delays\".equals(args[i].toLowerCase())) {\n         delays \u003d true;\n         continue;\n       }\n \n-      if (\"-runtimes\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n+      if (\"-runtimes\".equals(args[i].toLowerCase())) {\n         runtimes \u003d true;\n         continue;\n       }\n \n-      if (\"-tasktimes\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n+      if (\"-tasktimes\".equals(args[i].toLowerCase())) {\n         collectTaskTimes \u003d true;\n         continue;\n       }\n \n-      if (\"-v1\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n+      if (\"-v1\".equals(args[i].toLowerCase())) {\n         version \u003d 1;\n         continue;\n       }\n \n       throw new IllegalArgumentException(\"Unrecognized argument: \" + args[i]);\n     }\n \n     runTimeDists \u003d newDistributionBlock();\n     delayTimeDists \u003d newDistributionBlock();\n     mapTimeSpreadDists \u003d newDistributionBlock(\"map-time-spreads\");\n     shuffleTimeSpreadDists \u003d newDistributionBlock();\n     sortTimeSpreadDists \u003d newDistributionBlock();\n     reduceTimeSpreadDists \u003d newDistributionBlock();\n \n     mapTimeDists \u003d newDistributionBlock();\n     shuffleTimeDists \u003d newDistributionBlock();\n     sortTimeDists \u003d newDistributionBlock();\n     reduceTimeDists \u003d newDistributionBlock();\n \n     taskAttemptStartTimes \u003d new HashMap\u003cString, Long\u003e();\n     taskReduceAttemptShuffleEndTimes \u003d new HashMap\u003cString, Long\u003e();\n     taskReduceAttemptSortEndTimes \u003d new HashMap\u003cString, Long\u003e();\n     taskMapAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n     taskReduceAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n \n     final Path inputPath \u003d new Path(inputFilename);\n \n     inputIsDirectory \u003d pathIsDirectory(inputPath);\n \n     if (jobTraceFilename !\u003d null \u0026\u0026 attemptTimesPercentiles \u003d\u003d null) {\n       attemptTimesPercentiles \u003d new int[19];\n \n       for (int i \u003d 0; i \u003c 19; ++i) {\n         attemptTimesPercentiles[i] \u003d (i + 1) * 5;\n       }\n     }\n \n     if (!inputIsDirectory) {\n       input \u003d maybeUncompressedPath(inputPath);\n     } else {\n       inputDirectoryPath \u003d inputPath;\n       FileSystem fs \u003d inputPath.getFileSystem(getConf());\n       FileStatus[] statuses \u003d fs.listStatus(inputPath);\n       inputDirectoryFiles \u003d new String[statuses.length];\n \n       for (int i \u003d 0; i \u003c statuses.length; ++i) {\n         inputDirectoryFiles[i] \u003d statuses[i].getPath().getName();\n       }\n \n       // filter out the .crc files, if any\n       int dropPoint \u003d 0;\n \n       for (int i \u003d 0; i \u003c inputDirectoryFiles.length; ++i) {\n         String name \u003d inputDirectoryFiles[i];\n \n         if (!(name.length() \u003e\u003d 4 \u0026\u0026 \".crc\".equals(name\n             .substring(name.length() - 4)))) {\n           inputDirectoryFiles[dropPoint++] \u003d name;\n         }\n       }\n \n       LOG.info(\"We dropped \" + (inputDirectoryFiles.length - dropPoint)\n           + \" crc files.\");\n \n       String[] new_inputDirectoryFiles \u003d new String[dropPoint];\n       System.arraycopy(inputDirectoryFiles, 0, new_inputDirectoryFiles, 0,\n           dropPoint);\n       inputDirectoryFiles \u003d new_inputDirectoryFiles;\n \n       Arrays.sort(inputDirectoryFiles);\n \n       if (!setNextDirectoryInputStream()) {\n         throw new FileNotFoundException(\"Empty directory specified.\");\n       }\n     }\n \n     if (jobTraceFilename !\u003d null) {\n       jobTraceGen \u003d new DefaultOutputter\u003cLoggedJob\u003e();\n       jobTraceGen.init(jobTraceFilename, getConf());\n \n       if (topologyFilename !\u003d null) {\n         topologyGen \u003d new DefaultOutputter\u003cLoggedNetworkTopology\u003e();\n         topologyGen.init(topologyFilename, getConf());\n       }\n     }\n \n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int initializeHadoopLogsAnalyzer(String[] args)\n      throws FileNotFoundException, IOException {\n    Path jobTraceFilename \u003d null;\n    Path topologyFilename \u003d null;\n    if (args.length \u003d\u003d 0 || args[args.length - 1].charAt(0) \u003d\u003d \u0027-\u0027) {\n      throw new IllegalArgumentException(\"No input specified.\");\n    } else {\n      inputFilename \u003d args[args.length - 1];\n    }\n\n    for (int i \u003d 0; i \u003c args.length - (inputFilename \u003d\u003d null ? 0 : 1); ++i) {\n      if (\"-h\".equals(args[i].toLowerCase())\n          || \"-help\".equals(args[i].toLowerCase())) {\n        usage();\n        return 0;\n      }\n\n      if (\"-c\".equals(args[i].toLowerCase())\n          || \"-collect-prefixes\".equals(args[i].toLowerCase())) {\n        collecting \u003d true;\n        continue;\n      }\n\n      // these control the job digest\n      if (\"-write-job-trace\".equals(args[i].toLowerCase())) {\n        ++i;\n        jobTraceFilename \u003d new Path(args[i]);\n        continue;\n      }\n\n      if (\"-single-line-job-traces\".equals(args[i].toLowerCase())) {\n        prettyprintTrace \u003d false;\n        continue;\n      }\n\n      if (\"-omit-task-details\".equals(args[i].toLowerCase())) {\n        omitTaskDetails \u003d true;\n        continue;\n      }\n\n      if (\"-write-topology\".equals(args[i].toLowerCase())) {\n        ++i;\n        topologyFilename \u003d new Path(args[i]);\n        continue;\n      }\n\n      if (\"-job-digest-spectra\".equals(args[i].toLowerCase())) {\n        ArrayList\u003cInteger\u003e values \u003d new ArrayList\u003cInteger\u003e();\n\n        ++i;\n\n        while (i \u003c args.length \u0026\u0026 Character.isDigit(args[i].charAt(0))) {\n          values.add(Integer.parseInt(args[i]));\n          ++i;\n        }\n\n        if (values.size() \u003d\u003d 0) {\n          throw new IllegalArgumentException(\"Empty -job-digest-spectra list\");\n        }\n\n        attemptTimesPercentiles \u003d new int[values.size()];\n\n        int lastValue \u003d 0;\n\n        for (int j \u003d 0; j \u003c attemptTimesPercentiles.length; ++j) {\n          if (values.get(j) \u003c\u003d lastValue || values.get(j) \u003e\u003d 100) {\n            throw new IllegalArgumentException(\n                \"Bad -job-digest-spectra percentiles list\");\n          }\n          attemptTimesPercentiles[j] \u003d values.get(j);\n        }\n\n        --i;\n        continue;\n      }\n\n      if (\"-d\".equals(args[i].toLowerCase())\n          || \"-debug\".equals(args[i].toLowerCase())) {\n        debug \u003d true;\n        continue;\n      }\n\n      if (\"-spreads\".equals(args[i].toLowerCase())) {\n        int min \u003d Integer.parseInt(args[i + 1]);\n        int max \u003d Integer.parseInt(args[i + 2]);\n\n        if (min \u003c max \u0026\u0026 min \u003c 1000 \u0026\u0026 max \u003c 1000) {\n          spreadMin \u003d min;\n          spreadMax \u003d max;\n          spreading \u003d true;\n          i +\u003d 2;\n        }\n        continue;\n      }\n\n      // These control log-wide CDF outputs\n      if (\"-delays\".equals(args[i].toLowerCase())) {\n        delays \u003d true;\n        continue;\n      }\n\n      if (\"-runtimes\".equals(args[i].toLowerCase())) {\n        runtimes \u003d true;\n        continue;\n      }\n\n      if (\"-tasktimes\".equals(args[i].toLowerCase())) {\n        collectTaskTimes \u003d true;\n        continue;\n      }\n\n      if (\"-v1\".equals(args[i].toLowerCase())) {\n        version \u003d 1;\n        continue;\n      }\n\n      throw new IllegalArgumentException(\"Unrecognized argument: \" + args[i]);\n    }\n\n    runTimeDists \u003d newDistributionBlock();\n    delayTimeDists \u003d newDistributionBlock();\n    mapTimeSpreadDists \u003d newDistributionBlock(\"map-time-spreads\");\n    shuffleTimeSpreadDists \u003d newDistributionBlock();\n    sortTimeSpreadDists \u003d newDistributionBlock();\n    reduceTimeSpreadDists \u003d newDistributionBlock();\n\n    mapTimeDists \u003d newDistributionBlock();\n    shuffleTimeDists \u003d newDistributionBlock();\n    sortTimeDists \u003d newDistributionBlock();\n    reduceTimeDists \u003d newDistributionBlock();\n\n    taskAttemptStartTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptShuffleEndTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptSortEndTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskMapAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n\n    final Path inputPath \u003d new Path(inputFilename);\n\n    inputIsDirectory \u003d pathIsDirectory(inputPath);\n\n    if (jobTraceFilename !\u003d null \u0026\u0026 attemptTimesPercentiles \u003d\u003d null) {\n      attemptTimesPercentiles \u003d new int[19];\n\n      for (int i \u003d 0; i \u003c 19; ++i) {\n        attemptTimesPercentiles[i] \u003d (i + 1) * 5;\n      }\n    }\n\n    if (!inputIsDirectory) {\n      input \u003d maybeUncompressedPath(inputPath);\n    } else {\n      inputDirectoryPath \u003d inputPath;\n      FileSystem fs \u003d inputPath.getFileSystem(getConf());\n      FileStatus[] statuses \u003d fs.listStatus(inputPath);\n      inputDirectoryFiles \u003d new String[statuses.length];\n\n      for (int i \u003d 0; i \u003c statuses.length; ++i) {\n        inputDirectoryFiles[i] \u003d statuses[i].getPath().getName();\n      }\n\n      // filter out the .crc files, if any\n      int dropPoint \u003d 0;\n\n      for (int i \u003d 0; i \u003c inputDirectoryFiles.length; ++i) {\n        String name \u003d inputDirectoryFiles[i];\n\n        if (!(name.length() \u003e\u003d 4 \u0026\u0026 \".crc\".equals(name\n            .substring(name.length() - 4)))) {\n          inputDirectoryFiles[dropPoint++] \u003d name;\n        }\n      }\n\n      LOG.info(\"We dropped \" + (inputDirectoryFiles.length - dropPoint)\n          + \" crc files.\");\n\n      String[] new_inputDirectoryFiles \u003d new String[dropPoint];\n      System.arraycopy(inputDirectoryFiles, 0, new_inputDirectoryFiles, 0,\n          dropPoint);\n      inputDirectoryFiles \u003d new_inputDirectoryFiles;\n\n      Arrays.sort(inputDirectoryFiles);\n\n      if (!setNextDirectoryInputStream()) {\n        throw new FileNotFoundException(\"Empty directory specified.\");\n      }\n    }\n\n    if (jobTraceFilename !\u003d null) {\n      jobTraceGen \u003d new DefaultOutputter\u003cLoggedJob\u003e();\n      jobTraceGen.init(jobTraceFilename, getConf());\n\n      if (topologyFilename !\u003d null) {\n        topologyGen \u003d new DefaultOutputter\u003cLoggedNetworkTopology\u003e();\n        topologyGen.init(topologyFilename, getConf());\n      }\n    }\n\n    return 0;\n  }",
      "path": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
      "extendedDetails": {}
    },
    "946456c6d88780abe0251b098dd771e9e1e93ab3": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11602. Fix toUpperCase/toLowerCase to use Locale.ENGLISH. (ozawa)\n",
      "commitDate": "18/02/15 8:06 PM",
      "commitName": "946456c6d88780abe0251b098dd771e9e1e93ab3",
      "commitAuthor": "Tsuyoshi Ozawa",
      "commitDateOld": "04/02/15 9:25 AM",
      "commitNameOld": "34fe11c987730932f99dec6eb458a22624eb075b",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 14.45,
      "commitsBetweenForRepo": 194,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,200 +1,201 @@\n   private int initializeHadoopLogsAnalyzer(String[] args)\n       throws FileNotFoundException, IOException {\n     Path jobTraceFilename \u003d null;\n     Path topologyFilename \u003d null;\n     if (args.length \u003d\u003d 0 || args[args.length - 1].charAt(0) \u003d\u003d \u0027-\u0027) {\n       throw new IllegalArgumentException(\"No input specified.\");\n     } else {\n       inputFilename \u003d args[args.length - 1];\n     }\n \n     for (int i \u003d 0; i \u003c args.length - (inputFilename \u003d\u003d null ? 0 : 1); ++i) {\n-      if (\"-h\".equals(args[i].toLowerCase())\n-          || \"-help\".equals(args[i].toLowerCase())) {\n+      if (\"-h\".equals(args[i].toLowerCase(Locale.ENGLISH))\n+          || \"-help\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n         usage();\n         return 0;\n       }\n \n-      if (\"-c\".equals(args[i].toLowerCase())\n-          || \"-collect-prefixes\".equals(args[i].toLowerCase())) {\n+      if (\"-c\".equals(args[i].toLowerCase(Locale.ENGLISH))\n+          || \"-collect-prefixes\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n         collecting \u003d true;\n         continue;\n       }\n \n       // these control the job digest\n-      if (\"-write-job-trace\".equals(args[i].toLowerCase())) {\n+      if (\"-write-job-trace\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n         ++i;\n         jobTraceFilename \u003d new Path(args[i]);\n         continue;\n       }\n \n-      if (\"-single-line-job-traces\".equals(args[i].toLowerCase())) {\n+      if (\"-single-line-job-traces\".equals(\n+          args[i].toLowerCase(Locale.ENGLISH))) {\n         prettyprintTrace \u003d false;\n         continue;\n       }\n \n-      if (\"-omit-task-details\".equals(args[i].toLowerCase())) {\n+      if (\"-omit-task-details\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n         omitTaskDetails \u003d true;\n         continue;\n       }\n \n-      if (\"-write-topology\".equals(args[i].toLowerCase())) {\n+      if (\"-write-topology\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n         ++i;\n         topologyFilename \u003d new Path(args[i]);\n         continue;\n       }\n \n-      if (\"-job-digest-spectra\".equals(args[i].toLowerCase())) {\n+      if (\"-job-digest-spectra\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n         ArrayList\u003cInteger\u003e values \u003d new ArrayList\u003cInteger\u003e();\n \n         ++i;\n \n         while (i \u003c args.length \u0026\u0026 Character.isDigit(args[i].charAt(0))) {\n           values.add(Integer.parseInt(args[i]));\n           ++i;\n         }\n \n         if (values.size() \u003d\u003d 0) {\n           throw new IllegalArgumentException(\"Empty -job-digest-spectra list\");\n         }\n \n         attemptTimesPercentiles \u003d new int[values.size()];\n \n         int lastValue \u003d 0;\n \n         for (int j \u003d 0; j \u003c attemptTimesPercentiles.length; ++j) {\n           if (values.get(j) \u003c\u003d lastValue || values.get(j) \u003e\u003d 100) {\n             throw new IllegalArgumentException(\n                 \"Bad -job-digest-spectra percentiles list\");\n           }\n           attemptTimesPercentiles[j] \u003d values.get(j);\n         }\n \n         --i;\n         continue;\n       }\n \n-      if (\"-d\".equals(args[i].toLowerCase())\n-          || \"-debug\".equals(args[i].toLowerCase())) {\n+      if (\"-d\".equals(args[i].toLowerCase(Locale.ENGLISH))\n+          || \"-debug\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n         debug \u003d true;\n         continue;\n       }\n \n-      if (\"-spreads\".equals(args[i].toLowerCase())) {\n+      if (\"-spreads\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n         int min \u003d Integer.parseInt(args[i + 1]);\n         int max \u003d Integer.parseInt(args[i + 2]);\n \n         if (min \u003c max \u0026\u0026 min \u003c 1000 \u0026\u0026 max \u003c 1000) {\n           spreadMin \u003d min;\n           spreadMax \u003d max;\n           spreading \u003d true;\n           i +\u003d 2;\n         }\n         continue;\n       }\n \n       // These control log-wide CDF outputs\n-      if (\"-delays\".equals(args[i].toLowerCase())) {\n+      if (\"-delays\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n         delays \u003d true;\n         continue;\n       }\n \n-      if (\"-runtimes\".equals(args[i].toLowerCase())) {\n+      if (\"-runtimes\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n         runtimes \u003d true;\n         continue;\n       }\n \n-      if (\"-tasktimes\".equals(args[i].toLowerCase())) {\n+      if (\"-tasktimes\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n         collectTaskTimes \u003d true;\n         continue;\n       }\n \n-      if (\"-v1\".equals(args[i].toLowerCase())) {\n+      if (\"-v1\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n         version \u003d 1;\n         continue;\n       }\n \n       throw new IllegalArgumentException(\"Unrecognized argument: \" + args[i]);\n     }\n \n     runTimeDists \u003d newDistributionBlock();\n     delayTimeDists \u003d newDistributionBlock();\n     mapTimeSpreadDists \u003d newDistributionBlock(\"map-time-spreads\");\n     shuffleTimeSpreadDists \u003d newDistributionBlock();\n     sortTimeSpreadDists \u003d newDistributionBlock();\n     reduceTimeSpreadDists \u003d newDistributionBlock();\n \n     mapTimeDists \u003d newDistributionBlock();\n     shuffleTimeDists \u003d newDistributionBlock();\n     sortTimeDists \u003d newDistributionBlock();\n     reduceTimeDists \u003d newDistributionBlock();\n \n     taskAttemptStartTimes \u003d new HashMap\u003cString, Long\u003e();\n     taskReduceAttemptShuffleEndTimes \u003d new HashMap\u003cString, Long\u003e();\n     taskReduceAttemptSortEndTimes \u003d new HashMap\u003cString, Long\u003e();\n     taskMapAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n     taskReduceAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n \n     final Path inputPath \u003d new Path(inputFilename);\n \n     inputIsDirectory \u003d pathIsDirectory(inputPath);\n \n     if (jobTraceFilename !\u003d null \u0026\u0026 attemptTimesPercentiles \u003d\u003d null) {\n       attemptTimesPercentiles \u003d new int[19];\n \n       for (int i \u003d 0; i \u003c 19; ++i) {\n         attemptTimesPercentiles[i] \u003d (i + 1) * 5;\n       }\n     }\n \n     if (!inputIsDirectory) {\n       input \u003d maybeUncompressedPath(inputPath);\n     } else {\n       inputDirectoryPath \u003d inputPath;\n       FileSystem fs \u003d inputPath.getFileSystem(getConf());\n       FileStatus[] statuses \u003d fs.listStatus(inputPath);\n       inputDirectoryFiles \u003d new String[statuses.length];\n \n       for (int i \u003d 0; i \u003c statuses.length; ++i) {\n         inputDirectoryFiles[i] \u003d statuses[i].getPath().getName();\n       }\n \n       // filter out the .crc files, if any\n       int dropPoint \u003d 0;\n \n       for (int i \u003d 0; i \u003c inputDirectoryFiles.length; ++i) {\n         String name \u003d inputDirectoryFiles[i];\n \n         if (!(name.length() \u003e\u003d 4 \u0026\u0026 \".crc\".equals(name\n             .substring(name.length() - 4)))) {\n           inputDirectoryFiles[dropPoint++] \u003d name;\n         }\n       }\n \n       LOG.info(\"We dropped \" + (inputDirectoryFiles.length - dropPoint)\n           + \" crc files.\");\n \n       String[] new_inputDirectoryFiles \u003d new String[dropPoint];\n       System.arraycopy(inputDirectoryFiles, 0, new_inputDirectoryFiles, 0,\n           dropPoint);\n       inputDirectoryFiles \u003d new_inputDirectoryFiles;\n \n       Arrays.sort(inputDirectoryFiles);\n \n       if (!setNextDirectoryInputStream()) {\n         throw new FileNotFoundException(\"Empty directory specified.\");\n       }\n     }\n \n     if (jobTraceFilename !\u003d null) {\n       jobTraceGen \u003d new DefaultOutputter\u003cLoggedJob\u003e();\n       jobTraceGen.init(jobTraceFilename, getConf());\n \n       if (topologyFilename !\u003d null) {\n         topologyGen \u003d new DefaultOutputter\u003cLoggedNetworkTopology\u003e();\n         topologyGen.init(topologyFilename, getConf());\n       }\n     }\n \n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int initializeHadoopLogsAnalyzer(String[] args)\n      throws FileNotFoundException, IOException {\n    Path jobTraceFilename \u003d null;\n    Path topologyFilename \u003d null;\n    if (args.length \u003d\u003d 0 || args[args.length - 1].charAt(0) \u003d\u003d \u0027-\u0027) {\n      throw new IllegalArgumentException(\"No input specified.\");\n    } else {\n      inputFilename \u003d args[args.length - 1];\n    }\n\n    for (int i \u003d 0; i \u003c args.length - (inputFilename \u003d\u003d null ? 0 : 1); ++i) {\n      if (\"-h\".equals(args[i].toLowerCase(Locale.ENGLISH))\n          || \"-help\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n        usage();\n        return 0;\n      }\n\n      if (\"-c\".equals(args[i].toLowerCase(Locale.ENGLISH))\n          || \"-collect-prefixes\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n        collecting \u003d true;\n        continue;\n      }\n\n      // these control the job digest\n      if (\"-write-job-trace\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n        ++i;\n        jobTraceFilename \u003d new Path(args[i]);\n        continue;\n      }\n\n      if (\"-single-line-job-traces\".equals(\n          args[i].toLowerCase(Locale.ENGLISH))) {\n        prettyprintTrace \u003d false;\n        continue;\n      }\n\n      if (\"-omit-task-details\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n        omitTaskDetails \u003d true;\n        continue;\n      }\n\n      if (\"-write-topology\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n        ++i;\n        topologyFilename \u003d new Path(args[i]);\n        continue;\n      }\n\n      if (\"-job-digest-spectra\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n        ArrayList\u003cInteger\u003e values \u003d new ArrayList\u003cInteger\u003e();\n\n        ++i;\n\n        while (i \u003c args.length \u0026\u0026 Character.isDigit(args[i].charAt(0))) {\n          values.add(Integer.parseInt(args[i]));\n          ++i;\n        }\n\n        if (values.size() \u003d\u003d 0) {\n          throw new IllegalArgumentException(\"Empty -job-digest-spectra list\");\n        }\n\n        attemptTimesPercentiles \u003d new int[values.size()];\n\n        int lastValue \u003d 0;\n\n        for (int j \u003d 0; j \u003c attemptTimesPercentiles.length; ++j) {\n          if (values.get(j) \u003c\u003d lastValue || values.get(j) \u003e\u003d 100) {\n            throw new IllegalArgumentException(\n                \"Bad -job-digest-spectra percentiles list\");\n          }\n          attemptTimesPercentiles[j] \u003d values.get(j);\n        }\n\n        --i;\n        continue;\n      }\n\n      if (\"-d\".equals(args[i].toLowerCase(Locale.ENGLISH))\n          || \"-debug\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n        debug \u003d true;\n        continue;\n      }\n\n      if (\"-spreads\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n        int min \u003d Integer.parseInt(args[i + 1]);\n        int max \u003d Integer.parseInt(args[i + 2]);\n\n        if (min \u003c max \u0026\u0026 min \u003c 1000 \u0026\u0026 max \u003c 1000) {\n          spreadMin \u003d min;\n          spreadMax \u003d max;\n          spreading \u003d true;\n          i +\u003d 2;\n        }\n        continue;\n      }\n\n      // These control log-wide CDF outputs\n      if (\"-delays\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n        delays \u003d true;\n        continue;\n      }\n\n      if (\"-runtimes\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n        runtimes \u003d true;\n        continue;\n      }\n\n      if (\"-tasktimes\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n        collectTaskTimes \u003d true;\n        continue;\n      }\n\n      if (\"-v1\".equals(args[i].toLowerCase(Locale.ENGLISH))) {\n        version \u003d 1;\n        continue;\n      }\n\n      throw new IllegalArgumentException(\"Unrecognized argument: \" + args[i]);\n    }\n\n    runTimeDists \u003d newDistributionBlock();\n    delayTimeDists \u003d newDistributionBlock();\n    mapTimeSpreadDists \u003d newDistributionBlock(\"map-time-spreads\");\n    shuffleTimeSpreadDists \u003d newDistributionBlock();\n    sortTimeSpreadDists \u003d newDistributionBlock();\n    reduceTimeSpreadDists \u003d newDistributionBlock();\n\n    mapTimeDists \u003d newDistributionBlock();\n    shuffleTimeDists \u003d newDistributionBlock();\n    sortTimeDists \u003d newDistributionBlock();\n    reduceTimeDists \u003d newDistributionBlock();\n\n    taskAttemptStartTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptShuffleEndTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptSortEndTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskMapAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n\n    final Path inputPath \u003d new Path(inputFilename);\n\n    inputIsDirectory \u003d pathIsDirectory(inputPath);\n\n    if (jobTraceFilename !\u003d null \u0026\u0026 attemptTimesPercentiles \u003d\u003d null) {\n      attemptTimesPercentiles \u003d new int[19];\n\n      for (int i \u003d 0; i \u003c 19; ++i) {\n        attemptTimesPercentiles[i] \u003d (i + 1) * 5;\n      }\n    }\n\n    if (!inputIsDirectory) {\n      input \u003d maybeUncompressedPath(inputPath);\n    } else {\n      inputDirectoryPath \u003d inputPath;\n      FileSystem fs \u003d inputPath.getFileSystem(getConf());\n      FileStatus[] statuses \u003d fs.listStatus(inputPath);\n      inputDirectoryFiles \u003d new String[statuses.length];\n\n      for (int i \u003d 0; i \u003c statuses.length; ++i) {\n        inputDirectoryFiles[i] \u003d statuses[i].getPath().getName();\n      }\n\n      // filter out the .crc files, if any\n      int dropPoint \u003d 0;\n\n      for (int i \u003d 0; i \u003c inputDirectoryFiles.length; ++i) {\n        String name \u003d inputDirectoryFiles[i];\n\n        if (!(name.length() \u003e\u003d 4 \u0026\u0026 \".crc\".equals(name\n            .substring(name.length() - 4)))) {\n          inputDirectoryFiles[dropPoint++] \u003d name;\n        }\n      }\n\n      LOG.info(\"We dropped \" + (inputDirectoryFiles.length - dropPoint)\n          + \" crc files.\");\n\n      String[] new_inputDirectoryFiles \u003d new String[dropPoint];\n      System.arraycopy(inputDirectoryFiles, 0, new_inputDirectoryFiles, 0,\n          dropPoint);\n      inputDirectoryFiles \u003d new_inputDirectoryFiles;\n\n      Arrays.sort(inputDirectoryFiles);\n\n      if (!setNextDirectoryInputStream()) {\n        throw new FileNotFoundException(\"Empty directory specified.\");\n      }\n    }\n\n    if (jobTraceFilename !\u003d null) {\n      jobTraceGen \u003d new DefaultOutputter\u003cLoggedJob\u003e();\n      jobTraceGen.init(jobTraceFilename, getConf());\n\n      if (topologyFilename !\u003d null) {\n        topologyGen \u003d new DefaultOutputter\u003cLoggedNetworkTopology\u003e();\n        topologyGen.init(topologyFilename, getConf());\n      }\n    }\n\n    return 0;\n  }",
      "path": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
      "extendedDetails": {}
    },
    "10325d97329c214bb3899c8535df5a366bc86d2f": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-3582. Move successfully passing MR1 tests to MR2 maven tree.(ahmed via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1233090 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/01/12 2:10 PM",
      "commitName": "10325d97329c214bb3899c8535df5a366bc86d2f",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "18/01/12 10:20 AM",
      "commitNameOld": "8b2f6909ec7df5cffb5ef417f5c9cffdee43e38a",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.16,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private int initializeHadoopLogsAnalyzer(String[] args)\n      throws FileNotFoundException, IOException {\n    Path jobTraceFilename \u003d null;\n    Path topologyFilename \u003d null;\n    if (args.length \u003d\u003d 0 || args[args.length - 1].charAt(0) \u003d\u003d \u0027-\u0027) {\n      throw new IllegalArgumentException(\"No input specified.\");\n    } else {\n      inputFilename \u003d args[args.length - 1];\n    }\n\n    for (int i \u003d 0; i \u003c args.length - (inputFilename \u003d\u003d null ? 0 : 1); ++i) {\n      if (\"-h\".equals(args[i].toLowerCase())\n          || \"-help\".equals(args[i].toLowerCase())) {\n        usage();\n        return 0;\n      }\n\n      if (\"-c\".equals(args[i].toLowerCase())\n          || \"-collect-prefixes\".equals(args[i].toLowerCase())) {\n        collecting \u003d true;\n        continue;\n      }\n\n      // these control the job digest\n      if (\"-write-job-trace\".equals(args[i].toLowerCase())) {\n        ++i;\n        jobTraceFilename \u003d new Path(args[i]);\n        continue;\n      }\n\n      if (\"-single-line-job-traces\".equals(args[i].toLowerCase())) {\n        prettyprintTrace \u003d false;\n        continue;\n      }\n\n      if (\"-omit-task-details\".equals(args[i].toLowerCase())) {\n        omitTaskDetails \u003d true;\n        continue;\n      }\n\n      if (\"-write-topology\".equals(args[i].toLowerCase())) {\n        ++i;\n        topologyFilename \u003d new Path(args[i]);\n        continue;\n      }\n\n      if (\"-job-digest-spectra\".equals(args[i].toLowerCase())) {\n        ArrayList\u003cInteger\u003e values \u003d new ArrayList\u003cInteger\u003e();\n\n        ++i;\n\n        while (i \u003c args.length \u0026\u0026 Character.isDigit(args[i].charAt(0))) {\n          values.add(Integer.parseInt(args[i]));\n          ++i;\n        }\n\n        if (values.size() \u003d\u003d 0) {\n          throw new IllegalArgumentException(\"Empty -job-digest-spectra list\");\n        }\n\n        attemptTimesPercentiles \u003d new int[values.size()];\n\n        int lastValue \u003d 0;\n\n        for (int j \u003d 0; j \u003c attemptTimesPercentiles.length; ++j) {\n          if (values.get(j) \u003c\u003d lastValue || values.get(j) \u003e\u003d 100) {\n            throw new IllegalArgumentException(\n                \"Bad -job-digest-spectra percentiles list\");\n          }\n          attemptTimesPercentiles[j] \u003d values.get(j);\n        }\n\n        --i;\n        continue;\n      }\n\n      if (\"-d\".equals(args[i].toLowerCase())\n          || \"-debug\".equals(args[i].toLowerCase())) {\n        debug \u003d true;\n        continue;\n      }\n\n      if (\"-spreads\".equals(args[i].toLowerCase())) {\n        int min \u003d Integer.parseInt(args[i + 1]);\n        int max \u003d Integer.parseInt(args[i + 2]);\n\n        if (min \u003c max \u0026\u0026 min \u003c 1000 \u0026\u0026 max \u003c 1000) {\n          spreadMin \u003d min;\n          spreadMax \u003d max;\n          spreading \u003d true;\n          i +\u003d 2;\n        }\n        continue;\n      }\n\n      // These control log-wide CDF outputs\n      if (\"-delays\".equals(args[i].toLowerCase())) {\n        delays \u003d true;\n        continue;\n      }\n\n      if (\"-runtimes\".equals(args[i].toLowerCase())) {\n        runtimes \u003d true;\n        continue;\n      }\n\n      if (\"-tasktimes\".equals(args[i].toLowerCase())) {\n        collectTaskTimes \u003d true;\n        continue;\n      }\n\n      if (\"-v1\".equals(args[i].toLowerCase())) {\n        version \u003d 1;\n        continue;\n      }\n\n      throw new IllegalArgumentException(\"Unrecognized argument: \" + args[i]);\n    }\n\n    runTimeDists \u003d newDistributionBlock();\n    delayTimeDists \u003d newDistributionBlock();\n    mapTimeSpreadDists \u003d newDistributionBlock(\"map-time-spreads\");\n    shuffleTimeSpreadDists \u003d newDistributionBlock();\n    sortTimeSpreadDists \u003d newDistributionBlock();\n    reduceTimeSpreadDists \u003d newDistributionBlock();\n\n    mapTimeDists \u003d newDistributionBlock();\n    shuffleTimeDists \u003d newDistributionBlock();\n    sortTimeDists \u003d newDistributionBlock();\n    reduceTimeDists \u003d newDistributionBlock();\n\n    taskAttemptStartTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptShuffleEndTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptSortEndTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskMapAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n\n    final Path inputPath \u003d new Path(inputFilename);\n\n    inputIsDirectory \u003d pathIsDirectory(inputPath);\n\n    if (jobTraceFilename !\u003d null \u0026\u0026 attemptTimesPercentiles \u003d\u003d null) {\n      attemptTimesPercentiles \u003d new int[19];\n\n      for (int i \u003d 0; i \u003c 19; ++i) {\n        attemptTimesPercentiles[i] \u003d (i + 1) * 5;\n      }\n    }\n\n    if (!inputIsDirectory) {\n      input \u003d maybeUncompressedPath(inputPath);\n    } else {\n      inputDirectoryPath \u003d inputPath;\n      FileSystem fs \u003d inputPath.getFileSystem(getConf());\n      FileStatus[] statuses \u003d fs.listStatus(inputPath);\n      inputDirectoryFiles \u003d new String[statuses.length];\n\n      for (int i \u003d 0; i \u003c statuses.length; ++i) {\n        inputDirectoryFiles[i] \u003d statuses[i].getPath().getName();\n      }\n\n      // filter out the .crc files, if any\n      int dropPoint \u003d 0;\n\n      for (int i \u003d 0; i \u003c inputDirectoryFiles.length; ++i) {\n        String name \u003d inputDirectoryFiles[i];\n\n        if (!(name.length() \u003e\u003d 4 \u0026\u0026 \".crc\".equals(name\n            .substring(name.length() - 4)))) {\n          inputDirectoryFiles[dropPoint++] \u003d name;\n        }\n      }\n\n      LOG.info(\"We dropped \" + (inputDirectoryFiles.length - dropPoint)\n          + \" crc files.\");\n\n      String[] new_inputDirectoryFiles \u003d new String[dropPoint];\n      System.arraycopy(inputDirectoryFiles, 0, new_inputDirectoryFiles, 0,\n          dropPoint);\n      inputDirectoryFiles \u003d new_inputDirectoryFiles;\n\n      Arrays.sort(inputDirectoryFiles);\n\n      if (!setNextDirectoryInputStream()) {\n        throw new FileNotFoundException(\"Empty directory specified.\");\n      }\n    }\n\n    if (jobTraceFilename !\u003d null) {\n      jobTraceGen \u003d new DefaultOutputter\u003cLoggedJob\u003e();\n      jobTraceGen.init(jobTraceFilename, getConf());\n\n      if (topologyFilename !\u003d null) {\n        topologyGen \u003d new DefaultOutputter\u003cLoggedNetworkTopology\u003e();\n        topologyGen.init(topologyFilename, getConf());\n      }\n    }\n\n    return 0;\n  }",
      "path": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
        "newPath": "hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java"
      }
    },
    "a238f931ea7dce0ca620d1798156c84ff77097ff": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-778. Rumen Anonymizer. (Amar Kamat and Chris Douglas via amarrk)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1215141 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/12/11 6:20 AM",
      "commitName": "a238f931ea7dce0ca620d1798156c84ff77097ff",
      "commitAuthor": "Amar Kamat",
      "commitDateOld": "31/10/11 10:27 AM",
      "commitNameOld": "9db078212f5a37154925cc8872f9adaeca0ed371",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 45.87,
      "commitsBetweenForRepo": 279,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,216 +1,200 @@\n   private int initializeHadoopLogsAnalyzer(String[] args)\n       throws FileNotFoundException, IOException {\n     Path jobTraceFilename \u003d null;\n     Path topologyFilename \u003d null;\n     if (args.length \u003d\u003d 0 || args[args.length - 1].charAt(0) \u003d\u003d \u0027-\u0027) {\n       throw new IllegalArgumentException(\"No input specified.\");\n     } else {\n       inputFilename \u003d args[args.length - 1];\n     }\n \n     for (int i \u003d 0; i \u003c args.length - (inputFilename \u003d\u003d null ? 0 : 1); ++i) {\n       if (\"-h\".equals(args[i].toLowerCase())\n           || \"-help\".equals(args[i].toLowerCase())) {\n         usage();\n         return 0;\n       }\n \n       if (\"-c\".equals(args[i].toLowerCase())\n           || \"-collect-prefixes\".equals(args[i].toLowerCase())) {\n         collecting \u003d true;\n         continue;\n       }\n \n       // these control the job digest\n       if (\"-write-job-trace\".equals(args[i].toLowerCase())) {\n         ++i;\n         jobTraceFilename \u003d new Path(args[i]);\n         continue;\n       }\n \n       if (\"-single-line-job-traces\".equals(args[i].toLowerCase())) {\n         prettyprintTrace \u003d false;\n         continue;\n       }\n \n       if (\"-omit-task-details\".equals(args[i].toLowerCase())) {\n         omitTaskDetails \u003d true;\n         continue;\n       }\n \n       if (\"-write-topology\".equals(args[i].toLowerCase())) {\n         ++i;\n         topologyFilename \u003d new Path(args[i]);\n         continue;\n       }\n \n       if (\"-job-digest-spectra\".equals(args[i].toLowerCase())) {\n         ArrayList\u003cInteger\u003e values \u003d new ArrayList\u003cInteger\u003e();\n \n         ++i;\n \n         while (i \u003c args.length \u0026\u0026 Character.isDigit(args[i].charAt(0))) {\n           values.add(Integer.parseInt(args[i]));\n           ++i;\n         }\n \n         if (values.size() \u003d\u003d 0) {\n           throw new IllegalArgumentException(\"Empty -job-digest-spectra list\");\n         }\n \n         attemptTimesPercentiles \u003d new int[values.size()];\n \n         int lastValue \u003d 0;\n \n         for (int j \u003d 0; j \u003c attemptTimesPercentiles.length; ++j) {\n           if (values.get(j) \u003c\u003d lastValue || values.get(j) \u003e\u003d 100) {\n             throw new IllegalArgumentException(\n                 \"Bad -job-digest-spectra percentiles list\");\n           }\n           attemptTimesPercentiles[j] \u003d values.get(j);\n         }\n \n         --i;\n         continue;\n       }\n \n       if (\"-d\".equals(args[i].toLowerCase())\n           || \"-debug\".equals(args[i].toLowerCase())) {\n         debug \u003d true;\n         continue;\n       }\n \n       if (\"-spreads\".equals(args[i].toLowerCase())) {\n         int min \u003d Integer.parseInt(args[i + 1]);\n         int max \u003d Integer.parseInt(args[i + 2]);\n \n         if (min \u003c max \u0026\u0026 min \u003c 1000 \u0026\u0026 max \u003c 1000) {\n           spreadMin \u003d min;\n           spreadMax \u003d max;\n           spreading \u003d true;\n           i +\u003d 2;\n         }\n         continue;\n       }\n \n       // These control log-wide CDF outputs\n       if (\"-delays\".equals(args[i].toLowerCase())) {\n         delays \u003d true;\n         continue;\n       }\n \n       if (\"-runtimes\".equals(args[i].toLowerCase())) {\n         runtimes \u003d true;\n         continue;\n       }\n \n       if (\"-tasktimes\".equals(args[i].toLowerCase())) {\n         collectTaskTimes \u003d true;\n         continue;\n       }\n \n       if (\"-v1\".equals(args[i].toLowerCase())) {\n         version \u003d 1;\n         continue;\n       }\n \n       throw new IllegalArgumentException(\"Unrecognized argument: \" + args[i]);\n     }\n \n     runTimeDists \u003d newDistributionBlock();\n     delayTimeDists \u003d newDistributionBlock();\n     mapTimeSpreadDists \u003d newDistributionBlock(\"map-time-spreads\");\n     shuffleTimeSpreadDists \u003d newDistributionBlock();\n     sortTimeSpreadDists \u003d newDistributionBlock();\n     reduceTimeSpreadDists \u003d newDistributionBlock();\n \n     mapTimeDists \u003d newDistributionBlock();\n     shuffleTimeDists \u003d newDistributionBlock();\n     sortTimeDists \u003d newDistributionBlock();\n     reduceTimeDists \u003d newDistributionBlock();\n \n     taskAttemptStartTimes \u003d new HashMap\u003cString, Long\u003e();\n     taskReduceAttemptShuffleEndTimes \u003d new HashMap\u003cString, Long\u003e();\n     taskReduceAttemptSortEndTimes \u003d new HashMap\u003cString, Long\u003e();\n     taskMapAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n     taskReduceAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n \n     final Path inputPath \u003d new Path(inputFilename);\n \n     inputIsDirectory \u003d pathIsDirectory(inputPath);\n \n     if (jobTraceFilename !\u003d null \u0026\u0026 attemptTimesPercentiles \u003d\u003d null) {\n       attemptTimesPercentiles \u003d new int[19];\n \n       for (int i \u003d 0; i \u003c 19; ++i) {\n         attemptTimesPercentiles[i] \u003d (i + 1) * 5;\n       }\n     }\n \n     if (!inputIsDirectory) {\n       input \u003d maybeUncompressedPath(inputPath);\n     } else {\n       inputDirectoryPath \u003d inputPath;\n       FileSystem fs \u003d inputPath.getFileSystem(getConf());\n       FileStatus[] statuses \u003d fs.listStatus(inputPath);\n       inputDirectoryFiles \u003d new String[statuses.length];\n \n       for (int i \u003d 0; i \u003c statuses.length; ++i) {\n         inputDirectoryFiles[i] \u003d statuses[i].getPath().getName();\n       }\n \n       // filter out the .crc files, if any\n       int dropPoint \u003d 0;\n \n       for (int i \u003d 0; i \u003c inputDirectoryFiles.length; ++i) {\n         String name \u003d inputDirectoryFiles[i];\n \n         if (!(name.length() \u003e\u003d 4 \u0026\u0026 \".crc\".equals(name\n             .substring(name.length() - 4)))) {\n           inputDirectoryFiles[dropPoint++] \u003d name;\n         }\n       }\n \n       LOG.info(\"We dropped \" + (inputDirectoryFiles.length - dropPoint)\n           + \" crc files.\");\n \n       String[] new_inputDirectoryFiles \u003d new String[dropPoint];\n       System.arraycopy(inputDirectoryFiles, 0, new_inputDirectoryFiles, 0,\n           dropPoint);\n       inputDirectoryFiles \u003d new_inputDirectoryFiles;\n \n       Arrays.sort(inputDirectoryFiles);\n \n       if (!setNextDirectoryInputStream()) {\n         throw new FileNotFoundException(\"Empty directory specified.\");\n       }\n     }\n \n     if (jobTraceFilename !\u003d null) {\n-      ObjectMapper jmapper \u003d new ObjectMapper();\n-      jmapper.configure(\n-          SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n-      JsonFactory jfactory \u003d jmapper.getJsonFactory();\n-      FileSystem jobFS \u003d jobTraceFilename.getFileSystem(getConf());\n-      jobTraceGen \u003d\n-          jfactory.createJsonGenerator(jobFS.create(jobTraceFilename),\n-              JsonEncoding.UTF8);\n-      if (prettyprintTrace) {\n-        jobTraceGen.useDefaultPrettyPrinter();\n-      }\n+      jobTraceGen \u003d new DefaultOutputter\u003cLoggedJob\u003e();\n+      jobTraceGen.init(jobTraceFilename, getConf());\n \n       if (topologyFilename !\u003d null) {\n-        ObjectMapper tmapper \u003d new ObjectMapper();\n-        tmapper.configure(\n-            SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n-        JsonFactory tfactory \u003d tmapper.getJsonFactory();\n-        FileSystem topoFS \u003d topologyFilename.getFileSystem(getConf());\n-        topologyGen \u003d\n-            tfactory.createJsonGenerator(topoFS.create(topologyFilename),\n-                JsonEncoding.UTF8);\n-        topologyGen.useDefaultPrettyPrinter();\n+        topologyGen \u003d new DefaultOutputter\u003cLoggedNetworkTopology\u003e();\n+        topologyGen.init(topologyFilename, getConf());\n       }\n     }\n \n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int initializeHadoopLogsAnalyzer(String[] args)\n      throws FileNotFoundException, IOException {\n    Path jobTraceFilename \u003d null;\n    Path topologyFilename \u003d null;\n    if (args.length \u003d\u003d 0 || args[args.length - 1].charAt(0) \u003d\u003d \u0027-\u0027) {\n      throw new IllegalArgumentException(\"No input specified.\");\n    } else {\n      inputFilename \u003d args[args.length - 1];\n    }\n\n    for (int i \u003d 0; i \u003c args.length - (inputFilename \u003d\u003d null ? 0 : 1); ++i) {\n      if (\"-h\".equals(args[i].toLowerCase())\n          || \"-help\".equals(args[i].toLowerCase())) {\n        usage();\n        return 0;\n      }\n\n      if (\"-c\".equals(args[i].toLowerCase())\n          || \"-collect-prefixes\".equals(args[i].toLowerCase())) {\n        collecting \u003d true;\n        continue;\n      }\n\n      // these control the job digest\n      if (\"-write-job-trace\".equals(args[i].toLowerCase())) {\n        ++i;\n        jobTraceFilename \u003d new Path(args[i]);\n        continue;\n      }\n\n      if (\"-single-line-job-traces\".equals(args[i].toLowerCase())) {\n        prettyprintTrace \u003d false;\n        continue;\n      }\n\n      if (\"-omit-task-details\".equals(args[i].toLowerCase())) {\n        omitTaskDetails \u003d true;\n        continue;\n      }\n\n      if (\"-write-topology\".equals(args[i].toLowerCase())) {\n        ++i;\n        topologyFilename \u003d new Path(args[i]);\n        continue;\n      }\n\n      if (\"-job-digest-spectra\".equals(args[i].toLowerCase())) {\n        ArrayList\u003cInteger\u003e values \u003d new ArrayList\u003cInteger\u003e();\n\n        ++i;\n\n        while (i \u003c args.length \u0026\u0026 Character.isDigit(args[i].charAt(0))) {\n          values.add(Integer.parseInt(args[i]));\n          ++i;\n        }\n\n        if (values.size() \u003d\u003d 0) {\n          throw new IllegalArgumentException(\"Empty -job-digest-spectra list\");\n        }\n\n        attemptTimesPercentiles \u003d new int[values.size()];\n\n        int lastValue \u003d 0;\n\n        for (int j \u003d 0; j \u003c attemptTimesPercentiles.length; ++j) {\n          if (values.get(j) \u003c\u003d lastValue || values.get(j) \u003e\u003d 100) {\n            throw new IllegalArgumentException(\n                \"Bad -job-digest-spectra percentiles list\");\n          }\n          attemptTimesPercentiles[j] \u003d values.get(j);\n        }\n\n        --i;\n        continue;\n      }\n\n      if (\"-d\".equals(args[i].toLowerCase())\n          || \"-debug\".equals(args[i].toLowerCase())) {\n        debug \u003d true;\n        continue;\n      }\n\n      if (\"-spreads\".equals(args[i].toLowerCase())) {\n        int min \u003d Integer.parseInt(args[i + 1]);\n        int max \u003d Integer.parseInt(args[i + 2]);\n\n        if (min \u003c max \u0026\u0026 min \u003c 1000 \u0026\u0026 max \u003c 1000) {\n          spreadMin \u003d min;\n          spreadMax \u003d max;\n          spreading \u003d true;\n          i +\u003d 2;\n        }\n        continue;\n      }\n\n      // These control log-wide CDF outputs\n      if (\"-delays\".equals(args[i].toLowerCase())) {\n        delays \u003d true;\n        continue;\n      }\n\n      if (\"-runtimes\".equals(args[i].toLowerCase())) {\n        runtimes \u003d true;\n        continue;\n      }\n\n      if (\"-tasktimes\".equals(args[i].toLowerCase())) {\n        collectTaskTimes \u003d true;\n        continue;\n      }\n\n      if (\"-v1\".equals(args[i].toLowerCase())) {\n        version \u003d 1;\n        continue;\n      }\n\n      throw new IllegalArgumentException(\"Unrecognized argument: \" + args[i]);\n    }\n\n    runTimeDists \u003d newDistributionBlock();\n    delayTimeDists \u003d newDistributionBlock();\n    mapTimeSpreadDists \u003d newDistributionBlock(\"map-time-spreads\");\n    shuffleTimeSpreadDists \u003d newDistributionBlock();\n    sortTimeSpreadDists \u003d newDistributionBlock();\n    reduceTimeSpreadDists \u003d newDistributionBlock();\n\n    mapTimeDists \u003d newDistributionBlock();\n    shuffleTimeDists \u003d newDistributionBlock();\n    sortTimeDists \u003d newDistributionBlock();\n    reduceTimeDists \u003d newDistributionBlock();\n\n    taskAttemptStartTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptShuffleEndTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptSortEndTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskMapAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n\n    final Path inputPath \u003d new Path(inputFilename);\n\n    inputIsDirectory \u003d pathIsDirectory(inputPath);\n\n    if (jobTraceFilename !\u003d null \u0026\u0026 attemptTimesPercentiles \u003d\u003d null) {\n      attemptTimesPercentiles \u003d new int[19];\n\n      for (int i \u003d 0; i \u003c 19; ++i) {\n        attemptTimesPercentiles[i] \u003d (i + 1) * 5;\n      }\n    }\n\n    if (!inputIsDirectory) {\n      input \u003d maybeUncompressedPath(inputPath);\n    } else {\n      inputDirectoryPath \u003d inputPath;\n      FileSystem fs \u003d inputPath.getFileSystem(getConf());\n      FileStatus[] statuses \u003d fs.listStatus(inputPath);\n      inputDirectoryFiles \u003d new String[statuses.length];\n\n      for (int i \u003d 0; i \u003c statuses.length; ++i) {\n        inputDirectoryFiles[i] \u003d statuses[i].getPath().getName();\n      }\n\n      // filter out the .crc files, if any\n      int dropPoint \u003d 0;\n\n      for (int i \u003d 0; i \u003c inputDirectoryFiles.length; ++i) {\n        String name \u003d inputDirectoryFiles[i];\n\n        if (!(name.length() \u003e\u003d 4 \u0026\u0026 \".crc\".equals(name\n            .substring(name.length() - 4)))) {\n          inputDirectoryFiles[dropPoint++] \u003d name;\n        }\n      }\n\n      LOG.info(\"We dropped \" + (inputDirectoryFiles.length - dropPoint)\n          + \" crc files.\");\n\n      String[] new_inputDirectoryFiles \u003d new String[dropPoint];\n      System.arraycopy(inputDirectoryFiles, 0, new_inputDirectoryFiles, 0,\n          dropPoint);\n      inputDirectoryFiles \u003d new_inputDirectoryFiles;\n\n      Arrays.sort(inputDirectoryFiles);\n\n      if (!setNextDirectoryInputStream()) {\n        throw new FileNotFoundException(\"Empty directory specified.\");\n      }\n    }\n\n    if (jobTraceFilename !\u003d null) {\n      jobTraceGen \u003d new DefaultOutputter\u003cLoggedJob\u003e();\n      jobTraceGen.init(jobTraceFilename, getConf());\n\n      if (topologyFilename !\u003d null) {\n        topologyGen \u003d new DefaultOutputter\u003cLoggedNetworkTopology\u003e();\n        topologyGen.init(topologyFilename, getConf());\n      }\n    }\n\n    return 0;\n  }",
      "path": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private int initializeHadoopLogsAnalyzer(String[] args)\n      throws FileNotFoundException, IOException {\n    Path jobTraceFilename \u003d null;\n    Path topologyFilename \u003d null;\n    if (args.length \u003d\u003d 0 || args[args.length - 1].charAt(0) \u003d\u003d \u0027-\u0027) {\n      throw new IllegalArgumentException(\"No input specified.\");\n    } else {\n      inputFilename \u003d args[args.length - 1];\n    }\n\n    for (int i \u003d 0; i \u003c args.length - (inputFilename \u003d\u003d null ? 0 : 1); ++i) {\n      if (\"-h\".equals(args[i].toLowerCase())\n          || \"-help\".equals(args[i].toLowerCase())) {\n        usage();\n        return 0;\n      }\n\n      if (\"-c\".equals(args[i].toLowerCase())\n          || \"-collect-prefixes\".equals(args[i].toLowerCase())) {\n        collecting \u003d true;\n        continue;\n      }\n\n      // these control the job digest\n      if (\"-write-job-trace\".equals(args[i].toLowerCase())) {\n        ++i;\n        jobTraceFilename \u003d new Path(args[i]);\n        continue;\n      }\n\n      if (\"-single-line-job-traces\".equals(args[i].toLowerCase())) {\n        prettyprintTrace \u003d false;\n        continue;\n      }\n\n      if (\"-omit-task-details\".equals(args[i].toLowerCase())) {\n        omitTaskDetails \u003d true;\n        continue;\n      }\n\n      if (\"-write-topology\".equals(args[i].toLowerCase())) {\n        ++i;\n        topologyFilename \u003d new Path(args[i]);\n        continue;\n      }\n\n      if (\"-job-digest-spectra\".equals(args[i].toLowerCase())) {\n        ArrayList\u003cInteger\u003e values \u003d new ArrayList\u003cInteger\u003e();\n\n        ++i;\n\n        while (i \u003c args.length \u0026\u0026 Character.isDigit(args[i].charAt(0))) {\n          values.add(Integer.parseInt(args[i]));\n          ++i;\n        }\n\n        if (values.size() \u003d\u003d 0) {\n          throw new IllegalArgumentException(\"Empty -job-digest-spectra list\");\n        }\n\n        attemptTimesPercentiles \u003d new int[values.size()];\n\n        int lastValue \u003d 0;\n\n        for (int j \u003d 0; j \u003c attemptTimesPercentiles.length; ++j) {\n          if (values.get(j) \u003c\u003d lastValue || values.get(j) \u003e\u003d 100) {\n            throw new IllegalArgumentException(\n                \"Bad -job-digest-spectra percentiles list\");\n          }\n          attemptTimesPercentiles[j] \u003d values.get(j);\n        }\n\n        --i;\n        continue;\n      }\n\n      if (\"-d\".equals(args[i].toLowerCase())\n          || \"-debug\".equals(args[i].toLowerCase())) {\n        debug \u003d true;\n        continue;\n      }\n\n      if (\"-spreads\".equals(args[i].toLowerCase())) {\n        int min \u003d Integer.parseInt(args[i + 1]);\n        int max \u003d Integer.parseInt(args[i + 2]);\n\n        if (min \u003c max \u0026\u0026 min \u003c 1000 \u0026\u0026 max \u003c 1000) {\n          spreadMin \u003d min;\n          spreadMax \u003d max;\n          spreading \u003d true;\n          i +\u003d 2;\n        }\n        continue;\n      }\n\n      // These control log-wide CDF outputs\n      if (\"-delays\".equals(args[i].toLowerCase())) {\n        delays \u003d true;\n        continue;\n      }\n\n      if (\"-runtimes\".equals(args[i].toLowerCase())) {\n        runtimes \u003d true;\n        continue;\n      }\n\n      if (\"-tasktimes\".equals(args[i].toLowerCase())) {\n        collectTaskTimes \u003d true;\n        continue;\n      }\n\n      if (\"-v1\".equals(args[i].toLowerCase())) {\n        version \u003d 1;\n        continue;\n      }\n\n      throw new IllegalArgumentException(\"Unrecognized argument: \" + args[i]);\n    }\n\n    runTimeDists \u003d newDistributionBlock();\n    delayTimeDists \u003d newDistributionBlock();\n    mapTimeSpreadDists \u003d newDistributionBlock(\"map-time-spreads\");\n    shuffleTimeSpreadDists \u003d newDistributionBlock();\n    sortTimeSpreadDists \u003d newDistributionBlock();\n    reduceTimeSpreadDists \u003d newDistributionBlock();\n\n    mapTimeDists \u003d newDistributionBlock();\n    shuffleTimeDists \u003d newDistributionBlock();\n    sortTimeDists \u003d newDistributionBlock();\n    reduceTimeDists \u003d newDistributionBlock();\n\n    taskAttemptStartTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptShuffleEndTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptSortEndTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskMapAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n\n    final Path inputPath \u003d new Path(inputFilename);\n\n    inputIsDirectory \u003d pathIsDirectory(inputPath);\n\n    if (jobTraceFilename !\u003d null \u0026\u0026 attemptTimesPercentiles \u003d\u003d null) {\n      attemptTimesPercentiles \u003d new int[19];\n\n      for (int i \u003d 0; i \u003c 19; ++i) {\n        attemptTimesPercentiles[i] \u003d (i + 1) * 5;\n      }\n    }\n\n    if (!inputIsDirectory) {\n      input \u003d maybeUncompressedPath(inputPath);\n    } else {\n      inputDirectoryPath \u003d inputPath;\n      FileSystem fs \u003d inputPath.getFileSystem(getConf());\n      FileStatus[] statuses \u003d fs.listStatus(inputPath);\n      inputDirectoryFiles \u003d new String[statuses.length];\n\n      for (int i \u003d 0; i \u003c statuses.length; ++i) {\n        inputDirectoryFiles[i] \u003d statuses[i].getPath().getName();\n      }\n\n      // filter out the .crc files, if any\n      int dropPoint \u003d 0;\n\n      for (int i \u003d 0; i \u003c inputDirectoryFiles.length; ++i) {\n        String name \u003d inputDirectoryFiles[i];\n\n        if (!(name.length() \u003e\u003d 4 \u0026\u0026 \".crc\".equals(name\n            .substring(name.length() - 4)))) {\n          inputDirectoryFiles[dropPoint++] \u003d name;\n        }\n      }\n\n      LOG.info(\"We dropped \" + (inputDirectoryFiles.length - dropPoint)\n          + \" crc files.\");\n\n      String[] new_inputDirectoryFiles \u003d new String[dropPoint];\n      System.arraycopy(inputDirectoryFiles, 0, new_inputDirectoryFiles, 0,\n          dropPoint);\n      inputDirectoryFiles \u003d new_inputDirectoryFiles;\n\n      Arrays.sort(inputDirectoryFiles);\n\n      if (!setNextDirectoryInputStream()) {\n        throw new FileNotFoundException(\"Empty directory specified.\");\n      }\n    }\n\n    if (jobTraceFilename !\u003d null) {\n      ObjectMapper jmapper \u003d new ObjectMapper();\n      jmapper.configure(\n          SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n      JsonFactory jfactory \u003d jmapper.getJsonFactory();\n      FileSystem jobFS \u003d jobTraceFilename.getFileSystem(getConf());\n      jobTraceGen \u003d\n          jfactory.createJsonGenerator(jobFS.create(jobTraceFilename),\n              JsonEncoding.UTF8);\n      if (prettyprintTrace) {\n        jobTraceGen.useDefaultPrettyPrinter();\n      }\n\n      if (topologyFilename !\u003d null) {\n        ObjectMapper tmapper \u003d new ObjectMapper();\n        tmapper.configure(\n            SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n        JsonFactory tfactory \u003d tmapper.getJsonFactory();\n        FileSystem topoFS \u003d topologyFilename.getFileSystem(getConf());\n        topologyGen \u003d\n            tfactory.createJsonGenerator(topoFS.create(topologyFilename),\n                JsonEncoding.UTF8);\n        topologyGen.useDefaultPrettyPrinter();\n      }\n    }\n\n    return 0;\n  }",
      "path": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
        "newPath": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private int initializeHadoopLogsAnalyzer(String[] args)\n      throws FileNotFoundException, IOException {\n    Path jobTraceFilename \u003d null;\n    Path topologyFilename \u003d null;\n    if (args.length \u003d\u003d 0 || args[args.length - 1].charAt(0) \u003d\u003d \u0027-\u0027) {\n      throw new IllegalArgumentException(\"No input specified.\");\n    } else {\n      inputFilename \u003d args[args.length - 1];\n    }\n\n    for (int i \u003d 0; i \u003c args.length - (inputFilename \u003d\u003d null ? 0 : 1); ++i) {\n      if (\"-h\".equals(args[i].toLowerCase())\n          || \"-help\".equals(args[i].toLowerCase())) {\n        usage();\n        return 0;\n      }\n\n      if (\"-c\".equals(args[i].toLowerCase())\n          || \"-collect-prefixes\".equals(args[i].toLowerCase())) {\n        collecting \u003d true;\n        continue;\n      }\n\n      // these control the job digest\n      if (\"-write-job-trace\".equals(args[i].toLowerCase())) {\n        ++i;\n        jobTraceFilename \u003d new Path(args[i]);\n        continue;\n      }\n\n      if (\"-single-line-job-traces\".equals(args[i].toLowerCase())) {\n        prettyprintTrace \u003d false;\n        continue;\n      }\n\n      if (\"-omit-task-details\".equals(args[i].toLowerCase())) {\n        omitTaskDetails \u003d true;\n        continue;\n      }\n\n      if (\"-write-topology\".equals(args[i].toLowerCase())) {\n        ++i;\n        topologyFilename \u003d new Path(args[i]);\n        continue;\n      }\n\n      if (\"-job-digest-spectra\".equals(args[i].toLowerCase())) {\n        ArrayList\u003cInteger\u003e values \u003d new ArrayList\u003cInteger\u003e();\n\n        ++i;\n\n        while (i \u003c args.length \u0026\u0026 Character.isDigit(args[i].charAt(0))) {\n          values.add(Integer.parseInt(args[i]));\n          ++i;\n        }\n\n        if (values.size() \u003d\u003d 0) {\n          throw new IllegalArgumentException(\"Empty -job-digest-spectra list\");\n        }\n\n        attemptTimesPercentiles \u003d new int[values.size()];\n\n        int lastValue \u003d 0;\n\n        for (int j \u003d 0; j \u003c attemptTimesPercentiles.length; ++j) {\n          if (values.get(j) \u003c\u003d lastValue || values.get(j) \u003e\u003d 100) {\n            throw new IllegalArgumentException(\n                \"Bad -job-digest-spectra percentiles list\");\n          }\n          attemptTimesPercentiles[j] \u003d values.get(j);\n        }\n\n        --i;\n        continue;\n      }\n\n      if (\"-d\".equals(args[i].toLowerCase())\n          || \"-debug\".equals(args[i].toLowerCase())) {\n        debug \u003d true;\n        continue;\n      }\n\n      if (\"-spreads\".equals(args[i].toLowerCase())) {\n        int min \u003d Integer.parseInt(args[i + 1]);\n        int max \u003d Integer.parseInt(args[i + 2]);\n\n        if (min \u003c max \u0026\u0026 min \u003c 1000 \u0026\u0026 max \u003c 1000) {\n          spreadMin \u003d min;\n          spreadMax \u003d max;\n          spreading \u003d true;\n          i +\u003d 2;\n        }\n        continue;\n      }\n\n      // These control log-wide CDF outputs\n      if (\"-delays\".equals(args[i].toLowerCase())) {\n        delays \u003d true;\n        continue;\n      }\n\n      if (\"-runtimes\".equals(args[i].toLowerCase())) {\n        runtimes \u003d true;\n        continue;\n      }\n\n      if (\"-tasktimes\".equals(args[i].toLowerCase())) {\n        collectTaskTimes \u003d true;\n        continue;\n      }\n\n      if (\"-v1\".equals(args[i].toLowerCase())) {\n        version \u003d 1;\n        continue;\n      }\n\n      throw new IllegalArgumentException(\"Unrecognized argument: \" + args[i]);\n    }\n\n    runTimeDists \u003d newDistributionBlock();\n    delayTimeDists \u003d newDistributionBlock();\n    mapTimeSpreadDists \u003d newDistributionBlock(\"map-time-spreads\");\n    shuffleTimeSpreadDists \u003d newDistributionBlock();\n    sortTimeSpreadDists \u003d newDistributionBlock();\n    reduceTimeSpreadDists \u003d newDistributionBlock();\n\n    mapTimeDists \u003d newDistributionBlock();\n    shuffleTimeDists \u003d newDistributionBlock();\n    sortTimeDists \u003d newDistributionBlock();\n    reduceTimeDists \u003d newDistributionBlock();\n\n    taskAttemptStartTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptShuffleEndTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptSortEndTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskMapAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n\n    final Path inputPath \u003d new Path(inputFilename);\n\n    inputIsDirectory \u003d pathIsDirectory(inputPath);\n\n    if (jobTraceFilename !\u003d null \u0026\u0026 attemptTimesPercentiles \u003d\u003d null) {\n      attemptTimesPercentiles \u003d new int[19];\n\n      for (int i \u003d 0; i \u003c 19; ++i) {\n        attemptTimesPercentiles[i] \u003d (i + 1) * 5;\n      }\n    }\n\n    if (!inputIsDirectory) {\n      input \u003d maybeUncompressedPath(inputPath);\n    } else {\n      inputDirectoryPath \u003d inputPath;\n      FileSystem fs \u003d inputPath.getFileSystem(getConf());\n      FileStatus[] statuses \u003d fs.listStatus(inputPath);\n      inputDirectoryFiles \u003d new String[statuses.length];\n\n      for (int i \u003d 0; i \u003c statuses.length; ++i) {\n        inputDirectoryFiles[i] \u003d statuses[i].getPath().getName();\n      }\n\n      // filter out the .crc files, if any\n      int dropPoint \u003d 0;\n\n      for (int i \u003d 0; i \u003c inputDirectoryFiles.length; ++i) {\n        String name \u003d inputDirectoryFiles[i];\n\n        if (!(name.length() \u003e\u003d 4 \u0026\u0026 \".crc\".equals(name\n            .substring(name.length() - 4)))) {\n          inputDirectoryFiles[dropPoint++] \u003d name;\n        }\n      }\n\n      LOG.info(\"We dropped \" + (inputDirectoryFiles.length - dropPoint)\n          + \" crc files.\");\n\n      String[] new_inputDirectoryFiles \u003d new String[dropPoint];\n      System.arraycopy(inputDirectoryFiles, 0, new_inputDirectoryFiles, 0,\n          dropPoint);\n      inputDirectoryFiles \u003d new_inputDirectoryFiles;\n\n      Arrays.sort(inputDirectoryFiles);\n\n      if (!setNextDirectoryInputStream()) {\n        throw new FileNotFoundException(\"Empty directory specified.\");\n      }\n    }\n\n    if (jobTraceFilename !\u003d null) {\n      ObjectMapper jmapper \u003d new ObjectMapper();\n      jmapper.configure(\n          SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n      JsonFactory jfactory \u003d jmapper.getJsonFactory();\n      FileSystem jobFS \u003d jobTraceFilename.getFileSystem(getConf());\n      jobTraceGen \u003d\n          jfactory.createJsonGenerator(jobFS.create(jobTraceFilename),\n              JsonEncoding.UTF8);\n      if (prettyprintTrace) {\n        jobTraceGen.useDefaultPrettyPrinter();\n      }\n\n      if (topologyFilename !\u003d null) {\n        ObjectMapper tmapper \u003d new ObjectMapper();\n        tmapper.configure(\n            SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n        JsonFactory tfactory \u003d tmapper.getJsonFactory();\n        FileSystem topoFS \u003d topologyFilename.getFileSystem(getConf());\n        topologyGen \u003d\n            tfactory.createJsonGenerator(topoFS.create(topologyFilename),\n                JsonEncoding.UTF8);\n        topologyGen.useDefaultPrettyPrinter();\n      }\n    }\n\n    return 0;\n  }",
      "path": "hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java",
        "newPath": "hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,216 @@\n+  private int initializeHadoopLogsAnalyzer(String[] args)\n+      throws FileNotFoundException, IOException {\n+    Path jobTraceFilename \u003d null;\n+    Path topologyFilename \u003d null;\n+    if (args.length \u003d\u003d 0 || args[args.length - 1].charAt(0) \u003d\u003d \u0027-\u0027) {\n+      throw new IllegalArgumentException(\"No input specified.\");\n+    } else {\n+      inputFilename \u003d args[args.length - 1];\n+    }\n+\n+    for (int i \u003d 0; i \u003c args.length - (inputFilename \u003d\u003d null ? 0 : 1); ++i) {\n+      if (\"-h\".equals(args[i].toLowerCase())\n+          || \"-help\".equals(args[i].toLowerCase())) {\n+        usage();\n+        return 0;\n+      }\n+\n+      if (\"-c\".equals(args[i].toLowerCase())\n+          || \"-collect-prefixes\".equals(args[i].toLowerCase())) {\n+        collecting \u003d true;\n+        continue;\n+      }\n+\n+      // these control the job digest\n+      if (\"-write-job-trace\".equals(args[i].toLowerCase())) {\n+        ++i;\n+        jobTraceFilename \u003d new Path(args[i]);\n+        continue;\n+      }\n+\n+      if (\"-single-line-job-traces\".equals(args[i].toLowerCase())) {\n+        prettyprintTrace \u003d false;\n+        continue;\n+      }\n+\n+      if (\"-omit-task-details\".equals(args[i].toLowerCase())) {\n+        omitTaskDetails \u003d true;\n+        continue;\n+      }\n+\n+      if (\"-write-topology\".equals(args[i].toLowerCase())) {\n+        ++i;\n+        topologyFilename \u003d new Path(args[i]);\n+        continue;\n+      }\n+\n+      if (\"-job-digest-spectra\".equals(args[i].toLowerCase())) {\n+        ArrayList\u003cInteger\u003e values \u003d new ArrayList\u003cInteger\u003e();\n+\n+        ++i;\n+\n+        while (i \u003c args.length \u0026\u0026 Character.isDigit(args[i].charAt(0))) {\n+          values.add(Integer.parseInt(args[i]));\n+          ++i;\n+        }\n+\n+        if (values.size() \u003d\u003d 0) {\n+          throw new IllegalArgumentException(\"Empty -job-digest-spectra list\");\n+        }\n+\n+        attemptTimesPercentiles \u003d new int[values.size()];\n+\n+        int lastValue \u003d 0;\n+\n+        for (int j \u003d 0; j \u003c attemptTimesPercentiles.length; ++j) {\n+          if (values.get(j) \u003c\u003d lastValue || values.get(j) \u003e\u003d 100) {\n+            throw new IllegalArgumentException(\n+                \"Bad -job-digest-spectra percentiles list\");\n+          }\n+          attemptTimesPercentiles[j] \u003d values.get(j);\n+        }\n+\n+        --i;\n+        continue;\n+      }\n+\n+      if (\"-d\".equals(args[i].toLowerCase())\n+          || \"-debug\".equals(args[i].toLowerCase())) {\n+        debug \u003d true;\n+        continue;\n+      }\n+\n+      if (\"-spreads\".equals(args[i].toLowerCase())) {\n+        int min \u003d Integer.parseInt(args[i + 1]);\n+        int max \u003d Integer.parseInt(args[i + 2]);\n+\n+        if (min \u003c max \u0026\u0026 min \u003c 1000 \u0026\u0026 max \u003c 1000) {\n+          spreadMin \u003d min;\n+          spreadMax \u003d max;\n+          spreading \u003d true;\n+          i +\u003d 2;\n+        }\n+        continue;\n+      }\n+\n+      // These control log-wide CDF outputs\n+      if (\"-delays\".equals(args[i].toLowerCase())) {\n+        delays \u003d true;\n+        continue;\n+      }\n+\n+      if (\"-runtimes\".equals(args[i].toLowerCase())) {\n+        runtimes \u003d true;\n+        continue;\n+      }\n+\n+      if (\"-tasktimes\".equals(args[i].toLowerCase())) {\n+        collectTaskTimes \u003d true;\n+        continue;\n+      }\n+\n+      if (\"-v1\".equals(args[i].toLowerCase())) {\n+        version \u003d 1;\n+        continue;\n+      }\n+\n+      throw new IllegalArgumentException(\"Unrecognized argument: \" + args[i]);\n+    }\n+\n+    runTimeDists \u003d newDistributionBlock();\n+    delayTimeDists \u003d newDistributionBlock();\n+    mapTimeSpreadDists \u003d newDistributionBlock(\"map-time-spreads\");\n+    shuffleTimeSpreadDists \u003d newDistributionBlock();\n+    sortTimeSpreadDists \u003d newDistributionBlock();\n+    reduceTimeSpreadDists \u003d newDistributionBlock();\n+\n+    mapTimeDists \u003d newDistributionBlock();\n+    shuffleTimeDists \u003d newDistributionBlock();\n+    sortTimeDists \u003d newDistributionBlock();\n+    reduceTimeDists \u003d newDistributionBlock();\n+\n+    taskAttemptStartTimes \u003d new HashMap\u003cString, Long\u003e();\n+    taskReduceAttemptShuffleEndTimes \u003d new HashMap\u003cString, Long\u003e();\n+    taskReduceAttemptSortEndTimes \u003d new HashMap\u003cString, Long\u003e();\n+    taskMapAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n+    taskReduceAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n+\n+    final Path inputPath \u003d new Path(inputFilename);\n+\n+    inputIsDirectory \u003d pathIsDirectory(inputPath);\n+\n+    if (jobTraceFilename !\u003d null \u0026\u0026 attemptTimesPercentiles \u003d\u003d null) {\n+      attemptTimesPercentiles \u003d new int[19];\n+\n+      for (int i \u003d 0; i \u003c 19; ++i) {\n+        attemptTimesPercentiles[i] \u003d (i + 1) * 5;\n+      }\n+    }\n+\n+    if (!inputIsDirectory) {\n+      input \u003d maybeUncompressedPath(inputPath);\n+    } else {\n+      inputDirectoryPath \u003d inputPath;\n+      FileSystem fs \u003d inputPath.getFileSystem(getConf());\n+      FileStatus[] statuses \u003d fs.listStatus(inputPath);\n+      inputDirectoryFiles \u003d new String[statuses.length];\n+\n+      for (int i \u003d 0; i \u003c statuses.length; ++i) {\n+        inputDirectoryFiles[i] \u003d statuses[i].getPath().getName();\n+      }\n+\n+      // filter out the .crc files, if any\n+      int dropPoint \u003d 0;\n+\n+      for (int i \u003d 0; i \u003c inputDirectoryFiles.length; ++i) {\n+        String name \u003d inputDirectoryFiles[i];\n+\n+        if (!(name.length() \u003e\u003d 4 \u0026\u0026 \".crc\".equals(name\n+            .substring(name.length() - 4)))) {\n+          inputDirectoryFiles[dropPoint++] \u003d name;\n+        }\n+      }\n+\n+      LOG.info(\"We dropped \" + (inputDirectoryFiles.length - dropPoint)\n+          + \" crc files.\");\n+\n+      String[] new_inputDirectoryFiles \u003d new String[dropPoint];\n+      System.arraycopy(inputDirectoryFiles, 0, new_inputDirectoryFiles, 0,\n+          dropPoint);\n+      inputDirectoryFiles \u003d new_inputDirectoryFiles;\n+\n+      Arrays.sort(inputDirectoryFiles);\n+\n+      if (!setNextDirectoryInputStream()) {\n+        throw new FileNotFoundException(\"Empty directory specified.\");\n+      }\n+    }\n+\n+    if (jobTraceFilename !\u003d null) {\n+      ObjectMapper jmapper \u003d new ObjectMapper();\n+      jmapper.configure(\n+          SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n+      JsonFactory jfactory \u003d jmapper.getJsonFactory();\n+      FileSystem jobFS \u003d jobTraceFilename.getFileSystem(getConf());\n+      jobTraceGen \u003d\n+          jfactory.createJsonGenerator(jobFS.create(jobTraceFilename),\n+              JsonEncoding.UTF8);\n+      if (prettyprintTrace) {\n+        jobTraceGen.useDefaultPrettyPrinter();\n+      }\n+\n+      if (topologyFilename !\u003d null) {\n+        ObjectMapper tmapper \u003d new ObjectMapper();\n+        tmapper.configure(\n+            SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n+        JsonFactory tfactory \u003d tmapper.getJsonFactory();\n+        FileSystem topoFS \u003d topologyFilename.getFileSystem(getConf());\n+        topologyGen \u003d\n+            tfactory.createJsonGenerator(topoFS.create(topologyFilename),\n+                JsonEncoding.UTF8);\n+        topologyGen.useDefaultPrettyPrinter();\n+      }\n+    }\n+\n+    return 0;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private int initializeHadoopLogsAnalyzer(String[] args)\n      throws FileNotFoundException, IOException {\n    Path jobTraceFilename \u003d null;\n    Path topologyFilename \u003d null;\n    if (args.length \u003d\u003d 0 || args[args.length - 1].charAt(0) \u003d\u003d \u0027-\u0027) {\n      throw new IllegalArgumentException(\"No input specified.\");\n    } else {\n      inputFilename \u003d args[args.length - 1];\n    }\n\n    for (int i \u003d 0; i \u003c args.length - (inputFilename \u003d\u003d null ? 0 : 1); ++i) {\n      if (\"-h\".equals(args[i].toLowerCase())\n          || \"-help\".equals(args[i].toLowerCase())) {\n        usage();\n        return 0;\n      }\n\n      if (\"-c\".equals(args[i].toLowerCase())\n          || \"-collect-prefixes\".equals(args[i].toLowerCase())) {\n        collecting \u003d true;\n        continue;\n      }\n\n      // these control the job digest\n      if (\"-write-job-trace\".equals(args[i].toLowerCase())) {\n        ++i;\n        jobTraceFilename \u003d new Path(args[i]);\n        continue;\n      }\n\n      if (\"-single-line-job-traces\".equals(args[i].toLowerCase())) {\n        prettyprintTrace \u003d false;\n        continue;\n      }\n\n      if (\"-omit-task-details\".equals(args[i].toLowerCase())) {\n        omitTaskDetails \u003d true;\n        continue;\n      }\n\n      if (\"-write-topology\".equals(args[i].toLowerCase())) {\n        ++i;\n        topologyFilename \u003d new Path(args[i]);\n        continue;\n      }\n\n      if (\"-job-digest-spectra\".equals(args[i].toLowerCase())) {\n        ArrayList\u003cInteger\u003e values \u003d new ArrayList\u003cInteger\u003e();\n\n        ++i;\n\n        while (i \u003c args.length \u0026\u0026 Character.isDigit(args[i].charAt(0))) {\n          values.add(Integer.parseInt(args[i]));\n          ++i;\n        }\n\n        if (values.size() \u003d\u003d 0) {\n          throw new IllegalArgumentException(\"Empty -job-digest-spectra list\");\n        }\n\n        attemptTimesPercentiles \u003d new int[values.size()];\n\n        int lastValue \u003d 0;\n\n        for (int j \u003d 0; j \u003c attemptTimesPercentiles.length; ++j) {\n          if (values.get(j) \u003c\u003d lastValue || values.get(j) \u003e\u003d 100) {\n            throw new IllegalArgumentException(\n                \"Bad -job-digest-spectra percentiles list\");\n          }\n          attemptTimesPercentiles[j] \u003d values.get(j);\n        }\n\n        --i;\n        continue;\n      }\n\n      if (\"-d\".equals(args[i].toLowerCase())\n          || \"-debug\".equals(args[i].toLowerCase())) {\n        debug \u003d true;\n        continue;\n      }\n\n      if (\"-spreads\".equals(args[i].toLowerCase())) {\n        int min \u003d Integer.parseInt(args[i + 1]);\n        int max \u003d Integer.parseInt(args[i + 2]);\n\n        if (min \u003c max \u0026\u0026 min \u003c 1000 \u0026\u0026 max \u003c 1000) {\n          spreadMin \u003d min;\n          spreadMax \u003d max;\n          spreading \u003d true;\n          i +\u003d 2;\n        }\n        continue;\n      }\n\n      // These control log-wide CDF outputs\n      if (\"-delays\".equals(args[i].toLowerCase())) {\n        delays \u003d true;\n        continue;\n      }\n\n      if (\"-runtimes\".equals(args[i].toLowerCase())) {\n        runtimes \u003d true;\n        continue;\n      }\n\n      if (\"-tasktimes\".equals(args[i].toLowerCase())) {\n        collectTaskTimes \u003d true;\n        continue;\n      }\n\n      if (\"-v1\".equals(args[i].toLowerCase())) {\n        version \u003d 1;\n        continue;\n      }\n\n      throw new IllegalArgumentException(\"Unrecognized argument: \" + args[i]);\n    }\n\n    runTimeDists \u003d newDistributionBlock();\n    delayTimeDists \u003d newDistributionBlock();\n    mapTimeSpreadDists \u003d newDistributionBlock(\"map-time-spreads\");\n    shuffleTimeSpreadDists \u003d newDistributionBlock();\n    sortTimeSpreadDists \u003d newDistributionBlock();\n    reduceTimeSpreadDists \u003d newDistributionBlock();\n\n    mapTimeDists \u003d newDistributionBlock();\n    shuffleTimeDists \u003d newDistributionBlock();\n    sortTimeDists \u003d newDistributionBlock();\n    reduceTimeDists \u003d newDistributionBlock();\n\n    taskAttemptStartTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptShuffleEndTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptSortEndTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskMapAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n    taskReduceAttemptFinishTimes \u003d new HashMap\u003cString, Long\u003e();\n\n    final Path inputPath \u003d new Path(inputFilename);\n\n    inputIsDirectory \u003d pathIsDirectory(inputPath);\n\n    if (jobTraceFilename !\u003d null \u0026\u0026 attemptTimesPercentiles \u003d\u003d null) {\n      attemptTimesPercentiles \u003d new int[19];\n\n      for (int i \u003d 0; i \u003c 19; ++i) {\n        attemptTimesPercentiles[i] \u003d (i + 1) * 5;\n      }\n    }\n\n    if (!inputIsDirectory) {\n      input \u003d maybeUncompressedPath(inputPath);\n    } else {\n      inputDirectoryPath \u003d inputPath;\n      FileSystem fs \u003d inputPath.getFileSystem(getConf());\n      FileStatus[] statuses \u003d fs.listStatus(inputPath);\n      inputDirectoryFiles \u003d new String[statuses.length];\n\n      for (int i \u003d 0; i \u003c statuses.length; ++i) {\n        inputDirectoryFiles[i] \u003d statuses[i].getPath().getName();\n      }\n\n      // filter out the .crc files, if any\n      int dropPoint \u003d 0;\n\n      for (int i \u003d 0; i \u003c inputDirectoryFiles.length; ++i) {\n        String name \u003d inputDirectoryFiles[i];\n\n        if (!(name.length() \u003e\u003d 4 \u0026\u0026 \".crc\".equals(name\n            .substring(name.length() - 4)))) {\n          inputDirectoryFiles[dropPoint++] \u003d name;\n        }\n      }\n\n      LOG.info(\"We dropped \" + (inputDirectoryFiles.length - dropPoint)\n          + \" crc files.\");\n\n      String[] new_inputDirectoryFiles \u003d new String[dropPoint];\n      System.arraycopy(inputDirectoryFiles, 0, new_inputDirectoryFiles, 0,\n          dropPoint);\n      inputDirectoryFiles \u003d new_inputDirectoryFiles;\n\n      Arrays.sort(inputDirectoryFiles);\n\n      if (!setNextDirectoryInputStream()) {\n        throw new FileNotFoundException(\"Empty directory specified.\");\n      }\n    }\n\n    if (jobTraceFilename !\u003d null) {\n      ObjectMapper jmapper \u003d new ObjectMapper();\n      jmapper.configure(\n          SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n      JsonFactory jfactory \u003d jmapper.getJsonFactory();\n      FileSystem jobFS \u003d jobTraceFilename.getFileSystem(getConf());\n      jobTraceGen \u003d\n          jfactory.createJsonGenerator(jobFS.create(jobTraceFilename),\n              JsonEncoding.UTF8);\n      if (prettyprintTrace) {\n        jobTraceGen.useDefaultPrettyPrinter();\n      }\n\n      if (topologyFilename !\u003d null) {\n        ObjectMapper tmapper \u003d new ObjectMapper();\n        tmapper.configure(\n            SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n        JsonFactory tfactory \u003d tmapper.getJsonFactory();\n        FileSystem topoFS \u003d topologyFilename.getFileSystem(getConf());\n        topologyGen \u003d\n            tfactory.createJsonGenerator(topoFS.create(topologyFilename),\n                JsonEncoding.UTF8);\n        topologyGen.useDefaultPrettyPrinter();\n      }\n    }\n\n    return 0;\n  }",
      "path": "mapreduce/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java"
    }
  }
}