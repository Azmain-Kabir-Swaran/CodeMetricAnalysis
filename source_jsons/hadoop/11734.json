{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PmemVolumeManager.java",
  "functionName": "getCachePath",
  "functionId": "getCachePath___key-ExtendedBlockId",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/PmemVolumeManager.java",
  "functionStartLine": 466,
  "functionEndLine": 472,
  "numCommitsSeen": 5,
  "timeTaken": 3440,
  "changeHistory": [
    "d79cce20abbbf321f6dcce03f4087544124a7cd2",
    "9b0aace1e6c54f201784912c0b623707aa82b761",
    "35ff31dd9462cf4fb4ebf5556ee8ae6bcd7c5c3a"
  ],
  "changeHistoryShort": {
    "d79cce20abbbf321f6dcce03f4087544124a7cd2": "Ymultichange(Yexceptionschange,Ybodychange)",
    "9b0aace1e6c54f201784912c0b623707aa82b761": "Yrename",
    "35ff31dd9462cf4fb4ebf5556ee8ae6bcd7c5c3a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d79cce20abbbf321f6dcce03f4087544124a7cd2": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-14740. Recover data blocks from persistent memory read cache during datanode restarts. Contributed by Feilong He.\n",
      "commitDate": "01/01/20 10:14 PM",
      "commitName": "d79cce20abbbf321f6dcce03f4087544124a7cd2",
      "commitAuthor": "Rakesh Radhakrishnan",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-14740. Recover data blocks from persistent memory read cache during datanode restarts. Contributed by Feilong He.\n",
          "commitDate": "01/01/20 10:14 PM",
          "commitName": "d79cce20abbbf321f6dcce03f4087544124a7cd2",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "09/08/19 1:37 AM",
          "commitNameOld": "f6fa865d6fcb0ef0a25a00615f16f383e5032373",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 145.9,
          "commitsBetweenForRepo": 853,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,7 @@\n-  public String getCachePath(ExtendedBlockId key) {\n+  public String getCachePath(ExtendedBlockId key) throws IOException {\n     Byte volumeIndex \u003d blockKeyToVolume.get(key);\n     if (volumeIndex \u003d\u003d null) {\n       return  null;\n     }\n-    return inferCacheFilePath(volumeIndex, key);\n+    return idToCacheFilePath(volumeIndex, key);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public String getCachePath(ExtendedBlockId key) throws IOException {\n    Byte volumeIndex \u003d blockKeyToVolume.get(key);\n    if (volumeIndex \u003d\u003d null) {\n      return  null;\n    }\n    return idToCacheFilePath(volumeIndex, key);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/PmemVolumeManager.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-14740. Recover data blocks from persistent memory read cache during datanode restarts. Contributed by Feilong He.\n",
          "commitDate": "01/01/20 10:14 PM",
          "commitName": "d79cce20abbbf321f6dcce03f4087544124a7cd2",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "09/08/19 1:37 AM",
          "commitNameOld": "f6fa865d6fcb0ef0a25a00615f16f383e5032373",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 145.9,
          "commitsBetweenForRepo": 853,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,7 +1,7 @@\n-  public String getCachePath(ExtendedBlockId key) {\n+  public String getCachePath(ExtendedBlockId key) throws IOException {\n     Byte volumeIndex \u003d blockKeyToVolume.get(key);\n     if (volumeIndex \u003d\u003d null) {\n       return  null;\n     }\n-    return inferCacheFilePath(volumeIndex, key);\n+    return idToCacheFilePath(volumeIndex, key);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public String getCachePath(ExtendedBlockId key) throws IOException {\n    Byte volumeIndex \u003d blockKeyToVolume.get(key);\n    if (volumeIndex \u003d\u003d null) {\n      return  null;\n    }\n    return idToCacheFilePath(volumeIndex, key);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/PmemVolumeManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "9b0aace1e6c54f201784912c0b623707aa82b761": {
      "type": "Yrename",
      "commitMessage": "HDFS-14401. Refine the implementation for HDFS cache on SCM. Contributed by Feilong He.\n",
      "commitDate": "08/05/19 4:50 AM",
      "commitName": "9b0aace1e6c54f201784912c0b623707aa82b761",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "30/03/19 11:33 PM",
      "commitNameOld": "35ff31dd9462cf4fb4ebf5556ee8ae6bcd7c5c3a",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 38.22,
      "commitsBetweenForRepo": 236,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n-  public String getCacheFilePath(ExtendedBlockId key) {\n+  public String getCachePath(ExtendedBlockId key) {\n     Byte volumeIndex \u003d blockKeyToVolume.get(key);\n     if (volumeIndex \u003d\u003d null) {\n       return  null;\n     }\n     return inferCacheFilePath(volumeIndex, key);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String getCachePath(ExtendedBlockId key) {\n    Byte volumeIndex \u003d blockKeyToVolume.get(key);\n    if (volumeIndex \u003d\u003d null) {\n      return  null;\n    }\n    return inferCacheFilePath(volumeIndex, key);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/PmemVolumeManager.java",
      "extendedDetails": {
        "oldValue": "getCacheFilePath",
        "newValue": "getCachePath"
      }
    },
    "35ff31dd9462cf4fb4ebf5556ee8ae6bcd7c5c3a": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-14355 : Implement HDFS cache on SCM by using pure java mapped byte buffer. Contributed by Feilong He.\n",
      "commitDate": "30/03/19 11:33 PM",
      "commitName": "35ff31dd9462cf4fb4ebf5556ee8ae6bcd7c5c3a",
      "commitAuthor": "Uma Maheswara Rao G",
      "diff": "@@ -0,0 +1,7 @@\n+  public String getCacheFilePath(ExtendedBlockId key) {\n+    Byte volumeIndex \u003d blockKeyToVolume.get(key);\n+    if (volumeIndex \u003d\u003d null) {\n+      return  null;\n+    }\n+    return inferCacheFilePath(volumeIndex, key);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public String getCacheFilePath(ExtendedBlockId key) {\n    Byte volumeIndex \u003d blockKeyToVolume.get(key);\n    if (volumeIndex \u003d\u003d null) {\n      return  null;\n    }\n    return inferCacheFilePath(volumeIndex, key);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/PmemVolumeManager.java"
    }
  }
}