{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ReduceTask.java",
  "functionName": "run",
  "functionId": "run___job-JobConf__umbilical-TaskUmbilicalProtocol(modifiers-final)",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java",
  "functionStartLine": 320,
  "functionEndLine": 399,
  "numCommitsSeen": 16,
  "timeTaken": 9118,
  "changeHistory": [
    "0cb2fdc3b4fbbaa6153b6421a63082dc006f8eb4",
    "b096f61fe25752703785cad5fe0aaae8bf45da2f",
    "94e1703b7250117d6b18ef181f77bc58b5740cf9",
    "42e93829e5310f3cbd905384cd0529f8fffa887f",
    "6b343adfe880c7e9e2f441fd889cf16a8657c335",
    "482d840bcf3e8332e513bcea61f6d4ea7ee8579d",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "ded6f225a55517deedc2bd502f2b68f1ca2ddee8",
    "9bac807cedbcff34e1a144fb475eff267e5ed86d",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "0cb2fdc3b4fbbaa6153b6421a63082dc006f8eb4": "Ybodychange",
    "b096f61fe25752703785cad5fe0aaae8bf45da2f": "Ybodychange",
    "94e1703b7250117d6b18ef181f77bc58b5740cf9": "Ybodychange",
    "42e93829e5310f3cbd905384cd0529f8fffa887f": "Ybodychange",
    "6b343adfe880c7e9e2f441fd889cf16a8657c335": "Ybodychange",
    "482d840bcf3e8332e513bcea61f6d4ea7ee8579d": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Ymultichange(Ymovefromfile,Ybodychange)",
    "ded6f225a55517deedc2bd502f2b68f1ca2ddee8": "Ybodychange",
    "9bac807cedbcff34e1a144fb475eff267e5ed86d": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "0cb2fdc3b4fbbaa6153b6421a63082dc006f8eb4": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-434. LocalJobRunner limited to single reducer (Sandy Ryza and Aaron Kimball via Sandy Ryza)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1510866 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/08/13 11:36 PM",
      "commitName": "0cb2fdc3b4fbbaa6153b6421a63082dc006f8eb4",
      "commitAuthor": "Sanford Ryza",
      "commitDateOld": "24/04/13 10:38 AM",
      "commitNameOld": "40e78c2ca23bcc56e7ceadd30421c05dbad17a1e",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 103.54,
      "commitsBetweenForRepo": 654,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,105 +1,80 @@\n   public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n     throws IOException, InterruptedException, ClassNotFoundException {\n     job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n \n     if (isMapOrReduce()) {\n       copyPhase \u003d getProgress().addPhase(\"copy\");\n       sortPhase  \u003d getProgress().addPhase(\"sort\");\n       reducePhase \u003d getProgress().addPhase(\"reduce\");\n     }\n     // start thread that will handle communication with parent\n     TaskReporter reporter \u003d startReporter(umbilical);\n     \n     boolean useNewApi \u003d job.getUseNewReducer();\n     initialize(job, getJobID(), reporter, useNewApi);\n \n     // check if it is a cleanupJobTask\n     if (jobCleanup) {\n       runJobCleanupTask(umbilical, reporter);\n       return;\n     }\n     if (jobSetup) {\n       runJobSetupTask(umbilical, reporter);\n       return;\n     }\n     if (taskCleanup) {\n       runTaskCleanupTask(umbilical, reporter);\n       return;\n     }\n     \n     // Initialize the codec\n     codec \u003d initCodec();\n     RawKeyValueIterator rIter \u003d null;\n-    ShuffleConsumerPlugin shuffleConsumerPlugin \u003d null; \n+    ShuffleConsumerPlugin shuffleConsumerPlugin \u003d null;\n     \n-    boolean isLocal \u003d false; \n-    // local if\n-    // 1) framework \u003d\u003d local or\n-    // 2) framework \u003d\u003d null and job tracker address \u003d\u003d local\n-    String framework \u003d job.get(MRConfig.FRAMEWORK_NAME);\n-    String masterAddr \u003d job.get(MRConfig.MASTER_ADDRESS, \"local\");\n-    if ((framework \u003d\u003d null \u0026\u0026 masterAddr.equals(\"local\"))\n-        || (framework !\u003d null \u0026\u0026 framework.equals(MRConfig.LOCAL_FRAMEWORK_NAME))) {\n-      isLocal \u003d true;\n-    }\n-    \n-    if (!isLocal) {\n-      Class combinerClass \u003d conf.getCombinerClass();\n-      CombineOutputCollector combineCollector \u003d \n-        (null !\u003d combinerClass) ? \n- \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n+    Class combinerClass \u003d conf.getCombinerClass();\n+    CombineOutputCollector combineCollector \u003d \n+      (null !\u003d combinerClass) ? \n+     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n \n-      Class\u003c? extends ShuffleConsumerPlugin\u003e clazz \u003d\n-            job.getClass(MRConfig.SHUFFLE_CONSUMER_PLUGIN, Shuffle.class, ShuffleConsumerPlugin.class);\n-\t\t\t\t\t\t\n-      shuffleConsumerPlugin \u003d ReflectionUtils.newInstance(clazz, job);\n-      LOG.info(\"Using ShuffleConsumerPlugin: \" + shuffleConsumerPlugin);\n+    Class\u003c? extends ShuffleConsumerPlugin\u003e clazz \u003d\n+          job.getClass(MRConfig.SHUFFLE_CONSUMER_PLUGIN, Shuffle.class, ShuffleConsumerPlugin.class);\n+\t\t\t\t\t\n+    shuffleConsumerPlugin \u003d ReflectionUtils.newInstance(clazz, job);\n+    LOG.info(\"Using ShuffleConsumerPlugin: \" + shuffleConsumerPlugin);\n \n-      ShuffleConsumerPlugin.Context shuffleContext \u003d \n-        new ShuffleConsumerPlugin.Context(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n-                    super.lDirAlloc, reporter, codec, \n-                    combinerClass, combineCollector, \n-                    spilledRecordsCounter, reduceCombineInputCounter,\n-                    shuffledMapsCounter,\n-                    reduceShuffleBytes, failedShuffleCounter,\n-                    mergedMapOutputsCounter,\n-                    taskStatus, copyPhase, sortPhase, this,\n-                    mapOutputFile);\n-      shuffleConsumerPlugin.init(shuffleContext);\n-      rIter \u003d shuffleConsumerPlugin.run();\n-    } else {\n-      // local job runner doesn\u0027t have a copy phase\n-      copyPhase.complete();\n-      final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n-      rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n-                           job.getMapOutputValueClass(), codec, \n-                           getMapFiles(rfs, true),\n-                           !conf.getKeepFailedTaskFiles(), \n-                           job.getInt(JobContext.IO_SORT_FACTOR, 100),\n-                           new Path(getTaskID().toString()), \n-                           job.getOutputKeyComparator(),\n-                           reporter, spilledRecordsCounter, null, null);\n-    }\n+    ShuffleConsumerPlugin.Context shuffleContext \u003d \n+      new ShuffleConsumerPlugin.Context(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n+                  super.lDirAlloc, reporter, codec, \n+                  combinerClass, combineCollector, \n+                  spilledRecordsCounter, reduceCombineInputCounter,\n+                  shuffledMapsCounter,\n+                  reduceShuffleBytes, failedShuffleCounter,\n+                  mergedMapOutputsCounter,\n+                  taskStatus, copyPhase, sortPhase, this,\n+                  mapOutputFile, localMapFiles);\n+    shuffleConsumerPlugin.init(shuffleContext);\n+\n+    rIter \u003d shuffleConsumerPlugin.run();\n+\n     // free up the data structures\n     mapOutputFilesOnDisk.clear();\n     \n     sortPhase.complete();                         // sort is complete\n     setPhase(TaskStatus.Phase.REDUCE); \n     statusUpdate(umbilical);\n     Class keyClass \u003d job.getMapOutputKeyClass();\n     Class valueClass \u003d job.getMapOutputValueClass();\n     RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n \n     if (useNewApi) {\n       runNewReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     } else {\n       runOldReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     }\n \n-    if (shuffleConsumerPlugin !\u003d null) {\n-      shuffleConsumerPlugin.close();\n-    }\n+    shuffleConsumerPlugin.close();\n     done(umbilical, reporter);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n    throws IOException, InterruptedException, ClassNotFoundException {\n    job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n\n    if (isMapOrReduce()) {\n      copyPhase \u003d getProgress().addPhase(\"copy\");\n      sortPhase  \u003d getProgress().addPhase(\"sort\");\n      reducePhase \u003d getProgress().addPhase(\"reduce\");\n    }\n    // start thread that will handle communication with parent\n    TaskReporter reporter \u003d startReporter(umbilical);\n    \n    boolean useNewApi \u003d job.getUseNewReducer();\n    initialize(job, getJobID(), reporter, useNewApi);\n\n    // check if it is a cleanupJobTask\n    if (jobCleanup) {\n      runJobCleanupTask(umbilical, reporter);\n      return;\n    }\n    if (jobSetup) {\n      runJobSetupTask(umbilical, reporter);\n      return;\n    }\n    if (taskCleanup) {\n      runTaskCleanupTask(umbilical, reporter);\n      return;\n    }\n    \n    // Initialize the codec\n    codec \u003d initCodec();\n    RawKeyValueIterator rIter \u003d null;\n    ShuffleConsumerPlugin shuffleConsumerPlugin \u003d null;\n    \n    Class combinerClass \u003d conf.getCombinerClass();\n    CombineOutputCollector combineCollector \u003d \n      (null !\u003d combinerClass) ? \n     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n\n    Class\u003c? extends ShuffleConsumerPlugin\u003e clazz \u003d\n          job.getClass(MRConfig.SHUFFLE_CONSUMER_PLUGIN, Shuffle.class, ShuffleConsumerPlugin.class);\n\t\t\t\t\t\n    shuffleConsumerPlugin \u003d ReflectionUtils.newInstance(clazz, job);\n    LOG.info(\"Using ShuffleConsumerPlugin: \" + shuffleConsumerPlugin);\n\n    ShuffleConsumerPlugin.Context shuffleContext \u003d \n      new ShuffleConsumerPlugin.Context(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                  super.lDirAlloc, reporter, codec, \n                  combinerClass, combineCollector, \n                  spilledRecordsCounter, reduceCombineInputCounter,\n                  shuffledMapsCounter,\n                  reduceShuffleBytes, failedShuffleCounter,\n                  mergedMapOutputsCounter,\n                  taskStatus, copyPhase, sortPhase, this,\n                  mapOutputFile, localMapFiles);\n    shuffleConsumerPlugin.init(shuffleContext);\n\n    rIter \u003d shuffleConsumerPlugin.run();\n\n    // free up the data structures\n    mapOutputFilesOnDisk.clear();\n    \n    sortPhase.complete();                         // sort is complete\n    setPhase(TaskStatus.Phase.REDUCE); \n    statusUpdate(umbilical);\n    Class keyClass \u003d job.getMapOutputKeyClass();\n    Class valueClass \u003d job.getMapOutputValueClass();\n    RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n\n    if (useNewApi) {\n      runNewReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    } else {\n      runOldReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    }\n\n    shuffleConsumerPlugin.close();\n    done(umbilical, reporter);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java",
      "extendedDetails": {}
    },
    "b096f61fe25752703785cad5fe0aaae8bf45da2f": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4049. Experimental api to allow for alternate shuffle plugins. Contributed by Anver BenHanoch.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1418173 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/12/12 6:36 PM",
      "commitName": "b096f61fe25752703785cad5fe0aaae8bf45da2f",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "07/02/12 4:56 PM",
      "commitNameOld": "5fdfa2b4bdc2c75bcc920538ee1f8c2063c48e33",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 303.07,
      "commitsBetweenForRepo": 1843,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,93 +1,105 @@\n   public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n     throws IOException, InterruptedException, ClassNotFoundException {\n     job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n \n     if (isMapOrReduce()) {\n       copyPhase \u003d getProgress().addPhase(\"copy\");\n       sortPhase  \u003d getProgress().addPhase(\"sort\");\n       reducePhase \u003d getProgress().addPhase(\"reduce\");\n     }\n     // start thread that will handle communication with parent\n     TaskReporter reporter \u003d startReporter(umbilical);\n     \n     boolean useNewApi \u003d job.getUseNewReducer();\n     initialize(job, getJobID(), reporter, useNewApi);\n \n     // check if it is a cleanupJobTask\n     if (jobCleanup) {\n       runJobCleanupTask(umbilical, reporter);\n       return;\n     }\n     if (jobSetup) {\n       runJobSetupTask(umbilical, reporter);\n       return;\n     }\n     if (taskCleanup) {\n       runTaskCleanupTask(umbilical, reporter);\n       return;\n     }\n     \n     // Initialize the codec\n     codec \u003d initCodec();\n     RawKeyValueIterator rIter \u003d null;\n+    ShuffleConsumerPlugin shuffleConsumerPlugin \u003d null; \n     \n     boolean isLocal \u003d false; \n     // local if\n     // 1) framework \u003d\u003d local or\n     // 2) framework \u003d\u003d null and job tracker address \u003d\u003d local\n     String framework \u003d job.get(MRConfig.FRAMEWORK_NAME);\n     String masterAddr \u003d job.get(MRConfig.MASTER_ADDRESS, \"local\");\n     if ((framework \u003d\u003d null \u0026\u0026 masterAddr.equals(\"local\"))\n         || (framework !\u003d null \u0026\u0026 framework.equals(MRConfig.LOCAL_FRAMEWORK_NAME))) {\n       isLocal \u003d true;\n     }\n     \n     if (!isLocal) {\n       Class combinerClass \u003d conf.getCombinerClass();\n       CombineOutputCollector combineCollector \u003d \n         (null !\u003d combinerClass) ? \n  \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n \n-      Shuffle shuffle \u003d \n-        new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n+      Class\u003c? extends ShuffleConsumerPlugin\u003e clazz \u003d\n+            job.getClass(MRConfig.SHUFFLE_CONSUMER_PLUGIN, Shuffle.class, ShuffleConsumerPlugin.class);\n+\t\t\t\t\t\t\n+      shuffleConsumerPlugin \u003d ReflectionUtils.newInstance(clazz, job);\n+      LOG.info(\"Using ShuffleConsumerPlugin: \" + shuffleConsumerPlugin);\n+\n+      ShuffleConsumerPlugin.Context shuffleContext \u003d \n+        new ShuffleConsumerPlugin.Context(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                     super.lDirAlloc, reporter, codec, \n                     combinerClass, combineCollector, \n                     spilledRecordsCounter, reduceCombineInputCounter,\n                     shuffledMapsCounter,\n                     reduceShuffleBytes, failedShuffleCounter,\n                     mergedMapOutputsCounter,\n                     taskStatus, copyPhase, sortPhase, this,\n                     mapOutputFile);\n-      rIter \u003d shuffle.run();\n+      shuffleConsumerPlugin.init(shuffleContext);\n+      rIter \u003d shuffleConsumerPlugin.run();\n     } else {\n       // local job runner doesn\u0027t have a copy phase\n       copyPhase.complete();\n       final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n       rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                            job.getMapOutputValueClass(), codec, \n                            getMapFiles(rfs, true),\n                            !conf.getKeepFailedTaskFiles(), \n                            job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                            new Path(getTaskID().toString()), \n                            job.getOutputKeyComparator(),\n                            reporter, spilledRecordsCounter, null, null);\n     }\n     // free up the data structures\n     mapOutputFilesOnDisk.clear();\n     \n     sortPhase.complete();                         // sort is complete\n     setPhase(TaskStatus.Phase.REDUCE); \n     statusUpdate(umbilical);\n     Class keyClass \u003d job.getMapOutputKeyClass();\n     Class valueClass \u003d job.getMapOutputValueClass();\n     RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n \n     if (useNewApi) {\n       runNewReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     } else {\n       runOldReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     }\n+\n+    if (shuffleConsumerPlugin !\u003d null) {\n+      shuffleConsumerPlugin.close();\n+    }\n     done(umbilical, reporter);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n    throws IOException, InterruptedException, ClassNotFoundException {\n    job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n\n    if (isMapOrReduce()) {\n      copyPhase \u003d getProgress().addPhase(\"copy\");\n      sortPhase  \u003d getProgress().addPhase(\"sort\");\n      reducePhase \u003d getProgress().addPhase(\"reduce\");\n    }\n    // start thread that will handle communication with parent\n    TaskReporter reporter \u003d startReporter(umbilical);\n    \n    boolean useNewApi \u003d job.getUseNewReducer();\n    initialize(job, getJobID(), reporter, useNewApi);\n\n    // check if it is a cleanupJobTask\n    if (jobCleanup) {\n      runJobCleanupTask(umbilical, reporter);\n      return;\n    }\n    if (jobSetup) {\n      runJobSetupTask(umbilical, reporter);\n      return;\n    }\n    if (taskCleanup) {\n      runTaskCleanupTask(umbilical, reporter);\n      return;\n    }\n    \n    // Initialize the codec\n    codec \u003d initCodec();\n    RawKeyValueIterator rIter \u003d null;\n    ShuffleConsumerPlugin shuffleConsumerPlugin \u003d null; \n    \n    boolean isLocal \u003d false; \n    // local if\n    // 1) framework \u003d\u003d local or\n    // 2) framework \u003d\u003d null and job tracker address \u003d\u003d local\n    String framework \u003d job.get(MRConfig.FRAMEWORK_NAME);\n    String masterAddr \u003d job.get(MRConfig.MASTER_ADDRESS, \"local\");\n    if ((framework \u003d\u003d null \u0026\u0026 masterAddr.equals(\"local\"))\n        || (framework !\u003d null \u0026\u0026 framework.equals(MRConfig.LOCAL_FRAMEWORK_NAME))) {\n      isLocal \u003d true;\n    }\n    \n    if (!isLocal) {\n      Class combinerClass \u003d conf.getCombinerClass();\n      CombineOutputCollector combineCollector \u003d \n        (null !\u003d combinerClass) ? \n \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n\n      Class\u003c? extends ShuffleConsumerPlugin\u003e clazz \u003d\n            job.getClass(MRConfig.SHUFFLE_CONSUMER_PLUGIN, Shuffle.class, ShuffleConsumerPlugin.class);\n\t\t\t\t\t\t\n      shuffleConsumerPlugin \u003d ReflectionUtils.newInstance(clazz, job);\n      LOG.info(\"Using ShuffleConsumerPlugin: \" + shuffleConsumerPlugin);\n\n      ShuffleConsumerPlugin.Context shuffleContext \u003d \n        new ShuffleConsumerPlugin.Context(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                    super.lDirAlloc, reporter, codec, \n                    combinerClass, combineCollector, \n                    spilledRecordsCounter, reduceCombineInputCounter,\n                    shuffledMapsCounter,\n                    reduceShuffleBytes, failedShuffleCounter,\n                    mergedMapOutputsCounter,\n                    taskStatus, copyPhase, sortPhase, this,\n                    mapOutputFile);\n      shuffleConsumerPlugin.init(shuffleContext);\n      rIter \u003d shuffleConsumerPlugin.run();\n    } else {\n      // local job runner doesn\u0027t have a copy phase\n      copyPhase.complete();\n      final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n      rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                           job.getMapOutputValueClass(), codec, \n                           getMapFiles(rfs, true),\n                           !conf.getKeepFailedTaskFiles(), \n                           job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                           new Path(getTaskID().toString()), \n                           job.getOutputKeyComparator(),\n                           reporter, spilledRecordsCounter, null, null);\n    }\n    // free up the data structures\n    mapOutputFilesOnDisk.clear();\n    \n    sortPhase.complete();                         // sort is complete\n    setPhase(TaskStatus.Phase.REDUCE); \n    statusUpdate(umbilical);\n    Class keyClass \u003d job.getMapOutputKeyClass();\n    Class valueClass \u003d job.getMapOutputValueClass();\n    RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n\n    if (useNewApi) {\n      runNewReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    } else {\n      runOldReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    }\n\n    if (shuffleConsumerPlugin !\u003d null) {\n      shuffleConsumerPlugin.close();\n    }\n    done(umbilical, reporter);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java",
      "extendedDetails": {}
    },
    "94e1703b7250117d6b18ef181f77bc58b5740cf9": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3176. Fixed ant mapreduce tests that are timing out because of wrong framework name. Contributed by Hitesh Shah.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1186368 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/10/11 10:55 AM",
      "commitName": "94e1703b7250117d6b18ef181f77bc58b5740cf9",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "10/10/11 5:26 PM",
      "commitNameOld": "42e93829e5310f3cbd905384cd0529f8fffa887f",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 8.73,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,93 @@\n   public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n     throws IOException, InterruptedException, ClassNotFoundException {\n     job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n \n     if (isMapOrReduce()) {\n       copyPhase \u003d getProgress().addPhase(\"copy\");\n       sortPhase  \u003d getProgress().addPhase(\"sort\");\n       reducePhase \u003d getProgress().addPhase(\"reduce\");\n     }\n     // start thread that will handle communication with parent\n     TaskReporter reporter \u003d startReporter(umbilical);\n     \n     boolean useNewApi \u003d job.getUseNewReducer();\n     initialize(job, getJobID(), reporter, useNewApi);\n \n     // check if it is a cleanupJobTask\n     if (jobCleanup) {\n       runJobCleanupTask(umbilical, reporter);\n       return;\n     }\n     if (jobSetup) {\n       runJobSetupTask(umbilical, reporter);\n       return;\n     }\n     if (taskCleanup) {\n       runTaskCleanupTask(umbilical, reporter);\n       return;\n     }\n     \n     // Initialize the codec\n     codec \u003d initCodec();\n     RawKeyValueIterator rIter \u003d null;\n     \n     boolean isLocal \u003d false; \n-    // local iff framework \u003d\u003d local\n-    String framework \u003d job.get(MRConfig.FRAMEWORK_NAME, MRConfig.YARN_FRAMEWORK_NAME);\n-    isLocal \u003d framework.equals(MRConfig.LOCAL_FRAMEWORK_NAME);\n+    // local if\n+    // 1) framework \u003d\u003d local or\n+    // 2) framework \u003d\u003d null and job tracker address \u003d\u003d local\n+    String framework \u003d job.get(MRConfig.FRAMEWORK_NAME);\n+    String masterAddr \u003d job.get(MRConfig.MASTER_ADDRESS, \"local\");\n+    if ((framework \u003d\u003d null \u0026\u0026 masterAddr.equals(\"local\"))\n+        || (framework !\u003d null \u0026\u0026 framework.equals(MRConfig.LOCAL_FRAMEWORK_NAME))) {\n+      isLocal \u003d true;\n+    }\n     \n     if (!isLocal) {\n       Class combinerClass \u003d conf.getCombinerClass();\n       CombineOutputCollector combineCollector \u003d \n         (null !\u003d combinerClass) ? \n  \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n \n       Shuffle shuffle \u003d \n         new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                     super.lDirAlloc, reporter, codec, \n                     combinerClass, combineCollector, \n                     spilledRecordsCounter, reduceCombineInputCounter,\n                     shuffledMapsCounter,\n                     reduceShuffleBytes, failedShuffleCounter,\n                     mergedMapOutputsCounter,\n                     taskStatus, copyPhase, sortPhase, this,\n                     mapOutputFile);\n       rIter \u003d shuffle.run();\n     } else {\n       // local job runner doesn\u0027t have a copy phase\n       copyPhase.complete();\n       final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n       rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                            job.getMapOutputValueClass(), codec, \n                            getMapFiles(rfs, true),\n                            !conf.getKeepFailedTaskFiles(), \n                            job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                            new Path(getTaskID().toString()), \n                            job.getOutputKeyComparator(),\n                            reporter, spilledRecordsCounter, null, null);\n     }\n     // free up the data structures\n     mapOutputFilesOnDisk.clear();\n     \n     sortPhase.complete();                         // sort is complete\n     setPhase(TaskStatus.Phase.REDUCE); \n     statusUpdate(umbilical);\n     Class keyClass \u003d job.getMapOutputKeyClass();\n     Class valueClass \u003d job.getMapOutputValueClass();\n     RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n \n     if (useNewApi) {\n       runNewReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     } else {\n       runOldReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     }\n     done(umbilical, reporter);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n    throws IOException, InterruptedException, ClassNotFoundException {\n    job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n\n    if (isMapOrReduce()) {\n      copyPhase \u003d getProgress().addPhase(\"copy\");\n      sortPhase  \u003d getProgress().addPhase(\"sort\");\n      reducePhase \u003d getProgress().addPhase(\"reduce\");\n    }\n    // start thread that will handle communication with parent\n    TaskReporter reporter \u003d startReporter(umbilical);\n    \n    boolean useNewApi \u003d job.getUseNewReducer();\n    initialize(job, getJobID(), reporter, useNewApi);\n\n    // check if it is a cleanupJobTask\n    if (jobCleanup) {\n      runJobCleanupTask(umbilical, reporter);\n      return;\n    }\n    if (jobSetup) {\n      runJobSetupTask(umbilical, reporter);\n      return;\n    }\n    if (taskCleanup) {\n      runTaskCleanupTask(umbilical, reporter);\n      return;\n    }\n    \n    // Initialize the codec\n    codec \u003d initCodec();\n    RawKeyValueIterator rIter \u003d null;\n    \n    boolean isLocal \u003d false; \n    // local if\n    // 1) framework \u003d\u003d local or\n    // 2) framework \u003d\u003d null and job tracker address \u003d\u003d local\n    String framework \u003d job.get(MRConfig.FRAMEWORK_NAME);\n    String masterAddr \u003d job.get(MRConfig.MASTER_ADDRESS, \"local\");\n    if ((framework \u003d\u003d null \u0026\u0026 masterAddr.equals(\"local\"))\n        || (framework !\u003d null \u0026\u0026 framework.equals(MRConfig.LOCAL_FRAMEWORK_NAME))) {\n      isLocal \u003d true;\n    }\n    \n    if (!isLocal) {\n      Class combinerClass \u003d conf.getCombinerClass();\n      CombineOutputCollector combineCollector \u003d \n        (null !\u003d combinerClass) ? \n \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n\n      Shuffle shuffle \u003d \n        new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                    super.lDirAlloc, reporter, codec, \n                    combinerClass, combineCollector, \n                    spilledRecordsCounter, reduceCombineInputCounter,\n                    shuffledMapsCounter,\n                    reduceShuffleBytes, failedShuffleCounter,\n                    mergedMapOutputsCounter,\n                    taskStatus, copyPhase, sortPhase, this,\n                    mapOutputFile);\n      rIter \u003d shuffle.run();\n    } else {\n      // local job runner doesn\u0027t have a copy phase\n      copyPhase.complete();\n      final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n      rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                           job.getMapOutputValueClass(), codec, \n                           getMapFiles(rfs, true),\n                           !conf.getKeepFailedTaskFiles(), \n                           job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                           new Path(getTaskID().toString()), \n                           job.getOutputKeyComparator(),\n                           reporter, spilledRecordsCounter, null, null);\n    }\n    // free up the data structures\n    mapOutputFilesOnDisk.clear();\n    \n    sortPhase.complete();                         // sort is complete\n    setPhase(TaskStatus.Phase.REDUCE); \n    statusUpdate(umbilical);\n    Class keyClass \u003d job.getMapOutputKeyClass();\n    Class valueClass \u003d job.getMapOutputValueClass();\n    RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n\n    if (useNewApi) {\n      runNewReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    } else {\n      runOldReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    }\n    done(umbilical, reporter);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java",
      "extendedDetails": {}
    },
    "42e93829e5310f3cbd905384cd0529f8fffa887f": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3158. Fix test failures in MRv1 due to default framework being set to yarn. Contributed by Hitesh Shah. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1181310 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/10/11 5:26 PM",
      "commitName": "42e93829e5310f3cbd905384cd0529f8fffa887f",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "07/10/11 1:39 PM",
      "commitNameOld": "6b343adfe880c7e9e2f441fd889cf16a8657c335",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 3.16,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,89 +1,87 @@\n   public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n     throws IOException, InterruptedException, ClassNotFoundException {\n     job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n \n     if (isMapOrReduce()) {\n       copyPhase \u003d getProgress().addPhase(\"copy\");\n       sortPhase  \u003d getProgress().addPhase(\"sort\");\n       reducePhase \u003d getProgress().addPhase(\"reduce\");\n     }\n     // start thread that will handle communication with parent\n     TaskReporter reporter \u003d startReporter(umbilical);\n     \n     boolean useNewApi \u003d job.getUseNewReducer();\n     initialize(job, getJobID(), reporter, useNewApi);\n \n     // check if it is a cleanupJobTask\n     if (jobCleanup) {\n       runJobCleanupTask(umbilical, reporter);\n       return;\n     }\n     if (jobSetup) {\n       runJobSetupTask(umbilical, reporter);\n       return;\n     }\n     if (taskCleanup) {\n       runTaskCleanupTask(umbilical, reporter);\n       return;\n     }\n     \n     // Initialize the codec\n     codec \u003d initCodec();\n     RawKeyValueIterator rIter \u003d null;\n     \n     boolean isLocal \u003d false; \n-    // local iff framework \u003d\u003d classic \u0026\u0026 master address \u003d\u003d local\n+    // local iff framework \u003d\u003d local\n     String framework \u003d job.get(MRConfig.FRAMEWORK_NAME, MRConfig.YARN_FRAMEWORK_NAME);\n-    if (framework.equals(MRConfig.CLASSIC_FRAMEWORK_NAME)) {\n-    \tisLocal \u003d \"local\".equals(job.get(MRConfig.MASTER_ADDRESS, \"local\"));        \t\n-    }\n+    isLocal \u003d framework.equals(MRConfig.LOCAL_FRAMEWORK_NAME);\n     \n     if (!isLocal) {\n       Class combinerClass \u003d conf.getCombinerClass();\n       CombineOutputCollector combineCollector \u003d \n         (null !\u003d combinerClass) ? \n  \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n \n       Shuffle shuffle \u003d \n         new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                     super.lDirAlloc, reporter, codec, \n                     combinerClass, combineCollector, \n                     spilledRecordsCounter, reduceCombineInputCounter,\n                     shuffledMapsCounter,\n                     reduceShuffleBytes, failedShuffleCounter,\n                     mergedMapOutputsCounter,\n                     taskStatus, copyPhase, sortPhase, this,\n                     mapOutputFile);\n       rIter \u003d shuffle.run();\n     } else {\n       // local job runner doesn\u0027t have a copy phase\n       copyPhase.complete();\n       final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n       rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                            job.getMapOutputValueClass(), codec, \n                            getMapFiles(rfs, true),\n                            !conf.getKeepFailedTaskFiles(), \n                            job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                            new Path(getTaskID().toString()), \n                            job.getOutputKeyComparator(),\n                            reporter, spilledRecordsCounter, null, null);\n     }\n     // free up the data structures\n     mapOutputFilesOnDisk.clear();\n     \n     sortPhase.complete();                         // sort is complete\n     setPhase(TaskStatus.Phase.REDUCE); \n     statusUpdate(umbilical);\n     Class keyClass \u003d job.getMapOutputKeyClass();\n     Class valueClass \u003d job.getMapOutputValueClass();\n     RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n \n     if (useNewApi) {\n       runNewReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     } else {\n       runOldReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     }\n     done(umbilical, reporter);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n    throws IOException, InterruptedException, ClassNotFoundException {\n    job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n\n    if (isMapOrReduce()) {\n      copyPhase \u003d getProgress().addPhase(\"copy\");\n      sortPhase  \u003d getProgress().addPhase(\"sort\");\n      reducePhase \u003d getProgress().addPhase(\"reduce\");\n    }\n    // start thread that will handle communication with parent\n    TaskReporter reporter \u003d startReporter(umbilical);\n    \n    boolean useNewApi \u003d job.getUseNewReducer();\n    initialize(job, getJobID(), reporter, useNewApi);\n\n    // check if it is a cleanupJobTask\n    if (jobCleanup) {\n      runJobCleanupTask(umbilical, reporter);\n      return;\n    }\n    if (jobSetup) {\n      runJobSetupTask(umbilical, reporter);\n      return;\n    }\n    if (taskCleanup) {\n      runTaskCleanupTask(umbilical, reporter);\n      return;\n    }\n    \n    // Initialize the codec\n    codec \u003d initCodec();\n    RawKeyValueIterator rIter \u003d null;\n    \n    boolean isLocal \u003d false; \n    // local iff framework \u003d\u003d local\n    String framework \u003d job.get(MRConfig.FRAMEWORK_NAME, MRConfig.YARN_FRAMEWORK_NAME);\n    isLocal \u003d framework.equals(MRConfig.LOCAL_FRAMEWORK_NAME);\n    \n    if (!isLocal) {\n      Class combinerClass \u003d conf.getCombinerClass();\n      CombineOutputCollector combineCollector \u003d \n        (null !\u003d combinerClass) ? \n \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n\n      Shuffle shuffle \u003d \n        new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                    super.lDirAlloc, reporter, codec, \n                    combinerClass, combineCollector, \n                    spilledRecordsCounter, reduceCombineInputCounter,\n                    shuffledMapsCounter,\n                    reduceShuffleBytes, failedShuffleCounter,\n                    mergedMapOutputsCounter,\n                    taskStatus, copyPhase, sortPhase, this,\n                    mapOutputFile);\n      rIter \u003d shuffle.run();\n    } else {\n      // local job runner doesn\u0027t have a copy phase\n      copyPhase.complete();\n      final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n      rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                           job.getMapOutputValueClass(), codec, \n                           getMapFiles(rfs, true),\n                           !conf.getKeepFailedTaskFiles(), \n                           job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                           new Path(getTaskID().toString()), \n                           job.getOutputKeyComparator(),\n                           reporter, spilledRecordsCounter, null, null);\n    }\n    // free up the data structures\n    mapOutputFilesOnDisk.clear();\n    \n    sortPhase.complete();                         // sort is complete\n    setPhase(TaskStatus.Phase.REDUCE); \n    statusUpdate(umbilical);\n    Class keyClass \u003d job.getMapOutputKeyClass();\n    Class valueClass \u003d job.getMapOutputValueClass();\n    RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n\n    if (useNewApi) {\n      runNewReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    } else {\n      runOldReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    }\n    done(umbilical, reporter);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java",
      "extendedDetails": {}
    },
    "6b343adfe880c7e9e2f441fd889cf16a8657c335": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3033. Ensure Master interface pays attention to classic v/s yarn frameworks. Contributed by Hitesh Shah.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1180214 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/10/11 1:39 PM",
      "commitName": "6b343adfe880c7e9e2f441fd889cf16a8657c335",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "19/09/11 4:17 PM",
      "commitNameOld": "482d840bcf3e8332e513bcea61f6d4ea7ee8579d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 17.89,
      "commitsBetweenForRepo": 141,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,89 +1,89 @@\n   public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n     throws IOException, InterruptedException, ClassNotFoundException {\n     job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n \n     if (isMapOrReduce()) {\n       copyPhase \u003d getProgress().addPhase(\"copy\");\n       sortPhase  \u003d getProgress().addPhase(\"sort\");\n       reducePhase \u003d getProgress().addPhase(\"reduce\");\n     }\n     // start thread that will handle communication with parent\n     TaskReporter reporter \u003d startReporter(umbilical);\n     \n     boolean useNewApi \u003d job.getUseNewReducer();\n     initialize(job, getJobID(), reporter, useNewApi);\n \n     // check if it is a cleanupJobTask\n     if (jobCleanup) {\n       runJobCleanupTask(umbilical, reporter);\n       return;\n     }\n     if (jobSetup) {\n       runJobSetupTask(umbilical, reporter);\n       return;\n     }\n     if (taskCleanup) {\n       runTaskCleanupTask(umbilical, reporter);\n       return;\n     }\n     \n     // Initialize the codec\n     codec \u003d initCodec();\n     RawKeyValueIterator rIter \u003d null;\n     \n     boolean isLocal \u003d false; \n     // local iff framework \u003d\u003d classic \u0026\u0026 master address \u003d\u003d local\n-    String framework \u003d job.get(MRConfig.FRAMEWORK_NAME, MRConfig.CLASSIC_FRAMEWORK_NAME);\n+    String framework \u003d job.get(MRConfig.FRAMEWORK_NAME, MRConfig.YARN_FRAMEWORK_NAME);\n     if (framework.equals(MRConfig.CLASSIC_FRAMEWORK_NAME)) {\n     \tisLocal \u003d \"local\".equals(job.get(MRConfig.MASTER_ADDRESS, \"local\"));        \t\n     }\n     \n     if (!isLocal) {\n       Class combinerClass \u003d conf.getCombinerClass();\n       CombineOutputCollector combineCollector \u003d \n         (null !\u003d combinerClass) ? \n  \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n \n       Shuffle shuffle \u003d \n         new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                     super.lDirAlloc, reporter, codec, \n                     combinerClass, combineCollector, \n                     spilledRecordsCounter, reduceCombineInputCounter,\n                     shuffledMapsCounter,\n                     reduceShuffleBytes, failedShuffleCounter,\n                     mergedMapOutputsCounter,\n                     taskStatus, copyPhase, sortPhase, this,\n                     mapOutputFile);\n       rIter \u003d shuffle.run();\n     } else {\n       // local job runner doesn\u0027t have a copy phase\n       copyPhase.complete();\n       final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n       rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                            job.getMapOutputValueClass(), codec, \n                            getMapFiles(rfs, true),\n                            !conf.getKeepFailedTaskFiles(), \n                            job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                            new Path(getTaskID().toString()), \n                            job.getOutputKeyComparator(),\n                            reporter, spilledRecordsCounter, null, null);\n     }\n     // free up the data structures\n     mapOutputFilesOnDisk.clear();\n     \n     sortPhase.complete();                         // sort is complete\n     setPhase(TaskStatus.Phase.REDUCE); \n     statusUpdate(umbilical);\n     Class keyClass \u003d job.getMapOutputKeyClass();\n     Class valueClass \u003d job.getMapOutputValueClass();\n     RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n \n     if (useNewApi) {\n       runNewReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     } else {\n       runOldReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     }\n     done(umbilical, reporter);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n    throws IOException, InterruptedException, ClassNotFoundException {\n    job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n\n    if (isMapOrReduce()) {\n      copyPhase \u003d getProgress().addPhase(\"copy\");\n      sortPhase  \u003d getProgress().addPhase(\"sort\");\n      reducePhase \u003d getProgress().addPhase(\"reduce\");\n    }\n    // start thread that will handle communication with parent\n    TaskReporter reporter \u003d startReporter(umbilical);\n    \n    boolean useNewApi \u003d job.getUseNewReducer();\n    initialize(job, getJobID(), reporter, useNewApi);\n\n    // check if it is a cleanupJobTask\n    if (jobCleanup) {\n      runJobCleanupTask(umbilical, reporter);\n      return;\n    }\n    if (jobSetup) {\n      runJobSetupTask(umbilical, reporter);\n      return;\n    }\n    if (taskCleanup) {\n      runTaskCleanupTask(umbilical, reporter);\n      return;\n    }\n    \n    // Initialize the codec\n    codec \u003d initCodec();\n    RawKeyValueIterator rIter \u003d null;\n    \n    boolean isLocal \u003d false; \n    // local iff framework \u003d\u003d classic \u0026\u0026 master address \u003d\u003d local\n    String framework \u003d job.get(MRConfig.FRAMEWORK_NAME, MRConfig.YARN_FRAMEWORK_NAME);\n    if (framework.equals(MRConfig.CLASSIC_FRAMEWORK_NAME)) {\n    \tisLocal \u003d \"local\".equals(job.get(MRConfig.MASTER_ADDRESS, \"local\"));        \t\n    }\n    \n    if (!isLocal) {\n      Class combinerClass \u003d conf.getCombinerClass();\n      CombineOutputCollector combineCollector \u003d \n        (null !\u003d combinerClass) ? \n \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n\n      Shuffle shuffle \u003d \n        new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                    super.lDirAlloc, reporter, codec, \n                    combinerClass, combineCollector, \n                    spilledRecordsCounter, reduceCombineInputCounter,\n                    shuffledMapsCounter,\n                    reduceShuffleBytes, failedShuffleCounter,\n                    mergedMapOutputsCounter,\n                    taskStatus, copyPhase, sortPhase, this,\n                    mapOutputFile);\n      rIter \u003d shuffle.run();\n    } else {\n      // local job runner doesn\u0027t have a copy phase\n      copyPhase.complete();\n      final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n      rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                           job.getMapOutputValueClass(), codec, \n                           getMapFiles(rfs, true),\n                           !conf.getKeepFailedTaskFiles(), \n                           job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                           new Path(getTaskID().toString()), \n                           job.getOutputKeyComparator(),\n                           reporter, spilledRecordsCounter, null, null);\n    }\n    // free up the data structures\n    mapOutputFilesOnDisk.clear();\n    \n    sortPhase.complete();                         // sort is complete\n    setPhase(TaskStatus.Phase.REDUCE); \n    statusUpdate(umbilical);\n    Class keyClass \u003d job.getMapOutputKeyClass();\n    Class valueClass \u003d job.getMapOutputValueClass();\n    RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n\n    if (useNewApi) {\n      runNewReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    } else {\n      runOldReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    }\n    done(umbilical, reporter);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java",
      "extendedDetails": {}
    },
    "482d840bcf3e8332e513bcea61f6d4ea7ee8579d": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3004. Fix ReduceTask to not assume \u0027local\u0027 mode in YARN. Contributed by Hitesh Shah.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1172893 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/09/11 4:17 PM",
      "commitName": "482d840bcf3e8332e513bcea61f6d4ea7ee8579d",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 25.96,
      "commitsBetweenForRepo": 154,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,82 +1,89 @@\n   public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n     throws IOException, InterruptedException, ClassNotFoundException {\n     job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n \n     if (isMapOrReduce()) {\n       copyPhase \u003d getProgress().addPhase(\"copy\");\n       sortPhase  \u003d getProgress().addPhase(\"sort\");\n       reducePhase \u003d getProgress().addPhase(\"reduce\");\n     }\n     // start thread that will handle communication with parent\n     TaskReporter reporter \u003d startReporter(umbilical);\n     \n     boolean useNewApi \u003d job.getUseNewReducer();\n     initialize(job, getJobID(), reporter, useNewApi);\n \n     // check if it is a cleanupJobTask\n     if (jobCleanup) {\n       runJobCleanupTask(umbilical, reporter);\n       return;\n     }\n     if (jobSetup) {\n       runJobSetupTask(umbilical, reporter);\n       return;\n     }\n     if (taskCleanup) {\n       runTaskCleanupTask(umbilical, reporter);\n       return;\n     }\n     \n     // Initialize the codec\n     codec \u003d initCodec();\n     RawKeyValueIterator rIter \u003d null;\n-    boolean isLocal \u003d \"local\".equals(job.get(MRConfig.MASTER_ADDRESS, \"local\"));\n+    \n+    boolean isLocal \u003d false; \n+    // local iff framework \u003d\u003d classic \u0026\u0026 master address \u003d\u003d local\n+    String framework \u003d job.get(MRConfig.FRAMEWORK_NAME, MRConfig.CLASSIC_FRAMEWORK_NAME);\n+    if (framework.equals(MRConfig.CLASSIC_FRAMEWORK_NAME)) {\n+    \tisLocal \u003d \"local\".equals(job.get(MRConfig.MASTER_ADDRESS, \"local\"));        \t\n+    }\n+    \n     if (!isLocal) {\n       Class combinerClass \u003d conf.getCombinerClass();\n       CombineOutputCollector combineCollector \u003d \n         (null !\u003d combinerClass) ? \n  \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n \n       Shuffle shuffle \u003d \n         new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                     super.lDirAlloc, reporter, codec, \n                     combinerClass, combineCollector, \n                     spilledRecordsCounter, reduceCombineInputCounter,\n                     shuffledMapsCounter,\n                     reduceShuffleBytes, failedShuffleCounter,\n                     mergedMapOutputsCounter,\n                     taskStatus, copyPhase, sortPhase, this,\n                     mapOutputFile);\n       rIter \u003d shuffle.run();\n     } else {\n       // local job runner doesn\u0027t have a copy phase\n       copyPhase.complete();\n       final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n       rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                            job.getMapOutputValueClass(), codec, \n                            getMapFiles(rfs, true),\n                            !conf.getKeepFailedTaskFiles(), \n                            job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                            new Path(getTaskID().toString()), \n                            job.getOutputKeyComparator(),\n                            reporter, spilledRecordsCounter, null, null);\n     }\n     // free up the data structures\n     mapOutputFilesOnDisk.clear();\n     \n     sortPhase.complete();                         // sort is complete\n     setPhase(TaskStatus.Phase.REDUCE); \n     statusUpdate(umbilical);\n     Class keyClass \u003d job.getMapOutputKeyClass();\n     Class valueClass \u003d job.getMapOutputValueClass();\n     RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n \n     if (useNewApi) {\n       runNewReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     } else {\n       runOldReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     }\n     done(umbilical, reporter);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n    throws IOException, InterruptedException, ClassNotFoundException {\n    job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n\n    if (isMapOrReduce()) {\n      copyPhase \u003d getProgress().addPhase(\"copy\");\n      sortPhase  \u003d getProgress().addPhase(\"sort\");\n      reducePhase \u003d getProgress().addPhase(\"reduce\");\n    }\n    // start thread that will handle communication with parent\n    TaskReporter reporter \u003d startReporter(umbilical);\n    \n    boolean useNewApi \u003d job.getUseNewReducer();\n    initialize(job, getJobID(), reporter, useNewApi);\n\n    // check if it is a cleanupJobTask\n    if (jobCleanup) {\n      runJobCleanupTask(umbilical, reporter);\n      return;\n    }\n    if (jobSetup) {\n      runJobSetupTask(umbilical, reporter);\n      return;\n    }\n    if (taskCleanup) {\n      runTaskCleanupTask(umbilical, reporter);\n      return;\n    }\n    \n    // Initialize the codec\n    codec \u003d initCodec();\n    RawKeyValueIterator rIter \u003d null;\n    \n    boolean isLocal \u003d false; \n    // local iff framework \u003d\u003d classic \u0026\u0026 master address \u003d\u003d local\n    String framework \u003d job.get(MRConfig.FRAMEWORK_NAME, MRConfig.CLASSIC_FRAMEWORK_NAME);\n    if (framework.equals(MRConfig.CLASSIC_FRAMEWORK_NAME)) {\n    \tisLocal \u003d \"local\".equals(job.get(MRConfig.MASTER_ADDRESS, \"local\"));        \t\n    }\n    \n    if (!isLocal) {\n      Class combinerClass \u003d conf.getCombinerClass();\n      CombineOutputCollector combineCollector \u003d \n        (null !\u003d combinerClass) ? \n \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n\n      Shuffle shuffle \u003d \n        new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                    super.lDirAlloc, reporter, codec, \n                    combinerClass, combineCollector, \n                    spilledRecordsCounter, reduceCombineInputCounter,\n                    shuffledMapsCounter,\n                    reduceShuffleBytes, failedShuffleCounter,\n                    mergedMapOutputsCounter,\n                    taskStatus, copyPhase, sortPhase, this,\n                    mapOutputFile);\n      rIter \u003d shuffle.run();\n    } else {\n      // local job runner doesn\u0027t have a copy phase\n      copyPhase.complete();\n      final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n      rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                           job.getMapOutputValueClass(), codec, \n                           getMapFiles(rfs, true),\n                           !conf.getKeepFailedTaskFiles(), \n                           job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                           new Path(getTaskID().toString()), \n                           job.getOutputKeyComparator(),\n                           reporter, spilledRecordsCounter, null, null);\n    }\n    // free up the data structures\n    mapOutputFilesOnDisk.clear();\n    \n    sortPhase.complete();                         // sort is complete\n    setPhase(TaskStatus.Phase.REDUCE); \n    statusUpdate(umbilical);\n    Class keyClass \u003d job.getMapOutputKeyClass();\n    Class valueClass \u003d job.getMapOutputValueClass();\n    RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n\n    if (useNewApi) {\n      runNewReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    } else {\n      runOldReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    }\n    done(umbilical, reporter);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n    throws IOException, InterruptedException, ClassNotFoundException {\n    job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n\n    if (isMapOrReduce()) {\n      copyPhase \u003d getProgress().addPhase(\"copy\");\n      sortPhase  \u003d getProgress().addPhase(\"sort\");\n      reducePhase \u003d getProgress().addPhase(\"reduce\");\n    }\n    // start thread that will handle communication with parent\n    TaskReporter reporter \u003d startReporter(umbilical);\n    \n    boolean useNewApi \u003d job.getUseNewReducer();\n    initialize(job, getJobID(), reporter, useNewApi);\n\n    // check if it is a cleanupJobTask\n    if (jobCleanup) {\n      runJobCleanupTask(umbilical, reporter);\n      return;\n    }\n    if (jobSetup) {\n      runJobSetupTask(umbilical, reporter);\n      return;\n    }\n    if (taskCleanup) {\n      runTaskCleanupTask(umbilical, reporter);\n      return;\n    }\n    \n    // Initialize the codec\n    codec \u003d initCodec();\n    RawKeyValueIterator rIter \u003d null;\n    boolean isLocal \u003d \"local\".equals(job.get(MRConfig.MASTER_ADDRESS, \"local\"));\n    if (!isLocal) {\n      Class combinerClass \u003d conf.getCombinerClass();\n      CombineOutputCollector combineCollector \u003d \n        (null !\u003d combinerClass) ? \n \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n\n      Shuffle shuffle \u003d \n        new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                    super.lDirAlloc, reporter, codec, \n                    combinerClass, combineCollector, \n                    spilledRecordsCounter, reduceCombineInputCounter,\n                    shuffledMapsCounter,\n                    reduceShuffleBytes, failedShuffleCounter,\n                    mergedMapOutputsCounter,\n                    taskStatus, copyPhase, sortPhase, this,\n                    mapOutputFile);\n      rIter \u003d shuffle.run();\n    } else {\n      // local job runner doesn\u0027t have a copy phase\n      copyPhase.complete();\n      final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n      rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                           job.getMapOutputValueClass(), codec, \n                           getMapFiles(rfs, true),\n                           !conf.getKeepFailedTaskFiles(), \n                           job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                           new Path(getTaskID().toString()), \n                           job.getOutputKeyComparator(),\n                           reporter, spilledRecordsCounter, null, null);\n    }\n    // free up the data structures\n    mapOutputFilesOnDisk.clear();\n    \n    sortPhase.complete();                         // sort is complete\n    setPhase(TaskStatus.Phase.REDUCE); \n    statusUpdate(umbilical);\n    Class keyClass \u003d job.getMapOutputKeyClass();\n    Class valueClass \u003d job.getMapOutputValueClass();\n    RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n\n    if (useNewApi) {\n      runNewReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    } else {\n      runOldReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    }\n    done(umbilical, reporter);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,82 +1,82 @@\n   public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n     throws IOException, InterruptedException, ClassNotFoundException {\n     job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n \n     if (isMapOrReduce()) {\n       copyPhase \u003d getProgress().addPhase(\"copy\");\n       sortPhase  \u003d getProgress().addPhase(\"sort\");\n       reducePhase \u003d getProgress().addPhase(\"reduce\");\n     }\n     // start thread that will handle communication with parent\n     TaskReporter reporter \u003d startReporter(umbilical);\n     \n     boolean useNewApi \u003d job.getUseNewReducer();\n     initialize(job, getJobID(), reporter, useNewApi);\n \n     // check if it is a cleanupJobTask\n     if (jobCleanup) {\n       runJobCleanupTask(umbilical, reporter);\n       return;\n     }\n     if (jobSetup) {\n       runJobSetupTask(umbilical, reporter);\n       return;\n     }\n     if (taskCleanup) {\n       runTaskCleanupTask(umbilical, reporter);\n       return;\n     }\n     \n     // Initialize the codec\n     codec \u003d initCodec();\n     RawKeyValueIterator rIter \u003d null;\n-    boolean isLocal \u003d \"local\".equals(job.get(JTConfig.JT_IPC_ADDRESS, \"local\"));\n+    boolean isLocal \u003d \"local\".equals(job.get(MRConfig.MASTER_ADDRESS, \"local\"));\n     if (!isLocal) {\n       Class combinerClass \u003d conf.getCombinerClass();\n       CombineOutputCollector combineCollector \u003d \n         (null !\u003d combinerClass) ? \n  \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n \n       Shuffle shuffle \u003d \n         new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                     super.lDirAlloc, reporter, codec, \n                     combinerClass, combineCollector, \n                     spilledRecordsCounter, reduceCombineInputCounter,\n                     shuffledMapsCounter,\n                     reduceShuffleBytes, failedShuffleCounter,\n                     mergedMapOutputsCounter,\n                     taskStatus, copyPhase, sortPhase, this,\n                     mapOutputFile);\n       rIter \u003d shuffle.run();\n     } else {\n       // local job runner doesn\u0027t have a copy phase\n       copyPhase.complete();\n       final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n       rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                            job.getMapOutputValueClass(), codec, \n                            getMapFiles(rfs, true),\n                            !conf.getKeepFailedTaskFiles(), \n                            job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                            new Path(getTaskID().toString()), \n                            job.getOutputKeyComparator(),\n                            reporter, spilledRecordsCounter, null, null);\n     }\n     // free up the data structures\n     mapOutputFilesOnDisk.clear();\n     \n     sortPhase.complete();                         // sort is complete\n     setPhase(TaskStatus.Phase.REDUCE); \n     statusUpdate(umbilical);\n     Class keyClass \u003d job.getMapOutputKeyClass();\n     Class valueClass \u003d job.getMapOutputValueClass();\n     RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n \n     if (useNewApi) {\n       runNewReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     } else {\n       runOldReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     }\n     done(umbilical, reporter);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n    throws IOException, InterruptedException, ClassNotFoundException {\n    job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n\n    if (isMapOrReduce()) {\n      copyPhase \u003d getProgress().addPhase(\"copy\");\n      sortPhase  \u003d getProgress().addPhase(\"sort\");\n      reducePhase \u003d getProgress().addPhase(\"reduce\");\n    }\n    // start thread that will handle communication with parent\n    TaskReporter reporter \u003d startReporter(umbilical);\n    \n    boolean useNewApi \u003d job.getUseNewReducer();\n    initialize(job, getJobID(), reporter, useNewApi);\n\n    // check if it is a cleanupJobTask\n    if (jobCleanup) {\n      runJobCleanupTask(umbilical, reporter);\n      return;\n    }\n    if (jobSetup) {\n      runJobSetupTask(umbilical, reporter);\n      return;\n    }\n    if (taskCleanup) {\n      runTaskCleanupTask(umbilical, reporter);\n      return;\n    }\n    \n    // Initialize the codec\n    codec \u003d initCodec();\n    RawKeyValueIterator rIter \u003d null;\n    boolean isLocal \u003d \"local\".equals(job.get(MRConfig.MASTER_ADDRESS, \"local\"));\n    if (!isLocal) {\n      Class combinerClass \u003d conf.getCombinerClass();\n      CombineOutputCollector combineCollector \u003d \n        (null !\u003d combinerClass) ? \n \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n\n      Shuffle shuffle \u003d \n        new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                    super.lDirAlloc, reporter, codec, \n                    combinerClass, combineCollector, \n                    spilledRecordsCounter, reduceCombineInputCounter,\n                    shuffledMapsCounter,\n                    reduceShuffleBytes, failedShuffleCounter,\n                    mergedMapOutputsCounter,\n                    taskStatus, copyPhase, sortPhase, this,\n                    mapOutputFile);\n      rIter \u003d shuffle.run();\n    } else {\n      // local job runner doesn\u0027t have a copy phase\n      copyPhase.complete();\n      final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n      rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                           job.getMapOutputValueClass(), codec, \n                           getMapFiles(rfs, true),\n                           !conf.getKeepFailedTaskFiles(), \n                           job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                           new Path(getTaskID().toString()), \n                           job.getOutputKeyComparator(),\n                           reporter, spilledRecordsCounter, null, null);\n    }\n    // free up the data structures\n    mapOutputFilesOnDisk.clear();\n    \n    sortPhase.complete();                         // sort is complete\n    setPhase(TaskStatus.Phase.REDUCE); \n    statusUpdate(umbilical);\n    Class keyClass \u003d job.getMapOutputKeyClass();\n    Class valueClass \u003d job.getMapOutputValueClass();\n    RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n\n    if (useNewApi) {\n      runNewReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    } else {\n      runOldReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    }\n    done(umbilical, reporter);\n  }",
          "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java",
          "extendedDetails": {
            "oldPath": "mapreduce/src/java/org/apache/hadoop/mapred/ReduceTask.java",
            "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java",
            "oldMethodName": "run",
            "newMethodName": "run"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,82 +1,82 @@\n   public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n     throws IOException, InterruptedException, ClassNotFoundException {\n     job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n \n     if (isMapOrReduce()) {\n       copyPhase \u003d getProgress().addPhase(\"copy\");\n       sortPhase  \u003d getProgress().addPhase(\"sort\");\n       reducePhase \u003d getProgress().addPhase(\"reduce\");\n     }\n     // start thread that will handle communication with parent\n     TaskReporter reporter \u003d startReporter(umbilical);\n     \n     boolean useNewApi \u003d job.getUseNewReducer();\n     initialize(job, getJobID(), reporter, useNewApi);\n \n     // check if it is a cleanupJobTask\n     if (jobCleanup) {\n       runJobCleanupTask(umbilical, reporter);\n       return;\n     }\n     if (jobSetup) {\n       runJobSetupTask(umbilical, reporter);\n       return;\n     }\n     if (taskCleanup) {\n       runTaskCleanupTask(umbilical, reporter);\n       return;\n     }\n     \n     // Initialize the codec\n     codec \u003d initCodec();\n     RawKeyValueIterator rIter \u003d null;\n-    boolean isLocal \u003d \"local\".equals(job.get(JTConfig.JT_IPC_ADDRESS, \"local\"));\n+    boolean isLocal \u003d \"local\".equals(job.get(MRConfig.MASTER_ADDRESS, \"local\"));\n     if (!isLocal) {\n       Class combinerClass \u003d conf.getCombinerClass();\n       CombineOutputCollector combineCollector \u003d \n         (null !\u003d combinerClass) ? \n  \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n \n       Shuffle shuffle \u003d \n         new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                     super.lDirAlloc, reporter, codec, \n                     combinerClass, combineCollector, \n                     spilledRecordsCounter, reduceCombineInputCounter,\n                     shuffledMapsCounter,\n                     reduceShuffleBytes, failedShuffleCounter,\n                     mergedMapOutputsCounter,\n                     taskStatus, copyPhase, sortPhase, this,\n                     mapOutputFile);\n       rIter \u003d shuffle.run();\n     } else {\n       // local job runner doesn\u0027t have a copy phase\n       copyPhase.complete();\n       final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n       rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                            job.getMapOutputValueClass(), codec, \n                            getMapFiles(rfs, true),\n                            !conf.getKeepFailedTaskFiles(), \n                            job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                            new Path(getTaskID().toString()), \n                            job.getOutputKeyComparator(),\n                            reporter, spilledRecordsCounter, null, null);\n     }\n     // free up the data structures\n     mapOutputFilesOnDisk.clear();\n     \n     sortPhase.complete();                         // sort is complete\n     setPhase(TaskStatus.Phase.REDUCE); \n     statusUpdate(umbilical);\n     Class keyClass \u003d job.getMapOutputKeyClass();\n     Class valueClass \u003d job.getMapOutputValueClass();\n     RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n \n     if (useNewApi) {\n       runNewReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     } else {\n       runOldReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     }\n     done(umbilical, reporter);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n    throws IOException, InterruptedException, ClassNotFoundException {\n    job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n\n    if (isMapOrReduce()) {\n      copyPhase \u003d getProgress().addPhase(\"copy\");\n      sortPhase  \u003d getProgress().addPhase(\"sort\");\n      reducePhase \u003d getProgress().addPhase(\"reduce\");\n    }\n    // start thread that will handle communication with parent\n    TaskReporter reporter \u003d startReporter(umbilical);\n    \n    boolean useNewApi \u003d job.getUseNewReducer();\n    initialize(job, getJobID(), reporter, useNewApi);\n\n    // check if it is a cleanupJobTask\n    if (jobCleanup) {\n      runJobCleanupTask(umbilical, reporter);\n      return;\n    }\n    if (jobSetup) {\n      runJobSetupTask(umbilical, reporter);\n      return;\n    }\n    if (taskCleanup) {\n      runTaskCleanupTask(umbilical, reporter);\n      return;\n    }\n    \n    // Initialize the codec\n    codec \u003d initCodec();\n    RawKeyValueIterator rIter \u003d null;\n    boolean isLocal \u003d \"local\".equals(job.get(MRConfig.MASTER_ADDRESS, \"local\"));\n    if (!isLocal) {\n      Class combinerClass \u003d conf.getCombinerClass();\n      CombineOutputCollector combineCollector \u003d \n        (null !\u003d combinerClass) ? \n \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n\n      Shuffle shuffle \u003d \n        new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                    super.lDirAlloc, reporter, codec, \n                    combinerClass, combineCollector, \n                    spilledRecordsCounter, reduceCombineInputCounter,\n                    shuffledMapsCounter,\n                    reduceShuffleBytes, failedShuffleCounter,\n                    mergedMapOutputsCounter,\n                    taskStatus, copyPhase, sortPhase, this,\n                    mapOutputFile);\n      rIter \u003d shuffle.run();\n    } else {\n      // local job runner doesn\u0027t have a copy phase\n      copyPhase.complete();\n      final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n      rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                           job.getMapOutputValueClass(), codec, \n                           getMapFiles(rfs, true),\n                           !conf.getKeepFailedTaskFiles(), \n                           job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                           new Path(getTaskID().toString()), \n                           job.getOutputKeyComparator(),\n                           reporter, spilledRecordsCounter, null, null);\n    }\n    // free up the data structures\n    mapOutputFilesOnDisk.clear();\n    \n    sortPhase.complete();                         // sort is complete\n    setPhase(TaskStatus.Phase.REDUCE); \n    statusUpdate(umbilical);\n    Class keyClass \u003d job.getMapOutputKeyClass();\n    Class valueClass \u003d job.getMapOutputValueClass();\n    RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n\n    if (useNewApi) {\n      runNewReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    } else {\n      runOldReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    }\n    done(umbilical, reporter);\n  }",
          "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java",
          "extendedDetails": {}
        }
      ]
    },
    "ded6f225a55517deedc2bd502f2b68f1ca2ddee8": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2837. Ported bug fixes from y-merge to prepare for MAPREDUCE-279 merge. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1157249 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/08/11 2:00 PM",
      "commitName": "ded6f225a55517deedc2bd502f2b68f1ca2ddee8",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "01/08/11 3:53 PM",
      "commitNameOld": "9bac807cedbcff34e1a144fb475eff267e5ed86d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 10.92,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,82 @@\n   public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n     throws IOException, InterruptedException, ClassNotFoundException {\n     job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n \n     if (isMapOrReduce()) {\n       copyPhase \u003d getProgress().addPhase(\"copy\");\n       sortPhase  \u003d getProgress().addPhase(\"sort\");\n       reducePhase \u003d getProgress().addPhase(\"reduce\");\n     }\n     // start thread that will handle communication with parent\n     TaskReporter reporter \u003d startReporter(umbilical);\n     \n     boolean useNewApi \u003d job.getUseNewReducer();\n     initialize(job, getJobID(), reporter, useNewApi);\n \n     // check if it is a cleanupJobTask\n     if (jobCleanup) {\n       runJobCleanupTask(umbilical, reporter);\n       return;\n     }\n     if (jobSetup) {\n       runJobSetupTask(umbilical, reporter);\n       return;\n     }\n     if (taskCleanup) {\n       runTaskCleanupTask(umbilical, reporter);\n       return;\n     }\n     \n     // Initialize the codec\n     codec \u003d initCodec();\n     RawKeyValueIterator rIter \u003d null;\n     boolean isLocal \u003d \"local\".equals(job.get(JTConfig.JT_IPC_ADDRESS, \"local\"));\n     if (!isLocal) {\n       Class combinerClass \u003d conf.getCombinerClass();\n       CombineOutputCollector combineCollector \u003d \n         (null !\u003d combinerClass) ? \n  \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n \n       Shuffle shuffle \u003d \n         new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                     super.lDirAlloc, reporter, codec, \n                     combinerClass, combineCollector, \n                     spilledRecordsCounter, reduceCombineInputCounter,\n                     shuffledMapsCounter,\n                     reduceShuffleBytes, failedShuffleCounter,\n                     mergedMapOutputsCounter,\n-                    taskStatus, copyPhase, sortPhase, this);\n+                    taskStatus, copyPhase, sortPhase, this,\n+                    mapOutputFile);\n       rIter \u003d shuffle.run();\n     } else {\n       // local job runner doesn\u0027t have a copy phase\n       copyPhase.complete();\n       final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n       rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                            job.getMapOutputValueClass(), codec, \n                            getMapFiles(rfs, true),\n                            !conf.getKeepFailedTaskFiles(), \n                            job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                            new Path(getTaskID().toString()), \n                            job.getOutputKeyComparator(),\n                            reporter, spilledRecordsCounter, null, null);\n     }\n     // free up the data structures\n     mapOutputFilesOnDisk.clear();\n     \n     sortPhase.complete();                         // sort is complete\n     setPhase(TaskStatus.Phase.REDUCE); \n     statusUpdate(umbilical);\n     Class keyClass \u003d job.getMapOutputKeyClass();\n     Class valueClass \u003d job.getMapOutputValueClass();\n     RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n \n     if (useNewApi) {\n       runNewReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     } else {\n       runOldReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     }\n     done(umbilical, reporter);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n    throws IOException, InterruptedException, ClassNotFoundException {\n    job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n\n    if (isMapOrReduce()) {\n      copyPhase \u003d getProgress().addPhase(\"copy\");\n      sortPhase  \u003d getProgress().addPhase(\"sort\");\n      reducePhase \u003d getProgress().addPhase(\"reduce\");\n    }\n    // start thread that will handle communication with parent\n    TaskReporter reporter \u003d startReporter(umbilical);\n    \n    boolean useNewApi \u003d job.getUseNewReducer();\n    initialize(job, getJobID(), reporter, useNewApi);\n\n    // check if it is a cleanupJobTask\n    if (jobCleanup) {\n      runJobCleanupTask(umbilical, reporter);\n      return;\n    }\n    if (jobSetup) {\n      runJobSetupTask(umbilical, reporter);\n      return;\n    }\n    if (taskCleanup) {\n      runTaskCleanupTask(umbilical, reporter);\n      return;\n    }\n    \n    // Initialize the codec\n    codec \u003d initCodec();\n    RawKeyValueIterator rIter \u003d null;\n    boolean isLocal \u003d \"local\".equals(job.get(JTConfig.JT_IPC_ADDRESS, \"local\"));\n    if (!isLocal) {\n      Class combinerClass \u003d conf.getCombinerClass();\n      CombineOutputCollector combineCollector \u003d \n        (null !\u003d combinerClass) ? \n \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n\n      Shuffle shuffle \u003d \n        new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                    super.lDirAlloc, reporter, codec, \n                    combinerClass, combineCollector, \n                    spilledRecordsCounter, reduceCombineInputCounter,\n                    shuffledMapsCounter,\n                    reduceShuffleBytes, failedShuffleCounter,\n                    mergedMapOutputsCounter,\n                    taskStatus, copyPhase, sortPhase, this,\n                    mapOutputFile);\n      rIter \u003d shuffle.run();\n    } else {\n      // local job runner doesn\u0027t have a copy phase\n      copyPhase.complete();\n      final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n      rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                           job.getMapOutputValueClass(), codec, \n                           getMapFiles(rfs, true),\n                           !conf.getKeepFailedTaskFiles(), \n                           job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                           new Path(getTaskID().toString()), \n                           job.getOutputKeyComparator(),\n                           reporter, spilledRecordsCounter, null, null);\n    }\n    // free up the data structures\n    mapOutputFilesOnDisk.clear();\n    \n    sortPhase.complete();                         // sort is complete\n    setPhase(TaskStatus.Phase.REDUCE); \n    statusUpdate(umbilical);\n    Class keyClass \u003d job.getMapOutputKeyClass();\n    Class valueClass \u003d job.getMapOutputValueClass();\n    RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n\n    if (useNewApi) {\n      runNewReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    } else {\n      runOldReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    }\n    done(umbilical, reporter);\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapred/ReduceTask.java",
      "extendedDetails": {}
    },
    "9bac807cedbcff34e1a144fb475eff267e5ed86d": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2187. Reporter sends progress during sort/merge. Contributed by Anupam Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152964 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/08/11 3:53 PM",
      "commitName": "9bac807cedbcff34e1a144fb475eff267e5ed86d",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "13/07/11 4:36 PM",
      "commitNameOld": "4796e1adcb912005198c9003305c97cf3a8b523e",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 18.97,
      "commitsBetweenForRepo": 67,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,81 @@\n   public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n     throws IOException, InterruptedException, ClassNotFoundException {\n     job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n \n     if (isMapOrReduce()) {\n       copyPhase \u003d getProgress().addPhase(\"copy\");\n       sortPhase  \u003d getProgress().addPhase(\"sort\");\n       reducePhase \u003d getProgress().addPhase(\"reduce\");\n     }\n     // start thread that will handle communication with parent\n     TaskReporter reporter \u003d startReporter(umbilical);\n     \n     boolean useNewApi \u003d job.getUseNewReducer();\n     initialize(job, getJobID(), reporter, useNewApi);\n \n     // check if it is a cleanupJobTask\n     if (jobCleanup) {\n       runJobCleanupTask(umbilical, reporter);\n       return;\n     }\n     if (jobSetup) {\n       runJobSetupTask(umbilical, reporter);\n       return;\n     }\n     if (taskCleanup) {\n       runTaskCleanupTask(umbilical, reporter);\n       return;\n     }\n     \n     // Initialize the codec\n     codec \u003d initCodec();\n     RawKeyValueIterator rIter \u003d null;\n     boolean isLocal \u003d \"local\".equals(job.get(JTConfig.JT_IPC_ADDRESS, \"local\"));\n     if (!isLocal) {\n       Class combinerClass \u003d conf.getCombinerClass();\n       CombineOutputCollector combineCollector \u003d \n         (null !\u003d combinerClass) ? \n-            new CombineOutputCollector(reduceCombineOutputCounter) : null;\n+ \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n \n       Shuffle shuffle \u003d \n         new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                     super.lDirAlloc, reporter, codec, \n                     combinerClass, combineCollector, \n                     spilledRecordsCounter, reduceCombineInputCounter,\n                     shuffledMapsCounter,\n                     reduceShuffleBytes, failedShuffleCounter,\n                     mergedMapOutputsCounter,\n                     taskStatus, copyPhase, sortPhase, this);\n       rIter \u003d shuffle.run();\n     } else {\n       // local job runner doesn\u0027t have a copy phase\n       copyPhase.complete();\n       final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n       rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                            job.getMapOutputValueClass(), codec, \n                            getMapFiles(rfs, true),\n                            !conf.getKeepFailedTaskFiles(), \n                            job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                            new Path(getTaskID().toString()), \n                            job.getOutputKeyComparator(),\n                            reporter, spilledRecordsCounter, null, null);\n     }\n     // free up the data structures\n     mapOutputFilesOnDisk.clear();\n     \n     sortPhase.complete();                         // sort is complete\n     setPhase(TaskStatus.Phase.REDUCE); \n     statusUpdate(umbilical);\n     Class keyClass \u003d job.getMapOutputKeyClass();\n     Class valueClass \u003d job.getMapOutputValueClass();\n     RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n \n     if (useNewApi) {\n       runNewReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     } else {\n       runOldReducer(job, umbilical, reporter, rIter, comparator, \n                     keyClass, valueClass);\n     }\n     done(umbilical, reporter);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n    throws IOException, InterruptedException, ClassNotFoundException {\n    job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n\n    if (isMapOrReduce()) {\n      copyPhase \u003d getProgress().addPhase(\"copy\");\n      sortPhase  \u003d getProgress().addPhase(\"sort\");\n      reducePhase \u003d getProgress().addPhase(\"reduce\");\n    }\n    // start thread that will handle communication with parent\n    TaskReporter reporter \u003d startReporter(umbilical);\n    \n    boolean useNewApi \u003d job.getUseNewReducer();\n    initialize(job, getJobID(), reporter, useNewApi);\n\n    // check if it is a cleanupJobTask\n    if (jobCleanup) {\n      runJobCleanupTask(umbilical, reporter);\n      return;\n    }\n    if (jobSetup) {\n      runJobSetupTask(umbilical, reporter);\n      return;\n    }\n    if (taskCleanup) {\n      runTaskCleanupTask(umbilical, reporter);\n      return;\n    }\n    \n    // Initialize the codec\n    codec \u003d initCodec();\n    RawKeyValueIterator rIter \u003d null;\n    boolean isLocal \u003d \"local\".equals(job.get(JTConfig.JT_IPC_ADDRESS, \"local\"));\n    if (!isLocal) {\n      Class combinerClass \u003d conf.getCombinerClass();\n      CombineOutputCollector combineCollector \u003d \n        (null !\u003d combinerClass) ? \n \t     new CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : null;\n\n      Shuffle shuffle \u003d \n        new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                    super.lDirAlloc, reporter, codec, \n                    combinerClass, combineCollector, \n                    spilledRecordsCounter, reduceCombineInputCounter,\n                    shuffledMapsCounter,\n                    reduceShuffleBytes, failedShuffleCounter,\n                    mergedMapOutputsCounter,\n                    taskStatus, copyPhase, sortPhase, this);\n      rIter \u003d shuffle.run();\n    } else {\n      // local job runner doesn\u0027t have a copy phase\n      copyPhase.complete();\n      final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n      rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                           job.getMapOutputValueClass(), codec, \n                           getMapFiles(rfs, true),\n                           !conf.getKeepFailedTaskFiles(), \n                           job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                           new Path(getTaskID().toString()), \n                           job.getOutputKeyComparator(),\n                           reporter, spilledRecordsCounter, null, null);\n    }\n    // free up the data structures\n    mapOutputFilesOnDisk.clear();\n    \n    sortPhase.complete();                         // sort is complete\n    setPhase(TaskStatus.Phase.REDUCE); \n    statusUpdate(umbilical);\n    Class keyClass \u003d job.getMapOutputKeyClass();\n    Class valueClass \u003d job.getMapOutputValueClass();\n    RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n\n    if (useNewApi) {\n      runNewReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    } else {\n      runOldReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    }\n    done(umbilical, reporter);\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapred/ReduceTask.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,81 @@\n+  public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n+    throws IOException, InterruptedException, ClassNotFoundException {\n+    job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n+\n+    if (isMapOrReduce()) {\n+      copyPhase \u003d getProgress().addPhase(\"copy\");\n+      sortPhase  \u003d getProgress().addPhase(\"sort\");\n+      reducePhase \u003d getProgress().addPhase(\"reduce\");\n+    }\n+    // start thread that will handle communication with parent\n+    TaskReporter reporter \u003d startReporter(umbilical);\n+    \n+    boolean useNewApi \u003d job.getUseNewReducer();\n+    initialize(job, getJobID(), reporter, useNewApi);\n+\n+    // check if it is a cleanupJobTask\n+    if (jobCleanup) {\n+      runJobCleanupTask(umbilical, reporter);\n+      return;\n+    }\n+    if (jobSetup) {\n+      runJobSetupTask(umbilical, reporter);\n+      return;\n+    }\n+    if (taskCleanup) {\n+      runTaskCleanupTask(umbilical, reporter);\n+      return;\n+    }\n+    \n+    // Initialize the codec\n+    codec \u003d initCodec();\n+    RawKeyValueIterator rIter \u003d null;\n+    boolean isLocal \u003d \"local\".equals(job.get(JTConfig.JT_IPC_ADDRESS, \"local\"));\n+    if (!isLocal) {\n+      Class combinerClass \u003d conf.getCombinerClass();\n+      CombineOutputCollector combineCollector \u003d \n+        (null !\u003d combinerClass) ? \n+            new CombineOutputCollector(reduceCombineOutputCounter) : null;\n+\n+      Shuffle shuffle \u003d \n+        new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n+                    super.lDirAlloc, reporter, codec, \n+                    combinerClass, combineCollector, \n+                    spilledRecordsCounter, reduceCombineInputCounter,\n+                    shuffledMapsCounter,\n+                    reduceShuffleBytes, failedShuffleCounter,\n+                    mergedMapOutputsCounter,\n+                    taskStatus, copyPhase, sortPhase, this);\n+      rIter \u003d shuffle.run();\n+    } else {\n+      // local job runner doesn\u0027t have a copy phase\n+      copyPhase.complete();\n+      final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n+      rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n+                           job.getMapOutputValueClass(), codec, \n+                           getMapFiles(rfs, true),\n+                           !conf.getKeepFailedTaskFiles(), \n+                           job.getInt(JobContext.IO_SORT_FACTOR, 100),\n+                           new Path(getTaskID().toString()), \n+                           job.getOutputKeyComparator(),\n+                           reporter, spilledRecordsCounter, null, null);\n+    }\n+    // free up the data structures\n+    mapOutputFilesOnDisk.clear();\n+    \n+    sortPhase.complete();                         // sort is complete\n+    setPhase(TaskStatus.Phase.REDUCE); \n+    statusUpdate(umbilical);\n+    Class keyClass \u003d job.getMapOutputKeyClass();\n+    Class valueClass \u003d job.getMapOutputValueClass();\n+    RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n+\n+    if (useNewApi) {\n+      runNewReducer(job, umbilical, reporter, rIter, comparator, \n+                    keyClass, valueClass);\n+    } else {\n+      runOldReducer(job, umbilical, reporter, rIter, comparator, \n+                    keyClass, valueClass);\n+    }\n+    done(umbilical, reporter);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void run(JobConf job, final TaskUmbilicalProtocol umbilical)\n    throws IOException, InterruptedException, ClassNotFoundException {\n    job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());\n\n    if (isMapOrReduce()) {\n      copyPhase \u003d getProgress().addPhase(\"copy\");\n      sortPhase  \u003d getProgress().addPhase(\"sort\");\n      reducePhase \u003d getProgress().addPhase(\"reduce\");\n    }\n    // start thread that will handle communication with parent\n    TaskReporter reporter \u003d startReporter(umbilical);\n    \n    boolean useNewApi \u003d job.getUseNewReducer();\n    initialize(job, getJobID(), reporter, useNewApi);\n\n    // check if it is a cleanupJobTask\n    if (jobCleanup) {\n      runJobCleanupTask(umbilical, reporter);\n      return;\n    }\n    if (jobSetup) {\n      runJobSetupTask(umbilical, reporter);\n      return;\n    }\n    if (taskCleanup) {\n      runTaskCleanupTask(umbilical, reporter);\n      return;\n    }\n    \n    // Initialize the codec\n    codec \u003d initCodec();\n    RawKeyValueIterator rIter \u003d null;\n    boolean isLocal \u003d \"local\".equals(job.get(JTConfig.JT_IPC_ADDRESS, \"local\"));\n    if (!isLocal) {\n      Class combinerClass \u003d conf.getCombinerClass();\n      CombineOutputCollector combineCollector \u003d \n        (null !\u003d combinerClass) ? \n            new CombineOutputCollector(reduceCombineOutputCounter) : null;\n\n      Shuffle shuffle \u003d \n        new Shuffle(getTaskID(), job, FileSystem.getLocal(job), umbilical, \n                    super.lDirAlloc, reporter, codec, \n                    combinerClass, combineCollector, \n                    spilledRecordsCounter, reduceCombineInputCounter,\n                    shuffledMapsCounter,\n                    reduceShuffleBytes, failedShuffleCounter,\n                    mergedMapOutputsCounter,\n                    taskStatus, copyPhase, sortPhase, this);\n      rIter \u003d shuffle.run();\n    } else {\n      // local job runner doesn\u0027t have a copy phase\n      copyPhase.complete();\n      final FileSystem rfs \u003d FileSystem.getLocal(job).getRaw();\n      rIter \u003d Merger.merge(job, rfs, job.getMapOutputKeyClass(),\n                           job.getMapOutputValueClass(), codec, \n                           getMapFiles(rfs, true),\n                           !conf.getKeepFailedTaskFiles(), \n                           job.getInt(JobContext.IO_SORT_FACTOR, 100),\n                           new Path(getTaskID().toString()), \n                           job.getOutputKeyComparator(),\n                           reporter, spilledRecordsCounter, null, null);\n    }\n    // free up the data structures\n    mapOutputFilesOnDisk.clear();\n    \n    sortPhase.complete();                         // sort is complete\n    setPhase(TaskStatus.Phase.REDUCE); \n    statusUpdate(umbilical);\n    Class keyClass \u003d job.getMapOutputKeyClass();\n    Class valueClass \u003d job.getMapOutputValueClass();\n    RawComparator comparator \u003d job.getOutputValueGroupingComparator();\n\n    if (useNewApi) {\n      runNewReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    } else {\n      runOldReducer(job, umbilical, reporter, rIter, comparator, \n                    keyClass, valueClass);\n    }\n    done(umbilical, reporter);\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapred/ReduceTask.java"
    }
  }
}