{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AbstractCSQueue.java",
  "functionName": "canAssignToThisQueue",
  "functionId": "canAssignToThisQueue___clusterResource-Resource__nodePartition-String__currentResourceLimits-ResourceLimits__resourceCouldBeUnreserved-Resource__schedulingMode-SchedulingMode",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
  "functionStartLine": 1038,
  "functionEndLine": 1131,
  "numCommitsSeen": 313,
  "timeTaken": 17611,
  "changeHistory": [
    "cdb2107066a2d8557270888c0a9a75f29a6853bf",
    "39b4a37e02e929a698fcf9e32f1f71bb6b977635",
    "fa1aaee87b0141a0255b5f8e5fd8e8f49d7efe86",
    "9594c35dcb655add1991d8fd15897b40c4ad6205",
    "2b66d9ec5bdaec7e6b278926fbb6f222c4e3afaa",
    "ae14e5d07f1b6702a5160637438028bb03d9387e",
    "fa7a43529d529f0006c8033c2003f15b9b93f103",
    "7e8c9beb4156dcaeb3a11e60aaa06d2370626913",
    "83fe34ac0896cee0918bbfad7bd51231e4aec39b",
    "189a63a719c63b67a1783a280bfc2f72dcb55277",
    "0fefda645bca935b87b6bb8ca63e6f18340d59f5",
    "487374b7fe0c92fc7eb1406c568952722b5d5b15",
    "18a594257e052e8f10a03e5594e6cc6901dc56be",
    "86358221fc85a7743052a0b4c1647353508bf308",
    "f2ea555ac6c06a3f2f6559731f48711fff05d3f1",
    "9c22065109a77681bc2534063eabe8692fbcb3cd",
    "44b6261bfacddea88a3cf02d406f970bbbb98d04",
    "453926397182078c65a4428eb5de5a90d6af6448",
    "e1fdf62123625e4ba399af02f8aad500637d29d1",
    "9d1621da52fd7f4ee68f80fdbf420180a42b5b1d",
    "224fc101fdfa355b4ad842fc39192d8e4f1f2979",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "cdb2107066a2d8557270888c0a9a75f29a6853bf": "Ybodychange",
    "39b4a37e02e929a698fcf9e32f1f71bb6b977635": "Ybodychange",
    "fa1aaee87b0141a0255b5f8e5fd8e8f49d7efe86": "Ybodychange",
    "9594c35dcb655add1991d8fd15897b40c4ad6205": "Ybodychange",
    "2b66d9ec5bdaec7e6b278926fbb6f222c4e3afaa": "Ymultichange(Ymodifierchange,Ybodychange)",
    "ae14e5d07f1b6702a5160637438028bb03d9387e": "Ybodychange",
    "fa7a43529d529f0006c8033c2003f15b9b93f103": "Ybodychange",
    "7e8c9beb4156dcaeb3a11e60aaa06d2370626913": "Ybodychange",
    "83fe34ac0896cee0918bbfad7bd51231e4aec39b": "Ymultichange(Yparameterchange,Ybodychange)",
    "189a63a719c63b67a1783a280bfc2f72dcb55277": "Ybodychange",
    "0fefda645bca935b87b6bb8ca63e6f18340d59f5": "Ymultichange(Yparameterchange,Ybodychange)",
    "487374b7fe0c92fc7eb1406c568952722b5d5b15": "Ymultichange(Ymovefromfile,Ybodychange,Yparameterchange)",
    "18a594257e052e8f10a03e5594e6cc6901dc56be": "Ybodychange",
    "86358221fc85a7743052a0b4c1647353508bf308": "Ybodychange",
    "f2ea555ac6c06a3f2f6559731f48711fff05d3f1": "Ymultichange(Yrename,Yparameterchange,Ymodifierchange,Ybodychange)",
    "9c22065109a77681bc2534063eabe8692fbcb3cd": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
    "44b6261bfacddea88a3cf02d406f970bbbb98d04": "Ybodychange",
    "453926397182078c65a4428eb5de5a90d6af6448": "Ybodychange",
    "e1fdf62123625e4ba399af02f8aad500637d29d1": "Yfilerename",
    "9d1621da52fd7f4ee68f80fdbf420180a42b5b1d": "Ybodychange",
    "224fc101fdfa355b4ad842fc39192d8e4f1f2979": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "cdb2107066a2d8557270888c0a9a75f29a6853bf": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9879. Allow multiple leaf queues with the same name in CapacityScheduler. Contributed by Gergely Pollak.\n",
      "commitDate": "25/03/20 4:20 AM",
      "commitName": "cdb2107066a2d8557270888c0a9a75f29a6853bf",
      "commitAuthor": "Sunil G",
      "commitDateOld": "28/01/20 7:54 PM",
      "commitNameOld": "e578e52aae01248507e089b406fe038ab8e84207",
      "commitAuthorOld": "Eric Badger",
      "daysBetweenCommits": 56.31,
      "commitsBetweenForRepo": 177,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,94 @@\n   boolean canAssignToThisQueue(Resource clusterResource,\n       String nodePartition, ResourceLimits currentResourceLimits,\n       Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n     readLock.lock();\n     try {\n       // Get current limited resource:\n       // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n       // queues\u0027 max capacity.\n       // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n       // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n       // considered to be 100%. Which is a queue can use all resource in the\n       // partition.\n       // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n       // idle resource on the partition, to avoid wastage, such resource will be\n       // leveraged as much as we can, and preemption policy will reclaim it back\n       // when partitoned-resource-request comes back.\n       Resource currentLimitResource \u003d getCurrentLimitResource(nodePartition,\n           clusterResource, currentResourceLimits, schedulingMode);\n \n       Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n \n       // Set headroom for currentResourceLimits:\n       // When queue is a parent queue: Headroom \u003d limit - used + killable\n       // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n       Resource usedExceptKillable \u003d nowTotalUsed;\n       if (hasChildQueues()) {\n         usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n             getTotalKillableResource(nodePartition));\n       }\n       currentResourceLimits.setHeadroom(\n           Resources.subtract(currentLimitResource, usedExceptKillable));\n \n       if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n           usedExceptKillable, currentLimitResource)) {\n \n         // if reservation continous looking enabled, check to see if could we\n         // potentially use this node instead of a reserved node if the application\n         // has reserved containers.\n         // TODO, now only consider reservation cases when the node has no label\n         if (this.reservationsContinueLooking \u0026\u0026 nodePartition.equals(\n             RMNodeLabelsManager.NO_LABEL) \u0026\u0026 Resources.greaterThan(\n             resourceCalculator, clusterResource, resourceCouldBeUnreserved,\n             Resources.none())) {\n           // resource-without-reserved \u003d used - reserved\n           Resource newTotalWithoutReservedResource \u003d Resources.subtract(\n               usedExceptKillable, resourceCouldBeUnreserved);\n \n           // when total-used-without-reserved-resource \u003c currentLimit, we still\n           // have chance to allocate on this node by unreserving some containers\n           if (Resources.lessThan(resourceCalculator, clusterResource,\n               newTotalWithoutReservedResource, currentLimitResource)) {\n             if (LOG.isDebugEnabled()) {\n-              LOG.debug(\"try to use reserved: \" + getQueueName()\n+              LOG.debug(\"try to use reserved: \" + getQueuePath()\n                   + \" usedResources: \" + queueUsage.getUsed()\n                   + \", clusterResources: \" + clusterResource\n                   + \", reservedResources: \" + resourceCouldBeUnreserved\n                   + \", capacity-without-reserved: \"\n                   + newTotalWithoutReservedResource\n                   + \", maxLimitCapacity: \" + currentLimitResource);\n             }\n             return true;\n           }\n         }\n \n         // Can not assign to this queue\n         if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"Failed to assign to queue: \" + getQueueName()\n+          LOG.debug(\"Failed to assign to queue: \" + getQueuePath()\n               + \" nodePatrition: \" + nodePartition\n               + \", usedResources: \" + queueUsage.getUsed(nodePartition)\n               + \", clusterResources: \" + clusterResource\n               + \", reservedResources: \" + resourceCouldBeUnreserved\n               + \", maxLimitCapacity: \" + currentLimitResource\n               + \", currTotalUsed:\" + usedExceptKillable);\n         }\n         return false;\n       }\n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Check assign to queue: \" + getQueueName()\n+        LOG.debug(\"Check assign to queue: \" + getQueuePath()\n             + \" nodePartition: \" + nodePartition\n             + \", usedResources: \" + queueUsage.getUsed(nodePartition)\n             + \", clusterResources: \" + clusterResource\n             + \", currentUsedCapacity: \" + Resources\n             .divide(resourceCalculator, clusterResource,\n                 queueUsage.getUsed(nodePartition), labelManager\n                     .getResourceByLabel(nodePartition, clusterResource))\n             + \", max-capacity: \" + queueCapacities\n             .getAbsoluteMaximumCapacity(nodePartition));\n       }\n       return true;\n     } finally {\n       readLock.unlock();\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean canAssignToThisQueue(Resource clusterResource,\n      String nodePartition, ResourceLimits currentResourceLimits,\n      Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n    readLock.lock();\n    try {\n      // Get current limited resource:\n      // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n      // queues\u0027 max capacity.\n      // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n      // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n      // considered to be 100%. Which is a queue can use all resource in the\n      // partition.\n      // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n      // idle resource on the partition, to avoid wastage, such resource will be\n      // leveraged as much as we can, and preemption policy will reclaim it back\n      // when partitoned-resource-request comes back.\n      Resource currentLimitResource \u003d getCurrentLimitResource(nodePartition,\n          clusterResource, currentResourceLimits, schedulingMode);\n\n      Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n\n      // Set headroom for currentResourceLimits:\n      // When queue is a parent queue: Headroom \u003d limit - used + killable\n      // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n      Resource usedExceptKillable \u003d nowTotalUsed;\n      if (hasChildQueues()) {\n        usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n            getTotalKillableResource(nodePartition));\n      }\n      currentResourceLimits.setHeadroom(\n          Resources.subtract(currentLimitResource, usedExceptKillable));\n\n      if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n          usedExceptKillable, currentLimitResource)) {\n\n        // if reservation continous looking enabled, check to see if could we\n        // potentially use this node instead of a reserved node if the application\n        // has reserved containers.\n        // TODO, now only consider reservation cases when the node has no label\n        if (this.reservationsContinueLooking \u0026\u0026 nodePartition.equals(\n            RMNodeLabelsManager.NO_LABEL) \u0026\u0026 Resources.greaterThan(\n            resourceCalculator, clusterResource, resourceCouldBeUnreserved,\n            Resources.none())) {\n          // resource-without-reserved \u003d used - reserved\n          Resource newTotalWithoutReservedResource \u003d Resources.subtract(\n              usedExceptKillable, resourceCouldBeUnreserved);\n\n          // when total-used-without-reserved-resource \u003c currentLimit, we still\n          // have chance to allocate on this node by unreserving some containers\n          if (Resources.lessThan(resourceCalculator, clusterResource,\n              newTotalWithoutReservedResource, currentLimitResource)) {\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"try to use reserved: \" + getQueuePath()\n                  + \" usedResources: \" + queueUsage.getUsed()\n                  + \", clusterResources: \" + clusterResource\n                  + \", reservedResources: \" + resourceCouldBeUnreserved\n                  + \", capacity-without-reserved: \"\n                  + newTotalWithoutReservedResource\n                  + \", maxLimitCapacity: \" + currentLimitResource);\n            }\n            return true;\n          }\n        }\n\n        // Can not assign to this queue\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Failed to assign to queue: \" + getQueuePath()\n              + \" nodePatrition: \" + nodePartition\n              + \", usedResources: \" + queueUsage.getUsed(nodePartition)\n              + \", clusterResources: \" + clusterResource\n              + \", reservedResources: \" + resourceCouldBeUnreserved\n              + \", maxLimitCapacity: \" + currentLimitResource\n              + \", currTotalUsed:\" + usedExceptKillable);\n        }\n        return false;\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Check assign to queue: \" + getQueuePath()\n            + \" nodePartition: \" + nodePartition\n            + \", usedResources: \" + queueUsage.getUsed(nodePartition)\n            + \", clusterResources: \" + clusterResource\n            + \", currentUsedCapacity: \" + Resources\n            .divide(resourceCalculator, clusterResource,\n                queueUsage.getUsed(nodePartition), labelManager\n                    .getResourceByLabel(nodePartition, clusterResource))\n            + \", max-capacity: \" + queueCapacities\n            .getAbsoluteMaximumCapacity(nodePartition));\n      }\n      return true;\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
      "extendedDetails": {}
    },
    "39b4a37e02e929a698fcf9e32f1f71bb6b977635": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9341.  Fixed enentrant lock usage in YARN project.\n            Contributed by Prabhu Joseph\n",
      "commitDate": "07/03/19 1:47 PM",
      "commitName": "39b4a37e02e929a698fcf9e32f1f71bb6b977635",
      "commitAuthor": "Eric Yang",
      "commitDateOld": "04/03/19 9:10 PM",
      "commitNameOld": "e40e2d6ad5cbe782c3a067229270738b501ed27e",
      "commitAuthorOld": "Prabhu Joseph",
      "daysBetweenCommits": 2.69,
      "commitsBetweenForRepo": 39,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,94 @@\n   boolean canAssignToThisQueue(Resource clusterResource,\n       String nodePartition, ResourceLimits currentResourceLimits,\n       Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n+    readLock.lock();\n     try {\n-      readLock.lock();\n       // Get current limited resource:\n       // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n       // queues\u0027 max capacity.\n       // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n       // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n       // considered to be 100%. Which is a queue can use all resource in the\n       // partition.\n       // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n       // idle resource on the partition, to avoid wastage, such resource will be\n       // leveraged as much as we can, and preemption policy will reclaim it back\n       // when partitoned-resource-request comes back.\n       Resource currentLimitResource \u003d getCurrentLimitResource(nodePartition,\n           clusterResource, currentResourceLimits, schedulingMode);\n \n       Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n \n       // Set headroom for currentResourceLimits:\n       // When queue is a parent queue: Headroom \u003d limit - used + killable\n       // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n       Resource usedExceptKillable \u003d nowTotalUsed;\n       if (hasChildQueues()) {\n         usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n             getTotalKillableResource(nodePartition));\n       }\n       currentResourceLimits.setHeadroom(\n           Resources.subtract(currentLimitResource, usedExceptKillable));\n \n       if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n           usedExceptKillable, currentLimitResource)) {\n \n         // if reservation continous looking enabled, check to see if could we\n         // potentially use this node instead of a reserved node if the application\n         // has reserved containers.\n         // TODO, now only consider reservation cases when the node has no label\n         if (this.reservationsContinueLooking \u0026\u0026 nodePartition.equals(\n             RMNodeLabelsManager.NO_LABEL) \u0026\u0026 Resources.greaterThan(\n             resourceCalculator, clusterResource, resourceCouldBeUnreserved,\n             Resources.none())) {\n           // resource-without-reserved \u003d used - reserved\n           Resource newTotalWithoutReservedResource \u003d Resources.subtract(\n               usedExceptKillable, resourceCouldBeUnreserved);\n \n           // when total-used-without-reserved-resource \u003c currentLimit, we still\n           // have chance to allocate on this node by unreserving some containers\n           if (Resources.lessThan(resourceCalculator, clusterResource,\n               newTotalWithoutReservedResource, currentLimitResource)) {\n             if (LOG.isDebugEnabled()) {\n               LOG.debug(\"try to use reserved: \" + getQueueName()\n                   + \" usedResources: \" + queueUsage.getUsed()\n                   + \", clusterResources: \" + clusterResource\n                   + \", reservedResources: \" + resourceCouldBeUnreserved\n                   + \", capacity-without-reserved: \"\n                   + newTotalWithoutReservedResource\n                   + \", maxLimitCapacity: \" + currentLimitResource);\n             }\n             return true;\n           }\n         }\n \n         // Can not assign to this queue\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Failed to assign to queue: \" + getQueueName()\n               + \" nodePatrition: \" + nodePartition\n               + \", usedResources: \" + queueUsage.getUsed(nodePartition)\n               + \", clusterResources: \" + clusterResource\n               + \", reservedResources: \" + resourceCouldBeUnreserved\n               + \", maxLimitCapacity: \" + currentLimitResource\n               + \", currTotalUsed:\" + usedExceptKillable);\n         }\n         return false;\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Check assign to queue: \" + getQueueName()\n             + \" nodePartition: \" + nodePartition\n             + \", usedResources: \" + queueUsage.getUsed(nodePartition)\n             + \", clusterResources: \" + clusterResource\n             + \", currentUsedCapacity: \" + Resources\n             .divide(resourceCalculator, clusterResource,\n                 queueUsage.getUsed(nodePartition), labelManager\n                     .getResourceByLabel(nodePartition, clusterResource))\n             + \", max-capacity: \" + queueCapacities\n             .getAbsoluteMaximumCapacity(nodePartition));\n       }\n       return true;\n     } finally {\n       readLock.unlock();\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean canAssignToThisQueue(Resource clusterResource,\n      String nodePartition, ResourceLimits currentResourceLimits,\n      Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n    readLock.lock();\n    try {\n      // Get current limited resource:\n      // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n      // queues\u0027 max capacity.\n      // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n      // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n      // considered to be 100%. Which is a queue can use all resource in the\n      // partition.\n      // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n      // idle resource on the partition, to avoid wastage, such resource will be\n      // leveraged as much as we can, and preemption policy will reclaim it back\n      // when partitoned-resource-request comes back.\n      Resource currentLimitResource \u003d getCurrentLimitResource(nodePartition,\n          clusterResource, currentResourceLimits, schedulingMode);\n\n      Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n\n      // Set headroom for currentResourceLimits:\n      // When queue is a parent queue: Headroom \u003d limit - used + killable\n      // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n      Resource usedExceptKillable \u003d nowTotalUsed;\n      if (hasChildQueues()) {\n        usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n            getTotalKillableResource(nodePartition));\n      }\n      currentResourceLimits.setHeadroom(\n          Resources.subtract(currentLimitResource, usedExceptKillable));\n\n      if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n          usedExceptKillable, currentLimitResource)) {\n\n        // if reservation continous looking enabled, check to see if could we\n        // potentially use this node instead of a reserved node if the application\n        // has reserved containers.\n        // TODO, now only consider reservation cases when the node has no label\n        if (this.reservationsContinueLooking \u0026\u0026 nodePartition.equals(\n            RMNodeLabelsManager.NO_LABEL) \u0026\u0026 Resources.greaterThan(\n            resourceCalculator, clusterResource, resourceCouldBeUnreserved,\n            Resources.none())) {\n          // resource-without-reserved \u003d used - reserved\n          Resource newTotalWithoutReservedResource \u003d Resources.subtract(\n              usedExceptKillable, resourceCouldBeUnreserved);\n\n          // when total-used-without-reserved-resource \u003c currentLimit, we still\n          // have chance to allocate on this node by unreserving some containers\n          if (Resources.lessThan(resourceCalculator, clusterResource,\n              newTotalWithoutReservedResource, currentLimitResource)) {\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"try to use reserved: \" + getQueueName()\n                  + \" usedResources: \" + queueUsage.getUsed()\n                  + \", clusterResources: \" + clusterResource\n                  + \", reservedResources: \" + resourceCouldBeUnreserved\n                  + \", capacity-without-reserved: \"\n                  + newTotalWithoutReservedResource\n                  + \", maxLimitCapacity: \" + currentLimitResource);\n            }\n            return true;\n          }\n        }\n\n        // Can not assign to this queue\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Failed to assign to queue: \" + getQueueName()\n              + \" nodePatrition: \" + nodePartition\n              + \", usedResources: \" + queueUsage.getUsed(nodePartition)\n              + \", clusterResources: \" + clusterResource\n              + \", reservedResources: \" + resourceCouldBeUnreserved\n              + \", maxLimitCapacity: \" + currentLimitResource\n              + \", currTotalUsed:\" + usedExceptKillable);\n        }\n        return false;\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Check assign to queue: \" + getQueueName()\n            + \" nodePartition: \" + nodePartition\n            + \", usedResources: \" + queueUsage.getUsed(nodePartition)\n            + \", clusterResources: \" + clusterResource\n            + \", currentUsedCapacity: \" + Resources\n            .divide(resourceCalculator, clusterResource,\n                queueUsage.getUsed(nodePartition), labelManager\n                    .getResourceByLabel(nodePartition, clusterResource))\n            + \", max-capacity: \" + queueCapacities\n            .getAbsoluteMaximumCapacity(nodePartition));\n      }\n      return true;\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
      "extendedDetails": {}
    },
    "fa1aaee87b0141a0255b5f8e5fd8e8f49d7efe86": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6681. Eliminate double-copy of child queues in canAssignToThisQueue. Contributed by Daryn Sharp.\n",
      "commitDate": "30/06/17 11:59 PM",
      "commitName": "fa1aaee87b0141a0255b5f8e5fd8e8f49d7efe86",
      "commitAuthor": "Naganarasimha",
      "commitDateOld": "22/06/17 11:50 PM",
      "commitNameOld": "ca13b224b2feb9c44de861da9cbba8dd2a12cb35",
      "commitAuthorOld": "Sunil G",
      "daysBetweenCommits": 8.01,
      "commitsBetweenForRepo": 48,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,94 @@\n   boolean canAssignToThisQueue(Resource clusterResource,\n       String nodePartition, ResourceLimits currentResourceLimits,\n       Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n     try {\n       readLock.lock();\n       // Get current limited resource:\n       // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n       // queues\u0027 max capacity.\n       // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n       // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n       // considered to be 100%. Which is a queue can use all resource in the\n       // partition.\n       // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n       // idle resource on the partition, to avoid wastage, such resource will be\n       // leveraged as much as we can, and preemption policy will reclaim it back\n       // when partitoned-resource-request comes back.\n       Resource currentLimitResource \u003d getCurrentLimitResource(nodePartition,\n           clusterResource, currentResourceLimits, schedulingMode);\n \n       Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n \n       // Set headroom for currentResourceLimits:\n       // When queue is a parent queue: Headroom \u003d limit - used + killable\n       // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n       Resource usedExceptKillable \u003d nowTotalUsed;\n-      if (null !\u003d getChildQueues() \u0026\u0026 !getChildQueues().isEmpty()) {\n+      if (hasChildQueues()) {\n         usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n             getTotalKillableResource(nodePartition));\n       }\n       currentResourceLimits.setHeadroom(\n           Resources.subtract(currentLimitResource, usedExceptKillable));\n \n       if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n           usedExceptKillable, currentLimitResource)) {\n \n         // if reservation continous looking enabled, check to see if could we\n         // potentially use this node instead of a reserved node if the application\n         // has reserved containers.\n         // TODO, now only consider reservation cases when the node has no label\n         if (this.reservationsContinueLooking \u0026\u0026 nodePartition.equals(\n             RMNodeLabelsManager.NO_LABEL) \u0026\u0026 Resources.greaterThan(\n             resourceCalculator, clusterResource, resourceCouldBeUnreserved,\n             Resources.none())) {\n           // resource-without-reserved \u003d used - reserved\n           Resource newTotalWithoutReservedResource \u003d Resources.subtract(\n               usedExceptKillable, resourceCouldBeUnreserved);\n \n           // when total-used-without-reserved-resource \u003c currentLimit, we still\n           // have chance to allocate on this node by unreserving some containers\n           if (Resources.lessThan(resourceCalculator, clusterResource,\n               newTotalWithoutReservedResource, currentLimitResource)) {\n             if (LOG.isDebugEnabled()) {\n               LOG.debug(\"try to use reserved: \" + getQueueName()\n                   + \" usedResources: \" + queueUsage.getUsed()\n                   + \", clusterResources: \" + clusterResource\n                   + \", reservedResources: \" + resourceCouldBeUnreserved\n                   + \", capacity-without-reserved: \"\n                   + newTotalWithoutReservedResource\n                   + \", maxLimitCapacity: \" + currentLimitResource);\n             }\n             return true;\n           }\n         }\n \n         // Can not assign to this queue\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Failed to assign to queue: \" + getQueueName()\n               + \" nodePatrition: \" + nodePartition\n               + \", usedResources: \" + queueUsage.getUsed(nodePartition)\n               + \", clusterResources: \" + clusterResource\n               + \", reservedResources: \" + resourceCouldBeUnreserved\n               + \", maxLimitCapacity: \" + currentLimitResource\n               + \", currTotalUsed:\" + usedExceptKillable);\n         }\n         return false;\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Check assign to queue: \" + getQueueName()\n             + \" nodePartition: \" + nodePartition\n             + \", usedResources: \" + queueUsage.getUsed(nodePartition)\n             + \", clusterResources: \" + clusterResource\n             + \", currentUsedCapacity: \" + Resources\n             .divide(resourceCalculator, clusterResource,\n                 queueUsage.getUsed(nodePartition), labelManager\n                     .getResourceByLabel(nodePartition, clusterResource))\n             + \", max-capacity: \" + queueCapacities\n             .getAbsoluteMaximumCapacity(nodePartition));\n       }\n       return true;\n     } finally {\n       readLock.unlock();\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean canAssignToThisQueue(Resource clusterResource,\n      String nodePartition, ResourceLimits currentResourceLimits,\n      Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n    try {\n      readLock.lock();\n      // Get current limited resource:\n      // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n      // queues\u0027 max capacity.\n      // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n      // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n      // considered to be 100%. Which is a queue can use all resource in the\n      // partition.\n      // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n      // idle resource on the partition, to avoid wastage, such resource will be\n      // leveraged as much as we can, and preemption policy will reclaim it back\n      // when partitoned-resource-request comes back.\n      Resource currentLimitResource \u003d getCurrentLimitResource(nodePartition,\n          clusterResource, currentResourceLimits, schedulingMode);\n\n      Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n\n      // Set headroom for currentResourceLimits:\n      // When queue is a parent queue: Headroom \u003d limit - used + killable\n      // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n      Resource usedExceptKillable \u003d nowTotalUsed;\n      if (hasChildQueues()) {\n        usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n            getTotalKillableResource(nodePartition));\n      }\n      currentResourceLimits.setHeadroom(\n          Resources.subtract(currentLimitResource, usedExceptKillable));\n\n      if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n          usedExceptKillable, currentLimitResource)) {\n\n        // if reservation continous looking enabled, check to see if could we\n        // potentially use this node instead of a reserved node if the application\n        // has reserved containers.\n        // TODO, now only consider reservation cases when the node has no label\n        if (this.reservationsContinueLooking \u0026\u0026 nodePartition.equals(\n            RMNodeLabelsManager.NO_LABEL) \u0026\u0026 Resources.greaterThan(\n            resourceCalculator, clusterResource, resourceCouldBeUnreserved,\n            Resources.none())) {\n          // resource-without-reserved \u003d used - reserved\n          Resource newTotalWithoutReservedResource \u003d Resources.subtract(\n              usedExceptKillable, resourceCouldBeUnreserved);\n\n          // when total-used-without-reserved-resource \u003c currentLimit, we still\n          // have chance to allocate on this node by unreserving some containers\n          if (Resources.lessThan(resourceCalculator, clusterResource,\n              newTotalWithoutReservedResource, currentLimitResource)) {\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"try to use reserved: \" + getQueueName()\n                  + \" usedResources: \" + queueUsage.getUsed()\n                  + \", clusterResources: \" + clusterResource\n                  + \", reservedResources: \" + resourceCouldBeUnreserved\n                  + \", capacity-without-reserved: \"\n                  + newTotalWithoutReservedResource\n                  + \", maxLimitCapacity: \" + currentLimitResource);\n            }\n            return true;\n          }\n        }\n\n        // Can not assign to this queue\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Failed to assign to queue: \" + getQueueName()\n              + \" nodePatrition: \" + nodePartition\n              + \", usedResources: \" + queueUsage.getUsed(nodePartition)\n              + \", clusterResources: \" + clusterResource\n              + \", reservedResources: \" + resourceCouldBeUnreserved\n              + \", maxLimitCapacity: \" + currentLimitResource\n              + \", currTotalUsed:\" + usedExceptKillable);\n        }\n        return false;\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Check assign to queue: \" + getQueueName()\n            + \" nodePartition: \" + nodePartition\n            + \", usedResources: \" + queueUsage.getUsed(nodePartition)\n            + \", clusterResources: \" + clusterResource\n            + \", currentUsedCapacity: \" + Resources\n            .divide(resourceCalculator, clusterResource,\n                queueUsage.getUsed(nodePartition), labelManager\n                    .getResourceByLabel(nodePartition, clusterResource))\n            + \", max-capacity: \" + queueCapacities\n            .getAbsoluteMaximumCapacity(nodePartition));\n      }\n      return true;\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
      "extendedDetails": {}
    },
    "9594c35dcb655add1991d8fd15897b40c4ad6205": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5899. Debug log in AbstractCSQueue#canAssignToThisQueue needs improvement. Contributed by Ying Zhang.\n",
      "commitDate": "10/01/17 12:38 AM",
      "commitName": "9594c35dcb655add1991d8fd15897b40c4ad6205",
      "commitAuthor": "Sunil G",
      "commitDateOld": "27/12/16 9:18 PM",
      "commitNameOld": "0840b4329b2428b20b862f70d72cbdcd6d1618ed",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 13.14,
      "commitsBetweenForRepo": 57,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,94 @@\n   boolean canAssignToThisQueue(Resource clusterResource,\n       String nodePartition, ResourceLimits currentResourceLimits,\n       Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n     try {\n       readLock.lock();\n       // Get current limited resource:\n       // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n       // queues\u0027 max capacity.\n       // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n       // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n       // considered to be 100%. Which is a queue can use all resource in the\n       // partition.\n       // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n       // idle resource on the partition, to avoid wastage, such resource will be\n       // leveraged as much as we can, and preemption policy will reclaim it back\n       // when partitoned-resource-request comes back.\n       Resource currentLimitResource \u003d getCurrentLimitResource(nodePartition,\n           clusterResource, currentResourceLimits, schedulingMode);\n \n       Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n \n       // Set headroom for currentResourceLimits:\n       // When queue is a parent queue: Headroom \u003d limit - used + killable\n       // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n       Resource usedExceptKillable \u003d nowTotalUsed;\n       if (null !\u003d getChildQueues() \u0026\u0026 !getChildQueues().isEmpty()) {\n         usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n             getTotalKillableResource(nodePartition));\n       }\n       currentResourceLimits.setHeadroom(\n           Resources.subtract(currentLimitResource, usedExceptKillable));\n \n       if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n           usedExceptKillable, currentLimitResource)) {\n \n         // if reservation continous looking enabled, check to see if could we\n         // potentially use this node instead of a reserved node if the application\n         // has reserved containers.\n         // TODO, now only consider reservation cases when the node has no label\n         if (this.reservationsContinueLooking \u0026\u0026 nodePartition.equals(\n             RMNodeLabelsManager.NO_LABEL) \u0026\u0026 Resources.greaterThan(\n             resourceCalculator, clusterResource, resourceCouldBeUnreserved,\n             Resources.none())) {\n           // resource-without-reserved \u003d used - reserved\n           Resource newTotalWithoutReservedResource \u003d Resources.subtract(\n               usedExceptKillable, resourceCouldBeUnreserved);\n \n           // when total-used-without-reserved-resource \u003c currentLimit, we still\n           // have chance to allocate on this node by unreserving some containers\n           if (Resources.lessThan(resourceCalculator, clusterResource,\n               newTotalWithoutReservedResource, currentLimitResource)) {\n             if (LOG.isDebugEnabled()) {\n-              LOG.debug(\n-                  \"try to use reserved: \" + getQueueName() + \" usedResources: \"\n-                      + queueUsage.getUsed() + \", clusterResources: \"\n-                      + clusterResource + \", reservedResources: \"\n-                      + resourceCouldBeUnreserved\n-                      + \", capacity-without-reserved: \"\n-                      + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n-                      + currentLimitResource);\n+              LOG.debug(\"try to use reserved: \" + getQueueName()\n+                  + \" usedResources: \" + queueUsage.getUsed()\n+                  + \", clusterResources: \" + clusterResource\n+                  + \", reservedResources: \" + resourceCouldBeUnreserved\n+                  + \", capacity-without-reserved: \"\n+                  + newTotalWithoutReservedResource\n+                  + \", maxLimitCapacity: \" + currentLimitResource);\n             }\n             return true;\n           }\n         }\n+\n+        // Can not assign to this queue\n         if (LOG.isDebugEnabled()) {\n-          LOG.debug(getQueueName() + \"Check assign to queue, nodePartition\u003d\"\n-              + nodePartition + \" usedResources: \" + queueUsage\n-              .getUsed(nodePartition) + \" clusterResources: \" + clusterResource\n-              + \" currentUsedCapacity \" + Resources\n-              .divide(resourceCalculator, clusterResource,\n-                  queueUsage.getUsed(nodePartition), labelManager\n-                      .getResourceByLabel(nodePartition, clusterResource))\n-              + \" max-capacity: \" + queueCapacities\n-              .getAbsoluteMaximumCapacity(nodePartition) + \")\");\n+          LOG.debug(\"Failed to assign to queue: \" + getQueueName()\n+              + \" nodePatrition: \" + nodePartition\n+              + \", usedResources: \" + queueUsage.getUsed(nodePartition)\n+              + \", clusterResources: \" + clusterResource\n+              + \", reservedResources: \" + resourceCouldBeUnreserved\n+              + \", maxLimitCapacity: \" + currentLimitResource\n+              + \", currTotalUsed:\" + usedExceptKillable);\n         }\n         return false;\n       }\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Check assign to queue: \" + getQueueName()\n+            + \" nodePartition: \" + nodePartition\n+            + \", usedResources: \" + queueUsage.getUsed(nodePartition)\n+            + \", clusterResources: \" + clusterResource\n+            + \", currentUsedCapacity: \" + Resources\n+            .divide(resourceCalculator, clusterResource,\n+                queueUsage.getUsed(nodePartition), labelManager\n+                    .getResourceByLabel(nodePartition, clusterResource))\n+            + \", max-capacity: \" + queueCapacities\n+            .getAbsoluteMaximumCapacity(nodePartition));\n+      }\n       return true;\n     } finally {\n       readLock.unlock();\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean canAssignToThisQueue(Resource clusterResource,\n      String nodePartition, ResourceLimits currentResourceLimits,\n      Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n    try {\n      readLock.lock();\n      // Get current limited resource:\n      // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n      // queues\u0027 max capacity.\n      // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n      // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n      // considered to be 100%. Which is a queue can use all resource in the\n      // partition.\n      // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n      // idle resource on the partition, to avoid wastage, such resource will be\n      // leveraged as much as we can, and preemption policy will reclaim it back\n      // when partitoned-resource-request comes back.\n      Resource currentLimitResource \u003d getCurrentLimitResource(nodePartition,\n          clusterResource, currentResourceLimits, schedulingMode);\n\n      Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n\n      // Set headroom for currentResourceLimits:\n      // When queue is a parent queue: Headroom \u003d limit - used + killable\n      // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n      Resource usedExceptKillable \u003d nowTotalUsed;\n      if (null !\u003d getChildQueues() \u0026\u0026 !getChildQueues().isEmpty()) {\n        usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n            getTotalKillableResource(nodePartition));\n      }\n      currentResourceLimits.setHeadroom(\n          Resources.subtract(currentLimitResource, usedExceptKillable));\n\n      if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n          usedExceptKillable, currentLimitResource)) {\n\n        // if reservation continous looking enabled, check to see if could we\n        // potentially use this node instead of a reserved node if the application\n        // has reserved containers.\n        // TODO, now only consider reservation cases when the node has no label\n        if (this.reservationsContinueLooking \u0026\u0026 nodePartition.equals(\n            RMNodeLabelsManager.NO_LABEL) \u0026\u0026 Resources.greaterThan(\n            resourceCalculator, clusterResource, resourceCouldBeUnreserved,\n            Resources.none())) {\n          // resource-without-reserved \u003d used - reserved\n          Resource newTotalWithoutReservedResource \u003d Resources.subtract(\n              usedExceptKillable, resourceCouldBeUnreserved);\n\n          // when total-used-without-reserved-resource \u003c currentLimit, we still\n          // have chance to allocate on this node by unreserving some containers\n          if (Resources.lessThan(resourceCalculator, clusterResource,\n              newTotalWithoutReservedResource, currentLimitResource)) {\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"try to use reserved: \" + getQueueName()\n                  + \" usedResources: \" + queueUsage.getUsed()\n                  + \", clusterResources: \" + clusterResource\n                  + \", reservedResources: \" + resourceCouldBeUnreserved\n                  + \", capacity-without-reserved: \"\n                  + newTotalWithoutReservedResource\n                  + \", maxLimitCapacity: \" + currentLimitResource);\n            }\n            return true;\n          }\n        }\n\n        // Can not assign to this queue\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Failed to assign to queue: \" + getQueueName()\n              + \" nodePatrition: \" + nodePartition\n              + \", usedResources: \" + queueUsage.getUsed(nodePartition)\n              + \", clusterResources: \" + clusterResource\n              + \", reservedResources: \" + resourceCouldBeUnreserved\n              + \", maxLimitCapacity: \" + currentLimitResource\n              + \", currTotalUsed:\" + usedExceptKillable);\n        }\n        return false;\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Check assign to queue: \" + getQueueName()\n            + \" nodePartition: \" + nodePartition\n            + \", usedResources: \" + queueUsage.getUsed(nodePartition)\n            + \", clusterResources: \" + clusterResource\n            + \", currentUsedCapacity: \" + Resources\n            .divide(resourceCalculator, clusterResource,\n                queueUsage.getUsed(nodePartition), labelManager\n                    .getResourceByLabel(nodePartition, clusterResource))\n            + \", max-capacity: \" + queueCapacities\n            .getAbsoluteMaximumCapacity(nodePartition));\n      }\n      return true;\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
      "extendedDetails": {}
    },
    "2b66d9ec5bdaec7e6b278926fbb6f222c4e3afaa": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "YARN-3140. Improve locks in AbstractCSQueue/LeafQueue/ParentQueue. Contributed by Wangda Tan\n",
      "commitDate": "20/09/16 12:03 AM",
      "commitName": "2b66d9ec5bdaec7e6b278926fbb6f222c4e3afaa",
      "commitAuthor": "Jian He",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-3140. Improve locks in AbstractCSQueue/LeafQueue/ParentQueue. Contributed by Wangda Tan\n",
          "commitDate": "20/09/16 12:03 AM",
          "commitName": "2b66d9ec5bdaec7e6b278926fbb6f222c4e3afaa",
          "commitAuthor": "Jian He",
          "commitDateOld": "05/08/16 10:27 AM",
          "commitNameOld": "e0d131f055ee126052ad4d0f7b0d192e6c730188",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 45.57,
          "commitsBetweenForRepo": 270,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,81 +1,83 @@\n-  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n+  boolean canAssignToThisQueue(Resource clusterResource,\n       String nodePartition, ResourceLimits currentResourceLimits,\n       Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n-    // Get current limited resource: \n-    // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n-    // queues\u0027 max capacity.\n-    // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n-    // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n-    // considered to be 100%. Which is a queue can use all resource in the\n-    // partition. \n-    // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n-    // idle resource on the partition, to avoid wastage, such resource will be\n-    // leveraged as much as we can, and preemption policy will reclaim it back\n-    // when partitoned-resource-request comes back.  \n-    Resource currentLimitResource \u003d\n-        getCurrentLimitResource(nodePartition, clusterResource,\n-            currentResourceLimits, schedulingMode);\n+    try {\n+      readLock.lock();\n+      // Get current limited resource:\n+      // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n+      // queues\u0027 max capacity.\n+      // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n+      // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n+      // considered to be 100%. Which is a queue can use all resource in the\n+      // partition.\n+      // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n+      // idle resource on the partition, to avoid wastage, such resource will be\n+      // leveraged as much as we can, and preemption policy will reclaim it back\n+      // when partitoned-resource-request comes back.\n+      Resource currentLimitResource \u003d getCurrentLimitResource(nodePartition,\n+          clusterResource, currentResourceLimits, schedulingMode);\n \n-    Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n+      Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n \n-    // Set headroom for currentResourceLimits:\n-    // When queue is a parent queue: Headroom \u003d limit - used + killable\n-    // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n-    Resource usedExceptKillable \u003d nowTotalUsed;\n-    if (null !\u003d getChildQueues() \u0026\u0026 !getChildQueues().isEmpty()) {\n-      usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n-          getTotalKillableResource(nodePartition));\n-    }\n-    currentResourceLimits.setHeadroom(\n-        Resources.subtract(currentLimitResource, usedExceptKillable));\n+      // Set headroom for currentResourceLimits:\n+      // When queue is a parent queue: Headroom \u003d limit - used + killable\n+      // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n+      Resource usedExceptKillable \u003d nowTotalUsed;\n+      if (null !\u003d getChildQueues() \u0026\u0026 !getChildQueues().isEmpty()) {\n+        usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n+            getTotalKillableResource(nodePartition));\n+      }\n+      currentResourceLimits.setHeadroom(\n+          Resources.subtract(currentLimitResource, usedExceptKillable));\n \n-    if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n-        usedExceptKillable, currentLimitResource)) {\n+      if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n+          usedExceptKillable, currentLimitResource)) {\n \n-      // if reservation continous looking enabled, check to see if could we\n-      // potentially use this node instead of a reserved node if the application\n-      // has reserved containers.\n-      // TODO, now only consider reservation cases when the node has no label\n-      if (this.reservationsContinueLooking\n-          \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n-          \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n-              resourceCouldBeUnreserved, Resources.none())) {\n-        // resource-without-reserved \u003d used - reserved\n-        Resource newTotalWithoutReservedResource \u003d\n-            Resources.subtract(usedExceptKillable, resourceCouldBeUnreserved);\n+        // if reservation continous looking enabled, check to see if could we\n+        // potentially use this node instead of a reserved node if the application\n+        // has reserved containers.\n+        // TODO, now only consider reservation cases when the node has no label\n+        if (this.reservationsContinueLooking \u0026\u0026 nodePartition.equals(\n+            RMNodeLabelsManager.NO_LABEL) \u0026\u0026 Resources.greaterThan(\n+            resourceCalculator, clusterResource, resourceCouldBeUnreserved,\n+            Resources.none())) {\n+          // resource-without-reserved \u003d used - reserved\n+          Resource newTotalWithoutReservedResource \u003d Resources.subtract(\n+              usedExceptKillable, resourceCouldBeUnreserved);\n \n-        // when total-used-without-reserved-resource \u003c currentLimit, we still\n-        // have chance to allocate on this node by unreserving some containers\n-        if (Resources.lessThan(resourceCalculator, clusterResource,\n-            newTotalWithoutReservedResource, currentLimitResource)) {\n-          if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"try to use reserved: \" + getQueueName()\n-                + \" usedResources: \" + queueUsage.getUsed()\n-                + \", clusterResources: \" + clusterResource\n-                + \", reservedResources: \" + resourceCouldBeUnreserved\n-                + \", capacity-without-reserved: \"\n-                + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n-                + currentLimitResource);\n+          // when total-used-without-reserved-resource \u003c currentLimit, we still\n+          // have chance to allocate on this node by unreserving some containers\n+          if (Resources.lessThan(resourceCalculator, clusterResource,\n+              newTotalWithoutReservedResource, currentLimitResource)) {\n+            if (LOG.isDebugEnabled()) {\n+              LOG.debug(\n+                  \"try to use reserved: \" + getQueueName() + \" usedResources: \"\n+                      + queueUsage.getUsed() + \", clusterResources: \"\n+                      + clusterResource + \", reservedResources: \"\n+                      + resourceCouldBeUnreserved\n+                      + \", capacity-without-reserved: \"\n+                      + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n+                      + currentLimitResource);\n+            }\n+            return true;\n           }\n-          return true;\n         }\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(getQueueName() + \"Check assign to queue, nodePartition\u003d\"\n+              + nodePartition + \" usedResources: \" + queueUsage\n+              .getUsed(nodePartition) + \" clusterResources: \" + clusterResource\n+              + \" currentUsedCapacity \" + Resources\n+              .divide(resourceCalculator, clusterResource,\n+                  queueUsage.getUsed(nodePartition), labelManager\n+                      .getResourceByLabel(nodePartition, clusterResource))\n+              + \" max-capacity: \" + queueCapacities\n+              .getAbsoluteMaximumCapacity(nodePartition) + \")\");\n+        }\n+        return false;\n       }\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(getQueueName()\n-            + \"Check assign to queue, nodePartition\u003d\"\n-            + nodePartition\n-            + \" usedResources: \"\n-            + queueUsage.getUsed(nodePartition)\n-            + \" clusterResources: \"\n-            + clusterResource\n-            + \" currentUsedCapacity \"\n-            + Resources.divide(resourceCalculator, clusterResource,\n-                queueUsage.getUsed(nodePartition),\n-                labelManager.getResourceByLabel(nodePartition, clusterResource))\n-            + \" max-capacity: \"\n-            + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n-      }\n-      return false;\n+      return true;\n+    } finally {\n+      readLock.unlock();\n     }\n-    return true;\n+\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean canAssignToThisQueue(Resource clusterResource,\n      String nodePartition, ResourceLimits currentResourceLimits,\n      Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n    try {\n      readLock.lock();\n      // Get current limited resource:\n      // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n      // queues\u0027 max capacity.\n      // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n      // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n      // considered to be 100%. Which is a queue can use all resource in the\n      // partition.\n      // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n      // idle resource on the partition, to avoid wastage, such resource will be\n      // leveraged as much as we can, and preemption policy will reclaim it back\n      // when partitoned-resource-request comes back.\n      Resource currentLimitResource \u003d getCurrentLimitResource(nodePartition,\n          clusterResource, currentResourceLimits, schedulingMode);\n\n      Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n\n      // Set headroom for currentResourceLimits:\n      // When queue is a parent queue: Headroom \u003d limit - used + killable\n      // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n      Resource usedExceptKillable \u003d nowTotalUsed;\n      if (null !\u003d getChildQueues() \u0026\u0026 !getChildQueues().isEmpty()) {\n        usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n            getTotalKillableResource(nodePartition));\n      }\n      currentResourceLimits.setHeadroom(\n          Resources.subtract(currentLimitResource, usedExceptKillable));\n\n      if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n          usedExceptKillable, currentLimitResource)) {\n\n        // if reservation continous looking enabled, check to see if could we\n        // potentially use this node instead of a reserved node if the application\n        // has reserved containers.\n        // TODO, now only consider reservation cases when the node has no label\n        if (this.reservationsContinueLooking \u0026\u0026 nodePartition.equals(\n            RMNodeLabelsManager.NO_LABEL) \u0026\u0026 Resources.greaterThan(\n            resourceCalculator, clusterResource, resourceCouldBeUnreserved,\n            Resources.none())) {\n          // resource-without-reserved \u003d used - reserved\n          Resource newTotalWithoutReservedResource \u003d Resources.subtract(\n              usedExceptKillable, resourceCouldBeUnreserved);\n\n          // when total-used-without-reserved-resource \u003c currentLimit, we still\n          // have chance to allocate on this node by unreserving some containers\n          if (Resources.lessThan(resourceCalculator, clusterResource,\n              newTotalWithoutReservedResource, currentLimitResource)) {\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\n                  \"try to use reserved: \" + getQueueName() + \" usedResources: \"\n                      + queueUsage.getUsed() + \", clusterResources: \"\n                      + clusterResource + \", reservedResources: \"\n                      + resourceCouldBeUnreserved\n                      + \", capacity-without-reserved: \"\n                      + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n                      + currentLimitResource);\n            }\n            return true;\n          }\n        }\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(getQueueName() + \"Check assign to queue, nodePartition\u003d\"\n              + nodePartition + \" usedResources: \" + queueUsage\n              .getUsed(nodePartition) + \" clusterResources: \" + clusterResource\n              + \" currentUsedCapacity \" + Resources\n              .divide(resourceCalculator, clusterResource,\n                  queueUsage.getUsed(nodePartition), labelManager\n                      .getResourceByLabel(nodePartition, clusterResource))\n              + \" max-capacity: \" + queueCapacities\n              .getAbsoluteMaximumCapacity(nodePartition) + \")\");\n        }\n        return false;\n      }\n      return true;\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
          "extendedDetails": {
            "oldValue": "[synchronized]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-3140. Improve locks in AbstractCSQueue/LeafQueue/ParentQueue. Contributed by Wangda Tan\n",
          "commitDate": "20/09/16 12:03 AM",
          "commitName": "2b66d9ec5bdaec7e6b278926fbb6f222c4e3afaa",
          "commitAuthor": "Jian He",
          "commitDateOld": "05/08/16 10:27 AM",
          "commitNameOld": "e0d131f055ee126052ad4d0f7b0d192e6c730188",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 45.57,
          "commitsBetweenForRepo": 270,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,81 +1,83 @@\n-  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n+  boolean canAssignToThisQueue(Resource clusterResource,\n       String nodePartition, ResourceLimits currentResourceLimits,\n       Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n-    // Get current limited resource: \n-    // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n-    // queues\u0027 max capacity.\n-    // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n-    // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n-    // considered to be 100%. Which is a queue can use all resource in the\n-    // partition. \n-    // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n-    // idle resource on the partition, to avoid wastage, such resource will be\n-    // leveraged as much as we can, and preemption policy will reclaim it back\n-    // when partitoned-resource-request comes back.  \n-    Resource currentLimitResource \u003d\n-        getCurrentLimitResource(nodePartition, clusterResource,\n-            currentResourceLimits, schedulingMode);\n+    try {\n+      readLock.lock();\n+      // Get current limited resource:\n+      // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n+      // queues\u0027 max capacity.\n+      // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n+      // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n+      // considered to be 100%. Which is a queue can use all resource in the\n+      // partition.\n+      // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n+      // idle resource on the partition, to avoid wastage, such resource will be\n+      // leveraged as much as we can, and preemption policy will reclaim it back\n+      // when partitoned-resource-request comes back.\n+      Resource currentLimitResource \u003d getCurrentLimitResource(nodePartition,\n+          clusterResource, currentResourceLimits, schedulingMode);\n \n-    Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n+      Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n \n-    // Set headroom for currentResourceLimits:\n-    // When queue is a parent queue: Headroom \u003d limit - used + killable\n-    // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n-    Resource usedExceptKillable \u003d nowTotalUsed;\n-    if (null !\u003d getChildQueues() \u0026\u0026 !getChildQueues().isEmpty()) {\n-      usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n-          getTotalKillableResource(nodePartition));\n-    }\n-    currentResourceLimits.setHeadroom(\n-        Resources.subtract(currentLimitResource, usedExceptKillable));\n+      // Set headroom for currentResourceLimits:\n+      // When queue is a parent queue: Headroom \u003d limit - used + killable\n+      // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n+      Resource usedExceptKillable \u003d nowTotalUsed;\n+      if (null !\u003d getChildQueues() \u0026\u0026 !getChildQueues().isEmpty()) {\n+        usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n+            getTotalKillableResource(nodePartition));\n+      }\n+      currentResourceLimits.setHeadroom(\n+          Resources.subtract(currentLimitResource, usedExceptKillable));\n \n-    if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n-        usedExceptKillable, currentLimitResource)) {\n+      if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n+          usedExceptKillable, currentLimitResource)) {\n \n-      // if reservation continous looking enabled, check to see if could we\n-      // potentially use this node instead of a reserved node if the application\n-      // has reserved containers.\n-      // TODO, now only consider reservation cases when the node has no label\n-      if (this.reservationsContinueLooking\n-          \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n-          \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n-              resourceCouldBeUnreserved, Resources.none())) {\n-        // resource-without-reserved \u003d used - reserved\n-        Resource newTotalWithoutReservedResource \u003d\n-            Resources.subtract(usedExceptKillable, resourceCouldBeUnreserved);\n+        // if reservation continous looking enabled, check to see if could we\n+        // potentially use this node instead of a reserved node if the application\n+        // has reserved containers.\n+        // TODO, now only consider reservation cases when the node has no label\n+        if (this.reservationsContinueLooking \u0026\u0026 nodePartition.equals(\n+            RMNodeLabelsManager.NO_LABEL) \u0026\u0026 Resources.greaterThan(\n+            resourceCalculator, clusterResource, resourceCouldBeUnreserved,\n+            Resources.none())) {\n+          // resource-without-reserved \u003d used - reserved\n+          Resource newTotalWithoutReservedResource \u003d Resources.subtract(\n+              usedExceptKillable, resourceCouldBeUnreserved);\n \n-        // when total-used-without-reserved-resource \u003c currentLimit, we still\n-        // have chance to allocate on this node by unreserving some containers\n-        if (Resources.lessThan(resourceCalculator, clusterResource,\n-            newTotalWithoutReservedResource, currentLimitResource)) {\n-          if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"try to use reserved: \" + getQueueName()\n-                + \" usedResources: \" + queueUsage.getUsed()\n-                + \", clusterResources: \" + clusterResource\n-                + \", reservedResources: \" + resourceCouldBeUnreserved\n-                + \", capacity-without-reserved: \"\n-                + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n-                + currentLimitResource);\n+          // when total-used-without-reserved-resource \u003c currentLimit, we still\n+          // have chance to allocate on this node by unreserving some containers\n+          if (Resources.lessThan(resourceCalculator, clusterResource,\n+              newTotalWithoutReservedResource, currentLimitResource)) {\n+            if (LOG.isDebugEnabled()) {\n+              LOG.debug(\n+                  \"try to use reserved: \" + getQueueName() + \" usedResources: \"\n+                      + queueUsage.getUsed() + \", clusterResources: \"\n+                      + clusterResource + \", reservedResources: \"\n+                      + resourceCouldBeUnreserved\n+                      + \", capacity-without-reserved: \"\n+                      + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n+                      + currentLimitResource);\n+            }\n+            return true;\n           }\n-          return true;\n         }\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(getQueueName() + \"Check assign to queue, nodePartition\u003d\"\n+              + nodePartition + \" usedResources: \" + queueUsage\n+              .getUsed(nodePartition) + \" clusterResources: \" + clusterResource\n+              + \" currentUsedCapacity \" + Resources\n+              .divide(resourceCalculator, clusterResource,\n+                  queueUsage.getUsed(nodePartition), labelManager\n+                      .getResourceByLabel(nodePartition, clusterResource))\n+              + \" max-capacity: \" + queueCapacities\n+              .getAbsoluteMaximumCapacity(nodePartition) + \")\");\n+        }\n+        return false;\n       }\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(getQueueName()\n-            + \"Check assign to queue, nodePartition\u003d\"\n-            + nodePartition\n-            + \" usedResources: \"\n-            + queueUsage.getUsed(nodePartition)\n-            + \" clusterResources: \"\n-            + clusterResource\n-            + \" currentUsedCapacity \"\n-            + Resources.divide(resourceCalculator, clusterResource,\n-                queueUsage.getUsed(nodePartition),\n-                labelManager.getResourceByLabel(nodePartition, clusterResource))\n-            + \" max-capacity: \"\n-            + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n-      }\n-      return false;\n+      return true;\n+    } finally {\n+      readLock.unlock();\n     }\n-    return true;\n+\n   }\n\\ No newline at end of file\n",
          "actualSource": "  boolean canAssignToThisQueue(Resource clusterResource,\n      String nodePartition, ResourceLimits currentResourceLimits,\n      Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n    try {\n      readLock.lock();\n      // Get current limited resource:\n      // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n      // queues\u0027 max capacity.\n      // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n      // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n      // considered to be 100%. Which is a queue can use all resource in the\n      // partition.\n      // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n      // idle resource on the partition, to avoid wastage, such resource will be\n      // leveraged as much as we can, and preemption policy will reclaim it back\n      // when partitoned-resource-request comes back.\n      Resource currentLimitResource \u003d getCurrentLimitResource(nodePartition,\n          clusterResource, currentResourceLimits, schedulingMode);\n\n      Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n\n      // Set headroom for currentResourceLimits:\n      // When queue is a parent queue: Headroom \u003d limit - used + killable\n      // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n      Resource usedExceptKillable \u003d nowTotalUsed;\n      if (null !\u003d getChildQueues() \u0026\u0026 !getChildQueues().isEmpty()) {\n        usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n            getTotalKillableResource(nodePartition));\n      }\n      currentResourceLimits.setHeadroom(\n          Resources.subtract(currentLimitResource, usedExceptKillable));\n\n      if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n          usedExceptKillable, currentLimitResource)) {\n\n        // if reservation continous looking enabled, check to see if could we\n        // potentially use this node instead of a reserved node if the application\n        // has reserved containers.\n        // TODO, now only consider reservation cases when the node has no label\n        if (this.reservationsContinueLooking \u0026\u0026 nodePartition.equals(\n            RMNodeLabelsManager.NO_LABEL) \u0026\u0026 Resources.greaterThan(\n            resourceCalculator, clusterResource, resourceCouldBeUnreserved,\n            Resources.none())) {\n          // resource-without-reserved \u003d used - reserved\n          Resource newTotalWithoutReservedResource \u003d Resources.subtract(\n              usedExceptKillable, resourceCouldBeUnreserved);\n\n          // when total-used-without-reserved-resource \u003c currentLimit, we still\n          // have chance to allocate on this node by unreserving some containers\n          if (Resources.lessThan(resourceCalculator, clusterResource,\n              newTotalWithoutReservedResource, currentLimitResource)) {\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\n                  \"try to use reserved: \" + getQueueName() + \" usedResources: \"\n                      + queueUsage.getUsed() + \", clusterResources: \"\n                      + clusterResource + \", reservedResources: \"\n                      + resourceCouldBeUnreserved\n                      + \", capacity-without-reserved: \"\n                      + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n                      + currentLimitResource);\n            }\n            return true;\n          }\n        }\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(getQueueName() + \"Check assign to queue, nodePartition\u003d\"\n              + nodePartition + \" usedResources: \" + queueUsage\n              .getUsed(nodePartition) + \" clusterResources: \" + clusterResource\n              + \" currentUsedCapacity \" + Resources\n              .divide(resourceCalculator, clusterResource,\n                  queueUsage.getUsed(nodePartition), labelManager\n                      .getResourceByLabel(nodePartition, clusterResource))\n              + \" max-capacity: \" + queueCapacities\n              .getAbsoluteMaximumCapacity(nodePartition) + \")\");\n        }\n        return false;\n      }\n      return true;\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
          "extendedDetails": {}
        }
      ]
    },
    "ae14e5d07f1b6702a5160637438028bb03d9387e": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4108. CapacityScheduler: Improve preemption to only kill containers that would satisfy the incoming request. (Wangda Tan)\n\n(cherry picked from commit 7e8c9beb4156dcaeb3a11e60aaa06d2370626913)\n",
      "commitDate": "16/03/16 5:02 PM",
      "commitName": "ae14e5d07f1b6702a5160637438028bb03d9387e",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "16/03/16 5:02 PM",
      "commitNameOld": "fa7a43529d529f0006c8033c2003f15b9b93f103",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,74 +1,81 @@\n   synchronized boolean canAssignToThisQueue(Resource clusterResource,\n       String nodePartition, ResourceLimits currentResourceLimits,\n       Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n     // Get current limited resource: \n     // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n     // queues\u0027 max capacity.\n     // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n     // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n     // considered to be 100%. Which is a queue can use all resource in the\n     // partition. \n     // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n     // idle resource on the partition, to avoid wastage, such resource will be\n     // leveraged as much as we can, and preemption policy will reclaim it back\n     // when partitoned-resource-request comes back.  \n     Resource currentLimitResource \u003d\n         getCurrentLimitResource(nodePartition, clusterResource,\n             currentResourceLimits, schedulingMode);\n \n     Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n \n-    // Set headroom for currentResourceLimits\n-    currentResourceLimits.setHeadroom(Resources.subtract(currentLimitResource,\n-        nowTotalUsed));\n+    // Set headroom for currentResourceLimits:\n+    // When queue is a parent queue: Headroom \u003d limit - used + killable\n+    // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n+    Resource usedExceptKillable \u003d nowTotalUsed;\n+    if (null !\u003d getChildQueues() \u0026\u0026 !getChildQueues().isEmpty()) {\n+      usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n+          getTotalKillableResource(nodePartition));\n+    }\n+    currentResourceLimits.setHeadroom(\n+        Resources.subtract(currentLimitResource, usedExceptKillable));\n \n     if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n-        nowTotalUsed, currentLimitResource)) {\n+        usedExceptKillable, currentLimitResource)) {\n \n       // if reservation continous looking enabled, check to see if could we\n       // potentially use this node instead of a reserved node if the application\n       // has reserved containers.\n       // TODO, now only consider reservation cases when the node has no label\n       if (this.reservationsContinueLooking\n           \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n           \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n               resourceCouldBeUnreserved, Resources.none())) {\n         // resource-without-reserved \u003d used - reserved\n         Resource newTotalWithoutReservedResource \u003d\n-            Resources.subtract(nowTotalUsed, resourceCouldBeUnreserved);\n+            Resources.subtract(usedExceptKillable, resourceCouldBeUnreserved);\n \n         // when total-used-without-reserved-resource \u003c currentLimit, we still\n         // have chance to allocate on this node by unreserving some containers\n         if (Resources.lessThan(resourceCalculator, clusterResource,\n             newTotalWithoutReservedResource, currentLimitResource)) {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"try to use reserved: \" + getQueueName()\n                 + \" usedResources: \" + queueUsage.getUsed()\n                 + \", clusterResources: \" + clusterResource\n                 + \", reservedResources: \" + resourceCouldBeUnreserved\n                 + \", capacity-without-reserved: \"\n                 + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n                 + currentLimitResource);\n           }\n           return true;\n         }\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(getQueueName()\n             + \"Check assign to queue, nodePartition\u003d\"\n             + nodePartition\n             + \" usedResources: \"\n             + queueUsage.getUsed(nodePartition)\n             + \" clusterResources: \"\n             + clusterResource\n             + \" currentUsedCapacity \"\n             + Resources.divide(resourceCalculator, clusterResource,\n                 queueUsage.getUsed(nodePartition),\n                 labelManager.getResourceByLabel(nodePartition, clusterResource))\n             + \" max-capacity: \"\n             + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n       }\n       return false;\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n      String nodePartition, ResourceLimits currentResourceLimits,\n      Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n    // Get current limited resource: \n    // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n    // queues\u0027 max capacity.\n    // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n    // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n    // considered to be 100%. Which is a queue can use all resource in the\n    // partition. \n    // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n    // idle resource on the partition, to avoid wastage, such resource will be\n    // leveraged as much as we can, and preemption policy will reclaim it back\n    // when partitoned-resource-request comes back.  \n    Resource currentLimitResource \u003d\n        getCurrentLimitResource(nodePartition, clusterResource,\n            currentResourceLimits, schedulingMode);\n\n    Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n\n    // Set headroom for currentResourceLimits:\n    // When queue is a parent queue: Headroom \u003d limit - used + killable\n    // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n    Resource usedExceptKillable \u003d nowTotalUsed;\n    if (null !\u003d getChildQueues() \u0026\u0026 !getChildQueues().isEmpty()) {\n      usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n          getTotalKillableResource(nodePartition));\n    }\n    currentResourceLimits.setHeadroom(\n        Resources.subtract(currentLimitResource, usedExceptKillable));\n\n    if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n        usedExceptKillable, currentLimitResource)) {\n\n      // if reservation continous looking enabled, check to see if could we\n      // potentially use this node instead of a reserved node if the application\n      // has reserved containers.\n      // TODO, now only consider reservation cases when the node has no label\n      if (this.reservationsContinueLooking\n          \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n          \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n              resourceCouldBeUnreserved, Resources.none())) {\n        // resource-without-reserved \u003d used - reserved\n        Resource newTotalWithoutReservedResource \u003d\n            Resources.subtract(usedExceptKillable, resourceCouldBeUnreserved);\n\n        // when total-used-without-reserved-resource \u003c currentLimit, we still\n        // have chance to allocate on this node by unreserving some containers\n        if (Resources.lessThan(resourceCalculator, clusterResource,\n            newTotalWithoutReservedResource, currentLimitResource)) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \" + getQueueName()\n                + \" usedResources: \" + queueUsage.getUsed()\n                + \", clusterResources: \" + clusterResource\n                + \", reservedResources: \" + resourceCouldBeUnreserved\n                + \", capacity-without-reserved: \"\n                + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n                + currentLimitResource);\n          }\n          return true;\n        }\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \"Check assign to queue, nodePartition\u003d\"\n            + nodePartition\n            + \" usedResources: \"\n            + queueUsage.getUsed(nodePartition)\n            + \" clusterResources: \"\n            + clusterResource\n            + \" currentUsedCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n                queueUsage.getUsed(nodePartition),\n                labelManager.getResourceByLabel(nodePartition, clusterResource))\n            + \" max-capacity: \"\n            + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n      }\n      return false;\n    }\n    return true;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
      "extendedDetails": {}
    },
    "fa7a43529d529f0006c8033c2003f15b9b93f103": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"CapacityScheduler: Improve preemption to only kill containers that would satisfy the incoming request. (Wangda Tan)\"\n\nThis reverts commit 7e8c9beb4156dcaeb3a11e60aaa06d2370626913.\n",
      "commitDate": "16/03/16 5:02 PM",
      "commitName": "fa7a43529d529f0006c8033c2003f15b9b93f103",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "16/03/16 4:59 PM",
      "commitNameOld": "7e8c9beb4156dcaeb3a11e60aaa06d2370626913",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,74 @@\n   synchronized boolean canAssignToThisQueue(Resource clusterResource,\n       String nodePartition, ResourceLimits currentResourceLimits,\n       Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n     // Get current limited resource: \n     // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n     // queues\u0027 max capacity.\n     // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n     // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n     // considered to be 100%. Which is a queue can use all resource in the\n     // partition. \n     // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n     // idle resource on the partition, to avoid wastage, such resource will be\n     // leveraged as much as we can, and preemption policy will reclaim it back\n     // when partitoned-resource-request comes back.  \n     Resource currentLimitResource \u003d\n         getCurrentLimitResource(nodePartition, clusterResource,\n             currentResourceLimits, schedulingMode);\n \n     Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n \n-    // Set headroom for currentResourceLimits:\n-    // When queue is a parent queue: Headroom \u003d limit - used + killable\n-    // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n-    Resource usedExceptKillable \u003d nowTotalUsed;\n-    if (null !\u003d getChildQueues() \u0026\u0026 !getChildQueues().isEmpty()) {\n-      usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n-          getTotalKillableResource(nodePartition));\n-    }\n-    currentResourceLimits.setHeadroom(\n-        Resources.subtract(currentLimitResource, usedExceptKillable));\n+    // Set headroom for currentResourceLimits\n+    currentResourceLimits.setHeadroom(Resources.subtract(currentLimitResource,\n+        nowTotalUsed));\n \n     if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n-        usedExceptKillable, currentLimitResource)) {\n+        nowTotalUsed, currentLimitResource)) {\n \n       // if reservation continous looking enabled, check to see if could we\n       // potentially use this node instead of a reserved node if the application\n       // has reserved containers.\n       // TODO, now only consider reservation cases when the node has no label\n       if (this.reservationsContinueLooking\n           \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n           \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n               resourceCouldBeUnreserved, Resources.none())) {\n         // resource-without-reserved \u003d used - reserved\n         Resource newTotalWithoutReservedResource \u003d\n-            Resources.subtract(usedExceptKillable, resourceCouldBeUnreserved);\n+            Resources.subtract(nowTotalUsed, resourceCouldBeUnreserved);\n \n         // when total-used-without-reserved-resource \u003c currentLimit, we still\n         // have chance to allocate on this node by unreserving some containers\n         if (Resources.lessThan(resourceCalculator, clusterResource,\n             newTotalWithoutReservedResource, currentLimitResource)) {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"try to use reserved: \" + getQueueName()\n                 + \" usedResources: \" + queueUsage.getUsed()\n                 + \", clusterResources: \" + clusterResource\n                 + \", reservedResources: \" + resourceCouldBeUnreserved\n                 + \", capacity-without-reserved: \"\n                 + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n                 + currentLimitResource);\n           }\n           return true;\n         }\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(getQueueName()\n             + \"Check assign to queue, nodePartition\u003d\"\n             + nodePartition\n             + \" usedResources: \"\n             + queueUsage.getUsed(nodePartition)\n             + \" clusterResources: \"\n             + clusterResource\n             + \" currentUsedCapacity \"\n             + Resources.divide(resourceCalculator, clusterResource,\n                 queueUsage.getUsed(nodePartition),\n                 labelManager.getResourceByLabel(nodePartition, clusterResource))\n             + \" max-capacity: \"\n             + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n       }\n       return false;\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n      String nodePartition, ResourceLimits currentResourceLimits,\n      Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n    // Get current limited resource: \n    // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n    // queues\u0027 max capacity.\n    // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n    // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n    // considered to be 100%. Which is a queue can use all resource in the\n    // partition. \n    // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n    // idle resource on the partition, to avoid wastage, such resource will be\n    // leveraged as much as we can, and preemption policy will reclaim it back\n    // when partitoned-resource-request comes back.  \n    Resource currentLimitResource \u003d\n        getCurrentLimitResource(nodePartition, clusterResource,\n            currentResourceLimits, schedulingMode);\n\n    Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n\n    // Set headroom for currentResourceLimits\n    currentResourceLimits.setHeadroom(Resources.subtract(currentLimitResource,\n        nowTotalUsed));\n\n    if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n        nowTotalUsed, currentLimitResource)) {\n\n      // if reservation continous looking enabled, check to see if could we\n      // potentially use this node instead of a reserved node if the application\n      // has reserved containers.\n      // TODO, now only consider reservation cases when the node has no label\n      if (this.reservationsContinueLooking\n          \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n          \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n              resourceCouldBeUnreserved, Resources.none())) {\n        // resource-without-reserved \u003d used - reserved\n        Resource newTotalWithoutReservedResource \u003d\n            Resources.subtract(nowTotalUsed, resourceCouldBeUnreserved);\n\n        // when total-used-without-reserved-resource \u003c currentLimit, we still\n        // have chance to allocate on this node by unreserving some containers\n        if (Resources.lessThan(resourceCalculator, clusterResource,\n            newTotalWithoutReservedResource, currentLimitResource)) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \" + getQueueName()\n                + \" usedResources: \" + queueUsage.getUsed()\n                + \", clusterResources: \" + clusterResource\n                + \", reservedResources: \" + resourceCouldBeUnreserved\n                + \", capacity-without-reserved: \"\n                + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n                + currentLimitResource);\n          }\n          return true;\n        }\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \"Check assign to queue, nodePartition\u003d\"\n            + nodePartition\n            + \" usedResources: \"\n            + queueUsage.getUsed(nodePartition)\n            + \" clusterResources: \"\n            + clusterResource\n            + \" currentUsedCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n                queueUsage.getUsed(nodePartition),\n                labelManager.getResourceByLabel(nodePartition, clusterResource))\n            + \" max-capacity: \"\n            + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n      }\n      return false;\n    }\n    return true;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
      "extendedDetails": {}
    },
    "7e8c9beb4156dcaeb3a11e60aaa06d2370626913": {
      "type": "Ybodychange",
      "commitMessage": "CapacityScheduler: Improve preemption to only kill containers that would satisfy the incoming request. (Wangda Tan)\n",
      "commitDate": "16/03/16 4:59 PM",
      "commitName": "7e8c9beb4156dcaeb3a11e60aaa06d2370626913",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "17/01/16 7:11 PM",
      "commitNameOld": "b08ecf5c7589b055e93b2907413213f36097724d",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 58.87,
      "commitsBetweenForRepo": 402,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,74 +1,81 @@\n   synchronized boolean canAssignToThisQueue(Resource clusterResource,\n       String nodePartition, ResourceLimits currentResourceLimits,\n       Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n     // Get current limited resource: \n     // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n     // queues\u0027 max capacity.\n     // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n     // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n     // considered to be 100%. Which is a queue can use all resource in the\n     // partition. \n     // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n     // idle resource on the partition, to avoid wastage, such resource will be\n     // leveraged as much as we can, and preemption policy will reclaim it back\n     // when partitoned-resource-request comes back.  \n     Resource currentLimitResource \u003d\n         getCurrentLimitResource(nodePartition, clusterResource,\n             currentResourceLimits, schedulingMode);\n \n     Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n \n-    // Set headroom for currentResourceLimits\n-    currentResourceLimits.setHeadroom(Resources.subtract(currentLimitResource,\n-        nowTotalUsed));\n+    // Set headroom for currentResourceLimits:\n+    // When queue is a parent queue: Headroom \u003d limit - used + killable\n+    // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n+    Resource usedExceptKillable \u003d nowTotalUsed;\n+    if (null !\u003d getChildQueues() \u0026\u0026 !getChildQueues().isEmpty()) {\n+      usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n+          getTotalKillableResource(nodePartition));\n+    }\n+    currentResourceLimits.setHeadroom(\n+        Resources.subtract(currentLimitResource, usedExceptKillable));\n \n     if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n-        nowTotalUsed, currentLimitResource)) {\n+        usedExceptKillable, currentLimitResource)) {\n \n       // if reservation continous looking enabled, check to see if could we\n       // potentially use this node instead of a reserved node if the application\n       // has reserved containers.\n       // TODO, now only consider reservation cases when the node has no label\n       if (this.reservationsContinueLooking\n           \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n           \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n               resourceCouldBeUnreserved, Resources.none())) {\n         // resource-without-reserved \u003d used - reserved\n         Resource newTotalWithoutReservedResource \u003d\n-            Resources.subtract(nowTotalUsed, resourceCouldBeUnreserved);\n+            Resources.subtract(usedExceptKillable, resourceCouldBeUnreserved);\n \n         // when total-used-without-reserved-resource \u003c currentLimit, we still\n         // have chance to allocate on this node by unreserving some containers\n         if (Resources.lessThan(resourceCalculator, clusterResource,\n             newTotalWithoutReservedResource, currentLimitResource)) {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"try to use reserved: \" + getQueueName()\n                 + \" usedResources: \" + queueUsage.getUsed()\n                 + \", clusterResources: \" + clusterResource\n                 + \", reservedResources: \" + resourceCouldBeUnreserved\n                 + \", capacity-without-reserved: \"\n                 + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n                 + currentLimitResource);\n           }\n           return true;\n         }\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(getQueueName()\n             + \"Check assign to queue, nodePartition\u003d\"\n             + nodePartition\n             + \" usedResources: \"\n             + queueUsage.getUsed(nodePartition)\n             + \" clusterResources: \"\n             + clusterResource\n             + \" currentUsedCapacity \"\n             + Resources.divide(resourceCalculator, clusterResource,\n                 queueUsage.getUsed(nodePartition),\n                 labelManager.getResourceByLabel(nodePartition, clusterResource))\n             + \" max-capacity: \"\n             + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n       }\n       return false;\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n      String nodePartition, ResourceLimits currentResourceLimits,\n      Resource resourceCouldBeUnreserved, SchedulingMode schedulingMode) {\n    // Get current limited resource: \n    // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n    // queues\u0027 max capacity.\n    // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n    // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n    // considered to be 100%. Which is a queue can use all resource in the\n    // partition. \n    // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n    // idle resource on the partition, to avoid wastage, such resource will be\n    // leveraged as much as we can, and preemption policy will reclaim it back\n    // when partitoned-resource-request comes back.  \n    Resource currentLimitResource \u003d\n        getCurrentLimitResource(nodePartition, clusterResource,\n            currentResourceLimits, schedulingMode);\n\n    Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n\n    // Set headroom for currentResourceLimits:\n    // When queue is a parent queue: Headroom \u003d limit - used + killable\n    // When queue is a leaf queue: Headroom \u003d limit - used (leaf queue cannot preempt itself)\n    Resource usedExceptKillable \u003d nowTotalUsed;\n    if (null !\u003d getChildQueues() \u0026\u0026 !getChildQueues().isEmpty()) {\n      usedExceptKillable \u003d Resources.subtract(nowTotalUsed,\n          getTotalKillableResource(nodePartition));\n    }\n    currentResourceLimits.setHeadroom(\n        Resources.subtract(currentLimitResource, usedExceptKillable));\n\n    if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n        usedExceptKillable, currentLimitResource)) {\n\n      // if reservation continous looking enabled, check to see if could we\n      // potentially use this node instead of a reserved node if the application\n      // has reserved containers.\n      // TODO, now only consider reservation cases when the node has no label\n      if (this.reservationsContinueLooking\n          \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n          \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n              resourceCouldBeUnreserved, Resources.none())) {\n        // resource-without-reserved \u003d used - reserved\n        Resource newTotalWithoutReservedResource \u003d\n            Resources.subtract(usedExceptKillable, resourceCouldBeUnreserved);\n\n        // when total-used-without-reserved-resource \u003c currentLimit, we still\n        // have chance to allocate on this node by unreserving some containers\n        if (Resources.lessThan(resourceCalculator, clusterResource,\n            newTotalWithoutReservedResource, currentLimitResource)) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \" + getQueueName()\n                + \" usedResources: \" + queueUsage.getUsed()\n                + \", clusterResources: \" + clusterResource\n                + \", reservedResources: \" + resourceCouldBeUnreserved\n                + \", capacity-without-reserved: \"\n                + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n                + currentLimitResource);\n          }\n          return true;\n        }\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \"Check assign to queue, nodePartition\u003d\"\n            + nodePartition\n            + \" usedResources: \"\n            + queueUsage.getUsed(nodePartition)\n            + \" clusterResources: \"\n            + clusterResource\n            + \" currentUsedCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n                queueUsage.getUsed(nodePartition),\n                labelManager.getResourceByLabel(nodePartition, clusterResource))\n            + \" max-capacity: \"\n            + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n      }\n      return false;\n    }\n    return true;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
      "extendedDetails": {}
    },
    "83fe34ac0896cee0918bbfad7bd51231e4aec39b": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-3026. Move application-specific container allocation logic from LeafQueue to FiCaSchedulerApp. Contributed by Wangda Tan\n",
      "commitDate": "24/07/15 2:00 PM",
      "commitName": "83fe34ac0896cee0918bbfad7bd51231e4aec39b",
      "commitAuthor": "Jian He",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-3026. Move application-specific container allocation logic from LeafQueue to FiCaSchedulerApp. Contributed by Wangda Tan\n",
          "commitDate": "24/07/15 2:00 PM",
          "commitName": "83fe34ac0896cee0918bbfad7bd51231e4aec39b",
          "commitAuthor": "Jian He",
          "commitDateOld": "21/07/15 9:57 AM",
          "commitNameOld": "c39ca541f498712133890961598bbff50d89d68b",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 3.17,
          "commitsBetweenForRepo": 34,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,75 +1,74 @@\n   synchronized boolean canAssignToThisQueue(Resource clusterResource,\n-      String nodePartition, ResourceLimits currentResourceLimits,\n-      Resource nowRequired, Resource resourceCouldBeUnreserved,\n+      String nodePartition, ResourceLimits currentResourceLimits, Resource resourceCouldBeUnreserved,\n       SchedulingMode schedulingMode) {\n-    // New total resource \u003d used + required\n-    Resource newTotalResource \u003d\n-        Resources.add(queueUsage.getUsed(nodePartition), nowRequired);\n-\n     // Get current limited resource: \n     // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n     // queues\u0027 max capacity.\n     // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n     // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n     // considered to be 100%. Which is a queue can use all resource in the\n     // partition. \n     // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n     // idle resource on the partition, to avoid wastage, such resource will be\n     // leveraged as much as we can, and preemption policy will reclaim it back\n     // when partitoned-resource-request comes back.  \n     Resource currentLimitResource \u003d\n         getCurrentLimitResource(nodePartition, clusterResource,\n             currentResourceLimits, schedulingMode);\n \n-    if (Resources.greaterThan(resourceCalculator, clusterResource,\n-        newTotalResource, currentLimitResource)) {\n+    Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n+\n+    // Set headroom for currentResourceLimits\n+    currentResourceLimits.setHeadroom(Resources.subtract(currentLimitResource,\n+        nowTotalUsed));\n+\n+    if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n+        nowTotalUsed, currentLimitResource)) {\n \n       // if reservation continous looking enabled, check to see if could we\n       // potentially use this node instead of a reserved node if the application\n       // has reserved containers.\n       // TODO, now only consider reservation cases when the node has no label\n       if (this.reservationsContinueLooking\n           \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n           \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n               resourceCouldBeUnreserved, Resources.none())) {\n         // resource-without-reserved \u003d used - reserved\n         Resource newTotalWithoutReservedResource \u003d\n-            Resources.subtract(newTotalResource, resourceCouldBeUnreserved);\n+            Resources.subtract(nowTotalUsed, resourceCouldBeUnreserved);\n \n         // when total-used-without-reserved-resource \u003c currentLimit, we still\n         // have chance to allocate on this node by unreserving some containers\n         if (Resources.lessThan(resourceCalculator, clusterResource,\n             newTotalWithoutReservedResource, currentLimitResource)) {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"try to use reserved: \" + getQueueName()\n                 + \" usedResources: \" + queueUsage.getUsed()\n                 + \", clusterResources: \" + clusterResource\n                 + \", reservedResources: \" + resourceCouldBeUnreserved\n                 + \", capacity-without-reserved: \"\n                 + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n                 + currentLimitResource);\n           }\n-          currentResourceLimits.setAmountNeededUnreserve(Resources.subtract(newTotalResource,\n-            currentLimitResource));\n           return true;\n         }\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(getQueueName()\n             + \"Check assign to queue, nodePartition\u003d\"\n             + nodePartition\n             + \" usedResources: \"\n             + queueUsage.getUsed(nodePartition)\n             + \" clusterResources: \"\n             + clusterResource\n             + \" currentUsedCapacity \"\n             + Resources.divide(resourceCalculator, clusterResource,\n                 queueUsage.getUsed(nodePartition),\n                 labelManager.getResourceByLabel(nodePartition, clusterResource))\n             + \" max-capacity: \"\n             + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n       }\n       return false;\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n      String nodePartition, ResourceLimits currentResourceLimits, Resource resourceCouldBeUnreserved,\n      SchedulingMode schedulingMode) {\n    // Get current limited resource: \n    // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n    // queues\u0027 max capacity.\n    // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n    // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n    // considered to be 100%. Which is a queue can use all resource in the\n    // partition. \n    // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n    // idle resource on the partition, to avoid wastage, such resource will be\n    // leveraged as much as we can, and preemption policy will reclaim it back\n    // when partitoned-resource-request comes back.  \n    Resource currentLimitResource \u003d\n        getCurrentLimitResource(nodePartition, clusterResource,\n            currentResourceLimits, schedulingMode);\n\n    Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n\n    // Set headroom for currentResourceLimits\n    currentResourceLimits.setHeadroom(Resources.subtract(currentLimitResource,\n        nowTotalUsed));\n\n    if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n        nowTotalUsed, currentLimitResource)) {\n\n      // if reservation continous looking enabled, check to see if could we\n      // potentially use this node instead of a reserved node if the application\n      // has reserved containers.\n      // TODO, now only consider reservation cases when the node has no label\n      if (this.reservationsContinueLooking\n          \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n          \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n              resourceCouldBeUnreserved, Resources.none())) {\n        // resource-without-reserved \u003d used - reserved\n        Resource newTotalWithoutReservedResource \u003d\n            Resources.subtract(nowTotalUsed, resourceCouldBeUnreserved);\n\n        // when total-used-without-reserved-resource \u003c currentLimit, we still\n        // have chance to allocate on this node by unreserving some containers\n        if (Resources.lessThan(resourceCalculator, clusterResource,\n            newTotalWithoutReservedResource, currentLimitResource)) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \" + getQueueName()\n                + \" usedResources: \" + queueUsage.getUsed()\n                + \", clusterResources: \" + clusterResource\n                + \", reservedResources: \" + resourceCouldBeUnreserved\n                + \", capacity-without-reserved: \"\n                + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n                + currentLimitResource);\n          }\n          return true;\n        }\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \"Check assign to queue, nodePartition\u003d\"\n            + nodePartition\n            + \" usedResources: \"\n            + queueUsage.getUsed(nodePartition)\n            + \" clusterResources: \"\n            + clusterResource\n            + \" currentUsedCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n                queueUsage.getUsed(nodePartition),\n                labelManager.getResourceByLabel(nodePartition, clusterResource))\n            + \" max-capacity: \"\n            + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n      }\n      return false;\n    }\n    return true;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
          "extendedDetails": {
            "oldValue": "[clusterResource-Resource, nodePartition-String, currentResourceLimits-ResourceLimits, nowRequired-Resource, resourceCouldBeUnreserved-Resource, schedulingMode-SchedulingMode]",
            "newValue": "[clusterResource-Resource, nodePartition-String, currentResourceLimits-ResourceLimits, resourceCouldBeUnreserved-Resource, schedulingMode-SchedulingMode]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-3026. Move application-specific container allocation logic from LeafQueue to FiCaSchedulerApp. Contributed by Wangda Tan\n",
          "commitDate": "24/07/15 2:00 PM",
          "commitName": "83fe34ac0896cee0918bbfad7bd51231e4aec39b",
          "commitAuthor": "Jian He",
          "commitDateOld": "21/07/15 9:57 AM",
          "commitNameOld": "c39ca541f498712133890961598bbff50d89d68b",
          "commitAuthorOld": "Wangda Tan",
          "daysBetweenCommits": 3.17,
          "commitsBetweenForRepo": 34,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,75 +1,74 @@\n   synchronized boolean canAssignToThisQueue(Resource clusterResource,\n-      String nodePartition, ResourceLimits currentResourceLimits,\n-      Resource nowRequired, Resource resourceCouldBeUnreserved,\n+      String nodePartition, ResourceLimits currentResourceLimits, Resource resourceCouldBeUnreserved,\n       SchedulingMode schedulingMode) {\n-    // New total resource \u003d used + required\n-    Resource newTotalResource \u003d\n-        Resources.add(queueUsage.getUsed(nodePartition), nowRequired);\n-\n     // Get current limited resource: \n     // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n     // queues\u0027 max capacity.\n     // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n     // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n     // considered to be 100%. Which is a queue can use all resource in the\n     // partition. \n     // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n     // idle resource on the partition, to avoid wastage, such resource will be\n     // leveraged as much as we can, and preemption policy will reclaim it back\n     // when partitoned-resource-request comes back.  \n     Resource currentLimitResource \u003d\n         getCurrentLimitResource(nodePartition, clusterResource,\n             currentResourceLimits, schedulingMode);\n \n-    if (Resources.greaterThan(resourceCalculator, clusterResource,\n-        newTotalResource, currentLimitResource)) {\n+    Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n+\n+    // Set headroom for currentResourceLimits\n+    currentResourceLimits.setHeadroom(Resources.subtract(currentLimitResource,\n+        nowTotalUsed));\n+\n+    if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n+        nowTotalUsed, currentLimitResource)) {\n \n       // if reservation continous looking enabled, check to see if could we\n       // potentially use this node instead of a reserved node if the application\n       // has reserved containers.\n       // TODO, now only consider reservation cases when the node has no label\n       if (this.reservationsContinueLooking\n           \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n           \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n               resourceCouldBeUnreserved, Resources.none())) {\n         // resource-without-reserved \u003d used - reserved\n         Resource newTotalWithoutReservedResource \u003d\n-            Resources.subtract(newTotalResource, resourceCouldBeUnreserved);\n+            Resources.subtract(nowTotalUsed, resourceCouldBeUnreserved);\n \n         // when total-used-without-reserved-resource \u003c currentLimit, we still\n         // have chance to allocate on this node by unreserving some containers\n         if (Resources.lessThan(resourceCalculator, clusterResource,\n             newTotalWithoutReservedResource, currentLimitResource)) {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"try to use reserved: \" + getQueueName()\n                 + \" usedResources: \" + queueUsage.getUsed()\n                 + \", clusterResources: \" + clusterResource\n                 + \", reservedResources: \" + resourceCouldBeUnreserved\n                 + \", capacity-without-reserved: \"\n                 + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n                 + currentLimitResource);\n           }\n-          currentResourceLimits.setAmountNeededUnreserve(Resources.subtract(newTotalResource,\n-            currentLimitResource));\n           return true;\n         }\n       }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(getQueueName()\n             + \"Check assign to queue, nodePartition\u003d\"\n             + nodePartition\n             + \" usedResources: \"\n             + queueUsage.getUsed(nodePartition)\n             + \" clusterResources: \"\n             + clusterResource\n             + \" currentUsedCapacity \"\n             + Resources.divide(resourceCalculator, clusterResource,\n                 queueUsage.getUsed(nodePartition),\n                 labelManager.getResourceByLabel(nodePartition, clusterResource))\n             + \" max-capacity: \"\n             + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n       }\n       return false;\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n      String nodePartition, ResourceLimits currentResourceLimits, Resource resourceCouldBeUnreserved,\n      SchedulingMode schedulingMode) {\n    // Get current limited resource: \n    // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n    // queues\u0027 max capacity.\n    // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n    // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n    // considered to be 100%. Which is a queue can use all resource in the\n    // partition. \n    // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n    // idle resource on the partition, to avoid wastage, such resource will be\n    // leveraged as much as we can, and preemption policy will reclaim it back\n    // when partitoned-resource-request comes back.  \n    Resource currentLimitResource \u003d\n        getCurrentLimitResource(nodePartition, clusterResource,\n            currentResourceLimits, schedulingMode);\n\n    Resource nowTotalUsed \u003d queueUsage.getUsed(nodePartition);\n\n    // Set headroom for currentResourceLimits\n    currentResourceLimits.setHeadroom(Resources.subtract(currentLimitResource,\n        nowTotalUsed));\n\n    if (Resources.greaterThanOrEqual(resourceCalculator, clusterResource,\n        nowTotalUsed, currentLimitResource)) {\n\n      // if reservation continous looking enabled, check to see if could we\n      // potentially use this node instead of a reserved node if the application\n      // has reserved containers.\n      // TODO, now only consider reservation cases when the node has no label\n      if (this.reservationsContinueLooking\n          \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n          \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n              resourceCouldBeUnreserved, Resources.none())) {\n        // resource-without-reserved \u003d used - reserved\n        Resource newTotalWithoutReservedResource \u003d\n            Resources.subtract(nowTotalUsed, resourceCouldBeUnreserved);\n\n        // when total-used-without-reserved-resource \u003c currentLimit, we still\n        // have chance to allocate on this node by unreserving some containers\n        if (Resources.lessThan(resourceCalculator, clusterResource,\n            newTotalWithoutReservedResource, currentLimitResource)) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \" + getQueueName()\n                + \" usedResources: \" + queueUsage.getUsed()\n                + \", clusterResources: \" + clusterResource\n                + \", reservedResources: \" + resourceCouldBeUnreserved\n                + \", capacity-without-reserved: \"\n                + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n                + currentLimitResource);\n          }\n          return true;\n        }\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \"Check assign to queue, nodePartition\u003d\"\n            + nodePartition\n            + \" usedResources: \"\n            + queueUsage.getUsed(nodePartition)\n            + \" clusterResources: \"\n            + clusterResource\n            + \" currentUsedCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n                queueUsage.getUsed(nodePartition),\n                labelManager.getResourceByLabel(nodePartition, clusterResource))\n            + \" max-capacity: \"\n            + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n      }\n      return false;\n    }\n    return true;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
          "extendedDetails": {}
        }
      ]
    },
    "189a63a719c63b67a1783a280bfc2f72dcb55277": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3434. Interaction between reservations and userlimit can result in significant ULF violation\n",
      "commitDate": "23/04/15 7:39 AM",
      "commitName": "189a63a719c63b67a1783a280bfc2f72dcb55277",
      "commitAuthor": "tgraves",
      "commitDateOld": "21/04/15 8:06 PM",
      "commitNameOld": "bdd90110e6904b59746812d9a093924a65e72280",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 1.48,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,75 +1,75 @@\n   synchronized boolean canAssignToThisQueue(Resource clusterResource,\n       String nodePartition, ResourceLimits currentResourceLimits,\n       Resource nowRequired, Resource resourceCouldBeUnreserved,\n       SchedulingMode schedulingMode) {\n     // New total resource \u003d used + required\n     Resource newTotalResource \u003d\n         Resources.add(queueUsage.getUsed(nodePartition), nowRequired);\n \n     // Get current limited resource: \n     // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n     // queues\u0027 max capacity.\n     // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n     // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n     // considered to be 100%. Which is a queue can use all resource in the\n     // partition. \n     // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n     // idle resource on the partition, to avoid wastage, such resource will be\n     // leveraged as much as we can, and preemption policy will reclaim it back\n     // when partitoned-resource-request comes back.  \n     Resource currentLimitResource \u003d\n         getCurrentLimitResource(nodePartition, clusterResource,\n             currentResourceLimits, schedulingMode);\n \n-    // if reservation continous looking enabled, check to see if could we\n-    // potentially use this node instead of a reserved node if the application\n-    // has reserved containers.\n-    // TODO, now only consider reservation cases when the node has no label\n-    if (this.reservationsContinueLooking\n-        \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n-        \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n-            resourceCouldBeUnreserved, Resources.none())) {\n-      // resource-without-reserved \u003d used - reserved\n-      Resource newTotalWithoutReservedResource \u003d\n-          Resources.subtract(newTotalResource, resourceCouldBeUnreserved);\n-\n-      // when total-used-without-reserved-resource \u003c currentLimit, we still\n-      // have chance to allocate on this node by unreserving some containers\n-      if (Resources.lessThan(resourceCalculator, clusterResource,\n-          newTotalWithoutReservedResource, currentLimitResource)) {\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"try to use reserved: \" + getQueueName()\n-              + \" usedResources: \" + queueUsage.getUsed()\n-              + \", clusterResources: \" + clusterResource\n-              + \", reservedResources: \" + resourceCouldBeUnreserved\n-              + \", capacity-without-reserved: \"\n-              + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n-              + currentLimitResource);\n-        }\n-        return true;\n-      }\n-    }\n-\n-    // Check if we over current-resource-limit computed.\n     if (Resources.greaterThan(resourceCalculator, clusterResource,\n         newTotalResource, currentLimitResource)) {\n-      return false;\n-    }\n \n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(getQueueName()\n-          + \"Check assign to queue, nodePartition\u003d\"\n-          + nodePartition\n-          + \" usedResources: \"\n-          + queueUsage.getUsed(nodePartition)\n-          + \" clusterResources: \"\n-          + clusterResource\n-          + \" currentUsedCapacity \"\n-          + Resources.divide(resourceCalculator, clusterResource,\n-              queueUsage.getUsed(nodePartition),\n-              labelManager.getResourceByLabel(nodePartition, clusterResource))\n-          + \" max-capacity: \"\n-          + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n+      // if reservation continous looking enabled, check to see if could we\n+      // potentially use this node instead of a reserved node if the application\n+      // has reserved containers.\n+      // TODO, now only consider reservation cases when the node has no label\n+      if (this.reservationsContinueLooking\n+          \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n+          \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n+              resourceCouldBeUnreserved, Resources.none())) {\n+        // resource-without-reserved \u003d used - reserved\n+        Resource newTotalWithoutReservedResource \u003d\n+            Resources.subtract(newTotalResource, resourceCouldBeUnreserved);\n+\n+        // when total-used-without-reserved-resource \u003c currentLimit, we still\n+        // have chance to allocate on this node by unreserving some containers\n+        if (Resources.lessThan(resourceCalculator, clusterResource,\n+            newTotalWithoutReservedResource, currentLimitResource)) {\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"try to use reserved: \" + getQueueName()\n+                + \" usedResources: \" + queueUsage.getUsed()\n+                + \", clusterResources: \" + clusterResource\n+                + \", reservedResources: \" + resourceCouldBeUnreserved\n+                + \", capacity-without-reserved: \"\n+                + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n+                + currentLimitResource);\n+          }\n+          currentResourceLimits.setAmountNeededUnreserve(Resources.subtract(newTotalResource,\n+            currentLimitResource));\n+          return true;\n+        }\n+      }\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(getQueueName()\n+            + \"Check assign to queue, nodePartition\u003d\"\n+            + nodePartition\n+            + \" usedResources: \"\n+            + queueUsage.getUsed(nodePartition)\n+            + \" clusterResources: \"\n+            + clusterResource\n+            + \" currentUsedCapacity \"\n+            + Resources.divide(resourceCalculator, clusterResource,\n+                queueUsage.getUsed(nodePartition),\n+                labelManager.getResourceByLabel(nodePartition, clusterResource))\n+            + \" max-capacity: \"\n+            + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n+      }\n+      return false;\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n      String nodePartition, ResourceLimits currentResourceLimits,\n      Resource nowRequired, Resource resourceCouldBeUnreserved,\n      SchedulingMode schedulingMode) {\n    // New total resource \u003d used + required\n    Resource newTotalResource \u003d\n        Resources.add(queueUsage.getUsed(nodePartition), nowRequired);\n\n    // Get current limited resource: \n    // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n    // queues\u0027 max capacity.\n    // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n    // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n    // considered to be 100%. Which is a queue can use all resource in the\n    // partition. \n    // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n    // idle resource on the partition, to avoid wastage, such resource will be\n    // leveraged as much as we can, and preemption policy will reclaim it back\n    // when partitoned-resource-request comes back.  \n    Resource currentLimitResource \u003d\n        getCurrentLimitResource(nodePartition, clusterResource,\n            currentResourceLimits, schedulingMode);\n\n    if (Resources.greaterThan(resourceCalculator, clusterResource,\n        newTotalResource, currentLimitResource)) {\n\n      // if reservation continous looking enabled, check to see if could we\n      // potentially use this node instead of a reserved node if the application\n      // has reserved containers.\n      // TODO, now only consider reservation cases when the node has no label\n      if (this.reservationsContinueLooking\n          \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n          \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n              resourceCouldBeUnreserved, Resources.none())) {\n        // resource-without-reserved \u003d used - reserved\n        Resource newTotalWithoutReservedResource \u003d\n            Resources.subtract(newTotalResource, resourceCouldBeUnreserved);\n\n        // when total-used-without-reserved-resource \u003c currentLimit, we still\n        // have chance to allocate on this node by unreserving some containers\n        if (Resources.lessThan(resourceCalculator, clusterResource,\n            newTotalWithoutReservedResource, currentLimitResource)) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \" + getQueueName()\n                + \" usedResources: \" + queueUsage.getUsed()\n                + \", clusterResources: \" + clusterResource\n                + \", reservedResources: \" + resourceCouldBeUnreserved\n                + \", capacity-without-reserved: \"\n                + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n                + currentLimitResource);\n          }\n          currentResourceLimits.setAmountNeededUnreserve(Resources.subtract(newTotalResource,\n            currentLimitResource));\n          return true;\n        }\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \"Check assign to queue, nodePartition\u003d\"\n            + nodePartition\n            + \" usedResources: \"\n            + queueUsage.getUsed(nodePartition)\n            + \" clusterResources: \"\n            + clusterResource\n            + \" currentUsedCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n                queueUsage.getUsed(nodePartition),\n                labelManager.getResourceByLabel(nodePartition, clusterResource))\n            + \" max-capacity: \"\n            + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n      }\n      return false;\n    }\n    return true;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
      "extendedDetails": {}
    },
    "0fefda645bca935b87b6bb8ca63e6f18340d59f5": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-3361. CapacityScheduler side changes to support non-exclusive node labels. Contributed by Wangda Tan\n",
      "commitDate": "14/04/15 11:45 AM",
      "commitName": "0fefda645bca935b87b6bb8ca63e6f18340d59f5",
      "commitAuthor": "Jian He",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-3361. CapacityScheduler side changes to support non-exclusive node labels. Contributed by Wangda Tan\n",
          "commitDate": "14/04/15 11:45 AM",
          "commitName": "0fefda645bca935b87b6bb8ca63e6f18340d59f5",
          "commitAuthor": "Jian He",
          "commitDateOld": "10/04/15 9:57 AM",
          "commitNameOld": "577d755e4bf72d6adedeba51be01ff5f3f028de0",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 4.08,
          "commitsBetweenForRepo": 25,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,79 +1,75 @@\n   synchronized boolean canAssignToThisQueue(Resource clusterResource,\n-      Set\u003cString\u003e nodeLabels, ResourceLimits currentResourceLimits,\n-      Resource nowRequired, Resource resourceCouldBeUnreserved) {\n-    // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n-    Set\u003cString\u003e labelCanAccess;\n-    if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n-      labelCanAccess \u003d new HashSet\u003cString\u003e();\n-      // Any queue can always access any node without label\n-      labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n-    } else {\n-      labelCanAccess \u003d new HashSet\u003cString\u003e(\n-          accessibleLabels.contains(CommonNodeLabelsManager.ANY) ? nodeLabels\n-              : Sets.intersection(accessibleLabels, nodeLabels));\n-    }\n-    \n-    for (String label : labelCanAccess) {\n-      // New total resource \u003d used + required\n-      Resource newTotalResource \u003d\n-          Resources.add(queueUsage.getUsed(label), nowRequired);\n+      String nodePartition, ResourceLimits currentResourceLimits,\n+      Resource nowRequired, Resource resourceCouldBeUnreserved,\n+      SchedulingMode schedulingMode) {\n+    // New total resource \u003d used + required\n+    Resource newTotalResource \u003d\n+        Resources.add(queueUsage.getUsed(nodePartition), nowRequired);\n \n-      Resource currentLimitResource \u003d\n-          getCurrentLimitResource(label, clusterResource, currentResourceLimits);\n+    // Get current limited resource: \n+    // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n+    // queues\u0027 max capacity.\n+    // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n+    // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n+    // considered to be 100%. Which is a queue can use all resource in the\n+    // partition. \n+    // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n+    // idle resource on the partition, to avoid wastage, such resource will be\n+    // leveraged as much as we can, and preemption policy will reclaim it back\n+    // when partitoned-resource-request comes back.  \n+    Resource currentLimitResource \u003d\n+        getCurrentLimitResource(nodePartition, clusterResource,\n+            currentResourceLimits, schedulingMode);\n \n-      // if reservation continous looking enabled, check to see if could we\n-      // potentially use this node instead of a reserved node if the application\n-      // has reserved containers.\n-      // TODO, now only consider reservation cases when the node has no label\n-      if (this.reservationsContinueLooking\n-          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)\n-          \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n-              resourceCouldBeUnreserved, Resources.none())) {\n-        // resource-without-reserved \u003d used - reserved\n-        Resource newTotalWithoutReservedResource \u003d\n-            Resources.subtract(newTotalResource, resourceCouldBeUnreserved);\n-        \n-        // when total-used-without-reserved-resource \u003c currentLimit, we still\n-        // have chance to allocate on this node by unreserving some containers\n-        if (Resources.lessThan(resourceCalculator, clusterResource,\n-            newTotalWithoutReservedResource, currentLimitResource)) {\n-          if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"try to use reserved: \" + getQueueName()\n-                + \" usedResources: \" + queueUsage.getUsed()\n-                + \", clusterResources: \" + clusterResource\n-                + \", reservedResources: \" + resourceCouldBeUnreserved\n-                + \", capacity-without-reserved: \"\n-                + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n-                + currentLimitResource); \n-          }\n-          return true;\n+    // if reservation continous looking enabled, check to see if could we\n+    // potentially use this node instead of a reserved node if the application\n+    // has reserved containers.\n+    // TODO, now only consider reservation cases when the node has no label\n+    if (this.reservationsContinueLooking\n+        \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n+        \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n+            resourceCouldBeUnreserved, Resources.none())) {\n+      // resource-without-reserved \u003d used - reserved\n+      Resource newTotalWithoutReservedResource \u003d\n+          Resources.subtract(newTotalResource, resourceCouldBeUnreserved);\n+\n+      // when total-used-without-reserved-resource \u003c currentLimit, we still\n+      // have chance to allocate on this node by unreserving some containers\n+      if (Resources.lessThan(resourceCalculator, clusterResource,\n+          newTotalWithoutReservedResource, currentLimitResource)) {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"try to use reserved: \" + getQueueName()\n+              + \" usedResources: \" + queueUsage.getUsed()\n+              + \", clusterResources: \" + clusterResource\n+              + \", reservedResources: \" + resourceCouldBeUnreserved\n+              + \", capacity-without-reserved: \"\n+              + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n+              + currentLimitResource);\n         }\n+        return true;\n       }\n-      \n-      // Otherwise, if any of the label of this node beyond queue limit, we\n-      // cannot allocate on this node. Consider a small epsilon here.\n-      if (Resources.greaterThan(resourceCalculator, clusterResource,\n-          newTotalResource, currentLimitResource)) {\n-        return false;\n-      }\n-\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(getQueueName()\n-            + \"Check assign to queue, label\u003d\" + label\n-            + \" usedResources: \" + queueUsage.getUsed(label)\n-            + \" clusterResources: \" + clusterResource\n-            + \" currentUsedCapacity \"\n-            + Resources.divide(resourceCalculator, clusterResource,\n-                queueUsage.getUsed(label),\n-                labelManager.getResourceByLabel(label, clusterResource))\n-            + \" max-capacity: \"\n-            + queueCapacities.getAbsoluteMaximumCapacity(label)\n-            + \")\");\n-      }\n-      return true;\n     }\n-    \n-    // Actually, this will not happen, since labelCanAccess will be always\n-    // non-empty\n-    return false;\n+\n+    // Check if we over current-resource-limit computed.\n+    if (Resources.greaterThan(resourceCalculator, clusterResource,\n+        newTotalResource, currentLimitResource)) {\n+      return false;\n+    }\n+\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(getQueueName()\n+          + \"Check assign to queue, nodePartition\u003d\"\n+          + nodePartition\n+          + \" usedResources: \"\n+          + queueUsage.getUsed(nodePartition)\n+          + \" clusterResources: \"\n+          + clusterResource\n+          + \" currentUsedCapacity \"\n+          + Resources.divide(resourceCalculator, clusterResource,\n+              queueUsage.getUsed(nodePartition),\n+              labelManager.getResourceByLabel(nodePartition, clusterResource))\n+          + \" max-capacity: \"\n+          + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n+    }\n+    return true;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n      String nodePartition, ResourceLimits currentResourceLimits,\n      Resource nowRequired, Resource resourceCouldBeUnreserved,\n      SchedulingMode schedulingMode) {\n    // New total resource \u003d used + required\n    Resource newTotalResource \u003d\n        Resources.add(queueUsage.getUsed(nodePartition), nowRequired);\n\n    // Get current limited resource: \n    // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n    // queues\u0027 max capacity.\n    // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n    // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n    // considered to be 100%. Which is a queue can use all resource in the\n    // partition. \n    // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n    // idle resource on the partition, to avoid wastage, such resource will be\n    // leveraged as much as we can, and preemption policy will reclaim it back\n    // when partitoned-resource-request comes back.  \n    Resource currentLimitResource \u003d\n        getCurrentLimitResource(nodePartition, clusterResource,\n            currentResourceLimits, schedulingMode);\n\n    // if reservation continous looking enabled, check to see if could we\n    // potentially use this node instead of a reserved node if the application\n    // has reserved containers.\n    // TODO, now only consider reservation cases when the node has no label\n    if (this.reservationsContinueLooking\n        \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n        \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n            resourceCouldBeUnreserved, Resources.none())) {\n      // resource-without-reserved \u003d used - reserved\n      Resource newTotalWithoutReservedResource \u003d\n          Resources.subtract(newTotalResource, resourceCouldBeUnreserved);\n\n      // when total-used-without-reserved-resource \u003c currentLimit, we still\n      // have chance to allocate on this node by unreserving some containers\n      if (Resources.lessThan(resourceCalculator, clusterResource,\n          newTotalWithoutReservedResource, currentLimitResource)) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"try to use reserved: \" + getQueueName()\n              + \" usedResources: \" + queueUsage.getUsed()\n              + \", clusterResources: \" + clusterResource\n              + \", reservedResources: \" + resourceCouldBeUnreserved\n              + \", capacity-without-reserved: \"\n              + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n              + currentLimitResource);\n        }\n        return true;\n      }\n    }\n\n    // Check if we over current-resource-limit computed.\n    if (Resources.greaterThan(resourceCalculator, clusterResource,\n        newTotalResource, currentLimitResource)) {\n      return false;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getQueueName()\n          + \"Check assign to queue, nodePartition\u003d\"\n          + nodePartition\n          + \" usedResources: \"\n          + queueUsage.getUsed(nodePartition)\n          + \" clusterResources: \"\n          + clusterResource\n          + \" currentUsedCapacity \"\n          + Resources.divide(resourceCalculator, clusterResource,\n              queueUsage.getUsed(nodePartition),\n              labelManager.getResourceByLabel(nodePartition, clusterResource))\n          + \" max-capacity: \"\n          + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n    }\n    return true;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
          "extendedDetails": {
            "oldValue": "[clusterResource-Resource, nodeLabels-Set\u003cString\u003e, currentResourceLimits-ResourceLimits, nowRequired-Resource, resourceCouldBeUnreserved-Resource]",
            "newValue": "[clusterResource-Resource, nodePartition-String, currentResourceLimits-ResourceLimits, nowRequired-Resource, resourceCouldBeUnreserved-Resource, schedulingMode-SchedulingMode]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-3361. CapacityScheduler side changes to support non-exclusive node labels. Contributed by Wangda Tan\n",
          "commitDate": "14/04/15 11:45 AM",
          "commitName": "0fefda645bca935b87b6bb8ca63e6f18340d59f5",
          "commitAuthor": "Jian He",
          "commitDateOld": "10/04/15 9:57 AM",
          "commitNameOld": "577d755e4bf72d6adedeba51be01ff5f3f028de0",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 4.08,
          "commitsBetweenForRepo": 25,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,79 +1,75 @@\n   synchronized boolean canAssignToThisQueue(Resource clusterResource,\n-      Set\u003cString\u003e nodeLabels, ResourceLimits currentResourceLimits,\n-      Resource nowRequired, Resource resourceCouldBeUnreserved) {\n-    // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n-    Set\u003cString\u003e labelCanAccess;\n-    if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n-      labelCanAccess \u003d new HashSet\u003cString\u003e();\n-      // Any queue can always access any node without label\n-      labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n-    } else {\n-      labelCanAccess \u003d new HashSet\u003cString\u003e(\n-          accessibleLabels.contains(CommonNodeLabelsManager.ANY) ? nodeLabels\n-              : Sets.intersection(accessibleLabels, nodeLabels));\n-    }\n-    \n-    for (String label : labelCanAccess) {\n-      // New total resource \u003d used + required\n-      Resource newTotalResource \u003d\n-          Resources.add(queueUsage.getUsed(label), nowRequired);\n+      String nodePartition, ResourceLimits currentResourceLimits,\n+      Resource nowRequired, Resource resourceCouldBeUnreserved,\n+      SchedulingMode schedulingMode) {\n+    // New total resource \u003d used + required\n+    Resource newTotalResource \u003d\n+        Resources.add(queueUsage.getUsed(nodePartition), nowRequired);\n \n-      Resource currentLimitResource \u003d\n-          getCurrentLimitResource(label, clusterResource, currentResourceLimits);\n+    // Get current limited resource: \n+    // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n+    // queues\u0027 max capacity.\n+    // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n+    // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n+    // considered to be 100%. Which is a queue can use all resource in the\n+    // partition. \n+    // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n+    // idle resource on the partition, to avoid wastage, such resource will be\n+    // leveraged as much as we can, and preemption policy will reclaim it back\n+    // when partitoned-resource-request comes back.  \n+    Resource currentLimitResource \u003d\n+        getCurrentLimitResource(nodePartition, clusterResource,\n+            currentResourceLimits, schedulingMode);\n \n-      // if reservation continous looking enabled, check to see if could we\n-      // potentially use this node instead of a reserved node if the application\n-      // has reserved containers.\n-      // TODO, now only consider reservation cases when the node has no label\n-      if (this.reservationsContinueLooking\n-          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)\n-          \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n-              resourceCouldBeUnreserved, Resources.none())) {\n-        // resource-without-reserved \u003d used - reserved\n-        Resource newTotalWithoutReservedResource \u003d\n-            Resources.subtract(newTotalResource, resourceCouldBeUnreserved);\n-        \n-        // when total-used-without-reserved-resource \u003c currentLimit, we still\n-        // have chance to allocate on this node by unreserving some containers\n-        if (Resources.lessThan(resourceCalculator, clusterResource,\n-            newTotalWithoutReservedResource, currentLimitResource)) {\n-          if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"try to use reserved: \" + getQueueName()\n-                + \" usedResources: \" + queueUsage.getUsed()\n-                + \", clusterResources: \" + clusterResource\n-                + \", reservedResources: \" + resourceCouldBeUnreserved\n-                + \", capacity-without-reserved: \"\n-                + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n-                + currentLimitResource); \n-          }\n-          return true;\n+    // if reservation continous looking enabled, check to see if could we\n+    // potentially use this node instead of a reserved node if the application\n+    // has reserved containers.\n+    // TODO, now only consider reservation cases when the node has no label\n+    if (this.reservationsContinueLooking\n+        \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n+        \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n+            resourceCouldBeUnreserved, Resources.none())) {\n+      // resource-without-reserved \u003d used - reserved\n+      Resource newTotalWithoutReservedResource \u003d\n+          Resources.subtract(newTotalResource, resourceCouldBeUnreserved);\n+\n+      // when total-used-without-reserved-resource \u003c currentLimit, we still\n+      // have chance to allocate on this node by unreserving some containers\n+      if (Resources.lessThan(resourceCalculator, clusterResource,\n+          newTotalWithoutReservedResource, currentLimitResource)) {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"try to use reserved: \" + getQueueName()\n+              + \" usedResources: \" + queueUsage.getUsed()\n+              + \", clusterResources: \" + clusterResource\n+              + \", reservedResources: \" + resourceCouldBeUnreserved\n+              + \", capacity-without-reserved: \"\n+              + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n+              + currentLimitResource);\n         }\n+        return true;\n       }\n-      \n-      // Otherwise, if any of the label of this node beyond queue limit, we\n-      // cannot allocate on this node. Consider a small epsilon here.\n-      if (Resources.greaterThan(resourceCalculator, clusterResource,\n-          newTotalResource, currentLimitResource)) {\n-        return false;\n-      }\n-\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(getQueueName()\n-            + \"Check assign to queue, label\u003d\" + label\n-            + \" usedResources: \" + queueUsage.getUsed(label)\n-            + \" clusterResources: \" + clusterResource\n-            + \" currentUsedCapacity \"\n-            + Resources.divide(resourceCalculator, clusterResource,\n-                queueUsage.getUsed(label),\n-                labelManager.getResourceByLabel(label, clusterResource))\n-            + \" max-capacity: \"\n-            + queueCapacities.getAbsoluteMaximumCapacity(label)\n-            + \")\");\n-      }\n-      return true;\n     }\n-    \n-    // Actually, this will not happen, since labelCanAccess will be always\n-    // non-empty\n-    return false;\n+\n+    // Check if we over current-resource-limit computed.\n+    if (Resources.greaterThan(resourceCalculator, clusterResource,\n+        newTotalResource, currentLimitResource)) {\n+      return false;\n+    }\n+\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(getQueueName()\n+          + \"Check assign to queue, nodePartition\u003d\"\n+          + nodePartition\n+          + \" usedResources: \"\n+          + queueUsage.getUsed(nodePartition)\n+          + \" clusterResources: \"\n+          + clusterResource\n+          + \" currentUsedCapacity \"\n+          + Resources.divide(resourceCalculator, clusterResource,\n+              queueUsage.getUsed(nodePartition),\n+              labelManager.getResourceByLabel(nodePartition, clusterResource))\n+          + \" max-capacity: \"\n+          + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n+    }\n+    return true;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n      String nodePartition, ResourceLimits currentResourceLimits,\n      Resource nowRequired, Resource resourceCouldBeUnreserved,\n      SchedulingMode schedulingMode) {\n    // New total resource \u003d used + required\n    Resource newTotalResource \u003d\n        Resources.add(queueUsage.getUsed(nodePartition), nowRequired);\n\n    // Get current limited resource: \n    // - When doing RESPECT_PARTITION_EXCLUSIVITY allocation, we will respect\n    // queues\u0027 max capacity.\n    // - When doing IGNORE_PARTITION_EXCLUSIVITY allocation, we will not respect\n    // queue\u0027s max capacity, queue\u0027s max capacity on the partition will be\n    // considered to be 100%. Which is a queue can use all resource in the\n    // partition. \n    // Doing this because: for non-exclusive allocation, we make sure there\u0027s\n    // idle resource on the partition, to avoid wastage, such resource will be\n    // leveraged as much as we can, and preemption policy will reclaim it back\n    // when partitoned-resource-request comes back.  \n    Resource currentLimitResource \u003d\n        getCurrentLimitResource(nodePartition, clusterResource,\n            currentResourceLimits, schedulingMode);\n\n    // if reservation continous looking enabled, check to see if could we\n    // potentially use this node instead of a reserved node if the application\n    // has reserved containers.\n    // TODO, now only consider reservation cases when the node has no label\n    if (this.reservationsContinueLooking\n        \u0026\u0026 nodePartition.equals(RMNodeLabelsManager.NO_LABEL)\n        \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n            resourceCouldBeUnreserved, Resources.none())) {\n      // resource-without-reserved \u003d used - reserved\n      Resource newTotalWithoutReservedResource \u003d\n          Resources.subtract(newTotalResource, resourceCouldBeUnreserved);\n\n      // when total-used-without-reserved-resource \u003c currentLimit, we still\n      // have chance to allocate on this node by unreserving some containers\n      if (Resources.lessThan(resourceCalculator, clusterResource,\n          newTotalWithoutReservedResource, currentLimitResource)) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"try to use reserved: \" + getQueueName()\n              + \" usedResources: \" + queueUsage.getUsed()\n              + \", clusterResources: \" + clusterResource\n              + \", reservedResources: \" + resourceCouldBeUnreserved\n              + \", capacity-without-reserved: \"\n              + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n              + currentLimitResource);\n        }\n        return true;\n      }\n    }\n\n    // Check if we over current-resource-limit computed.\n    if (Resources.greaterThan(resourceCalculator, clusterResource,\n        newTotalResource, currentLimitResource)) {\n      return false;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getQueueName()\n          + \"Check assign to queue, nodePartition\u003d\"\n          + nodePartition\n          + \" usedResources: \"\n          + queueUsage.getUsed(nodePartition)\n          + \" clusterResources: \"\n          + clusterResource\n          + \" currentUsedCapacity \"\n          + Resources.divide(resourceCalculator, clusterResource,\n              queueUsage.getUsed(nodePartition),\n              labelManager.getResourceByLabel(nodePartition, clusterResource))\n          + \" max-capacity: \"\n          + queueCapacities.getAbsoluteMaximumCapacity(nodePartition) + \")\");\n    }\n    return true;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
          "extendedDetails": {}
        }
      ]
    },
    "487374b7fe0c92fc7eb1406c568952722b5d5b15": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange,Yparameterchange)",
      "commitMessage": "YARN-3243. CapacityScheduler should pass headroom from parent to children to make sure ParentQueue obey its capacity limits. Contributed by Wangda Tan.\n",
      "commitDate": "17/03/15 10:24 AM",
      "commitName": "487374b7fe0c92fc7eb1406c568952722b5d5b15",
      "commitAuthor": "Jian He",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "YARN-3243. CapacityScheduler should pass headroom from parent to children to make sure ParentQueue obey its capacity limits. Contributed by Wangda Tan.\n",
          "commitDate": "17/03/15 10:24 AM",
          "commitName": "487374b7fe0c92fc7eb1406c568952722b5d5b15",
          "commitAuthor": "Jian He",
          "commitDateOld": "17/03/15 9:09 AM",
          "commitNameOld": "a89b087c45e549e1f5b5fc953de4657fcbb97195",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 0.05,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,83 +1,79 @@\n   synchronized boolean canAssignToThisQueue(Resource clusterResource,\n-      Resource required, Set\u003cString\u003e nodeLabels, FiCaSchedulerApp application, \n-      boolean checkReservations) {\n+      Set\u003cString\u003e nodeLabels, ResourceLimits currentResourceLimits,\n+      Resource nowRequired, Resource resourceCouldBeUnreserved) {\n     // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n     Set\u003cString\u003e labelCanAccess;\n     if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n       labelCanAccess \u003d new HashSet\u003cString\u003e();\n       // Any queue can always access any node without label\n       labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n     } else {\n-      labelCanAccess \u003d new HashSet\u003cString\u003e(Sets.intersection(accessibleLabels, nodeLabels));\n+      labelCanAccess \u003d new HashSet\u003cString\u003e(\n+          accessibleLabels.contains(CommonNodeLabelsManager.ANY) ? nodeLabels\n+              : Sets.intersection(accessibleLabels, nodeLabels));\n     }\n     \n-    boolean canAssign \u003d true;\n     for (String label : labelCanAccess) {\n-      Resource potentialTotalCapacity \u003d\n-          Resources.add(queueUsage.getUsed(label), required);\n-      \n-      float potentialNewCapacity \u003d\n-          Resources.divide(resourceCalculator, clusterResource,\n-              potentialTotalCapacity,\n-              labelManager.getResourceByLabel(label, clusterResource));\n-      // if enabled, check to see if could we potentially use this node instead\n-      // of a reserved node if the application has reserved containers\n-      // TODO, now only consider reservation cases when the node has no label\n-      if (this.reservationsContinueLooking \u0026\u0026 checkReservations\n-          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)) {\n-        float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n-            resourceCalculator,\n-            clusterResource,\n-            Resources.subtract(potentialTotalCapacity,\n-               application.getCurrentReservation()),\n-            labelManager.getResourceByLabel(label, clusterResource));\n+      // New total resource \u003d used + required\n+      Resource newTotalResource \u003d\n+          Resources.add(queueUsage.getUsed(label), nowRequired);\n \n-        if (potentialNewWithoutReservedCapacity \u003c\u003d queueCapacities\n-            .getAbsoluteMaximumCapacity()) {\n+      Resource currentLimitResource \u003d\n+          getCurrentLimitResource(label, clusterResource, currentResourceLimits);\n+\n+      // if reservation continous looking enabled, check to see if could we\n+      // potentially use this node instead of a reserved node if the application\n+      // has reserved containers.\n+      // TODO, now only consider reservation cases when the node has no label\n+      if (this.reservationsContinueLooking\n+          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)\n+          \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n+              resourceCouldBeUnreserved, Resources.none())) {\n+        // resource-without-reserved \u003d used - reserved\n+        Resource newTotalWithoutReservedResource \u003d\n+            Resources.subtract(newTotalResource, resourceCouldBeUnreserved);\n+        \n+        // when total-used-without-reserved-resource \u003c currentLimit, we still\n+        // have chance to allocate on this node by unreserving some containers\n+        if (Resources.lessThan(resourceCalculator, clusterResource,\n+            newTotalWithoutReservedResource, currentLimitResource)) {\n           if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"try to use reserved: \"\n-                + getQueueName()\n-                + \" usedResources: \"\n-                + queueUsage.getUsed()\n-                + \" clusterResources: \"\n-                + clusterResource\n-                + \" reservedResources: \"\n-                + application.getCurrentReservation()\n-                + \" currentCapacity \"\n-                + Resources.divide(resourceCalculator, clusterResource,\n-                    queueUsage.getUsed(), clusterResource) + \" required \" + required\n-                + \" potentialNewWithoutReservedCapacity: \"\n-                + potentialNewWithoutReservedCapacity + \" ( \"\n-                + \" max-capacity: \"\n-                + queueCapacities.getAbsoluteMaximumCapacity() + \")\");\n+            LOG.debug(\"try to use reserved: \" + getQueueName()\n+                + \" usedResources: \" + queueUsage.getUsed()\n+                + \", clusterResources: \" + clusterResource\n+                + \", reservedResources: \" + resourceCouldBeUnreserved\n+                + \", capacity-without-reserved: \"\n+                + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n+                + currentLimitResource); \n           }\n-          // we could potentially use this node instead of reserved node\n           return true;\n         }\n       }\n       \n       // Otherwise, if any of the label of this node beyond queue limit, we\n       // cannot allocate on this node. Consider a small epsilon here.\n-      if (potentialNewCapacity \u003e queueCapacities\n-          .getAbsoluteMaximumCapacity(label) + 1e-4) {\n-        canAssign \u003d false;\n-        break;\n+      if (Resources.greaterThan(resourceCalculator, clusterResource,\n+          newTotalResource, currentLimitResource)) {\n+        return false;\n       }\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(getQueueName()\n             + \"Check assign to queue, label\u003d\" + label\n             + \" usedResources: \" + queueUsage.getUsed(label)\n             + \" clusterResources: \" + clusterResource\n-            + \" currentCapacity \"\n+            + \" currentUsedCapacity \"\n             + Resources.divide(resourceCalculator, clusterResource,\n                 queueUsage.getUsed(label),\n                 labelManager.getResourceByLabel(label, clusterResource))\n-            + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n-            + \" max-capacity: \" + queueCapacities.getAbsoluteMaximumCapacity()\n+            + \" max-capacity: \"\n+            + queueCapacities.getAbsoluteMaximumCapacity(label)\n             + \")\");\n       }\n+      return true;\n     }\n     \n-    return canAssign;\n+    // Actually, this will not happen, since labelCanAccess will be always\n+    // non-empty\n+    return false;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n      Set\u003cString\u003e nodeLabels, ResourceLimits currentResourceLimits,\n      Resource nowRequired, Resource resourceCouldBeUnreserved) {\n    // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n    Set\u003cString\u003e labelCanAccess;\n    if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n      labelCanAccess \u003d new HashSet\u003cString\u003e();\n      // Any queue can always access any node without label\n      labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n    } else {\n      labelCanAccess \u003d new HashSet\u003cString\u003e(\n          accessibleLabels.contains(CommonNodeLabelsManager.ANY) ? nodeLabels\n              : Sets.intersection(accessibleLabels, nodeLabels));\n    }\n    \n    for (String label : labelCanAccess) {\n      // New total resource \u003d used + required\n      Resource newTotalResource \u003d\n          Resources.add(queueUsage.getUsed(label), nowRequired);\n\n      Resource currentLimitResource \u003d\n          getCurrentLimitResource(label, clusterResource, currentResourceLimits);\n\n      // if reservation continous looking enabled, check to see if could we\n      // potentially use this node instead of a reserved node if the application\n      // has reserved containers.\n      // TODO, now only consider reservation cases when the node has no label\n      if (this.reservationsContinueLooking\n          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)\n          \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n              resourceCouldBeUnreserved, Resources.none())) {\n        // resource-without-reserved \u003d used - reserved\n        Resource newTotalWithoutReservedResource \u003d\n            Resources.subtract(newTotalResource, resourceCouldBeUnreserved);\n        \n        // when total-used-without-reserved-resource \u003c currentLimit, we still\n        // have chance to allocate on this node by unreserving some containers\n        if (Resources.lessThan(resourceCalculator, clusterResource,\n            newTotalWithoutReservedResource, currentLimitResource)) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \" + getQueueName()\n                + \" usedResources: \" + queueUsage.getUsed()\n                + \", clusterResources: \" + clusterResource\n                + \", reservedResources: \" + resourceCouldBeUnreserved\n                + \", capacity-without-reserved: \"\n                + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n                + currentLimitResource); \n          }\n          return true;\n        }\n      }\n      \n      // Otherwise, if any of the label of this node beyond queue limit, we\n      // cannot allocate on this node. Consider a small epsilon here.\n      if (Resources.greaterThan(resourceCalculator, clusterResource,\n          newTotalResource, currentLimitResource)) {\n        return false;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \"Check assign to queue, label\u003d\" + label\n            + \" usedResources: \" + queueUsage.getUsed(label)\n            + \" clusterResources: \" + clusterResource\n            + \" currentUsedCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n                queueUsage.getUsed(label),\n                labelManager.getResourceByLabel(label, clusterResource))\n            + \" max-capacity: \"\n            + queueCapacities.getAbsoluteMaximumCapacity(label)\n            + \")\");\n      }\n      return true;\n    }\n    \n    // Actually, this will not happen, since labelCanAccess will be always\n    // non-empty\n    return false;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
          "extendedDetails": {
            "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
            "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
            "oldMethodName": "canAssignToThisQueue",
            "newMethodName": "canAssignToThisQueue"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-3243. CapacityScheduler should pass headroom from parent to children to make sure ParentQueue obey its capacity limits. Contributed by Wangda Tan.\n",
          "commitDate": "17/03/15 10:24 AM",
          "commitName": "487374b7fe0c92fc7eb1406c568952722b5d5b15",
          "commitAuthor": "Jian He",
          "commitDateOld": "17/03/15 9:09 AM",
          "commitNameOld": "a89b087c45e549e1f5b5fc953de4657fcbb97195",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 0.05,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,83 +1,79 @@\n   synchronized boolean canAssignToThisQueue(Resource clusterResource,\n-      Resource required, Set\u003cString\u003e nodeLabels, FiCaSchedulerApp application, \n-      boolean checkReservations) {\n+      Set\u003cString\u003e nodeLabels, ResourceLimits currentResourceLimits,\n+      Resource nowRequired, Resource resourceCouldBeUnreserved) {\n     // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n     Set\u003cString\u003e labelCanAccess;\n     if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n       labelCanAccess \u003d new HashSet\u003cString\u003e();\n       // Any queue can always access any node without label\n       labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n     } else {\n-      labelCanAccess \u003d new HashSet\u003cString\u003e(Sets.intersection(accessibleLabels, nodeLabels));\n+      labelCanAccess \u003d new HashSet\u003cString\u003e(\n+          accessibleLabels.contains(CommonNodeLabelsManager.ANY) ? nodeLabels\n+              : Sets.intersection(accessibleLabels, nodeLabels));\n     }\n     \n-    boolean canAssign \u003d true;\n     for (String label : labelCanAccess) {\n-      Resource potentialTotalCapacity \u003d\n-          Resources.add(queueUsage.getUsed(label), required);\n-      \n-      float potentialNewCapacity \u003d\n-          Resources.divide(resourceCalculator, clusterResource,\n-              potentialTotalCapacity,\n-              labelManager.getResourceByLabel(label, clusterResource));\n-      // if enabled, check to see if could we potentially use this node instead\n-      // of a reserved node if the application has reserved containers\n-      // TODO, now only consider reservation cases when the node has no label\n-      if (this.reservationsContinueLooking \u0026\u0026 checkReservations\n-          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)) {\n-        float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n-            resourceCalculator,\n-            clusterResource,\n-            Resources.subtract(potentialTotalCapacity,\n-               application.getCurrentReservation()),\n-            labelManager.getResourceByLabel(label, clusterResource));\n+      // New total resource \u003d used + required\n+      Resource newTotalResource \u003d\n+          Resources.add(queueUsage.getUsed(label), nowRequired);\n \n-        if (potentialNewWithoutReservedCapacity \u003c\u003d queueCapacities\n-            .getAbsoluteMaximumCapacity()) {\n+      Resource currentLimitResource \u003d\n+          getCurrentLimitResource(label, clusterResource, currentResourceLimits);\n+\n+      // if reservation continous looking enabled, check to see if could we\n+      // potentially use this node instead of a reserved node if the application\n+      // has reserved containers.\n+      // TODO, now only consider reservation cases when the node has no label\n+      if (this.reservationsContinueLooking\n+          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)\n+          \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n+              resourceCouldBeUnreserved, Resources.none())) {\n+        // resource-without-reserved \u003d used - reserved\n+        Resource newTotalWithoutReservedResource \u003d\n+            Resources.subtract(newTotalResource, resourceCouldBeUnreserved);\n+        \n+        // when total-used-without-reserved-resource \u003c currentLimit, we still\n+        // have chance to allocate on this node by unreserving some containers\n+        if (Resources.lessThan(resourceCalculator, clusterResource,\n+            newTotalWithoutReservedResource, currentLimitResource)) {\n           if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"try to use reserved: \"\n-                + getQueueName()\n-                + \" usedResources: \"\n-                + queueUsage.getUsed()\n-                + \" clusterResources: \"\n-                + clusterResource\n-                + \" reservedResources: \"\n-                + application.getCurrentReservation()\n-                + \" currentCapacity \"\n-                + Resources.divide(resourceCalculator, clusterResource,\n-                    queueUsage.getUsed(), clusterResource) + \" required \" + required\n-                + \" potentialNewWithoutReservedCapacity: \"\n-                + potentialNewWithoutReservedCapacity + \" ( \"\n-                + \" max-capacity: \"\n-                + queueCapacities.getAbsoluteMaximumCapacity() + \")\");\n+            LOG.debug(\"try to use reserved: \" + getQueueName()\n+                + \" usedResources: \" + queueUsage.getUsed()\n+                + \", clusterResources: \" + clusterResource\n+                + \", reservedResources: \" + resourceCouldBeUnreserved\n+                + \", capacity-without-reserved: \"\n+                + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n+                + currentLimitResource); \n           }\n-          // we could potentially use this node instead of reserved node\n           return true;\n         }\n       }\n       \n       // Otherwise, if any of the label of this node beyond queue limit, we\n       // cannot allocate on this node. Consider a small epsilon here.\n-      if (potentialNewCapacity \u003e queueCapacities\n-          .getAbsoluteMaximumCapacity(label) + 1e-4) {\n-        canAssign \u003d false;\n-        break;\n+      if (Resources.greaterThan(resourceCalculator, clusterResource,\n+          newTotalResource, currentLimitResource)) {\n+        return false;\n       }\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(getQueueName()\n             + \"Check assign to queue, label\u003d\" + label\n             + \" usedResources: \" + queueUsage.getUsed(label)\n             + \" clusterResources: \" + clusterResource\n-            + \" currentCapacity \"\n+            + \" currentUsedCapacity \"\n             + Resources.divide(resourceCalculator, clusterResource,\n                 queueUsage.getUsed(label),\n                 labelManager.getResourceByLabel(label, clusterResource))\n-            + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n-            + \" max-capacity: \" + queueCapacities.getAbsoluteMaximumCapacity()\n+            + \" max-capacity: \"\n+            + queueCapacities.getAbsoluteMaximumCapacity(label)\n             + \")\");\n       }\n+      return true;\n     }\n     \n-    return canAssign;\n+    // Actually, this will not happen, since labelCanAccess will be always\n+    // non-empty\n+    return false;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n      Set\u003cString\u003e nodeLabels, ResourceLimits currentResourceLimits,\n      Resource nowRequired, Resource resourceCouldBeUnreserved) {\n    // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n    Set\u003cString\u003e labelCanAccess;\n    if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n      labelCanAccess \u003d new HashSet\u003cString\u003e();\n      // Any queue can always access any node without label\n      labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n    } else {\n      labelCanAccess \u003d new HashSet\u003cString\u003e(\n          accessibleLabels.contains(CommonNodeLabelsManager.ANY) ? nodeLabels\n              : Sets.intersection(accessibleLabels, nodeLabels));\n    }\n    \n    for (String label : labelCanAccess) {\n      // New total resource \u003d used + required\n      Resource newTotalResource \u003d\n          Resources.add(queueUsage.getUsed(label), nowRequired);\n\n      Resource currentLimitResource \u003d\n          getCurrentLimitResource(label, clusterResource, currentResourceLimits);\n\n      // if reservation continous looking enabled, check to see if could we\n      // potentially use this node instead of a reserved node if the application\n      // has reserved containers.\n      // TODO, now only consider reservation cases when the node has no label\n      if (this.reservationsContinueLooking\n          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)\n          \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n              resourceCouldBeUnreserved, Resources.none())) {\n        // resource-without-reserved \u003d used - reserved\n        Resource newTotalWithoutReservedResource \u003d\n            Resources.subtract(newTotalResource, resourceCouldBeUnreserved);\n        \n        // when total-used-without-reserved-resource \u003c currentLimit, we still\n        // have chance to allocate on this node by unreserving some containers\n        if (Resources.lessThan(resourceCalculator, clusterResource,\n            newTotalWithoutReservedResource, currentLimitResource)) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \" + getQueueName()\n                + \" usedResources: \" + queueUsage.getUsed()\n                + \", clusterResources: \" + clusterResource\n                + \", reservedResources: \" + resourceCouldBeUnreserved\n                + \", capacity-without-reserved: \"\n                + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n                + currentLimitResource); \n          }\n          return true;\n        }\n      }\n      \n      // Otherwise, if any of the label of this node beyond queue limit, we\n      // cannot allocate on this node. Consider a small epsilon here.\n      if (Resources.greaterThan(resourceCalculator, clusterResource,\n          newTotalResource, currentLimitResource)) {\n        return false;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \"Check assign to queue, label\u003d\" + label\n            + \" usedResources: \" + queueUsage.getUsed(label)\n            + \" clusterResources: \" + clusterResource\n            + \" currentUsedCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n                queueUsage.getUsed(label),\n                labelManager.getResourceByLabel(label, clusterResource))\n            + \" max-capacity: \"\n            + queueCapacities.getAbsoluteMaximumCapacity(label)\n            + \")\");\n      }\n      return true;\n    }\n    \n    // Actually, this will not happen, since labelCanAccess will be always\n    // non-empty\n    return false;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-3243. CapacityScheduler should pass headroom from parent to children to make sure ParentQueue obey its capacity limits. Contributed by Wangda Tan.\n",
          "commitDate": "17/03/15 10:24 AM",
          "commitName": "487374b7fe0c92fc7eb1406c568952722b5d5b15",
          "commitAuthor": "Jian He",
          "commitDateOld": "17/03/15 9:09 AM",
          "commitNameOld": "a89b087c45e549e1f5b5fc953de4657fcbb97195",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 0.05,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,83 +1,79 @@\n   synchronized boolean canAssignToThisQueue(Resource clusterResource,\n-      Resource required, Set\u003cString\u003e nodeLabels, FiCaSchedulerApp application, \n-      boolean checkReservations) {\n+      Set\u003cString\u003e nodeLabels, ResourceLimits currentResourceLimits,\n+      Resource nowRequired, Resource resourceCouldBeUnreserved) {\n     // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n     Set\u003cString\u003e labelCanAccess;\n     if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n       labelCanAccess \u003d new HashSet\u003cString\u003e();\n       // Any queue can always access any node without label\n       labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n     } else {\n-      labelCanAccess \u003d new HashSet\u003cString\u003e(Sets.intersection(accessibleLabels, nodeLabels));\n+      labelCanAccess \u003d new HashSet\u003cString\u003e(\n+          accessibleLabels.contains(CommonNodeLabelsManager.ANY) ? nodeLabels\n+              : Sets.intersection(accessibleLabels, nodeLabels));\n     }\n     \n-    boolean canAssign \u003d true;\n     for (String label : labelCanAccess) {\n-      Resource potentialTotalCapacity \u003d\n-          Resources.add(queueUsage.getUsed(label), required);\n-      \n-      float potentialNewCapacity \u003d\n-          Resources.divide(resourceCalculator, clusterResource,\n-              potentialTotalCapacity,\n-              labelManager.getResourceByLabel(label, clusterResource));\n-      // if enabled, check to see if could we potentially use this node instead\n-      // of a reserved node if the application has reserved containers\n-      // TODO, now only consider reservation cases when the node has no label\n-      if (this.reservationsContinueLooking \u0026\u0026 checkReservations\n-          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)) {\n-        float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n-            resourceCalculator,\n-            clusterResource,\n-            Resources.subtract(potentialTotalCapacity,\n-               application.getCurrentReservation()),\n-            labelManager.getResourceByLabel(label, clusterResource));\n+      // New total resource \u003d used + required\n+      Resource newTotalResource \u003d\n+          Resources.add(queueUsage.getUsed(label), nowRequired);\n \n-        if (potentialNewWithoutReservedCapacity \u003c\u003d queueCapacities\n-            .getAbsoluteMaximumCapacity()) {\n+      Resource currentLimitResource \u003d\n+          getCurrentLimitResource(label, clusterResource, currentResourceLimits);\n+\n+      // if reservation continous looking enabled, check to see if could we\n+      // potentially use this node instead of a reserved node if the application\n+      // has reserved containers.\n+      // TODO, now only consider reservation cases when the node has no label\n+      if (this.reservationsContinueLooking\n+          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)\n+          \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n+              resourceCouldBeUnreserved, Resources.none())) {\n+        // resource-without-reserved \u003d used - reserved\n+        Resource newTotalWithoutReservedResource \u003d\n+            Resources.subtract(newTotalResource, resourceCouldBeUnreserved);\n+        \n+        // when total-used-without-reserved-resource \u003c currentLimit, we still\n+        // have chance to allocate on this node by unreserving some containers\n+        if (Resources.lessThan(resourceCalculator, clusterResource,\n+            newTotalWithoutReservedResource, currentLimitResource)) {\n           if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"try to use reserved: \"\n-                + getQueueName()\n-                + \" usedResources: \"\n-                + queueUsage.getUsed()\n-                + \" clusterResources: \"\n-                + clusterResource\n-                + \" reservedResources: \"\n-                + application.getCurrentReservation()\n-                + \" currentCapacity \"\n-                + Resources.divide(resourceCalculator, clusterResource,\n-                    queueUsage.getUsed(), clusterResource) + \" required \" + required\n-                + \" potentialNewWithoutReservedCapacity: \"\n-                + potentialNewWithoutReservedCapacity + \" ( \"\n-                + \" max-capacity: \"\n-                + queueCapacities.getAbsoluteMaximumCapacity() + \")\");\n+            LOG.debug(\"try to use reserved: \" + getQueueName()\n+                + \" usedResources: \" + queueUsage.getUsed()\n+                + \", clusterResources: \" + clusterResource\n+                + \", reservedResources: \" + resourceCouldBeUnreserved\n+                + \", capacity-without-reserved: \"\n+                + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n+                + currentLimitResource); \n           }\n-          // we could potentially use this node instead of reserved node\n           return true;\n         }\n       }\n       \n       // Otherwise, if any of the label of this node beyond queue limit, we\n       // cannot allocate on this node. Consider a small epsilon here.\n-      if (potentialNewCapacity \u003e queueCapacities\n-          .getAbsoluteMaximumCapacity(label) + 1e-4) {\n-        canAssign \u003d false;\n-        break;\n+      if (Resources.greaterThan(resourceCalculator, clusterResource,\n+          newTotalResource, currentLimitResource)) {\n+        return false;\n       }\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(getQueueName()\n             + \"Check assign to queue, label\u003d\" + label\n             + \" usedResources: \" + queueUsage.getUsed(label)\n             + \" clusterResources: \" + clusterResource\n-            + \" currentCapacity \"\n+            + \" currentUsedCapacity \"\n             + Resources.divide(resourceCalculator, clusterResource,\n                 queueUsage.getUsed(label),\n                 labelManager.getResourceByLabel(label, clusterResource))\n-            + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n-            + \" max-capacity: \" + queueCapacities.getAbsoluteMaximumCapacity()\n+            + \" max-capacity: \"\n+            + queueCapacities.getAbsoluteMaximumCapacity(label)\n             + \")\");\n       }\n+      return true;\n     }\n     \n-    return canAssign;\n+    // Actually, this will not happen, since labelCanAccess will be always\n+    // non-empty\n+    return false;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n      Set\u003cString\u003e nodeLabels, ResourceLimits currentResourceLimits,\n      Resource nowRequired, Resource resourceCouldBeUnreserved) {\n    // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n    Set\u003cString\u003e labelCanAccess;\n    if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n      labelCanAccess \u003d new HashSet\u003cString\u003e();\n      // Any queue can always access any node without label\n      labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n    } else {\n      labelCanAccess \u003d new HashSet\u003cString\u003e(\n          accessibleLabels.contains(CommonNodeLabelsManager.ANY) ? nodeLabels\n              : Sets.intersection(accessibleLabels, nodeLabels));\n    }\n    \n    for (String label : labelCanAccess) {\n      // New total resource \u003d used + required\n      Resource newTotalResource \u003d\n          Resources.add(queueUsage.getUsed(label), nowRequired);\n\n      Resource currentLimitResource \u003d\n          getCurrentLimitResource(label, clusterResource, currentResourceLimits);\n\n      // if reservation continous looking enabled, check to see if could we\n      // potentially use this node instead of a reserved node if the application\n      // has reserved containers.\n      // TODO, now only consider reservation cases when the node has no label\n      if (this.reservationsContinueLooking\n          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)\n          \u0026\u0026 Resources.greaterThan(resourceCalculator, clusterResource,\n              resourceCouldBeUnreserved, Resources.none())) {\n        // resource-without-reserved \u003d used - reserved\n        Resource newTotalWithoutReservedResource \u003d\n            Resources.subtract(newTotalResource, resourceCouldBeUnreserved);\n        \n        // when total-used-without-reserved-resource \u003c currentLimit, we still\n        // have chance to allocate on this node by unreserving some containers\n        if (Resources.lessThan(resourceCalculator, clusterResource,\n            newTotalWithoutReservedResource, currentLimitResource)) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \" + getQueueName()\n                + \" usedResources: \" + queueUsage.getUsed()\n                + \", clusterResources: \" + clusterResource\n                + \", reservedResources: \" + resourceCouldBeUnreserved\n                + \", capacity-without-reserved: \"\n                + newTotalWithoutReservedResource + \", maxLimitCapacity: \"\n                + currentLimitResource); \n          }\n          return true;\n        }\n      }\n      \n      // Otherwise, if any of the label of this node beyond queue limit, we\n      // cannot allocate on this node. Consider a small epsilon here.\n      if (Resources.greaterThan(resourceCalculator, clusterResource,\n          newTotalResource, currentLimitResource)) {\n        return false;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \"Check assign to queue, label\u003d\" + label\n            + \" usedResources: \" + queueUsage.getUsed(label)\n            + \" clusterResources: \" + clusterResource\n            + \" currentUsedCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n                queueUsage.getUsed(label),\n                labelManager.getResourceByLabel(label, clusterResource))\n            + \" max-capacity: \"\n            + queueCapacities.getAbsoluteMaximumCapacity(label)\n            + \")\");\n      }\n      return true;\n    }\n    \n    // Actually, this will not happen, since labelCanAccess will be always\n    // non-empty\n    return false;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java",
          "extendedDetails": {
            "oldValue": "[clusterResource-Resource, required-Resource, nodeLabels-Set\u003cString\u003e, application-FiCaSchedulerApp, checkReservations-boolean]",
            "newValue": "[clusterResource-Resource, nodeLabels-Set\u003cString\u003e, currentResourceLimits-ResourceLimits, nowRequired-Resource, resourceCouldBeUnreserved-Resource]"
          }
        }
      ]
    },
    "18a594257e052e8f10a03e5594e6cc6901dc56be": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3124. Fixed CS LeafQueue/ParentQueue to use QueueCapacities to track capacities-by-label. Contributed by Wangda Tan\n",
      "commitDate": "12/02/15 2:58 PM",
      "commitName": "18a594257e052e8f10a03e5594e6cc6901dc56be",
      "commitAuthor": "Jian He",
      "commitDateOld": "09/02/15 8:34 PM",
      "commitNameOld": "23bf6c72071782e3fd5a628e21495d6b974c7a9e",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 2.77,
      "commitsBetweenForRepo": 56,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,79 +1,83 @@\n   synchronized boolean canAssignToThisQueue(Resource clusterResource,\n       Resource required, Set\u003cString\u003e nodeLabels, FiCaSchedulerApp application, \n       boolean checkReservations) {\n     // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n     Set\u003cString\u003e labelCanAccess;\n     if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n       labelCanAccess \u003d new HashSet\u003cString\u003e();\n       // Any queue can always access any node without label\n       labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n     } else {\n       labelCanAccess \u003d new HashSet\u003cString\u003e(Sets.intersection(accessibleLabels, nodeLabels));\n     }\n     \n     boolean canAssign \u003d true;\n     for (String label : labelCanAccess) {\n       Resource potentialTotalCapacity \u003d\n           Resources.add(queueUsage.getUsed(label), required);\n       \n       float potentialNewCapacity \u003d\n           Resources.divide(resourceCalculator, clusterResource,\n               potentialTotalCapacity,\n               labelManager.getResourceByLabel(label, clusterResource));\n       // if enabled, check to see if could we potentially use this node instead\n       // of a reserved node if the application has reserved containers\n       // TODO, now only consider reservation cases when the node has no label\n       if (this.reservationsContinueLooking \u0026\u0026 checkReservations\n           \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)) {\n         float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n             resourceCalculator,\n             clusterResource,\n             Resources.subtract(potentialTotalCapacity,\n                application.getCurrentReservation()),\n             labelManager.getResourceByLabel(label, clusterResource));\n \n-        if (potentialNewWithoutReservedCapacity \u003c\u003d absoluteMaxCapacity) {\n+        if (potentialNewWithoutReservedCapacity \u003c\u003d queueCapacities\n+            .getAbsoluteMaximumCapacity()) {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"try to use reserved: \"\n                 + getQueueName()\n                 + \" usedResources: \"\n                 + queueUsage.getUsed()\n                 + \" clusterResources: \"\n                 + clusterResource\n                 + \" reservedResources: \"\n                 + application.getCurrentReservation()\n                 + \" currentCapacity \"\n                 + Resources.divide(resourceCalculator, clusterResource,\n                     queueUsage.getUsed(), clusterResource) + \" required \" + required\n                 + \" potentialNewWithoutReservedCapacity: \"\n-                + potentialNewWithoutReservedCapacity + \" ( \" + \" max-capacity: \"\n-                + absoluteMaxCapacity + \")\");\n+                + potentialNewWithoutReservedCapacity + \" ( \"\n+                + \" max-capacity: \"\n+                + queueCapacities.getAbsoluteMaximumCapacity() + \")\");\n           }\n           // we could potentially use this node instead of reserved node\n           return true;\n         }\n       }\n       \n       // Otherwise, if any of the label of this node beyond queue limit, we\n       // cannot allocate on this node. Consider a small epsilon here.\n-      if (potentialNewCapacity \u003e getAbsoluteMaximumCapacityByNodeLabel(label) + 1e-4) {\n+      if (potentialNewCapacity \u003e queueCapacities\n+          .getAbsoluteMaximumCapacity(label) + 1e-4) {\n         canAssign \u003d false;\n         break;\n       }\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(getQueueName()\n             + \"Check assign to queue, label\u003d\" + label\n             + \" usedResources: \" + queueUsage.getUsed(label)\n             + \" clusterResources: \" + clusterResource\n             + \" currentCapacity \"\n             + Resources.divide(resourceCalculator, clusterResource,\n                 queueUsage.getUsed(label),\n                 labelManager.getResourceByLabel(label, clusterResource))\n             + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n-            + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n+            + \" max-capacity: \" + queueCapacities.getAbsoluteMaximumCapacity()\n+            + \")\");\n       }\n     }\n     \n     return canAssign;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n      Resource required, Set\u003cString\u003e nodeLabels, FiCaSchedulerApp application, \n      boolean checkReservations) {\n    // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n    Set\u003cString\u003e labelCanAccess;\n    if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n      labelCanAccess \u003d new HashSet\u003cString\u003e();\n      // Any queue can always access any node without label\n      labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n    } else {\n      labelCanAccess \u003d new HashSet\u003cString\u003e(Sets.intersection(accessibleLabels, nodeLabels));\n    }\n    \n    boolean canAssign \u003d true;\n    for (String label : labelCanAccess) {\n      Resource potentialTotalCapacity \u003d\n          Resources.add(queueUsage.getUsed(label), required);\n      \n      float potentialNewCapacity \u003d\n          Resources.divide(resourceCalculator, clusterResource,\n              potentialTotalCapacity,\n              labelManager.getResourceByLabel(label, clusterResource));\n      // if enabled, check to see if could we potentially use this node instead\n      // of a reserved node if the application has reserved containers\n      // TODO, now only consider reservation cases when the node has no label\n      if (this.reservationsContinueLooking \u0026\u0026 checkReservations\n          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)) {\n        float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n            resourceCalculator,\n            clusterResource,\n            Resources.subtract(potentialTotalCapacity,\n               application.getCurrentReservation()),\n            labelManager.getResourceByLabel(label, clusterResource));\n\n        if (potentialNewWithoutReservedCapacity \u003c\u003d queueCapacities\n            .getAbsoluteMaximumCapacity()) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \"\n                + getQueueName()\n                + \" usedResources: \"\n                + queueUsage.getUsed()\n                + \" clusterResources: \"\n                + clusterResource\n                + \" reservedResources: \"\n                + application.getCurrentReservation()\n                + \" currentCapacity \"\n                + Resources.divide(resourceCalculator, clusterResource,\n                    queueUsage.getUsed(), clusterResource) + \" required \" + required\n                + \" potentialNewWithoutReservedCapacity: \"\n                + potentialNewWithoutReservedCapacity + \" ( \"\n                + \" max-capacity: \"\n                + queueCapacities.getAbsoluteMaximumCapacity() + \")\");\n          }\n          // we could potentially use this node instead of reserved node\n          return true;\n        }\n      }\n      \n      // Otherwise, if any of the label of this node beyond queue limit, we\n      // cannot allocate on this node. Consider a small epsilon here.\n      if (potentialNewCapacity \u003e queueCapacities\n          .getAbsoluteMaximumCapacity(label) + 1e-4) {\n        canAssign \u003d false;\n        break;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \"Check assign to queue, label\u003d\" + label\n            + \" usedResources: \" + queueUsage.getUsed(label)\n            + \" clusterResources: \" + clusterResource\n            + \" currentCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n                queueUsage.getUsed(label),\n                labelManager.getResourceByLabel(label, clusterResource))\n            + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n            + \" max-capacity: \" + queueCapacities.getAbsoluteMaximumCapacity()\n            + \")\");\n      }\n    }\n    \n    return canAssign;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
      "extendedDetails": {}
    },
    "86358221fc85a7743052a0b4c1647353508bf308": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3099. Capacity Scheduler LeafQueue/ParentQueue should use ResourceUsage to track used-resources-by-label. Contributed by Wangda Tan\n",
      "commitDate": "30/01/15 3:15 PM",
      "commitName": "86358221fc85a7743052a0b4c1647353508bf308",
      "commitAuthor": "Jian He",
      "commitDateOld": "27/01/15 3:36 PM",
      "commitNameOld": "18741adf97f4fda5f8743318b59c440928e51297",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 2.99,
      "commitsBetweenForRepo": 25,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,79 @@\n   synchronized boolean canAssignToThisQueue(Resource clusterResource,\n       Resource required, Set\u003cString\u003e nodeLabels, FiCaSchedulerApp application, \n       boolean checkReservations) {\n     // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n     Set\u003cString\u003e labelCanAccess;\n     if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n       labelCanAccess \u003d new HashSet\u003cString\u003e();\n       // Any queue can always access any node without label\n       labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n     } else {\n       labelCanAccess \u003d new HashSet\u003cString\u003e(Sets.intersection(accessibleLabels, nodeLabels));\n     }\n     \n     boolean canAssign \u003d true;\n     for (String label : labelCanAccess) {\n-      if (!usedResourcesByNodeLabels.containsKey(label)) {\n-        usedResourcesByNodeLabels.put(label, Resources.createResource(0));\n-      }\n-      \n       Resource potentialTotalCapacity \u003d\n-          Resources.add(usedResourcesByNodeLabels.get(label), required);\n+          Resources.add(queueUsage.getUsed(label), required);\n       \n       float potentialNewCapacity \u003d\n           Resources.divide(resourceCalculator, clusterResource,\n               potentialTotalCapacity,\n               labelManager.getResourceByLabel(label, clusterResource));\n       // if enabled, check to see if could we potentially use this node instead\n       // of a reserved node if the application has reserved containers\n       // TODO, now only consider reservation cases when the node has no label\n       if (this.reservationsContinueLooking \u0026\u0026 checkReservations\n           \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)) {\n         float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n             resourceCalculator,\n             clusterResource,\n             Resources.subtract(potentialTotalCapacity,\n                application.getCurrentReservation()),\n             labelManager.getResourceByLabel(label, clusterResource));\n \n         if (potentialNewWithoutReservedCapacity \u003c\u003d absoluteMaxCapacity) {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"try to use reserved: \"\n                 + getQueueName()\n                 + \" usedResources: \"\n-                + usedResources\n+                + queueUsage.getUsed()\n                 + \" clusterResources: \"\n                 + clusterResource\n                 + \" reservedResources: \"\n                 + application.getCurrentReservation()\n                 + \" currentCapacity \"\n                 + Resources.divide(resourceCalculator, clusterResource,\n-                    usedResources, clusterResource) + \" required \" + required\n+                    queueUsage.getUsed(), clusterResource) + \" required \" + required\n                 + \" potentialNewWithoutReservedCapacity: \"\n                 + potentialNewWithoutReservedCapacity + \" ( \" + \" max-capacity: \"\n                 + absoluteMaxCapacity + \")\");\n           }\n           // we could potentially use this node instead of reserved node\n           return true;\n         }\n       }\n       \n       // Otherwise, if any of the label of this node beyond queue limit, we\n       // cannot allocate on this node. Consider a small epsilon here.\n       if (potentialNewCapacity \u003e getAbsoluteMaximumCapacityByNodeLabel(label) + 1e-4) {\n         canAssign \u003d false;\n         break;\n       }\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(getQueueName()\n             + \"Check assign to queue, label\u003d\" + label\n-            + \" usedResources: \" + usedResourcesByNodeLabels.get(label)\n+            + \" usedResources: \" + queueUsage.getUsed(label)\n             + \" clusterResources: \" + clusterResource\n             + \" currentCapacity \"\n             + Resources.divide(resourceCalculator, clusterResource,\n-                usedResourcesByNodeLabels.get(label),\n+                queueUsage.getUsed(label),\n                 labelManager.getResourceByLabel(label, clusterResource))\n             + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n             + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n       }\n     }\n     \n     return canAssign;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n      Resource required, Set\u003cString\u003e nodeLabels, FiCaSchedulerApp application, \n      boolean checkReservations) {\n    // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n    Set\u003cString\u003e labelCanAccess;\n    if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n      labelCanAccess \u003d new HashSet\u003cString\u003e();\n      // Any queue can always access any node without label\n      labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n    } else {\n      labelCanAccess \u003d new HashSet\u003cString\u003e(Sets.intersection(accessibleLabels, nodeLabels));\n    }\n    \n    boolean canAssign \u003d true;\n    for (String label : labelCanAccess) {\n      Resource potentialTotalCapacity \u003d\n          Resources.add(queueUsage.getUsed(label), required);\n      \n      float potentialNewCapacity \u003d\n          Resources.divide(resourceCalculator, clusterResource,\n              potentialTotalCapacity,\n              labelManager.getResourceByLabel(label, clusterResource));\n      // if enabled, check to see if could we potentially use this node instead\n      // of a reserved node if the application has reserved containers\n      // TODO, now only consider reservation cases when the node has no label\n      if (this.reservationsContinueLooking \u0026\u0026 checkReservations\n          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)) {\n        float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n            resourceCalculator,\n            clusterResource,\n            Resources.subtract(potentialTotalCapacity,\n               application.getCurrentReservation()),\n            labelManager.getResourceByLabel(label, clusterResource));\n\n        if (potentialNewWithoutReservedCapacity \u003c\u003d absoluteMaxCapacity) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \"\n                + getQueueName()\n                + \" usedResources: \"\n                + queueUsage.getUsed()\n                + \" clusterResources: \"\n                + clusterResource\n                + \" reservedResources: \"\n                + application.getCurrentReservation()\n                + \" currentCapacity \"\n                + Resources.divide(resourceCalculator, clusterResource,\n                    queueUsage.getUsed(), clusterResource) + \" required \" + required\n                + \" potentialNewWithoutReservedCapacity: \"\n                + potentialNewWithoutReservedCapacity + \" ( \" + \" max-capacity: \"\n                + absoluteMaxCapacity + \")\");\n          }\n          // we could potentially use this node instead of reserved node\n          return true;\n        }\n      }\n      \n      // Otherwise, if any of the label of this node beyond queue limit, we\n      // cannot allocate on this node. Consider a small epsilon here.\n      if (potentialNewCapacity \u003e getAbsoluteMaximumCapacityByNodeLabel(label) + 1e-4) {\n        canAssign \u003d false;\n        break;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \"Check assign to queue, label\u003d\" + label\n            + \" usedResources: \" + queueUsage.getUsed(label)\n            + \" clusterResources: \" + clusterResource\n            + \" currentCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n                queueUsage.getUsed(label),\n                labelManager.getResourceByLabel(label, clusterResource))\n            + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n            + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n      }\n    }\n    \n    return canAssign;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
      "extendedDetails": {}
    },
    "f2ea555ac6c06a3f2f6559731f48711fff05d3f1": {
      "type": "Ymultichange(Yrename,Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "YARN-2496. Enhanced Capacity Scheduler to have basic support for allocating resources based on node-labels. Contributed by Wangda Tan.\nYARN-2500. Ehnaced ResourceManager to support schedulers allocating resources based on node-labels. Contributed by Wangda Tan.\n",
      "commitDate": "15/10/14 6:33 PM",
      "commitName": "f2ea555ac6c06a3f2f6559731f48711fff05d3f1",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "YARN-2496. Enhanced Capacity Scheduler to have basic support for allocating resources based on node-labels. Contributed by Wangda Tan.\nYARN-2500. Ehnaced ResourceManager to support schedulers allocating resources based on node-labels. Contributed by Wangda Tan.\n",
          "commitDate": "15/10/14 6:33 PM",
          "commitName": "f2ea555ac6c06a3f2f6559731f48711fff05d3f1",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "07/10/14 1:45 PM",
          "commitNameOld": "30d56fdbb40d06c4e267d6c314c8c767a7adc6a3",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 8.2,
          "commitsBetweenForRepo": 71,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,56 +1,83 @@\n-  protected synchronized boolean assignToQueue(Resource clusterResource, \n-      Resource required, FiCaSchedulerApp application, \n+  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n+      Resource required, Set\u003cString\u003e nodeLabels, FiCaSchedulerApp application, \n       boolean checkReservations) {\n-\n-    Resource potentialTotalResource \u003d Resources.add(usedResources, required);\n-    // Check how of the cluster\u0027s absolute capacity we are currently using...\n-    float potentialNewCapacity \u003d Resources.divide(resourceCalculator,\n-        clusterResource, potentialTotalResource, clusterResource);\n-    if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n+    // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n+    Set\u003cString\u003e labelCanAccess;\n+    if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n+      labelCanAccess \u003d new HashSet\u003cString\u003e();\n+      // Any queue can always access any node without label\n+      labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n+    } else {\n+      labelCanAccess \u003d new HashSet\u003cString\u003e(Sets.intersection(accessibleLabels, nodeLabels));\n+    }\n+    \n+    boolean canAssign \u003d true;\n+    for (String label : labelCanAccess) {\n+      if (!usedResourcesByNodeLabels.containsKey(label)) {\n+        usedResourcesByNodeLabels.put(label, Resources.createResource(0));\n+      }\n+      \n+      Resource potentialTotalCapacity \u003d\n+          Resources.add(usedResourcesByNodeLabels.get(label), required);\n+      \n+      float potentialNewCapacity \u003d\n+          Resources.divide(resourceCalculator, clusterResource,\n+              potentialTotalCapacity,\n+              labelManager.getResourceByLabel(label, clusterResource));\n       // if enabled, check to see if could we potentially use this node instead\n       // of a reserved node if the application has reserved containers\n-      if (this.reservationsContinueLooking \u0026\u0026 checkReservations) {\n-\n+      // TODO, now only consider reservation cases when the node has no label\n+      if (this.reservationsContinueLooking \u0026\u0026 checkReservations\n+          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)) {\n         float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n             resourceCalculator,\n             clusterResource,\n-            Resources.subtract(potentialTotalResource,\n-                application.getCurrentReservation()),\n-             clusterResource);\n+            Resources.subtract(potentialTotalCapacity,\n+               application.getCurrentReservation()),\n+            labelManager.getResourceByLabel(label, clusterResource));\n \n         if (potentialNewWithoutReservedCapacity \u003c\u003d absoluteMaxCapacity) {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"try to use reserved: \"\n                 + getQueueName()\n                 + \" usedResources: \"\n                 + usedResources\n                 + \" clusterResources: \"\n                 + clusterResource\n                 + \" reservedResources: \"\n                 + application.getCurrentReservation()\n                 + \" currentCapacity \"\n                 + Resources.divide(resourceCalculator, clusterResource,\n                     usedResources, clusterResource) + \" required \" + required\n                 + \" potentialNewWithoutReservedCapacity: \"\n                 + potentialNewWithoutReservedCapacity + \" ( \" + \" max-capacity: \"\n                 + absoluteMaxCapacity + \")\");\n           }\n           // we could potentially use this node instead of reserved node\n           return true;\n         }\n-\n       }\n+      \n+      // Otherwise, if any of the label of this node beyond queue limit, we\n+      // cannot allocate on this node. Consider a small epsilon here.\n+      if (potentialNewCapacity \u003e getAbsoluteMaximumCapacityByNodeLabel(label) + 1e-4) {\n+        canAssign \u003d false;\n+        break;\n+      }\n+\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(getQueueName()\n-            + \" usedResources: \" + usedResources\n+            + \"Check assign to queue, label\u003d\" + label\n+            + \" usedResources: \" + usedResourcesByNodeLabels.get(label)\n             + \" clusterResources: \" + clusterResource\n             + \" currentCapacity \"\n             + Resources.divide(resourceCalculator, clusterResource,\n-              usedResources, clusterResource) + \" required \" + required\n+                usedResourcesByNodeLabels.get(label),\n+                labelManager.getResourceByLabel(label, clusterResource))\n             + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n             + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n       }\n-      return false;\n     }\n-    return true;\n+    \n+    return canAssign;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n      Resource required, Set\u003cString\u003e nodeLabels, FiCaSchedulerApp application, \n      boolean checkReservations) {\n    // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n    Set\u003cString\u003e labelCanAccess;\n    if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n      labelCanAccess \u003d new HashSet\u003cString\u003e();\n      // Any queue can always access any node without label\n      labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n    } else {\n      labelCanAccess \u003d new HashSet\u003cString\u003e(Sets.intersection(accessibleLabels, nodeLabels));\n    }\n    \n    boolean canAssign \u003d true;\n    for (String label : labelCanAccess) {\n      if (!usedResourcesByNodeLabels.containsKey(label)) {\n        usedResourcesByNodeLabels.put(label, Resources.createResource(0));\n      }\n      \n      Resource potentialTotalCapacity \u003d\n          Resources.add(usedResourcesByNodeLabels.get(label), required);\n      \n      float potentialNewCapacity \u003d\n          Resources.divide(resourceCalculator, clusterResource,\n              potentialTotalCapacity,\n              labelManager.getResourceByLabel(label, clusterResource));\n      // if enabled, check to see if could we potentially use this node instead\n      // of a reserved node if the application has reserved containers\n      // TODO, now only consider reservation cases when the node has no label\n      if (this.reservationsContinueLooking \u0026\u0026 checkReservations\n          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)) {\n        float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n            resourceCalculator,\n            clusterResource,\n            Resources.subtract(potentialTotalCapacity,\n               application.getCurrentReservation()),\n            labelManager.getResourceByLabel(label, clusterResource));\n\n        if (potentialNewWithoutReservedCapacity \u003c\u003d absoluteMaxCapacity) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \"\n                + getQueueName()\n                + \" usedResources: \"\n                + usedResources\n                + \" clusterResources: \"\n                + clusterResource\n                + \" reservedResources: \"\n                + application.getCurrentReservation()\n                + \" currentCapacity \"\n                + Resources.divide(resourceCalculator, clusterResource,\n                    usedResources, clusterResource) + \" required \" + required\n                + \" potentialNewWithoutReservedCapacity: \"\n                + potentialNewWithoutReservedCapacity + \" ( \" + \" max-capacity: \"\n                + absoluteMaxCapacity + \")\");\n          }\n          // we could potentially use this node instead of reserved node\n          return true;\n        }\n      }\n      \n      // Otherwise, if any of the label of this node beyond queue limit, we\n      // cannot allocate on this node. Consider a small epsilon here.\n      if (potentialNewCapacity \u003e getAbsoluteMaximumCapacityByNodeLabel(label) + 1e-4) {\n        canAssign \u003d false;\n        break;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \"Check assign to queue, label\u003d\" + label\n            + \" usedResources: \" + usedResourcesByNodeLabels.get(label)\n            + \" clusterResources: \" + clusterResource\n            + \" currentCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n                usedResourcesByNodeLabels.get(label),\n                labelManager.getResourceByLabel(label, clusterResource))\n            + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n            + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n      }\n    }\n    \n    return canAssign;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
          "extendedDetails": {
            "oldValue": "assignToQueue",
            "newValue": "canAssignToThisQueue"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-2496. Enhanced Capacity Scheduler to have basic support for allocating resources based on node-labels. Contributed by Wangda Tan.\nYARN-2500. Ehnaced ResourceManager to support schedulers allocating resources based on node-labels. Contributed by Wangda Tan.\n",
          "commitDate": "15/10/14 6:33 PM",
          "commitName": "f2ea555ac6c06a3f2f6559731f48711fff05d3f1",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "07/10/14 1:45 PM",
          "commitNameOld": "30d56fdbb40d06c4e267d6c314c8c767a7adc6a3",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 8.2,
          "commitsBetweenForRepo": 71,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,56 +1,83 @@\n-  protected synchronized boolean assignToQueue(Resource clusterResource, \n-      Resource required, FiCaSchedulerApp application, \n+  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n+      Resource required, Set\u003cString\u003e nodeLabels, FiCaSchedulerApp application, \n       boolean checkReservations) {\n-\n-    Resource potentialTotalResource \u003d Resources.add(usedResources, required);\n-    // Check how of the cluster\u0027s absolute capacity we are currently using...\n-    float potentialNewCapacity \u003d Resources.divide(resourceCalculator,\n-        clusterResource, potentialTotalResource, clusterResource);\n-    if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n+    // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n+    Set\u003cString\u003e labelCanAccess;\n+    if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n+      labelCanAccess \u003d new HashSet\u003cString\u003e();\n+      // Any queue can always access any node without label\n+      labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n+    } else {\n+      labelCanAccess \u003d new HashSet\u003cString\u003e(Sets.intersection(accessibleLabels, nodeLabels));\n+    }\n+    \n+    boolean canAssign \u003d true;\n+    for (String label : labelCanAccess) {\n+      if (!usedResourcesByNodeLabels.containsKey(label)) {\n+        usedResourcesByNodeLabels.put(label, Resources.createResource(0));\n+      }\n+      \n+      Resource potentialTotalCapacity \u003d\n+          Resources.add(usedResourcesByNodeLabels.get(label), required);\n+      \n+      float potentialNewCapacity \u003d\n+          Resources.divide(resourceCalculator, clusterResource,\n+              potentialTotalCapacity,\n+              labelManager.getResourceByLabel(label, clusterResource));\n       // if enabled, check to see if could we potentially use this node instead\n       // of a reserved node if the application has reserved containers\n-      if (this.reservationsContinueLooking \u0026\u0026 checkReservations) {\n-\n+      // TODO, now only consider reservation cases when the node has no label\n+      if (this.reservationsContinueLooking \u0026\u0026 checkReservations\n+          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)) {\n         float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n             resourceCalculator,\n             clusterResource,\n-            Resources.subtract(potentialTotalResource,\n-                application.getCurrentReservation()),\n-             clusterResource);\n+            Resources.subtract(potentialTotalCapacity,\n+               application.getCurrentReservation()),\n+            labelManager.getResourceByLabel(label, clusterResource));\n \n         if (potentialNewWithoutReservedCapacity \u003c\u003d absoluteMaxCapacity) {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"try to use reserved: \"\n                 + getQueueName()\n                 + \" usedResources: \"\n                 + usedResources\n                 + \" clusterResources: \"\n                 + clusterResource\n                 + \" reservedResources: \"\n                 + application.getCurrentReservation()\n                 + \" currentCapacity \"\n                 + Resources.divide(resourceCalculator, clusterResource,\n                     usedResources, clusterResource) + \" required \" + required\n                 + \" potentialNewWithoutReservedCapacity: \"\n                 + potentialNewWithoutReservedCapacity + \" ( \" + \" max-capacity: \"\n                 + absoluteMaxCapacity + \")\");\n           }\n           // we could potentially use this node instead of reserved node\n           return true;\n         }\n-\n       }\n+      \n+      // Otherwise, if any of the label of this node beyond queue limit, we\n+      // cannot allocate on this node. Consider a small epsilon here.\n+      if (potentialNewCapacity \u003e getAbsoluteMaximumCapacityByNodeLabel(label) + 1e-4) {\n+        canAssign \u003d false;\n+        break;\n+      }\n+\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(getQueueName()\n-            + \" usedResources: \" + usedResources\n+            + \"Check assign to queue, label\u003d\" + label\n+            + \" usedResources: \" + usedResourcesByNodeLabels.get(label)\n             + \" clusterResources: \" + clusterResource\n             + \" currentCapacity \"\n             + Resources.divide(resourceCalculator, clusterResource,\n-              usedResources, clusterResource) + \" required \" + required\n+                usedResourcesByNodeLabels.get(label),\n+                labelManager.getResourceByLabel(label, clusterResource))\n             + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n             + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n       }\n-      return false;\n     }\n-    return true;\n+    \n+    return canAssign;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n      Resource required, Set\u003cString\u003e nodeLabels, FiCaSchedulerApp application, \n      boolean checkReservations) {\n    // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n    Set\u003cString\u003e labelCanAccess;\n    if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n      labelCanAccess \u003d new HashSet\u003cString\u003e();\n      // Any queue can always access any node without label\n      labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n    } else {\n      labelCanAccess \u003d new HashSet\u003cString\u003e(Sets.intersection(accessibleLabels, nodeLabels));\n    }\n    \n    boolean canAssign \u003d true;\n    for (String label : labelCanAccess) {\n      if (!usedResourcesByNodeLabels.containsKey(label)) {\n        usedResourcesByNodeLabels.put(label, Resources.createResource(0));\n      }\n      \n      Resource potentialTotalCapacity \u003d\n          Resources.add(usedResourcesByNodeLabels.get(label), required);\n      \n      float potentialNewCapacity \u003d\n          Resources.divide(resourceCalculator, clusterResource,\n              potentialTotalCapacity,\n              labelManager.getResourceByLabel(label, clusterResource));\n      // if enabled, check to see if could we potentially use this node instead\n      // of a reserved node if the application has reserved containers\n      // TODO, now only consider reservation cases when the node has no label\n      if (this.reservationsContinueLooking \u0026\u0026 checkReservations\n          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)) {\n        float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n            resourceCalculator,\n            clusterResource,\n            Resources.subtract(potentialTotalCapacity,\n               application.getCurrentReservation()),\n            labelManager.getResourceByLabel(label, clusterResource));\n\n        if (potentialNewWithoutReservedCapacity \u003c\u003d absoluteMaxCapacity) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \"\n                + getQueueName()\n                + \" usedResources: \"\n                + usedResources\n                + \" clusterResources: \"\n                + clusterResource\n                + \" reservedResources: \"\n                + application.getCurrentReservation()\n                + \" currentCapacity \"\n                + Resources.divide(resourceCalculator, clusterResource,\n                    usedResources, clusterResource) + \" required \" + required\n                + \" potentialNewWithoutReservedCapacity: \"\n                + potentialNewWithoutReservedCapacity + \" ( \" + \" max-capacity: \"\n                + absoluteMaxCapacity + \")\");\n          }\n          // we could potentially use this node instead of reserved node\n          return true;\n        }\n      }\n      \n      // Otherwise, if any of the label of this node beyond queue limit, we\n      // cannot allocate on this node. Consider a small epsilon here.\n      if (potentialNewCapacity \u003e getAbsoluteMaximumCapacityByNodeLabel(label) + 1e-4) {\n        canAssign \u003d false;\n        break;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \"Check assign to queue, label\u003d\" + label\n            + \" usedResources: \" + usedResourcesByNodeLabels.get(label)\n            + \" clusterResources: \" + clusterResource\n            + \" currentCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n                usedResourcesByNodeLabels.get(label),\n                labelManager.getResourceByLabel(label, clusterResource))\n            + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n            + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n      }\n    }\n    \n    return canAssign;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
          "extendedDetails": {
            "oldValue": "[clusterResource-Resource, required-Resource, application-FiCaSchedulerApp, checkReservations-boolean]",
            "newValue": "[clusterResource-Resource, required-Resource, nodeLabels-Set\u003cString\u003e, application-FiCaSchedulerApp, checkReservations-boolean]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-2496. Enhanced Capacity Scheduler to have basic support for allocating resources based on node-labels. Contributed by Wangda Tan.\nYARN-2500. Ehnaced ResourceManager to support schedulers allocating resources based on node-labels. Contributed by Wangda Tan.\n",
          "commitDate": "15/10/14 6:33 PM",
          "commitName": "f2ea555ac6c06a3f2f6559731f48711fff05d3f1",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "07/10/14 1:45 PM",
          "commitNameOld": "30d56fdbb40d06c4e267d6c314c8c767a7adc6a3",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 8.2,
          "commitsBetweenForRepo": 71,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,56 +1,83 @@\n-  protected synchronized boolean assignToQueue(Resource clusterResource, \n-      Resource required, FiCaSchedulerApp application, \n+  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n+      Resource required, Set\u003cString\u003e nodeLabels, FiCaSchedulerApp application, \n       boolean checkReservations) {\n-\n-    Resource potentialTotalResource \u003d Resources.add(usedResources, required);\n-    // Check how of the cluster\u0027s absolute capacity we are currently using...\n-    float potentialNewCapacity \u003d Resources.divide(resourceCalculator,\n-        clusterResource, potentialTotalResource, clusterResource);\n-    if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n+    // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n+    Set\u003cString\u003e labelCanAccess;\n+    if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n+      labelCanAccess \u003d new HashSet\u003cString\u003e();\n+      // Any queue can always access any node without label\n+      labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n+    } else {\n+      labelCanAccess \u003d new HashSet\u003cString\u003e(Sets.intersection(accessibleLabels, nodeLabels));\n+    }\n+    \n+    boolean canAssign \u003d true;\n+    for (String label : labelCanAccess) {\n+      if (!usedResourcesByNodeLabels.containsKey(label)) {\n+        usedResourcesByNodeLabels.put(label, Resources.createResource(0));\n+      }\n+      \n+      Resource potentialTotalCapacity \u003d\n+          Resources.add(usedResourcesByNodeLabels.get(label), required);\n+      \n+      float potentialNewCapacity \u003d\n+          Resources.divide(resourceCalculator, clusterResource,\n+              potentialTotalCapacity,\n+              labelManager.getResourceByLabel(label, clusterResource));\n       // if enabled, check to see if could we potentially use this node instead\n       // of a reserved node if the application has reserved containers\n-      if (this.reservationsContinueLooking \u0026\u0026 checkReservations) {\n-\n+      // TODO, now only consider reservation cases when the node has no label\n+      if (this.reservationsContinueLooking \u0026\u0026 checkReservations\n+          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)) {\n         float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n             resourceCalculator,\n             clusterResource,\n-            Resources.subtract(potentialTotalResource,\n-                application.getCurrentReservation()),\n-             clusterResource);\n+            Resources.subtract(potentialTotalCapacity,\n+               application.getCurrentReservation()),\n+            labelManager.getResourceByLabel(label, clusterResource));\n \n         if (potentialNewWithoutReservedCapacity \u003c\u003d absoluteMaxCapacity) {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"try to use reserved: \"\n                 + getQueueName()\n                 + \" usedResources: \"\n                 + usedResources\n                 + \" clusterResources: \"\n                 + clusterResource\n                 + \" reservedResources: \"\n                 + application.getCurrentReservation()\n                 + \" currentCapacity \"\n                 + Resources.divide(resourceCalculator, clusterResource,\n                     usedResources, clusterResource) + \" required \" + required\n                 + \" potentialNewWithoutReservedCapacity: \"\n                 + potentialNewWithoutReservedCapacity + \" ( \" + \" max-capacity: \"\n                 + absoluteMaxCapacity + \")\");\n           }\n           // we could potentially use this node instead of reserved node\n           return true;\n         }\n-\n       }\n+      \n+      // Otherwise, if any of the label of this node beyond queue limit, we\n+      // cannot allocate on this node. Consider a small epsilon here.\n+      if (potentialNewCapacity \u003e getAbsoluteMaximumCapacityByNodeLabel(label) + 1e-4) {\n+        canAssign \u003d false;\n+        break;\n+      }\n+\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(getQueueName()\n-            + \" usedResources: \" + usedResources\n+            + \"Check assign to queue, label\u003d\" + label\n+            + \" usedResources: \" + usedResourcesByNodeLabels.get(label)\n             + \" clusterResources: \" + clusterResource\n             + \" currentCapacity \"\n             + Resources.divide(resourceCalculator, clusterResource,\n-              usedResources, clusterResource) + \" required \" + required\n+                usedResourcesByNodeLabels.get(label),\n+                labelManager.getResourceByLabel(label, clusterResource))\n             + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n             + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n       }\n-      return false;\n     }\n-    return true;\n+    \n+    return canAssign;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n      Resource required, Set\u003cString\u003e nodeLabels, FiCaSchedulerApp application, \n      boolean checkReservations) {\n    // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n    Set\u003cString\u003e labelCanAccess;\n    if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n      labelCanAccess \u003d new HashSet\u003cString\u003e();\n      // Any queue can always access any node without label\n      labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n    } else {\n      labelCanAccess \u003d new HashSet\u003cString\u003e(Sets.intersection(accessibleLabels, nodeLabels));\n    }\n    \n    boolean canAssign \u003d true;\n    for (String label : labelCanAccess) {\n      if (!usedResourcesByNodeLabels.containsKey(label)) {\n        usedResourcesByNodeLabels.put(label, Resources.createResource(0));\n      }\n      \n      Resource potentialTotalCapacity \u003d\n          Resources.add(usedResourcesByNodeLabels.get(label), required);\n      \n      float potentialNewCapacity \u003d\n          Resources.divide(resourceCalculator, clusterResource,\n              potentialTotalCapacity,\n              labelManager.getResourceByLabel(label, clusterResource));\n      // if enabled, check to see if could we potentially use this node instead\n      // of a reserved node if the application has reserved containers\n      // TODO, now only consider reservation cases when the node has no label\n      if (this.reservationsContinueLooking \u0026\u0026 checkReservations\n          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)) {\n        float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n            resourceCalculator,\n            clusterResource,\n            Resources.subtract(potentialTotalCapacity,\n               application.getCurrentReservation()),\n            labelManager.getResourceByLabel(label, clusterResource));\n\n        if (potentialNewWithoutReservedCapacity \u003c\u003d absoluteMaxCapacity) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \"\n                + getQueueName()\n                + \" usedResources: \"\n                + usedResources\n                + \" clusterResources: \"\n                + clusterResource\n                + \" reservedResources: \"\n                + application.getCurrentReservation()\n                + \" currentCapacity \"\n                + Resources.divide(resourceCalculator, clusterResource,\n                    usedResources, clusterResource) + \" required \" + required\n                + \" potentialNewWithoutReservedCapacity: \"\n                + potentialNewWithoutReservedCapacity + \" ( \" + \" max-capacity: \"\n                + absoluteMaxCapacity + \")\");\n          }\n          // we could potentially use this node instead of reserved node\n          return true;\n        }\n      }\n      \n      // Otherwise, if any of the label of this node beyond queue limit, we\n      // cannot allocate on this node. Consider a small epsilon here.\n      if (potentialNewCapacity \u003e getAbsoluteMaximumCapacityByNodeLabel(label) + 1e-4) {\n        canAssign \u003d false;\n        break;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \"Check assign to queue, label\u003d\" + label\n            + \" usedResources: \" + usedResourcesByNodeLabels.get(label)\n            + \" clusterResources: \" + clusterResource\n            + \" currentCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n                usedResourcesByNodeLabels.get(label),\n                labelManager.getResourceByLabel(label, clusterResource))\n            + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n            + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n      }\n    }\n    \n    return canAssign;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
          "extendedDetails": {
            "oldValue": "[protected, synchronized]",
            "newValue": "[synchronized]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-2496. Enhanced Capacity Scheduler to have basic support for allocating resources based on node-labels. Contributed by Wangda Tan.\nYARN-2500. Ehnaced ResourceManager to support schedulers allocating resources based on node-labels. Contributed by Wangda Tan.\n",
          "commitDate": "15/10/14 6:33 PM",
          "commitName": "f2ea555ac6c06a3f2f6559731f48711fff05d3f1",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "07/10/14 1:45 PM",
          "commitNameOld": "30d56fdbb40d06c4e267d6c314c8c767a7adc6a3",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 8.2,
          "commitsBetweenForRepo": 71,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,56 +1,83 @@\n-  protected synchronized boolean assignToQueue(Resource clusterResource, \n-      Resource required, FiCaSchedulerApp application, \n+  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n+      Resource required, Set\u003cString\u003e nodeLabels, FiCaSchedulerApp application, \n       boolean checkReservations) {\n-\n-    Resource potentialTotalResource \u003d Resources.add(usedResources, required);\n-    // Check how of the cluster\u0027s absolute capacity we are currently using...\n-    float potentialNewCapacity \u003d Resources.divide(resourceCalculator,\n-        clusterResource, potentialTotalResource, clusterResource);\n-    if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n+    // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n+    Set\u003cString\u003e labelCanAccess;\n+    if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n+      labelCanAccess \u003d new HashSet\u003cString\u003e();\n+      // Any queue can always access any node without label\n+      labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n+    } else {\n+      labelCanAccess \u003d new HashSet\u003cString\u003e(Sets.intersection(accessibleLabels, nodeLabels));\n+    }\n+    \n+    boolean canAssign \u003d true;\n+    for (String label : labelCanAccess) {\n+      if (!usedResourcesByNodeLabels.containsKey(label)) {\n+        usedResourcesByNodeLabels.put(label, Resources.createResource(0));\n+      }\n+      \n+      Resource potentialTotalCapacity \u003d\n+          Resources.add(usedResourcesByNodeLabels.get(label), required);\n+      \n+      float potentialNewCapacity \u003d\n+          Resources.divide(resourceCalculator, clusterResource,\n+              potentialTotalCapacity,\n+              labelManager.getResourceByLabel(label, clusterResource));\n       // if enabled, check to see if could we potentially use this node instead\n       // of a reserved node if the application has reserved containers\n-      if (this.reservationsContinueLooking \u0026\u0026 checkReservations) {\n-\n+      // TODO, now only consider reservation cases when the node has no label\n+      if (this.reservationsContinueLooking \u0026\u0026 checkReservations\n+          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)) {\n         float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n             resourceCalculator,\n             clusterResource,\n-            Resources.subtract(potentialTotalResource,\n-                application.getCurrentReservation()),\n-             clusterResource);\n+            Resources.subtract(potentialTotalCapacity,\n+               application.getCurrentReservation()),\n+            labelManager.getResourceByLabel(label, clusterResource));\n \n         if (potentialNewWithoutReservedCapacity \u003c\u003d absoluteMaxCapacity) {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"try to use reserved: \"\n                 + getQueueName()\n                 + \" usedResources: \"\n                 + usedResources\n                 + \" clusterResources: \"\n                 + clusterResource\n                 + \" reservedResources: \"\n                 + application.getCurrentReservation()\n                 + \" currentCapacity \"\n                 + Resources.divide(resourceCalculator, clusterResource,\n                     usedResources, clusterResource) + \" required \" + required\n                 + \" potentialNewWithoutReservedCapacity: \"\n                 + potentialNewWithoutReservedCapacity + \" ( \" + \" max-capacity: \"\n                 + absoluteMaxCapacity + \")\");\n           }\n           // we could potentially use this node instead of reserved node\n           return true;\n         }\n-\n       }\n+      \n+      // Otherwise, if any of the label of this node beyond queue limit, we\n+      // cannot allocate on this node. Consider a small epsilon here.\n+      if (potentialNewCapacity \u003e getAbsoluteMaximumCapacityByNodeLabel(label) + 1e-4) {\n+        canAssign \u003d false;\n+        break;\n+      }\n+\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(getQueueName()\n-            + \" usedResources: \" + usedResources\n+            + \"Check assign to queue, label\u003d\" + label\n+            + \" usedResources: \" + usedResourcesByNodeLabels.get(label)\n             + \" clusterResources: \" + clusterResource\n             + \" currentCapacity \"\n             + Resources.divide(resourceCalculator, clusterResource,\n-              usedResources, clusterResource) + \" required \" + required\n+                usedResourcesByNodeLabels.get(label),\n+                labelManager.getResourceByLabel(label, clusterResource))\n             + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n             + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n       }\n-      return false;\n     }\n-    return true;\n+    \n+    return canAssign;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized boolean canAssignToThisQueue(Resource clusterResource,\n      Resource required, Set\u003cString\u003e nodeLabels, FiCaSchedulerApp application, \n      boolean checkReservations) {\n    // Get label of this queue can access, it\u0027s (nodeLabel AND queueLabel)\n    Set\u003cString\u003e labelCanAccess;\n    if (null \u003d\u003d nodeLabels || nodeLabels.isEmpty()) {\n      labelCanAccess \u003d new HashSet\u003cString\u003e();\n      // Any queue can always access any node without label\n      labelCanAccess.add(RMNodeLabelsManager.NO_LABEL);\n    } else {\n      labelCanAccess \u003d new HashSet\u003cString\u003e(Sets.intersection(accessibleLabels, nodeLabels));\n    }\n    \n    boolean canAssign \u003d true;\n    for (String label : labelCanAccess) {\n      if (!usedResourcesByNodeLabels.containsKey(label)) {\n        usedResourcesByNodeLabels.put(label, Resources.createResource(0));\n      }\n      \n      Resource potentialTotalCapacity \u003d\n          Resources.add(usedResourcesByNodeLabels.get(label), required);\n      \n      float potentialNewCapacity \u003d\n          Resources.divide(resourceCalculator, clusterResource,\n              potentialTotalCapacity,\n              labelManager.getResourceByLabel(label, clusterResource));\n      // if enabled, check to see if could we potentially use this node instead\n      // of a reserved node if the application has reserved containers\n      // TODO, now only consider reservation cases when the node has no label\n      if (this.reservationsContinueLooking \u0026\u0026 checkReservations\n          \u0026\u0026 label.equals(RMNodeLabelsManager.NO_LABEL)) {\n        float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n            resourceCalculator,\n            clusterResource,\n            Resources.subtract(potentialTotalCapacity,\n               application.getCurrentReservation()),\n            labelManager.getResourceByLabel(label, clusterResource));\n\n        if (potentialNewWithoutReservedCapacity \u003c\u003d absoluteMaxCapacity) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \"\n                + getQueueName()\n                + \" usedResources: \"\n                + usedResources\n                + \" clusterResources: \"\n                + clusterResource\n                + \" reservedResources: \"\n                + application.getCurrentReservation()\n                + \" currentCapacity \"\n                + Resources.divide(resourceCalculator, clusterResource,\n                    usedResources, clusterResource) + \" required \" + required\n                + \" potentialNewWithoutReservedCapacity: \"\n                + potentialNewWithoutReservedCapacity + \" ( \" + \" max-capacity: \"\n                + absoluteMaxCapacity + \")\");\n          }\n          // we could potentially use this node instead of reserved node\n          return true;\n        }\n      }\n      \n      // Otherwise, if any of the label of this node beyond queue limit, we\n      // cannot allocate on this node. Consider a small epsilon here.\n      if (potentialNewCapacity \u003e getAbsoluteMaximumCapacityByNodeLabel(label) + 1e-4) {\n        canAssign \u003d false;\n        break;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \"Check assign to queue, label\u003d\" + label\n            + \" usedResources: \" + usedResourcesByNodeLabels.get(label)\n            + \" clusterResources: \" + clusterResource\n            + \" currentCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n                usedResourcesByNodeLabels.get(label),\n                labelManager.getResourceByLabel(label, clusterResource))\n            + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n            + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n      }\n    }\n    \n    return canAssign;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
          "extendedDetails": {}
        }
      ]
    },
    "9c22065109a77681bc2534063eabe8692fbcb3cd": {
      "type": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "YARN-1769. CapacityScheduler: Improve reservations. Contributed by Thomas Graves\n",
      "commitDate": "29/09/14 7:12 AM",
      "commitName": "9c22065109a77681bc2534063eabe8692fbcb3cd",
      "commitAuthor": "Jason Lowe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-1769. CapacityScheduler: Improve reservations. Contributed by Thomas Graves\n",
          "commitDate": "29/09/14 7:12 AM",
          "commitName": "9c22065109a77681bc2534063eabe8692fbcb3cd",
          "commitAuthor": "Jason Lowe",
          "commitDateOld": "14/08/14 11:00 PM",
          "commitNameOld": "7360cec692be5dcc3377ae5082fe22870caac96b",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 45.34,
          "commitsBetweenForRepo": 409,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,56 @@\n-  private synchronized boolean assignToQueue(Resource clusterResource, \n-      Resource required) {\n+  protected synchronized boolean assignToQueue(Resource clusterResource, \n+      Resource required, FiCaSchedulerApp application, \n+      boolean checkReservations) {\n+\n+    Resource potentialTotalResource \u003d Resources.add(usedResources, required);\n     // Check how of the cluster\u0027s absolute capacity we are currently using...\n-    float potentialNewCapacity \u003d \n-        Resources.divide(\n-            resourceCalculator, clusterResource, \n-            Resources.add(usedResources, required), \n-            clusterResource);\n+    float potentialNewCapacity \u003d Resources.divide(resourceCalculator,\n+        clusterResource, potentialTotalResource, clusterResource);\n     if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n+      // if enabled, check to see if could we potentially use this node instead\n+      // of a reserved node if the application has reserved containers\n+      if (this.reservationsContinueLooking \u0026\u0026 checkReservations) {\n+\n+        float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n+            resourceCalculator,\n+            clusterResource,\n+            Resources.subtract(potentialTotalResource,\n+                application.getCurrentReservation()),\n+             clusterResource);\n+\n+        if (potentialNewWithoutReservedCapacity \u003c\u003d absoluteMaxCapacity) {\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"try to use reserved: \"\n+                + getQueueName()\n+                + \" usedResources: \"\n+                + usedResources\n+                + \" clusterResources: \"\n+                + clusterResource\n+                + \" reservedResources: \"\n+                + application.getCurrentReservation()\n+                + \" currentCapacity \"\n+                + Resources.divide(resourceCalculator, clusterResource,\n+                    usedResources, clusterResource) + \" required \" + required\n+                + \" potentialNewWithoutReservedCapacity: \"\n+                + potentialNewWithoutReservedCapacity + \" ( \" + \" max-capacity: \"\n+                + absoluteMaxCapacity + \")\");\n+          }\n+          // we could potentially use this node instead of reserved node\n+          return true;\n+        }\n+\n+      }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(getQueueName()\n             + \" usedResources: \" + usedResources\n             + \" clusterResources: \" + clusterResource\n             + \" currentCapacity \"\n             + Resources.divide(resourceCalculator, clusterResource,\n               usedResources, clusterResource) + \" required \" + required\n             + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n             + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n       }\n       return false;\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected synchronized boolean assignToQueue(Resource clusterResource, \n      Resource required, FiCaSchedulerApp application, \n      boolean checkReservations) {\n\n    Resource potentialTotalResource \u003d Resources.add(usedResources, required);\n    // Check how of the cluster\u0027s absolute capacity we are currently using...\n    float potentialNewCapacity \u003d Resources.divide(resourceCalculator,\n        clusterResource, potentialTotalResource, clusterResource);\n    if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n      // if enabled, check to see if could we potentially use this node instead\n      // of a reserved node if the application has reserved containers\n      if (this.reservationsContinueLooking \u0026\u0026 checkReservations) {\n\n        float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n            resourceCalculator,\n            clusterResource,\n            Resources.subtract(potentialTotalResource,\n                application.getCurrentReservation()),\n             clusterResource);\n\n        if (potentialNewWithoutReservedCapacity \u003c\u003d absoluteMaxCapacity) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \"\n                + getQueueName()\n                + \" usedResources: \"\n                + usedResources\n                + \" clusterResources: \"\n                + clusterResource\n                + \" reservedResources: \"\n                + application.getCurrentReservation()\n                + \" currentCapacity \"\n                + Resources.divide(resourceCalculator, clusterResource,\n                    usedResources, clusterResource) + \" required \" + required\n                + \" potentialNewWithoutReservedCapacity: \"\n                + potentialNewWithoutReservedCapacity + \" ( \" + \" max-capacity: \"\n                + absoluteMaxCapacity + \")\");\n          }\n          // we could potentially use this node instead of reserved node\n          return true;\n        }\n\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \" usedResources: \" + usedResources\n            + \" clusterResources: \" + clusterResource\n            + \" currentCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n              usedResources, clusterResource) + \" required \" + required\n            + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n            + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n      }\n      return false;\n    }\n    return true;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
          "extendedDetails": {
            "oldValue": "[clusterResource-Resource, required-Resource]",
            "newValue": "[clusterResource-Resource, required-Resource, application-FiCaSchedulerApp, checkReservations-boolean]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-1769. CapacityScheduler: Improve reservations. Contributed by Thomas Graves\n",
          "commitDate": "29/09/14 7:12 AM",
          "commitName": "9c22065109a77681bc2534063eabe8692fbcb3cd",
          "commitAuthor": "Jason Lowe",
          "commitDateOld": "14/08/14 11:00 PM",
          "commitNameOld": "7360cec692be5dcc3377ae5082fe22870caac96b",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 45.34,
          "commitsBetweenForRepo": 409,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,56 @@\n-  private synchronized boolean assignToQueue(Resource clusterResource, \n-      Resource required) {\n+  protected synchronized boolean assignToQueue(Resource clusterResource, \n+      Resource required, FiCaSchedulerApp application, \n+      boolean checkReservations) {\n+\n+    Resource potentialTotalResource \u003d Resources.add(usedResources, required);\n     // Check how of the cluster\u0027s absolute capacity we are currently using...\n-    float potentialNewCapacity \u003d \n-        Resources.divide(\n-            resourceCalculator, clusterResource, \n-            Resources.add(usedResources, required), \n-            clusterResource);\n+    float potentialNewCapacity \u003d Resources.divide(resourceCalculator,\n+        clusterResource, potentialTotalResource, clusterResource);\n     if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n+      // if enabled, check to see if could we potentially use this node instead\n+      // of a reserved node if the application has reserved containers\n+      if (this.reservationsContinueLooking \u0026\u0026 checkReservations) {\n+\n+        float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n+            resourceCalculator,\n+            clusterResource,\n+            Resources.subtract(potentialTotalResource,\n+                application.getCurrentReservation()),\n+             clusterResource);\n+\n+        if (potentialNewWithoutReservedCapacity \u003c\u003d absoluteMaxCapacity) {\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"try to use reserved: \"\n+                + getQueueName()\n+                + \" usedResources: \"\n+                + usedResources\n+                + \" clusterResources: \"\n+                + clusterResource\n+                + \" reservedResources: \"\n+                + application.getCurrentReservation()\n+                + \" currentCapacity \"\n+                + Resources.divide(resourceCalculator, clusterResource,\n+                    usedResources, clusterResource) + \" required \" + required\n+                + \" potentialNewWithoutReservedCapacity: \"\n+                + potentialNewWithoutReservedCapacity + \" ( \" + \" max-capacity: \"\n+                + absoluteMaxCapacity + \")\");\n+          }\n+          // we could potentially use this node instead of reserved node\n+          return true;\n+        }\n+\n+      }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(getQueueName()\n             + \" usedResources: \" + usedResources\n             + \" clusterResources: \" + clusterResource\n             + \" currentCapacity \"\n             + Resources.divide(resourceCalculator, clusterResource,\n               usedResources, clusterResource) + \" required \" + required\n             + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n             + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n       }\n       return false;\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected synchronized boolean assignToQueue(Resource clusterResource, \n      Resource required, FiCaSchedulerApp application, \n      boolean checkReservations) {\n\n    Resource potentialTotalResource \u003d Resources.add(usedResources, required);\n    // Check how of the cluster\u0027s absolute capacity we are currently using...\n    float potentialNewCapacity \u003d Resources.divide(resourceCalculator,\n        clusterResource, potentialTotalResource, clusterResource);\n    if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n      // if enabled, check to see if could we potentially use this node instead\n      // of a reserved node if the application has reserved containers\n      if (this.reservationsContinueLooking \u0026\u0026 checkReservations) {\n\n        float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n            resourceCalculator,\n            clusterResource,\n            Resources.subtract(potentialTotalResource,\n                application.getCurrentReservation()),\n             clusterResource);\n\n        if (potentialNewWithoutReservedCapacity \u003c\u003d absoluteMaxCapacity) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \"\n                + getQueueName()\n                + \" usedResources: \"\n                + usedResources\n                + \" clusterResources: \"\n                + clusterResource\n                + \" reservedResources: \"\n                + application.getCurrentReservation()\n                + \" currentCapacity \"\n                + Resources.divide(resourceCalculator, clusterResource,\n                    usedResources, clusterResource) + \" required \" + required\n                + \" potentialNewWithoutReservedCapacity: \"\n                + potentialNewWithoutReservedCapacity + \" ( \" + \" max-capacity: \"\n                + absoluteMaxCapacity + \")\");\n          }\n          // we could potentially use this node instead of reserved node\n          return true;\n        }\n\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \" usedResources: \" + usedResources\n            + \" clusterResources: \" + clusterResource\n            + \" currentCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n              usedResources, clusterResource) + \" required \" + required\n            + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n            + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n      }\n      return false;\n    }\n    return true;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
          "extendedDetails": {
            "oldValue": "[private, synchronized]",
            "newValue": "[protected, synchronized]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-1769. CapacityScheduler: Improve reservations. Contributed by Thomas Graves\n",
          "commitDate": "29/09/14 7:12 AM",
          "commitName": "9c22065109a77681bc2534063eabe8692fbcb3cd",
          "commitAuthor": "Jason Lowe",
          "commitDateOld": "14/08/14 11:00 PM",
          "commitNameOld": "7360cec692be5dcc3377ae5082fe22870caac96b",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 45.34,
          "commitsBetweenForRepo": 409,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,56 @@\n-  private synchronized boolean assignToQueue(Resource clusterResource, \n-      Resource required) {\n+  protected synchronized boolean assignToQueue(Resource clusterResource, \n+      Resource required, FiCaSchedulerApp application, \n+      boolean checkReservations) {\n+\n+    Resource potentialTotalResource \u003d Resources.add(usedResources, required);\n     // Check how of the cluster\u0027s absolute capacity we are currently using...\n-    float potentialNewCapacity \u003d \n-        Resources.divide(\n-            resourceCalculator, clusterResource, \n-            Resources.add(usedResources, required), \n-            clusterResource);\n+    float potentialNewCapacity \u003d Resources.divide(resourceCalculator,\n+        clusterResource, potentialTotalResource, clusterResource);\n     if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n+      // if enabled, check to see if could we potentially use this node instead\n+      // of a reserved node if the application has reserved containers\n+      if (this.reservationsContinueLooking \u0026\u0026 checkReservations) {\n+\n+        float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n+            resourceCalculator,\n+            clusterResource,\n+            Resources.subtract(potentialTotalResource,\n+                application.getCurrentReservation()),\n+             clusterResource);\n+\n+        if (potentialNewWithoutReservedCapacity \u003c\u003d absoluteMaxCapacity) {\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"try to use reserved: \"\n+                + getQueueName()\n+                + \" usedResources: \"\n+                + usedResources\n+                + \" clusterResources: \"\n+                + clusterResource\n+                + \" reservedResources: \"\n+                + application.getCurrentReservation()\n+                + \" currentCapacity \"\n+                + Resources.divide(resourceCalculator, clusterResource,\n+                    usedResources, clusterResource) + \" required \" + required\n+                + \" potentialNewWithoutReservedCapacity: \"\n+                + potentialNewWithoutReservedCapacity + \" ( \" + \" max-capacity: \"\n+                + absoluteMaxCapacity + \")\");\n+          }\n+          // we could potentially use this node instead of reserved node\n+          return true;\n+        }\n+\n+      }\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(getQueueName()\n             + \" usedResources: \" + usedResources\n             + \" clusterResources: \" + clusterResource\n             + \" currentCapacity \"\n             + Resources.divide(resourceCalculator, clusterResource,\n               usedResources, clusterResource) + \" required \" + required\n             + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n             + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n       }\n       return false;\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected synchronized boolean assignToQueue(Resource clusterResource, \n      Resource required, FiCaSchedulerApp application, \n      boolean checkReservations) {\n\n    Resource potentialTotalResource \u003d Resources.add(usedResources, required);\n    // Check how of the cluster\u0027s absolute capacity we are currently using...\n    float potentialNewCapacity \u003d Resources.divide(resourceCalculator,\n        clusterResource, potentialTotalResource, clusterResource);\n    if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n      // if enabled, check to see if could we potentially use this node instead\n      // of a reserved node if the application has reserved containers\n      if (this.reservationsContinueLooking \u0026\u0026 checkReservations) {\n\n        float potentialNewWithoutReservedCapacity \u003d Resources.divide(\n            resourceCalculator,\n            clusterResource,\n            Resources.subtract(potentialTotalResource,\n                application.getCurrentReservation()),\n             clusterResource);\n\n        if (potentialNewWithoutReservedCapacity \u003c\u003d absoluteMaxCapacity) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"try to use reserved: \"\n                + getQueueName()\n                + \" usedResources: \"\n                + usedResources\n                + \" clusterResources: \"\n                + clusterResource\n                + \" reservedResources: \"\n                + application.getCurrentReservation()\n                + \" currentCapacity \"\n                + Resources.divide(resourceCalculator, clusterResource,\n                    usedResources, clusterResource) + \" required \" + required\n                + \" potentialNewWithoutReservedCapacity: \"\n                + potentialNewWithoutReservedCapacity + \" ( \" + \" max-capacity: \"\n                + absoluteMaxCapacity + \")\");\n          }\n          // we could potentially use this node instead of reserved node\n          return true;\n        }\n\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \" usedResources: \" + usedResources\n            + \" clusterResources: \" + clusterResource\n            + \" currentCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n              usedResources, clusterResource) + \" required \" + required\n            + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n            + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n      }\n      return false;\n    }\n    return true;\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
          "extendedDetails": {}
        }
      ]
    },
    "44b6261bfacddea88a3cf02d406f970bbbb98d04": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1892. Improved some logs in the scheduler. Contributed by Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1587717 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/04/14 1:37 PM",
      "commitName": "44b6261bfacddea88a3cf02d406f970bbbb98d04",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "12/03/14 7:36 AM",
      "commitNameOld": "4ce0e4bf2e91278bbc33f4a1c44c7929627b5d6e",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 34.25,
      "commitsBetweenForRepo": 252,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,23 @@\n   private synchronized boolean assignToQueue(Resource clusterResource, \n       Resource required) {\n     // Check how of the cluster\u0027s absolute capacity we are currently using...\n     float potentialNewCapacity \u003d \n         Resources.divide(\n             resourceCalculator, clusterResource, \n             Resources.add(usedResources, required), \n             clusterResource);\n     if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n-      LOG.info(getQueueName() + \n-          \" usedResources: \" + usedResources +\n-          \" clusterResources: \" + clusterResource +\n-          \" currentCapacity \" + \n-            Resources.divide(resourceCalculator, clusterResource, \n-                usedResources, clusterResource) + \n-          \" required \" + required +\n-          \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \" +\n-          \" max-capacity: \" + absoluteMaxCapacity + \")\");\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(getQueueName()\n+            + \" usedResources: \" + usedResources\n+            + \" clusterResources: \" + clusterResource\n+            + \" currentCapacity \"\n+            + Resources.divide(resourceCalculator, clusterResource,\n+              usedResources, clusterResource) + \" required \" + required\n+            + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n+            + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n+      }\n       return false;\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized boolean assignToQueue(Resource clusterResource, \n      Resource required) {\n    // Check how of the cluster\u0027s absolute capacity we are currently using...\n    float potentialNewCapacity \u003d \n        Resources.divide(\n            resourceCalculator, clusterResource, \n            Resources.add(usedResources, required), \n            clusterResource);\n    if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(getQueueName()\n            + \" usedResources: \" + usedResources\n            + \" clusterResources: \" + clusterResource\n            + \" currentCapacity \"\n            + Resources.divide(resourceCalculator, clusterResource,\n              usedResources, clusterResource) + \" required \" + required\n            + \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \"\n            + \" max-capacity: \" + absoluteMaxCapacity + \")\");\n      }\n      return false;\n    }\n    return true;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
      "extendedDetails": {}
    },
    "453926397182078c65a4428eb5de5a90d6af6448": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2. Enhanced CapacityScheduler to account for CPU alongwith memory for multi-dimensional resource scheduling. Contributed by Arun C. Murthy.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1430682 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/01/13 9:08 PM",
      "commitName": "453926397182078c65a4428eb5de5a90d6af6448",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "07/11/12 1:56 PM",
      "commitNameOld": "fb5b96dfc324f999e8b3698288c110a1c3b71c30",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 62.3,
      "commitsBetweenForRepo": 257,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,22 @@\n   private synchronized boolean assignToQueue(Resource clusterResource, \n       Resource required) {\n     // Check how of the cluster\u0027s absolute capacity we are currently using...\n     float potentialNewCapacity \u003d \n-      (float)(usedResources.getMemory() + required.getMemory()) / \n-        clusterResource.getMemory();\n+        Resources.divide(\n+            resourceCalculator, clusterResource, \n+            Resources.add(usedResources, required), \n+            clusterResource);\n     if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n       LOG.info(getQueueName() + \n-          \" usedResources: \" + usedResources.getMemory() +\n-          \" clusterResources: \" + clusterResource.getMemory() +\n-          \" currentCapacity \" + ((float)usedResources.getMemory())/clusterResource.getMemory() + \n-          \" required \" + required.getMemory() +\n+          \" usedResources: \" + usedResources +\n+          \" clusterResources: \" + clusterResource +\n+          \" currentCapacity \" + \n+            Resources.divide(resourceCalculator, clusterResource, \n+                usedResources, clusterResource) + \n+          \" required \" + required +\n           \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \" +\n           \" max-capacity: \" + absoluteMaxCapacity + \")\");\n       return false;\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized boolean assignToQueue(Resource clusterResource, \n      Resource required) {\n    // Check how of the cluster\u0027s absolute capacity we are currently using...\n    float potentialNewCapacity \u003d \n        Resources.divide(\n            resourceCalculator, clusterResource, \n            Resources.add(usedResources, required), \n            clusterResource);\n    if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n      LOG.info(getQueueName() + \n          \" usedResources: \" + usedResources +\n          \" clusterResources: \" + clusterResource +\n          \" currentCapacity \" + \n            Resources.divide(resourceCalculator, clusterResource, \n                usedResources, clusterResource) + \n          \" required \" + required +\n          \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \" +\n          \" max-capacity: \" + absoluteMaxCapacity + \")\");\n      return false;\n    }\n    return true;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
      "extendedDetails": {}
    },
    "e1fdf62123625e4ba399af02f8aad500637d29d1": {
      "type": "Yfilerename",
      "commitMessage": "YARN-1. Promote YARN to be a sub-project of Apache Hadoop.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370666 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/12 10:22 PM",
      "commitName": "e1fdf62123625e4ba399af02f8aad500637d29d1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "07/08/12 7:53 PM",
      "commitNameOld": "34554d1e11ee1d5b564d7d9ed3e6d55931d72749",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private synchronized boolean assignToQueue(Resource clusterResource, \n      Resource required) {\n    // Check how of the cluster\u0027s absolute capacity we are currently using...\n    float potentialNewCapacity \u003d \n      (float)(usedResources.getMemory() + required.getMemory()) / \n        clusterResource.getMemory();\n    if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n      LOG.info(getQueueName() + \n          \" usedResources: \" + usedResources.getMemory() +\n          \" clusterResources: \" + clusterResource.getMemory() +\n          \" currentCapacity \" + ((float)usedResources.getMemory())/clusterResource.getMemory() + \n          \" required \" + required.getMemory() +\n          \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \" +\n          \" max-capacity: \" + absoluteMaxCapacity + \")\");\n      return false;\n    }\n    return true;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java"
      }
    },
    "9d1621da52fd7f4ee68f80fdbf420180a42b5b1d": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3683. Fixed maxCapacity of queues to be product of parent maxCapacities. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1235858 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/01/12 10:17 AM",
      "commitName": "9d1621da52fd7f4ee68f80fdbf420180a42b5b1d",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "23/01/12 5:00 PM",
      "commitNameOld": "9a153334ac5a83a49a44ead02466453f3127120f",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 1.72,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,18 @@\n   private synchronized boolean assignToQueue(Resource clusterResource, \n       Resource required) {\n     // Check how of the cluster\u0027s absolute capacity we are currently using...\n     float potentialNewCapacity \u003d \n       (float)(usedResources.getMemory() + required.getMemory()) / \n         clusterResource.getMemory();\n-    LOG.info(getQueueName() + \n-        \" usedResources: \" + usedResources.getMemory() + \n-        \" currentCapacity \" + ((float)usedResources.getMemory())/clusterResource.getMemory() + \n-        \" required \" + required.getMemory() +\n-        \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \" +\n-        \" max-capacity: \" + absoluteMaxCapacity + \")\");\n     if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n+      LOG.info(getQueueName() + \n+          \" usedResources: \" + usedResources.getMemory() +\n+          \" clusterResources: \" + clusterResource.getMemory() +\n+          \" currentCapacity \" + ((float)usedResources.getMemory())/clusterResource.getMemory() + \n+          \" required \" + required.getMemory() +\n+          \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \" +\n+          \" max-capacity: \" + absoluteMaxCapacity + \")\");\n       return false;\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized boolean assignToQueue(Resource clusterResource, \n      Resource required) {\n    // Check how of the cluster\u0027s absolute capacity we are currently using...\n    float potentialNewCapacity \u003d \n      (float)(usedResources.getMemory() + required.getMemory()) / \n        clusterResource.getMemory();\n    if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n      LOG.info(getQueueName() + \n          \" usedResources: \" + usedResources.getMemory() +\n          \" clusterResources: \" + clusterResource.getMemory() +\n          \" currentCapacity \" + ((float)usedResources.getMemory())/clusterResource.getMemory() + \n          \" required \" + required.getMemory() +\n          \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \" +\n          \" max-capacity: \" + absoluteMaxCapacity + \")\");\n      return false;\n    }\n    return true;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
      "extendedDetails": {}
    },
    "224fc101fdfa355b4ad842fc39192d8e4f1f2979": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3327. RM web ui scheduler link doesn\u0027t show correct max value for queues (Anupam Seth via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1212212 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/12/11 5:38 PM",
      "commitName": "224fc101fdfa355b4ad842fc39192d8e4f1f2979",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "22/11/11 5:42 PM",
      "commitNameOld": "41b1e3ffec808db440778bebc258c10c76834513",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 16.0,
      "commitsBetweenForRepo": 78,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   private synchronized boolean assignToQueue(Resource clusterResource, \n       Resource required) {\n     // Check how of the cluster\u0027s absolute capacity we are currently using...\n     float potentialNewCapacity \u003d \n       (float)(usedResources.getMemory() + required.getMemory()) / \n         clusterResource.getMemory();\n+    LOG.info(getQueueName() + \n+        \" usedResources: \" + usedResources.getMemory() + \n+        \" currentCapacity \" + ((float)usedResources.getMemory())/clusterResource.getMemory() + \n+        \" required \" + required.getMemory() +\n+        \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \" +\n+        \" max-capacity: \" + absoluteMaxCapacity + \")\");\n     if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n-      LOG.info(getQueueName() + \n-          \" usedResources: \" + usedResources.getMemory() + \n-          \" currentCapacity \" + ((float)usedResources.getMemory())/clusterResource.getMemory() + \n-          \" required \" + required.getMemory() +\n-          \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \" +\n-          \" \u003e max-capacity (\" + absoluteMaxCapacity + \")\");\n       return false;\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized boolean assignToQueue(Resource clusterResource, \n      Resource required) {\n    // Check how of the cluster\u0027s absolute capacity we are currently using...\n    float potentialNewCapacity \u003d \n      (float)(usedResources.getMemory() + required.getMemory()) / \n        clusterResource.getMemory();\n    LOG.info(getQueueName() + \n        \" usedResources: \" + usedResources.getMemory() + \n        \" currentCapacity \" + ((float)usedResources.getMemory())/clusterResource.getMemory() + \n        \" required \" + required.getMemory() +\n        \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \" +\n        \" max-capacity: \" + absoluteMaxCapacity + \")\");\n    if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n      return false;\n    }\n    return true;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private synchronized boolean assignToQueue(Resource clusterResource, \n      Resource required) {\n    // Check how of the cluster\u0027s absolute capacity we are currently using...\n    float potentialNewCapacity \u003d \n      (float)(usedResources.getMemory() + required.getMemory()) / \n        clusterResource.getMemory();\n    if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n      LOG.info(getQueueName() + \n          \" usedResources: \" + usedResources.getMemory() + \n          \" currentCapacity \" + ((float)usedResources.getMemory())/clusterResource.getMemory() + \n          \" required \" + required.getMemory() +\n          \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \" +\n          \" \u003e max-capacity (\" + absoluteMaxCapacity + \")\");\n      return false;\n    }\n    return true;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java",
        "newPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,17 @@\n+  private synchronized boolean assignToQueue(Resource clusterResource, \n+      Resource required) {\n+    // Check how of the cluster\u0027s absolute capacity we are currently using...\n+    float potentialNewCapacity \u003d \n+      (float)(usedResources.getMemory() + required.getMemory()) / \n+        clusterResource.getMemory();\n+    if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n+      LOG.info(getQueueName() + \n+          \" usedResources: \" + usedResources.getMemory() + \n+          \" currentCapacity \" + ((float)usedResources.getMemory())/clusterResource.getMemory() + \n+          \" required \" + required.getMemory() +\n+          \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \" +\n+          \" \u003e max-capacity (\" + absoluteMaxCapacity + \")\");\n+      return false;\n+    }\n+    return true;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized boolean assignToQueue(Resource clusterResource, \n      Resource required) {\n    // Check how of the cluster\u0027s absolute capacity we are currently using...\n    float potentialNewCapacity \u003d \n      (float)(usedResources.getMemory() + required.getMemory()) / \n        clusterResource.getMemory();\n    if (potentialNewCapacity \u003e absoluteMaxCapacity) {\n      LOG.info(getQueueName() + \n          \" usedResources: \" + usedResources.getMemory() + \n          \" currentCapacity \" + ((float)usedResources.getMemory())/clusterResource.getMemory() + \n          \" required \" + required.getMemory() +\n          \" potentialNewCapacity: \" + potentialNewCapacity + \" ( \" +\n          \" \u003e max-capacity (\" + absoluteMaxCapacity + \")\");\n      return false;\n    }\n    return true;\n  }",
      "path": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java"
    }
  }
}