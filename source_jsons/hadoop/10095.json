{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FinalizedReplica.java",
  "functionName": "loadLastPartialChunkChecksum",
  "functionId": "loadLastPartialChunkChecksum",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/FinalizedReplica.java",
  "functionStartLine": 164,
  "functionEndLine": 169,
  "numCommitsSeen": 13,
  "timeTaken": 1806,
  "changeHistory": [
    "2021f4bdce3b27c46edaad198f0007a26a8a1391"
  ],
  "changeHistoryShort": {
    "2021f4bdce3b27c46edaad198f0007a26a8a1391": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2021f4bdce3b27c46edaad198f0007a26a8a1391": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11187. Optimize disk access for last partial chunk checksum of Finalized replica. Contributed by Wei-Chiu Chuang.\n",
      "commitDate": "02/02/18 5:18 PM",
      "commitName": "2021f4bdce3b27c46edaad198f0007a26a8a1391",
      "commitAuthor": "Wei-Chiu Chuang",
      "diff": "@@ -0,0 +1,6 @@\n+  public void loadLastPartialChunkChecksum()\n+      throws IOException {\n+    byte[] lastChecksum \u003d getVolume().loadLastPartialChunkChecksum(\n+        getBlockFile(), getMetaFile());\n+    setLastPartialChunkChecksum(lastChecksum);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void loadLastPartialChunkChecksum()\n      throws IOException {\n    byte[] lastChecksum \u003d getVolume().loadLastPartialChunkChecksum(\n        getBlockFile(), getMetaFile());\n    setLastPartialChunkChecksum(lastChecksum);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/FinalizedReplica.java"
    }
  }
}