{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HistoryFileManager.java",
  "functionName": "scanOldDirsForJob",
  "functionId": "scanOldDirsForJob___jobId-JobId",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
  "functionStartLine": 1049,
  "functionEndLine": 1066,
  "numCommitsSeen": 57,
  "timeTaken": 8191,
  "changeHistory": [
    "8ac3910ae0aa8c9e082b8aa1cd1f6b3e8b4a6bd8",
    "7d04a96027ad75877b41b7cd8f67455dd13159d7",
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "8ac3910ae0aa8c9e082b8aa1cd1f6b3e8b4a6bd8": "Ybodychange",
    "7d04a96027ad75877b41b7cd8f67455dd13159d7": "Ymultichange(Yreturntypechange,Ybodychange)",
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f": "Ymultichange(Ymovefromfile,Ybodychange)",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "8ac3910ae0aa8c9e082b8aa1cd1f6b3e8b4a6bd8": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4705. Fix a bug in job history lookup, which makes older jobs inaccessible despite the presence of a valid history file. (Contributed by Jason Lowe)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1395850 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/10/12 8:23 PM",
      "commitName": "8ac3910ae0aa8c9e082b8aa1cd1f6b3e8b4a6bd8",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "28/09/12 2:55 PM",
      "commitNameOld": "03b7ad04fadeb1a98271ac1775f900999989eafb",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 10.23,
      "commitsBetweenForRepo": 58,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   private HistoryFileInfo scanOldDirsForJob(JobId jobId) throws IOException {\n-    int jobSerialNumber \u003d JobHistoryUtils.jobSerialNumber(jobId);\n-    String boxedSerialNumber \u003d String.valueOf(jobSerialNumber);\n+    String boxedSerialNumber \u003d JobHistoryUtils.serialNumberDirectoryComponent(\n+        jobId, serialNumberFormat);\n     Set\u003cString\u003e dateStringSet \u003d serialNumberIndex.get(boxedSerialNumber);\n     if (dateStringSet \u003d\u003d null) {\n       return null;\n     }\n     for (String timestampPart : dateStringSet) {\n       Path logDir \u003d canonicalHistoryLogPath(jobId, timestampPart);\n       List\u003cFileStatus\u003e fileStatusList \u003d scanDirectoryForHistoryFiles(logDir,\n           doneDirFc);\n       HistoryFileInfo fileInfo \u003d getJobFileInfo(fileStatusList, jobId);\n       if (fileInfo !\u003d null) {\n         return fileInfo;\n       }\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private HistoryFileInfo scanOldDirsForJob(JobId jobId) throws IOException {\n    String boxedSerialNumber \u003d JobHistoryUtils.serialNumberDirectoryComponent(\n        jobId, serialNumberFormat);\n    Set\u003cString\u003e dateStringSet \u003d serialNumberIndex.get(boxedSerialNumber);\n    if (dateStringSet \u003d\u003d null) {\n      return null;\n    }\n    for (String timestampPart : dateStringSet) {\n      Path logDir \u003d canonicalHistoryLogPath(jobId, timestampPart);\n      List\u003cFileStatus\u003e fileStatusList \u003d scanDirectoryForHistoryFiles(logDir,\n          doneDirFc);\n      HistoryFileInfo fileInfo \u003d getJobFileInfo(fileStatusList, jobId);\n      if (fileInfo !\u003d null) {\n        return fileInfo;\n      }\n    }\n    return null;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
      "extendedDetails": {}
    },
    "7d04a96027ad75877b41b7cd8f67455dd13159d7": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "MAPREDUCE-3972. Fix locking and exception issues in JobHistory server. (Contributed by Robert Joseph Evans)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1327354 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/04/12 6:59 PM",
      "commitName": "7d04a96027ad75877b41b7cd8f67455dd13159d7",
      "commitAuthor": "Siddharth Seth",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "MAPREDUCE-3972. Fix locking and exception issues in JobHistory server. (Contributed by Robert Joseph Evans)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1327354 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "17/04/12 6:59 PM",
          "commitName": "7d04a96027ad75877b41b7cd8f67455dd13159d7",
          "commitAuthor": "Siddharth Seth",
          "commitDateOld": "10/04/12 11:11 AM",
          "commitNameOld": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
          "commitAuthorOld": "Thomas Graves",
          "daysBetweenCommits": 7.32,
          "commitsBetweenForRepo": 59,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,18 @@\n-  private MetaInfo scanOldDirsForJob(JobId jobId) throws IOException {\n+  private HistoryFileInfo scanOldDirsForJob(JobId jobId) throws IOException {\n     int jobSerialNumber \u003d JobHistoryUtils.jobSerialNumber(jobId);\n     String boxedSerialNumber \u003d String.valueOf(jobSerialNumber);\n-    Set\u003cString\u003e dateStringSet;\n-    synchronized (idToDateString) {\n-      Set\u003cString\u003e found \u003d idToDateString.get(boxedSerialNumber);\n-      if (found \u003d\u003d null) {\n-        return null;\n-      } else {\n-        dateStringSet \u003d new HashSet\u003cString\u003e(found);\n-      }\n+    Set\u003cString\u003e dateStringSet \u003d serialNumberIndex.get(boxedSerialNumber);\n+    if (dateStringSet \u003d\u003d null) {\n+      return null;\n     }\n     for (String timestampPart : dateStringSet) {\n       Path logDir \u003d canonicalHistoryLogPath(jobId, timestampPart);\n       List\u003cFileStatus\u003e fileStatusList \u003d scanDirectoryForHistoryFiles(logDir,\n           doneDirFc);\n-      MetaInfo metaInfo \u003d getJobMetaInfo(fileStatusList, jobId);\n-      if (metaInfo !\u003d null) {\n-        return metaInfo;\n+      HistoryFileInfo fileInfo \u003d getJobFileInfo(fileStatusList, jobId);\n+      if (fileInfo !\u003d null) {\n+        return fileInfo;\n       }\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private HistoryFileInfo scanOldDirsForJob(JobId jobId) throws IOException {\n    int jobSerialNumber \u003d JobHistoryUtils.jobSerialNumber(jobId);\n    String boxedSerialNumber \u003d String.valueOf(jobSerialNumber);\n    Set\u003cString\u003e dateStringSet \u003d serialNumberIndex.get(boxedSerialNumber);\n    if (dateStringSet \u003d\u003d null) {\n      return null;\n    }\n    for (String timestampPart : dateStringSet) {\n      Path logDir \u003d canonicalHistoryLogPath(jobId, timestampPart);\n      List\u003cFileStatus\u003e fileStatusList \u003d scanDirectoryForHistoryFiles(logDir,\n          doneDirFc);\n      HistoryFileInfo fileInfo \u003d getJobFileInfo(fileStatusList, jobId);\n      if (fileInfo !\u003d null) {\n        return fileInfo;\n      }\n    }\n    return null;\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
          "extendedDetails": {
            "oldValue": "MetaInfo",
            "newValue": "HistoryFileInfo"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-3972. Fix locking and exception issues in JobHistory server. (Contributed by Robert Joseph Evans)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1327354 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "17/04/12 6:59 PM",
          "commitName": "7d04a96027ad75877b41b7cd8f67455dd13159d7",
          "commitAuthor": "Siddharth Seth",
          "commitDateOld": "10/04/12 11:11 AM",
          "commitNameOld": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
          "commitAuthorOld": "Thomas Graves",
          "daysBetweenCommits": 7.32,
          "commitsBetweenForRepo": 59,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,18 @@\n-  private MetaInfo scanOldDirsForJob(JobId jobId) throws IOException {\n+  private HistoryFileInfo scanOldDirsForJob(JobId jobId) throws IOException {\n     int jobSerialNumber \u003d JobHistoryUtils.jobSerialNumber(jobId);\n     String boxedSerialNumber \u003d String.valueOf(jobSerialNumber);\n-    Set\u003cString\u003e dateStringSet;\n-    synchronized (idToDateString) {\n-      Set\u003cString\u003e found \u003d idToDateString.get(boxedSerialNumber);\n-      if (found \u003d\u003d null) {\n-        return null;\n-      } else {\n-        dateStringSet \u003d new HashSet\u003cString\u003e(found);\n-      }\n+    Set\u003cString\u003e dateStringSet \u003d serialNumberIndex.get(boxedSerialNumber);\n+    if (dateStringSet \u003d\u003d null) {\n+      return null;\n     }\n     for (String timestampPart : dateStringSet) {\n       Path logDir \u003d canonicalHistoryLogPath(jobId, timestampPart);\n       List\u003cFileStatus\u003e fileStatusList \u003d scanDirectoryForHistoryFiles(logDir,\n           doneDirFc);\n-      MetaInfo metaInfo \u003d getJobMetaInfo(fileStatusList, jobId);\n-      if (metaInfo !\u003d null) {\n-        return metaInfo;\n+      HistoryFileInfo fileInfo \u003d getJobFileInfo(fileStatusList, jobId);\n+      if (fileInfo !\u003d null) {\n+        return fileInfo;\n       }\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private HistoryFileInfo scanOldDirsForJob(JobId jobId) throws IOException {\n    int jobSerialNumber \u003d JobHistoryUtils.jobSerialNumber(jobId);\n    String boxedSerialNumber \u003d String.valueOf(jobSerialNumber);\n    Set\u003cString\u003e dateStringSet \u003d serialNumberIndex.get(boxedSerialNumber);\n    if (dateStringSet \u003d\u003d null) {\n      return null;\n    }\n    for (String timestampPart : dateStringSet) {\n      Path logDir \u003d canonicalHistoryLogPath(jobId, timestampPart);\n      List\u003cFileStatus\u003e fileStatusList \u003d scanDirectoryForHistoryFiles(logDir,\n          doneDirFc);\n      HistoryFileInfo fileInfo \u003d getJobFileInfo(fileStatusList, jobId);\n      if (fileInfo !\u003d null) {\n        return fileInfo;\n      }\n    }\n    return null;\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311896 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/04/12 11:11 AM",
      "commitName": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
      "commitAuthor": "Thomas Graves",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311896 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/04/12 11:11 AM",
          "commitName": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
          "commitAuthor": "Thomas Graves",
          "commitDateOld": "10/04/12 9:13 AM",
          "commitNameOld": "000859a534f4cc6a57524a676805d8af6ad199de",
          "commitAuthorOld": "Robert Joseph Evans",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,23 @@\n   private MetaInfo scanOldDirsForJob(JobId jobId) throws IOException {\n     int jobSerialNumber \u003d JobHistoryUtils.jobSerialNumber(jobId);\n     String boxedSerialNumber \u003d String.valueOf(jobSerialNumber);\n-    Set\u003cString\u003e dateStringSet \u003d idToDateString.get(boxedSerialNumber);\n-    if (dateStringSet \u003d\u003d null) {\n-      return null;\n+    Set\u003cString\u003e dateStringSet;\n+    synchronized (idToDateString) {\n+      Set\u003cString\u003e found \u003d idToDateString.get(boxedSerialNumber);\n+      if (found \u003d\u003d null) {\n+        return null;\n+      } else {\n+        dateStringSet \u003d new HashSet\u003cString\u003e(found);\n+      }\n     }\n     for (String timestampPart : dateStringSet) {\n       Path logDir \u003d canonicalHistoryLogPath(jobId, timestampPart);\n       List\u003cFileStatus\u003e fileStatusList \u003d scanDirectoryForHistoryFiles(logDir,\n           doneDirFc);\n       MetaInfo metaInfo \u003d getJobMetaInfo(fileStatusList, jobId);\n       if (metaInfo !\u003d null) {\n         return metaInfo;\n       }\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private MetaInfo scanOldDirsForJob(JobId jobId) throws IOException {\n    int jobSerialNumber \u003d JobHistoryUtils.jobSerialNumber(jobId);\n    String boxedSerialNumber \u003d String.valueOf(jobSerialNumber);\n    Set\u003cString\u003e dateStringSet;\n    synchronized (idToDateString) {\n      Set\u003cString\u003e found \u003d idToDateString.get(boxedSerialNumber);\n      if (found \u003d\u003d null) {\n        return null;\n      } else {\n        dateStringSet \u003d new HashSet\u003cString\u003e(found);\n      }\n    }\n    for (String timestampPart : dateStringSet) {\n      Path logDir \u003d canonicalHistoryLogPath(jobId, timestampPart);\n      List\u003cFileStatus\u003e fileStatusList \u003d scanDirectoryForHistoryFiles(logDir,\n          doneDirFc);\n      MetaInfo metaInfo \u003d getJobMetaInfo(fileStatusList, jobId);\n      if (metaInfo !\u003d null) {\n        return metaInfo;\n      }\n    }\n    return null;\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
          "extendedDetails": {
            "oldPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
            "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
            "oldMethodName": "scanOldDirsForJob",
            "newMethodName": "scanOldDirsForJob"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311896 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/04/12 11:11 AM",
          "commitName": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
          "commitAuthor": "Thomas Graves",
          "commitDateOld": "10/04/12 9:13 AM",
          "commitNameOld": "000859a534f4cc6a57524a676805d8af6ad199de",
          "commitAuthorOld": "Robert Joseph Evans",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,23 @@\n   private MetaInfo scanOldDirsForJob(JobId jobId) throws IOException {\n     int jobSerialNumber \u003d JobHistoryUtils.jobSerialNumber(jobId);\n     String boxedSerialNumber \u003d String.valueOf(jobSerialNumber);\n-    Set\u003cString\u003e dateStringSet \u003d idToDateString.get(boxedSerialNumber);\n-    if (dateStringSet \u003d\u003d null) {\n-      return null;\n+    Set\u003cString\u003e dateStringSet;\n+    synchronized (idToDateString) {\n+      Set\u003cString\u003e found \u003d idToDateString.get(boxedSerialNumber);\n+      if (found \u003d\u003d null) {\n+        return null;\n+      } else {\n+        dateStringSet \u003d new HashSet\u003cString\u003e(found);\n+      }\n     }\n     for (String timestampPart : dateStringSet) {\n       Path logDir \u003d canonicalHistoryLogPath(jobId, timestampPart);\n       List\u003cFileStatus\u003e fileStatusList \u003d scanDirectoryForHistoryFiles(logDir,\n           doneDirFc);\n       MetaInfo metaInfo \u003d getJobMetaInfo(fileStatusList, jobId);\n       if (metaInfo !\u003d null) {\n         return metaInfo;\n       }\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private MetaInfo scanOldDirsForJob(JobId jobId) throws IOException {\n    int jobSerialNumber \u003d JobHistoryUtils.jobSerialNumber(jobId);\n    String boxedSerialNumber \u003d String.valueOf(jobSerialNumber);\n    Set\u003cString\u003e dateStringSet;\n    synchronized (idToDateString) {\n      Set\u003cString\u003e found \u003d idToDateString.get(boxedSerialNumber);\n      if (found \u003d\u003d null) {\n        return null;\n      } else {\n        dateStringSet \u003d new HashSet\u003cString\u003e(found);\n      }\n    }\n    for (String timestampPart : dateStringSet) {\n      Path logDir \u003d canonicalHistoryLogPath(jobId, timestampPart);\n      List\u003cFileStatus\u003e fileStatusList \u003d scanDirectoryForHistoryFiles(logDir,\n          doneDirFc);\n      MetaInfo metaInfo \u003d getJobMetaInfo(fileStatusList, jobId);\n      if (metaInfo !\u003d null) {\n        return metaInfo;\n      }\n    }\n    return null;\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private MetaInfo scanOldDirsForJob(JobId jobId) throws IOException {\n    int jobSerialNumber \u003d JobHistoryUtils.jobSerialNumber(jobId);\n    String boxedSerialNumber \u003d String.valueOf(jobSerialNumber);\n    Set\u003cString\u003e dateStringSet \u003d idToDateString.get(boxedSerialNumber);\n    if (dateStringSet \u003d\u003d null) {\n      return null;\n    }\n    for (String timestampPart : dateStringSet) {\n      Path logDir \u003d canonicalHistoryLogPath(jobId, timestampPart);\n      List\u003cFileStatus\u003e fileStatusList \u003d scanDirectoryForHistoryFiles(logDir, doneDirFc);\n      MetaInfo metaInfo \u003d getJobMetaInfo(fileStatusList, jobId);\n      if (metaInfo !\u003d null) {\n        return metaInfo;\n      }\n    }\n    return null;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,17 @@\n+  private MetaInfo scanOldDirsForJob(JobId jobId) throws IOException {\n+    int jobSerialNumber \u003d JobHistoryUtils.jobSerialNumber(jobId);\n+    String boxedSerialNumber \u003d String.valueOf(jobSerialNumber);\n+    Set\u003cString\u003e dateStringSet \u003d idToDateString.get(boxedSerialNumber);\n+    if (dateStringSet \u003d\u003d null) {\n+      return null;\n+    }\n+    for (String timestampPart : dateStringSet) {\n+      Path logDir \u003d canonicalHistoryLogPath(jobId, timestampPart);\n+      List\u003cFileStatus\u003e fileStatusList \u003d scanDirectoryForHistoryFiles(logDir, doneDirFc);\n+      MetaInfo metaInfo \u003d getJobMetaInfo(fileStatusList, jobId);\n+      if (metaInfo !\u003d null) {\n+        return metaInfo;\n+      }\n+    }\n+    return null;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private MetaInfo scanOldDirsForJob(JobId jobId) throws IOException {\n    int jobSerialNumber \u003d JobHistoryUtils.jobSerialNumber(jobId);\n    String boxedSerialNumber \u003d String.valueOf(jobSerialNumber);\n    Set\u003cString\u003e dateStringSet \u003d idToDateString.get(boxedSerialNumber);\n    if (dateStringSet \u003d\u003d null) {\n      return null;\n    }\n    for (String timestampPart : dateStringSet) {\n      Path logDir \u003d canonicalHistoryLogPath(jobId, timestampPart);\n      List\u003cFileStatus\u003e fileStatusList \u003d scanDirectoryForHistoryFiles(logDir, doneDirFc);\n      MetaInfo metaInfo \u003d getJobMetaInfo(fileStatusList, jobId);\n      if (metaInfo !\u003d null) {\n        return metaInfo;\n      }\n    }\n    return null;\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java"
    }
  }
}