{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "INodeWithAdditionalFields.java",
  "functionName": "removeFeature",
  "functionId": "removeFeature___f-Feature",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeWithAdditionalFields.java",
  "functionStartLine": 306,
  "functionEndLine": 338,
  "numCommitsSeen": 98,
  "timeTaken": 3187,
  "changeHistory": [
    "1a79dcfc457969d6a6c08ffffe4152fd7638e48a",
    "5fd7230671bb3d90081d4138c364c3f65b35cdbc",
    "82ff2d3f2e569879500d851f4d67dfa2d02b5c9b"
  ],
  "changeHistoryShort": {
    "1a79dcfc457969d6a6c08ffffe4152fd7638e48a": "Ybodychange",
    "5fd7230671bb3d90081d4138c364c3f65b35cdbc": "Ymultichange(Ymovefromfile,Yreturntypechange,Ymodifierchange,Ybodychange,Yparameterchange)",
    "82ff2d3f2e569879500d851f4d67dfa2d02b5c9b": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1a79dcfc457969d6a6c08ffffe4152fd7638e48a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12143. Improve performance of getting and removing inode features. Contributed by Daryn Sharp.\n",
      "commitDate": "25/07/17 8:28 AM",
      "commitName": "1a79dcfc457969d6a6c08ffffe4152fd7638e48a",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "31/05/17 8:09 AM",
      "commitNameOld": "13de636b4079b077890ad10389ff350dcf8086a2",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 55.01,
      "commitsBetweenForRepo": 259,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,33 @@\n   protected void removeFeature(Feature f) {\n     int size \u003d features.length;\n-    Preconditions.checkState(size \u003e 0, \"Feature \"\n-        + f.getClass().getSimpleName() + \" not found.\");\n+    if (size \u003d\u003d 0) {\n+      throwFeatureNotFoundException(f);\n+    }\n \n     if (size \u003d\u003d 1) {\n-      Preconditions.checkState(features[0] \u003d\u003d f, \"Feature \"\n-          + f.getClass().getSimpleName() + \" not found.\");\n+      if (features[0] !\u003d f) {\n+        throwFeatureNotFoundException(f);\n+      }\n       features \u003d EMPTY_FEATURE;\n       return;\n     }\n \n     Feature[] arr \u003d new Feature[size - 1];\n     int j \u003d 0;\n     boolean overflow \u003d false;\n     for (Feature f1 : features) {\n       if (f1 !\u003d f) {\n         if (j \u003d\u003d size - 1) {\n           overflow \u003d true;\n           break;\n         } else {\n           arr[j++] \u003d f1;\n         }\n       }\n     }\n \n-    Preconditions.checkState(!overflow \u0026\u0026 j \u003d\u003d size - 1, \"Feature \"\n-        + f.getClass().getSimpleName() + \" not found.\");\n+    if (overflow || j !\u003d size - 1) {\n+      throwFeatureNotFoundException(f);\n+    }\n     features \u003d arr;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void removeFeature(Feature f) {\n    int size \u003d features.length;\n    if (size \u003d\u003d 0) {\n      throwFeatureNotFoundException(f);\n    }\n\n    if (size \u003d\u003d 1) {\n      if (features[0] !\u003d f) {\n        throwFeatureNotFoundException(f);\n      }\n      features \u003d EMPTY_FEATURE;\n      return;\n    }\n\n    Feature[] arr \u003d new Feature[size - 1];\n    int j \u003d 0;\n    boolean overflow \u003d false;\n    for (Feature f1 : features) {\n      if (f1 !\u003d f) {\n        if (j \u003d\u003d size - 1) {\n          overflow \u003d true;\n          break;\n        } else {\n          arr[j++] \u003d f1;\n        }\n      }\n    }\n\n    if (overflow || j !\u003d size - 1) {\n      throwFeatureNotFoundException(f);\n    }\n    features \u003d arr;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeWithAdditionalFields.java",
      "extendedDetails": {}
    },
    "5fd7230671bb3d90081d4138c364c3f65b35cdbc": {
      "type": "Ymultichange(Ymovefromfile,Yreturntypechange,Ymodifierchange,Ybodychange,Yparameterchange)",
      "commitMessage": "HDFS-5647. Merge INodeDirectory.Feature and INodeFile.Feature. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1550469 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/12/13 10:26 AM",
      "commitName": "5fd7230671bb3d90081d4138c364c3f65b35cdbc",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-5647. Merge INodeDirectory.Feature and INodeFile.Feature. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1550469 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "12/12/13 10:26 AM",
          "commitName": "5fd7230671bb3d90081d4138c364c3f65b35cdbc",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "11/12/13 11:47 PM",
          "commitNameOld": "329093ae1bed3e9cfd20fa425bdc60d88a536e51",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.44,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,30 @@\n-      static \u003cF extends Feature\u003cF\u003e\u003e F removeFeature(F feature, F head) {\n-        if (feature \u003d\u003d head) {\n-          final F newHead \u003d head.getNextFeature();\n-          head.setNextFeature(null);\n-          return newHead;\n-        } else if (head !\u003d null) {\n-          F prev \u003d head;\n-          F curr \u003d head.getNextFeature();\n-          for (; curr !\u003d null \u0026\u0026 curr !\u003d feature;\n-              prev \u003d curr, curr \u003d curr.getNextFeature())\n-            ;\n-          if (curr !\u003d null) {\n-            prev.setNextFeature(curr.getNextFeature());\n-            curr.setNextFeature(null);\n-            return head;\n-          }\n+  protected void removeFeature(Feature f) {\n+    int size \u003d features.length;\n+    Preconditions.checkState(size \u003e 0, \"Feature \"\n+        + f.getClass().getSimpleName() + \" not found.\");\n+\n+    if (size \u003d\u003d 1) {\n+      Preconditions.checkState(features[0] \u003d\u003d f, \"Feature \"\n+          + f.getClass().getSimpleName() + \" not found.\");\n+      features \u003d EMPTY_FEATURE;\n+      return;\n+    }\n+\n+    Feature[] arr \u003d new Feature[size - 1];\n+    int j \u003d 0;\n+    boolean overflow \u003d false;\n+    for (Feature f1 : features) {\n+      if (f1 !\u003d f) {\n+        if (j \u003d\u003d size - 1) {\n+          overflow \u003d true;\n+          break;\n+        } else {\n+          arr[j++] \u003d f1;\n         }\n-        throw new IllegalStateException(\"Feature \" + feature + \" not found.\");\n-      }\n\\ No newline at end of file\n+      }\n+    }\n+\n+    Preconditions.checkState(!overflow \u0026\u0026 j \u003d\u003d size - 1, \"Feature \"\n+        + f.getClass().getSimpleName() + \" not found.\");\n+    features \u003d arr;\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  protected void removeFeature(Feature f) {\n    int size \u003d features.length;\n    Preconditions.checkState(size \u003e 0, \"Feature \"\n        + f.getClass().getSimpleName() + \" not found.\");\n\n    if (size \u003d\u003d 1) {\n      Preconditions.checkState(features[0] \u003d\u003d f, \"Feature \"\n          + f.getClass().getSimpleName() + \" not found.\");\n      features \u003d EMPTY_FEATURE;\n      return;\n    }\n\n    Feature[] arr \u003d new Feature[size - 1];\n    int j \u003d 0;\n    boolean overflow \u003d false;\n    for (Feature f1 : features) {\n      if (f1 !\u003d f) {\n        if (j \u003d\u003d size - 1) {\n          overflow \u003d true;\n          break;\n        } else {\n          arr[j++] \u003d f1;\n        }\n      }\n    }\n\n    Preconditions.checkState(!overflow \u0026\u0026 j \u003d\u003d size - 1, \"Feature \"\n        + f.getClass().getSimpleName() + \" not found.\");\n    features \u003d arr;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeWithAdditionalFields.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INode.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeWithAdditionalFields.java",
            "oldMethodName": "removeFeature",
            "newMethodName": "removeFeature"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-5647. Merge INodeDirectory.Feature and INodeFile.Feature. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1550469 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "12/12/13 10:26 AM",
          "commitName": "5fd7230671bb3d90081d4138c364c3f65b35cdbc",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "11/12/13 11:47 PM",
          "commitNameOld": "329093ae1bed3e9cfd20fa425bdc60d88a536e51",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.44,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,30 @@\n-      static \u003cF extends Feature\u003cF\u003e\u003e F removeFeature(F feature, F head) {\n-        if (feature \u003d\u003d head) {\n-          final F newHead \u003d head.getNextFeature();\n-          head.setNextFeature(null);\n-          return newHead;\n-        } else if (head !\u003d null) {\n-          F prev \u003d head;\n-          F curr \u003d head.getNextFeature();\n-          for (; curr !\u003d null \u0026\u0026 curr !\u003d feature;\n-              prev \u003d curr, curr \u003d curr.getNextFeature())\n-            ;\n-          if (curr !\u003d null) {\n-            prev.setNextFeature(curr.getNextFeature());\n-            curr.setNextFeature(null);\n-            return head;\n-          }\n+  protected void removeFeature(Feature f) {\n+    int size \u003d features.length;\n+    Preconditions.checkState(size \u003e 0, \"Feature \"\n+        + f.getClass().getSimpleName() + \" not found.\");\n+\n+    if (size \u003d\u003d 1) {\n+      Preconditions.checkState(features[0] \u003d\u003d f, \"Feature \"\n+          + f.getClass().getSimpleName() + \" not found.\");\n+      features \u003d EMPTY_FEATURE;\n+      return;\n+    }\n+\n+    Feature[] arr \u003d new Feature[size - 1];\n+    int j \u003d 0;\n+    boolean overflow \u003d false;\n+    for (Feature f1 : features) {\n+      if (f1 !\u003d f) {\n+        if (j \u003d\u003d size - 1) {\n+          overflow \u003d true;\n+          break;\n+        } else {\n+          arr[j++] \u003d f1;\n         }\n-        throw new IllegalStateException(\"Feature \" + feature + \" not found.\");\n-      }\n\\ No newline at end of file\n+      }\n+    }\n+\n+    Preconditions.checkState(!overflow \u0026\u0026 j \u003d\u003d size - 1, \"Feature \"\n+        + f.getClass().getSimpleName() + \" not found.\");\n+    features \u003d arr;\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  protected void removeFeature(Feature f) {\n    int size \u003d features.length;\n    Preconditions.checkState(size \u003e 0, \"Feature \"\n        + f.getClass().getSimpleName() + \" not found.\");\n\n    if (size \u003d\u003d 1) {\n      Preconditions.checkState(features[0] \u003d\u003d f, \"Feature \"\n          + f.getClass().getSimpleName() + \" not found.\");\n      features \u003d EMPTY_FEATURE;\n      return;\n    }\n\n    Feature[] arr \u003d new Feature[size - 1];\n    int j \u003d 0;\n    boolean overflow \u003d false;\n    for (Feature f1 : features) {\n      if (f1 !\u003d f) {\n        if (j \u003d\u003d size - 1) {\n          overflow \u003d true;\n          break;\n        } else {\n          arr[j++] \u003d f1;\n        }\n      }\n    }\n\n    Preconditions.checkState(!overflow \u0026\u0026 j \u003d\u003d size - 1, \"Feature \"\n        + f.getClass().getSimpleName() + \" not found.\");\n    features \u003d arr;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeWithAdditionalFields.java",
          "extendedDetails": {
            "oldValue": "F",
            "newValue": "void"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-5647. Merge INodeDirectory.Feature and INodeFile.Feature. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1550469 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "12/12/13 10:26 AM",
          "commitName": "5fd7230671bb3d90081d4138c364c3f65b35cdbc",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "11/12/13 11:47 PM",
          "commitNameOld": "329093ae1bed3e9cfd20fa425bdc60d88a536e51",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.44,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,30 @@\n-      static \u003cF extends Feature\u003cF\u003e\u003e F removeFeature(F feature, F head) {\n-        if (feature \u003d\u003d head) {\n-          final F newHead \u003d head.getNextFeature();\n-          head.setNextFeature(null);\n-          return newHead;\n-        } else if (head !\u003d null) {\n-          F prev \u003d head;\n-          F curr \u003d head.getNextFeature();\n-          for (; curr !\u003d null \u0026\u0026 curr !\u003d feature;\n-              prev \u003d curr, curr \u003d curr.getNextFeature())\n-            ;\n-          if (curr !\u003d null) {\n-            prev.setNextFeature(curr.getNextFeature());\n-            curr.setNextFeature(null);\n-            return head;\n-          }\n+  protected void removeFeature(Feature f) {\n+    int size \u003d features.length;\n+    Preconditions.checkState(size \u003e 0, \"Feature \"\n+        + f.getClass().getSimpleName() + \" not found.\");\n+\n+    if (size \u003d\u003d 1) {\n+      Preconditions.checkState(features[0] \u003d\u003d f, \"Feature \"\n+          + f.getClass().getSimpleName() + \" not found.\");\n+      features \u003d EMPTY_FEATURE;\n+      return;\n+    }\n+\n+    Feature[] arr \u003d new Feature[size - 1];\n+    int j \u003d 0;\n+    boolean overflow \u003d false;\n+    for (Feature f1 : features) {\n+      if (f1 !\u003d f) {\n+        if (j \u003d\u003d size - 1) {\n+          overflow \u003d true;\n+          break;\n+        } else {\n+          arr[j++] \u003d f1;\n         }\n-        throw new IllegalStateException(\"Feature \" + feature + \" not found.\");\n-      }\n\\ No newline at end of file\n+      }\n+    }\n+\n+    Preconditions.checkState(!overflow \u0026\u0026 j \u003d\u003d size - 1, \"Feature \"\n+        + f.getClass().getSimpleName() + \" not found.\");\n+    features \u003d arr;\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  protected void removeFeature(Feature f) {\n    int size \u003d features.length;\n    Preconditions.checkState(size \u003e 0, \"Feature \"\n        + f.getClass().getSimpleName() + \" not found.\");\n\n    if (size \u003d\u003d 1) {\n      Preconditions.checkState(features[0] \u003d\u003d f, \"Feature \"\n          + f.getClass().getSimpleName() + \" not found.\");\n      features \u003d EMPTY_FEATURE;\n      return;\n    }\n\n    Feature[] arr \u003d new Feature[size - 1];\n    int j \u003d 0;\n    boolean overflow \u003d false;\n    for (Feature f1 : features) {\n      if (f1 !\u003d f) {\n        if (j \u003d\u003d size - 1) {\n          overflow \u003d true;\n          break;\n        } else {\n          arr[j++] \u003d f1;\n        }\n      }\n    }\n\n    Preconditions.checkState(!overflow \u0026\u0026 j \u003d\u003d size - 1, \"Feature \"\n        + f.getClass().getSimpleName() + \" not found.\");\n    features \u003d arr;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeWithAdditionalFields.java",
          "extendedDetails": {
            "oldValue": "[static]",
            "newValue": "[protected]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5647. Merge INodeDirectory.Feature and INodeFile.Feature. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1550469 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "12/12/13 10:26 AM",
          "commitName": "5fd7230671bb3d90081d4138c364c3f65b35cdbc",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "11/12/13 11:47 PM",
          "commitNameOld": "329093ae1bed3e9cfd20fa425bdc60d88a536e51",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.44,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,30 @@\n-      static \u003cF extends Feature\u003cF\u003e\u003e F removeFeature(F feature, F head) {\n-        if (feature \u003d\u003d head) {\n-          final F newHead \u003d head.getNextFeature();\n-          head.setNextFeature(null);\n-          return newHead;\n-        } else if (head !\u003d null) {\n-          F prev \u003d head;\n-          F curr \u003d head.getNextFeature();\n-          for (; curr !\u003d null \u0026\u0026 curr !\u003d feature;\n-              prev \u003d curr, curr \u003d curr.getNextFeature())\n-            ;\n-          if (curr !\u003d null) {\n-            prev.setNextFeature(curr.getNextFeature());\n-            curr.setNextFeature(null);\n-            return head;\n-          }\n+  protected void removeFeature(Feature f) {\n+    int size \u003d features.length;\n+    Preconditions.checkState(size \u003e 0, \"Feature \"\n+        + f.getClass().getSimpleName() + \" not found.\");\n+\n+    if (size \u003d\u003d 1) {\n+      Preconditions.checkState(features[0] \u003d\u003d f, \"Feature \"\n+          + f.getClass().getSimpleName() + \" not found.\");\n+      features \u003d EMPTY_FEATURE;\n+      return;\n+    }\n+\n+    Feature[] arr \u003d new Feature[size - 1];\n+    int j \u003d 0;\n+    boolean overflow \u003d false;\n+    for (Feature f1 : features) {\n+      if (f1 !\u003d f) {\n+        if (j \u003d\u003d size - 1) {\n+          overflow \u003d true;\n+          break;\n+        } else {\n+          arr[j++] \u003d f1;\n         }\n-        throw new IllegalStateException(\"Feature \" + feature + \" not found.\");\n-      }\n\\ No newline at end of file\n+      }\n+    }\n+\n+    Preconditions.checkState(!overflow \u0026\u0026 j \u003d\u003d size - 1, \"Feature \"\n+        + f.getClass().getSimpleName() + \" not found.\");\n+    features \u003d arr;\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  protected void removeFeature(Feature f) {\n    int size \u003d features.length;\n    Preconditions.checkState(size \u003e 0, \"Feature \"\n        + f.getClass().getSimpleName() + \" not found.\");\n\n    if (size \u003d\u003d 1) {\n      Preconditions.checkState(features[0] \u003d\u003d f, \"Feature \"\n          + f.getClass().getSimpleName() + \" not found.\");\n      features \u003d EMPTY_FEATURE;\n      return;\n    }\n\n    Feature[] arr \u003d new Feature[size - 1];\n    int j \u003d 0;\n    boolean overflow \u003d false;\n    for (Feature f1 : features) {\n      if (f1 !\u003d f) {\n        if (j \u003d\u003d size - 1) {\n          overflow \u003d true;\n          break;\n        } else {\n          arr[j++] \u003d f1;\n        }\n      }\n    }\n\n    Preconditions.checkState(!overflow \u0026\u0026 j \u003d\u003d size - 1, \"Feature \"\n        + f.getClass().getSimpleName() + \" not found.\");\n    features \u003d arr;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeWithAdditionalFields.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5647. Merge INodeDirectory.Feature and INodeFile.Feature. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1550469 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "12/12/13 10:26 AM",
          "commitName": "5fd7230671bb3d90081d4138c364c3f65b35cdbc",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "11/12/13 11:47 PM",
          "commitNameOld": "329093ae1bed3e9cfd20fa425bdc60d88a536e51",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.44,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,30 @@\n-      static \u003cF extends Feature\u003cF\u003e\u003e F removeFeature(F feature, F head) {\n-        if (feature \u003d\u003d head) {\n-          final F newHead \u003d head.getNextFeature();\n-          head.setNextFeature(null);\n-          return newHead;\n-        } else if (head !\u003d null) {\n-          F prev \u003d head;\n-          F curr \u003d head.getNextFeature();\n-          for (; curr !\u003d null \u0026\u0026 curr !\u003d feature;\n-              prev \u003d curr, curr \u003d curr.getNextFeature())\n-            ;\n-          if (curr !\u003d null) {\n-            prev.setNextFeature(curr.getNextFeature());\n-            curr.setNextFeature(null);\n-            return head;\n-          }\n+  protected void removeFeature(Feature f) {\n+    int size \u003d features.length;\n+    Preconditions.checkState(size \u003e 0, \"Feature \"\n+        + f.getClass().getSimpleName() + \" not found.\");\n+\n+    if (size \u003d\u003d 1) {\n+      Preconditions.checkState(features[0] \u003d\u003d f, \"Feature \"\n+          + f.getClass().getSimpleName() + \" not found.\");\n+      features \u003d EMPTY_FEATURE;\n+      return;\n+    }\n+\n+    Feature[] arr \u003d new Feature[size - 1];\n+    int j \u003d 0;\n+    boolean overflow \u003d false;\n+    for (Feature f1 : features) {\n+      if (f1 !\u003d f) {\n+        if (j \u003d\u003d size - 1) {\n+          overflow \u003d true;\n+          break;\n+        } else {\n+          arr[j++] \u003d f1;\n         }\n-        throw new IllegalStateException(\"Feature \" + feature + \" not found.\");\n-      }\n\\ No newline at end of file\n+      }\n+    }\n+\n+    Preconditions.checkState(!overflow \u0026\u0026 j \u003d\u003d size - 1, \"Feature \"\n+        + f.getClass().getSimpleName() + \" not found.\");\n+    features \u003d arr;\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  protected void removeFeature(Feature f) {\n    int size \u003d features.length;\n    Preconditions.checkState(size \u003e 0, \"Feature \"\n        + f.getClass().getSimpleName() + \" not found.\");\n\n    if (size \u003d\u003d 1) {\n      Preconditions.checkState(features[0] \u003d\u003d f, \"Feature \"\n          + f.getClass().getSimpleName() + \" not found.\");\n      features \u003d EMPTY_FEATURE;\n      return;\n    }\n\n    Feature[] arr \u003d new Feature[size - 1];\n    int j \u003d 0;\n    boolean overflow \u003d false;\n    for (Feature f1 : features) {\n      if (f1 !\u003d f) {\n        if (j \u003d\u003d size - 1) {\n          overflow \u003d true;\n          break;\n        } else {\n          arr[j++] \u003d f1;\n        }\n      }\n    }\n\n    Preconditions.checkState(!overflow \u0026\u0026 j \u003d\u003d size - 1, \"Feature \"\n        + f.getClass().getSimpleName() + \" not found.\");\n    features \u003d arr;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeWithAdditionalFields.java",
          "extendedDetails": {
            "oldValue": "[feature-F, head-F]",
            "newValue": "[f-Feature]"
          }
        }
      ]
    },
    "82ff2d3f2e569879500d851f4d67dfa2d02b5c9b": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5286. Flatten INodeDirectory hierarchy: Replace INodeDirectoryWithQuota with DirectoryWithQuotaFeature.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1545768 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/11/13 10:33 AM",
      "commitName": "82ff2d3f2e569879500d851f4d67dfa2d02b5c9b",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,19 @@\n+      static \u003cF extends Feature\u003cF\u003e\u003e F removeFeature(F feature, F head) {\n+        if (feature \u003d\u003d head) {\n+          final F newHead \u003d head.getNextFeature();\n+          head.setNextFeature(null);\n+          return newHead;\n+        } else if (head !\u003d null) {\n+          F prev \u003d head;\n+          F curr \u003d head.getNextFeature();\n+          for (; curr !\u003d null \u0026\u0026 curr !\u003d feature;\n+              prev \u003d curr, curr \u003d curr.getNextFeature())\n+            ;\n+          if (curr !\u003d null) {\n+            prev.setNextFeature(curr.getNextFeature());\n+            curr.setNextFeature(null);\n+            return head;\n+          }\n+        }\n+        throw new IllegalStateException(\"Feature \" + feature + \" not found.\");\n+      }\n\\ No newline at end of file\n",
      "actualSource": "      static \u003cF extends Feature\u003cF\u003e\u003e F removeFeature(F feature, F head) {\n        if (feature \u003d\u003d head) {\n          final F newHead \u003d head.getNextFeature();\n          head.setNextFeature(null);\n          return newHead;\n        } else if (head !\u003d null) {\n          F prev \u003d head;\n          F curr \u003d head.getNextFeature();\n          for (; curr !\u003d null \u0026\u0026 curr !\u003d feature;\n              prev \u003d curr, curr \u003d curr.getNextFeature())\n            ;\n          if (curr !\u003d null) {\n            prev.setNextFeature(curr.getNextFeature());\n            curr.setNextFeature(null);\n            return head;\n          }\n        }\n        throw new IllegalStateException(\"Feature \" + feature + \" not found.\");\n      }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INode.java"
    }
  }
}