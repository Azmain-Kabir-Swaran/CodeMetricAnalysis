{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RouterCacheAdmin.java",
  "functionName": "listCacheDirectives",
  "functionId": "listCacheDirectives___prevId-long__filter-CacheDirectiveInfo",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterCacheAdmin.java",
  "functionStartLine": 101,
  "functionEndLine": 121,
  "numCommitsSeen": 1,
  "timeTaken": 708,
  "changeHistory": [
    "9b197c289384d2cd3879f9a464b35ae80aecdf39"
  ],
  "changeHistoryShort": {
    "9b197c289384d2cd3879f9a464b35ae80aecdf39": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9b197c289384d2cd3879f9a464b35ae80aecdf39": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13909. RBF: Add Cache pools and directives related ClientProtocol APIs. Contributed by Ayush Saxena.\n",
      "commitDate": "24/06/19 9:33 AM",
      "commitName": "9b197c289384d2cd3879f9a464b35ae80aecdf39",
      "commitAuthor": "Ayush Saxena",
      "diff": "@@ -0,0 +1,21 @@\n+  public BatchedEntries\u003cCacheDirectiveEntry\u003e listCacheDirectives(long prevId,\n+      CacheDirectiveInfo filter) throws IOException {\n+    rpcServer.checkOperation(NameNode.OperationCategory.READ, true);\n+    if (filter.getPath() !\u003d null) {\n+      final List\u003cRemoteLocation\u003e locations \u003d rpcServer\n+          .getLocationsForPath(filter.getPath().toString(), true, false);\n+      RemoteMethod method \u003d new RemoteMethod(\"listCacheDirectives\",\n+          new Class\u003c?\u003e[] {long.class, CacheDirectiveInfo.class}, prevId,\n+          new RemoteParam(getRemoteMap(filter, locations)));\n+      Map\u003cRemoteLocation, BatchedEntries\u003e response \u003d rpcClient.invokeConcurrent(\n+          locations, method, false, false, BatchedEntries.class);\n+      return response.values().iterator().next();\n+    }\n+    RemoteMethod method \u003d new RemoteMethod(\"listCacheDirectives\",\n+        new Class\u003c?\u003e[] {long.class, CacheDirectiveInfo.class}, prevId,\n+        filter);\n+    Set\u003cFederationNamespaceInfo\u003e nss \u003d namenodeResolver.getNamespaces();\n+    Map\u003cFederationNamespaceInfo, BatchedEntries\u003e results \u003d rpcClient\n+        .invokeConcurrent(nss, method, true, false, BatchedEntries.class);\n+    return results.values().iterator().next();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public BatchedEntries\u003cCacheDirectiveEntry\u003e listCacheDirectives(long prevId,\n      CacheDirectiveInfo filter) throws IOException {\n    rpcServer.checkOperation(NameNode.OperationCategory.READ, true);\n    if (filter.getPath() !\u003d null) {\n      final List\u003cRemoteLocation\u003e locations \u003d rpcServer\n          .getLocationsForPath(filter.getPath().toString(), true, false);\n      RemoteMethod method \u003d new RemoteMethod(\"listCacheDirectives\",\n          new Class\u003c?\u003e[] {long.class, CacheDirectiveInfo.class}, prevId,\n          new RemoteParam(getRemoteMap(filter, locations)));\n      Map\u003cRemoteLocation, BatchedEntries\u003e response \u003d rpcClient.invokeConcurrent(\n          locations, method, false, false, BatchedEntries.class);\n      return response.values().iterator().next();\n    }\n    RemoteMethod method \u003d new RemoteMethod(\"listCacheDirectives\",\n        new Class\u003c?\u003e[] {long.class, CacheDirectiveInfo.class}, prevId,\n        filter);\n    Set\u003cFederationNamespaceInfo\u003e nss \u003d namenodeResolver.getNamespaces();\n    Map\u003cFederationNamespaceInfo, BatchedEntries\u003e results \u003d rpcClient\n        .invokeConcurrent(nss, method, true, false, BatchedEntries.class);\n    return results.values().iterator().next();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterCacheAdmin.java"
    }
  }
}