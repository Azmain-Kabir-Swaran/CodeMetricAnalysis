{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataXceiver.java",
  "functionName": "sendShmSuccessResponse",
  "functionId": "sendShmSuccessResponse___sock-DomainSocket__shmInfo-NewShmInfo",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
  "functionStartLine": 481,
  "functionEndLine": 492,
  "numCommitsSeen": 114,
  "timeTaken": 3691,
  "changeHistory": [
    "778146eaae5b1e17928a1f26fb1e46536a6ee510",
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
    "a0e0a63209b5eb17dca5cc503be36aa52defeabd",
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f"
  ],
  "changeHistoryShort": {
    "778146eaae5b1e17928a1f26fb1e46536a6ee510": "Ybodychange",
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": "Ybodychange",
    "a0e0a63209b5eb17dca5cc503be36aa52defeabd": "Ybodychange",
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "778146eaae5b1e17928a1f26fb1e46536a6ee510": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12658. Clear javadoc and check style issues around DomainSocket. Contributed by Kai Zheng\n",
      "commitDate": "04/01/16 2:32 PM",
      "commitName": "778146eaae5b1e17928a1f26fb1e46536a6ee510",
      "commitAuthor": "Uma Mahesh",
      "commitDateOld": "17/12/15 2:04 PM",
      "commitNameOld": "03bab8dea163a9ee45d09d2a0483d45cf6fe57c9",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 18.02,
      "commitsBetweenForRepo": 62,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   private void sendShmSuccessResponse(DomainSocket sock, NewShmInfo shmInfo)\n       throws IOException {\n     DataNodeFaultInjector.get().sendShortCircuitShmResponse();\n     ShortCircuitShmResponseProto.newBuilder().setStatus(SUCCESS).\n-        setId(PBHelperClient.convert(shmInfo.shmId)).build().\n+        setId(PBHelperClient.convert(shmInfo.getShmId())).build().\n         writeDelimitedTo(socketOut);\n     // Send the file descriptor for the shared memory segment.\n     byte buf[] \u003d new byte[] { (byte)0 };\n     FileDescriptor shmFdArray[] \u003d\n-        new FileDescriptor[] { shmInfo.stream.getFD() };\n+        new FileDescriptor[] {shmInfo.getFileStream().getFD()};\n     sock.sendFileDescriptors(shmFdArray, buf, 0, buf.length);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void sendShmSuccessResponse(DomainSocket sock, NewShmInfo shmInfo)\n      throws IOException {\n    DataNodeFaultInjector.get().sendShortCircuitShmResponse();\n    ShortCircuitShmResponseProto.newBuilder().setStatus(SUCCESS).\n        setId(PBHelperClient.convert(shmInfo.getShmId())).build().\n        writeDelimitedTo(socketOut);\n    // Send the file descriptor for the shared memory segment.\n    byte buf[] \u003d new byte[] { (byte)0 };\n    FileDescriptor shmFdArray[] \u003d\n        new FileDescriptor[] {shmInfo.getFileStream().getFD()};\n    sock.sendFileDescriptors(shmFdArray, buf, 0, buf.length);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8934. Move ShortCircuitShm to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "22/08/15 1:31 PM",
      "commitName": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "19/08/15 11:28 AM",
      "commitNameOld": "3aac4758b007a56e3d66998d457b2156effca528",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 3.09,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   private void sendShmSuccessResponse(DomainSocket sock, NewShmInfo shmInfo)\n       throws IOException {\n     DataNodeFaultInjector.get().sendShortCircuitShmResponse();\n     ShortCircuitShmResponseProto.newBuilder().setStatus(SUCCESS).\n-        setId(PBHelper.convert(shmInfo.shmId)).build().\n+        setId(PBHelperClient.convert(shmInfo.shmId)).build().\n         writeDelimitedTo(socketOut);\n     // Send the file descriptor for the shared memory segment.\n     byte buf[] \u003d new byte[] { (byte)0 };\n     FileDescriptor shmFdArray[] \u003d\n         new FileDescriptor[] { shmInfo.stream.getFD() };\n     sock.sendFileDescriptors(shmFdArray, buf, 0, buf.length);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void sendShmSuccessResponse(DomainSocket sock, NewShmInfo shmInfo)\n      throws IOException {\n    DataNodeFaultInjector.get().sendShortCircuitShmResponse();\n    ShortCircuitShmResponseProto.newBuilder().setStatus(SUCCESS).\n        setId(PBHelperClient.convert(shmInfo.shmId)).build().\n        writeDelimitedTo(socketOut);\n    // Send the file descriptor for the shared memory segment.\n    byte buf[] \u003d new byte[] { (byte)0 };\n    FileDescriptor shmFdArray[] \u003d\n        new FileDescriptor[] { shmInfo.stream.getFD() };\n    sock.sendFileDescriptors(shmFdArray, buf, 0, buf.length);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "a0e0a63209b5eb17dca5cc503be36aa52defeabd": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11802. DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm (cmccabe)\n",
      "commitDate": "23/04/15 7:00 PM",
      "commitName": "a0e0a63209b5eb17dca5cc503be36aa52defeabd",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "10/04/15 4:36 PM",
      "commitNameOld": "36e4cd3be6f7fec8db82d3d1bcb258af470ece2e",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 13.1,
      "commitsBetweenForRepo": 100,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,12 @@\n   private void sendShmSuccessResponse(DomainSocket sock, NewShmInfo shmInfo)\n       throws IOException {\n+    DataNodeFaultInjector.get().sendShortCircuitShmResponse();\n     ShortCircuitShmResponseProto.newBuilder().setStatus(SUCCESS).\n         setId(PBHelper.convert(shmInfo.shmId)).build().\n         writeDelimitedTo(socketOut);\n     // Send the file descriptor for the shared memory segment.\n     byte buf[] \u003d new byte[] { (byte)0 };\n     FileDescriptor shmFdArray[] \u003d\n         new FileDescriptor[] { shmInfo.stream.getFD() };\n     sock.sendFileDescriptors(shmFdArray, buf, 0, buf.length);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void sendShmSuccessResponse(DomainSocket sock, NewShmInfo shmInfo)\n      throws IOException {\n    DataNodeFaultInjector.get().sendShortCircuitShmResponse();\n    ShortCircuitShmResponseProto.newBuilder().setStatus(SUCCESS).\n        setId(PBHelper.convert(shmInfo.shmId)).build().\n        writeDelimitedTo(socketOut);\n    // Send the file descriptor for the shared memory segment.\n    byte buf[] \u003d new byte[] { (byte)0 };\n    FileDescriptor shmFdArray[] \u003d\n        new FileDescriptor[] { shmInfo.stream.getFD() };\n    sock.sendFileDescriptors(shmFdArray, buf, 0, buf.length);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5950. The DFSClient and DataNode should use shared memory segments to communicate short-circuit information (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1573433 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/03/14 7:58 PM",
      "commitName": "dd049a2f6097da189ccce2f5890a2b9bc77fa73f",
      "commitAuthor": "Colin McCabe",
      "diff": "@@ -0,0 +1,11 @@\n+  private void sendShmSuccessResponse(DomainSocket sock, NewShmInfo shmInfo)\n+      throws IOException {\n+    ShortCircuitShmResponseProto.newBuilder().setStatus(SUCCESS).\n+        setId(PBHelper.convert(shmInfo.shmId)).build().\n+        writeDelimitedTo(socketOut);\n+    // Send the file descriptor for the shared memory segment.\n+    byte buf[] \u003d new byte[] { (byte)0 };\n+    FileDescriptor shmFdArray[] \u003d\n+        new FileDescriptor[] { shmInfo.stream.getFD() };\n+    sock.sendFileDescriptors(shmFdArray, buf, 0, buf.length);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void sendShmSuccessResponse(DomainSocket sock, NewShmInfo shmInfo)\n      throws IOException {\n    ShortCircuitShmResponseProto.newBuilder().setStatus(SUCCESS).\n        setId(PBHelper.convert(shmInfo.shmId)).build().\n        writeDelimitedTo(socketOut);\n    // Send the file descriptor for the shared memory segment.\n    byte buf[] \u003d new byte[] { (byte)0 };\n    FileDescriptor shmFdArray[] \u003d\n        new FileDescriptor[] { shmInfo.stream.getFD() };\n    sock.sendFileDescriptors(shmFdArray, buf, 0, buf.length);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java"
    }
  }
}