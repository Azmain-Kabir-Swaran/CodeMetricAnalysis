{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3ABlockOutputStream.java",
  "functionName": "putObject",
  "functionId": "putObject",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
  "functionStartLine": 425,
  "functionEndLine": 463,
  "numCommitsSeen": 18,
  "timeTaken": 4237,
  "changeHistory": [
    "990063d2af0a37e9474949f33128805e34c3f016",
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
    "621b43e254afaff708cd6fc4698b29628f6abc33",
    "a5a4867f3b193a137a6260d539da7e21f02ffab3",
    "dab00da19f25619ccc71c7f803a235b21766bf1e",
    "839b690ed5edc2ac4984640d58c005bb63cd8a07",
    "6c348c56918973fd988b110e79231324a8befe12",
    "c58a59f7081d55dd2108545ebf9ee48cf43ca944",
    "39ec1515a205952eda7e171408a8b83eceb4abde",
    "15b7076ad5f2ae92d231140b2f8cebc392a92c87"
  ],
  "changeHistoryShort": {
    "990063d2af0a37e9474949f33128805e34c3f016": "Ybodychange",
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c": "Ybodychange",
    "621b43e254afaff708cd6fc4698b29628f6abc33": "Ymultichange(Yreturntypechange,Ybodychange)",
    "a5a4867f3b193a137a6260d539da7e21f02ffab3": "Ybodychange",
    "dab00da19f25619ccc71c7f803a235b21766bf1e": "Ybodychange",
    "839b690ed5edc2ac4984640d58c005bb63cd8a07": "Ybodychange",
    "6c348c56918973fd988b110e79231324a8befe12": "Ymultichange(Ymovefromfile,Ybodychange)",
    "c58a59f7081d55dd2108545ebf9ee48cf43ca944": "Ybodychange",
    "39ec1515a205952eda7e171408a8b83eceb4abde": "Ybodychange",
    "15b7076ad5f2ae92d231140b2f8cebc392a92c87": "Yintroduced"
  },
  "changeHistoryDetails": {
    "990063d2af0a37e9474949f33128805e34c3f016": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16665. Filesystems to be closed if they failed during initialize().\n\nContributed by Steve Loughran.\n\nThis FileSystem instantiation so if an IOException or RuntimeException is\nraised in the invocation of FileSystem.initialize() then a best-effort\nattempt is made to close the FS instance; exceptions raised that there\nare swallowed.\n\nThe S3AFileSystem is also modified to do its own cleanup if an\nIOException is raised during its initialize() process, it being the\nFS we know has the \"potential\" to leak threads, especially in\nextension points (e.g AWS Authenticators) which spawn threads.\n\nChange-Id: Ib84073a606c9d53bf53cbfca4629876a03894f04\n",
      "commitDate": "12/11/19 10:17 AM",
      "commitName": "990063d2af0a37e9474949f33128805e34c3f016",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "25/09/19 4:16 AM",
      "commitNameOld": "e346e3638c595a512cd582739ff51fb64c3b4950",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 48.29,
      "commitsBetweenForRepo": 247,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,39 @@\n   private int putObject() throws IOException {\n     LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n \n     final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n     int size \u003d block.dataSize();\n     final S3ADataBlocks.BlockUploadData uploadData \u003d block.startUpload();\n     final PutObjectRequest putObjectRequest \u003d uploadData.hasFile() ?\n         writeOperationHelper.createPutObjectRequest(key, uploadData.getFile())\n         : writeOperationHelper.createPutObjectRequest(key,\n             uploadData.getUploadStream(), size);\n     long transferQueueTime \u003d now();\n     BlockUploadProgress callback \u003d\n         new BlockUploadProgress(\n             block, progressListener, transferQueueTime);\n     putObjectRequest.setGeneralProgressListener(callback);\n     statistics.blockUploadQueued(size);\n     ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n         executorService.submit(() -\u003e {\n           try {\n             // the putObject call automatically closes the input\n             // stream afterwards.\n             return writeOperationHelper.putObject(putObjectRequest);\n           } finally {\n-            closeAll(LOG, uploadData, block);\n+            cleanupWithLogger(LOG, uploadData, block);\n           }\n         });\n     clearActiveBlock();\n     //wait for completion\n     try {\n       putObjectResult.get();\n       return size;\n     } catch (InterruptedException ie) {\n       LOG.warn(\"Interrupted object upload\", ie);\n       Thread.currentThread().interrupt();\n       return 0;\n     } catch (ExecutionException ee) {\n       throw extractException(\"regular upload\", key, ee);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int putObject() throws IOException {\n    LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n\n    final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n    int size \u003d block.dataSize();\n    final S3ADataBlocks.BlockUploadData uploadData \u003d block.startUpload();\n    final PutObjectRequest putObjectRequest \u003d uploadData.hasFile() ?\n        writeOperationHelper.createPutObjectRequest(key, uploadData.getFile())\n        : writeOperationHelper.createPutObjectRequest(key,\n            uploadData.getUploadStream(), size);\n    long transferQueueTime \u003d now();\n    BlockUploadProgress callback \u003d\n        new BlockUploadProgress(\n            block, progressListener, transferQueueTime);\n    putObjectRequest.setGeneralProgressListener(callback);\n    statistics.blockUploadQueued(size);\n    ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n        executorService.submit(() -\u003e {\n          try {\n            // the putObject call automatically closes the input\n            // stream afterwards.\n            return writeOperationHelper.putObject(putObjectRequest);\n          } finally {\n            cleanupWithLogger(LOG, uploadData, block);\n          }\n        });\n    clearActiveBlock();\n    //wait for completion\n    try {\n      putObjectResult.get();\n      return size;\n    } catch (InterruptedException ie) {\n      LOG.warn(\"Interrupted object upload\", ie);\n      Thread.currentThread().interrupt();\n      return 0;\n    } catch (ExecutionException ee) {\n      throw extractException(\"regular upload\", key, ee);\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
      "extendedDetails": {}
    },
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13786 Add S3A committer for zero-rename commits to S3 endpoints.\nContributed by Steve Loughran and Ryan Blue.\n",
      "commitDate": "22/11/17 7:28 AM",
      "commitName": "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "01/09/17 6:13 AM",
      "commitNameOld": "621b43e254afaff708cd6fc4698b29628f6abc33",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 82.09,
      "commitsBetweenForRepo": 710,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,39 @@\n   private int putObject() throws IOException {\n     LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n \n     final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n     int size \u003d block.dataSize();\n     final S3ADataBlocks.BlockUploadData uploadData \u003d block.startUpload();\n     final PutObjectRequest putObjectRequest \u003d uploadData.hasFile() ?\n-        writeOperationHelper.newPutRequest(uploadData.getFile()) :\n-        writeOperationHelper.newPutRequest(uploadData.getUploadStream(), size);\n+        writeOperationHelper.createPutObjectRequest(key, uploadData.getFile())\n+        : writeOperationHelper.createPutObjectRequest(key,\n+            uploadData.getUploadStream(), size);\n     long transferQueueTime \u003d now();\n     BlockUploadProgress callback \u003d\n         new BlockUploadProgress(\n             block, progressListener, transferQueueTime);\n     putObjectRequest.setGeneralProgressListener(callback);\n     statistics.blockUploadQueued(size);\n     ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n-        executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n-          @Override\n-          public PutObjectResult call() throws Exception {\n-            PutObjectResult result;\n-            try {\n-              // the putObject call automatically closes the input\n-              // stream afterwards.\n-              result \u003d writeOperationHelper.putObject(putObjectRequest);\n-            } finally {\n-              closeAll(LOG, uploadData, block);\n-            }\n-            return result;\n+        executorService.submit(() -\u003e {\n+          try {\n+            // the putObject call automatically closes the input\n+            // stream afterwards.\n+            return writeOperationHelper.putObject(putObjectRequest);\n+          } finally {\n+            closeAll(LOG, uploadData, block);\n           }\n         });\n     clearActiveBlock();\n     //wait for completion\n     try {\n       putObjectResult.get();\n       return size;\n     } catch (InterruptedException ie) {\n       LOG.warn(\"Interrupted object upload\", ie);\n       Thread.currentThread().interrupt();\n       return 0;\n     } catch (ExecutionException ee) {\n       throw extractException(\"regular upload\", key, ee);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int putObject() throws IOException {\n    LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n\n    final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n    int size \u003d block.dataSize();\n    final S3ADataBlocks.BlockUploadData uploadData \u003d block.startUpload();\n    final PutObjectRequest putObjectRequest \u003d uploadData.hasFile() ?\n        writeOperationHelper.createPutObjectRequest(key, uploadData.getFile())\n        : writeOperationHelper.createPutObjectRequest(key,\n            uploadData.getUploadStream(), size);\n    long transferQueueTime \u003d now();\n    BlockUploadProgress callback \u003d\n        new BlockUploadProgress(\n            block, progressListener, transferQueueTime);\n    putObjectRequest.setGeneralProgressListener(callback);\n    statistics.blockUploadQueued(size);\n    ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n        executorService.submit(() -\u003e {\n          try {\n            // the putObject call automatically closes the input\n            // stream afterwards.\n            return writeOperationHelper.putObject(putObjectRequest);\n          } finally {\n            closeAll(LOG, uploadData, block);\n          }\n        });\n    clearActiveBlock();\n    //wait for completion\n    try {\n      putObjectResult.get();\n      return size;\n    } catch (InterruptedException ie) {\n      LOG.warn(\"Interrupted object upload\", ie);\n      Thread.currentThread().interrupt();\n      return 0;\n    } catch (ExecutionException ee) {\n      throw extractException(\"regular upload\", key, ee);\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
      "extendedDetails": {}
    },
    "621b43e254afaff708cd6fc4698b29628f6abc33": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HADOOP-13345 HS3Guard: Improved Consistency for S3A.\nContributed by: Chris Nauroth, Aaron Fabbri, Mingliang Liu, Lei (Eddy) Xu,\nSean Mackrory, Steve Loughran and others.\n",
      "commitDate": "01/09/17 6:13 AM",
      "commitName": "621b43e254afaff708cd6fc4698b29628f6abc33",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HADOOP-13345 HS3Guard: Improved Consistency for S3A.\nContributed by: Chris Nauroth, Aaron Fabbri, Mingliang Liu, Lei (Eddy) Xu,\nSean Mackrory, Steve Loughran and others.\n",
          "commitDate": "01/09/17 6:13 AM",
          "commitName": "621b43e254afaff708cd6fc4698b29628f6abc33",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "23/03/17 5:54 AM",
          "commitNameOld": "a5a4867f3b193a137a6260d539da7e21f02ffab3",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 162.01,
          "commitsBetweenForRepo": 999,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,43 @@\n-  private void putObject() throws IOException {\n+  private int putObject() throws IOException {\n     LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n \n     final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n     int size \u003d block.dataSize();\n     final S3ADataBlocks.BlockUploadData uploadData \u003d block.startUpload();\n     final PutObjectRequest putObjectRequest \u003d uploadData.hasFile() ?\n         writeOperationHelper.newPutRequest(uploadData.getFile()) :\n         writeOperationHelper.newPutRequest(uploadData.getUploadStream(), size);\n     long transferQueueTime \u003d now();\n     BlockUploadProgress callback \u003d\n         new BlockUploadProgress(\n             block, progressListener, transferQueueTime);\n     putObjectRequest.setGeneralProgressListener(callback);\n     statistics.blockUploadQueued(size);\n     ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n         executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n           @Override\n           public PutObjectResult call() throws Exception {\n             PutObjectResult result;\n             try {\n               // the putObject call automatically closes the input\n               // stream afterwards.\n               result \u003d writeOperationHelper.putObject(putObjectRequest);\n             } finally {\n               closeAll(LOG, uploadData, block);\n             }\n             return result;\n           }\n         });\n     clearActiveBlock();\n     //wait for completion\n     try {\n       putObjectResult.get();\n+      return size;\n     } catch (InterruptedException ie) {\n       LOG.warn(\"Interrupted object upload\", ie);\n       Thread.currentThread().interrupt();\n+      return 0;\n     } catch (ExecutionException ee) {\n       throw extractException(\"regular upload\", key, ee);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int putObject() throws IOException {\n    LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n\n    final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n    int size \u003d block.dataSize();\n    final S3ADataBlocks.BlockUploadData uploadData \u003d block.startUpload();\n    final PutObjectRequest putObjectRequest \u003d uploadData.hasFile() ?\n        writeOperationHelper.newPutRequest(uploadData.getFile()) :\n        writeOperationHelper.newPutRequest(uploadData.getUploadStream(), size);\n    long transferQueueTime \u003d now();\n    BlockUploadProgress callback \u003d\n        new BlockUploadProgress(\n            block, progressListener, transferQueueTime);\n    putObjectRequest.setGeneralProgressListener(callback);\n    statistics.blockUploadQueued(size);\n    ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n        executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n          @Override\n          public PutObjectResult call() throws Exception {\n            PutObjectResult result;\n            try {\n              // the putObject call automatically closes the input\n              // stream afterwards.\n              result \u003d writeOperationHelper.putObject(putObjectRequest);\n            } finally {\n              closeAll(LOG, uploadData, block);\n            }\n            return result;\n          }\n        });\n    clearActiveBlock();\n    //wait for completion\n    try {\n      putObjectResult.get();\n      return size;\n    } catch (InterruptedException ie) {\n      LOG.warn(\"Interrupted object upload\", ie);\n      Thread.currentThread().interrupt();\n      return 0;\n    } catch (ExecutionException ee) {\n      throw extractException(\"regular upload\", key, ee);\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
          "extendedDetails": {
            "oldValue": "void",
            "newValue": "int"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-13345 HS3Guard: Improved Consistency for S3A.\nContributed by: Chris Nauroth, Aaron Fabbri, Mingliang Liu, Lei (Eddy) Xu,\nSean Mackrory, Steve Loughran and others.\n",
          "commitDate": "01/09/17 6:13 AM",
          "commitName": "621b43e254afaff708cd6fc4698b29628f6abc33",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "23/03/17 5:54 AM",
          "commitNameOld": "a5a4867f3b193a137a6260d539da7e21f02ffab3",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 162.01,
          "commitsBetweenForRepo": 999,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,41 +1,43 @@\n-  private void putObject() throws IOException {\n+  private int putObject() throws IOException {\n     LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n \n     final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n     int size \u003d block.dataSize();\n     final S3ADataBlocks.BlockUploadData uploadData \u003d block.startUpload();\n     final PutObjectRequest putObjectRequest \u003d uploadData.hasFile() ?\n         writeOperationHelper.newPutRequest(uploadData.getFile()) :\n         writeOperationHelper.newPutRequest(uploadData.getUploadStream(), size);\n     long transferQueueTime \u003d now();\n     BlockUploadProgress callback \u003d\n         new BlockUploadProgress(\n             block, progressListener, transferQueueTime);\n     putObjectRequest.setGeneralProgressListener(callback);\n     statistics.blockUploadQueued(size);\n     ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n         executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n           @Override\n           public PutObjectResult call() throws Exception {\n             PutObjectResult result;\n             try {\n               // the putObject call automatically closes the input\n               // stream afterwards.\n               result \u003d writeOperationHelper.putObject(putObjectRequest);\n             } finally {\n               closeAll(LOG, uploadData, block);\n             }\n             return result;\n           }\n         });\n     clearActiveBlock();\n     //wait for completion\n     try {\n       putObjectResult.get();\n+      return size;\n     } catch (InterruptedException ie) {\n       LOG.warn(\"Interrupted object upload\", ie);\n       Thread.currentThread().interrupt();\n+      return 0;\n     } catch (ExecutionException ee) {\n       throw extractException(\"regular upload\", key, ee);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int putObject() throws IOException {\n    LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n\n    final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n    int size \u003d block.dataSize();\n    final S3ADataBlocks.BlockUploadData uploadData \u003d block.startUpload();\n    final PutObjectRequest putObjectRequest \u003d uploadData.hasFile() ?\n        writeOperationHelper.newPutRequest(uploadData.getFile()) :\n        writeOperationHelper.newPutRequest(uploadData.getUploadStream(), size);\n    long transferQueueTime \u003d now();\n    BlockUploadProgress callback \u003d\n        new BlockUploadProgress(\n            block, progressListener, transferQueueTime);\n    putObjectRequest.setGeneralProgressListener(callback);\n    statistics.blockUploadQueued(size);\n    ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n        executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n          @Override\n          public PutObjectResult call() throws Exception {\n            PutObjectResult result;\n            try {\n              // the putObject call automatically closes the input\n              // stream afterwards.\n              result \u003d writeOperationHelper.putObject(putObjectRequest);\n            } finally {\n              closeAll(LOG, uploadData, block);\n            }\n            return result;\n          }\n        });\n    clearActiveBlock();\n    //wait for completion\n    try {\n      putObjectResult.get();\n      return size;\n    } catch (InterruptedException ie) {\n      LOG.warn(\"Interrupted object upload\", ie);\n      Thread.currentThread().interrupt();\n      return 0;\n    } catch (ExecutionException ee) {\n      throw extractException(\"regular upload\", key, ee);\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "a5a4867f3b193a137a6260d539da7e21f02ffab3": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14120 needless S3AFileSystem.setOptionalPutRequestParameters in S3ABlockOutputStream putObject().\nContributed by Yuanbo Liu\n\n(cherry picked from commit 20878d052cebc715c2494a97362fdff08885a77f)\n",
      "commitDate": "23/03/17 5:54 AM",
      "commitName": "a5a4867f3b193a137a6260d539da7e21f02ffab3",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "25/02/17 7:35 AM",
      "commitNameOld": "dab00da19f25619ccc71c7f803a235b21766bf1e",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 25.89,
      "commitsBetweenForRepo": 148,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,42 +1,41 @@\n   private void putObject() throws IOException {\n     LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n \n     final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n     int size \u003d block.dataSize();\n     final S3ADataBlocks.BlockUploadData uploadData \u003d block.startUpload();\n     final PutObjectRequest putObjectRequest \u003d uploadData.hasFile() ?\n-        writeOperationHelper.newPutRequest(uploadData.getFile())\n-        : writeOperationHelper.newPutRequest(uploadData.getUploadStream(), size);\n-    fs.setOptionalPutRequestParameters(putObjectRequest);\n+        writeOperationHelper.newPutRequest(uploadData.getFile()) :\n+        writeOperationHelper.newPutRequest(uploadData.getUploadStream(), size);\n     long transferQueueTime \u003d now();\n     BlockUploadProgress callback \u003d\n         new BlockUploadProgress(\n             block, progressListener, transferQueueTime);\n     putObjectRequest.setGeneralProgressListener(callback);\n     statistics.blockUploadQueued(size);\n     ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n         executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n           @Override\n           public PutObjectResult call() throws Exception {\n             PutObjectResult result;\n             try {\n               // the putObject call automatically closes the input\n               // stream afterwards.\n               result \u003d writeOperationHelper.putObject(putObjectRequest);\n             } finally {\n               closeAll(LOG, uploadData, block);\n             }\n             return result;\n           }\n         });\n     clearActiveBlock();\n     //wait for completion\n     try {\n       putObjectResult.get();\n     } catch (InterruptedException ie) {\n       LOG.warn(\"Interrupted object upload\", ie);\n       Thread.currentThread().interrupt();\n     } catch (ExecutionException ee) {\n       throw extractException(\"regular upload\", key, ee);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void putObject() throws IOException {\n    LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n\n    final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n    int size \u003d block.dataSize();\n    final S3ADataBlocks.BlockUploadData uploadData \u003d block.startUpload();\n    final PutObjectRequest putObjectRequest \u003d uploadData.hasFile() ?\n        writeOperationHelper.newPutRequest(uploadData.getFile()) :\n        writeOperationHelper.newPutRequest(uploadData.getUploadStream(), size);\n    long transferQueueTime \u003d now();\n    BlockUploadProgress callback \u003d\n        new BlockUploadProgress(\n            block, progressListener, transferQueueTime);\n    putObjectRequest.setGeneralProgressListener(callback);\n    statistics.blockUploadQueued(size);\n    ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n        executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n          @Override\n          public PutObjectResult call() throws Exception {\n            PutObjectResult result;\n            try {\n              // the putObject call automatically closes the input\n              // stream afterwards.\n              result \u003d writeOperationHelper.putObject(putObjectRequest);\n            } finally {\n              closeAll(LOG, uploadData, block);\n            }\n            return result;\n          }\n        });\n    clearActiveBlock();\n    //wait for completion\n    try {\n      putObjectResult.get();\n    } catch (InterruptedException ie) {\n      LOG.warn(\"Interrupted object upload\", ie);\n      Thread.currentThread().interrupt();\n    } catch (ExecutionException ee) {\n      throw extractException(\"regular upload\", key, ee);\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
      "extendedDetails": {}
    },
    "dab00da19f25619ccc71c7f803a235b21766bf1e": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14028. S3A BlockOutputStreams doesn\u0027t delete temporary files in multipart uploads or handle part upload failures.\nContributed by Steve Loughran.\n\n(cherry picked from commit 29fe5af017b945d8750c074ca39031b5b777eddd)\n",
      "commitDate": "25/02/17 7:35 AM",
      "commitName": "dab00da19f25619ccc71c7f803a235b21766bf1e",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "11/02/17 1:59 PM",
      "commitNameOld": "839b690ed5edc2ac4984640d58c005bb63cd8a07",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 13.73,
      "commitsBetweenForRepo": 86,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,42 @@\n   private void putObject() throws IOException {\n     LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n \n     final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n     int size \u003d block.dataSize();\n-    final PutObjectRequest putObjectRequest \u003d\n-        writeOperationHelper.newPutRequest(\n-            block.startUpload(),\n-            size);\n+    final S3ADataBlocks.BlockUploadData uploadData \u003d block.startUpload();\n+    final PutObjectRequest putObjectRequest \u003d uploadData.hasFile() ?\n+        writeOperationHelper.newPutRequest(uploadData.getFile())\n+        : writeOperationHelper.newPutRequest(uploadData.getUploadStream(), size);\n     fs.setOptionalPutRequestParameters(putObjectRequest);\n     long transferQueueTime \u003d now();\n     BlockUploadProgress callback \u003d\n         new BlockUploadProgress(\n             block, progressListener, transferQueueTime);\n     putObjectRequest.setGeneralProgressListener(callback);\n     statistics.blockUploadQueued(size);\n     ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n         executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n           @Override\n           public PutObjectResult call() throws Exception {\n-            PutObjectResult result \u003d fs.putObjectDirect(putObjectRequest);\n-            block.close();\n+            PutObjectResult result;\n+            try {\n+              // the putObject call automatically closes the input\n+              // stream afterwards.\n+              result \u003d writeOperationHelper.putObject(putObjectRequest);\n+            } finally {\n+              closeAll(LOG, uploadData, block);\n+            }\n             return result;\n           }\n         });\n     clearActiveBlock();\n     //wait for completion\n     try {\n       putObjectResult.get();\n     } catch (InterruptedException ie) {\n       LOG.warn(\"Interrupted object upload\", ie);\n       Thread.currentThread().interrupt();\n     } catch (ExecutionException ee) {\n       throw extractException(\"regular upload\", key, ee);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void putObject() throws IOException {\n    LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n\n    final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n    int size \u003d block.dataSize();\n    final S3ADataBlocks.BlockUploadData uploadData \u003d block.startUpload();\n    final PutObjectRequest putObjectRequest \u003d uploadData.hasFile() ?\n        writeOperationHelper.newPutRequest(uploadData.getFile())\n        : writeOperationHelper.newPutRequest(uploadData.getUploadStream(), size);\n    fs.setOptionalPutRequestParameters(putObjectRequest);\n    long transferQueueTime \u003d now();\n    BlockUploadProgress callback \u003d\n        new BlockUploadProgress(\n            block, progressListener, transferQueueTime);\n    putObjectRequest.setGeneralProgressListener(callback);\n    statistics.blockUploadQueued(size);\n    ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n        executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n          @Override\n          public PutObjectResult call() throws Exception {\n            PutObjectResult result;\n            try {\n              // the putObject call automatically closes the input\n              // stream afterwards.\n              result \u003d writeOperationHelper.putObject(putObjectRequest);\n            } finally {\n              closeAll(LOG, uploadData, block);\n            }\n            return result;\n          }\n        });\n    clearActiveBlock();\n    //wait for completion\n    try {\n      putObjectResult.get();\n    } catch (InterruptedException ie) {\n      LOG.warn(\"Interrupted object upload\", ie);\n      Thread.currentThread().interrupt();\n    } catch (ExecutionException ee) {\n      throw extractException(\"regular upload\", key, ee);\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
      "extendedDetails": {}
    },
    "839b690ed5edc2ac4984640d58c005bb63cd8a07": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13075. Add support for SSE-KMS and SSE-C in s3a filesystem. (Steve Moist via lei)\n",
      "commitDate": "11/02/17 1:59 PM",
      "commitName": "839b690ed5edc2ac4984640d58c005bb63cd8a07",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "18/10/16 1:16 PM",
      "commitNameOld": "6c348c56918973fd988b110e79231324a8befe12",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 116.07,
      "commitsBetweenForRepo": 713,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,36 @@\n   private void putObject() throws IOException {\n     LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n \n     final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n     int size \u003d block.dataSize();\n     final PutObjectRequest putObjectRequest \u003d\n         writeOperationHelper.newPutRequest(\n             block.startUpload(),\n             size);\n+    fs.setOptionalPutRequestParameters(putObjectRequest);\n     long transferQueueTime \u003d now();\n     BlockUploadProgress callback \u003d\n         new BlockUploadProgress(\n             block, progressListener, transferQueueTime);\n     putObjectRequest.setGeneralProgressListener(callback);\n     statistics.blockUploadQueued(size);\n     ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n         executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n           @Override\n           public PutObjectResult call() throws Exception {\n             PutObjectResult result \u003d fs.putObjectDirect(putObjectRequest);\n             block.close();\n             return result;\n           }\n         });\n     clearActiveBlock();\n     //wait for completion\n     try {\n       putObjectResult.get();\n     } catch (InterruptedException ie) {\n       LOG.warn(\"Interrupted object upload\", ie);\n       Thread.currentThread().interrupt();\n     } catch (ExecutionException ee) {\n       throw extractException(\"regular upload\", key, ee);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void putObject() throws IOException {\n    LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n\n    final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n    int size \u003d block.dataSize();\n    final PutObjectRequest putObjectRequest \u003d\n        writeOperationHelper.newPutRequest(\n            block.startUpload(),\n            size);\n    fs.setOptionalPutRequestParameters(putObjectRequest);\n    long transferQueueTime \u003d now();\n    BlockUploadProgress callback \u003d\n        new BlockUploadProgress(\n            block, progressListener, transferQueueTime);\n    putObjectRequest.setGeneralProgressListener(callback);\n    statistics.blockUploadQueued(size);\n    ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n        executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n          @Override\n          public PutObjectResult call() throws Exception {\n            PutObjectResult result \u003d fs.putObjectDirect(putObjectRequest);\n            block.close();\n            return result;\n          }\n        });\n    clearActiveBlock();\n    //wait for completion\n    try {\n      putObjectResult.get();\n    } catch (InterruptedException ie) {\n      LOG.warn(\"Interrupted object upload\", ie);\n      Thread.currentThread().interrupt();\n    } catch (ExecutionException ee) {\n      throw extractException(\"regular upload\", key, ee);\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
      "extendedDetails": {}
    },
    "6c348c56918973fd988b110e79231324a8befe12": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HADOOP-13560. S3ABlockOutputStream to support huge (many GB) file writes. Contributed by Steve Loughran\n",
      "commitDate": "18/10/16 1:16 PM",
      "commitName": "6c348c56918973fd988b110e79231324a8befe12",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HADOOP-13560. S3ABlockOutputStream to support huge (many GB) file writes. Contributed by Steve Loughran\n",
          "commitDate": "18/10/16 1:16 PM",
          "commitName": "6c348c56918973fd988b110e79231324a8befe12",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "18/10/16 11:06 AM",
          "commitNameOld": "b733a6f86262522e535cebc972baecbe6a6eab50",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 0.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,35 @@\n   private void putObject() throws IOException {\n-    LOG.debug(\"Executing regular upload for bucket \u0027{}\u0027 key \u0027{}\u0027\",\n-        bucket, key);\n-    final ObjectMetadata om \u003d createDefaultMetadata();\n-    final int size \u003d buffer.size();\n-    om.setContentLength(size);\n+    LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n+\n+    final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n+    int size \u003d block.dataSize();\n     final PutObjectRequest putObjectRequest \u003d\n-        fs.newPutObjectRequest(key,\n-            om,\n-            new ByteArrayInputStream(buffer.toByteArray()));\n-    putObjectRequest.setGeneralProgressListener(progressListener);\n+        writeOperationHelper.newPutRequest(\n+            block.startUpload(),\n+            size);\n+    long transferQueueTime \u003d now();\n+    BlockUploadProgress callback \u003d\n+        new BlockUploadProgress(\n+            block, progressListener, transferQueueTime);\n+    putObjectRequest.setGeneralProgressListener(callback);\n+    statistics.blockUploadQueued(size);\n     ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n         executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n           @Override\n           public PutObjectResult call() throws Exception {\n-            fs.incrementPutStartStatistics(size);\n-            return client.putObject(putObjectRequest);\n+            PutObjectResult result \u003d fs.putObjectDirect(putObjectRequest);\n+            block.close();\n+            return result;\n           }\n         });\n+    clearActiveBlock();\n     //wait for completion\n     try {\n       putObjectResult.get();\n     } catch (InterruptedException ie) {\n-      LOG.warn(\"Interrupted object upload: {}\", ie, ie);\n+      LOG.warn(\"Interrupted object upload\", ie);\n       Thread.currentThread().interrupt();\n     } catch (ExecutionException ee) {\n       throw extractException(\"regular upload\", key, ee);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void putObject() throws IOException {\n    LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n\n    final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n    int size \u003d block.dataSize();\n    final PutObjectRequest putObjectRequest \u003d\n        writeOperationHelper.newPutRequest(\n            block.startUpload(),\n            size);\n    long transferQueueTime \u003d now();\n    BlockUploadProgress callback \u003d\n        new BlockUploadProgress(\n            block, progressListener, transferQueueTime);\n    putObjectRequest.setGeneralProgressListener(callback);\n    statistics.blockUploadQueued(size);\n    ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n        executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n          @Override\n          public PutObjectResult call() throws Exception {\n            PutObjectResult result \u003d fs.putObjectDirect(putObjectRequest);\n            block.close();\n            return result;\n          }\n        });\n    clearActiveBlock();\n    //wait for completion\n    try {\n      putObjectResult.get();\n    } catch (InterruptedException ie) {\n      LOG.warn(\"Interrupted object upload\", ie);\n      Thread.currentThread().interrupt();\n    } catch (ExecutionException ee) {\n      throw extractException(\"regular upload\", key, ee);\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
          "extendedDetails": {
            "oldPath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java",
            "newPath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
            "oldMethodName": "putObject",
            "newMethodName": "putObject"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-13560. S3ABlockOutputStream to support huge (many GB) file writes. Contributed by Steve Loughran\n",
          "commitDate": "18/10/16 1:16 PM",
          "commitName": "6c348c56918973fd988b110e79231324a8befe12",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "18/10/16 11:06 AM",
          "commitNameOld": "b733a6f86262522e535cebc972baecbe6a6eab50",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 0.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,35 @@\n   private void putObject() throws IOException {\n-    LOG.debug(\"Executing regular upload for bucket \u0027{}\u0027 key \u0027{}\u0027\",\n-        bucket, key);\n-    final ObjectMetadata om \u003d createDefaultMetadata();\n-    final int size \u003d buffer.size();\n-    om.setContentLength(size);\n+    LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n+\n+    final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n+    int size \u003d block.dataSize();\n     final PutObjectRequest putObjectRequest \u003d\n-        fs.newPutObjectRequest(key,\n-            om,\n-            new ByteArrayInputStream(buffer.toByteArray()));\n-    putObjectRequest.setGeneralProgressListener(progressListener);\n+        writeOperationHelper.newPutRequest(\n+            block.startUpload(),\n+            size);\n+    long transferQueueTime \u003d now();\n+    BlockUploadProgress callback \u003d\n+        new BlockUploadProgress(\n+            block, progressListener, transferQueueTime);\n+    putObjectRequest.setGeneralProgressListener(callback);\n+    statistics.blockUploadQueued(size);\n     ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n         executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n           @Override\n           public PutObjectResult call() throws Exception {\n-            fs.incrementPutStartStatistics(size);\n-            return client.putObject(putObjectRequest);\n+            PutObjectResult result \u003d fs.putObjectDirect(putObjectRequest);\n+            block.close();\n+            return result;\n           }\n         });\n+    clearActiveBlock();\n     //wait for completion\n     try {\n       putObjectResult.get();\n     } catch (InterruptedException ie) {\n-      LOG.warn(\"Interrupted object upload: {}\", ie, ie);\n+      LOG.warn(\"Interrupted object upload\", ie);\n       Thread.currentThread().interrupt();\n     } catch (ExecutionException ee) {\n       throw extractException(\"regular upload\", key, ee);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void putObject() throws IOException {\n    LOG.debug(\"Executing regular upload for {}\", writeOperationHelper);\n\n    final S3ADataBlocks.DataBlock block \u003d getActiveBlock();\n    int size \u003d block.dataSize();\n    final PutObjectRequest putObjectRequest \u003d\n        writeOperationHelper.newPutRequest(\n            block.startUpload(),\n            size);\n    long transferQueueTime \u003d now();\n    BlockUploadProgress callback \u003d\n        new BlockUploadProgress(\n            block, progressListener, transferQueueTime);\n    putObjectRequest.setGeneralProgressListener(callback);\n    statistics.blockUploadQueued(size);\n    ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n        executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n          @Override\n          public PutObjectResult call() throws Exception {\n            PutObjectResult result \u003d fs.putObjectDirect(putObjectRequest);\n            block.close();\n            return result;\n          }\n        });\n    clearActiveBlock();\n    //wait for completion\n    try {\n      putObjectResult.get();\n    } catch (InterruptedException ie) {\n      LOG.warn(\"Interrupted object upload\", ie);\n      Thread.currentThread().interrupt();\n    } catch (ExecutionException ee) {\n      throw extractException(\"regular upload\", key, ee);\n    }\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "c58a59f7081d55dd2108545ebf9ee48cf43ca944": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13171. Add StorageStatistics to S3A; instrument some more operations. Contributed by Steve Loughran.\n",
      "commitDate": "03/06/16 8:55 AM",
      "commitName": "c58a59f7081d55dd2108545ebf9ee48cf43ca944",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "21/05/16 8:39 AM",
      "commitNameOld": "39ec1515a205952eda7e171408a8b83eceb4abde",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 13.01,
      "commitsBetweenForRepo": 75,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,29 @@\n   private void putObject() throws IOException {\n     LOG.debug(\"Executing regular upload for bucket \u0027{}\u0027 key \u0027{}\u0027\",\n         bucket, key);\n     final ObjectMetadata om \u003d createDefaultMetadata();\n-    om.setContentLength(buffer.size());\n-    final PutObjectRequest putObjectRequest \u003d new PutObjectRequest(bucket, key,\n-        new ByteArrayInputStream(buffer.toByteArray()), om);\n-    putObjectRequest.setCannedAcl(cannedACL);\n+    final int size \u003d buffer.size();\n+    om.setContentLength(size);\n+    final PutObjectRequest putObjectRequest \u003d\n+        fs.newPutObjectRequest(key,\n+            om,\n+            new ByteArrayInputStream(buffer.toByteArray()));\n     putObjectRequest.setGeneralProgressListener(progressListener);\n     ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n         executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n           @Override\n           public PutObjectResult call() throws Exception {\n+            fs.incrementPutStartStatistics(size);\n             return client.putObject(putObjectRequest);\n           }\n         });\n     //wait for completion\n     try {\n       putObjectResult.get();\n     } catch (InterruptedException ie) {\n-      LOG.warn(\"Interrupted object upload:\" + ie, ie);\n+      LOG.warn(\"Interrupted object upload: {}\", ie, ie);\n       Thread.currentThread().interrupt();\n     } catch (ExecutionException ee) {\n       throw extractException(\"regular upload\", key, ee);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void putObject() throws IOException {\n    LOG.debug(\"Executing regular upload for bucket \u0027{}\u0027 key \u0027{}\u0027\",\n        bucket, key);\n    final ObjectMetadata om \u003d createDefaultMetadata();\n    final int size \u003d buffer.size();\n    om.setContentLength(size);\n    final PutObjectRequest putObjectRequest \u003d\n        fs.newPutObjectRequest(key,\n            om,\n            new ByteArrayInputStream(buffer.toByteArray()));\n    putObjectRequest.setGeneralProgressListener(progressListener);\n    ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n        executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n          @Override\n          public PutObjectResult call() throws Exception {\n            fs.incrementPutStartStatistics(size);\n            return client.putObject(putObjectRequest);\n          }\n        });\n    //wait for completion\n    try {\n      putObjectResult.get();\n    } catch (InterruptedException ie) {\n      LOG.warn(\"Interrupted object upload: {}\", ie, ie);\n      Thread.currentThread().interrupt();\n    } catch (ExecutionException ee) {\n      throw extractException(\"regular upload\", key, ee);\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java",
      "extendedDetails": {}
    },
    "39ec1515a205952eda7e171408a8b83eceb4abde": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13130. s3a failures can surface as RTEs, not IOEs. (Steve Loughran)\n",
      "commitDate": "21/05/16 8:39 AM",
      "commitName": "39ec1515a205952eda7e171408a8b83eceb4abde",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "12/05/16 11:24 AM",
      "commitNameOld": "27c4e90efce04e1b1302f668b5eb22412e00d033",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 8.89,
      "commitsBetweenForRepo": 74,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,26 @@\n   private void putObject() throws IOException {\n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"Executing regular upload for bucket \u0027{}\u0027 key \u0027{}\u0027\", bucket,\n-          key);\n-    }\n+    LOG.debug(\"Executing regular upload for bucket \u0027{}\u0027 key \u0027{}\u0027\",\n+        bucket, key);\n     final ObjectMetadata om \u003d createDefaultMetadata();\n     om.setContentLength(buffer.size());\n     final PutObjectRequest putObjectRequest \u003d new PutObjectRequest(bucket, key,\n         new ByteArrayInputStream(buffer.toByteArray()), om);\n     putObjectRequest.setCannedAcl(cannedACL);\n     putObjectRequest.setGeneralProgressListener(progressListener);\n     ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n         executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n           @Override\n           public PutObjectResult call() throws Exception {\n             return client.putObject(putObjectRequest);\n           }\n         });\n     //wait for completion\n     try {\n       putObjectResult.get();\n     } catch (InterruptedException ie) {\n       LOG.warn(\"Interrupted object upload:\" + ie, ie);\n       Thread.currentThread().interrupt();\n     } catch (ExecutionException ee) {\n-      throw new IOException(\"Regular upload failed\", ee.getCause());\n+      throw extractException(\"regular upload\", key, ee);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void putObject() throws IOException {\n    LOG.debug(\"Executing regular upload for bucket \u0027{}\u0027 key \u0027{}\u0027\",\n        bucket, key);\n    final ObjectMetadata om \u003d createDefaultMetadata();\n    om.setContentLength(buffer.size());\n    final PutObjectRequest putObjectRequest \u003d new PutObjectRequest(bucket, key,\n        new ByteArrayInputStream(buffer.toByteArray()), om);\n    putObjectRequest.setCannedAcl(cannedACL);\n    putObjectRequest.setGeneralProgressListener(progressListener);\n    ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n        executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n          @Override\n          public PutObjectResult call() throws Exception {\n            return client.putObject(putObjectRequest);\n          }\n        });\n    //wait for completion\n    try {\n      putObjectResult.get();\n    } catch (InterruptedException ie) {\n      LOG.warn(\"Interrupted object upload:\" + ie, ie);\n      Thread.currentThread().interrupt();\n    } catch (ExecutionException ee) {\n      throw extractException(\"regular upload\", key, ee);\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java",
      "extendedDetails": {}
    },
    "15b7076ad5f2ae92d231140b2f8cebc392a92c87": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-11183. Memory-based S3AOutputstream. (Thomas Demoor via stevel)\n",
      "commitDate": "03/03/15 4:18 PM",
      "commitName": "15b7076ad5f2ae92d231140b2f8cebc392a92c87",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,28 @@\n+  private void putObject() throws IOException {\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Executing regular upload for bucket \u0027{}\u0027 key \u0027{}\u0027\", bucket,\n+          key);\n+    }\n+    final ObjectMetadata om \u003d createDefaultMetadata();\n+    om.setContentLength(buffer.size());\n+    final PutObjectRequest putObjectRequest \u003d new PutObjectRequest(bucket, key,\n+        new ByteArrayInputStream(buffer.toByteArray()), om);\n+    putObjectRequest.setCannedAcl(cannedACL);\n+    putObjectRequest.setGeneralProgressListener(progressListener);\n+    ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n+        executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n+          @Override\n+          public PutObjectResult call() throws Exception {\n+            return client.putObject(putObjectRequest);\n+          }\n+        });\n+    //wait for completion\n+    try {\n+      putObjectResult.get();\n+    } catch (InterruptedException ie) {\n+      LOG.warn(\"Interrupted object upload:\" + ie, ie);\n+      Thread.currentThread().interrupt();\n+    } catch (ExecutionException ee) {\n+      throw new IOException(\"Regular upload failed\", ee.getCause());\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void putObject() throws IOException {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Executing regular upload for bucket \u0027{}\u0027 key \u0027{}\u0027\", bucket,\n          key);\n    }\n    final ObjectMetadata om \u003d createDefaultMetadata();\n    om.setContentLength(buffer.size());\n    final PutObjectRequest putObjectRequest \u003d new PutObjectRequest(bucket, key,\n        new ByteArrayInputStream(buffer.toByteArray()), om);\n    putObjectRequest.setCannedAcl(cannedACL);\n    putObjectRequest.setGeneralProgressListener(progressListener);\n    ListenableFuture\u003cPutObjectResult\u003e putObjectResult \u003d\n        executorService.submit(new Callable\u003cPutObjectResult\u003e() {\n          @Override\n          public PutObjectResult call() throws Exception {\n            return client.putObject(putObjectRequest);\n          }\n        });\n    //wait for completion\n    try {\n      putObjectResult.get();\n    } catch (InterruptedException ie) {\n      LOG.warn(\"Interrupted object upload:\" + ie, ie);\n      Thread.currentThread().interrupt();\n    } catch (ExecutionException ee) {\n      throw new IOException(\"Regular upload failed\", ee.getCause());\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java"
    }
  }
}