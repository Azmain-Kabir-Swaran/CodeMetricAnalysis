{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JobResourceUploader.java",
  "functionName": "checkLocalizationLimits",
  "functionId": "checkLocalizationLimits___conf-Configuration__files-Collection__String____libjars-Collection__String____archives-Collection__String____jobJar-String__statCache-Map__URI,FileStatus__",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/JobResourceUploader.java",
  "functionStartLine": 494,
  "functionEndLine": 533,
  "numCommitsSeen": 17,
  "timeTaken": 1387,
  "changeHistory": [
    "ceab00ac62f8057a07b4b936799e6f04271e6e41",
    "f80a7298325a4626638ee24467e2012442e480d4"
  ],
  "changeHistoryShort": {
    "ceab00ac62f8057a07b4b936799e6f04271e6e41": "Ybodychange",
    "f80a7298325a4626638ee24467e2012442e480d4": "Yintroduced"
  },
  "changeHistoryDetails": {
    "ceab00ac62f8057a07b4b936799e6f04271e6e41": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6862. Fragments are not handled correctly by resource limit checking. (Chris Trezzo via mingma)\n",
      "commitDate": "29/03/17 5:41 PM",
      "commitName": "ceab00ac62f8057a07b4b936799e6f04271e6e41",
      "commitAuthor": "Ming Ma",
      "commitDateOld": "15/11/16 10:57 AM",
      "commitNameOld": "5af572b6443715b7a741296c1bd520a1840f9a7c",
      "commitAuthorOld": "Mingliang Liu",
      "daysBetweenCommits": 134.24,
      "commitsBetweenForRepo": 721,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,40 @@\n   void checkLocalizationLimits(Configuration conf, Collection\u003cString\u003e files,\n       Collection\u003cString\u003e libjars, Collection\u003cString\u003e archives, String jobJar,\n       Map\u003cURI, FileStatus\u003e statCache) throws IOException {\n \n     LimitChecker limitChecker \u003d new LimitChecker(conf);\n     if (!limitChecker.hasLimits()) {\n       // there are no limits set, so we are done.\n       return;\n     }\n \n     // Get the files and archives that are already in the distributed cache\n     Collection\u003cString\u003e dcFiles \u003d\n         conf.getStringCollection(MRJobConfig.CACHE_FILES);\n     Collection\u003cString\u003e dcArchives \u003d\n         conf.getStringCollection(MRJobConfig.CACHE_ARCHIVES);\n \n-    for (String path : dcFiles) {\n-      explorePath(conf, new Path(path), limitChecker, statCache);\n+    for (String uri : dcFiles) {\n+      explorePath(conf, stringToPath(uri), limitChecker, statCache);\n     }\n \n-    for (String path : dcArchives) {\n-      explorePath(conf, new Path(path), limitChecker, statCache);\n+    for (String uri : dcArchives) {\n+      explorePath(conf, stringToPath(uri), limitChecker, statCache);\n     }\n \n-    for (String path : files) {\n-      explorePath(conf, new Path(path), limitChecker, statCache);\n+    for (String uri : files) {\n+      explorePath(conf, stringToPath(uri), limitChecker, statCache);\n     }\n \n-    for (String path : libjars) {\n-      explorePath(conf, new Path(path), limitChecker, statCache);\n+    for (String uri : libjars) {\n+      explorePath(conf, stringToPath(uri), limitChecker, statCache);\n     }\n \n-    for (String path : archives) {\n-      explorePath(conf, new Path(path), limitChecker, statCache);\n+    for (String uri : archives) {\n+      explorePath(conf, stringToPath(uri), limitChecker, statCache);\n     }\n \n     if (jobJar !\u003d null) {\n-      explorePath(conf, new Path(jobJar), limitChecker, statCache);\n+      explorePath(conf, stringToPath(jobJar), limitChecker, statCache);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void checkLocalizationLimits(Configuration conf, Collection\u003cString\u003e files,\n      Collection\u003cString\u003e libjars, Collection\u003cString\u003e archives, String jobJar,\n      Map\u003cURI, FileStatus\u003e statCache) throws IOException {\n\n    LimitChecker limitChecker \u003d new LimitChecker(conf);\n    if (!limitChecker.hasLimits()) {\n      // there are no limits set, so we are done.\n      return;\n    }\n\n    // Get the files and archives that are already in the distributed cache\n    Collection\u003cString\u003e dcFiles \u003d\n        conf.getStringCollection(MRJobConfig.CACHE_FILES);\n    Collection\u003cString\u003e dcArchives \u003d\n        conf.getStringCollection(MRJobConfig.CACHE_ARCHIVES);\n\n    for (String uri : dcFiles) {\n      explorePath(conf, stringToPath(uri), limitChecker, statCache);\n    }\n\n    for (String uri : dcArchives) {\n      explorePath(conf, stringToPath(uri), limitChecker, statCache);\n    }\n\n    for (String uri : files) {\n      explorePath(conf, stringToPath(uri), limitChecker, statCache);\n    }\n\n    for (String uri : libjars) {\n      explorePath(conf, stringToPath(uri), limitChecker, statCache);\n    }\n\n    for (String uri : archives) {\n      explorePath(conf, stringToPath(uri), limitChecker, statCache);\n    }\n\n    if (jobJar !\u003d null) {\n      explorePath(conf, stringToPath(jobJar), limitChecker, statCache);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/JobResourceUploader.java",
      "extendedDetails": {}
    },
    "f80a7298325a4626638ee24467e2012442e480d4": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-6690. Limit the number of resources a single map reduce job can submit for localization. Contributed by Chris Trezzo\n",
      "commitDate": "17/08/16 9:22 AM",
      "commitName": "f80a7298325a4626638ee24467e2012442e480d4",
      "commitAuthor": "Jason Lowe",
      "diff": "@@ -0,0 +1,40 @@\n+  void checkLocalizationLimits(Configuration conf, Collection\u003cString\u003e files,\n+      Collection\u003cString\u003e libjars, Collection\u003cString\u003e archives, String jobJar,\n+      Map\u003cURI, FileStatus\u003e statCache) throws IOException {\n+\n+    LimitChecker limitChecker \u003d new LimitChecker(conf);\n+    if (!limitChecker.hasLimits()) {\n+      // there are no limits set, so we are done.\n+      return;\n+    }\n+\n+    // Get the files and archives that are already in the distributed cache\n+    Collection\u003cString\u003e dcFiles \u003d\n+        conf.getStringCollection(MRJobConfig.CACHE_FILES);\n+    Collection\u003cString\u003e dcArchives \u003d\n+        conf.getStringCollection(MRJobConfig.CACHE_ARCHIVES);\n+\n+    for (String path : dcFiles) {\n+      explorePath(conf, new Path(path), limitChecker, statCache);\n+    }\n+\n+    for (String path : dcArchives) {\n+      explorePath(conf, new Path(path), limitChecker, statCache);\n+    }\n+\n+    for (String path : files) {\n+      explorePath(conf, new Path(path), limitChecker, statCache);\n+    }\n+\n+    for (String path : libjars) {\n+      explorePath(conf, new Path(path), limitChecker, statCache);\n+    }\n+\n+    for (String path : archives) {\n+      explorePath(conf, new Path(path), limitChecker, statCache);\n+    }\n+\n+    if (jobJar !\u003d null) {\n+      explorePath(conf, new Path(jobJar), limitChecker, statCache);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void checkLocalizationLimits(Configuration conf, Collection\u003cString\u003e files,\n      Collection\u003cString\u003e libjars, Collection\u003cString\u003e archives, String jobJar,\n      Map\u003cURI, FileStatus\u003e statCache) throws IOException {\n\n    LimitChecker limitChecker \u003d new LimitChecker(conf);\n    if (!limitChecker.hasLimits()) {\n      // there are no limits set, so we are done.\n      return;\n    }\n\n    // Get the files and archives that are already in the distributed cache\n    Collection\u003cString\u003e dcFiles \u003d\n        conf.getStringCollection(MRJobConfig.CACHE_FILES);\n    Collection\u003cString\u003e dcArchives \u003d\n        conf.getStringCollection(MRJobConfig.CACHE_ARCHIVES);\n\n    for (String path : dcFiles) {\n      explorePath(conf, new Path(path), limitChecker, statCache);\n    }\n\n    for (String path : dcArchives) {\n      explorePath(conf, new Path(path), limitChecker, statCache);\n    }\n\n    for (String path : files) {\n      explorePath(conf, new Path(path), limitChecker, statCache);\n    }\n\n    for (String path : libjars) {\n      explorePath(conf, new Path(path), limitChecker, statCache);\n    }\n\n    for (String path : archives) {\n      explorePath(conf, new Path(path), limitChecker, statCache);\n    }\n\n    if (jobJar !\u003d null) {\n      explorePath(conf, new Path(jobJar), limitChecker, statCache);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/JobResourceUploader.java"
    }
  }
}