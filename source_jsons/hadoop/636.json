{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockReaderLocalLegacy.java",
  "functionName": "fillBuffer",
  "functionId": "fillBuffer___stream-FileInputStream__buf-ByteBuffer",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java",
  "functionStartLine": 373,
  "functionEndLine": 389,
  "numCommitsSeen": 30,
  "timeTaken": 3400,
  "changeHistory": [
    "5d748bd056a32f2c6922514cd0c5b31d866a9919",
    "f308561f1d885491b88db73ac63003202056d661",
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
    "892ade689f9bcce76daae8f66fc00a49bee8548e",
    "e2c9b288b223b9fd82dc12018936e13128413492",
    "7f6ed7fe365166e8075359f1d0ad035fa876c70f",
    "694a6721316aea14c1244447974231abc8dff0cb"
  ],
  "changeHistoryShort": {
    "5d748bd056a32f2c6922514cd0c5b31d866a9919": "Ybodychange",
    "f308561f1d885491b88db73ac63003202056d661": "Yfilerename",
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": "Ybodychange",
    "892ade689f9bcce76daae8f66fc00a49bee8548e": "Ybodychange",
    "e2c9b288b223b9fd82dc12018936e13128413492": "Yfilerename",
    "7f6ed7fe365166e8075359f1d0ad035fa876c70f": "Ybodychange",
    "694a6721316aea14c1244447974231abc8dff0cb": "Yintroduced"
  },
  "changeHistoryDetails": {
    "5d748bd056a32f2c6922514cd0c5b31d866a9919": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13702. Remove HTrace hooks from DFSClient to reduce CPU usage. Contributed by Todd Lipcon.\n",
      "commitDate": "02/07/18 3:11 AM",
      "commitName": "5d748bd056a32f2c6922514cd0c5b31d866a9919",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "25/04/16 12:01 PM",
      "commitNameOld": "f308561f1d885491b88db73ac63003202056d661",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 797.63,
      "commitsBetweenForRepo": 6015,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,17 @@\n   private int fillBuffer(FileInputStream stream, ByteBuffer buf)\n       throws IOException {\n-    try (TraceScope ignored \u003d tracer.\n-        newScope(\"BlockReaderLocalLegacy#fillBuffer(\" + blockId + \")\")) {\n-      int bytesRead \u003d stream.getChannel().read(buf);\n-      if (bytesRead \u003c 0) {\n+    int bytesRead \u003d stream.getChannel().read(buf);\n+    if (bytesRead \u003c 0) {\n+      //EOF\n+      return bytesRead;\n+    }\n+    while (buf.remaining() \u003e 0) {\n+      int n \u003d stream.getChannel().read(buf);\n+      if (n \u003c 0) {\n         //EOF\n         return bytesRead;\n       }\n-      while (buf.remaining() \u003e 0) {\n-        int n \u003d stream.getChannel().read(buf);\n-        if (n \u003c 0) {\n-          //EOF\n-          return bytesRead;\n-        }\n-        bytesRead +\u003d n;\n-      }\n-      return bytesRead;\n+      bytesRead +\u003d n;\n     }\n+    return bytesRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int fillBuffer(FileInputStream stream, ByteBuffer buf)\n      throws IOException {\n    int bytesRead \u003d stream.getChannel().read(buf);\n    if (bytesRead \u003c 0) {\n      //EOF\n      return bytesRead;\n    }\n    while (buf.remaining() \u003e 0) {\n      int n \u003d stream.getChannel().read(buf);\n      if (n \u003c 0) {\n        //EOF\n        return bytesRead;\n      }\n      bytesRead +\u003d n;\n    }\n    return bytesRead;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java",
      "extendedDetails": {}
    },
    "f308561f1d885491b88db73ac63003202056d661": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8057 Move BlockReader implementation to the client implementation package.  Contributed by Takanobu Asanuma\n",
      "commitDate": "25/04/16 12:01 PM",
      "commitName": "f308561f1d885491b88db73ac63003202056d661",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "25/04/16 9:38 AM",
      "commitNameOld": "10f0f7851a3255caab775777e8fb6c2781d97062",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private int fillBuffer(FileInputStream stream, ByteBuffer buf)\n      throws IOException {\n    try (TraceScope ignored \u003d tracer.\n        newScope(\"BlockReaderLocalLegacy#fillBuffer(\" + blockId + \")\")) {\n      int bytesRead \u003d stream.getChannel().read(buf);\n      if (bytesRead \u003c 0) {\n        //EOF\n        return bytesRead;\n      }\n      while (buf.remaining() \u003e 0) {\n        int n \u003d stream.getChannel().read(buf);\n        if (n \u003c 0) {\n          //EOF\n          return bytesRead;\n        }\n        bytesRead +\u003d n;\n      }\n      return bytesRead;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java"
      }
    },
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8979. Clean up checkstyle warnings in hadoop-hdfs-client module. Contributed by Mingliang Liu.\n",
      "commitDate": "03/10/15 11:38 AM",
      "commitName": "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "30/09/15 8:39 AM",
      "commitNameOld": "6c17d315287020368689fa078a40a1eaedf89d5b",
      "commitAuthorOld": "",
      "daysBetweenCommits": 3.12,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,20 @@\n   private int fillBuffer(FileInputStream stream, ByteBuffer buf)\n       throws IOException {\n-    TraceScope scope \u003d tracer.\n-        newScope(\"BlockReaderLocalLegacy#fillBuffer(\" + blockId + \")\");\n-    try {\n+    try (TraceScope ignored \u003d tracer.\n+        newScope(\"BlockReaderLocalLegacy#fillBuffer(\" + blockId + \")\")) {\n       int bytesRead \u003d stream.getChannel().read(buf);\n       if (bytesRead \u003c 0) {\n         //EOF\n         return bytesRead;\n       }\n       while (buf.remaining() \u003e 0) {\n         int n \u003d stream.getChannel().read(buf);\n         if (n \u003c 0) {\n           //EOF\n           return bytesRead;\n         }\n         bytesRead +\u003d n;\n       }\n       return bytesRead;\n-    } finally {\n-      scope.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int fillBuffer(FileInputStream stream, ByteBuffer buf)\n      throws IOException {\n    try (TraceScope ignored \u003d tracer.\n        newScope(\"BlockReaderLocalLegacy#fillBuffer(\" + blockId + \")\")) {\n      int bytesRead \u003d stream.getChannel().read(buf);\n      if (bytesRead \u003c 0) {\n        //EOF\n        return bytesRead;\n      }\n      while (buf.remaining() \u003e 0) {\n        int n \u003d stream.getChannel().read(buf);\n        if (n \u003c 0) {\n          //EOF\n          return bytesRead;\n        }\n        bytesRead +\u003d n;\n      }\n      return bytesRead;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
      "extendedDetails": {}
    },
    "892ade689f9bcce76daae8f66fc00a49bee8548e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9080. Update htrace version to 4.0.1 (cmccabe)\n",
      "commitDate": "28/09/15 7:42 AM",
      "commitName": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "28/08/15 2:38 PM",
      "commitNameOld": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 30.71,
      "commitsBetweenForRepo": 195,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,23 @@\n   private int fillBuffer(FileInputStream stream, ByteBuffer buf)\n       throws IOException {\n-    TraceScope scope \u003d Trace.startSpan(\"BlockReaderLocalLegacy#fillBuffer(\" +\n-        blockId + \")\", Sampler.NEVER);\n+    TraceScope scope \u003d tracer.\n+        newScope(\"BlockReaderLocalLegacy#fillBuffer(\" + blockId + \")\");\n     try {\n       int bytesRead \u003d stream.getChannel().read(buf);\n       if (bytesRead \u003c 0) {\n         //EOF\n         return bytesRead;\n       }\n       while (buf.remaining() \u003e 0) {\n         int n \u003d stream.getChannel().read(buf);\n         if (n \u003c 0) {\n           //EOF\n           return bytesRead;\n         }\n         bytesRead +\u003d n;\n       }\n       return bytesRead;\n     } finally {\n       scope.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int fillBuffer(FileInputStream stream, ByteBuffer buf)\n      throws IOException {\n    TraceScope scope \u003d tracer.\n        newScope(\"BlockReaderLocalLegacy#fillBuffer(\" + blockId + \")\");\n    try {\n      int bytesRead \u003d stream.getChannel().read(buf);\n      if (bytesRead \u003c 0) {\n        //EOF\n        return bytesRead;\n      }\n      while (buf.remaining() \u003e 0) {\n        int n \u003d stream.getChannel().read(buf);\n        if (n \u003c 0) {\n          //EOF\n          return bytesRead;\n        }\n        bytesRead +\u003d n;\n      }\n      return bytesRead;\n    } finally {\n      scope.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
      "extendedDetails": {}
    },
    "e2c9b288b223b9fd82dc12018936e13128413492": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8925. Move BlockReaderLocal to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "28/08/15 2:38 PM",
      "commitName": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/08/15 2:21 PM",
      "commitNameOld": "b94b56806d3d6e04984e229b479f7ac15b62bbfa",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private int fillBuffer(FileInputStream stream, ByteBuffer buf)\n      throws IOException {\n    TraceScope scope \u003d Trace.startSpan(\"BlockReaderLocalLegacy#fillBuffer(\" +\n        blockId + \")\", Sampler.NEVER);\n    try {\n      int bytesRead \u003d stream.getChannel().read(buf);\n      if (bytesRead \u003c 0) {\n        //EOF\n        return bytesRead;\n      }\n      while (buf.remaining() \u003e 0) {\n        int n \u003d stream.getChannel().read(buf);\n        if (n \u003c 0) {\n          //EOF\n          return bytesRead;\n        }\n        bytesRead +\u003d n;\n      }\n      return bytesRead;\n    } finally {\n      scope.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java"
      }
    },
    "7f6ed7fe365166e8075359f1d0ad035fa876c70f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7055. Add tracing to DFSInputStream (cmccabe)\n",
      "commitDate": "03/10/14 1:35 PM",
      "commitName": "7f6ed7fe365166e8075359f1d0ad035fa876c70f",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "23/07/14 11:22 PM",
      "commitNameOld": "2054453a39efeca86361e26033a65f2715f4785c",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 71.59,
      "commitsBetweenForRepo": 715,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,23 @@\n   private int fillBuffer(FileInputStream stream, ByteBuffer buf)\n       throws IOException {\n-    int bytesRead \u003d stream.getChannel().read(buf);\n-    if (bytesRead \u003c 0) {\n-      //EOF\n-      return bytesRead;\n-    }\n-    while (buf.remaining() \u003e 0) {\n-      int n \u003d stream.getChannel().read(buf);\n-      if (n \u003c 0) {\n+    TraceScope scope \u003d Trace.startSpan(\"BlockReaderLocalLegacy#fillBuffer(\" +\n+        blockId + \")\", Sampler.NEVER);\n+    try {\n+      int bytesRead \u003d stream.getChannel().read(buf);\n+      if (bytesRead \u003c 0) {\n         //EOF\n         return bytesRead;\n       }\n-      bytesRead +\u003d n;\n+      while (buf.remaining() \u003e 0) {\n+        int n \u003d stream.getChannel().read(buf);\n+        if (n \u003c 0) {\n+          //EOF\n+          return bytesRead;\n+        }\n+        bytesRead +\u003d n;\n+      }\n+      return bytesRead;\n+    } finally {\n+      scope.close();\n     }\n-    return bytesRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int fillBuffer(FileInputStream stream, ByteBuffer buf)\n      throws IOException {\n    TraceScope scope \u003d Trace.startSpan(\"BlockReaderLocalLegacy#fillBuffer(\" +\n        blockId + \")\", Sampler.NEVER);\n    try {\n      int bytesRead \u003d stream.getChannel().read(buf);\n      if (bytesRead \u003c 0) {\n        //EOF\n        return bytesRead;\n      }\n      while (buf.remaining() \u003e 0) {\n        int n \u003d stream.getChannel().read(buf);\n        if (n \u003c 0) {\n          //EOF\n          return bytesRead;\n        }\n        bytesRead +\u003d n;\n      }\n      return bytesRead;\n    } finally {\n      scope.close();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
      "extendedDetails": {}
    },
    "694a6721316aea14c1244447974231abc8dff0cb": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4538. Allow use of legacy blockreader. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1461818 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/03/13 12:28 PM",
      "commitName": "694a6721316aea14c1244447974231abc8dff0cb",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,17 @@\n+  private int fillBuffer(FileInputStream stream, ByteBuffer buf)\n+      throws IOException {\n+    int bytesRead \u003d stream.getChannel().read(buf);\n+    if (bytesRead \u003c 0) {\n+      //EOF\n+      return bytesRead;\n+    }\n+    while (buf.remaining() \u003e 0) {\n+      int n \u003d stream.getChannel().read(buf);\n+      if (n \u003c 0) {\n+        //EOF\n+        return bytesRead;\n+      }\n+      bytesRead +\u003d n;\n+    }\n+    return bytesRead;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private int fillBuffer(FileInputStream stream, ByteBuffer buf)\n      throws IOException {\n    int bytesRead \u003d stream.getChannel().read(buf);\n    if (bytesRead \u003c 0) {\n      //EOF\n      return bytesRead;\n    }\n    while (buf.remaining() \u003e 0) {\n      int n \u003d stream.getChannel().read(buf);\n      if (n \u003c 0) {\n        //EOF\n        return bytesRead;\n      }\n      bytesRead +\u003d n;\n    }\n    return bytesRead;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java"
    }
  }
}