{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FsDatasetImpl.java",
  "functionName": "removeVolumes",
  "functionId": "removeVolumes___storageLocsToRemove-Collection__StorageLocation__(modifiers-final)__clearFailure-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
  "functionStartLine": 556,
  "functionEndLine": 628,
  "numCommitsSeen": 574,
  "timeTaken": 11689,
  "changeHistory": [
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8",
    "6814324c332a7d780f3b844fd6f1c62db2f6c88e",
    "6d356b6b4d8ccb32397cacfb5d0357b21f6035fc",
    "96b12662ea76e3ded4ef13944fc8df206cfb4613",
    "a99bf26a0899bcc4307c3a242c8414eaef555aa7",
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c",
    "e50aa53eed3d0ff1bc8fe60381524bb3bbe53bc1",
    "a48301791e9564363bc2abad4e89e344b0d7a5ff",
    "b49c3a1813aa8c5b05fe6c02a653286c573137ca",
    "6e62a1a6728b1f782f64065424f92b292c3f163a",
    "a17584936cc5141e3f5612ac3ecf35e27968e439",
    "1efd9c98258fbb973d2058dcf0850042e53bd02f",
    "fe38d2e9b5ac7e13f97cd2d3d2a984ab6bbaaf77",
    "7eab2a29a5706ce10912c12fa225ef6b27a82cbe"
  ],
  "changeHistoryShort": {
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8": "Ybodychange",
    "6814324c332a7d780f3b844fd6f1c62db2f6c88e": "Ybodychange",
    "6d356b6b4d8ccb32397cacfb5d0357b21f6035fc": "Ymultichange(Yparameterchange,Ybodychange)",
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": "Ymultichange(Yparameterchange,Ybodychange)",
    "a99bf26a0899bcc4307c3a242c8414eaef555aa7": "Ybodychange",
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c": "Ybodychange",
    "e50aa53eed3d0ff1bc8fe60381524bb3bbe53bc1": "Ybodychange",
    "a48301791e9564363bc2abad4e89e344b0d7a5ff": "Ymultichange(Ymodifierchange,Ybodychange)",
    "b49c3a1813aa8c5b05fe6c02a653286c573137ca": "Ymultichange(Yparameterchange,Ybodychange)",
    "6e62a1a6728b1f782f64065424f92b292c3f163a": "Ybodychange",
    "a17584936cc5141e3f5612ac3ecf35e27968e439": "Ybodychange",
    "1efd9c98258fbb973d2058dcf0850042e53bd02f": "Ybodychange",
    "fe38d2e9b5ac7e13f97cd2d3d2a984ab6bbaaf77": "Ybodychange",
    "7eab2a29a5706ce10912c12fa225ef6b27a82cbe": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15150. Introduce read write lock to Datanode. Contributed Stephen O\u0027Donnell.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "11/02/20 8:00 AM",
      "commitName": "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8",
      "commitAuthor": "Stephen O\u0027Donnell",
      "commitDateOld": "28/01/20 10:10 AM",
      "commitNameOld": "1839c467f60cbb8592d446694ec3d7710cda5142",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 13.91,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,73 +1,73 @@\n   public void removeVolumes(\n       final Collection\u003cStorageLocation\u003e storageLocsToRemove,\n       boolean clearFailure) {\n     Collection\u003cStorageLocation\u003e storageLocationsToRemove \u003d\n         new ArrayList\u003c\u003e(storageLocsToRemove);\n     Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n     List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n-    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n+    try (AutoCloseableLock lock \u003d datasetWriteLock.acquire()) {\n       for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n         Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n         final StorageLocation sdLocation \u003d sd.getStorageLocation();\n         LOG.info(\"Checking removing StorageLocation \" +\n             sdLocation + \" with id \" + sd.getStorageUuid());\n         if (storageLocationsToRemove.contains(sdLocation)) {\n           LOG.info(\"Removing StorageLocation \" + sdLocation + \" with id \" +\n               sd.getStorageUuid() + \" from FsDataset.\");\n           // Disable the volume from the service.\n           asyncDiskService.removeVolume(sd.getStorageUuid());\n           volumes.removeVolume(sdLocation, clearFailure);\n-          volumes.waitVolumeRemoved(5000, datasetLockCondition);\n+          volumes.waitVolumeRemoved(5000, datasetWriteLockCondition);\n \n           // Removed all replica information for the blocks on the volume.\n           // Unlike updating the volumeMap in addVolume(), this operation does\n           // not scan disks.\n           for (String bpid : volumeMap.getBlockPoolList()) {\n             List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n             for (Iterator\u003cReplicaInfo\u003e it \u003d\n                   volumeMap.replicas(bpid).iterator(); it.hasNext();) {\n               ReplicaInfo block \u003d it.next();\n               final StorageLocation blockStorageLocation \u003d\n                   block.getVolume().getStorageLocation();\n               LOG.trace(\"checking for block \" + block.getBlockId() +\n                   \" with storageLocation \" + blockStorageLocation);\n               if (blockStorageLocation.equals(sdLocation)) {\n                 blocks.add(block);\n                 it.remove();\n               }\n             }\n             blkToInvalidate.put(bpid, blocks);\n           }\n \n           storageToRemove.add(sd.getStorageUuid());\n           storageLocationsToRemove.remove(sdLocation);\n         }\n       }\n \n       // A reconfigure can remove the storage location which is already\n       // removed when the failure was detected by DataNode#checkDiskErrorAsync.\n       // Now, lets remove this from the failed volume list.\n       if (clearFailure) {\n         for (StorageLocation storageLocToRemove : storageLocationsToRemove) {\n           volumes.removeVolumeFailureInfo(storageLocToRemove);\n         }\n       }\n       setupAsyncLazyPersistThreads();\n     }\n \n     // Call this outside the lock.\n     for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n         blkToInvalidate.entrySet()) {\n       String bpid \u003d entry.getKey();\n       List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n       for (ReplicaInfo block : blocks) {\n         invalidate(bpid, block);\n       }\n     }\n \n-    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n+    try (AutoCloseableLock lock \u003d datasetWriteLock.acquire()) {\n       for(String storageUuid : storageToRemove) {\n         storageMap.remove(storageUuid);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void removeVolumes(\n      final Collection\u003cStorageLocation\u003e storageLocsToRemove,\n      boolean clearFailure) {\n    Collection\u003cStorageLocation\u003e storageLocationsToRemove \u003d\n        new ArrayList\u003c\u003e(storageLocsToRemove);\n    Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n    List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n    try (AutoCloseableLock lock \u003d datasetWriteLock.acquire()) {\n      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n        final StorageLocation sdLocation \u003d sd.getStorageLocation();\n        LOG.info(\"Checking removing StorageLocation \" +\n            sdLocation + \" with id \" + sd.getStorageUuid());\n        if (storageLocationsToRemove.contains(sdLocation)) {\n          LOG.info(\"Removing StorageLocation \" + sdLocation + \" with id \" +\n              sd.getStorageUuid() + \" from FsDataset.\");\n          // Disable the volume from the service.\n          asyncDiskService.removeVolume(sd.getStorageUuid());\n          volumes.removeVolume(sdLocation, clearFailure);\n          volumes.waitVolumeRemoved(5000, datasetWriteLockCondition);\n\n          // Removed all replica information for the blocks on the volume.\n          // Unlike updating the volumeMap in addVolume(), this operation does\n          // not scan disks.\n          for (String bpid : volumeMap.getBlockPoolList()) {\n            List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n            for (Iterator\u003cReplicaInfo\u003e it \u003d\n                  volumeMap.replicas(bpid).iterator(); it.hasNext();) {\n              ReplicaInfo block \u003d it.next();\n              final StorageLocation blockStorageLocation \u003d\n                  block.getVolume().getStorageLocation();\n              LOG.trace(\"checking for block \" + block.getBlockId() +\n                  \" with storageLocation \" + blockStorageLocation);\n              if (blockStorageLocation.equals(sdLocation)) {\n                blocks.add(block);\n                it.remove();\n              }\n            }\n            blkToInvalidate.put(bpid, blocks);\n          }\n\n          storageToRemove.add(sd.getStorageUuid());\n          storageLocationsToRemove.remove(sdLocation);\n        }\n      }\n\n      // A reconfigure can remove the storage location which is already\n      // removed when the failure was detected by DataNode#checkDiskErrorAsync.\n      // Now, lets remove this from the failed volume list.\n      if (clearFailure) {\n        for (StorageLocation storageLocToRemove : storageLocationsToRemove) {\n          volumes.removeVolumeFailureInfo(storageLocToRemove);\n        }\n      }\n      setupAsyncLazyPersistThreads();\n    }\n\n    // Call this outside the lock.\n    for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n        blkToInvalidate.entrySet()) {\n      String bpid \u003d entry.getKey();\n      List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n      for (ReplicaInfo block : blocks) {\n        invalidate(bpid, block);\n      }\n    }\n\n    try (AutoCloseableLock lock \u003d datasetWriteLock.acquire()) {\n      for(String storageUuid : storageToRemove) {\n        storageMap.remove(storageUuid);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "6814324c332a7d780f3b844fd6f1c62db2f6c88e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12107. FsDatasetImpl#removeVolumes floods the logs when removing the volume. Contributed by Kelvin Chu.\n",
      "commitDate": "01/08/17 6:34 PM",
      "commitName": "6814324c332a7d780f3b844fd6f1c62db2f6c88e",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "20/07/17 2:47 PM",
      "commitNameOld": "8c2c8128328d465ec9699d0573bef69019742512",
      "commitAuthorOld": "Konstantin V Shvachko",
      "daysBetweenCommits": 12.16,
      "commitsBetweenForRepo": 117,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,73 +1,73 @@\n   public void removeVolumes(\n       final Collection\u003cStorageLocation\u003e storageLocsToRemove,\n       boolean clearFailure) {\n     Collection\u003cStorageLocation\u003e storageLocationsToRemove \u003d\n         new ArrayList\u003c\u003e(storageLocsToRemove);\n     Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n     List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n     try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n         Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n         final StorageLocation sdLocation \u003d sd.getStorageLocation();\n         LOG.info(\"Checking removing StorageLocation \" +\n             sdLocation + \" with id \" + sd.getStorageUuid());\n         if (storageLocationsToRemove.contains(sdLocation)) {\n           LOG.info(\"Removing StorageLocation \" + sdLocation + \" with id \" +\n               sd.getStorageUuid() + \" from FsDataset.\");\n           // Disable the volume from the service.\n           asyncDiskService.removeVolume(sd.getStorageUuid());\n           volumes.removeVolume(sdLocation, clearFailure);\n           volumes.waitVolumeRemoved(5000, datasetLockCondition);\n \n           // Removed all replica information for the blocks on the volume.\n           // Unlike updating the volumeMap in addVolume(), this operation does\n           // not scan disks.\n           for (String bpid : volumeMap.getBlockPoolList()) {\n             List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n             for (Iterator\u003cReplicaInfo\u003e it \u003d\n                   volumeMap.replicas(bpid).iterator(); it.hasNext();) {\n               ReplicaInfo block \u003d it.next();\n               final StorageLocation blockStorageLocation \u003d\n                   block.getVolume().getStorageLocation();\n-              LOG.info(\"checking for block \" + block.getBlockId() +\n+              LOG.trace(\"checking for block \" + block.getBlockId() +\n                   \" with storageLocation \" + blockStorageLocation);\n               if (blockStorageLocation.equals(sdLocation)) {\n                 blocks.add(block);\n                 it.remove();\n               }\n             }\n             blkToInvalidate.put(bpid, blocks);\n           }\n \n           storageToRemove.add(sd.getStorageUuid());\n           storageLocationsToRemove.remove(sdLocation);\n         }\n       }\n \n       // A reconfigure can remove the storage location which is already\n       // removed when the failure was detected by DataNode#checkDiskErrorAsync.\n       // Now, lets remove this from the failed volume list.\n       if (clearFailure) {\n         for (StorageLocation storageLocToRemove : storageLocationsToRemove) {\n           volumes.removeVolumeFailureInfo(storageLocToRemove);\n         }\n       }\n       setupAsyncLazyPersistThreads();\n     }\n \n     // Call this outside the lock.\n     for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n         blkToInvalidate.entrySet()) {\n       String bpid \u003d entry.getKey();\n       List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n       for (ReplicaInfo block : blocks) {\n         invalidate(bpid, block);\n       }\n     }\n \n     try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       for(String storageUuid : storageToRemove) {\n         storageMap.remove(storageUuid);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void removeVolumes(\n      final Collection\u003cStorageLocation\u003e storageLocsToRemove,\n      boolean clearFailure) {\n    Collection\u003cStorageLocation\u003e storageLocationsToRemove \u003d\n        new ArrayList\u003c\u003e(storageLocsToRemove);\n    Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n    List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n        final StorageLocation sdLocation \u003d sd.getStorageLocation();\n        LOG.info(\"Checking removing StorageLocation \" +\n            sdLocation + \" with id \" + sd.getStorageUuid());\n        if (storageLocationsToRemove.contains(sdLocation)) {\n          LOG.info(\"Removing StorageLocation \" + sdLocation + \" with id \" +\n              sd.getStorageUuid() + \" from FsDataset.\");\n          // Disable the volume from the service.\n          asyncDiskService.removeVolume(sd.getStorageUuid());\n          volumes.removeVolume(sdLocation, clearFailure);\n          volumes.waitVolumeRemoved(5000, datasetLockCondition);\n\n          // Removed all replica information for the blocks on the volume.\n          // Unlike updating the volumeMap in addVolume(), this operation does\n          // not scan disks.\n          for (String bpid : volumeMap.getBlockPoolList()) {\n            List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n            for (Iterator\u003cReplicaInfo\u003e it \u003d\n                  volumeMap.replicas(bpid).iterator(); it.hasNext();) {\n              ReplicaInfo block \u003d it.next();\n              final StorageLocation blockStorageLocation \u003d\n                  block.getVolume().getStorageLocation();\n              LOG.trace(\"checking for block \" + block.getBlockId() +\n                  \" with storageLocation \" + blockStorageLocation);\n              if (blockStorageLocation.equals(sdLocation)) {\n                blocks.add(block);\n                it.remove();\n              }\n            }\n            blkToInvalidate.put(bpid, blocks);\n          }\n\n          storageToRemove.add(sd.getStorageUuid());\n          storageLocationsToRemove.remove(sdLocation);\n        }\n      }\n\n      // A reconfigure can remove the storage location which is already\n      // removed when the failure was detected by DataNode#checkDiskErrorAsync.\n      // Now, lets remove this from the failed volume list.\n      if (clearFailure) {\n        for (StorageLocation storageLocToRemove : storageLocationsToRemove) {\n          volumes.removeVolumeFailureInfo(storageLocToRemove);\n        }\n      }\n      setupAsyncLazyPersistThreads();\n    }\n\n    // Call this outside the lock.\n    for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n        blkToInvalidate.entrySet()) {\n      String bpid \u003d entry.getKey();\n      List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n      for (ReplicaInfo block : blocks) {\n        invalidate(bpid, block);\n      }\n    }\n\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      for(String storageUuid : storageToRemove) {\n        storageMap.remove(storageUuid);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "6d356b6b4d8ccb32397cacfb5d0357b21f6035fc": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-11340. DataNode reconfigure for disks doesn\u0027t remove the failed volumes. (Manoj Govindassamy via lei)\n",
      "commitDate": "10/03/17 2:37 PM",
      "commitName": "6d356b6b4d8ccb32397cacfb5d0357b21f6035fc",
      "commitAuthor": "Lei Xu",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-11340. DataNode reconfigure for disks doesn\u0027t remove the failed volumes. (Manoj Govindassamy via lei)\n",
          "commitDate": "10/03/17 2:37 PM",
          "commitName": "6d356b6b4d8ccb32397cacfb5d0357b21f6035fc",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "03/03/17 1:31 PM",
          "commitNameOld": "ac5ae0065a127ac150a887fa6c6f3cffd86ef733",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 7.05,
          "commitsBetweenForRepo": 52,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,61 +1,73 @@\n   public void removeVolumes(\n-      Collection\u003cStorageLocation\u003e storageLocationsToRemove,\n+      final Collection\u003cStorageLocation\u003e storageLocsToRemove,\n       boolean clearFailure) {\n+    Collection\u003cStorageLocation\u003e storageLocationsToRemove \u003d\n+        new ArrayList\u003c\u003e(storageLocsToRemove);\n     Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n     List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n     try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n         Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n         final StorageLocation sdLocation \u003d sd.getStorageLocation();\n         LOG.info(\"Checking removing StorageLocation \" +\n             sdLocation + \" with id \" + sd.getStorageUuid());\n         if (storageLocationsToRemove.contains(sdLocation)) {\n           LOG.info(\"Removing StorageLocation \" + sdLocation + \" with id \" +\n               sd.getStorageUuid() + \" from FsDataset.\");\n           // Disable the volume from the service.\n           asyncDiskService.removeVolume(sd.getStorageUuid());\n           volumes.removeVolume(sdLocation, clearFailure);\n           volumes.waitVolumeRemoved(5000, datasetLockCondition);\n \n           // Removed all replica information for the blocks on the volume.\n           // Unlike updating the volumeMap in addVolume(), this operation does\n           // not scan disks.\n           for (String bpid : volumeMap.getBlockPoolList()) {\n             List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n             for (Iterator\u003cReplicaInfo\u003e it \u003d\n                   volumeMap.replicas(bpid).iterator(); it.hasNext();) {\n               ReplicaInfo block \u003d it.next();\n               final StorageLocation blockStorageLocation \u003d\n                   block.getVolume().getStorageLocation();\n               LOG.info(\"checking for block \" + block.getBlockId() +\n                   \" with storageLocation \" + blockStorageLocation);\n               if (blockStorageLocation.equals(sdLocation)) {\n                 blocks.add(block);\n                 it.remove();\n               }\n             }\n             blkToInvalidate.put(bpid, blocks);\n           }\n \n           storageToRemove.add(sd.getStorageUuid());\n+          storageLocationsToRemove.remove(sdLocation);\n+        }\n+      }\n+\n+      // A reconfigure can remove the storage location which is already\n+      // removed when the failure was detected by DataNode#checkDiskErrorAsync.\n+      // Now, lets remove this from the failed volume list.\n+      if (clearFailure) {\n+        for (StorageLocation storageLocToRemove : storageLocationsToRemove) {\n+          volumes.removeVolumeFailureInfo(storageLocToRemove);\n         }\n       }\n       setupAsyncLazyPersistThreads();\n     }\n \n     // Call this outside the lock.\n     for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n         blkToInvalidate.entrySet()) {\n       String bpid \u003d entry.getKey();\n       List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n       for (ReplicaInfo block : blocks) {\n         invalidate(bpid, block);\n       }\n     }\n \n     try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       for(String storageUuid : storageToRemove) {\n         storageMap.remove(storageUuid);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void removeVolumes(\n      final Collection\u003cStorageLocation\u003e storageLocsToRemove,\n      boolean clearFailure) {\n    Collection\u003cStorageLocation\u003e storageLocationsToRemove \u003d\n        new ArrayList\u003c\u003e(storageLocsToRemove);\n    Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n    List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n        final StorageLocation sdLocation \u003d sd.getStorageLocation();\n        LOG.info(\"Checking removing StorageLocation \" +\n            sdLocation + \" with id \" + sd.getStorageUuid());\n        if (storageLocationsToRemove.contains(sdLocation)) {\n          LOG.info(\"Removing StorageLocation \" + sdLocation + \" with id \" +\n              sd.getStorageUuid() + \" from FsDataset.\");\n          // Disable the volume from the service.\n          asyncDiskService.removeVolume(sd.getStorageUuid());\n          volumes.removeVolume(sdLocation, clearFailure);\n          volumes.waitVolumeRemoved(5000, datasetLockCondition);\n\n          // Removed all replica information for the blocks on the volume.\n          // Unlike updating the volumeMap in addVolume(), this operation does\n          // not scan disks.\n          for (String bpid : volumeMap.getBlockPoolList()) {\n            List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n            for (Iterator\u003cReplicaInfo\u003e it \u003d\n                  volumeMap.replicas(bpid).iterator(); it.hasNext();) {\n              ReplicaInfo block \u003d it.next();\n              final StorageLocation blockStorageLocation \u003d\n                  block.getVolume().getStorageLocation();\n              LOG.info(\"checking for block \" + block.getBlockId() +\n                  \" with storageLocation \" + blockStorageLocation);\n              if (blockStorageLocation.equals(sdLocation)) {\n                blocks.add(block);\n                it.remove();\n              }\n            }\n            blkToInvalidate.put(bpid, blocks);\n          }\n\n          storageToRemove.add(sd.getStorageUuid());\n          storageLocationsToRemove.remove(sdLocation);\n        }\n      }\n\n      // A reconfigure can remove the storage location which is already\n      // removed when the failure was detected by DataNode#checkDiskErrorAsync.\n      // Now, lets remove this from the failed volume list.\n      if (clearFailure) {\n        for (StorageLocation storageLocToRemove : storageLocationsToRemove) {\n          volumes.removeVolumeFailureInfo(storageLocToRemove);\n        }\n      }\n      setupAsyncLazyPersistThreads();\n    }\n\n    // Call this outside the lock.\n    for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n        blkToInvalidate.entrySet()) {\n      String bpid \u003d entry.getKey();\n      List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n      for (ReplicaInfo block : blocks) {\n        invalidate(bpid, block);\n      }\n    }\n\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      for(String storageUuid : storageToRemove) {\n        storageMap.remove(storageUuid);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldValue": "[storageLocationsToRemove-Collection\u003cStorageLocation\u003e, clearFailure-boolean]",
            "newValue": "[storageLocsToRemove-Collection\u003cStorageLocation\u003e(modifiers-final), clearFailure-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-11340. DataNode reconfigure for disks doesn\u0027t remove the failed volumes. (Manoj Govindassamy via lei)\n",
          "commitDate": "10/03/17 2:37 PM",
          "commitName": "6d356b6b4d8ccb32397cacfb5d0357b21f6035fc",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "03/03/17 1:31 PM",
          "commitNameOld": "ac5ae0065a127ac150a887fa6c6f3cffd86ef733",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 7.05,
          "commitsBetweenForRepo": 52,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,61 +1,73 @@\n   public void removeVolumes(\n-      Collection\u003cStorageLocation\u003e storageLocationsToRemove,\n+      final Collection\u003cStorageLocation\u003e storageLocsToRemove,\n       boolean clearFailure) {\n+    Collection\u003cStorageLocation\u003e storageLocationsToRemove \u003d\n+        new ArrayList\u003c\u003e(storageLocsToRemove);\n     Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n     List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n     try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n         Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n         final StorageLocation sdLocation \u003d sd.getStorageLocation();\n         LOG.info(\"Checking removing StorageLocation \" +\n             sdLocation + \" with id \" + sd.getStorageUuid());\n         if (storageLocationsToRemove.contains(sdLocation)) {\n           LOG.info(\"Removing StorageLocation \" + sdLocation + \" with id \" +\n               sd.getStorageUuid() + \" from FsDataset.\");\n           // Disable the volume from the service.\n           asyncDiskService.removeVolume(sd.getStorageUuid());\n           volumes.removeVolume(sdLocation, clearFailure);\n           volumes.waitVolumeRemoved(5000, datasetLockCondition);\n \n           // Removed all replica information for the blocks on the volume.\n           // Unlike updating the volumeMap in addVolume(), this operation does\n           // not scan disks.\n           for (String bpid : volumeMap.getBlockPoolList()) {\n             List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n             for (Iterator\u003cReplicaInfo\u003e it \u003d\n                   volumeMap.replicas(bpid).iterator(); it.hasNext();) {\n               ReplicaInfo block \u003d it.next();\n               final StorageLocation blockStorageLocation \u003d\n                   block.getVolume().getStorageLocation();\n               LOG.info(\"checking for block \" + block.getBlockId() +\n                   \" with storageLocation \" + blockStorageLocation);\n               if (blockStorageLocation.equals(sdLocation)) {\n                 blocks.add(block);\n                 it.remove();\n               }\n             }\n             blkToInvalidate.put(bpid, blocks);\n           }\n \n           storageToRemove.add(sd.getStorageUuid());\n+          storageLocationsToRemove.remove(sdLocation);\n+        }\n+      }\n+\n+      // A reconfigure can remove the storage location which is already\n+      // removed when the failure was detected by DataNode#checkDiskErrorAsync.\n+      // Now, lets remove this from the failed volume list.\n+      if (clearFailure) {\n+        for (StorageLocation storageLocToRemove : storageLocationsToRemove) {\n+          volumes.removeVolumeFailureInfo(storageLocToRemove);\n         }\n       }\n       setupAsyncLazyPersistThreads();\n     }\n \n     // Call this outside the lock.\n     for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n         blkToInvalidate.entrySet()) {\n       String bpid \u003d entry.getKey();\n       List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n       for (ReplicaInfo block : blocks) {\n         invalidate(bpid, block);\n       }\n     }\n \n     try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       for(String storageUuid : storageToRemove) {\n         storageMap.remove(storageUuid);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void removeVolumes(\n      final Collection\u003cStorageLocation\u003e storageLocsToRemove,\n      boolean clearFailure) {\n    Collection\u003cStorageLocation\u003e storageLocationsToRemove \u003d\n        new ArrayList\u003c\u003e(storageLocsToRemove);\n    Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n    List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n        final StorageLocation sdLocation \u003d sd.getStorageLocation();\n        LOG.info(\"Checking removing StorageLocation \" +\n            sdLocation + \" with id \" + sd.getStorageUuid());\n        if (storageLocationsToRemove.contains(sdLocation)) {\n          LOG.info(\"Removing StorageLocation \" + sdLocation + \" with id \" +\n              sd.getStorageUuid() + \" from FsDataset.\");\n          // Disable the volume from the service.\n          asyncDiskService.removeVolume(sd.getStorageUuid());\n          volumes.removeVolume(sdLocation, clearFailure);\n          volumes.waitVolumeRemoved(5000, datasetLockCondition);\n\n          // Removed all replica information for the blocks on the volume.\n          // Unlike updating the volumeMap in addVolume(), this operation does\n          // not scan disks.\n          for (String bpid : volumeMap.getBlockPoolList()) {\n            List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n            for (Iterator\u003cReplicaInfo\u003e it \u003d\n                  volumeMap.replicas(bpid).iterator(); it.hasNext();) {\n              ReplicaInfo block \u003d it.next();\n              final StorageLocation blockStorageLocation \u003d\n                  block.getVolume().getStorageLocation();\n              LOG.info(\"checking for block \" + block.getBlockId() +\n                  \" with storageLocation \" + blockStorageLocation);\n              if (blockStorageLocation.equals(sdLocation)) {\n                blocks.add(block);\n                it.remove();\n              }\n            }\n            blkToInvalidate.put(bpid, blocks);\n          }\n\n          storageToRemove.add(sd.getStorageUuid());\n          storageLocationsToRemove.remove(sdLocation);\n        }\n      }\n\n      // A reconfigure can remove the storage location which is already\n      // removed when the failure was detected by DataNode#checkDiskErrorAsync.\n      // Now, lets remove this from the failed volume list.\n      if (clearFailure) {\n        for (StorageLocation storageLocToRemove : storageLocationsToRemove) {\n          volumes.removeVolumeFailureInfo(storageLocToRemove);\n        }\n      }\n      setupAsyncLazyPersistThreads();\n    }\n\n    // Call this outside the lock.\n    for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n        blkToInvalidate.entrySet()) {\n      String bpid \u003d entry.getKey();\n      List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n      for (ReplicaInfo block : blocks) {\n        invalidate(bpid, block);\n      }\n    }\n\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      for(String storageUuid : storageToRemove) {\n        storageMap.remove(storageUuid);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-10637. Modifications to remove the assumption that FsVolumes are backed by java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "10/10/16 3:30 PM",
      "commitName": "96b12662ea76e3ded4ef13944fc8df206cfb4613",
      "commitAuthor": "Lei Xu",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-10637. Modifications to remove the assumption that FsVolumes are backed by java.io.File. (Virajith Jalaparti via lei)\n",
          "commitDate": "10/10/16 3:30 PM",
          "commitName": "96b12662ea76e3ded4ef13944fc8df206cfb4613",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "30/09/16 11:11 PM",
          "commitNameOld": "fe9ebe20ab113567f0777c11cb48ce0d3ce587a8",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 9.68,
          "commitsBetweenForRepo": 64,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,61 +1,61 @@\n-  public void removeVolumes(Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n-    // Make sure that all volumes are absolute path.\n-    for (File vol : volumesToRemove) {\n-      Preconditions.checkArgument(vol.isAbsolute(),\n-          String.format(\"%s is not absolute path.\", vol.getPath()));\n-    }\n-\n+  public void removeVolumes(\n+      Collection\u003cStorageLocation\u003e storageLocationsToRemove,\n+      boolean clearFailure) {\n     Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n     List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n     try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n         Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n-        final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n-        if (volumesToRemove.contains(absRoot)) {\n-          LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n-\n+        final StorageLocation sdLocation \u003d sd.getStorageLocation();\n+        LOG.info(\"Checking removing StorageLocation \" +\n+            sdLocation + \" with id \" + sd.getStorageUuid());\n+        if (storageLocationsToRemove.contains(sdLocation)) {\n+          LOG.info(\"Removing StorageLocation \" + sdLocation + \" with id \" +\n+              sd.getStorageUuid() + \" from FsDataset.\");\n           // Disable the volume from the service.\n-          asyncDiskService.removeVolume(sd.getCurrentDir());\n-          volumes.removeVolume(absRoot, clearFailure);\n+          asyncDiskService.removeVolume(sd.getStorageUuid());\n+          volumes.removeVolume(sdLocation, clearFailure);\n           volumes.waitVolumeRemoved(5000, datasetLockCondition);\n \n           // Removed all replica information for the blocks on the volume.\n           // Unlike updating the volumeMap in addVolume(), this operation does\n           // not scan disks.\n           for (String bpid : volumeMap.getBlockPoolList()) {\n             List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n-            for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n-                 it.hasNext(); ) {\n+            for (Iterator\u003cReplicaInfo\u003e it \u003d\n+                  volumeMap.replicas(bpid).iterator(); it.hasNext();) {\n               ReplicaInfo block \u003d it.next();\n-              final File absBasePath \u003d\n-                  new File(block.getVolume().getBasePath()).getAbsoluteFile();\n-              if (absBasePath.equals(absRoot)) {\n+              final StorageLocation blockStorageLocation \u003d\n+                  block.getVolume().getStorageLocation();\n+              LOG.info(\"checking for block \" + block.getBlockId() +\n+                  \" with storageLocation \" + blockStorageLocation);\n+              if (blockStorageLocation.equals(sdLocation)) {\n                 blocks.add(block);\n                 it.remove();\n               }\n             }\n             blkToInvalidate.put(bpid, blocks);\n           }\n \n           storageToRemove.add(sd.getStorageUuid());\n         }\n       }\n       setupAsyncLazyPersistThreads();\n     }\n \n     // Call this outside the lock.\n     for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n         blkToInvalidate.entrySet()) {\n       String bpid \u003d entry.getKey();\n       List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n       for (ReplicaInfo block : blocks) {\n         invalidate(bpid, block);\n       }\n     }\n \n     try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       for(String storageUuid : storageToRemove) {\n         storageMap.remove(storageUuid);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void removeVolumes(\n      Collection\u003cStorageLocation\u003e storageLocationsToRemove,\n      boolean clearFailure) {\n    Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n    List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n        final StorageLocation sdLocation \u003d sd.getStorageLocation();\n        LOG.info(\"Checking removing StorageLocation \" +\n            sdLocation + \" with id \" + sd.getStorageUuid());\n        if (storageLocationsToRemove.contains(sdLocation)) {\n          LOG.info(\"Removing StorageLocation \" + sdLocation + \" with id \" +\n              sd.getStorageUuid() + \" from FsDataset.\");\n          // Disable the volume from the service.\n          asyncDiskService.removeVolume(sd.getStorageUuid());\n          volumes.removeVolume(sdLocation, clearFailure);\n          volumes.waitVolumeRemoved(5000, datasetLockCondition);\n\n          // Removed all replica information for the blocks on the volume.\n          // Unlike updating the volumeMap in addVolume(), this operation does\n          // not scan disks.\n          for (String bpid : volumeMap.getBlockPoolList()) {\n            List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n            for (Iterator\u003cReplicaInfo\u003e it \u003d\n                  volumeMap.replicas(bpid).iterator(); it.hasNext();) {\n              ReplicaInfo block \u003d it.next();\n              final StorageLocation blockStorageLocation \u003d\n                  block.getVolume().getStorageLocation();\n              LOG.info(\"checking for block \" + block.getBlockId() +\n                  \" with storageLocation \" + blockStorageLocation);\n              if (blockStorageLocation.equals(sdLocation)) {\n                blocks.add(block);\n                it.remove();\n              }\n            }\n            blkToInvalidate.put(bpid, blocks);\n          }\n\n          storageToRemove.add(sd.getStorageUuid());\n        }\n      }\n      setupAsyncLazyPersistThreads();\n    }\n\n    // Call this outside the lock.\n    for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n        blkToInvalidate.entrySet()) {\n      String bpid \u003d entry.getKey();\n      List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n      for (ReplicaInfo block : blocks) {\n        invalidate(bpid, block);\n      }\n    }\n\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      for(String storageUuid : storageToRemove) {\n        storageMap.remove(storageUuid);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldValue": "[volumesToRemove-Set\u003cFile\u003e, clearFailure-boolean]",
            "newValue": "[storageLocationsToRemove-Collection\u003cStorageLocation\u003e, clearFailure-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10637. Modifications to remove the assumption that FsVolumes are backed by java.io.File. (Virajith Jalaparti via lei)\n",
          "commitDate": "10/10/16 3:30 PM",
          "commitName": "96b12662ea76e3ded4ef13944fc8df206cfb4613",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "30/09/16 11:11 PM",
          "commitNameOld": "fe9ebe20ab113567f0777c11cb48ce0d3ce587a8",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 9.68,
          "commitsBetweenForRepo": 64,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,61 +1,61 @@\n-  public void removeVolumes(Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n-    // Make sure that all volumes are absolute path.\n-    for (File vol : volumesToRemove) {\n-      Preconditions.checkArgument(vol.isAbsolute(),\n-          String.format(\"%s is not absolute path.\", vol.getPath()));\n-    }\n-\n+  public void removeVolumes(\n+      Collection\u003cStorageLocation\u003e storageLocationsToRemove,\n+      boolean clearFailure) {\n     Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n     List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n     try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n         Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n-        final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n-        if (volumesToRemove.contains(absRoot)) {\n-          LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n-\n+        final StorageLocation sdLocation \u003d sd.getStorageLocation();\n+        LOG.info(\"Checking removing StorageLocation \" +\n+            sdLocation + \" with id \" + sd.getStorageUuid());\n+        if (storageLocationsToRemove.contains(sdLocation)) {\n+          LOG.info(\"Removing StorageLocation \" + sdLocation + \" with id \" +\n+              sd.getStorageUuid() + \" from FsDataset.\");\n           // Disable the volume from the service.\n-          asyncDiskService.removeVolume(sd.getCurrentDir());\n-          volumes.removeVolume(absRoot, clearFailure);\n+          asyncDiskService.removeVolume(sd.getStorageUuid());\n+          volumes.removeVolume(sdLocation, clearFailure);\n           volumes.waitVolumeRemoved(5000, datasetLockCondition);\n \n           // Removed all replica information for the blocks on the volume.\n           // Unlike updating the volumeMap in addVolume(), this operation does\n           // not scan disks.\n           for (String bpid : volumeMap.getBlockPoolList()) {\n             List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n-            for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n-                 it.hasNext(); ) {\n+            for (Iterator\u003cReplicaInfo\u003e it \u003d\n+                  volumeMap.replicas(bpid).iterator(); it.hasNext();) {\n               ReplicaInfo block \u003d it.next();\n-              final File absBasePath \u003d\n-                  new File(block.getVolume().getBasePath()).getAbsoluteFile();\n-              if (absBasePath.equals(absRoot)) {\n+              final StorageLocation blockStorageLocation \u003d\n+                  block.getVolume().getStorageLocation();\n+              LOG.info(\"checking for block \" + block.getBlockId() +\n+                  \" with storageLocation \" + blockStorageLocation);\n+              if (blockStorageLocation.equals(sdLocation)) {\n                 blocks.add(block);\n                 it.remove();\n               }\n             }\n             blkToInvalidate.put(bpid, blocks);\n           }\n \n           storageToRemove.add(sd.getStorageUuid());\n         }\n       }\n       setupAsyncLazyPersistThreads();\n     }\n \n     // Call this outside the lock.\n     for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n         blkToInvalidate.entrySet()) {\n       String bpid \u003d entry.getKey();\n       List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n       for (ReplicaInfo block : blocks) {\n         invalidate(bpid, block);\n       }\n     }\n \n     try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       for(String storageUuid : storageToRemove) {\n         storageMap.remove(storageUuid);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void removeVolumes(\n      Collection\u003cStorageLocation\u003e storageLocationsToRemove,\n      boolean clearFailure) {\n    Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n    List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n        final StorageLocation sdLocation \u003d sd.getStorageLocation();\n        LOG.info(\"Checking removing StorageLocation \" +\n            sdLocation + \" with id \" + sd.getStorageUuid());\n        if (storageLocationsToRemove.contains(sdLocation)) {\n          LOG.info(\"Removing StorageLocation \" + sdLocation + \" with id \" +\n              sd.getStorageUuid() + \" from FsDataset.\");\n          // Disable the volume from the service.\n          asyncDiskService.removeVolume(sd.getStorageUuid());\n          volumes.removeVolume(sdLocation, clearFailure);\n          volumes.waitVolumeRemoved(5000, datasetLockCondition);\n\n          // Removed all replica information for the blocks on the volume.\n          // Unlike updating the volumeMap in addVolume(), this operation does\n          // not scan disks.\n          for (String bpid : volumeMap.getBlockPoolList()) {\n            List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n            for (Iterator\u003cReplicaInfo\u003e it \u003d\n                  volumeMap.replicas(bpid).iterator(); it.hasNext();) {\n              ReplicaInfo block \u003d it.next();\n              final StorageLocation blockStorageLocation \u003d\n                  block.getVolume().getStorageLocation();\n              LOG.info(\"checking for block \" + block.getBlockId() +\n                  \" with storageLocation \" + blockStorageLocation);\n              if (blockStorageLocation.equals(sdLocation)) {\n                blocks.add(block);\n                it.remove();\n              }\n            }\n            blkToInvalidate.put(bpid, blocks);\n          }\n\n          storageToRemove.add(sd.getStorageUuid());\n        }\n      }\n      setupAsyncLazyPersistThreads();\n    }\n\n    // Call this outside the lock.\n    for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n        blkToInvalidate.entrySet()) {\n      String bpid \u003d entry.getKey();\n      List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n      for (ReplicaInfo block : blocks) {\n        invalidate(bpid, block);\n      }\n    }\n\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      for(String storageUuid : storageToRemove) {\n        storageMap.remove(storageUuid);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "a99bf26a0899bcc4307c3a242c8414eaef555aa7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10830. FsDatasetImpl#removeVolumes crashes with IllegalMonitorStateException when vol being removed is in use. (Arpit Agarwal and Manoj Govindassamy)\n",
      "commitDate": "10/09/16 6:22 PM",
      "commitName": "a99bf26a0899bcc4307c3a242c8414eaef555aa7",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "08/09/16 5:53 PM",
      "commitNameOld": "011f3b24d4bfda505a90ab5b5576916a41f869c5",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 2.02,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,61 +1,61 @@\n   public void removeVolumes(Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n     // Make sure that all volumes are absolute path.\n     for (File vol : volumesToRemove) {\n       Preconditions.checkArgument(vol.isAbsolute(),\n           String.format(\"%s is not absolute path.\", vol.getPath()));\n     }\n \n     Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n     List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n     try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n         Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n         final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n         if (volumesToRemove.contains(absRoot)) {\n           LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n \n           // Disable the volume from the service.\n           asyncDiskService.removeVolume(sd.getCurrentDir());\n           volumes.removeVolume(absRoot, clearFailure);\n-          volumes.waitVolumeRemoved(5000, this);\n+          volumes.waitVolumeRemoved(5000, datasetLockCondition);\n \n           // Removed all replica information for the blocks on the volume.\n           // Unlike updating the volumeMap in addVolume(), this operation does\n           // not scan disks.\n           for (String bpid : volumeMap.getBlockPoolList()) {\n             List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n             for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n                  it.hasNext(); ) {\n               ReplicaInfo block \u003d it.next();\n               final File absBasePath \u003d\n                   new File(block.getVolume().getBasePath()).getAbsoluteFile();\n               if (absBasePath.equals(absRoot)) {\n                 blocks.add(block);\n                 it.remove();\n               }\n             }\n             blkToInvalidate.put(bpid, blocks);\n           }\n \n           storageToRemove.add(sd.getStorageUuid());\n         }\n       }\n       setupAsyncLazyPersistThreads();\n     }\n \n     // Call this outside the lock.\n     for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n         blkToInvalidate.entrySet()) {\n       String bpid \u003d entry.getKey();\n       List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n       for (ReplicaInfo block : blocks) {\n         invalidate(bpid, block);\n       }\n     }\n \n     try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       for(String storageUuid : storageToRemove) {\n         storageMap.remove(storageUuid);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void removeVolumes(Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n    // Make sure that all volumes are absolute path.\n    for (File vol : volumesToRemove) {\n      Preconditions.checkArgument(vol.isAbsolute(),\n          String.format(\"%s is not absolute path.\", vol.getPath()));\n    }\n\n    Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n    List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n        final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n        if (volumesToRemove.contains(absRoot)) {\n          LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n\n          // Disable the volume from the service.\n          asyncDiskService.removeVolume(sd.getCurrentDir());\n          volumes.removeVolume(absRoot, clearFailure);\n          volumes.waitVolumeRemoved(5000, datasetLockCondition);\n\n          // Removed all replica information for the blocks on the volume.\n          // Unlike updating the volumeMap in addVolume(), this operation does\n          // not scan disks.\n          for (String bpid : volumeMap.getBlockPoolList()) {\n            List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n            for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n                 it.hasNext(); ) {\n              ReplicaInfo block \u003d it.next();\n              final File absBasePath \u003d\n                  new File(block.getVolume().getBasePath()).getAbsoluteFile();\n              if (absBasePath.equals(absRoot)) {\n                blocks.add(block);\n                it.remove();\n              }\n            }\n            blkToInvalidate.put(bpid, blocks);\n          }\n\n          storageToRemove.add(sd.getStorageUuid());\n        }\n      }\n      setupAsyncLazyPersistThreads();\n    }\n\n    // Call this outside the lock.\n    for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n        blkToInvalidate.entrySet()) {\n      String bpid \u003d entry.getKey();\n      List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n      for (ReplicaInfo block : blocks) {\n        invalidate(bpid, block);\n      }\n    }\n\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      for(String storageUuid : storageToRemove) {\n        storageMap.remove(storageUuid);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10682. Replace FsDatasetImpl object lock with a separate lock object. (Chen Liang)\n",
      "commitDate": "08/08/16 12:02 PM",
      "commitName": "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "08/07/16 7:40 PM",
      "commitNameOld": "da6f1b88dd47e22b24d44f6fc8bbee73e85746f7",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 30.68,
      "commitsBetweenForRepo": 320,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,61 +1,61 @@\n   public void removeVolumes(Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n     // Make sure that all volumes are absolute path.\n     for (File vol : volumesToRemove) {\n       Preconditions.checkArgument(vol.isAbsolute(),\n           String.format(\"%s is not absolute path.\", vol.getPath()));\n     }\n \n     Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n     List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n-    synchronized (this) {\n+    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n         Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n         final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n         if (volumesToRemove.contains(absRoot)) {\n           LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n \n           // Disable the volume from the service.\n           asyncDiskService.removeVolume(sd.getCurrentDir());\n           volumes.removeVolume(absRoot, clearFailure);\n           volumes.waitVolumeRemoved(5000, this);\n \n           // Removed all replica information for the blocks on the volume.\n           // Unlike updating the volumeMap in addVolume(), this operation does\n           // not scan disks.\n           for (String bpid : volumeMap.getBlockPoolList()) {\n             List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n             for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n                  it.hasNext(); ) {\n               ReplicaInfo block \u003d it.next();\n               final File absBasePath \u003d\n                   new File(block.getVolume().getBasePath()).getAbsoluteFile();\n               if (absBasePath.equals(absRoot)) {\n                 blocks.add(block);\n                 it.remove();\n               }\n             }\n             blkToInvalidate.put(bpid, blocks);\n           }\n \n           storageToRemove.add(sd.getStorageUuid());\n         }\n       }\n       setupAsyncLazyPersistThreads();\n     }\n \n     // Call this outside the lock.\n     for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n         blkToInvalidate.entrySet()) {\n       String bpid \u003d entry.getKey();\n       List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n       for (ReplicaInfo block : blocks) {\n         invalidate(bpid, block);\n       }\n     }\n \n-    synchronized (this) {\n+    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n       for(String storageUuid : storageToRemove) {\n         storageMap.remove(storageUuid);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void removeVolumes(Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n    // Make sure that all volumes are absolute path.\n    for (File vol : volumesToRemove) {\n      Preconditions.checkArgument(vol.isAbsolute(),\n          String.format(\"%s is not absolute path.\", vol.getPath()));\n    }\n\n    Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n    List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n        final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n        if (volumesToRemove.contains(absRoot)) {\n          LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n\n          // Disable the volume from the service.\n          asyncDiskService.removeVolume(sd.getCurrentDir());\n          volumes.removeVolume(absRoot, clearFailure);\n          volumes.waitVolumeRemoved(5000, this);\n\n          // Removed all replica information for the blocks on the volume.\n          // Unlike updating the volumeMap in addVolume(), this operation does\n          // not scan disks.\n          for (String bpid : volumeMap.getBlockPoolList()) {\n            List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n            for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n                 it.hasNext(); ) {\n              ReplicaInfo block \u003d it.next();\n              final File absBasePath \u003d\n                  new File(block.getVolume().getBasePath()).getAbsoluteFile();\n              if (absBasePath.equals(absRoot)) {\n                blocks.add(block);\n                it.remove();\n              }\n            }\n            blkToInvalidate.put(bpid, blocks);\n          }\n\n          storageToRemove.add(sd.getStorageUuid());\n        }\n      }\n      setupAsyncLazyPersistThreads();\n    }\n\n    // Call this outside the lock.\n    for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n        blkToInvalidate.entrySet()) {\n      String bpid \u003d entry.getKey();\n      List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n      for (ReplicaInfo block : blocks) {\n        invalidate(bpid, block);\n      }\n    }\n\n    try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n      for(String storageUuid : storageToRemove) {\n        storageMap.remove(storageUuid);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "e50aa53eed3d0ff1bc8fe60381524bb3bbe53bc1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9701. DN may deadlock when hot-swapping under load. (Xiao Chen via lei)\n",
      "commitDate": "01/02/16 12:56 PM",
      "commitName": "e50aa53eed3d0ff1bc8fe60381524bb3bbe53bc1",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "20/01/16 7:34 AM",
      "commitNameOld": "14255786908f991fd2022480fe5575533a3dc7ce",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 12.22,
      "commitsBetweenForRepo": 83,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,60 +1,61 @@\n   public void removeVolumes(Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n     // Make sure that all volumes are absolute path.\n     for (File vol : volumesToRemove) {\n       Preconditions.checkArgument(vol.isAbsolute(),\n           String.format(\"%s is not absolute path.\", vol.getPath()));\n     }\n \n     Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n     List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n     synchronized (this) {\n       for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n         Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n         final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n         if (volumesToRemove.contains(absRoot)) {\n           LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n \n           // Disable the volume from the service.\n           asyncDiskService.removeVolume(sd.getCurrentDir());\n           volumes.removeVolume(absRoot, clearFailure);\n+          volumes.waitVolumeRemoved(5000, this);\n \n           // Removed all replica information for the blocks on the volume.\n           // Unlike updating the volumeMap in addVolume(), this operation does\n           // not scan disks.\n           for (String bpid : volumeMap.getBlockPoolList()) {\n             List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n             for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n                  it.hasNext(); ) {\n               ReplicaInfo block \u003d it.next();\n               final File absBasePath \u003d\n                   new File(block.getVolume().getBasePath()).getAbsoluteFile();\n               if (absBasePath.equals(absRoot)) {\n                 blocks.add(block);\n                 it.remove();\n               }\n             }\n             blkToInvalidate.put(bpid, blocks);\n           }\n \n           storageToRemove.add(sd.getStorageUuid());\n         }\n       }\n       setupAsyncLazyPersistThreads();\n     }\n \n     // Call this outside the lock.\n     for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n         blkToInvalidate.entrySet()) {\n       String bpid \u003d entry.getKey();\n       List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n       for (ReplicaInfo block : blocks) {\n         invalidate(bpid, block);\n       }\n     }\n \n     synchronized (this) {\n       for(String storageUuid : storageToRemove) {\n         storageMap.remove(storageUuid);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void removeVolumes(Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n    // Make sure that all volumes are absolute path.\n    for (File vol : volumesToRemove) {\n      Preconditions.checkArgument(vol.isAbsolute(),\n          String.format(\"%s is not absolute path.\", vol.getPath()));\n    }\n\n    Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n    List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n    synchronized (this) {\n      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n        final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n        if (volumesToRemove.contains(absRoot)) {\n          LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n\n          // Disable the volume from the service.\n          asyncDiskService.removeVolume(sd.getCurrentDir());\n          volumes.removeVolume(absRoot, clearFailure);\n          volumes.waitVolumeRemoved(5000, this);\n\n          // Removed all replica information for the blocks on the volume.\n          // Unlike updating the volumeMap in addVolume(), this operation does\n          // not scan disks.\n          for (String bpid : volumeMap.getBlockPoolList()) {\n            List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n            for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n                 it.hasNext(); ) {\n              ReplicaInfo block \u003d it.next();\n              final File absBasePath \u003d\n                  new File(block.getVolume().getBasePath()).getAbsoluteFile();\n              if (absBasePath.equals(absRoot)) {\n                blocks.add(block);\n                it.remove();\n              }\n            }\n            blkToInvalidate.put(bpid, blocks);\n          }\n\n          storageToRemove.add(sd.getStorageUuid());\n        }\n      }\n      setupAsyncLazyPersistThreads();\n    }\n\n    // Call this outside the lock.\n    for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n        blkToInvalidate.entrySet()) {\n      String bpid \u003d entry.getKey();\n      List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n      for (ReplicaInfo block : blocks) {\n        invalidate(bpid, block);\n      }\n    }\n\n    synchronized (this) {\n      for(String storageUuid : storageToRemove) {\n        storageMap.remove(storageUuid);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "a48301791e9564363bc2abad4e89e344b0d7a5ff": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-9445. Datanode may deadlock while handling a bad volume. Contributed by Walter Su.\n",
      "commitDate": "11/12/15 6:44 AM",
      "commitName": "a48301791e9564363bc2abad4e89e344b0d7a5ff",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-9445. Datanode may deadlock while handling a bad volume. Contributed by Walter Su.\n",
          "commitDate": "11/12/15 6:44 AM",
          "commitName": "a48301791e9564363bc2abad4e89e344b0d7a5ff",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "10/12/15 12:57 PM",
          "commitNameOld": "7f393a6f61f5a34a1de11481ad321c6a941d5d27",
          "commitAuthorOld": "Lei Xu",
          "daysBetweenCommits": 0.74,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,60 @@\n-  public synchronized void removeVolumes(\n-      Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n+  public void removeVolumes(Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n     // Make sure that all volumes are absolute path.\n     for (File vol : volumesToRemove) {\n       Preconditions.checkArgument(vol.isAbsolute(),\n           String.format(\"%s is not absolute path.\", vol.getPath()));\n     }\n-    for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n-      Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n-      final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n-      if (volumesToRemove.contains(absRoot)) {\n-        LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n \n-        // Disable the volume from the service.\n-        asyncDiskService.removeVolume(sd.getCurrentDir());\n-        volumes.removeVolume(absRoot, clearFailure);\n+    Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n+    List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n+    synchronized (this) {\n+      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n+        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n+        final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n+        if (volumesToRemove.contains(absRoot)) {\n+          LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n \n-        // Removed all replica information for the blocks on the volume. Unlike\n-        // updating the volumeMap in addVolume(), this operation does not scan\n-        // disks.\n-        for (String bpid : volumeMap.getBlockPoolList()) {\n-          for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n-               it.hasNext(); ) {\n-            ReplicaInfo block \u003d it.next();\n-            final File absBasePath \u003d\n-                new File(block.getVolume().getBasePath()).getAbsoluteFile();\n-            if (absBasePath.equals(absRoot)) {\n-              invalidate(bpid, block);\n-              it.remove();\n+          // Disable the volume from the service.\n+          asyncDiskService.removeVolume(sd.getCurrentDir());\n+          volumes.removeVolume(absRoot, clearFailure);\n+\n+          // Removed all replica information for the blocks on the volume.\n+          // Unlike updating the volumeMap in addVolume(), this operation does\n+          // not scan disks.\n+          for (String bpid : volumeMap.getBlockPoolList()) {\n+            List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n+            for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n+                 it.hasNext(); ) {\n+              ReplicaInfo block \u003d it.next();\n+              final File absBasePath \u003d\n+                  new File(block.getVolume().getBasePath()).getAbsoluteFile();\n+              if (absBasePath.equals(absRoot)) {\n+                blocks.add(block);\n+                it.remove();\n+              }\n             }\n+            blkToInvalidate.put(bpid, blocks);\n           }\n-        }\n \n-        storageMap.remove(sd.getStorageUuid());\n+          storageToRemove.add(sd.getStorageUuid());\n+        }\n+      }\n+      setupAsyncLazyPersistThreads();\n+    }\n+\n+    // Call this outside the lock.\n+    for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n+        blkToInvalidate.entrySet()) {\n+      String bpid \u003d entry.getKey();\n+      List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n+      for (ReplicaInfo block : blocks) {\n+        invalidate(bpid, block);\n       }\n     }\n-    setupAsyncLazyPersistThreads();\n+\n+    synchronized (this) {\n+      for(String storageUuid : storageToRemove) {\n+        storageMap.remove(storageUuid);\n+      }\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void removeVolumes(Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n    // Make sure that all volumes are absolute path.\n    for (File vol : volumesToRemove) {\n      Preconditions.checkArgument(vol.isAbsolute(),\n          String.format(\"%s is not absolute path.\", vol.getPath()));\n    }\n\n    Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n    List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n    synchronized (this) {\n      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n        final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n        if (volumesToRemove.contains(absRoot)) {\n          LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n\n          // Disable the volume from the service.\n          asyncDiskService.removeVolume(sd.getCurrentDir());\n          volumes.removeVolume(absRoot, clearFailure);\n\n          // Removed all replica information for the blocks on the volume.\n          // Unlike updating the volumeMap in addVolume(), this operation does\n          // not scan disks.\n          for (String bpid : volumeMap.getBlockPoolList()) {\n            List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n            for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n                 it.hasNext(); ) {\n              ReplicaInfo block \u003d it.next();\n              final File absBasePath \u003d\n                  new File(block.getVolume().getBasePath()).getAbsoluteFile();\n              if (absBasePath.equals(absRoot)) {\n                blocks.add(block);\n                it.remove();\n              }\n            }\n            blkToInvalidate.put(bpid, blocks);\n          }\n\n          storageToRemove.add(sd.getStorageUuid());\n        }\n      }\n      setupAsyncLazyPersistThreads();\n    }\n\n    // Call this outside the lock.\n    for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n        blkToInvalidate.entrySet()) {\n      String bpid \u003d entry.getKey();\n      List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n      for (ReplicaInfo block : blocks) {\n        invalidate(bpid, block);\n      }\n    }\n\n    synchronized (this) {\n      for(String storageUuid : storageToRemove) {\n        storageMap.remove(storageUuid);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldValue": "[public, synchronized]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9445. Datanode may deadlock while handling a bad volume. Contributed by Walter Su.\n",
          "commitDate": "11/12/15 6:44 AM",
          "commitName": "a48301791e9564363bc2abad4e89e344b0d7a5ff",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "10/12/15 12:57 PM",
          "commitNameOld": "7f393a6f61f5a34a1de11481ad321c6a941d5d27",
          "commitAuthorOld": "Lei Xu",
          "daysBetweenCommits": 0.74,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,60 @@\n-  public synchronized void removeVolumes(\n-      Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n+  public void removeVolumes(Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n     // Make sure that all volumes are absolute path.\n     for (File vol : volumesToRemove) {\n       Preconditions.checkArgument(vol.isAbsolute(),\n           String.format(\"%s is not absolute path.\", vol.getPath()));\n     }\n-    for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n-      Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n-      final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n-      if (volumesToRemove.contains(absRoot)) {\n-        LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n \n-        // Disable the volume from the service.\n-        asyncDiskService.removeVolume(sd.getCurrentDir());\n-        volumes.removeVolume(absRoot, clearFailure);\n+    Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n+    List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n+    synchronized (this) {\n+      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n+        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n+        final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n+        if (volumesToRemove.contains(absRoot)) {\n+          LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n \n-        // Removed all replica information for the blocks on the volume. Unlike\n-        // updating the volumeMap in addVolume(), this operation does not scan\n-        // disks.\n-        for (String bpid : volumeMap.getBlockPoolList()) {\n-          for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n-               it.hasNext(); ) {\n-            ReplicaInfo block \u003d it.next();\n-            final File absBasePath \u003d\n-                new File(block.getVolume().getBasePath()).getAbsoluteFile();\n-            if (absBasePath.equals(absRoot)) {\n-              invalidate(bpid, block);\n-              it.remove();\n+          // Disable the volume from the service.\n+          asyncDiskService.removeVolume(sd.getCurrentDir());\n+          volumes.removeVolume(absRoot, clearFailure);\n+\n+          // Removed all replica information for the blocks on the volume.\n+          // Unlike updating the volumeMap in addVolume(), this operation does\n+          // not scan disks.\n+          for (String bpid : volumeMap.getBlockPoolList()) {\n+            List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n+            for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n+                 it.hasNext(); ) {\n+              ReplicaInfo block \u003d it.next();\n+              final File absBasePath \u003d\n+                  new File(block.getVolume().getBasePath()).getAbsoluteFile();\n+              if (absBasePath.equals(absRoot)) {\n+                blocks.add(block);\n+                it.remove();\n+              }\n             }\n+            blkToInvalidate.put(bpid, blocks);\n           }\n-        }\n \n-        storageMap.remove(sd.getStorageUuid());\n+          storageToRemove.add(sd.getStorageUuid());\n+        }\n+      }\n+      setupAsyncLazyPersistThreads();\n+    }\n+\n+    // Call this outside the lock.\n+    for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n+        blkToInvalidate.entrySet()) {\n+      String bpid \u003d entry.getKey();\n+      List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n+      for (ReplicaInfo block : blocks) {\n+        invalidate(bpid, block);\n       }\n     }\n-    setupAsyncLazyPersistThreads();\n+\n+    synchronized (this) {\n+      for(String storageUuid : storageToRemove) {\n+        storageMap.remove(storageUuid);\n+      }\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void removeVolumes(Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n    // Make sure that all volumes are absolute path.\n    for (File vol : volumesToRemove) {\n      Preconditions.checkArgument(vol.isAbsolute(),\n          String.format(\"%s is not absolute path.\", vol.getPath()));\n    }\n\n    Map\u003cString, List\u003cReplicaInfo\u003e\u003e blkToInvalidate \u003d new HashMap\u003c\u003e();\n    List\u003cString\u003e storageToRemove \u003d new ArrayList\u003c\u003e();\n    synchronized (this) {\n      for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n        Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n        final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n        if (volumesToRemove.contains(absRoot)) {\n          LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n\n          // Disable the volume from the service.\n          asyncDiskService.removeVolume(sd.getCurrentDir());\n          volumes.removeVolume(absRoot, clearFailure);\n\n          // Removed all replica information for the blocks on the volume.\n          // Unlike updating the volumeMap in addVolume(), this operation does\n          // not scan disks.\n          for (String bpid : volumeMap.getBlockPoolList()) {\n            List\u003cReplicaInfo\u003e blocks \u003d new ArrayList\u003c\u003e();\n            for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n                 it.hasNext(); ) {\n              ReplicaInfo block \u003d it.next();\n              final File absBasePath \u003d\n                  new File(block.getVolume().getBasePath()).getAbsoluteFile();\n              if (absBasePath.equals(absRoot)) {\n                blocks.add(block);\n                it.remove();\n              }\n            }\n            blkToInvalidate.put(bpid, blocks);\n          }\n\n          storageToRemove.add(sd.getStorageUuid());\n        }\n      }\n      setupAsyncLazyPersistThreads();\n    }\n\n    // Call this outside the lock.\n    for (Map.Entry\u003cString, List\u003cReplicaInfo\u003e\u003e entry :\n        blkToInvalidate.entrySet()) {\n      String bpid \u003d entry.getKey();\n      List\u003cReplicaInfo\u003e blocks \u003d entry.getValue();\n      for (ReplicaInfo block : blocks) {\n        invalidate(bpid, block);\n      }\n    }\n\n    synchronized (this) {\n      for(String storageUuid : storageToRemove) {\n        storageMap.remove(storageUuid);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "b49c3a1813aa8c5b05fe6c02a653286c573137ca": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7722. DataNode#checkDiskError should also remove Storage when error is found. (Lei Xu via Colin P. McCabe)\n",
      "commitDate": "12/03/15 12:00 PM",
      "commitName": "b49c3a1813aa8c5b05fe6c02a653286c573137ca",
      "commitAuthor": "Colin Patrick Mccabe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7722. DataNode#checkDiskError should also remove Storage when error is found. (Lei Xu via Colin P. McCabe)\n",
          "commitDate": "12/03/15 12:00 PM",
          "commitName": "b49c3a1813aa8c5b05fe6c02a653286c573137ca",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "12/03/15 11:25 AM",
          "commitNameOld": "6dae6d12ec5abb716e1501cd4e18b10ae7809b94",
          "commitAuthorOld": "Tsz-Wo Nicholas Sze",
          "daysBetweenCommits": 0.02,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,38 @@\n-  public synchronized void removeVolumes(Collection\u003cStorageLocation\u003e volumes) {\n-    Set\u003cString\u003e volumeSet \u003d new HashSet\u003c\u003e();\n-    for (StorageLocation sl : volumes) {\n-      volumeSet.add(sl.getFile().getAbsolutePath());\n+  public synchronized void removeVolumes(\n+      Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n+    // Make sure that all volumes are absolute path.\n+    for (File vol : volumesToRemove) {\n+      Preconditions.checkArgument(vol.isAbsolute(),\n+          String.format(\"%s is not absolute path.\", vol.getPath()));\n     }\n     for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n       Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n-      String volume \u003d sd.getRoot().getAbsolutePath();\n-      if (volumeSet.contains(volume)) {\n-        LOG.info(\"Removing \" + volume + \" from FsDataset.\");\n+      final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n+      if (volumesToRemove.contains(absRoot)) {\n+        LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n \n         // Disable the volume from the service.\n         asyncDiskService.removeVolume(sd.getCurrentDir());\n-        this.volumes.removeVolume(sd.getRoot());\n+        volumes.removeVolume(absRoot, clearFailure);\n \n         // Removed all replica information for the blocks on the volume. Unlike\n         // updating the volumeMap in addVolume(), this operation does not scan\n         // disks.\n         for (String bpid : volumeMap.getBlockPoolList()) {\n-          List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n           for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n-              it.hasNext(); ) {\n+               it.hasNext(); ) {\n             ReplicaInfo block \u003d it.next();\n-            String absBasePath \u003d\n-                  new File(block.getVolume().getBasePath()).getAbsolutePath();\n-            if (absBasePath.equals(volume)) {\n+            final File absBasePath \u003d\n+                new File(block.getVolume().getBasePath()).getAbsoluteFile();\n+            if (absBasePath.equals(absRoot)) {\n               invalidate(bpid, block);\n-              blocks.add(block);\n               it.remove();\n             }\n           }\n         }\n \n         storageMap.remove(sd.getStorageUuid());\n       }\n     }\n     setupAsyncLazyPersistThreads();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void removeVolumes(\n      Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n    // Make sure that all volumes are absolute path.\n    for (File vol : volumesToRemove) {\n      Preconditions.checkArgument(vol.isAbsolute(),\n          String.format(\"%s is not absolute path.\", vol.getPath()));\n    }\n    for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n      Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n      final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n      if (volumesToRemove.contains(absRoot)) {\n        LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n\n        // Disable the volume from the service.\n        asyncDiskService.removeVolume(sd.getCurrentDir());\n        volumes.removeVolume(absRoot, clearFailure);\n\n        // Removed all replica information for the blocks on the volume. Unlike\n        // updating the volumeMap in addVolume(), this operation does not scan\n        // disks.\n        for (String bpid : volumeMap.getBlockPoolList()) {\n          for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n               it.hasNext(); ) {\n            ReplicaInfo block \u003d it.next();\n            final File absBasePath \u003d\n                new File(block.getVolume().getBasePath()).getAbsoluteFile();\n            if (absBasePath.equals(absRoot)) {\n              invalidate(bpid, block);\n              it.remove();\n            }\n          }\n        }\n\n        storageMap.remove(sd.getStorageUuid());\n      }\n    }\n    setupAsyncLazyPersistThreads();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldValue": "[volumes-Collection\u003cStorageLocation\u003e]",
            "newValue": "[volumesToRemove-Set\u003cFile\u003e, clearFailure-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7722. DataNode#checkDiskError should also remove Storage when error is found. (Lei Xu via Colin P. McCabe)\n",
          "commitDate": "12/03/15 12:00 PM",
          "commitName": "b49c3a1813aa8c5b05fe6c02a653286c573137ca",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "12/03/15 11:25 AM",
          "commitNameOld": "6dae6d12ec5abb716e1501cd4e18b10ae7809b94",
          "commitAuthorOld": "Tsz-Wo Nicholas Sze",
          "daysBetweenCommits": 0.02,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,38 @@\n-  public synchronized void removeVolumes(Collection\u003cStorageLocation\u003e volumes) {\n-    Set\u003cString\u003e volumeSet \u003d new HashSet\u003c\u003e();\n-    for (StorageLocation sl : volumes) {\n-      volumeSet.add(sl.getFile().getAbsolutePath());\n+  public synchronized void removeVolumes(\n+      Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n+    // Make sure that all volumes are absolute path.\n+    for (File vol : volumesToRemove) {\n+      Preconditions.checkArgument(vol.isAbsolute(),\n+          String.format(\"%s is not absolute path.\", vol.getPath()));\n     }\n     for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n       Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n-      String volume \u003d sd.getRoot().getAbsolutePath();\n-      if (volumeSet.contains(volume)) {\n-        LOG.info(\"Removing \" + volume + \" from FsDataset.\");\n+      final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n+      if (volumesToRemove.contains(absRoot)) {\n+        LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n \n         // Disable the volume from the service.\n         asyncDiskService.removeVolume(sd.getCurrentDir());\n-        this.volumes.removeVolume(sd.getRoot());\n+        volumes.removeVolume(absRoot, clearFailure);\n \n         // Removed all replica information for the blocks on the volume. Unlike\n         // updating the volumeMap in addVolume(), this operation does not scan\n         // disks.\n         for (String bpid : volumeMap.getBlockPoolList()) {\n-          List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n           for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n-              it.hasNext(); ) {\n+               it.hasNext(); ) {\n             ReplicaInfo block \u003d it.next();\n-            String absBasePath \u003d\n-                  new File(block.getVolume().getBasePath()).getAbsolutePath();\n-            if (absBasePath.equals(volume)) {\n+            final File absBasePath \u003d\n+                new File(block.getVolume().getBasePath()).getAbsoluteFile();\n+            if (absBasePath.equals(absRoot)) {\n               invalidate(bpid, block);\n-              blocks.add(block);\n               it.remove();\n             }\n           }\n         }\n \n         storageMap.remove(sd.getStorageUuid());\n       }\n     }\n     setupAsyncLazyPersistThreads();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void removeVolumes(\n      Set\u003cFile\u003e volumesToRemove, boolean clearFailure) {\n    // Make sure that all volumes are absolute path.\n    for (File vol : volumesToRemove) {\n      Preconditions.checkArgument(vol.isAbsolute(),\n          String.format(\"%s is not absolute path.\", vol.getPath()));\n    }\n    for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n      Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n      final File absRoot \u003d sd.getRoot().getAbsoluteFile();\n      if (volumesToRemove.contains(absRoot)) {\n        LOG.info(\"Removing \" + absRoot + \" from FsDataset.\");\n\n        // Disable the volume from the service.\n        asyncDiskService.removeVolume(sd.getCurrentDir());\n        volumes.removeVolume(absRoot, clearFailure);\n\n        // Removed all replica information for the blocks on the volume. Unlike\n        // updating the volumeMap in addVolume(), this operation does not scan\n        // disks.\n        for (String bpid : volumeMap.getBlockPoolList()) {\n          for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n               it.hasNext(); ) {\n            ReplicaInfo block \u003d it.next();\n            final File absBasePath \u003d\n                new File(block.getVolume().getBasePath()).getAbsoluteFile();\n            if (absBasePath.equals(absRoot)) {\n              invalidate(bpid, block);\n              it.remove();\n            }\n          }\n        }\n\n        storageMap.remove(sd.getStorageUuid());\n      }\n    }\n    setupAsyncLazyPersistThreads();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "6e62a1a6728b1f782f64065424f92b292c3f163a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7430. Refactor the BlockScanner to use O(1) memory and use multiple threads (cmccabe)\n",
      "commitDate": "21/01/15 7:00 PM",
      "commitName": "6e62a1a6728b1f782f64065424f92b292c3f163a",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "21/01/15 12:41 PM",
      "commitNameOld": "c0af72c7f74b6925786e24543cac433b906dd6d3",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.26,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,38 @@\n   public synchronized void removeVolumes(Collection\u003cStorageLocation\u003e volumes) {\n     Set\u003cString\u003e volumeSet \u003d new HashSet\u003c\u003e();\n     for (StorageLocation sl : volumes) {\n       volumeSet.add(sl.getFile().getAbsolutePath());\n     }\n     for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n       Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n       String volume \u003d sd.getRoot().getAbsolutePath();\n       if (volumeSet.contains(volume)) {\n         LOG.info(\"Removing \" + volume + \" from FsDataset.\");\n \n         // Disable the volume from the service.\n         asyncDiskService.removeVolume(sd.getCurrentDir());\n         this.volumes.removeVolume(sd.getRoot());\n \n         // Removed all replica information for the blocks on the volume. Unlike\n         // updating the volumeMap in addVolume(), this operation does not scan\n         // disks.\n         for (String bpid : volumeMap.getBlockPoolList()) {\n           List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n           for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n               it.hasNext(); ) {\n             ReplicaInfo block \u003d it.next();\n             String absBasePath \u003d\n                   new File(block.getVolume().getBasePath()).getAbsolutePath();\n             if (absBasePath.equals(volume)) {\n               invalidate(bpid, block);\n               blocks.add(block);\n               it.remove();\n             }\n           }\n-          // Delete blocks from the block scanner in batch.\n-          datanode.getBlockScanner().deleteBlocks(bpid,\n-              blocks.toArray(new Block[blocks.size()]));\n         }\n \n         storageMap.remove(sd.getStorageUuid());\n       }\n     }\n     setupAsyncLazyPersistThreads();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void removeVolumes(Collection\u003cStorageLocation\u003e volumes) {\n    Set\u003cString\u003e volumeSet \u003d new HashSet\u003c\u003e();\n    for (StorageLocation sl : volumes) {\n      volumeSet.add(sl.getFile().getAbsolutePath());\n    }\n    for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n      Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n      String volume \u003d sd.getRoot().getAbsolutePath();\n      if (volumeSet.contains(volume)) {\n        LOG.info(\"Removing \" + volume + \" from FsDataset.\");\n\n        // Disable the volume from the service.\n        asyncDiskService.removeVolume(sd.getCurrentDir());\n        this.volumes.removeVolume(sd.getRoot());\n\n        // Removed all replica information for the blocks on the volume. Unlike\n        // updating the volumeMap in addVolume(), this operation does not scan\n        // disks.\n        for (String bpid : volumeMap.getBlockPoolList()) {\n          List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n          for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n              it.hasNext(); ) {\n            ReplicaInfo block \u003d it.next();\n            String absBasePath \u003d\n                  new File(block.getVolume().getBasePath()).getAbsolutePath();\n            if (absBasePath.equals(volume)) {\n              invalidate(bpid, block);\n              blocks.add(block);\n              it.remove();\n            }\n          }\n        }\n\n        storageMap.remove(sd.getStorageUuid());\n      }\n    }\n    setupAsyncLazyPersistThreads();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "a17584936cc5141e3f5612ac3ecf35e27968e439": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7610. Fix removal of dynamically added DN volumes (Lei (Eddy) Xu via Colin P. McCabe)\n",
      "commitDate": "20/01/15 8:11 PM",
      "commitName": "a17584936cc5141e3f5612ac3ecf35e27968e439",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "20/01/15 7:05 PM",
      "commitNameOld": "b7f4a3156c0f5c600816c469637237ba6c9b330c",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.05,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,41 @@\n   public synchronized void removeVolumes(Collection\u003cStorageLocation\u003e volumes) {\n-    Set\u003cFile\u003e volumeSet \u003d new HashSet\u003cFile\u003e();\n+    Set\u003cString\u003e volumeSet \u003d new HashSet\u003c\u003e();\n     for (StorageLocation sl : volumes) {\n-      volumeSet.add(sl.getFile());\n+      volumeSet.add(sl.getFile().getAbsolutePath());\n     }\n     for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n       Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n-      if (volumeSet.contains(sd.getRoot())) {\n-        String volume \u003d sd.getRoot().toString();\n+      String volume \u003d sd.getRoot().getAbsolutePath();\n+      if (volumeSet.contains(volume)) {\n         LOG.info(\"Removing \" + volume + \" from FsDataset.\");\n \n         // Disable the volume from the service.\n         asyncDiskService.removeVolume(sd.getCurrentDir());\n-        this.volumes.removeVolume(volume);\n+        this.volumes.removeVolume(sd.getRoot());\n \n         // Removed all replica information for the blocks on the volume. Unlike\n         // updating the volumeMap in addVolume(), this operation does not scan\n         // disks.\n         for (String bpid : volumeMap.getBlockPoolList()) {\n           List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n           for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n               it.hasNext(); ) {\n             ReplicaInfo block \u003d it.next();\n-            if (block.getVolume().getBasePath().equals(volume)) {\n+            String absBasePath \u003d\n+                  new File(block.getVolume().getBasePath()).getAbsolutePath();\n+            if (absBasePath.equals(volume)) {\n               invalidate(bpid, block);\n               blocks.add(block);\n               it.remove();\n             }\n           }\n           // Delete blocks from the block scanner in batch.\n           datanode.getBlockScanner().deleteBlocks(bpid,\n               blocks.toArray(new Block[blocks.size()]));\n         }\n \n         storageMap.remove(sd.getStorageUuid());\n       }\n     }\n     setupAsyncLazyPersistThreads();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void removeVolumes(Collection\u003cStorageLocation\u003e volumes) {\n    Set\u003cString\u003e volumeSet \u003d new HashSet\u003c\u003e();\n    for (StorageLocation sl : volumes) {\n      volumeSet.add(sl.getFile().getAbsolutePath());\n    }\n    for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n      Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n      String volume \u003d sd.getRoot().getAbsolutePath();\n      if (volumeSet.contains(volume)) {\n        LOG.info(\"Removing \" + volume + \" from FsDataset.\");\n\n        // Disable the volume from the service.\n        asyncDiskService.removeVolume(sd.getCurrentDir());\n        this.volumes.removeVolume(sd.getRoot());\n\n        // Removed all replica information for the blocks on the volume. Unlike\n        // updating the volumeMap in addVolume(), this operation does not scan\n        // disks.\n        for (String bpid : volumeMap.getBlockPoolList()) {\n          List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n          for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n              it.hasNext(); ) {\n            ReplicaInfo block \u003d it.next();\n            String absBasePath \u003d\n                  new File(block.getVolume().getBasePath()).getAbsolutePath();\n            if (absBasePath.equals(volume)) {\n              invalidate(bpid, block);\n              blocks.add(block);\n              it.remove();\n            }\n          }\n          // Delete blocks from the block scanner in batch.\n          datanode.getBlockScanner().deleteBlocks(bpid,\n              blocks.toArray(new Block[blocks.size()]));\n        }\n\n        storageMap.remove(sd.getStorageUuid());\n      }\n    }\n    setupAsyncLazyPersistThreads();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "1efd9c98258fbb973d2058dcf0850042e53bd02f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7112. LazyWriter should use either async IO or one thread per physical disk. Contributed by Xiaoyu Yao.\n",
      "commitDate": "07/10/14 8:25 PM",
      "commitName": "1efd9c98258fbb973d2058dcf0850042e53bd02f",
      "commitAuthor": "cnauroth",
      "commitDateOld": "30/09/14 12:53 AM",
      "commitNameOld": "5e8b6973527e5f714652641ed95e8a4509e18cfa",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 7.81,
      "commitsBetweenForRepo": 80,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,39 @@\n   public synchronized void removeVolumes(Collection\u003cStorageLocation\u003e volumes) {\n     Set\u003cFile\u003e volumeSet \u003d new HashSet\u003cFile\u003e();\n     for (StorageLocation sl : volumes) {\n       volumeSet.add(sl.getFile());\n     }\n     for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n       Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n       if (volumeSet.contains(sd.getRoot())) {\n         String volume \u003d sd.getRoot().toString();\n         LOG.info(\"Removing \" + volume + \" from FsDataset.\");\n \n         // Disable the volume from the service.\n         asyncDiskService.removeVolume(sd.getCurrentDir());\n         this.volumes.removeVolume(volume);\n \n         // Removed all replica information for the blocks on the volume. Unlike\n         // updating the volumeMap in addVolume(), this operation does not scan\n         // disks.\n         for (String bpid : volumeMap.getBlockPoolList()) {\n           List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n           for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n               it.hasNext(); ) {\n             ReplicaInfo block \u003d it.next();\n             if (block.getVolume().getBasePath().equals(volume)) {\n               invalidate(bpid, block);\n               blocks.add(block);\n               it.remove();\n             }\n           }\n           // Delete blocks from the block scanner in batch.\n           datanode.getBlockScanner().deleteBlocks(bpid,\n               blocks.toArray(new Block[blocks.size()]));\n         }\n \n         storageMap.remove(sd.getStorageUuid());\n       }\n     }\n+    setupAsyncLazyPersistThreads();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void removeVolumes(Collection\u003cStorageLocation\u003e volumes) {\n    Set\u003cFile\u003e volumeSet \u003d new HashSet\u003cFile\u003e();\n    for (StorageLocation sl : volumes) {\n      volumeSet.add(sl.getFile());\n    }\n    for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n      Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n      if (volumeSet.contains(sd.getRoot())) {\n        String volume \u003d sd.getRoot().toString();\n        LOG.info(\"Removing \" + volume + \" from FsDataset.\");\n\n        // Disable the volume from the service.\n        asyncDiskService.removeVolume(sd.getCurrentDir());\n        this.volumes.removeVolume(volume);\n\n        // Removed all replica information for the blocks on the volume. Unlike\n        // updating the volumeMap in addVolume(), this operation does not scan\n        // disks.\n        for (String bpid : volumeMap.getBlockPoolList()) {\n          List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n          for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n              it.hasNext(); ) {\n            ReplicaInfo block \u003d it.next();\n            if (block.getVolume().getBasePath().equals(volume)) {\n              invalidate(bpid, block);\n              blocks.add(block);\n              it.remove();\n            }\n          }\n          // Delete blocks from the block scanner in batch.\n          datanode.getBlockScanner().deleteBlocks(bpid,\n              blocks.toArray(new Block[blocks.size()]));\n        }\n\n        storageMap.remove(sd.getStorageUuid());\n      }\n    }\n    setupAsyncLazyPersistThreads();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "fe38d2e9b5ac7e13f97cd2d3d2a984ab6bbaaf77": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6727. Refresh data volumes on DataNode based on configuration changes (Lei Xu via Colin Patrick McCabe)\n",
      "commitDate": "18/09/14 4:52 PM",
      "commitName": "fe38d2e9b5ac7e13f97cd2d3d2a984ab6bbaaf77",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "08/09/14 9:20 PM",
      "commitNameOld": "f949f6b54825dac61511a5761837e2fd14437239",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 9.81,
      "commitsBetweenForRepo": 117,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,38 @@\n   public synchronized void removeVolumes(Collection\u003cStorageLocation\u003e volumes) {\n     Set\u003cFile\u003e volumeSet \u003d new HashSet\u003cFile\u003e();\n     for (StorageLocation sl : volumes) {\n       volumeSet.add(sl.getFile());\n     }\n     for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n       Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n       if (volumeSet.contains(sd.getRoot())) {\n         String volume \u003d sd.getRoot().toString();\n         LOG.info(\"Removing \" + volume + \" from FsDataset.\");\n \n-        this.volumes.removeVolume(volume);\n-        storageMap.remove(sd.getStorageUuid());\n+        // Disable the volume from the service.\n         asyncDiskService.removeVolume(sd.getCurrentDir());\n+        this.volumes.removeVolume(volume);\n \n         // Removed all replica information for the blocks on the volume. Unlike\n         // updating the volumeMap in addVolume(), this operation does not scan\n         // disks.\n         for (String bpid : volumeMap.getBlockPoolList()) {\n           List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n           for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n               it.hasNext(); ) {\n             ReplicaInfo block \u003d it.next();\n             if (block.getVolume().getBasePath().equals(volume)) {\n-              invalidate(bpid, block.getBlockId());\n+              invalidate(bpid, block);\n               blocks.add(block);\n               it.remove();\n             }\n           }\n           // Delete blocks from the block scanner in batch.\n           datanode.getBlockScanner().deleteBlocks(bpid,\n               blocks.toArray(new Block[blocks.size()]));\n         }\n+\n+        storageMap.remove(sd.getStorageUuid());\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void removeVolumes(Collection\u003cStorageLocation\u003e volumes) {\n    Set\u003cFile\u003e volumeSet \u003d new HashSet\u003cFile\u003e();\n    for (StorageLocation sl : volumes) {\n      volumeSet.add(sl.getFile());\n    }\n    for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n      Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n      if (volumeSet.contains(sd.getRoot())) {\n        String volume \u003d sd.getRoot().toString();\n        LOG.info(\"Removing \" + volume + \" from FsDataset.\");\n\n        // Disable the volume from the service.\n        asyncDiskService.removeVolume(sd.getCurrentDir());\n        this.volumes.removeVolume(volume);\n\n        // Removed all replica information for the blocks on the volume. Unlike\n        // updating the volumeMap in addVolume(), this operation does not scan\n        // disks.\n        for (String bpid : volumeMap.getBlockPoolList()) {\n          List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n          for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n              it.hasNext(); ) {\n            ReplicaInfo block \u003d it.next();\n            if (block.getVolume().getBasePath().equals(volume)) {\n              invalidate(bpid, block);\n              blocks.add(block);\n              it.remove();\n            }\n          }\n          // Delete blocks from the block scanner in batch.\n          datanode.getBlockScanner().deleteBlocks(bpid,\n              blocks.toArray(new Block[blocks.size()]));\n        }\n\n        storageMap.remove(sd.getStorageUuid());\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "7eab2a29a5706ce10912c12fa225ef6b27a82cbe": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6774. Make FsDataset and DataStore support removing volumes. Contributed by Lei Xu.\n",
      "commitDate": "29/08/14 1:00 PM",
      "commitName": "7eab2a29a5706ce10912c12fa225ef6b27a82cbe",
      "commitAuthor": "Aaron T. Myers",
      "diff": "@@ -0,0 +1,36 @@\n+  public synchronized void removeVolumes(Collection\u003cStorageLocation\u003e volumes) {\n+    Set\u003cFile\u003e volumeSet \u003d new HashSet\u003cFile\u003e();\n+    for (StorageLocation sl : volumes) {\n+      volumeSet.add(sl.getFile());\n+    }\n+    for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n+      Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n+      if (volumeSet.contains(sd.getRoot())) {\n+        String volume \u003d sd.getRoot().toString();\n+        LOG.info(\"Removing \" + volume + \" from FsDataset.\");\n+\n+        this.volumes.removeVolume(volume);\n+        storageMap.remove(sd.getStorageUuid());\n+        asyncDiskService.removeVolume(sd.getCurrentDir());\n+\n+        // Removed all replica information for the blocks on the volume. Unlike\n+        // updating the volumeMap in addVolume(), this operation does not scan\n+        // disks.\n+        for (String bpid : volumeMap.getBlockPoolList()) {\n+          List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n+          for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n+              it.hasNext(); ) {\n+            ReplicaInfo block \u003d it.next();\n+            if (block.getVolume().getBasePath().equals(volume)) {\n+              invalidate(bpid, block.getBlockId());\n+              blocks.add(block);\n+              it.remove();\n+            }\n+          }\n+          // Delete blocks from the block scanner in batch.\n+          datanode.getBlockScanner().deleteBlocks(bpid,\n+              blocks.toArray(new Block[blocks.size()]));\n+        }\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void removeVolumes(Collection\u003cStorageLocation\u003e volumes) {\n    Set\u003cFile\u003e volumeSet \u003d new HashSet\u003cFile\u003e();\n    for (StorageLocation sl : volumes) {\n      volumeSet.add(sl.getFile());\n    }\n    for (int idx \u003d 0; idx \u003c dataStorage.getNumStorageDirs(); idx++) {\n      Storage.StorageDirectory sd \u003d dataStorage.getStorageDir(idx);\n      if (volumeSet.contains(sd.getRoot())) {\n        String volume \u003d sd.getRoot().toString();\n        LOG.info(\"Removing \" + volume + \" from FsDataset.\");\n\n        this.volumes.removeVolume(volume);\n        storageMap.remove(sd.getStorageUuid());\n        asyncDiskService.removeVolume(sd.getCurrentDir());\n\n        // Removed all replica information for the blocks on the volume. Unlike\n        // updating the volumeMap in addVolume(), this operation does not scan\n        // disks.\n        for (String bpid : volumeMap.getBlockPoolList()) {\n          List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n          for (Iterator\u003cReplicaInfo\u003e it \u003d volumeMap.replicas(bpid).iterator();\n              it.hasNext(); ) {\n            ReplicaInfo block \u003d it.next();\n            if (block.getVolume().getBasePath().equals(volume)) {\n              invalidate(bpid, block.getBlockId());\n              blocks.add(block);\n              it.remove();\n            }\n          }\n          // Delete blocks from the block scanner in batch.\n          datanode.getBlockScanner().deleteBlocks(bpid,\n              blocks.toArray(new Block[blocks.size()]));\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java"
    }
  }
}