{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Mover.java",
  "functionName": "init",
  "functionId": "init",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java",
  "functionStartLine": 151,
  "functionEndLine": 164,
  "numCommitsSeen": 54,
  "timeTaken": 2126,
  "changeHistory": [
    "e8e7fbe81abc64a9ae3d2f3f62c088426073b2bf",
    "073bbd805c6680f47bbfcc6e8efd708ad729bca4",
    "84a0a629d3c63589b9aed7889e2a764538676471",
    "8ea20b53a861a2771c206afaacf8e7783568c4b1"
  ],
  "changeHistoryShort": {
    "e8e7fbe81abc64a9ae3d2f3f62c088426073b2bf": "Ybodychange",
    "073bbd805c6680f47bbfcc6e8efd708ad729bca4": "Ybodychange",
    "84a0a629d3c63589b9aed7889e2a764538676471": "Ybodychange",
    "8ea20b53a861a2771c206afaacf8e7783568c4b1": "Yintroduced"
  },
  "changeHistoryDetails": {
    "e8e7fbe81abc64a9ae3d2f3f62c088426073b2bf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6932. Balancer and Mover tools should ignore replicas on RAM_DISK. (Contributed by Xiaoyu Yao)\n",
      "commitDate": "24/09/14 9:08 PM",
      "commitName": "e8e7fbe81abc64a9ae3d2f3f62c088426073b2bf",
      "commitAuthor": "arp",
      "commitDateOld": "24/09/14 7:11 PM",
      "commitNameOld": "428a76663a0de5d0d74cc9525273ddc470760e44",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   void init() throws IOException {\n     initStoragePolicies();\n     final List\u003cDatanodeStorageReport\u003e reports \u003d dispatcher.init();\n     for(DatanodeStorageReport r : reports) {\n       final DDatanode dn \u003d dispatcher.newDatanode(r.getDatanodeInfo());\n-      for(StorageType t : StorageType.asList()) {\n+      for(StorageType t : StorageType.getMovableTypes()) {\n         final Source source \u003d dn.addSource(t, Long.MAX_VALUE, dispatcher);\n         final long maxRemaining \u003d getMaxRemaining(r, t);\n         final StorageGroup target \u003d maxRemaining \u003e 0L ? dn.addTarget(t,\n             maxRemaining) : null;\n         storages.add(source, target);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void init() throws IOException {\n    initStoragePolicies();\n    final List\u003cDatanodeStorageReport\u003e reports \u003d dispatcher.init();\n    for(DatanodeStorageReport r : reports) {\n      final DDatanode dn \u003d dispatcher.newDatanode(r.getDatanodeInfo());\n      for(StorageType t : StorageType.getMovableTypes()) {\n        final Source source \u003d dn.addSource(t, Long.MAX_VALUE, dispatcher);\n        final long maxRemaining \u003d getMaxRemaining(r, t);\n        final StorageGroup target \u003d maxRemaining \u003e 0L ? dn.addTarget(t,\n            maxRemaining) : null;\n        storages.add(source, target);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java",
      "extendedDetails": {}
    },
    "073bbd805c6680f47bbfcc6e8efd708ad729bca4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7081. Add new DistributedFileSystem API for getting all the existing storage policies. Contributed by Jing Zhao.\n",
      "commitDate": "24/09/14 10:05 AM",
      "commitName": "073bbd805c6680f47bbfcc6e8efd708ad729bca4",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "20/09/14 1:44 PM",
      "commitNameOld": "84a0a629d3c63589b9aed7889e2a764538676471",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 3.85,
      "commitsBetweenForRepo": 30,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,14 @@\n   void init() throws IOException {\n+    initStoragePolicies();\n     final List\u003cDatanodeStorageReport\u003e reports \u003d dispatcher.init();\n     for(DatanodeStorageReport r : reports) {\n       final DDatanode dn \u003d dispatcher.newDatanode(r.getDatanodeInfo());\n       for(StorageType t : StorageType.asList()) {\n         final Source source \u003d dn.addSource(t, Long.MAX_VALUE, dispatcher);\n         final long maxRemaining \u003d getMaxRemaining(r, t);\n         final StorageGroup target \u003d maxRemaining \u003e 0L ? dn.addTarget(t,\n             maxRemaining) : null;\n         storages.add(source, target);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void init() throws IOException {\n    initStoragePolicies();\n    final List\u003cDatanodeStorageReport\u003e reports \u003d dispatcher.init();\n    for(DatanodeStorageReport r : reports) {\n      final DDatanode dn \u003d dispatcher.newDatanode(r.getDatanodeInfo());\n      for(StorageType t : StorageType.asList()) {\n        final Source source \u003d dn.addSource(t, Long.MAX_VALUE, dispatcher);\n        final long maxRemaining \u003d getMaxRemaining(r, t);\n        final StorageGroup target \u003d maxRemaining \u003e 0L ? dn.addTarget(t,\n            maxRemaining) : null;\n        storages.add(source, target);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java",
      "extendedDetails": {}
    },
    "84a0a629d3c63589b9aed7889e2a764538676471": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7095. Archival Storage: TestStorageMover often fails in Jenkins. Contributed by Jing Zhao.\n",
      "commitDate": "20/09/14 1:44 PM",
      "commitName": "84a0a629d3c63589b9aed7889e2a764538676471",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "17/09/14 9:40 AM",
      "commitNameOld": "b014e83bc5899ec135b1e7a54ca1902c970047a5",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 3.17,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,13 @@\n   void init() throws IOException {\n     final List\u003cDatanodeStorageReport\u003e reports \u003d dispatcher.init();\n     for(DatanodeStorageReport r : reports) {\n       final DDatanode dn \u003d dispatcher.newDatanode(r.getDatanodeInfo());\n       for(StorageType t : StorageType.asList()) {\n+        final Source source \u003d dn.addSource(t, Long.MAX_VALUE, dispatcher);\n         final long maxRemaining \u003d getMaxRemaining(r, t);\n-        if (maxRemaining \u003e 0L) {\n-          final Source source \u003d dn.addSource(t, Long.MAX_VALUE, dispatcher); \n-          final StorageGroup target \u003d dn.addTarget(t, maxRemaining);\n-          storages.add(source, target);\n-        }\n+        final StorageGroup target \u003d maxRemaining \u003e 0L ? dn.addTarget(t,\n+            maxRemaining) : null;\n+        storages.add(source, target);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void init() throws IOException {\n    final List\u003cDatanodeStorageReport\u003e reports \u003d dispatcher.init();\n    for(DatanodeStorageReport r : reports) {\n      final DDatanode dn \u003d dispatcher.newDatanode(r.getDatanodeInfo());\n      for(StorageType t : StorageType.asList()) {\n        final Source source \u003d dn.addSource(t, Long.MAX_VALUE, dispatcher);\n        final long maxRemaining \u003d getMaxRemaining(r, t);\n        final StorageGroup target \u003d maxRemaining \u003e 0L ? dn.addTarget(t,\n            maxRemaining) : null;\n        storages.add(source, target);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java",
      "extendedDetails": {}
    },
    "8ea20b53a861a2771c206afaacf8e7783568c4b1": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6911. Archival Storage: check if a block is already scheduled in Mover. Contributed by Tsz Wo Nicholas Sze.\n",
      "commitDate": "27/08/14 10:38 AM",
      "commitName": "8ea20b53a861a2771c206afaacf8e7783568c4b1",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,14 @@\n+  void init() throws IOException {\n+    final List\u003cDatanodeStorageReport\u003e reports \u003d dispatcher.init();\n+    for(DatanodeStorageReport r : reports) {\n+      final DDatanode dn \u003d dispatcher.newDatanode(r.getDatanodeInfo());\n+      for(StorageType t : StorageType.asList()) {\n+        final long maxRemaining \u003d getMaxRemaining(r, t);\n+        if (maxRemaining \u003e 0L) {\n+          final Source source \u003d dn.addSource(t, Long.MAX_VALUE, dispatcher); \n+          final StorageGroup target \u003d dn.addTarget(t, maxRemaining);\n+          storages.add(source, target);\n+        }\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void init() throws IOException {\n    final List\u003cDatanodeStorageReport\u003e reports \u003d dispatcher.init();\n    for(DatanodeStorageReport r : reports) {\n      final DDatanode dn \u003d dispatcher.newDatanode(r.getDatanodeInfo());\n      for(StorageType t : StorageType.asList()) {\n        final long maxRemaining \u003d getMaxRemaining(r, t);\n        if (maxRemaining \u003e 0L) {\n          final Source source \u003d dn.addSource(t, Long.MAX_VALUE, dispatcher); \n          final StorageGroup target \u003d dn.addTarget(t, maxRemaining);\n          storages.add(source, target);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java"
    }
  }
}