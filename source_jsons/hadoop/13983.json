{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockToMarkCorrupt.java",
  "functionName": "toString",
  "functionId": "toString",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockToMarkCorrupt.java",
  "functionStartLine": 78,
  "functionEndLine": 81,
  "numCommitsSeen": 566,
  "timeTaken": 9842,
  "changeHistory": [
    "6d12cd8d609dec26d44cece9937c35b7d72a3cd1",
    "035ed26147f10620fc6ed3a514d9ebbcc31304b5",
    "4e9307f26dd41270f95fb50166e1a091852e4d58",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
    "40eb94ade3161d93e7a762a839004748f6d0ae89",
    "28e8151ad3defc85a4ac1d19b39a9377253c718f"
  ],
  "changeHistoryShort": {
    "6d12cd8d609dec26d44cece9937c35b7d72a3cd1": "Ymovefromfile",
    "035ed26147f10620fc6ed3a514d9ebbcc31304b5": "Ymovefromfile",
    "4e9307f26dd41270f95fb50166e1a091852e4d58": "Ymovefromfile",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": "Ymovefromfile",
    "40eb94ade3161d93e7a762a839004748f6d0ae89": "Ymovefromfile",
    "28e8151ad3defc85a4ac1d19b39a9377253c718f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6d12cd8d609dec26d44cece9937c35b7d72a3cd1": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-8938. Extract BlockToMarkCorrupt and ReplicationWork as standalone classes from BlockManager. Contributed by Mingliang Liu.\n",
      "commitDate": "28/08/15 2:14 PM",
      "commitName": "6d12cd8d609dec26d44cece9937c35b7d72a3cd1",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/08/15 12:13 PM",
      "commitNameOld": "cbb249534aa72ff6c290c4f99766415aeea9d6f5",
      "commitAuthorOld": "Zhihai Xu",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,4 @@\n-    public String toString() {\n-      return corrupted + \"(\"\n-          + (corrupted \u003d\u003d stored? \"same as stored\": \"stored\u003d\" + stored) + \")\";\n-    }\n\\ No newline at end of file\n+  public String toString() {\n+    return corrupted + \"(\"\n+        + (corrupted \u003d\u003d stored ? \"same as stored\": \"stored\u003d\" + stored) + \")\";\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public String toString() {\n    return corrupted + \"(\"\n        + (corrupted \u003d\u003d stored ? \"same as stored\": \"stored\u003d\" + stored) + \")\";\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockToMarkCorrupt.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockToMarkCorrupt.java",
        "oldMethodName": "toString",
        "newMethodName": "toString"
      }
    },
    "035ed26147f10620fc6ed3a514d9ebbcc31304b5": {
      "type": "Ymovefromfile",
      "commitMessage": "Revert \"HDFS-8938. Extract BlockToMarkCorrupt and ReplicationWork as standalone classes from BlockManager. Contributed by Mingliang Liu.\"\n\nThis reverts commit 4e9307f26dd41270f95fb50166e1a091852e4d58.\n",
      "commitDate": "27/08/15 4:09 PM",
      "commitName": "035ed26147f10620fc6ed3a514d9ebbcc31304b5",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "27/08/15 3:36 PM",
      "commitNameOld": "4e9307f26dd41270f95fb50166e1a091852e4d58",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,4 @@\n-  public String toString() {\n-    return corrupted + \"(\"\n-        + (corrupted \u003d\u003d stored ? \"same as stored\": \"stored\u003d\" + stored) + \")\";\n-  }\n\\ No newline at end of file\n+    public String toString() {\n+      return corrupted + \"(\"\n+          + (corrupted \u003d\u003d stored? \"same as stored\": \"stored\u003d\" + stored) + \")\";\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public String toString() {\n      return corrupted + \"(\"\n          + (corrupted \u003d\u003d stored? \"same as stored\": \"stored\u003d\" + stored) + \")\";\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockToMarkCorrupt.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
        "oldMethodName": "toString",
        "newMethodName": "toString"
      }
    },
    "4e9307f26dd41270f95fb50166e1a091852e4d58": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-8938. Extract BlockToMarkCorrupt and ReplicationWork as standalone classes from BlockManager. Contributed by Mingliang Liu.\n",
      "commitDate": "27/08/15 3:36 PM",
      "commitName": "4e9307f26dd41270f95fb50166e1a091852e4d58",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "27/08/15 1:25 PM",
      "commitNameOld": "a9c8ea71aa427ff5f25caec98be15bc880e578a7",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 0.09,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,4 @@\n-    public String toString() {\n-      return corrupted + \"(\"\n-          + (corrupted \u003d\u003d stored? \"same as stored\": \"stored\u003d\" + stored) + \")\";\n-    }\n\\ No newline at end of file\n+  public String toString() {\n+    return corrupted + \"(\"\n+        + (corrupted \u003d\u003d stored ? \"same as stored\": \"stored\u003d\" + stored) + \")\";\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public String toString() {\n    return corrupted + \"(\"\n        + (corrupted \u003d\u003d stored ? \"same as stored\": \"stored\u003d\" + stored) + \")\";\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockToMarkCorrupt.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockToMarkCorrupt.java",
        "oldMethodName": "toString",
        "newMethodName": "toString"
      }
    },
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 3:15 PM",
      "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "16/10/13 1:23 PM",
      "commitNameOld": "8da82eba1c84f828617a13a6f785a9b6cfc057a5",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public String toString() {\n      return corrupted + \"(\"\n          + (corrupted \u003d\u003d stored? \"same as stored\": \"stored\u003d\" + stored) + \")\";\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ReportProcessor.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
        "oldMethodName": "toString",
        "newMethodName": "toString"
      }
    },
    "40eb94ade3161d93e7a762a839004748f6d0ae89": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-5053. NameNode should invoke DataNode APIs to coordinate caching. (Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1523145 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/09/13 4:27 PM",
      "commitName": "40eb94ade3161d93e7a762a839004748f6d0ae89",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "13/09/13 1:47 PM",
      "commitNameOld": "1a1f49fa4f1696712b921e7b499d602292e10279",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 0.11,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public String toString() {\n      return corrupted + \"(\"\n          + (corrupted \u003d\u003d stored? \"same as stored\": \"stored\u003d\" + stored) + \")\";\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ReportProcessor.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ReportProcessor.java",
        "oldMethodName": "toString",
        "newMethodName": "toString"
      }
    },
    "28e8151ad3defc85a4ac1d19b39a9377253c718f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3157. Fix a bug in the case that the generation stamps of the stored block in a namenode and the reported block from a datanode do not match.  Contributed by Ashish Singhi\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1356086 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/07/12 12:26 AM",
      "commitName": "28e8151ad3defc85a4ac1d19b39a9377253c718f",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,4 @@\n+    public String toString() {\n+      return corrupted + \"(\"\n+          + (corrupted \u003d\u003d stored? \"same as stored\": \"stored\u003d\" + stored) + \")\";\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public String toString() {\n      return corrupted + \"(\"\n          + (corrupted \u003d\u003d stored? \"same as stored\": \"stored\u003d\" + stored) + \")\";\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
    }
  }
}