{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FsDatasetAsyncDiskService.java",
  "functionName": "moveFiles",
  "functionId": "moveFiles",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetAsyncDiskService.java",
  "functionStartLine": 282,
  "functionEndLine": 313,
  "numCommitsSeen": 21,
  "timeTaken": 2468,
  "changeHistory": [
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
    "86c9862bec0248d671e657aa56094a2919b8ac14",
    "3f7852bd27de4f87e242ad4eb73932b739922a5b",
    "329c7051817c956bfc64661f4e1349b7009a2747",
    "5df82fa01d26c18685ad7617128dbc2913547cb3"
  ],
  "changeHistoryShort": {
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": "Ybodychange",
    "86c9862bec0248d671e657aa56094a2919b8ac14": "Ybodychange",
    "3f7852bd27de4f87e242ad4eb73932b739922a5b": "Ybodychange",
    "329c7051817c956bfc64661f4e1349b7009a2747": "Ybodychange",
    "5df82fa01d26c18685ad7617128dbc2913547cb3": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10958. Add instrumentation hooks around Datanode disk IO.\n",
      "commitDate": "14/12/16 11:18 AM",
      "commitName": "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "06/12/16 11:05 AM",
      "commitNameOld": "df983b524ab68ea0c70cee9033bfff2d28052cbf",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 8.01,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,32 @@\n     private boolean moveFiles() {\n       if (trashDirectory \u003d\u003d null) {\n         LOG.error(\"Trash dir for replica \" + replicaToDelete + \" is null\");\n         return false;\n       }\n \n       File trashDirFile \u003d new File(trashDirectory);\n-      if (!trashDirFile.exists() \u0026\u0026 !trashDirFile.mkdirs()) {\n-        LOG.error(\"Failed to create trash directory \" + trashDirectory);\n+      try {\n+        volume.getFileIoProvider().mkdirsWithExistsCheck(\n+            volume, trashDirFile);\n+      } catch (IOException e) {\n         return false;\n       }\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Moving files \" + replicaToDelete.getBlockURI() + \" and \" +\n             replicaToDelete.getMetadataURI() + \" to trash.\");\n       }\n \n       final String blockName \u003d replicaToDelete.getBlockName();\n       final long genstamp \u003d replicaToDelete.getGenerationStamp();\n       File newBlockFile \u003d new File(trashDirectory, blockName);\n       File newMetaFile \u003d new File(trashDirectory,\n           DatanodeUtil.getMetaName(blockName, genstamp));\n       try {\n         return (replicaToDelete.renameData(newBlockFile.toURI()) \u0026\u0026\n                 replicaToDelete.renameMeta(newMetaFile.toURI()));\n       } catch (IOException e) {\n         LOG.error(\"Error moving files to trash: \" + replicaToDelete, e);\n       }\n       return false;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private boolean moveFiles() {\n      if (trashDirectory \u003d\u003d null) {\n        LOG.error(\"Trash dir for replica \" + replicaToDelete + \" is null\");\n        return false;\n      }\n\n      File trashDirFile \u003d new File(trashDirectory);\n      try {\n        volume.getFileIoProvider().mkdirsWithExistsCheck(\n            volume, trashDirFile);\n      } catch (IOException e) {\n        return false;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Moving files \" + replicaToDelete.getBlockURI() + \" and \" +\n            replicaToDelete.getMetadataURI() + \" to trash.\");\n      }\n\n      final String blockName \u003d replicaToDelete.getBlockName();\n      final long genstamp \u003d replicaToDelete.getGenerationStamp();\n      File newBlockFile \u003d new File(trashDirectory, blockName);\n      File newMetaFile \u003d new File(trashDirectory,\n          DatanodeUtil.getMetaName(blockName, genstamp));\n      try {\n        return (replicaToDelete.renameData(newBlockFile.toURI()) \u0026\u0026\n                replicaToDelete.renameMeta(newMetaFile.toURI()));\n      } catch (IOException e) {\n        LOG.error(\"Error moving files to trash: \" + replicaToDelete, e);\n      }\n      return false;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetAsyncDiskService.java",
      "extendedDetails": {}
    },
    "86c9862bec0248d671e657aa56094a2919b8ac14": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "13/09/16 12:54 PM",
      "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "16/05/15 9:05 AM",
      "commitNameOld": "e453989a5722e653bd97e3e54f9bbdffc9454fba",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 486.16,
      "commitsBetweenForRepo": 3508,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,30 @@\n     private boolean moveFiles() {\n+      if (trashDirectory \u003d\u003d null) {\n+        LOG.error(\"Trash dir for replica \" + replicaToDelete + \" is null\");\n+        return false;\n+      }\n+\n       File trashDirFile \u003d new File(trashDirectory);\n       if (!trashDirFile.exists() \u0026\u0026 !trashDirFile.mkdirs()) {\n         LOG.error(\"Failed to create trash directory \" + trashDirectory);\n         return false;\n       }\n \n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Moving files \" + blockFile.getName() + \" and \" +\n-            metaFile.getName() + \" to trash.\");\n+        LOG.debug(\"Moving files \" + replicaToDelete.getBlockURI() + \" and \" +\n+            replicaToDelete.getMetadataURI() + \" to trash.\");\n       }\n \n-      File newBlockFile \u003d new File(trashDirectory, blockFile.getName());\n-      File newMetaFile \u003d new File(trashDirectory, metaFile.getName());\n-      return (blockFile.renameTo(newBlockFile) \u0026\u0026\n-              metaFile.renameTo(newMetaFile));\n+      final String blockName \u003d replicaToDelete.getBlockName();\n+      final long genstamp \u003d replicaToDelete.getGenerationStamp();\n+      File newBlockFile \u003d new File(trashDirectory, blockName);\n+      File newMetaFile \u003d new File(trashDirectory,\n+          DatanodeUtil.getMetaName(blockName, genstamp));\n+      try {\n+        return (replicaToDelete.renameData(newBlockFile.toURI()) \u0026\u0026\n+                replicaToDelete.renameMeta(newMetaFile.toURI()));\n+      } catch (IOException e) {\n+        LOG.error(\"Error moving files to trash: \" + replicaToDelete, e);\n+      }\n+      return false;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private boolean moveFiles() {\n      if (trashDirectory \u003d\u003d null) {\n        LOG.error(\"Trash dir for replica \" + replicaToDelete + \" is null\");\n        return false;\n      }\n\n      File trashDirFile \u003d new File(trashDirectory);\n      if (!trashDirFile.exists() \u0026\u0026 !trashDirFile.mkdirs()) {\n        LOG.error(\"Failed to create trash directory \" + trashDirectory);\n        return false;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Moving files \" + replicaToDelete.getBlockURI() + \" and \" +\n            replicaToDelete.getMetadataURI() + \" to trash.\");\n      }\n\n      final String blockName \u003d replicaToDelete.getBlockName();\n      final long genstamp \u003d replicaToDelete.getGenerationStamp();\n      File newBlockFile \u003d new File(trashDirectory, blockName);\n      File newMetaFile \u003d new File(trashDirectory,\n          DatanodeUtil.getMetaName(blockName, genstamp));\n      try {\n        return (replicaToDelete.renameData(newBlockFile.toURI()) \u0026\u0026\n                replicaToDelete.renameMeta(newMetaFile.toURI()));\n      } catch (IOException e) {\n        LOG.error(\"Error moving files to trash: \" + replicaToDelete, e);\n      }\n      return false;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetAsyncDiskService.java",
      "extendedDetails": {}
    },
    "3f7852bd27de4f87e242ad4eb73932b739922a5b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5994. Fix TestDataNodeRollingUpgrade.  Contributed by Arpit Agarwal\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1570734 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/02/14 2:40 PM",
      "commitName": "3f7852bd27de4f87e242ad4eb73932b739922a5b",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "20/02/14 3:21 PM",
      "commitNameOld": "329c7051817c956bfc64661f4e1349b7009a2747",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.97,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,17 @@\n     private boolean moveFiles() {\n-      File newBlockFile \u003d new File(trashDirectory, blockFile.getName());\n-      File newMetaFile \u003d new File(trashDirectory, metaFile.getName());\n-      if (!new File(trashDirectory).mkdirs()) {\n+      File trashDirFile \u003d new File(trashDirectory);\n+      if (!trashDirFile.exists() \u0026\u0026 !trashDirFile.mkdirs()) {\n         LOG.error(\"Failed to create trash directory \" + trashDirectory);\n         return false;\n       }\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Moving files \" + blockFile.getName() + \" and \" +\n             metaFile.getName() + \" to trash.\");\n       }\n+\n+      File newBlockFile \u003d new File(trashDirectory, blockFile.getName());\n+      File newMetaFile \u003d new File(trashDirectory, metaFile.getName());\n       return (blockFile.renameTo(newBlockFile) \u0026\u0026\n               metaFile.renameTo(newMetaFile));\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private boolean moveFiles() {\n      File trashDirFile \u003d new File(trashDirectory);\n      if (!trashDirFile.exists() \u0026\u0026 !trashDirFile.mkdirs()) {\n        LOG.error(\"Failed to create trash directory \" + trashDirectory);\n        return false;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Moving files \" + blockFile.getName() + \" and \" +\n            metaFile.getName() + \" to trash.\");\n      }\n\n      File newBlockFile \u003d new File(trashDirectory, blockFile.getName());\n      File newMetaFile \u003d new File(trashDirectory, metaFile.getName());\n      return (blockFile.renameTo(newBlockFile) \u0026\u0026\n              metaFile.renameTo(newMetaFile));\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetAsyncDiskService.java",
      "extendedDetails": {}
    },
    "329c7051817c956bfc64661f4e1349b7009a2747": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5987. Fix findbugs warnings in Rolling Upgrade branch. (Contributed by szetszwo)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1570389 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/02/14 3:21 PM",
      "commitName": "329c7051817c956bfc64661f4e1349b7009a2747",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "14/02/14 8:37 AM",
      "commitNameOld": "5df82fa01d26c18685ad7617128dbc2913547cb3",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 6.28,
      "commitsBetweenForRepo": 56,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,15 @@\n     private boolean moveFiles() {\n       File newBlockFile \u003d new File(trashDirectory, blockFile.getName());\n       File newMetaFile \u003d new File(trashDirectory, metaFile.getName());\n-      (new File(trashDirectory)).mkdirs();\n+      if (!new File(trashDirectory).mkdirs()) {\n+        LOG.error(\"Failed to create trash directory \" + trashDirectory);\n+        return false;\n+      }\n \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Moving files \" + blockFile.getName() + \" and \" +\n             metaFile.getName() + \" to trash.\");\n       }\n       return (blockFile.renameTo(newBlockFile) \u0026\u0026\n               metaFile.renameTo(newMetaFile));\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private boolean moveFiles() {\n      File newBlockFile \u003d new File(trashDirectory, blockFile.getName());\n      File newMetaFile \u003d new File(trashDirectory, metaFile.getName());\n      if (!new File(trashDirectory).mkdirs()) {\n        LOG.error(\"Failed to create trash directory \" + trashDirectory);\n        return false;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Moving files \" + blockFile.getName() + \" and \" +\n            metaFile.getName() + \" to trash.\");\n      }\n      return (blockFile.renameTo(newBlockFile) \u0026\u0026\n              metaFile.renameTo(newMetaFile));\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetAsyncDiskService.java",
      "extendedDetails": {}
    },
    "5df82fa01d26c18685ad7617128dbc2913547cb3": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5907. BlockPoolSliceStorage trash to handle block deletions during rolling upgrade. (Arpit Agarwal)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1568346 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/02/14 8:37 AM",
      "commitName": "5df82fa01d26c18685ad7617128dbc2913547cb3",
      "commitAuthor": "Arpit Agarwal",
      "diff": "@@ -0,0 +1,12 @@\n+    private boolean moveFiles() {\n+      File newBlockFile \u003d new File(trashDirectory, blockFile.getName());\n+      File newMetaFile \u003d new File(trashDirectory, metaFile.getName());\n+      (new File(trashDirectory)).mkdirs();\n+\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Moving files \" + blockFile.getName() + \" and \" +\n+            metaFile.getName() + \" to trash.\");\n+      }\n+      return (blockFile.renameTo(newBlockFile) \u0026\u0026\n+              metaFile.renameTo(newMetaFile));\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private boolean moveFiles() {\n      File newBlockFile \u003d new File(trashDirectory, blockFile.getName());\n      File newMetaFile \u003d new File(trashDirectory, metaFile.getName());\n      (new File(trashDirectory)).mkdirs();\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Moving files \" + blockFile.getName() + \" and \" +\n            metaFile.getName() + \" to trash.\");\n      }\n      return (blockFile.renameTo(newBlockFile) \u0026\u0026\n              metaFile.renameTo(newMetaFile));\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetAsyncDiskService.java"
    }
  }
}