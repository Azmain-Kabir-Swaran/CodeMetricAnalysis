{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockChecksumHelper.java",
  "functionName": "recalculateChecksum",
  "functionId": "recalculateChecksum___errBlkIndex-int__blockLength-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockChecksumHelper.java",
  "functionStartLine": 691,
  "functionEndLine": 721,
  "numCommitsSeen": 13,
  "timeTaken": 2609,
  "changeHistory": [
    "7c9cdad6d04c98db5a83e2108219bf6e6c903daf",
    "e6cb07520f935efde3e881de8f84ee7f6e0a746f",
    "d749cf65e1ab0e0daf5be86931507183f189e855"
  ],
  "changeHistoryShort": {
    "7c9cdad6d04c98db5a83e2108219bf6e6c903daf": "Ybodychange",
    "e6cb07520f935efde3e881de8f84ee7f6e0a746f": "Ymultichange(Yparameterchange,Ybodychange)",
    "d749cf65e1ab0e0daf5be86931507183f189e855": "Yintroduced"
  },
  "changeHistoryDetails": {
    "7c9cdad6d04c98db5a83e2108219bf6e6c903daf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13056. Expose file-level composite CRCs in HDFS which are comparable across different instances/layouts. Contributed by Dennis Huo.\n",
      "commitDate": "10/04/18 9:31 PM",
      "commitName": "7c9cdad6d04c98db5a83e2108219bf6e6c903daf",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "14/03/17 4:41 PM",
      "commitNameOld": "cc1292e73acd39c1f1023ad4841ffe30176f7daf",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 392.2,
      "commitsBetweenForRepo": 2722,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,31 @@\n     private void recalculateChecksum(int errBlkIndex, long blockLength)\n         throws IOException {\n       LOG.debug(\"Recalculate checksum for the missing/failed block index {}\",\n           errBlkIndex);\n       byte[] errIndices \u003d new byte[1];\n       errIndices[0] \u003d (byte) errBlkIndex;\n \n       StripedReconstructionInfo stripedReconInfo \u003d\n           new StripedReconstructionInfo(\n               blockGroup, ecPolicy, blockIndices, datanodes, errIndices);\n+      BlockChecksumType groupChecksumType \u003d\n+          getBlockChecksumOptions().getBlockChecksumType();\n       final StripedBlockChecksumReconstructor checksumRecon \u003d\n-          new StripedBlockChecksumReconstructor(\n+          groupChecksumType \u003d\u003d BlockChecksumType.COMPOSITE_CRC ?\n+          new StripedBlockChecksumCompositeCrcReconstructor(\n               getDatanode().getErasureCodingWorker(), stripedReconInfo,\n-              md5writer, blockLength);\n+              blockChecksumBuf, blockLength) :\n+          new StripedBlockChecksumMd5CrcReconstructor(\n+              getDatanode().getErasureCodingWorker(), stripedReconInfo,\n+              blockChecksumBuf, blockLength);\n       checksumRecon.reconstruct();\n \n       DataChecksum checksum \u003d checksumRecon.getChecksum();\n       long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0\n           : checksumRecon.getChecksumDataLen() / checksum.getChecksumSize();\n       setOrVerifyChecksumProperties(errBlkIndex,\n           checksum.getBytesPerChecksum(), crcPerBlock,\n           checksum.getChecksumType());\n-      LOG.debug(\"Recalculated checksum for the block index:{}, md5\u003d{}\",\n-          errBlkIndex, checksumRecon.getMD5());\n+      LOG.debug(\"Recalculated checksum for the block index:{}, checksum\u003d{}\",\n+          errBlkIndex, checksumRecon.getDigestObject());\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void recalculateChecksum(int errBlkIndex, long blockLength)\n        throws IOException {\n      LOG.debug(\"Recalculate checksum for the missing/failed block index {}\",\n          errBlkIndex);\n      byte[] errIndices \u003d new byte[1];\n      errIndices[0] \u003d (byte) errBlkIndex;\n\n      StripedReconstructionInfo stripedReconInfo \u003d\n          new StripedReconstructionInfo(\n              blockGroup, ecPolicy, blockIndices, datanodes, errIndices);\n      BlockChecksumType groupChecksumType \u003d\n          getBlockChecksumOptions().getBlockChecksumType();\n      final StripedBlockChecksumReconstructor checksumRecon \u003d\n          groupChecksumType \u003d\u003d BlockChecksumType.COMPOSITE_CRC ?\n          new StripedBlockChecksumCompositeCrcReconstructor(\n              getDatanode().getErasureCodingWorker(), stripedReconInfo,\n              blockChecksumBuf, blockLength) :\n          new StripedBlockChecksumMd5CrcReconstructor(\n              getDatanode().getErasureCodingWorker(), stripedReconInfo,\n              blockChecksumBuf, blockLength);\n      checksumRecon.reconstruct();\n\n      DataChecksum checksum \u003d checksumRecon.getChecksum();\n      long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0\n          : checksumRecon.getChecksumDataLen() / checksum.getChecksumSize();\n      setOrVerifyChecksumProperties(errBlkIndex,\n          checksum.getBytesPerChecksum(), crcPerBlock,\n          checksum.getChecksumType());\n      LOG.debug(\"Recalculated checksum for the block index:{}, checksum\u003d{}\",\n          errBlkIndex, checksumRecon.getDigestObject());\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockChecksumHelper.java",
      "extendedDetails": {}
    },
    "e6cb07520f935efde3e881de8f84ee7f6e0a746f": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-10460. Recompute block checksum for a particular range less than file size on the fly by reconstructing missed block. Contributed by Rakesh R\n",
      "commitDate": "24/06/16 2:39 AM",
      "commitName": "e6cb07520f935efde3e881de8f84ee7f6e0a746f",
      "commitAuthor": "Kai Zheng",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-10460. Recompute block checksum for a particular range less than file size on the fly by reconstructing missed block. Contributed by Rakesh R\n",
          "commitDate": "24/06/16 2:39 AM",
          "commitName": "e6cb07520f935efde3e881de8f84ee7f6e0a746f",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "01/06/16 9:56 PM",
          "commitNameOld": "d749cf65e1ab0e0daf5be86931507183f189e855",
          "commitAuthorOld": "Kai Zheng",
          "daysBetweenCommits": 22.2,
          "commitsBetweenForRepo": 141,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,25 @@\n-    private void recalculateChecksum(int errBlkIndex) throws IOException {\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Recalculate checksum for the missing/failed block index \"\n-            + errBlkIndex);\n-      }\n+    private void recalculateChecksum(int errBlkIndex, long blockLength)\n+        throws IOException {\n+      LOG.debug(\"Recalculate checksum for the missing/failed block index {}\",\n+          errBlkIndex);\n       byte[] errIndices \u003d new byte[1];\n       errIndices[0] \u003d (byte) errBlkIndex;\n+\n       StripedReconstructionInfo stripedReconInfo \u003d\n           new StripedReconstructionInfo(\n-          blockGroup, ecPolicy, blockIndices, datanodes, errIndices);\n+              blockGroup, ecPolicy, blockIndices, datanodes, errIndices);\n       final StripedBlockChecksumReconstructor checksumRecon \u003d\n           new StripedBlockChecksumReconstructor(\n-          getDatanode().getErasureCodingWorker(), stripedReconInfo,\n-          md5writer);\n+              getDatanode().getErasureCodingWorker(), stripedReconInfo,\n+              md5writer, blockLength);\n       checksumRecon.reconstruct();\n \n       DataChecksum checksum \u003d checksumRecon.getChecksum();\n       long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0\n           : checksumRecon.getChecksumDataLen() / checksum.getChecksumSize();\n-      setOrVerifyChecksumProperties(errBlkIndex, checksum.getBytesPerChecksum(),\n-          crcPerBlock, checksum.getChecksumType());\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Recalculated checksum for the block index \" + errBlkIndex\n-            + \": md5\u003d\" + checksumRecon.getMD5());\n-      }\n+      setOrVerifyChecksumProperties(errBlkIndex,\n+          checksum.getBytesPerChecksum(), crcPerBlock,\n+          checksum.getChecksumType());\n+      LOG.debug(\"Recalculated checksum for the block index:{}, md5\u003d{}\",\n+          errBlkIndex, checksumRecon.getMD5());\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void recalculateChecksum(int errBlkIndex, long blockLength)\n        throws IOException {\n      LOG.debug(\"Recalculate checksum for the missing/failed block index {}\",\n          errBlkIndex);\n      byte[] errIndices \u003d new byte[1];\n      errIndices[0] \u003d (byte) errBlkIndex;\n\n      StripedReconstructionInfo stripedReconInfo \u003d\n          new StripedReconstructionInfo(\n              blockGroup, ecPolicy, blockIndices, datanodes, errIndices);\n      final StripedBlockChecksumReconstructor checksumRecon \u003d\n          new StripedBlockChecksumReconstructor(\n              getDatanode().getErasureCodingWorker(), stripedReconInfo,\n              md5writer, blockLength);\n      checksumRecon.reconstruct();\n\n      DataChecksum checksum \u003d checksumRecon.getChecksum();\n      long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0\n          : checksumRecon.getChecksumDataLen() / checksum.getChecksumSize();\n      setOrVerifyChecksumProperties(errBlkIndex,\n          checksum.getBytesPerChecksum(), crcPerBlock,\n          checksum.getChecksumType());\n      LOG.debug(\"Recalculated checksum for the block index:{}, md5\u003d{}\",\n          errBlkIndex, checksumRecon.getMD5());\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockChecksumHelper.java",
          "extendedDetails": {
            "oldValue": "[errBlkIndex-int]",
            "newValue": "[errBlkIndex-int, blockLength-long]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10460. Recompute block checksum for a particular range less than file size on the fly by reconstructing missed block. Contributed by Rakesh R\n",
          "commitDate": "24/06/16 2:39 AM",
          "commitName": "e6cb07520f935efde3e881de8f84ee7f6e0a746f",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "01/06/16 9:56 PM",
          "commitNameOld": "d749cf65e1ab0e0daf5be86931507183f189e855",
          "commitAuthorOld": "Kai Zheng",
          "daysBetweenCommits": 22.2,
          "commitsBetweenForRepo": 141,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,25 @@\n-    private void recalculateChecksum(int errBlkIndex) throws IOException {\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Recalculate checksum for the missing/failed block index \"\n-            + errBlkIndex);\n-      }\n+    private void recalculateChecksum(int errBlkIndex, long blockLength)\n+        throws IOException {\n+      LOG.debug(\"Recalculate checksum for the missing/failed block index {}\",\n+          errBlkIndex);\n       byte[] errIndices \u003d new byte[1];\n       errIndices[0] \u003d (byte) errBlkIndex;\n+\n       StripedReconstructionInfo stripedReconInfo \u003d\n           new StripedReconstructionInfo(\n-          blockGroup, ecPolicy, blockIndices, datanodes, errIndices);\n+              blockGroup, ecPolicy, blockIndices, datanodes, errIndices);\n       final StripedBlockChecksumReconstructor checksumRecon \u003d\n           new StripedBlockChecksumReconstructor(\n-          getDatanode().getErasureCodingWorker(), stripedReconInfo,\n-          md5writer);\n+              getDatanode().getErasureCodingWorker(), stripedReconInfo,\n+              md5writer, blockLength);\n       checksumRecon.reconstruct();\n \n       DataChecksum checksum \u003d checksumRecon.getChecksum();\n       long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0\n           : checksumRecon.getChecksumDataLen() / checksum.getChecksumSize();\n-      setOrVerifyChecksumProperties(errBlkIndex, checksum.getBytesPerChecksum(),\n-          crcPerBlock, checksum.getChecksumType());\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Recalculated checksum for the block index \" + errBlkIndex\n-            + \": md5\u003d\" + checksumRecon.getMD5());\n-      }\n+      setOrVerifyChecksumProperties(errBlkIndex,\n+          checksum.getBytesPerChecksum(), crcPerBlock,\n+          checksum.getChecksumType());\n+      LOG.debug(\"Recalculated checksum for the block index:{}, md5\u003d{}\",\n+          errBlkIndex, checksumRecon.getMD5());\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void recalculateChecksum(int errBlkIndex, long blockLength)\n        throws IOException {\n      LOG.debug(\"Recalculate checksum for the missing/failed block index {}\",\n          errBlkIndex);\n      byte[] errIndices \u003d new byte[1];\n      errIndices[0] \u003d (byte) errBlkIndex;\n\n      StripedReconstructionInfo stripedReconInfo \u003d\n          new StripedReconstructionInfo(\n              blockGroup, ecPolicy, blockIndices, datanodes, errIndices);\n      final StripedBlockChecksumReconstructor checksumRecon \u003d\n          new StripedBlockChecksumReconstructor(\n              getDatanode().getErasureCodingWorker(), stripedReconInfo,\n              md5writer, blockLength);\n      checksumRecon.reconstruct();\n\n      DataChecksum checksum \u003d checksumRecon.getChecksum();\n      long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0\n          : checksumRecon.getChecksumDataLen() / checksum.getChecksumSize();\n      setOrVerifyChecksumProperties(errBlkIndex,\n          checksum.getBytesPerChecksum(), crcPerBlock,\n          checksum.getChecksumType());\n      LOG.debug(\"Recalculated checksum for the block index:{}, md5\u003d{}\",\n          errBlkIndex, checksumRecon.getMD5());\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockChecksumHelper.java",
          "extendedDetails": {}
        }
      ]
    },
    "d749cf65e1ab0e0daf5be86931507183f189e855": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9833. Erasure coding: recomputing block checksum on the fly by reconstructing the missed/corrupt block data. Contributed by Rakesh R.\n",
      "commitDate": "01/06/16 9:56 PM",
      "commitName": "d749cf65e1ab0e0daf5be86931507183f189e855",
      "commitAuthor": "Kai Zheng",
      "diff": "@@ -0,0 +1,26 @@\n+    private void recalculateChecksum(int errBlkIndex) throws IOException {\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Recalculate checksum for the missing/failed block index \"\n+            + errBlkIndex);\n+      }\n+      byte[] errIndices \u003d new byte[1];\n+      errIndices[0] \u003d (byte) errBlkIndex;\n+      StripedReconstructionInfo stripedReconInfo \u003d\n+          new StripedReconstructionInfo(\n+          blockGroup, ecPolicy, blockIndices, datanodes, errIndices);\n+      final StripedBlockChecksumReconstructor checksumRecon \u003d\n+          new StripedBlockChecksumReconstructor(\n+          getDatanode().getErasureCodingWorker(), stripedReconInfo,\n+          md5writer);\n+      checksumRecon.reconstruct();\n+\n+      DataChecksum checksum \u003d checksumRecon.getChecksum();\n+      long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0\n+          : checksumRecon.getChecksumDataLen() / checksum.getChecksumSize();\n+      setOrVerifyChecksumProperties(errBlkIndex, checksum.getBytesPerChecksum(),\n+          crcPerBlock, checksum.getChecksumType());\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Recalculated checksum for the block index \" + errBlkIndex\n+            + \": md5\u003d\" + checksumRecon.getMD5());\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private void recalculateChecksum(int errBlkIndex) throws IOException {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Recalculate checksum for the missing/failed block index \"\n            + errBlkIndex);\n      }\n      byte[] errIndices \u003d new byte[1];\n      errIndices[0] \u003d (byte) errBlkIndex;\n      StripedReconstructionInfo stripedReconInfo \u003d\n          new StripedReconstructionInfo(\n          blockGroup, ecPolicy, blockIndices, datanodes, errIndices);\n      final StripedBlockChecksumReconstructor checksumRecon \u003d\n          new StripedBlockChecksumReconstructor(\n          getDatanode().getErasureCodingWorker(), stripedReconInfo,\n          md5writer);\n      checksumRecon.reconstruct();\n\n      DataChecksum checksum \u003d checksumRecon.getChecksum();\n      long crcPerBlock \u003d checksum.getChecksumSize() \u003c\u003d 0 ? 0\n          : checksumRecon.getChecksumDataLen() / checksum.getChecksumSize();\n      setOrVerifyChecksumProperties(errBlkIndex, checksum.getBytesPerChecksum(),\n          crcPerBlock, checksum.getChecksumType());\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Recalculated checksum for the block index \" + errBlkIndex\n            + \": md5\u003d\" + checksumRecon.getMD5());\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockChecksumHelper.java"
    }
  }
}