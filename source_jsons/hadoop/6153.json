{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImageFormat.java",
  "functionName": "updateBlocksMap",
  "functionId": "updateBlocksMap___file-INodeFile",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
  "functionStartLine": 688,
  "functionEndLine": 697,
  "numCommitsSeen": 127,
  "timeTaken": 3515,
  "changeHistory": [
    "4928f5473394981829e5ffd4b16ea0801baf5c45",
    "4c039b0876bb9399c2b4a751ad7b99b36349117b",
    "9f2f583f401189c3f4a2687795a9e3e0b288322b",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
    "a6250a4943d90c10bcfe9a2a46d6558c6d1a2d50"
  ],
  "changeHistoryShort": {
    "4928f5473394981829e5ffd4b16ea0801baf5c45": "Ybodychange",
    "4c039b0876bb9399c2b4a751ad7b99b36349117b": "Ybodychange",
    "9f2f583f401189c3f4a2687795a9e3e0b288322b": "Ybodychange",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": "Ybodychange",
    "a6250a4943d90c10bcfe9a2a46d6558c6d1a2d50": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4928f5473394981829e5ffd4b16ea0801baf5c45": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8482. Rename BlockInfoContiguous to BlockInfo. Contributed by Zhe Zhang.\n",
      "commitDate": "27/05/15 3:42 PM",
      "commitName": "4928f5473394981829e5ffd4b16ea0801baf5c45",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "08/05/15 11:04 PM",
      "commitNameOld": "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 18.69,
      "commitsBetweenForRepo": 146,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,10 @@\n     public void updateBlocksMap(INodeFile file) {\n       // Add file-\u003eblock mapping\n-      final BlockInfoContiguous[] blocks \u003d file.getBlocks();\n+      final BlockInfo[] blocks \u003d file.getBlocks();\n       if (blocks !\u003d null) {\n         final BlockManager bm \u003d namesystem.getBlockManager();\n         for (int i \u003d 0; i \u003c blocks.length; i++) {\n           file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n         } \n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void updateBlocksMap(INodeFile file) {\n      // Add file-\u003eblock mapping\n      final BlockInfo[] blocks \u003d file.getBlocks();\n      if (blocks !\u003d null) {\n        final BlockManager bm \u003d namesystem.getBlockManager();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n        } \n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "4c039b0876bb9399c2b4a751ad7b99b36349117b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7994. Detect if resevered EC Block ID is already used during namenode startup. Contributed by Hui Zheng\n",
      "commitDate": "26/05/15 11:59 AM",
      "commitName": "4c039b0876bb9399c2b4a751ad7b99b36349117b",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "26/05/15 11:43 AM",
      "commitNameOld": "d0d75a833907f6cf723a42a007ca04e0004a8e52",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 37,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,10 @@\n     public void updateBlocksMap(INodeFile file) {\n       // Add file-\u003eblock mapping\n       final BlockInfo[] blocks \u003d file.getBlocks();\n       if (blocks !\u003d null) {\n         final BlockManager bm \u003d namesystem.getBlockManager();\n         for (int i \u003d 0; i \u003c blocks.length; i++) {\n-          file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n+          file.setBlock(i, bm.addBlockCollectionWithCheck(blocks[i], file));\n         } \n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void updateBlocksMap(INodeFile file) {\n      // Add file-\u003eblock mapping\n      final BlockInfo[] blocks \u003d file.getBlocks();\n      if (blocks !\u003d null) {\n        final BlockManager bm \u003d namesystem.getBlockManager();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          file.setBlock(i, bm.addBlockCollectionWithCheck(blocks[i], file));\n        } \n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "9f2f583f401189c3f4a2687795a9e3e0b288322b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7749. Erasure Coding: Add striped block support in INodeFile. Contributed by Jing Zhao.\n",
      "commitDate": "26/05/15 11:07 AM",
      "commitName": "9f2f583f401189c3f4a2687795a9e3e0b288322b",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "08/05/15 11:04 PM",
      "commitNameOld": "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 17.5,
      "commitsBetweenForRepo": 144,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,10 @@\n     public void updateBlocksMap(INodeFile file) {\n       // Add file-\u003eblock mapping\n-      final BlockInfoContiguous[] blocks \u003d file.getBlocks();\n+      final BlockInfo[] blocks \u003d file.getBlocks();\n       if (blocks !\u003d null) {\n         final BlockManager bm \u003d namesystem.getBlockManager();\n         for (int i \u003d 0; i \u003c blocks.length; i++) {\n           file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n         } \n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void updateBlocksMap(INodeFile file) {\n      // Add file-\u003eblock mapping\n      final BlockInfo[] blocks \u003d file.getBlocks();\n      if (blocks !\u003d null) {\n        final BlockManager bm \u003d namesystem.getBlockManager();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n        } \n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7743. Code cleanup of BlockInfo and rename BlockInfo to BlockInfoContiguous. Contributed by Jing Zhao.\n",
      "commitDate": "08/02/15 11:51 AM",
      "commitName": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "12/12/14 3:13 PM",
      "commitNameOld": "c78e3a7cdd10c40454e9acb06986ba6d8573cb19",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 57.86,
      "commitsBetweenForRepo": 371,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,10 @@\n     public void updateBlocksMap(INodeFile file) {\n       // Add file-\u003eblock mapping\n-      final BlockInfo[] blocks \u003d file.getBlocks();\n+      final BlockInfoContiguous[] blocks \u003d file.getBlocks();\n       if (blocks !\u003d null) {\n         final BlockManager bm \u003d namesystem.getBlockManager();\n         for (int i \u003d 0; i \u003c blocks.length; i++) {\n           file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n         } \n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void updateBlocksMap(INodeFile file) {\n      // Add file-\u003eblock mapping\n      final BlockInfoContiguous[] blocks \u003d file.getBlocks();\n      if (blocks !\u003d null) {\n        final BlockManager bm \u003d namesystem.getBlockManager();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n        } \n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java",
      "extendedDetails": {}
    },
    "a6250a4943d90c10bcfe9a2a46d6558c6d1a2d50": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5427. Not able to read deleted files from snapshot directly under snapshottable dir after checkpoint and NN restart. Contributed by Vinay.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1538875 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/11/13 10:38 PM",
      "commitName": "a6250a4943d90c10bcfe9a2a46d6558c6d1a2d50",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,10 @@\n+    public void updateBlocksMap(INodeFile file) {\n+      // Add file-\u003eblock mapping\n+      final BlockInfo[] blocks \u003d file.getBlocks();\n+      if (blocks !\u003d null) {\n+        final BlockManager bm \u003d namesystem.getBlockManager();\n+        for (int i \u003d 0; i \u003c blocks.length; i++) {\n+          file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n+        } \n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public void updateBlocksMap(INodeFile file) {\n      // Add file-\u003eblock mapping\n      final BlockInfo[] blocks \u003d file.getBlocks();\n      if (blocks !\u003d null) {\n        final BlockManager bm \u003d namesystem.getBlockManager();\n        for (int i \u003d 0; i \u003c blocks.length; i++) {\n          file.setBlock(i, bm.addBlockCollection(blocks[i], file));\n        } \n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java"
    }
  }
}