{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JobImpl.java",
  "functionName": "createReduceTasks",
  "functionId": "createReduceTasks___job-JobImpl",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java",
  "functionStartLine": 1588,
  "functionEndLine": 1603,
  "numCommitsSeen": 96,
  "timeTaken": 8850,
  "changeHistory": [
    "b64572b06b1282128180b9ebdd971f9b1e973e61",
    "6a1c41111edcdc58c846fc50e53554fbba230171",
    "402eb1851341fce72c8e46266a2578bb67b5b684",
    "f67c2d1bd0c8abc3d4ea76deffe45fdd92ef5e05",
    "c3a4de0ec0389064f5468180d1b9024f64b00f40",
    "c9a7d3dbf902244902b636bf566154c09ecd1116",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "b64572b06b1282128180b9ebdd971f9b1e973e61": "Ybodychange",
    "6a1c41111edcdc58c846fc50e53554fbba230171": "Ybodychange",
    "402eb1851341fce72c8e46266a2578bb67b5b684": "Ybodychange",
    "f67c2d1bd0c8abc3d4ea76deffe45fdd92ef5e05": "Ybodychange",
    "c3a4de0ec0389064f5468180d1b9024f64b00f40": "Ybodychange",
    "c9a7d3dbf902244902b636bf566154c09ecd1116": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b64572b06b1282128180b9ebdd971f9b1e973e61": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5199. Removing ApplicationTokens file as it is no longer needed. Contributed by Daryn Sharp.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492848 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/06/13 1:20 PM",
      "commitName": "b64572b06b1282128180b9ebdd971f9b1e973e61",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "03/06/13 9:05 PM",
      "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 9.68,
      "commitsBetweenForRepo": 64,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n     private void createReduceTasks(JobImpl job) {\n       for (int i \u003d 0; i \u003c job.numReduceTasks; i++) {\n         TaskImpl task \u003d\n             new ReduceTaskImpl(job.jobId, i,\n                 job.eventHandler, \n                 job.remoteJobConfFile, \n                 job.conf, job.numMapTasks, \n                 job.taskAttemptListener, job.jobToken,\n-                job.fsTokens, job.clock,\n+                job.jobCredentials, job.clock,\n                 job.applicationAttemptId.getAttemptId(),\n                 job.metrics, job.appContext);\n         job.addTask(task);\n       }\n       LOG.info(\"Number of reduces for job \" + job.jobId + \" \u003d \"\n           + job.numReduceTasks);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void createReduceTasks(JobImpl job) {\n      for (int i \u003d 0; i \u003c job.numReduceTasks; i++) {\n        TaskImpl task \u003d\n            new ReduceTaskImpl(job.jobId, i,\n                job.eventHandler, \n                job.remoteJobConfFile, \n                job.conf, job.numMapTasks, \n                job.taskAttemptListener, job.jobToken,\n                job.jobCredentials, job.clock,\n                job.applicationAttemptId.getAttemptId(),\n                job.metrics, job.appContext);\n        job.addTask(task);\n      }\n      LOG.info(\"Number of reduces for job \" + job.jobId + \" \u003d \"\n          + job.numReduceTasks);\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java",
      "extendedDetails": {}
    },
    "6a1c41111edcdc58c846fc50e53554fbba230171": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5079. Changes job recovery to restore state directly from job history, instaed of simulating state machine events. Contributed by Jason Lowe and Robert Parker.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1466767 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/04/13 9:52 PM",
      "commitName": "6a1c41111edcdc58c846fc50e53554fbba230171",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "05/04/13 10:30 PM",
      "commitNameOld": "7f13207ed15d9f84c9957b7d9efc9d3a0701ed10",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 4.97,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,16 @@\n     private void createReduceTasks(JobImpl job) {\n       for (int i \u003d 0; i \u003c job.numReduceTasks; i++) {\n         TaskImpl task \u003d\n             new ReduceTaskImpl(job.jobId, i,\n                 job.eventHandler, \n                 job.remoteJobConfFile, \n                 job.conf, job.numMapTasks, \n                 job.taskAttemptListener, job.jobToken,\n                 job.fsTokens, job.clock,\n-                job.completedTasksFromPreviousRun, \n                 job.applicationAttemptId.getAttemptId(),\n                 job.metrics, job.appContext);\n         job.addTask(task);\n       }\n       LOG.info(\"Number of reduces for job \" + job.jobId + \" \u003d \"\n           + job.numReduceTasks);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void createReduceTasks(JobImpl job) {\n      for (int i \u003d 0; i \u003c job.numReduceTasks; i++) {\n        TaskImpl task \u003d\n            new ReduceTaskImpl(job.jobId, i,\n                job.eventHandler, \n                job.remoteJobConfFile, \n                job.conf, job.numMapTasks, \n                job.taskAttemptListener, job.jobToken,\n                job.fsTokens, job.clock,\n                job.applicationAttemptId.getAttemptId(),\n                job.metrics, job.appContext);\n        job.addTask(task);\n      }\n      LOG.info(\"Number of reduces for job \" + job.jobId + \" \u003d \"\n          + job.numReduceTasks);\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java",
      "extendedDetails": {}
    },
    "402eb1851341fce72c8e46266a2578bb67b5b684": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4813. AM timing out during job commit (jlowe via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1426536 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/12/12 7:01 AM",
      "commitName": "402eb1851341fce72c8e46266a2578bb67b5b684",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "28/11/12 9:52 AM",
      "commitNameOld": "b43deb9af85575ee71e29b385737436139ec5b13",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 29.88,
      "commitsBetweenForRepo": 109,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n     private void createReduceTasks(JobImpl job) {\n       for (int i \u003d 0; i \u003c job.numReduceTasks; i++) {\n         TaskImpl task \u003d\n             new ReduceTaskImpl(job.jobId, i,\n                 job.eventHandler, \n                 job.remoteJobConfFile, \n                 job.conf, job.numMapTasks, \n-                job.taskAttemptListener, job.committer, job.jobToken,\n+                job.taskAttemptListener, job.jobToken,\n                 job.fsTokens, job.clock,\n                 job.completedTasksFromPreviousRun, \n                 job.applicationAttemptId.getAttemptId(),\n                 job.metrics, job.appContext);\n         job.addTask(task);\n       }\n       LOG.info(\"Number of reduces for job \" + job.jobId + \" \u003d \"\n           + job.numReduceTasks);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void createReduceTasks(JobImpl job) {\n      for (int i \u003d 0; i \u003c job.numReduceTasks; i++) {\n        TaskImpl task \u003d\n            new ReduceTaskImpl(job.jobId, i,\n                job.eventHandler, \n                job.remoteJobConfFile, \n                job.conf, job.numMapTasks, \n                job.taskAttemptListener, job.jobToken,\n                job.fsTokens, job.clock,\n                job.completedTasksFromPreviousRun, \n                job.applicationAttemptId.getAttemptId(),\n                job.metrics, job.appContext);\n        job.addTask(task);\n      }\n      LOG.info(\"Number of reduces for job \" + job.jobId + \" \u003d \"\n          + job.numReduceTasks);\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java",
      "extendedDetails": {}
    },
    "f67c2d1bd0c8abc3d4ea76deffe45fdd92ef5e05": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4043. Secret keys set in Credentials are not seen by tasks (Jason Lowe via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1304587 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/03/12 1:46 PM",
      "commitName": "f67c2d1bd0c8abc3d4ea76deffe45fdd92ef5e05",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "06/03/12 3:21 PM",
      "commitNameOld": "c3a4de0ec0389064f5468180d1b9024f64b00f40",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 16.89,
      "commitsBetweenForRepo": 90,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n     private void createReduceTasks(JobImpl job) {\n       for (int i \u003d 0; i \u003c job.numReduceTasks; i++) {\n         TaskImpl task \u003d\n             new ReduceTaskImpl(job.jobId, i,\n                 job.eventHandler, \n                 job.remoteJobConfFile, \n                 job.conf, job.numMapTasks, \n                 job.taskAttemptListener, job.committer, job.jobToken,\n-                job.fsTokens.getAllTokens(), job.clock, \n+                job.fsTokens, job.clock,\n                 job.completedTasksFromPreviousRun, \n                 job.applicationAttemptId.getAttemptId(),\n                 job.metrics, job.appContext);\n         job.addTask(task);\n       }\n       LOG.info(\"Number of reduces for job \" + job.jobId + \" \u003d \"\n           + job.numReduceTasks);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void createReduceTasks(JobImpl job) {\n      for (int i \u003d 0; i \u003c job.numReduceTasks; i++) {\n        TaskImpl task \u003d\n            new ReduceTaskImpl(job.jobId, i,\n                job.eventHandler, \n                job.remoteJobConfFile, \n                job.conf, job.numMapTasks, \n                job.taskAttemptListener, job.committer, job.jobToken,\n                job.fsTokens, job.clock,\n                job.completedTasksFromPreviousRun, \n                job.applicationAttemptId.getAttemptId(),\n                job.metrics, job.appContext);\n        job.addTask(task);\n      }\n      LOG.info(\"Number of reduces for job \" + job.jobId + \" \u003d \"\n          + job.numReduceTasks);\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java",
      "extendedDetails": {}
    },
    "c3a4de0ec0389064f5468180d1b9024f64b00f40": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3961. Map/ReduceSlotMillis computation incorrect (Siddharth Seth via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1297788 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/03/12 3:21 PM",
      "commitName": "c3a4de0ec0389064f5468180d1b9024f64b00f40",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "24/02/12 2:30 PM",
      "commitNameOld": "582b97c3e75d3e7535a6cdf32a53582e89380490",
      "commitAuthorOld": "Thomas Graves",
      "daysBetweenCommits": 11.04,
      "commitsBetweenForRepo": 97,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n     private void createReduceTasks(JobImpl job) {\n       for (int i \u003d 0; i \u003c job.numReduceTasks; i++) {\n         TaskImpl task \u003d\n             new ReduceTaskImpl(job.jobId, i,\n                 job.eventHandler, \n                 job.remoteJobConfFile, \n                 job.conf, job.numMapTasks, \n                 job.taskAttemptListener, job.committer, job.jobToken,\n                 job.fsTokens.getAllTokens(), job.clock, \n                 job.completedTasksFromPreviousRun, \n                 job.applicationAttemptId.getAttemptId(),\n-                job.metrics);\n+                job.metrics, job.appContext);\n         job.addTask(task);\n       }\n       LOG.info(\"Number of reduces for job \" + job.jobId + \" \u003d \"\n           + job.numReduceTasks);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void createReduceTasks(JobImpl job) {\n      for (int i \u003d 0; i \u003c job.numReduceTasks; i++) {\n        TaskImpl task \u003d\n            new ReduceTaskImpl(job.jobId, i,\n                job.eventHandler, \n                job.remoteJobConfFile, \n                job.conf, job.numMapTasks, \n                job.taskAttemptListener, job.committer, job.jobToken,\n                job.fsTokens.getAllTokens(), job.clock, \n                job.completedTasksFromPreviousRun, \n                job.applicationAttemptId.getAttemptId(),\n                job.metrics, job.appContext);\n        job.addTask(task);\n      }\n      LOG.info(\"Number of reduces for job \" + job.jobId + \" \u003d \"\n          + job.numReduceTasks);\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java",
      "extendedDetails": {}
    },
    "c9a7d3dbf902244902b636bf566154c09ecd1116": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3090. Fix MR AM to use ApplicationAttemptId rather than (ApplicationId, startCount) consistently. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1175718 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/09/11 1:44 AM",
      "commitName": "c9a7d3dbf902244902b636bf566154c09ecd1116",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "21/09/11 11:28 AM",
      "commitNameOld": "d00b3c49f6fb3f6a617add6203c6b55f6c345940",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 4.59,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,17 @@\n     private void createReduceTasks(JobImpl job) {\n       for (int i \u003d 0; i \u003c job.numReduceTasks; i++) {\n         TaskImpl task \u003d\n             new ReduceTaskImpl(job.jobId, i,\n                 job.eventHandler, \n                 job.remoteJobConfFile, \n                 job.conf, job.numMapTasks, \n                 job.taskAttemptListener, job.committer, job.jobToken,\n                 job.fsTokens.getAllTokens(), job.clock, \n-                job.completedTasksFromPreviousRun, job.startCount, job.metrics);\n+                job.completedTasksFromPreviousRun, \n+                job.applicationAttemptId.getAttemptId(),\n+                job.metrics);\n         job.addTask(task);\n       }\n       LOG.info(\"Number of reduces for job \" + job.jobId + \" \u003d \"\n           + job.numReduceTasks);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void createReduceTasks(JobImpl job) {\n      for (int i \u003d 0; i \u003c job.numReduceTasks; i++) {\n        TaskImpl task \u003d\n            new ReduceTaskImpl(job.jobId, i,\n                job.eventHandler, \n                job.remoteJobConfFile, \n                job.conf, job.numMapTasks, \n                job.taskAttemptListener, job.committer, job.jobToken,\n                job.fsTokens.getAllTokens(), job.clock, \n                job.completedTasksFromPreviousRun, \n                job.applicationAttemptId.getAttemptId(),\n                job.metrics);\n        job.addTask(task);\n      }\n      LOG.info(\"Number of reduces for job \" + job.jobId + \" \u003d \"\n          + job.numReduceTasks);\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void createReduceTasks(JobImpl job) {\n      for (int i \u003d 0; i \u003c job.numReduceTasks; i++) {\n        TaskImpl task \u003d\n            new ReduceTaskImpl(job.jobId, i,\n                job.eventHandler, \n                job.remoteJobConfFile, \n                job.conf, job.numMapTasks, \n                job.taskAttemptListener, job.committer, job.jobToken,\n                job.fsTokens.getAllTokens(), job.clock, \n                job.completedTasksFromPreviousRun, job.startCount, job.metrics);\n        job.addTask(task);\n      }\n      LOG.info(\"Number of reduces for job \" + job.jobId + \" \u003d \"\n          + job.numReduceTasks);\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,15 @@\n+    private void createReduceTasks(JobImpl job) {\n+      for (int i \u003d 0; i \u003c job.numReduceTasks; i++) {\n+        TaskImpl task \u003d\n+            new ReduceTaskImpl(job.jobId, i,\n+                job.eventHandler, \n+                job.remoteJobConfFile, \n+                job.conf, job.numMapTasks, \n+                job.taskAttemptListener, job.committer, job.jobToken,\n+                job.fsTokens.getAllTokens(), job.clock, \n+                job.completedTasksFromPreviousRun, job.startCount, job.metrics);\n+        job.addTask(task);\n+      }\n+      LOG.info(\"Number of reduces for job \" + job.jobId + \" \u003d \"\n+          + job.numReduceTasks);\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private void createReduceTasks(JobImpl job) {\n      for (int i \u003d 0; i \u003c job.numReduceTasks; i++) {\n        TaskImpl task \u003d\n            new ReduceTaskImpl(job.jobId, i,\n                job.eventHandler, \n                job.remoteJobConfFile, \n                job.conf, job.numMapTasks, \n                job.taskAttemptListener, job.committer, job.jobToken,\n                job.fsTokens.getAllTokens(), job.clock, \n                job.completedTasksFromPreviousRun, job.startCount, job.metrics);\n        job.addTask(task);\n      }\n      LOG.info(\"Number of reduces for job \" + job.jobId + \" \u003d \"\n          + job.numReduceTasks);\n    }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java"
    }
  }
}