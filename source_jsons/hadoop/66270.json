{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RumenToSLSConverter.java",
  "functionName": "generateSLSNodeFile",
  "functionId": "generateSLSNodeFile___outputFile-String",
  "sourceFilePath": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/RumenToSLSConverter.java",
  "functionStartLine": 140,
  "functionEndLine": 159,
  "numCommitsSeen": 6,
  "timeTaken": 878,
  "changeHistory": [
    "f384a063a653b33d69f7d2c7d4fd45c24b5aa46a",
    "b8f250a99dd746599c5d9830fa1d52149ca418b0",
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b"
  ],
  "changeHistoryShort": {
    "f384a063a653b33d69f7d2c7d4fd45c24b5aa46a": "Ybodychange",
    "b8f250a99dd746599c5d9830fa1d52149ca418b0": "Ybodychange",
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f384a063a653b33d69f7d2c7d4fd45c24b5aa46a": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11821. Fix findbugs warnings in hadoop-sls. Contributed by Brahma Reddy Battula.\n",
      "commitDate": "30/04/15 3:34 AM",
      "commitName": "f384a063a653b33d69f7d2c7d4fd45c24b5aa46a",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "25/07/14 10:12 AM",
      "commitNameOld": "77363b9d839e47bef2325b8682eabe00d4c83354",
      "commitAuthorOld": "Karthik Kambatla",
      "daysBetweenCommits": 278.72,
      "commitsBetweenForRepo": 2401,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,20 @@\n   private static void generateSLSNodeFile(String outputFile)\n           throws IOException {\n-    Writer output \u003d new FileWriter(outputFile);\n-    try {\n+    try (Writer output \u003d\n+        new OutputStreamWriter(new FileOutputStream(outputFile), \"UTF-8\")) {\n       ObjectMapper mapper \u003d new ObjectMapper();\n       ObjectWriter writer \u003d mapper.writerWithDefaultPrettyPrinter();\n       for (Map.Entry\u003cString, Set\u003cString\u003e\u003e entry : rackNodeMap.entrySet()) {\n         Map rack \u003d new LinkedHashMap();\n         rack.put(\"rack\", entry.getKey());\n         List nodes \u003d new ArrayList();\n         for (String name : entry.getValue()) {\n           Map node \u003d new LinkedHashMap();\n           node.put(\"node\", name);\n           nodes.add(node);\n         }\n         rack.put(\"nodes\", nodes);\n         output.write(writer.writeValueAsString(rack) + EOL);\n       }\n-    } finally {\n-      output.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static void generateSLSNodeFile(String outputFile)\n          throws IOException {\n    try (Writer output \u003d\n        new OutputStreamWriter(new FileOutputStream(outputFile), \"UTF-8\")) {\n      ObjectMapper mapper \u003d new ObjectMapper();\n      ObjectWriter writer \u003d mapper.writerWithDefaultPrettyPrinter();\n      for (Map.Entry\u003cString, Set\u003cString\u003e\u003e entry : rackNodeMap.entrySet()) {\n        Map rack \u003d new LinkedHashMap();\n        rack.put(\"rack\", entry.getKey());\n        List nodes \u003d new ArrayList();\n        for (String name : entry.getValue()) {\n          Map node \u003d new LinkedHashMap();\n          node.put(\"node\", name);\n          nodes.add(node);\n        }\n        rack.put(\"nodes\", nodes);\n        output.write(writer.writeValueAsString(rack) + EOL);\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/RumenToSLSConverter.java",
      "extendedDetails": {}
    },
    "b8f250a99dd746599c5d9830fa1d52149ca418b0": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10104. Update jackson to 1.9.13 (Akira Ajisaka via stevel)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1585932 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/04/14 4:11 AM",
      "commitName": "b8f250a99dd746599c5d9830fa1d52149ca418b0",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "27/09/13 1:23 PM",
      "commitNameOld": "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 193.62,
      "commitsBetweenForRepo": 1355,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   private static void generateSLSNodeFile(String outputFile)\n           throws IOException {\n     Writer output \u003d new FileWriter(outputFile);\n     try {\n       ObjectMapper mapper \u003d new ObjectMapper();\n-      ObjectWriter writer \u003d mapper.defaultPrettyPrintingWriter();\n+      ObjectWriter writer \u003d mapper.writerWithDefaultPrettyPrinter();\n       for (Map.Entry\u003cString, Set\u003cString\u003e\u003e entry : rackNodeMap.entrySet()) {\n         Map rack \u003d new LinkedHashMap();\n         rack.put(\"rack\", entry.getKey());\n         List nodes \u003d new ArrayList();\n         for (String name : entry.getValue()) {\n           Map node \u003d new LinkedHashMap();\n           node.put(\"node\", name);\n           nodes.add(node);\n         }\n         rack.put(\"nodes\", nodes);\n         output.write(writer.writeValueAsString(rack) + EOL);\n       }\n     } finally {\n       output.close();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static void generateSLSNodeFile(String outputFile)\n          throws IOException {\n    Writer output \u003d new FileWriter(outputFile);\n    try {\n      ObjectMapper mapper \u003d new ObjectMapper();\n      ObjectWriter writer \u003d mapper.writerWithDefaultPrettyPrinter();\n      for (Map.Entry\u003cString, Set\u003cString\u003e\u003e entry : rackNodeMap.entrySet()) {\n        Map rack \u003d new LinkedHashMap();\n        rack.put(\"rack\", entry.getKey());\n        List nodes \u003d new ArrayList();\n        for (String name : entry.getValue()) {\n          Map node \u003d new LinkedHashMap();\n          node.put(\"node\", name);\n          nodes.add(node);\n        }\n        rack.put(\"nodes\", nodes);\n        output.write(writer.writeValueAsString(rack) + EOL);\n      }\n    } finally {\n      output.close();\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/RumenToSLSConverter.java",
      "extendedDetails": {}
    },
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b": {
      "type": "Yintroduced",
      "commitMessage": "YARN-1021. Yarn Scheduler Load Simulator. (ywskycn via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1527059 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/09/13 1:23 PM",
      "commitName": "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b",
      "commitAuthor": "Alejandro Abdelnur",
      "diff": "@@ -0,0 +1,22 @@\n+  private static void generateSLSNodeFile(String outputFile)\n+          throws IOException {\n+    Writer output \u003d new FileWriter(outputFile);\n+    try {\n+      ObjectMapper mapper \u003d new ObjectMapper();\n+      ObjectWriter writer \u003d mapper.defaultPrettyPrintingWriter();\n+      for (Map.Entry\u003cString, Set\u003cString\u003e\u003e entry : rackNodeMap.entrySet()) {\n+        Map rack \u003d new LinkedHashMap();\n+        rack.put(\"rack\", entry.getKey());\n+        List nodes \u003d new ArrayList();\n+        for (String name : entry.getValue()) {\n+          Map node \u003d new LinkedHashMap();\n+          node.put(\"node\", name);\n+          nodes.add(node);\n+        }\n+        rack.put(\"nodes\", nodes);\n+        output.write(writer.writeValueAsString(rack) + EOL);\n+      }\n+    } finally {\n+      output.close();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static void generateSLSNodeFile(String outputFile)\n          throws IOException {\n    Writer output \u003d new FileWriter(outputFile);\n    try {\n      ObjectMapper mapper \u003d new ObjectMapper();\n      ObjectWriter writer \u003d mapper.defaultPrettyPrintingWriter();\n      for (Map.Entry\u003cString, Set\u003cString\u003e\u003e entry : rackNodeMap.entrySet()) {\n        Map rack \u003d new LinkedHashMap();\n        rack.put(\"rack\", entry.getKey());\n        List nodes \u003d new ArrayList();\n        for (String name : entry.getValue()) {\n          Map node \u003d new LinkedHashMap();\n          node.put(\"node\", name);\n          nodes.add(node);\n        }\n        rack.put(\"nodes\", nodes);\n        output.write(writer.writeValueAsString(rack) + EOL);\n      }\n    } finally {\n      output.close();\n    }\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/RumenToSLSConverter.java"
    }
  }
}