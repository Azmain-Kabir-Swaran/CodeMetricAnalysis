{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NMClientAsyncImpl.java",
  "functionName": "serviceStart",
  "functionId": "serviceStart",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/async/impl/NMClientAsyncImpl.java",
  "functionStartLine": 145,
  "functionEndLine": 212,
  "numCommitsSeen": 19,
  "timeTaken": 1615,
  "changeHistory": [
    "7ef54faad4bee4346da082a3f8cc5d6ea405d74a",
    "0928502029ef141759008997335ea2cd836a7154",
    "edc6d7d3abac3ebad711dda43d7c6a3aeabe025b"
  ],
  "changeHistoryShort": {
    "7ef54faad4bee4346da082a3f8cc5d6ea405d74a": "Yfilerename",
    "0928502029ef141759008997335ea2cd836a7154": "Ymultichange(Yrename,Ymodifierchange,Yexceptionschange,Ybodychange)",
    "edc6d7d3abac3ebad711dda43d7c6a3aeabe025b": "Yintroduced"
  },
  "changeHistoryDetails": {
    "7ef54faad4bee4346da082a3f8cc5d6ea405d74a": {
      "type": "Yfilerename",
      "commitMessage": "YARN-834. Fixed annotations for yarn-client module, reorganized packages and clearly differentiated *Async apis. Contributed by Arun C Murthy and Zhijie Shen.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1494017 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/06/13 9:02 PM",
      "commitName": "7ef54faad4bee4346da082a3f8cc5d6ea405d74a",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/06/13 8:10 PM",
      "commitNameOld": "2b14656ab5050dd75935b64681cdc25fb49db94f",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected void serviceStart() throws Exception {\n    client.start();\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        this.getClass().getName() + \" #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size and change it dynamically.\n    int initSize \u003d Math.min(INITIAL_THREAD_POOL_SIZE, maxThreadPoolSize);\n    threadPool \u003d new ThreadPoolExecutor(initSize, Integer.MAX_VALUE, 1,\n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n\n    eventDispatcherThread \u003d new Thread() {\n      @Override\n      public void run() {\n        ContainerEvent event \u003d null;\n        Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d events.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, thread interrupted\", e);\n            }\n            return;\n          }\n\n          allNodes.add(event.getNodeId().toString());\n\n          int threadPoolSize \u003d threadPool.getCorePoolSize();\n\n          // We can increase the pool size only if haven\u0027t reached the maximum\n          // limit yet.\n          if (threadPoolSize !\u003d maxThreadPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int nodeNum \u003d allNodes.size();\n            int idealThreadPoolSize \u003d Math.min(maxThreadPoolSize, nodeNum);\n\n            if (threadPoolSize \u003c idealThreadPoolSize) {\n              // Bump up the pool size to idealThreadPoolSize +\n              // INITIAL_POOL_SIZE, the later is just a buffer so we are not\n              // always increasing the pool-size\n              int newThreadPoolSize \u003d Math.min(maxThreadPoolSize,\n                  idealThreadPoolSize + INITIAL_THREAD_POOL_SIZE);\n              LOG.info(\"Set NMClientAsync thread pool size to \" +\n                  newThreadPoolSize + \" as the number of nodes to talk to is \"\n                  + nodeNum);\n              threadPool.setCorePoolSize(newThreadPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel with a thread\n          // pool\n          threadPool.execute(getContainerEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    };\n    eventDispatcherThread.setName(\"Container  Event Dispatcher\");\n    eventDispatcherThread.setDaemon(false);\n    eventDispatcherThread.start();\n\n    super.serviceStart();\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/async/impl/NMClientAsyncImpl.java",
      "extendedDetails": {
        "oldPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/NMClientAsync.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/async/impl/NMClientAsyncImpl.java"
      }
    },
    "0928502029ef141759008997335ea2cd836a7154": {
      "type": "Ymultichange(Yrename,Ymodifierchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/06/13 8:54 AM",
      "commitName": "0928502029ef141759008997335ea2cd836a7154",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,68 +1,68 @@\n-  public void start() {\n+  protected void serviceStart() throws Exception {\n     client.start();\n \n     ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n         this.getClass().getName() + \" #%d\").setDaemon(true).build();\n \n     // Start with a default core-pool size and change it dynamically.\n     int initSize \u003d Math.min(INITIAL_THREAD_POOL_SIZE, maxThreadPoolSize);\n     threadPool \u003d new ThreadPoolExecutor(initSize, Integer.MAX_VALUE, 1,\n         TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n \n     eventDispatcherThread \u003d new Thread() {\n       @Override\n       public void run() {\n         ContainerEvent event \u003d null;\n         Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n \n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d events.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, thread interrupted\", e);\n             }\n             return;\n           }\n \n           allNodes.add(event.getNodeId().toString());\n \n           int threadPoolSize \u003d threadPool.getCorePoolSize();\n \n           // We can increase the pool size only if haven\u0027t reached the maximum\n           // limit yet.\n           if (threadPoolSize !\u003d maxThreadPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n             int nodeNum \u003d allNodes.size();\n             int idealThreadPoolSize \u003d Math.min(maxThreadPoolSize, nodeNum);\n \n             if (threadPoolSize \u003c idealThreadPoolSize) {\n               // Bump up the pool size to idealThreadPoolSize +\n               // INITIAL_POOL_SIZE, the later is just a buffer so we are not\n               // always increasing the pool-size\n               int newThreadPoolSize \u003d Math.min(maxThreadPoolSize,\n                   idealThreadPoolSize + INITIAL_THREAD_POOL_SIZE);\n               LOG.info(\"Set NMClientAsync thread pool size to \" +\n                   newThreadPoolSize + \" as the number of nodes to talk to is \"\n                   + nodeNum);\n               threadPool.setCorePoolSize(newThreadPoolSize);\n             }\n           }\n \n           // the events from the queue are handled in parallel with a thread\n           // pool\n           threadPool.execute(getContainerEventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     };\n     eventDispatcherThread.setName(\"Container  Event Dispatcher\");\n     eventDispatcherThread.setDaemon(false);\n     eventDispatcherThread.start();\n \n-    super.start();\n+    super.serviceStart();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceStart() throws Exception {\n    client.start();\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        this.getClass().getName() + \" #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size and change it dynamically.\n    int initSize \u003d Math.min(INITIAL_THREAD_POOL_SIZE, maxThreadPoolSize);\n    threadPool \u003d new ThreadPoolExecutor(initSize, Integer.MAX_VALUE, 1,\n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n\n    eventDispatcherThread \u003d new Thread() {\n      @Override\n      public void run() {\n        ContainerEvent event \u003d null;\n        Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d events.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, thread interrupted\", e);\n            }\n            return;\n          }\n\n          allNodes.add(event.getNodeId().toString());\n\n          int threadPoolSize \u003d threadPool.getCorePoolSize();\n\n          // We can increase the pool size only if haven\u0027t reached the maximum\n          // limit yet.\n          if (threadPoolSize !\u003d maxThreadPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int nodeNum \u003d allNodes.size();\n            int idealThreadPoolSize \u003d Math.min(maxThreadPoolSize, nodeNum);\n\n            if (threadPoolSize \u003c idealThreadPoolSize) {\n              // Bump up the pool size to idealThreadPoolSize +\n              // INITIAL_POOL_SIZE, the later is just a buffer so we are not\n              // always increasing the pool-size\n              int newThreadPoolSize \u003d Math.min(maxThreadPoolSize,\n                  idealThreadPoolSize + INITIAL_THREAD_POOL_SIZE);\n              LOG.info(\"Set NMClientAsync thread pool size to \" +\n                  newThreadPoolSize + \" as the number of nodes to talk to is \"\n                  + nodeNum);\n              threadPool.setCorePoolSize(newThreadPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel with a thread\n          // pool\n          threadPool.execute(getContainerEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    };\n    eventDispatcherThread.setName(\"Container  Event Dispatcher\");\n    eventDispatcherThread.setDaemon(false);\n    eventDispatcherThread.start();\n\n    super.serviceStart();\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/NMClientAsync.java",
          "extendedDetails": {
            "oldValue": "start",
            "newValue": "serviceStart"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,68 +1,68 @@\n-  public void start() {\n+  protected void serviceStart() throws Exception {\n     client.start();\n \n     ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n         this.getClass().getName() + \" #%d\").setDaemon(true).build();\n \n     // Start with a default core-pool size and change it dynamically.\n     int initSize \u003d Math.min(INITIAL_THREAD_POOL_SIZE, maxThreadPoolSize);\n     threadPool \u003d new ThreadPoolExecutor(initSize, Integer.MAX_VALUE, 1,\n         TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n \n     eventDispatcherThread \u003d new Thread() {\n       @Override\n       public void run() {\n         ContainerEvent event \u003d null;\n         Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n \n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d events.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, thread interrupted\", e);\n             }\n             return;\n           }\n \n           allNodes.add(event.getNodeId().toString());\n \n           int threadPoolSize \u003d threadPool.getCorePoolSize();\n \n           // We can increase the pool size only if haven\u0027t reached the maximum\n           // limit yet.\n           if (threadPoolSize !\u003d maxThreadPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n             int nodeNum \u003d allNodes.size();\n             int idealThreadPoolSize \u003d Math.min(maxThreadPoolSize, nodeNum);\n \n             if (threadPoolSize \u003c idealThreadPoolSize) {\n               // Bump up the pool size to idealThreadPoolSize +\n               // INITIAL_POOL_SIZE, the later is just a buffer so we are not\n               // always increasing the pool-size\n               int newThreadPoolSize \u003d Math.min(maxThreadPoolSize,\n                   idealThreadPoolSize + INITIAL_THREAD_POOL_SIZE);\n               LOG.info(\"Set NMClientAsync thread pool size to \" +\n                   newThreadPoolSize + \" as the number of nodes to talk to is \"\n                   + nodeNum);\n               threadPool.setCorePoolSize(newThreadPoolSize);\n             }\n           }\n \n           // the events from the queue are handled in parallel with a thread\n           // pool\n           threadPool.execute(getContainerEventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     };\n     eventDispatcherThread.setName(\"Container  Event Dispatcher\");\n     eventDispatcherThread.setDaemon(false);\n     eventDispatcherThread.start();\n \n-    super.start();\n+    super.serviceStart();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceStart() throws Exception {\n    client.start();\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        this.getClass().getName() + \" #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size and change it dynamically.\n    int initSize \u003d Math.min(INITIAL_THREAD_POOL_SIZE, maxThreadPoolSize);\n    threadPool \u003d new ThreadPoolExecutor(initSize, Integer.MAX_VALUE, 1,\n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n\n    eventDispatcherThread \u003d new Thread() {\n      @Override\n      public void run() {\n        ContainerEvent event \u003d null;\n        Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d events.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, thread interrupted\", e);\n            }\n            return;\n          }\n\n          allNodes.add(event.getNodeId().toString());\n\n          int threadPoolSize \u003d threadPool.getCorePoolSize();\n\n          // We can increase the pool size only if haven\u0027t reached the maximum\n          // limit yet.\n          if (threadPoolSize !\u003d maxThreadPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int nodeNum \u003d allNodes.size();\n            int idealThreadPoolSize \u003d Math.min(maxThreadPoolSize, nodeNum);\n\n            if (threadPoolSize \u003c idealThreadPoolSize) {\n              // Bump up the pool size to idealThreadPoolSize +\n              // INITIAL_POOL_SIZE, the later is just a buffer so we are not\n              // always increasing the pool-size\n              int newThreadPoolSize \u003d Math.min(maxThreadPoolSize,\n                  idealThreadPoolSize + INITIAL_THREAD_POOL_SIZE);\n              LOG.info(\"Set NMClientAsync thread pool size to \" +\n                  newThreadPoolSize + \" as the number of nodes to talk to is \"\n                  + nodeNum);\n              threadPool.setCorePoolSize(newThreadPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel with a thread\n          // pool\n          threadPool.execute(getContainerEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    };\n    eventDispatcherThread.setName(\"Container  Event Dispatcher\");\n    eventDispatcherThread.setDaemon(false);\n    eventDispatcherThread.start();\n\n    super.serviceStart();\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/NMClientAsync.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[protected]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,68 +1,68 @@\n-  public void start() {\n+  protected void serviceStart() throws Exception {\n     client.start();\n \n     ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n         this.getClass().getName() + \" #%d\").setDaemon(true).build();\n \n     // Start with a default core-pool size and change it dynamically.\n     int initSize \u003d Math.min(INITIAL_THREAD_POOL_SIZE, maxThreadPoolSize);\n     threadPool \u003d new ThreadPoolExecutor(initSize, Integer.MAX_VALUE, 1,\n         TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n \n     eventDispatcherThread \u003d new Thread() {\n       @Override\n       public void run() {\n         ContainerEvent event \u003d null;\n         Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n \n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d events.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, thread interrupted\", e);\n             }\n             return;\n           }\n \n           allNodes.add(event.getNodeId().toString());\n \n           int threadPoolSize \u003d threadPool.getCorePoolSize();\n \n           // We can increase the pool size only if haven\u0027t reached the maximum\n           // limit yet.\n           if (threadPoolSize !\u003d maxThreadPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n             int nodeNum \u003d allNodes.size();\n             int idealThreadPoolSize \u003d Math.min(maxThreadPoolSize, nodeNum);\n \n             if (threadPoolSize \u003c idealThreadPoolSize) {\n               // Bump up the pool size to idealThreadPoolSize +\n               // INITIAL_POOL_SIZE, the later is just a buffer so we are not\n               // always increasing the pool-size\n               int newThreadPoolSize \u003d Math.min(maxThreadPoolSize,\n                   idealThreadPoolSize + INITIAL_THREAD_POOL_SIZE);\n               LOG.info(\"Set NMClientAsync thread pool size to \" +\n                   newThreadPoolSize + \" as the number of nodes to talk to is \"\n                   + nodeNum);\n               threadPool.setCorePoolSize(newThreadPoolSize);\n             }\n           }\n \n           // the events from the queue are handled in parallel with a thread\n           // pool\n           threadPool.execute(getContainerEventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     };\n     eventDispatcherThread.setName(\"Container  Event Dispatcher\");\n     eventDispatcherThread.setDaemon(false);\n     eventDispatcherThread.start();\n \n-    super.start();\n+    super.serviceStart();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceStart() throws Exception {\n    client.start();\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        this.getClass().getName() + \" #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size and change it dynamically.\n    int initSize \u003d Math.min(INITIAL_THREAD_POOL_SIZE, maxThreadPoolSize);\n    threadPool \u003d new ThreadPoolExecutor(initSize, Integer.MAX_VALUE, 1,\n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n\n    eventDispatcherThread \u003d new Thread() {\n      @Override\n      public void run() {\n        ContainerEvent event \u003d null;\n        Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d events.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, thread interrupted\", e);\n            }\n            return;\n          }\n\n          allNodes.add(event.getNodeId().toString());\n\n          int threadPoolSize \u003d threadPool.getCorePoolSize();\n\n          // We can increase the pool size only if haven\u0027t reached the maximum\n          // limit yet.\n          if (threadPoolSize !\u003d maxThreadPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int nodeNum \u003d allNodes.size();\n            int idealThreadPoolSize \u003d Math.min(maxThreadPoolSize, nodeNum);\n\n            if (threadPoolSize \u003c idealThreadPoolSize) {\n              // Bump up the pool size to idealThreadPoolSize +\n              // INITIAL_POOL_SIZE, the later is just a buffer so we are not\n              // always increasing the pool-size\n              int newThreadPoolSize \u003d Math.min(maxThreadPoolSize,\n                  idealThreadPoolSize + INITIAL_THREAD_POOL_SIZE);\n              LOG.info(\"Set NMClientAsync thread pool size to \" +\n                  newThreadPoolSize + \" as the number of nodes to talk to is \"\n                  + nodeNum);\n              threadPool.setCorePoolSize(newThreadPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel with a thread\n          // pool\n          threadPool.execute(getContainerEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    };\n    eventDispatcherThread.setName(\"Container  Event Dispatcher\");\n    eventDispatcherThread.setDaemon(false);\n    eventDispatcherThread.start();\n\n    super.serviceStart();\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/NMClientAsync.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[Exception]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,68 +1,68 @@\n-  public void start() {\n+  protected void serviceStart() throws Exception {\n     client.start();\n \n     ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n         this.getClass().getName() + \" #%d\").setDaemon(true).build();\n \n     // Start with a default core-pool size and change it dynamically.\n     int initSize \u003d Math.min(INITIAL_THREAD_POOL_SIZE, maxThreadPoolSize);\n     threadPool \u003d new ThreadPoolExecutor(initSize, Integer.MAX_VALUE, 1,\n         TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n \n     eventDispatcherThread \u003d new Thread() {\n       @Override\n       public void run() {\n         ContainerEvent event \u003d null;\n         Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n \n         while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n           try {\n             event \u003d events.take();\n           } catch (InterruptedException e) {\n             if (!stopped.get()) {\n               LOG.error(\"Returning, thread interrupted\", e);\n             }\n             return;\n           }\n \n           allNodes.add(event.getNodeId().toString());\n \n           int threadPoolSize \u003d threadPool.getCorePoolSize();\n \n           // We can increase the pool size only if haven\u0027t reached the maximum\n           // limit yet.\n           if (threadPoolSize !\u003d maxThreadPoolSize) {\n \n             // nodes where containers will run at *this* point of time. This is\n             // *not* the cluster size and doesn\u0027t need to be.\n             int nodeNum \u003d allNodes.size();\n             int idealThreadPoolSize \u003d Math.min(maxThreadPoolSize, nodeNum);\n \n             if (threadPoolSize \u003c idealThreadPoolSize) {\n               // Bump up the pool size to idealThreadPoolSize +\n               // INITIAL_POOL_SIZE, the later is just a buffer so we are not\n               // always increasing the pool-size\n               int newThreadPoolSize \u003d Math.min(maxThreadPoolSize,\n                   idealThreadPoolSize + INITIAL_THREAD_POOL_SIZE);\n               LOG.info(\"Set NMClientAsync thread pool size to \" +\n                   newThreadPoolSize + \" as the number of nodes to talk to is \"\n                   + nodeNum);\n               threadPool.setCorePoolSize(newThreadPoolSize);\n             }\n           }\n \n           // the events from the queue are handled in parallel with a thread\n           // pool\n           threadPool.execute(getContainerEventProcessor(event));\n \n           // TODO: Group launching of multiple containers to a single\n           // NodeManager into a single connection\n         }\n       }\n     };\n     eventDispatcherThread.setName(\"Container  Event Dispatcher\");\n     eventDispatcherThread.setDaemon(false);\n     eventDispatcherThread.start();\n \n-    super.start();\n+    super.serviceStart();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceStart() throws Exception {\n    client.start();\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        this.getClass().getName() + \" #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size and change it dynamically.\n    int initSize \u003d Math.min(INITIAL_THREAD_POOL_SIZE, maxThreadPoolSize);\n    threadPool \u003d new ThreadPoolExecutor(initSize, Integer.MAX_VALUE, 1,\n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n\n    eventDispatcherThread \u003d new Thread() {\n      @Override\n      public void run() {\n        ContainerEvent event \u003d null;\n        Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d events.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, thread interrupted\", e);\n            }\n            return;\n          }\n\n          allNodes.add(event.getNodeId().toString());\n\n          int threadPoolSize \u003d threadPool.getCorePoolSize();\n\n          // We can increase the pool size only if haven\u0027t reached the maximum\n          // limit yet.\n          if (threadPoolSize !\u003d maxThreadPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int nodeNum \u003d allNodes.size();\n            int idealThreadPoolSize \u003d Math.min(maxThreadPoolSize, nodeNum);\n\n            if (threadPoolSize \u003c idealThreadPoolSize) {\n              // Bump up the pool size to idealThreadPoolSize +\n              // INITIAL_POOL_SIZE, the later is just a buffer so we are not\n              // always increasing the pool-size\n              int newThreadPoolSize \u003d Math.min(maxThreadPoolSize,\n                  idealThreadPoolSize + INITIAL_THREAD_POOL_SIZE);\n              LOG.info(\"Set NMClientAsync thread pool size to \" +\n                  newThreadPoolSize + \" as the number of nodes to talk to is \"\n                  + nodeNum);\n              threadPool.setCorePoolSize(newThreadPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel with a thread\n          // pool\n          threadPool.execute(getContainerEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    };\n    eventDispatcherThread.setName(\"Container  Event Dispatcher\");\n    eventDispatcherThread.setDaemon(false);\n    eventDispatcherThread.start();\n\n    super.serviceStart();\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/NMClientAsync.java",
          "extendedDetails": {}
        }
      ]
    },
    "edc6d7d3abac3ebad711dda43d7c6a3aeabe025b": {
      "type": "Yintroduced",
      "commitMessage": "YARN-422. Add a NM Client library to help application-writers. Contributed by Zhijie Shen.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1487184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/05/13 6:41 PM",
      "commitName": "edc6d7d3abac3ebad711dda43d7c6a3aeabe025b",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,68 @@\n+  public void start() {\n+    client.start();\n+\n+    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n+        this.getClass().getName() + \" #%d\").setDaemon(true).build();\n+\n+    // Start with a default core-pool size and change it dynamically.\n+    int initSize \u003d Math.min(INITIAL_THREAD_POOL_SIZE, maxThreadPoolSize);\n+    threadPool \u003d new ThreadPoolExecutor(initSize, Integer.MAX_VALUE, 1,\n+        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n+\n+    eventDispatcherThread \u003d new Thread() {\n+      @Override\n+      public void run() {\n+        ContainerEvent event \u003d null;\n+        Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n+\n+        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n+          try {\n+            event \u003d events.take();\n+          } catch (InterruptedException e) {\n+            if (!stopped.get()) {\n+              LOG.error(\"Returning, thread interrupted\", e);\n+            }\n+            return;\n+          }\n+\n+          allNodes.add(event.getNodeId().toString());\n+\n+          int threadPoolSize \u003d threadPool.getCorePoolSize();\n+\n+          // We can increase the pool size only if haven\u0027t reached the maximum\n+          // limit yet.\n+          if (threadPoolSize !\u003d maxThreadPoolSize) {\n+\n+            // nodes where containers will run at *this* point of time. This is\n+            // *not* the cluster size and doesn\u0027t need to be.\n+            int nodeNum \u003d allNodes.size();\n+            int idealThreadPoolSize \u003d Math.min(maxThreadPoolSize, nodeNum);\n+\n+            if (threadPoolSize \u003c idealThreadPoolSize) {\n+              // Bump up the pool size to idealThreadPoolSize +\n+              // INITIAL_POOL_SIZE, the later is just a buffer so we are not\n+              // always increasing the pool-size\n+              int newThreadPoolSize \u003d Math.min(maxThreadPoolSize,\n+                  idealThreadPoolSize + INITIAL_THREAD_POOL_SIZE);\n+              LOG.info(\"Set NMClientAsync thread pool size to \" +\n+                  newThreadPoolSize + \" as the number of nodes to talk to is \"\n+                  + nodeNum);\n+              threadPool.setCorePoolSize(newThreadPoolSize);\n+            }\n+          }\n+\n+          // the events from the queue are handled in parallel with a thread\n+          // pool\n+          threadPool.execute(getContainerEventProcessor(event));\n+\n+          // TODO: Group launching of multiple containers to a single\n+          // NodeManager into a single connection\n+        }\n+      }\n+    };\n+    eventDispatcherThread.setName(\"Container  Event Dispatcher\");\n+    eventDispatcherThread.setDaemon(false);\n+    eventDispatcherThread.start();\n+\n+    super.start();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void start() {\n    client.start();\n\n    ThreadFactory tf \u003d new ThreadFactoryBuilder().setNameFormat(\n        this.getClass().getName() + \" #%d\").setDaemon(true).build();\n\n    // Start with a default core-pool size and change it dynamically.\n    int initSize \u003d Math.min(INITIAL_THREAD_POOL_SIZE, maxThreadPoolSize);\n    threadPool \u003d new ThreadPoolExecutor(initSize, Integer.MAX_VALUE, 1,\n        TimeUnit.HOURS, new LinkedBlockingQueue\u003cRunnable\u003e(), tf);\n\n    eventDispatcherThread \u003d new Thread() {\n      @Override\n      public void run() {\n        ContainerEvent event \u003d null;\n        Set\u003cString\u003e allNodes \u003d new HashSet\u003cString\u003e();\n\n        while (!stopped.get() \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d events.take();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.error(\"Returning, thread interrupted\", e);\n            }\n            return;\n          }\n\n          allNodes.add(event.getNodeId().toString());\n\n          int threadPoolSize \u003d threadPool.getCorePoolSize();\n\n          // We can increase the pool size only if haven\u0027t reached the maximum\n          // limit yet.\n          if (threadPoolSize !\u003d maxThreadPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn\u0027t need to be.\n            int nodeNum \u003d allNodes.size();\n            int idealThreadPoolSize \u003d Math.min(maxThreadPoolSize, nodeNum);\n\n            if (threadPoolSize \u003c idealThreadPoolSize) {\n              // Bump up the pool size to idealThreadPoolSize +\n              // INITIAL_POOL_SIZE, the later is just a buffer so we are not\n              // always increasing the pool-size\n              int newThreadPoolSize \u003d Math.min(maxThreadPoolSize,\n                  idealThreadPoolSize + INITIAL_THREAD_POOL_SIZE);\n              LOG.info(\"Set NMClientAsync thread pool size to \" +\n                  newThreadPoolSize + \" as the number of nodes to talk to is \"\n                  + nodeNum);\n              threadPool.setCorePoolSize(newThreadPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel with a thread\n          // pool\n          threadPool.execute(getContainerEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }\n    };\n    eventDispatcherThread.setName(\"Container  Event Dispatcher\");\n    eventDispatcherThread.setDaemon(false);\n    eventDispatcherThread.start();\n\n    super.start();\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/NMClientAsync.java"
    }
  }
}