{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeProtocolServerSideTranslatorPB.java",
  "functionName": "commitBlockSynchronization",
  "functionId": "commitBlockSynchronization___controller-RpcController__request-CommitBlockSynchronizationRequestProto",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
  "functionStartLine": 291,
  "functionEndLine": 309,
  "numCommitsSeen": 42,
  "timeTaken": 3218,
  "changeHistory": [
    "06022b8fdc40e50eaac63758246353058e8cfa6d",
    "e2c9b288b223b9fd82dc12018936e13128413492",
    "8f70a25b1c5df498c441a9b3475a8ada5a92111f",
    "6326605acb5a5bf48d994278c9d3a39733679e81",
    "38a19bc293dec6221ae96e304fc6ab660d94e706"
  ],
  "changeHistoryShort": {
    "06022b8fdc40e50eaac63758246353058e8cfa6d": "Ybodychange",
    "e2c9b288b223b9fd82dc12018936e13128413492": "Ybodychange",
    "8f70a25b1c5df498c441a9b3475a8ada5a92111f": "Ybodychange",
    "6326605acb5a5bf48d994278c9d3a39733679e81": "Ybodychange",
    "38a19bc293dec6221ae96e304fc6ab660d94e706": "Yintroduced"
  },
  "changeHistoryDetails": {
    "06022b8fdc40e50eaac63758246353058e8cfa6d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9111. Move hdfs-client protobuf convert methods from PBHelper to PBHelperClient. Contributed by Mingliang Liu.\n",
      "commitDate": "21/09/15 6:53 PM",
      "commitName": "06022b8fdc40e50eaac63758246353058e8cfa6d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/08/15 2:38 PM",
      "commitNameOld": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 24.18,
      "commitsBetweenForRepo": 143,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n   public CommitBlockSynchronizationResponseProto commitBlockSynchronization(\n       RpcController controller, CommitBlockSynchronizationRequestProto request)\n       throws ServiceException {\n     List\u003cDatanodeIDProto\u003e dnprotos \u003d request.getNewTaragetsList();\n     DatanodeID[] dns \u003d new DatanodeID[dnprotos.size()];\n     for (int i \u003d 0; i \u003c dnprotos.size(); i++) {\n-      dns[i] \u003d PBHelper.convert(dnprotos.get(i));\n+      dns[i] \u003d PBHelperClient.convert(dnprotos.get(i));\n     }\n     final List\u003cString\u003e sidprotos \u003d request.getNewTargetStoragesList();\n     final String[] storageIDs \u003d sidprotos.toArray(new String[sidprotos.size()]);\n     try {\n       impl.commitBlockSynchronization(PBHelperClient.convert(request.getBlock()),\n           request.getNewGenStamp(), request.getNewLength(),\n           request.getCloseFile(), request.getDeleteBlock(), dns, storageIDs);\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     return VOID_COMMIT_BLOCK_SYNCHRONIZATION_RESPONSE_PROTO;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public CommitBlockSynchronizationResponseProto commitBlockSynchronization(\n      RpcController controller, CommitBlockSynchronizationRequestProto request)\n      throws ServiceException {\n    List\u003cDatanodeIDProto\u003e dnprotos \u003d request.getNewTaragetsList();\n    DatanodeID[] dns \u003d new DatanodeID[dnprotos.size()];\n    for (int i \u003d 0; i \u003c dnprotos.size(); i++) {\n      dns[i] \u003d PBHelperClient.convert(dnprotos.get(i));\n    }\n    final List\u003cString\u003e sidprotos \u003d request.getNewTargetStoragesList();\n    final String[] storageIDs \u003d sidprotos.toArray(new String[sidprotos.size()]);\n    try {\n      impl.commitBlockSynchronization(PBHelperClient.convert(request.getBlock()),\n          request.getNewGenStamp(), request.getNewLength(),\n          request.getCloseFile(), request.getDeleteBlock(), dns, storageIDs);\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    return VOID_COMMIT_BLOCK_SYNCHRONIZATION_RESPONSE_PROTO;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "e2c9b288b223b9fd82dc12018936e13128413492": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8925. Move BlockReaderLocal to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "28/08/15 2:38 PM",
      "commitName": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "12/06/15 11:17 AM",
      "commitNameOld": "12b5b06c063d93e6c683c9b6fac9a96912f59e59",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 77.14,
      "commitsBetweenForRepo": 458,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n   public CommitBlockSynchronizationResponseProto commitBlockSynchronization(\n       RpcController controller, CommitBlockSynchronizationRequestProto request)\n       throws ServiceException {\n     List\u003cDatanodeIDProto\u003e dnprotos \u003d request.getNewTaragetsList();\n     DatanodeID[] dns \u003d new DatanodeID[dnprotos.size()];\n     for (int i \u003d 0; i \u003c dnprotos.size(); i++) {\n       dns[i] \u003d PBHelper.convert(dnprotos.get(i));\n     }\n     final List\u003cString\u003e sidprotos \u003d request.getNewTargetStoragesList();\n     final String[] storageIDs \u003d sidprotos.toArray(new String[sidprotos.size()]);\n     try {\n-      impl.commitBlockSynchronization(PBHelper.convert(request.getBlock()),\n+      impl.commitBlockSynchronization(PBHelperClient.convert(request.getBlock()),\n           request.getNewGenStamp(), request.getNewLength(),\n           request.getCloseFile(), request.getDeleteBlock(), dns, storageIDs);\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     return VOID_COMMIT_BLOCK_SYNCHRONIZATION_RESPONSE_PROTO;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public CommitBlockSynchronizationResponseProto commitBlockSynchronization(\n      RpcController controller, CommitBlockSynchronizationRequestProto request)\n      throws ServiceException {\n    List\u003cDatanodeIDProto\u003e dnprotos \u003d request.getNewTaragetsList();\n    DatanodeID[] dns \u003d new DatanodeID[dnprotos.size()];\n    for (int i \u003d 0; i \u003c dnprotos.size(); i++) {\n      dns[i] \u003d PBHelper.convert(dnprotos.get(i));\n    }\n    final List\u003cString\u003e sidprotos \u003d request.getNewTargetStoragesList();\n    final String[] storageIDs \u003d sidprotos.toArray(new String[sidprotos.size()]);\n    try {\n      impl.commitBlockSynchronization(PBHelperClient.convert(request.getBlock()),\n          request.getNewGenStamp(), request.getNewLength(),\n          request.getCloseFile(), request.getDeleteBlock(), dns, storageIDs);\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    return VOID_COMMIT_BLOCK_SYNCHRONIZATION_RESPONSE_PROTO;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "8f70a25b1c5df498c441a9b3475a8ada5a92111f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4393. Make empty request and responses in protocol translators can be static final members. Contributed by Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1434844 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/01/13 10:21 AM",
      "commitName": "8f70a25b1c5df498c441a9b3475a8ada5a92111f",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "22/08/12 9:59 AM",
      "commitNameOld": "380870d54453c1113d46d0f070f4e19b6cea7b8c",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 148.06,
      "commitsBetweenForRepo": 786,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n   public CommitBlockSynchronizationResponseProto commitBlockSynchronization(\n       RpcController controller, CommitBlockSynchronizationRequestProto request)\n       throws ServiceException {\n     List\u003cDatanodeIDProto\u003e dnprotos \u003d request.getNewTaragetsList();\n     DatanodeID[] dns \u003d new DatanodeID[dnprotos.size()];\n     for (int i \u003d 0; i \u003c dnprotos.size(); i++) {\n       dns[i] \u003d PBHelper.convert(dnprotos.get(i));\n     }\n     final List\u003cString\u003e sidprotos \u003d request.getNewTargetStoragesList();\n     final String[] storageIDs \u003d sidprotos.toArray(new String[sidprotos.size()]);\n     try {\n       impl.commitBlockSynchronization(PBHelper.convert(request.getBlock()),\n           request.getNewGenStamp(), request.getNewLength(),\n           request.getCloseFile(), request.getDeleteBlock(), dns, storageIDs);\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n-    return COMMIT_BLOCK_SYNCHRONIZATION_RESPONSE_PROTO;\n+    return VOID_COMMIT_BLOCK_SYNCHRONIZATION_RESPONSE_PROTO;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public CommitBlockSynchronizationResponseProto commitBlockSynchronization(\n      RpcController controller, CommitBlockSynchronizationRequestProto request)\n      throws ServiceException {\n    List\u003cDatanodeIDProto\u003e dnprotos \u003d request.getNewTaragetsList();\n    DatanodeID[] dns \u003d new DatanodeID[dnprotos.size()];\n    for (int i \u003d 0; i \u003c dnprotos.size(); i++) {\n      dns[i] \u003d PBHelper.convert(dnprotos.get(i));\n    }\n    final List\u003cString\u003e sidprotos \u003d request.getNewTargetStoragesList();\n    final String[] storageIDs \u003d sidprotos.toArray(new String[sidprotos.size()]);\n    try {\n      impl.commitBlockSynchronization(PBHelper.convert(request.getBlock()),\n          request.getNewGenStamp(), request.getNewLength(),\n          request.getCloseFile(), request.getDeleteBlock(), dns, storageIDs);\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    return VOID_COMMIT_BLOCK_SYNCHRONIZATION_RESPONSE_PROTO;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "6326605acb5a5bf48d994278c9d3a39733679e81": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3105.  Add DatanodeStorage information to block recovery.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1302683 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/03/12 3:09 PM",
      "commitName": "6326605acb5a5bf48d994278c9d3a39733679e81",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "29/02/12 3:47 PM",
      "commitNameOld": "1ba357553aafe30ecf33b9c7863c44c0b8021e78",
      "commitAuthorOld": "",
      "daysBetweenCommits": 18.93,
      "commitsBetweenForRepo": 108,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,19 @@\n   public CommitBlockSynchronizationResponseProto commitBlockSynchronization(\n       RpcController controller, CommitBlockSynchronizationRequestProto request)\n       throws ServiceException {\n     List\u003cDatanodeIDProto\u003e dnprotos \u003d request.getNewTaragetsList();\n     DatanodeID[] dns \u003d new DatanodeID[dnprotos.size()];\n     for (int i \u003d 0; i \u003c dnprotos.size(); i++) {\n       dns[i] \u003d PBHelper.convert(dnprotos.get(i));\n     }\n+    final List\u003cString\u003e sidprotos \u003d request.getNewTargetStoragesList();\n+    final String[] storageIDs \u003d sidprotos.toArray(new String[sidprotos.size()]);\n     try {\n       impl.commitBlockSynchronization(PBHelper.convert(request.getBlock()),\n           request.getNewGenStamp(), request.getNewLength(),\n-          request.getCloseFile(), request.getDeleteBlock(), dns);\n+          request.getCloseFile(), request.getDeleteBlock(), dns, storageIDs);\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     return COMMIT_BLOCK_SYNCHRONIZATION_RESPONSE_PROTO;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public CommitBlockSynchronizationResponseProto commitBlockSynchronization(\n      RpcController controller, CommitBlockSynchronizationRequestProto request)\n      throws ServiceException {\n    List\u003cDatanodeIDProto\u003e dnprotos \u003d request.getNewTaragetsList();\n    DatanodeID[] dns \u003d new DatanodeID[dnprotos.size()];\n    for (int i \u003d 0; i \u003c dnprotos.size(); i++) {\n      dns[i] \u003d PBHelper.convert(dnprotos.get(i));\n    }\n    final List\u003cString\u003e sidprotos \u003d request.getNewTargetStoragesList();\n    final String[] storageIDs \u003d sidprotos.toArray(new String[sidprotos.size()]);\n    try {\n      impl.commitBlockSynchronization(PBHelper.convert(request.getBlock()),\n          request.getNewGenStamp(), request.getNewLength(),\n          request.getCloseFile(), request.getDeleteBlock(), dns, storageIDs);\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    return COMMIT_BLOCK_SYNCHRONIZATION_RESPONSE_PROTO;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "38a19bc293dec6221ae96e304fc6ab660d94e706": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2642. Protobuf translators for DatanodeProtocol.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1212606 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/12/11 12:02 PM",
      "commitName": "38a19bc293dec6221ae96e304fc6ab660d94e706",
      "commitAuthor": "Jitendra Nath Pandey",
      "diff": "@@ -0,0 +1,17 @@\n+  public CommitBlockSynchronizationResponseProto commitBlockSynchronization(\n+      RpcController controller, CommitBlockSynchronizationRequestProto request)\n+      throws ServiceException {\n+    List\u003cDatanodeIDProto\u003e dnprotos \u003d request.getNewTaragetsList();\n+    DatanodeID[] dns \u003d new DatanodeID[dnprotos.size()];\n+    for (int i \u003d 0; i \u003c dnprotos.size(); i++) {\n+      dns[i] \u003d PBHelper.convert(dnprotos.get(i));\n+    }\n+    try {\n+      impl.commitBlockSynchronization(PBHelper.convert(request.getBlock()),\n+          request.getNewGenStamp(), request.getNewLength(),\n+          request.getCloseFile(), request.getDeleteBlock(), dns);\n+    } catch (IOException e) {\n+      throw new ServiceException(e);\n+    }\n+    return COMMIT_BLOCK_SYNCHRONIZATION_RESPONSE_PROTO;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public CommitBlockSynchronizationResponseProto commitBlockSynchronization(\n      RpcController controller, CommitBlockSynchronizationRequestProto request)\n      throws ServiceException {\n    List\u003cDatanodeIDProto\u003e dnprotos \u003d request.getNewTaragetsList();\n    DatanodeID[] dns \u003d new DatanodeID[dnprotos.size()];\n    for (int i \u003d 0; i \u003c dnprotos.size(); i++) {\n      dns[i] \u003d PBHelper.convert(dnprotos.get(i));\n    }\n    try {\n      impl.commitBlockSynchronization(PBHelper.convert(request.getBlock()),\n          request.getNewGenStamp(), request.getNewLength(),\n          request.getCloseFile(), request.getDeleteBlock(), dns);\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    return COMMIT_BLOCK_SYNCHRONIZATION_RESPONSE_PROTO;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java"
    }
  }
}