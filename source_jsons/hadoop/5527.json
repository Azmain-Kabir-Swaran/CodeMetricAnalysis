{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "INodeFile.java",
  "functionName": "assertAllBlocksComplete",
  "functionId": "assertAllBlocksComplete___numCommittedAllowed-int__minReplication-short",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
  "functionStartLine": 350,
  "functionEndLine": 361,
  "numCommitsSeen": 564,
  "timeTaken": 7492,
  "changeHistory": [
    "e5f0622a6f40706d360d45200c8f259c79046438",
    "0faee62a0c8c1b8fd83227babfd00fbc2b26bddf",
    "bd909ed9f2d853f614f04a50e2230a7932732776",
    "7e091de1366f4b57b5433bc19d738199dc05313d",
    "9f2f583f401189c3f4a2687795a9e3e0b288322b",
    "ce68f410b05a58ad05965f32ad7f5b246b363a75"
  ],
  "changeHistoryShort": {
    "e5f0622a6f40706d360d45200c8f259c79046438": "Ybodychange",
    "0faee62a0c8c1b8fd83227babfd00fbc2b26bddf": "Ybodychange",
    "bd909ed9f2d853f614f04a50e2230a7932732776": "Ymultichange(Yparameterchange,Ybodychange)",
    "7e091de1366f4b57b5433bc19d738199dc05313d": "Ymultichange(Yparameterchange,Ybodychange)",
    "9f2f583f401189c3f4a2687795a9e3e0b288322b": "Ymultichange(Yparameterchange,Ybodychange)",
    "ce68f410b05a58ad05965f32ad7f5b246b363a75": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "e5f0622a6f40706d360d45200c8f259c79046438": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11592. Closing a file has a wasteful preconditions in NameNode. Contributed by Eric Badger\n",
      "commitDate": "30/03/17 3:44 PM",
      "commitName": "e5f0622a6f40706d360d45200c8f259c79046438",
      "commitAuthor": "Mingliang Liu",
      "commitDateOld": "08/03/17 4:41 PM",
      "commitNameOld": "33a38a534110de454662256545a7f4c075d328c8",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 21.92,
      "commitsBetweenForRepo": 131,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,12 @@\n   private void assertAllBlocksComplete(int numCommittedAllowed,\n       short minReplication) {\n     for (int i \u003d 0; i \u003c blocks.length; i++) {\n       final String err \u003d checkBlockComplete(blocks, i, numCommittedAllowed,\n           minReplication);\n-      Preconditions.checkState(err \u003d\u003d null,\n-          \"Unexpected block state: %s, file\u003d%s (%s), blocks\u003d%s (i\u003d%s)\",\n-          err, this, getClass().getSimpleName(), Arrays.asList(blocks), i);\n+      if(err !\u003d null) {\n+        throw new IllegalStateException(String.format(\"Unexpected block state: \" +\n+            \"%s, file\u003d%s (%s), blocks\u003d%s (i\u003d%s)\", err, this,\n+            getClass().getSimpleName(), Arrays.asList(blocks), i));\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void assertAllBlocksComplete(int numCommittedAllowed,\n      short minReplication) {\n    for (int i \u003d 0; i \u003c blocks.length; i++) {\n      final String err \u003d checkBlockComplete(blocks, i, numCommittedAllowed,\n          minReplication);\n      if(err !\u003d null) {\n        throw new IllegalStateException(String.format(\"Unexpected block state: \" +\n            \"%s, file\u003d%s (%s), blocks\u003d%s (i\u003d%s)\", err, this,\n            getClass().getSimpleName(), Arrays.asList(blocks), i));\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "0faee62a0c8c1b8fd83227babfd00fbc2b26bddf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10764. Fix INodeFile#getBlocks to not return null. Contributed by Arpit Agarwal.\n",
      "commitDate": "19/08/16 10:13 PM",
      "commitName": "0faee62a0c8c1b8fd83227babfd00fbc2b26bddf",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "22/06/16 11:17 AM",
      "commitNameOld": "17eae9ebb30a3b106c4f6ae0c5374a3ab83abd8a",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 58.46,
      "commitsBetweenForRepo": 541,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,10 @@\n   private void assertAllBlocksComplete(int numCommittedAllowed,\n       short minReplication) {\n-    if (blocks \u003d\u003d null) {\n-      return;\n-    }\n     for (int i \u003d 0; i \u003c blocks.length; i++) {\n       final String err \u003d checkBlockComplete(blocks, i, numCommittedAllowed,\n           minReplication);\n       Preconditions.checkState(err \u003d\u003d null,\n           \"Unexpected block state: %s, file\u003d%s (%s), blocks\u003d%s (i\u003d%s)\",\n           err, this, getClass().getSimpleName(), Arrays.asList(blocks), i);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void assertAllBlocksComplete(int numCommittedAllowed,\n      short minReplication) {\n    for (int i \u003d 0; i \u003c blocks.length; i++) {\n      final String err \u003d checkBlockComplete(blocks, i, numCommittedAllowed,\n          minReplication);\n      Preconditions.checkState(err \u003d\u003d null,\n          \"Unexpected block state: %s, file\u003d%s (%s), blocks\u003d%s (i\u003d%s)\",\n          err, this, getClass().getSimpleName(), Arrays.asList(blocks), i);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "bd909ed9f2d853f614f04a50e2230a7932732776": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-8999. Allow a file to be closed with COMMITTED but not yet COMPLETE blocks.\n",
      "commitDate": "25/01/16 6:32 PM",
      "commitName": "bd909ed9f2d853f614f04a50e2230a7932732776",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-8999. Allow a file to be closed with COMMITTED but not yet COMPLETE blocks.\n",
          "commitDate": "25/01/16 6:32 PM",
          "commitName": "bd909ed9f2d853f614f04a50e2230a7932732776",
          "commitAuthor": "Tsz-Wo Nicholas Sze",
          "commitDateOld": "05/11/15 1:30 AM",
          "commitNameOld": "ea5bb483269b51a349c358b71f84904c76693a66",
          "commitAuthorOld": "Xiaoyu Yao",
          "daysBetweenCommits": 81.71,
          "commitsBetweenForRepo": 498,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,10 +1,13 @@\n-  private void assertAllBlocksComplete() {\n+  private void assertAllBlocksComplete(int numCommittedAllowed,\n+      short minReplication) {\n     if (blocks \u003d\u003d null) {\n       return;\n     }\n     for (int i \u003d 0; i \u003c blocks.length; i++) {\n-      Preconditions.checkState(blocks[i].isComplete(), \"Failed to finalize\"\n-          + \" %s %s since blocks[%s] is non-complete, where blocks\u003d%s.\",\n-          getClass().getSimpleName(), this, i, Arrays.asList(blocks));\n+      final String err \u003d checkBlockComplete(blocks, i, numCommittedAllowed,\n+          minReplication);\n+      Preconditions.checkState(err \u003d\u003d null,\n+          \"Unexpected block state: %s, file\u003d%s (%s), blocks\u003d%s (i\u003d%s)\",\n+          err, this, getClass().getSimpleName(), Arrays.asList(blocks), i);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void assertAllBlocksComplete(int numCommittedAllowed,\n      short minReplication) {\n    if (blocks \u003d\u003d null) {\n      return;\n    }\n    for (int i \u003d 0; i \u003c blocks.length; i++) {\n      final String err \u003d checkBlockComplete(blocks, i, numCommittedAllowed,\n          minReplication);\n      Preconditions.checkState(err \u003d\u003d null,\n          \"Unexpected block state: %s, file\u003d%s (%s), blocks\u003d%s (i\u003d%s)\",\n          err, this, getClass().getSimpleName(), Arrays.asList(blocks), i);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[numCommittedAllowed-int, minReplication-short]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8999. Allow a file to be closed with COMMITTED but not yet COMPLETE blocks.\n",
          "commitDate": "25/01/16 6:32 PM",
          "commitName": "bd909ed9f2d853f614f04a50e2230a7932732776",
          "commitAuthor": "Tsz-Wo Nicholas Sze",
          "commitDateOld": "05/11/15 1:30 AM",
          "commitNameOld": "ea5bb483269b51a349c358b71f84904c76693a66",
          "commitAuthorOld": "Xiaoyu Yao",
          "daysBetweenCommits": 81.71,
          "commitsBetweenForRepo": 498,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,10 +1,13 @@\n-  private void assertAllBlocksComplete() {\n+  private void assertAllBlocksComplete(int numCommittedAllowed,\n+      short minReplication) {\n     if (blocks \u003d\u003d null) {\n       return;\n     }\n     for (int i \u003d 0; i \u003c blocks.length; i++) {\n-      Preconditions.checkState(blocks[i].isComplete(), \"Failed to finalize\"\n-          + \" %s %s since blocks[%s] is non-complete, where blocks\u003d%s.\",\n-          getClass().getSimpleName(), this, i, Arrays.asList(blocks));\n+      final String err \u003d checkBlockComplete(blocks, i, numCommittedAllowed,\n+          minReplication);\n+      Preconditions.checkState(err \u003d\u003d null,\n+          \"Unexpected block state: %s, file\u003d%s (%s), blocks\u003d%s (i\u003d%s)\",\n+          err, this, getClass().getSimpleName(), Arrays.asList(blocks), i);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void assertAllBlocksComplete(int numCommittedAllowed,\n      short minReplication) {\n    if (blocks \u003d\u003d null) {\n      return;\n    }\n    for (int i \u003d 0; i \u003c blocks.length; i++) {\n      final String err \u003d checkBlockComplete(blocks, i, numCommittedAllowed,\n          minReplication);\n      Preconditions.checkState(err \u003d\u003d null,\n          \"Unexpected block state: %s, file\u003d%s (%s), blocks\u003d%s (i\u003d%s)\",\n          err, this, getClass().getSimpleName(), Arrays.asList(blocks), i);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {}
        }
      ]
    },
    "7e091de1366f4b57b5433bc19d738199dc05313d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-8058. Erasure coding: use BlockInfo[] for both striped and contiguous blocks in INodeFile. Contributed by Zhe Zhang and Yi Liu.\n",
      "commitDate": "15/07/15 9:49 AM",
      "commitName": "7e091de1366f4b57b5433bc19d738199dc05313d",
      "commitAuthor": "Zhe Zhang",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-8058. Erasure coding: use BlockInfo[] for both striped and contiguous blocks in INodeFile. Contributed by Zhe Zhang and Yi Liu.\n",
          "commitDate": "15/07/15 9:49 AM",
          "commitName": "7e091de1366f4b57b5433bc19d738199dc05313d",
          "commitAuthor": "Zhe Zhang",
          "commitDateOld": "06/07/15 4:14 AM",
          "commitNameOld": "ee01a09500224136464f2c3e0a5d9ba53242d93f",
          "commitAuthorOld": "yliu",
          "daysBetweenCommits": 9.23,
          "commitsBetweenForRepo": 11,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,10 +1,10 @@\n-  private void assertAllBlocksComplete(BlockInfo[] blks) {\n-    if (blks \u003d\u003d null) {\n+  private void assertAllBlocksComplete() {\n+    if (blocks \u003d\u003d null) {\n       return;\n     }\n-    for (int i \u003d 0; i \u003c blks.length; i++) {\n-      Preconditions.checkState(blks[i].isComplete(), \"Failed to finalize\"\n+    for (int i \u003d 0; i \u003c blocks.length; i++) {\n+      Preconditions.checkState(blocks[i].isComplete(), \"Failed to finalize\"\n           + \" %s %s since blocks[%s] is non-complete, where blocks\u003d%s.\",\n-          getClass().getSimpleName(), this, i, Arrays.asList(blks));\n+          getClass().getSimpleName(), this, i, Arrays.asList(blocks));\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void assertAllBlocksComplete() {\n    if (blocks \u003d\u003d null) {\n      return;\n    }\n    for (int i \u003d 0; i \u003c blocks.length; i++) {\n      Preconditions.checkState(blocks[i].isComplete(), \"Failed to finalize\"\n          + \" %s %s since blocks[%s] is non-complete, where blocks\u003d%s.\",\n          getClass().getSimpleName(), this, i, Arrays.asList(blocks));\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldValue": "[blks-BlockInfo[]]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8058. Erasure coding: use BlockInfo[] for both striped and contiguous blocks in INodeFile. Contributed by Zhe Zhang and Yi Liu.\n",
          "commitDate": "15/07/15 9:49 AM",
          "commitName": "7e091de1366f4b57b5433bc19d738199dc05313d",
          "commitAuthor": "Zhe Zhang",
          "commitDateOld": "06/07/15 4:14 AM",
          "commitNameOld": "ee01a09500224136464f2c3e0a5d9ba53242d93f",
          "commitAuthorOld": "yliu",
          "daysBetweenCommits": 9.23,
          "commitsBetweenForRepo": 11,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,10 +1,10 @@\n-  private void assertAllBlocksComplete(BlockInfo[] blks) {\n-    if (blks \u003d\u003d null) {\n+  private void assertAllBlocksComplete() {\n+    if (blocks \u003d\u003d null) {\n       return;\n     }\n-    for (int i \u003d 0; i \u003c blks.length; i++) {\n-      Preconditions.checkState(blks[i].isComplete(), \"Failed to finalize\"\n+    for (int i \u003d 0; i \u003c blocks.length; i++) {\n+      Preconditions.checkState(blocks[i].isComplete(), \"Failed to finalize\"\n           + \" %s %s since blocks[%s] is non-complete, where blocks\u003d%s.\",\n-          getClass().getSimpleName(), this, i, Arrays.asList(blks));\n+          getClass().getSimpleName(), this, i, Arrays.asList(blocks));\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void assertAllBlocksComplete() {\n    if (blocks \u003d\u003d null) {\n      return;\n    }\n    for (int i \u003d 0; i \u003c blocks.length; i++) {\n      Preconditions.checkState(blocks[i].isComplete(), \"Failed to finalize\"\n          + \" %s %s since blocks[%s] is non-complete, where blocks\u003d%s.\",\n          getClass().getSimpleName(), this, i, Arrays.asList(blocks));\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {}
        }
      ]
    },
    "9f2f583f401189c3f4a2687795a9e3e0b288322b": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7749. Erasure Coding: Add striped block support in INodeFile. Contributed by Jing Zhao.\n",
      "commitDate": "26/05/15 11:07 AM",
      "commitName": "9f2f583f401189c3f4a2687795a9e3e0b288322b",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7749. Erasure Coding: Add striped block support in INodeFile. Contributed by Jing Zhao.\n",
          "commitDate": "26/05/15 11:07 AM",
          "commitName": "9f2f583f401189c3f4a2687795a9e3e0b288322b",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "26/05/15 11:03 AM",
          "commitNameOld": "bc2833b1c91e107d090619d755c584f6eae82327",
          "commitAuthorOld": "Zhe Zhang",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 8,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,10 +1,10 @@\n-  private void assertAllBlocksComplete() {\n-    if (blocks \u003d\u003d null) {\n+  private void assertAllBlocksComplete(BlockInfo[] blks) {\n+    if (blks \u003d\u003d null) {\n       return;\n     }\n-    for (int i \u003d 0; i \u003c blocks.length; i++) {\n-      Preconditions.checkState(blocks[i].isComplete(), \"Failed to finalize\"\n+    for (int i \u003d 0; i \u003c blks.length; i++) {\n+      Preconditions.checkState(blks[i].isComplete(), \"Failed to finalize\"\n           + \" %s %s since blocks[%s] is non-complete, where blocks\u003d%s.\",\n-          getClass().getSimpleName(), this, i, Arrays.asList(blocks));\n+          getClass().getSimpleName(), this, i, Arrays.asList(blks));\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void assertAllBlocksComplete(BlockInfo[] blks) {\n    if (blks \u003d\u003d null) {\n      return;\n    }\n    for (int i \u003d 0; i \u003c blks.length; i++) {\n      Preconditions.checkState(blks[i].isComplete(), \"Failed to finalize\"\n          + \" %s %s since blocks[%s] is non-complete, where blocks\u003d%s.\",\n          getClass().getSimpleName(), this, i, Arrays.asList(blks));\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[blks-BlockInfo[]]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7749. Erasure Coding: Add striped block support in INodeFile. Contributed by Jing Zhao.\n",
          "commitDate": "26/05/15 11:07 AM",
          "commitName": "9f2f583f401189c3f4a2687795a9e3e0b288322b",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "26/05/15 11:03 AM",
          "commitNameOld": "bc2833b1c91e107d090619d755c584f6eae82327",
          "commitAuthorOld": "Zhe Zhang",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 8,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,10 +1,10 @@\n-  private void assertAllBlocksComplete() {\n-    if (blocks \u003d\u003d null) {\n+  private void assertAllBlocksComplete(BlockInfo[] blks) {\n+    if (blks \u003d\u003d null) {\n       return;\n     }\n-    for (int i \u003d 0; i \u003c blocks.length; i++) {\n-      Preconditions.checkState(blocks[i].isComplete(), \"Failed to finalize\"\n+    for (int i \u003d 0; i \u003c blks.length; i++) {\n+      Preconditions.checkState(blks[i].isComplete(), \"Failed to finalize\"\n           + \" %s %s since blocks[%s] is non-complete, where blocks\u003d%s.\",\n-          getClass().getSimpleName(), this, i, Arrays.asList(blocks));\n+          getClass().getSimpleName(), this, i, Arrays.asList(blks));\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void assertAllBlocksComplete(BlockInfo[] blks) {\n    if (blks \u003d\u003d null) {\n      return;\n    }\n    for (int i \u003d 0; i \u003c blks.length; i++) {\n      Preconditions.checkState(blks[i].isComplete(), \"Failed to finalize\"\n          + \" %s %s since blocks[%s] is non-complete, where blocks\u003d%s.\",\n          getClass().getSimpleName(), this, i, Arrays.asList(blks));\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {}
        }
      ]
    },
    "ce68f410b05a58ad05965f32ad7f5b246b363a75": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-5285. Flatten INodeFile hierarchy: Replace INodeFileUnderConstruction and INodeFileUnderConstructionWithSnapshot with FileUnderContructionFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544389 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/11/13 5:39 PM",
      "commitName": "ce68f410b05a58ad05965f32ad7f5b246b363a75",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-5285. Flatten INodeFile hierarchy: Replace INodeFileUnderConstruction and INodeFileUnderConstructionWithSnapshot with FileUnderContructionFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544389 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/11/13 5:39 PM",
          "commitName": "ce68f410b05a58ad05965f32ad7f5b246b363a75",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/11/13 3:16 PM",
          "commitNameOld": "33a8234040959ecd0d0202162e1b18c990effabe",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 0.1,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,10 @@\n-  protected void assertAllBlocksComplete() {\n-    final BlockInfo[] blocks \u003d getBlocks();\n+  private void assertAllBlocksComplete() {\n+    if (blocks \u003d\u003d null) {\n+      return;\n+    }\n     for (int i \u003d 0; i \u003c blocks.length; i++) {\n       Preconditions.checkState(blocks[i].isComplete(), \"Failed to finalize\"\n           + \" %s %s since blocks[%s] is non-complete, where blocks\u003d%s.\",\n-          getClass().getSimpleName(), this, i, Arrays.asList(getBlocks()));\n+          getClass().getSimpleName(), this, i, Arrays.asList(blocks));\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void assertAllBlocksComplete() {\n    if (blocks \u003d\u003d null) {\n      return;\n    }\n    for (int i \u003d 0; i \u003c blocks.length; i++) {\n      Preconditions.checkState(blocks[i].isComplete(), \"Failed to finalize\"\n          + \" %s %s since blocks[%s] is non-complete, where blocks\u003d%s.\",\n          getClass().getSimpleName(), this, i, Arrays.asList(blocks));\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
            "oldMethodName": "assertAllBlocksComplete",
            "newMethodName": "assertAllBlocksComplete"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-5285. Flatten INodeFile hierarchy: Replace INodeFileUnderConstruction and INodeFileUnderConstructionWithSnapshot with FileUnderContructionFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544389 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/11/13 5:39 PM",
          "commitName": "ce68f410b05a58ad05965f32ad7f5b246b363a75",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/11/13 3:16 PM",
          "commitNameOld": "33a8234040959ecd0d0202162e1b18c990effabe",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 0.1,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,10 @@\n-  protected void assertAllBlocksComplete() {\n-    final BlockInfo[] blocks \u003d getBlocks();\n+  private void assertAllBlocksComplete() {\n+    if (blocks \u003d\u003d null) {\n+      return;\n+    }\n     for (int i \u003d 0; i \u003c blocks.length; i++) {\n       Preconditions.checkState(blocks[i].isComplete(), \"Failed to finalize\"\n           + \" %s %s since blocks[%s] is non-complete, where blocks\u003d%s.\",\n-          getClass().getSimpleName(), this, i, Arrays.asList(getBlocks()));\n+          getClass().getSimpleName(), this, i, Arrays.asList(blocks));\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void assertAllBlocksComplete() {\n    if (blocks \u003d\u003d null) {\n      return;\n    }\n    for (int i \u003d 0; i \u003c blocks.length; i++) {\n      Preconditions.checkState(blocks[i].isComplete(), \"Failed to finalize\"\n          + \" %s %s since blocks[%s] is non-complete, where blocks\u003d%s.\",\n          getClass().getSimpleName(), this, i, Arrays.asList(blocks));\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldValue": "[protected]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5285. Flatten INodeFile hierarchy: Replace INodeFileUnderConstruction and INodeFileUnderConstructionWithSnapshot with FileUnderContructionFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544389 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/11/13 5:39 PM",
          "commitName": "ce68f410b05a58ad05965f32ad7f5b246b363a75",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/11/13 3:16 PM",
          "commitNameOld": "33a8234040959ecd0d0202162e1b18c990effabe",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 0.1,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,10 @@\n-  protected void assertAllBlocksComplete() {\n-    final BlockInfo[] blocks \u003d getBlocks();\n+  private void assertAllBlocksComplete() {\n+    if (blocks \u003d\u003d null) {\n+      return;\n+    }\n     for (int i \u003d 0; i \u003c blocks.length; i++) {\n       Preconditions.checkState(blocks[i].isComplete(), \"Failed to finalize\"\n           + \" %s %s since blocks[%s] is non-complete, where blocks\u003d%s.\",\n-          getClass().getSimpleName(), this, i, Arrays.asList(getBlocks()));\n+          getClass().getSimpleName(), this, i, Arrays.asList(blocks));\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void assertAllBlocksComplete() {\n    if (blocks \u003d\u003d null) {\n      return;\n    }\n    for (int i \u003d 0; i \u003c blocks.length; i++) {\n      Preconditions.checkState(blocks[i].isComplete(), \"Failed to finalize\"\n          + \" %s %s since blocks[%s] is non-complete, where blocks\u003d%s.\",\n          getClass().getSimpleName(), this, i, Arrays.asList(blocks));\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}