{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSUtil.java",
  "functionName": "getPathComponents",
  "functionId": "getPathComponents___path-String",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java",
  "functionStartLine": 348,
  "functionEndLine": 353,
  "numCommitsSeen": 154,
  "timeTaken": 2006,
  "changeHistory": [
    "b1c7654ee40b372ed777525a42981c7cf55b5c72",
    "bd3dcf46e263b6e6aa3fca6a5d9936cc49e3280f"
  ],
  "changeHistoryShort": {
    "b1c7654ee40b372ed777525a42981c7cf55b5c72": "Ybodychange",
    "bd3dcf46e263b6e6aa3fca6a5d9936cc49e3280f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b1c7654ee40b372ed777525a42981c7cf55b5c72": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12594. snapshotDiff fails if the report exceeds the RPC response limit. Contributed by Shashikant Banerjee\n",
      "commitDate": "30/11/17 12:18 PM",
      "commitName": "b1c7654ee40b372ed777525a42981c7cf55b5c72",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "06/10/17 6:50 PM",
      "commitNameOld": "d8c81073320320a019fb3868be4f06f46aebea43",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 54.77,
      "commitsBetweenForRepo": 427,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,6 @@\n   public static byte[][] getPathComponents(String path) {\n     // avoid intermediate split to String[]\n     final byte[] bytes \u003d string2Bytes(path);\n-    return bytes2byteArray(bytes, bytes.length, (byte)Path.SEPARATOR_CHAR);\n+    return DFSUtilClient\n+        .bytes2byteArray(bytes, bytes.length, (byte) Path.SEPARATOR_CHAR);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static byte[][] getPathComponents(String path) {\n    // avoid intermediate split to String[]\n    final byte[] bytes \u003d string2Bytes(path);\n    return DFSUtilClient\n        .bytes2byteArray(bytes, bytes.length, (byte) Path.SEPARATOR_CHAR);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java",
      "extendedDetails": {}
    },
    "bd3dcf46e263b6e6aa3fca6a5d9936cc49e3280f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-10653. Optimize conversion from path string to components. Contributed by Daryn Sharp.\n",
      "commitDate": "21/07/16 11:14 AM",
      "commitName": "bd3dcf46e263b6e6aa3fca6a5d9936cc49e3280f",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,5 @@\n+  public static byte[][] getPathComponents(String path) {\n+    // avoid intermediate split to String[]\n+    final byte[] bytes \u003d string2Bytes(path);\n+    return bytes2byteArray(bytes, bytes.length, (byte)Path.SEPARATOR_CHAR);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static byte[][] getPathComponents(String path) {\n    // avoid intermediate split to String[]\n    final byte[] bytes \u003d string2Bytes(path);\n    return bytes2byteArray(bytes, bytes.length, (byte)Path.SEPARATOR_CHAR);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java"
    }
  }
}