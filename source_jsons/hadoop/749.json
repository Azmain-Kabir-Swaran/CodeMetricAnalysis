{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataStreamer.java",
  "functionName": "backOffIfNecessary",
  "functionId": "backOffIfNecessary",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
  "functionStartLine": 1880,
  "functionEndLine": 1903,
  "numCommitsSeen": 53,
  "timeTaken": 2650,
  "changeHistory": [
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "7947e5b53b9ac9524b535b0384c1c355b74723ff",
    "6ccf4fbf8a8374c289370f67b26ac05abad30ebc"
  ],
  "changeHistoryShort": {
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "7947e5b53b9ac9524b535b0384c1c355b74723ff": "Ybodychange",
    "6ccf4fbf8a8374c289370f67b26ac05abad30ebc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void backOffIfNecessary() throws InterruptedException {\n    int t \u003d 0;\n    synchronized (congestedNodes) {\n      if (!congestedNodes.isEmpty()) {\n        StringBuilder sb \u003d new StringBuilder(\"DataNode\");\n        for (DatanodeInfo i : congestedNodes) {\n          sb.append(\u0027 \u0027).append(i);\n        }\n        int range \u003d Math.abs(lastCongestionBackoffTime * 3 -\n                                CONGESTION_BACKOFF_MEAN_TIME_IN_MS);\n        int base \u003d Math.min(lastCongestionBackoffTime * 3,\n                            CONGESTION_BACKOFF_MEAN_TIME_IN_MS);\n        t \u003d Math.min(CONGESTION_BACK_OFF_MAX_TIME_IN_MS,\n                     (int)(base + Math.random() * range));\n        lastCongestionBackoffTime \u003d t;\n        sb.append(\" are congested. Backing off for \").append(t).append(\" ms\");\n        LOG.info(sb.toString());\n        congestedNodes.clear();\n      }\n    }\n    if (t !\u003d 0) {\n      Thread.sleep(t);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java"
      }
    },
    "7947e5b53b9ac9524b535b0384c1c355b74723ff": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8283. DataStreamer cleanup and some minor improvement. Contributed by Tsz Wo Nicholas Sze.\n",
      "commitDate": "29/04/15 10:41 AM",
      "commitName": "7947e5b53b9ac9524b535b0384c1c355b74723ff",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "24/04/15 12:21 AM",
      "commitNameOld": "c8d72907ff5a4cb9ce1effca8ad9b69689d11d1d",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 5.43,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   private void backOffIfNecessary() throws InterruptedException {\n     int t \u003d 0;\n     synchronized (congestedNodes) {\n       if (!congestedNodes.isEmpty()) {\n         StringBuilder sb \u003d new StringBuilder(\"DataNode\");\n         for (DatanodeInfo i : congestedNodes) {\n           sb.append(\u0027 \u0027).append(i);\n         }\n         int range \u003d Math.abs(lastCongestionBackoffTime * 3 -\n                                 CONGESTION_BACKOFF_MEAN_TIME_IN_MS);\n         int base \u003d Math.min(lastCongestionBackoffTime * 3,\n                             CONGESTION_BACKOFF_MEAN_TIME_IN_MS);\n         t \u003d Math.min(CONGESTION_BACK_OFF_MAX_TIME_IN_MS,\n                      (int)(base + Math.random() * range));\n         lastCongestionBackoffTime \u003d t;\n         sb.append(\" are congested. Backing off for \").append(t).append(\" ms\");\n-        DFSClient.LOG.info(sb.toString());\n+        LOG.info(sb.toString());\n         congestedNodes.clear();\n       }\n     }\n     if (t !\u003d 0) {\n       Thread.sleep(t);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void backOffIfNecessary() throws InterruptedException {\n    int t \u003d 0;\n    synchronized (congestedNodes) {\n      if (!congestedNodes.isEmpty()) {\n        StringBuilder sb \u003d new StringBuilder(\"DataNode\");\n        for (DatanodeInfo i : congestedNodes) {\n          sb.append(\u0027 \u0027).append(i);\n        }\n        int range \u003d Math.abs(lastCongestionBackoffTime * 3 -\n                                CONGESTION_BACKOFF_MEAN_TIME_IN_MS);\n        int base \u003d Math.min(lastCongestionBackoffTime * 3,\n                            CONGESTION_BACKOFF_MEAN_TIME_IN_MS);\n        t \u003d Math.min(CONGESTION_BACK_OFF_MAX_TIME_IN_MS,\n                     (int)(base + Math.random() * range));\n        lastCongestionBackoffTime \u003d t;\n        sb.append(\" are congested. Backing off for \").append(t).append(\" ms\");\n        LOG.info(sb.toString());\n        congestedNodes.clear();\n      }\n    }\n    if (t !\u003d 0) {\n      Thread.sleep(t);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {}
    },
    "6ccf4fbf8a8374c289370f67b26ac05abad30ebc": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-8008. Support client-side back off when the datanodes are congested. Contributed by Haohui Mai.\n",
      "commitDate": "01/04/15 4:54 PM",
      "commitName": "6ccf4fbf8a8374c289370f67b26ac05abad30ebc",
      "commitAuthor": "Haohui Mai",
      "diff": "@@ -0,0 +1,24 @@\n+  private void backOffIfNecessary() throws InterruptedException {\n+    int t \u003d 0;\n+    synchronized (congestedNodes) {\n+      if (!congestedNodes.isEmpty()) {\n+        StringBuilder sb \u003d new StringBuilder(\"DataNode\");\n+        for (DatanodeInfo i : congestedNodes) {\n+          sb.append(\u0027 \u0027).append(i);\n+        }\n+        int range \u003d Math.abs(lastCongestionBackoffTime * 3 -\n+                                CONGESTION_BACKOFF_MEAN_TIME_IN_MS);\n+        int base \u003d Math.min(lastCongestionBackoffTime * 3,\n+                            CONGESTION_BACKOFF_MEAN_TIME_IN_MS);\n+        t \u003d Math.min(CONGESTION_BACK_OFF_MAX_TIME_IN_MS,\n+                     (int)(base + Math.random() * range));\n+        lastCongestionBackoffTime \u003d t;\n+        sb.append(\" are congested. Backing off for \").append(t).append(\" ms\");\n+        DFSClient.LOG.info(sb.toString());\n+        congestedNodes.clear();\n+      }\n+    }\n+    if (t !\u003d 0) {\n+      Thread.sleep(t);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void backOffIfNecessary() throws InterruptedException {\n    int t \u003d 0;\n    synchronized (congestedNodes) {\n      if (!congestedNodes.isEmpty()) {\n        StringBuilder sb \u003d new StringBuilder(\"DataNode\");\n        for (DatanodeInfo i : congestedNodes) {\n          sb.append(\u0027 \u0027).append(i);\n        }\n        int range \u003d Math.abs(lastCongestionBackoffTime * 3 -\n                                CONGESTION_BACKOFF_MEAN_TIME_IN_MS);\n        int base \u003d Math.min(lastCongestionBackoffTime * 3,\n                            CONGESTION_BACKOFF_MEAN_TIME_IN_MS);\n        t \u003d Math.min(CONGESTION_BACK_OFF_MAX_TIME_IN_MS,\n                     (int)(base + Math.random() * range));\n        lastCongestionBackoffTime \u003d t;\n        sb.append(\" are congested. Backing off for \").append(t).append(\" ms\");\n        DFSClient.LOG.info(sb.toString());\n        congestedNodes.clear();\n      }\n    }\n    if (t !\u003d 0) {\n      Thread.sleep(t);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java"
    }
  }
}