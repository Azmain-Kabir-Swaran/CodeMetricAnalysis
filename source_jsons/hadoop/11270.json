{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BPOfferService.java",
  "functionName": "processCommandFromActive",
  "functionId": "processCommandFromActive___cmd-DatanodeCommand__actor-BPServiceActor",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
  "functionStartLine": 714,
  "functionEndLine": 804,
  "numCommitsSeen": 87,
  "timeTaken": 7050,
  "changeHistory": [
    "39ed3a66dbb01383ed16b141183fc48bfd2e613d",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
    "e34331c31d68cb22891db48011db5b36ad178af1",
    "e2a15d18bbbb86c20003c4e34d85244996a4cc3b",
    "a3954ccab148bddc290cb96528e63ff19799bcc9",
    "4ae543fdcd6dcfbe32257b1e72a405df9aa73e17",
    "e287e7d14b838a866ba03d895fa35819999d7c09",
    "914580934c566cd18019035b244f82006868bd7b",
    "014d8675c59d44ad68dec36db6afe3f3666a3f15",
    "9d8952f97f638ede27e4336b9601507d7bb1de7b",
    "6e62a1a6728b1f782f64065424f92b292c3f163a",
    "25b0e8471ed744578b2d8e3f0debe5477b268e54",
    "d265dd9eb01bb4ed5335872f5976740258d6bfc0",
    "5df82fa01d26c18685ad7617128dbc2913547cb3",
    "916ab9286b6006571649d21c74d9ae70273a3ddc",
    "04cf2a768c0fb1c2c5c80d2480aa072ec7e43c3f",
    "15d08c4778350a86d7bae0174aeb48f8d8f61cce",
    "40eb94ade3161d93e7a762a839004748f6d0ae89",
    "b992219fa13ccee2b417d91222fd0c3e8c3ffe11",
    "456064d8999b8aaba32bc398ad39143e9ee1439f",
    "380870d54453c1113d46d0f070f4e19b6cea7b8c",
    "6c0ccb5989c2053f5a1ebab0dd9fdb7b4019fda8",
    "fb95fce24056c0b0aa5b77683c684fe1b68c4f76",
    "befd45fcb193a944dd144a9ebeca006b2b73cb0d",
    "5258d6bf3fb8090739cf96f5089f96cee87393c4",
    "3e582c690cb8c29267c8c8a741a21eea918f0145",
    "978a8050e28b2afb193a3e00d82a8475fa4d2428"
  ],
  "changeHistoryShort": {
    "39ed3a66dbb01383ed16b141183fc48bfd2e613d": "Ybodychange",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": "Ybodychange",
    "e34331c31d68cb22891db48011db5b36ad178af1": "Ybodychange",
    "e2a15d18bbbb86c20003c4e34d85244996a4cc3b": "Ybodychange",
    "a3954ccab148bddc290cb96528e63ff19799bcc9": "Ybodychange",
    "4ae543fdcd6dcfbe32257b1e72a405df9aa73e17": "Ybodychange",
    "e287e7d14b838a866ba03d895fa35819999d7c09": "Ybodychange",
    "914580934c566cd18019035b244f82006868bd7b": "Ybodychange",
    "014d8675c59d44ad68dec36db6afe3f3666a3f15": "Ybodychange",
    "9d8952f97f638ede27e4336b9601507d7bb1de7b": "Ybodychange",
    "6e62a1a6728b1f782f64065424f92b292c3f163a": "Ybodychange",
    "25b0e8471ed744578b2d8e3f0debe5477b268e54": "Ybodychange",
    "d265dd9eb01bb4ed5335872f5976740258d6bfc0": "Ybodychange",
    "5df82fa01d26c18685ad7617128dbc2913547cb3": "Ybodychange",
    "916ab9286b6006571649d21c74d9ae70273a3ddc": "Ybodychange",
    "04cf2a768c0fb1c2c5c80d2480aa072ec7e43c3f": "Ybodychange",
    "15d08c4778350a86d7bae0174aeb48f8d8f61cce": "Ybodychange",
    "40eb94ade3161d93e7a762a839004748f6d0ae89": "Ybodychange",
    "b992219fa13ccee2b417d91222fd0c3e8c3ffe11": "Ybodychange",
    "456064d8999b8aaba32bc398ad39143e9ee1439f": "Ybodychange",
    "380870d54453c1113d46d0f070f4e19b6cea7b8c": "Ybodychange",
    "6c0ccb5989c2053f5a1ebab0dd9fdb7b4019fda8": "Ybodychange",
    "fb95fce24056c0b0aa5b77683c684fe1b68c4f76": "Ybodychange",
    "befd45fcb193a944dd144a9ebeca006b2b73cb0d": "Ybodychange",
    "5258d6bf3fb8090739cf96f5089f96cee87393c4": "Ybodychange",
    "3e582c690cb8c29267c8c8a741a21eea918f0145": "Ybodychange",
    "978a8050e28b2afb193a3e00d82a8475fa4d2428": "Ybodychange"
  },
  "changeHistoryDetails": {
    "39ed3a66dbb01383ed16b141183fc48bfd2e613d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13076: [SPS]: Cleanup work for HDFS-10285 merge. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "39ed3a66dbb01383ed16b141183fc48bfd2e613d",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,101 +1,91 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n     final BlockIdCommand blockIdCmd \u003d \n       cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n           bcmd.getTargets(), bcmd.getTargetStorageTypes(),\n           bcmd.getTargetStorageIDs());\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n       LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n       LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n       LOG.info(\"Got finalize command for block pool \" + bp);\n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.getBlockRecoveryWorker().recoverBlocks(who,\n           ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     case DatanodeProtocol.DNA_ERASURE_CODING_RECONSTRUCTION:\n       LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n       Collection\u003cBlockECReconstructionInfo\u003e ecTasks \u003d\n           ((BlockECReconstructionCommand) cmd).getECTasks();\n       dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n       break;\n-    case DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT:\n-      LOG.info(\"DatanodeCommand action: DNA_BLOCK_STORAGE_MOVEMENT\");\n-      BlockStorageMovementCommand blkSPSCmd \u003d (BlockStorageMovementCommand) cmd;\n-      dn.getStoragePolicySatisfyWorker().processBlockMovingTasks(\n-          blkSPSCmd.getBlockPoolId(), blkSPSCmd.getBlockMovingTasks());\n-      break;\n-    case DatanodeProtocol.DNA_DROP_SPS_WORK_COMMAND:\n-      LOG.info(\"DatanodeCommand action: DNA_DROP_SPS_WORK_COMMAND\");\n-      dn.getStoragePolicySatisfyWorker().dropSPSWork();\n-      break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n    final BlockIdCommand blockIdCmd \u003d \n      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n          bcmd.getTargets(), bcmd.getTargetStorageTypes(),\n          bcmd.getTargetStorageIDs());\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n      LOG.info(\"Got finalize command for block pool \" + bp);\n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.getBlockRecoveryWorker().recoverBlocks(who,\n          ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    case DatanodeProtocol.DNA_ERASURE_CODING_RECONSTRUCTION:\n      LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n      Collection\u003cBlockECReconstructionInfo\u003e ecTasks \u003d\n          ((BlockECReconstructionCommand) cmd).getECTasks();\n      dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,102 +1,101 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n     final BlockIdCommand blockIdCmd \u003d \n       cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n           bcmd.getTargets(), bcmd.getTargetStorageTypes(),\n           bcmd.getTargetStorageIDs());\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n       LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n       LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n       LOG.info(\"Got finalize command for block pool \" + bp);\n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.getBlockRecoveryWorker().recoverBlocks(who,\n           ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     case DatanodeProtocol.DNA_ERASURE_CODING_RECONSTRUCTION:\n       LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n       Collection\u003cBlockECReconstructionInfo\u003e ecTasks \u003d\n           ((BlockECReconstructionCommand) cmd).getECTasks();\n       dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n       break;\n     case DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT:\n       LOG.info(\"DatanodeCommand action: DNA_BLOCK_STORAGE_MOVEMENT\");\n       BlockStorageMovementCommand blkSPSCmd \u003d (BlockStorageMovementCommand) cmd;\n       dn.getStoragePolicySatisfyWorker().processBlockMovingTasks(\n-          blkSPSCmd.getTrackID(), blkSPSCmd.getBlockPoolId(),\n-          blkSPSCmd.getBlockMovingTasks());\n+          blkSPSCmd.getBlockPoolId(), blkSPSCmd.getBlockMovingTasks());\n       break;\n     case DatanodeProtocol.DNA_DROP_SPS_WORK_COMMAND:\n       LOG.info(\"DatanodeCommand action: DNA_DROP_SPS_WORK_COMMAND\");\n       dn.getStoragePolicySatisfyWorker().dropSPSWork();\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n    final BlockIdCommand blockIdCmd \u003d \n      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n          bcmd.getTargets(), bcmd.getTargetStorageTypes(),\n          bcmd.getTargetStorageIDs());\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n      LOG.info(\"Got finalize command for block pool \" + bp);\n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.getBlockRecoveryWorker().recoverBlocks(who,\n          ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    case DatanodeProtocol.DNA_ERASURE_CODING_RECONSTRUCTION:\n      LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n      Collection\u003cBlockECReconstructionInfo\u003e ecTasks \u003d\n          ((BlockECReconstructionCommand) cmd).getECTasks();\n      dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n      break;\n    case DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT:\n      LOG.info(\"DatanodeCommand action: DNA_BLOCK_STORAGE_MOVEMENT\");\n      BlockStorageMovementCommand blkSPSCmd \u003d (BlockStorageMovementCommand) cmd;\n      dn.getStoragePolicySatisfyWorker().processBlockMovingTasks(\n          blkSPSCmd.getBlockPoolId(), blkSPSCmd.getBlockMovingTasks());\n      break;\n    case DatanodeProtocol.DNA_DROP_SPS_WORK_COMMAND:\n      LOG.info(\"DatanodeCommand action: DNA_DROP_SPS_WORK_COMMAND\");\n      dn.getStoragePolicySatisfyWorker().dropSPSWork();\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "e34331c31d68cb22891db48011db5b36ad178af1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11243. [SPS]: Add a protocol command from NN to DN for dropping the SPS work and queues. Contributed by Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "e34331c31d68cb22891db48011db5b36ad178af1",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "e2a15d18bbbb86c20003c4e34d85244996a4cc3b",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,98 +1,102 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n     final BlockIdCommand blockIdCmd \u003d \n       cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n           bcmd.getTargets(), bcmd.getTargetStorageTypes(),\n           bcmd.getTargetStorageIDs());\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n       LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n       LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n       LOG.info(\"Got finalize command for block pool \" + bp);\n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.getBlockRecoveryWorker().recoverBlocks(who,\n           ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     case DatanodeProtocol.DNA_ERASURE_CODING_RECONSTRUCTION:\n       LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n       Collection\u003cBlockECReconstructionInfo\u003e ecTasks \u003d\n           ((BlockECReconstructionCommand) cmd).getECTasks();\n       dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n       break;\n     case DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT:\n       LOG.info(\"DatanodeCommand action: DNA_BLOCK_STORAGE_MOVEMENT\");\n       BlockStorageMovementCommand blkSPSCmd \u003d (BlockStorageMovementCommand) cmd;\n       dn.getStoragePolicySatisfyWorker().processBlockMovingTasks(\n           blkSPSCmd.getTrackID(), blkSPSCmd.getBlockPoolId(),\n           blkSPSCmd.getBlockMovingTasks());\n       break;\n+    case DatanodeProtocol.DNA_DROP_SPS_WORK_COMMAND:\n+      LOG.info(\"DatanodeCommand action: DNA_DROP_SPS_WORK_COMMAND\");\n+      dn.getStoragePolicySatisfyWorker().dropSPSWork();\n+      break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n    final BlockIdCommand blockIdCmd \u003d \n      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n          bcmd.getTargets(), bcmd.getTargetStorageTypes(),\n          bcmd.getTargetStorageIDs());\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n      LOG.info(\"Got finalize command for block pool \" + bp);\n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.getBlockRecoveryWorker().recoverBlocks(who,\n          ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    case DatanodeProtocol.DNA_ERASURE_CODING_RECONSTRUCTION:\n      LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n      Collection\u003cBlockECReconstructionInfo\u003e ecTasks \u003d\n          ((BlockECReconstructionCommand) cmd).getECTasks();\n      dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n      break;\n    case DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT:\n      LOG.info(\"DatanodeCommand action: DNA_BLOCK_STORAGE_MOVEMENT\");\n      BlockStorageMovementCommand blkSPSCmd \u003d (BlockStorageMovementCommand) cmd;\n      dn.getStoragePolicySatisfyWorker().processBlockMovingTasks(\n          blkSPSCmd.getTrackID(), blkSPSCmd.getBlockPoolId(),\n          blkSPSCmd.getBlockMovingTasks());\n      break;\n    case DatanodeProtocol.DNA_DROP_SPS_WORK_COMMAND:\n      LOG.info(\"DatanodeCommand action: DNA_DROP_SPS_WORK_COMMAND\");\n      dn.getStoragePolicySatisfyWorker().dropSPSWork();\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "e2a15d18bbbb86c20003c4e34d85244996a4cc3b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10801. [SPS]: Protocol buffer changes for sending storage movement commands from NN to DN. Contributed by Rakesh R\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "e2a15d18bbbb86c20003c4e34d85244996a4cc3b",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "16/01/18 2:51 AM",
      "commitNameOld": "880b9d24ff7b5f350ec99bac9b0862009460b486",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 207.97,
      "commitsBetweenForRepo": 2058,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,91 +1,98 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n     final BlockIdCommand blockIdCmd \u003d \n       cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n           bcmd.getTargets(), bcmd.getTargetStorageTypes(),\n           bcmd.getTargetStorageIDs());\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n       LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n       LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n       LOG.info(\"Got finalize command for block pool \" + bp);\n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.getBlockRecoveryWorker().recoverBlocks(who,\n           ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     case DatanodeProtocol.DNA_ERASURE_CODING_RECONSTRUCTION:\n       LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n       Collection\u003cBlockECReconstructionInfo\u003e ecTasks \u003d\n           ((BlockECReconstructionCommand) cmd).getECTasks();\n       dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n       break;\n+    case DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT:\n+      LOG.info(\"DatanodeCommand action: DNA_BLOCK_STORAGE_MOVEMENT\");\n+      BlockStorageMovementCommand blkSPSCmd \u003d (BlockStorageMovementCommand) cmd;\n+      dn.getStoragePolicySatisfyWorker().processBlockMovingTasks(\n+          blkSPSCmd.getTrackID(), blkSPSCmd.getBlockPoolId(),\n+          blkSPSCmd.getBlockMovingTasks());\n+      break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n    final BlockIdCommand blockIdCmd \u003d \n      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n          bcmd.getTargets(), bcmd.getTargetStorageTypes(),\n          bcmd.getTargetStorageIDs());\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n      LOG.info(\"Got finalize command for block pool \" + bp);\n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.getBlockRecoveryWorker().recoverBlocks(who,\n          ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    case DatanodeProtocol.DNA_ERASURE_CODING_RECONSTRUCTION:\n      LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n      Collection\u003cBlockECReconstructionInfo\u003e ecTasks \u003d\n          ((BlockECReconstructionCommand) cmd).getECTasks();\n      dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n      break;\n    case DatanodeProtocol.DNA_BLOCK_STORAGE_MOVEMENT:\n      LOG.info(\"DatanodeCommand action: DNA_BLOCK_STORAGE_MOVEMENT\");\n      BlockStorageMovementCommand blkSPSCmd \u003d (BlockStorageMovementCommand) cmd;\n      dn.getStoragePolicySatisfyWorker().processBlockMovingTasks(\n          blkSPSCmd.getTrackID(), blkSPSCmd.getBlockPoolId(),\n          blkSPSCmd.getBlockMovingTasks());\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "a3954ccab148bddc290cb96528e63ff19799bcc9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9807. Add an optional StorageID to writes. Contributed by Ewan Higgs\n",
      "commitDate": "05/05/17 12:01 PM",
      "commitName": "a3954ccab148bddc290cb96528e63ff19799bcc9",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "11/04/17 3:29 PM",
      "commitNameOld": "3a91376707d451777b8269f81bcd48315edd9fc7",
      "commitAuthorOld": "Mingliang Liu",
      "daysBetweenCommits": 23.86,
      "commitsBetweenForRepo": 129,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,91 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n     final BlockIdCommand blockIdCmd \u003d \n       cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n-          bcmd.getTargets(), bcmd.getTargetStorageTypes());\n+          bcmd.getTargets(), bcmd.getTargetStorageTypes(),\n+          bcmd.getTargetStorageIDs());\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n       LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n       LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n       LOG.info(\"Got finalize command for block pool \" + bp);\n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.getBlockRecoveryWorker().recoverBlocks(who,\n           ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     case DatanodeProtocol.DNA_ERASURE_CODING_RECONSTRUCTION:\n       LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n       Collection\u003cBlockECReconstructionInfo\u003e ecTasks \u003d\n           ((BlockECReconstructionCommand) cmd).getECTasks();\n       dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n    final BlockIdCommand blockIdCmd \u003d \n      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n          bcmd.getTargets(), bcmd.getTargetStorageTypes(),\n          bcmd.getTargetStorageIDs());\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n      LOG.info(\"Got finalize command for block pool \" + bp);\n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.getBlockRecoveryWorker().recoverBlocks(who,\n          ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    case DatanodeProtocol.DNA_ERASURE_CODING_RECONSTRUCTION:\n      LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n      Collection\u003cBlockECReconstructionInfo\u003e ecTasks \u003d\n          ((BlockECReconstructionCommand) cmd).getECTasks();\n      dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "4ae543fdcd6dcfbe32257b1e72a405df9aa73e17": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9731. Erasure Coding: Rename BlockECRecoveryCommand to BlockECReconstructionCommand. Contributed by Rakesh R.\n\nChange-Id: I405365a8395770e494b92bfe9651f4f0366d8f28\n",
      "commitDate": "02/02/16 12:32 PM",
      "commitName": "4ae543fdcd6dcfbe32257b1e72a405df9aa73e17",
      "commitAuthor": "zhezhang",
      "commitDateOld": "22/11/15 3:54 PM",
      "commitNameOld": "176ff5ce90f2cbcd8342016d0f5570337d2ff79f",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 71.86,
      "commitsBetweenForRepo": 462,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,89 +1,90 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n     final BlockIdCommand blockIdCmd \u003d \n       cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n           bcmd.getTargets(), bcmd.getTargetStorageTypes());\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n       LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n       LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n       LOG.info(\"Got finalize command for block pool \" + bp);\n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.getBlockRecoveryWorker().recoverBlocks(who,\n           ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n-    case DatanodeProtocol.DNA_ERASURE_CODING_RECOVERY:\n+    case DatanodeProtocol.DNA_ERASURE_CODING_RECONSTRUCTION:\n       LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n-      Collection\u003cBlockECRecoveryInfo\u003e ecTasks \u003d ((BlockECRecoveryCommand) cmd).getECTasks();\n+      Collection\u003cBlockECReconstructionInfo\u003e ecTasks \u003d\n+          ((BlockECReconstructionCommand) cmd).getECTasks();\n       dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n    final BlockIdCommand blockIdCmd \u003d \n      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n          bcmd.getTargets(), bcmd.getTargetStorageTypes());\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n      LOG.info(\"Got finalize command for block pool \" + bp);\n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.getBlockRecoveryWorker().recoverBlocks(who,\n          ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    case DatanodeProtocol.DNA_ERASURE_CODING_RECONSTRUCTION:\n      LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n      Collection\u003cBlockECReconstructionInfo\u003e ecTasks \u003d\n          ((BlockECReconstructionCommand) cmd).getECTasks();\n      dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "e287e7d14b838a866ba03d895fa35819999d7c09": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9255. Consolidate block recovery related implementation into a single class. Contributed by Walter Su.\n\nChange-Id: I7a1c03f50123d79ac0a78c981d9721617e3229d1\n",
      "commitDate": "28/10/15 7:34 AM",
      "commitName": "e287e7d14b838a866ba03d895fa35819999d7c09",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "22/09/15 1:27 PM",
      "commitNameOld": "1080c3730068177ddd10dc313890ac1f5dc58f1a",
      "commitAuthorOld": "",
      "daysBetweenCommits": 35.75,
      "commitsBetweenForRepo": 306,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,88 +1,89 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n     final BlockIdCommand blockIdCmd \u003d \n       cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n           bcmd.getTargets(), bcmd.getTargetStorageTypes());\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n       LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n       LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n       LOG.info(\"Got finalize command for block pool \" + bp);\n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n-      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n+      dn.getBlockRecoveryWorker().recoverBlocks(who,\n+          ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     case DatanodeProtocol.DNA_ERASURE_CODING_RECOVERY:\n       LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n       Collection\u003cBlockECRecoveryInfo\u003e ecTasks \u003d ((BlockECRecoveryCommand) cmd).getECTasks();\n       dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n    final BlockIdCommand blockIdCmd \u003d \n      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n          bcmd.getTargets(), bcmd.getTargetStorageTypes());\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n      LOG.info(\"Got finalize command for block pool \" + bp);\n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.getBlockRecoveryWorker().recoverBlocks(who,\n          ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    case DatanodeProtocol.DNA_ERASURE_CODING_RECOVERY:\n      LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n      Collection\u003cBlockECRecoveryInfo\u003e ecTasks \u003d ((BlockECRecoveryCommand) cmd).getECTasks();\n      dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "914580934c566cd18019035b244f82006868bd7b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8378. Erasure Coding: Few improvements for the erasure coding worker. Contributed by Rakesh R.\n",
      "commitDate": "26/05/15 12:02 PM",
      "commitName": "914580934c566cd18019035b244f82006868bd7b",
      "commitAuthor": "Walter Su",
      "commitDateOld": "26/05/15 11:59 AM",
      "commitNameOld": "f9eb95c31da9199b393d7994cf9f21250abe41b9",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 40,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,88 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n     final BlockIdCommand blockIdCmd \u003d \n       cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n           bcmd.getTargets(), bcmd.getTargetStorageTypes());\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n       LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n       LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n       LOG.info(\"Got finalize command for block pool \" + bp);\n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     case DatanodeProtocol.DNA_ERASURE_CODING_RECOVERY:\n       LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n       Collection\u003cBlockECRecoveryInfo\u003e ecTasks \u003d ((BlockECRecoveryCommand) cmd).getECTasks();\n       dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n+      break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n    final BlockIdCommand blockIdCmd \u003d \n      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n          bcmd.getTargets(), bcmd.getTargetStorageTypes());\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n      LOG.info(\"Got finalize command for block pool \" + bp);\n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    case DatanodeProtocol.DNA_ERASURE_CODING_RECOVERY:\n      LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n      Collection\u003cBlockECRecoveryInfo\u003e ecTasks \u003d ((BlockECRecoveryCommand) cmd).getECTasks();\n      dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "014d8675c59d44ad68dec36db6afe3f3666a3f15": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8024. Erasure Coding: ECworker frame, basics, bootstraping and configuration. (Contributed by Uma Maheswara Rao G)\n",
      "commitDate": "26/05/15 11:59 AM",
      "commitName": "014d8675c59d44ad68dec36db6afe3f3666a3f15",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "21/04/15 10:58 AM",
      "commitNameOld": "dfc1c4c303cf15afc6c3361ed9d3238562f73cbd",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 35.04,
      "commitsBetweenForRepo": 458,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,87 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n     final BlockIdCommand blockIdCmd \u003d \n       cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n           bcmd.getTargets(), bcmd.getTargetStorageTypes());\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n       LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n       LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n       LOG.info(\"Got finalize command for block pool \" + bp);\n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n+    case DatanodeProtocol.DNA_ERASURE_CODING_RECOVERY:\n+      LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n+      Collection\u003cBlockECRecoveryInfo\u003e ecTasks \u003d ((BlockECRecoveryCommand) cmd).getECTasks();\n+      dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n    final BlockIdCommand blockIdCmd \u003d \n      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n          bcmd.getTargets(), bcmd.getTargetStorageTypes());\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n      LOG.info(\"Got finalize command for block pool \" + bp);\n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    case DatanodeProtocol.DNA_ERASURE_CODING_RECOVERY:\n      LOG.info(\"DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY\");\n      Collection\u003cBlockECRecoveryInfo\u003e ecTasks \u003d ((BlockECRecoveryCommand) cmd).getECTasks();\n      dn.getErasureCodingWorker().processErasureCodingTasks(ecTasks);\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "9d8952f97f638ede27e4336b9601507d7bb1de7b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8096. DatanodeMetrics#blocksReplicated will get incremented early and even for failed transfers (Contributed by Vinayakumar B)\n",
      "commitDate": "08/04/15 11:28 PM",
      "commitName": "9d8952f97f638ede27e4336b9601507d7bb1de7b",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "30/03/15 3:25 PM",
      "commitNameOld": "1a495fbb489c9e9a23b341a52696d10e9e272b04",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 9.34,
      "commitsBetweenForRepo": 83,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,83 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n     final BlockIdCommand blockIdCmd \u003d \n       cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n           bcmd.getTargets(), bcmd.getTargetStorageTypes());\n-      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n       LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n       LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n       LOG.info(\"Got finalize command for block pool \" + bp);\n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n    final BlockIdCommand blockIdCmd \u003d \n      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n          bcmd.getTargets(), bcmd.getTargetStorageTypes());\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n      LOG.info(\"Got finalize command for block pool \" + bp);\n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "6e62a1a6728b1f782f64065424f92b292c3f163a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7430. Refactor the BlockScanner to use O(1) memory and use multiple threads (cmccabe)\n",
      "commitDate": "21/01/15 7:00 PM",
      "commitName": "6e62a1a6728b1f782f64065424f92b292c3f163a",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "09/10/14 10:07 AM",
      "commitNameOld": "db71bb54bcc75b71c5841b25ceb03fb0218c6d4f",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 104.41,
      "commitsBetweenForRepo": 757,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,84 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n     final BlockIdCommand blockIdCmd \u003d \n       cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n           bcmd.getTargets(), bcmd.getTargetStorageTypes());\n       dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n-        if (dn.blockScanner !\u003d null) {\n-          dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n-        }\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n       LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n       LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n       LOG.info(\"Got finalize command for block pool \" + bp);\n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n    final BlockIdCommand blockIdCmd \u003d \n      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n          bcmd.getTargets(), bcmd.getTargetStorageTypes());\n      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n      LOG.info(\"Got finalize command for block pool \" + bp);\n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "25b0e8471ed744578b2d8e3f0debe5477b268e54": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6702. Change DFSClient to pass the StorageType from the namenode to datanodes and change datanode to write block replicas using the specified storage type.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1612493 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/07/14 12:41 AM",
      "commitName": "25b0e8471ed744578b2d8e3f0debe5477b268e54",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "29/04/14 3:27 AM",
      "commitNameOld": "9d21180c1a625295bb9da0d9d5d8c55740944008",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 83.88,
      "commitsBetweenForRepo": 513,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,87 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n     final BlockIdCommand blockIdCmd \u003d \n       cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n-      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n+      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n+          bcmd.getTargets(), bcmd.getTargetStorageTypes());\n       dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         if (dn.blockScanner !\u003d null) {\n           dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n         }\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n       LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n       LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n       LOG.info(\"Got finalize command for block pool \" + bp);\n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n    final BlockIdCommand blockIdCmd \u003d \n      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(),\n          bcmd.getTargets(), bcmd.getTargetStorageTypes());\n      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        if (dn.blockScanner !\u003d null) {\n          dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n        }\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n      LOG.info(\"Got finalize command for block pool \" + bp);\n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "d265dd9eb01bb4ed5335872f5976740258d6bfc0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6107. When a block cannot be cached due to limited space on the DataNode, it becomes uncacheable (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1578508 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/03/14 11:46 AM",
      "commitName": "d265dd9eb01bb4ed5335872f5976740258d6bfc0",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "07/03/14 3:47 PM",
      "commitNameOld": "1f6c2b09c6a5dc07f5caa1cad7036e0e1465f33e",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 9.79,
      "commitsBetweenForRepo": 70,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,88 +1,86 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n     final BlockIdCommand blockIdCmd \u003d \n       cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n       dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         if (dn.blockScanner !\u003d null) {\n           dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n         }\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n       LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n-      dn.metrics.incrBlocksCached(blockIdCmd.getBlockIds().length);\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n       LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n-      dn.metrics.incrBlocksUncached(blockIdCmd.getBlockIds().length);\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n       LOG.info(\"Got finalize command for block pool \" + bp);\n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n    final BlockIdCommand blockIdCmd \u003d \n      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        if (dn.blockScanner !\u003d null) {\n          dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n        }\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n      LOG.info(\"Got finalize command for block pool \" + bp);\n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "5df82fa01d26c18685ad7617128dbc2913547cb3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5907. BlockPoolSliceStorage trash to handle block deletions during rolling upgrade. (Arpit Agarwal)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1568346 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/02/14 8:37 AM",
      "commitName": "5df82fa01d26c18685ad7617128dbc2913547cb3",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "16/12/13 10:35 AM",
      "commitNameOld": "8e32e6aff16e99c493c152e97d84ecc7c494ffb9",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 59.92,
      "commitsBetweenForRepo": 309,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,88 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n     final BlockIdCommand blockIdCmd \u003d \n       cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n       dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         if (dn.blockScanner !\u003d null) {\n           dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n         }\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n       LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       dn.metrics.incrBlocksCached(blockIdCmd.getBlockIds().length);\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n       LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n         blockIdCmd.getBlockPoolId() + \" of [\" +\n           blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       dn.metrics.incrBlocksUncached(blockIdCmd.getBlockIds().length);\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_FINALIZE:\n-      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n+      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n+      LOG.info(\"Got finalize command for block pool \" + bp);\n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n    final BlockIdCommand blockIdCmd \u003d \n      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        if (dn.blockScanner !\u003d null) {\n          dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n        }\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      dn.metrics.incrBlocksCached(blockIdCmd.getBlockIds().length);\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      dn.metrics.incrBlocksUncached(blockIdCmd.getBlockIds().length);\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId();\n      LOG.info(\"Got finalize command for block pool \" + bp);\n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "916ab9286b6006571649d21c74d9ae70273a3ddc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5451. Add byte and file statistics to PathBasedCacheEntry. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1543958 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/11/13 1:31 PM",
      "commitName": "916ab9286b6006571649d21c74d9ae70273a3ddc",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "20/11/13 8:27 AM",
      "commitNameOld": "04cf2a768c0fb1c2c5c80d2480aa072ec7e43c3f",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.21,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,87 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n     final BlockIdCommand blockIdCmd \u003d \n       cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n       dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         if (dn.blockScanner !\u003d null) {\n           dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n         }\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n-      LOG.info(\"DatanodeCommand action: DNA_CACHE\");\n+      LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n+        blockIdCmd.getBlockPoolId() + \" of [\" +\n+          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       dn.metrics.incrBlocksCached(blockIdCmd.getBlockIds().length);\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n-      LOG.info(\"DatanodeCommand action: DNA_UNCACHE\");\n+      LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n+        blockIdCmd.getBlockPoolId() + \" of [\" +\n+          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n       dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       dn.metrics.incrBlocksUncached(blockIdCmd.getBlockIds().length);\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n    final BlockIdCommand blockIdCmd \u003d \n      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        if (dn.blockScanner !\u003d null) {\n          dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n        }\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      dn.metrics.incrBlocksCached(blockIdCmd.getBlockIds().length);\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE for \" +\n        blockIdCmd.getBlockPoolId() + \" of [\" +\n          blockIdArrayToString(blockIdCmd.getBlockIds()) + \"]\");\n      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      dn.metrics.incrBlocksUncached(blockIdCmd.getBlockIds().length);\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "04cf2a768c0fb1c2c5c80d2480aa072ec7e43c3f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5014. Process register commands with out holding BPOfferService lock. Contributed by Vinay.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1543861 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/11/13 8:27 AM",
      "commitName": "04cf2a768c0fb1c2c5c80d2480aa072ec7e43c3f",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "16/10/13 3:15 PM",
      "commitNameOld": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 34.76,
      "commitsBetweenForRepo": 190,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,90 +1,83 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n-    if (cmd \u003d\u003d null)\n-      return true;\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n     final BlockIdCommand blockIdCmd \u003d \n       cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n       dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         if (dn.blockScanner !\u003d null) {\n           dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n         }\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n       LOG.info(\"DatanodeCommand action: DNA_CACHE\");\n       dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       dn.metrics.incrBlocksCached(blockIdCmd.getBlockIds().length);\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n       LOG.info(\"DatanodeCommand action: DNA_UNCACHE\");\n       dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n       dn.metrics.incrBlocksUncached(blockIdCmd.getBlockIds().length);\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n-    case DatanodeProtocol.DNA_REGISTER:\n-      // namenode requested a registration - at start or if NN lost contact\n-      LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n-      actor.reRegister();\n-      break;\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n    final BlockIdCommand blockIdCmd \u003d \n      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        if (dn.blockScanner !\u003d null) {\n          dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n        }\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE\");\n      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      dn.metrics.incrBlocksCached(blockIdCmd.getBlockIds().length);\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE\");\n      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      dn.metrics.incrBlocksUncached(blockIdCmd.getBlockIds().length);\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "15d08c4778350a86d7bae0174aeb48f8d8f61cce": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5349. DNA_CACHE and DNA_UNCACHE should be by blockId only (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532116 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/10/13 3:19 PM",
      "commitName": "15d08c4778350a86d7bae0174aeb48f8d8f61cce",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "16/09/13 11:41 AM",
      "commitNameOld": "85c203602993a946fb5f41eadf1cf1484a0ce686",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 28.15,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,88 +1,90 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     if (cmd \u003d\u003d null)\n       return true;\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n+    final BlockIdCommand blockIdCmd \u003d \n+      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n       dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         if (dn.blockScanner !\u003d null) {\n           dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n         }\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n       LOG.info(\"DatanodeCommand action: DNA_CACHE\");\n-      dn.getFSDataset().cache(bcmd.getBlockPoolId(), bcmd.getBlocks());\n-      dn.metrics.incrBlocksCached(bcmd.getBlocks().length);\n+      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n+      dn.metrics.incrBlocksCached(blockIdCmd.getBlockIds().length);\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n       LOG.info(\"DatanodeCommand action: DNA_UNCACHE\");\n-      dn.getFSDataset().uncache(bcmd.getBlockPoolId(), bcmd.getBlocks());\n-      dn.metrics.incrBlocksUncached(bcmd.getBlocks().length);\n+      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n+      dn.metrics.incrBlocksUncached(blockIdCmd.getBlockIds().length);\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_REGISTER:\n       // namenode requested a registration - at start or if NN lost contact\n       LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n       actor.reRegister();\n       break;\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    if (cmd \u003d\u003d null)\n      return true;\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n    final BlockIdCommand blockIdCmd \u003d \n      cmd instanceof BlockIdCommand ? (BlockIdCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        if (dn.blockScanner !\u003d null) {\n          dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n        }\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE\");\n      dn.getFSDataset().cache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      dn.metrics.incrBlocksCached(blockIdCmd.getBlockIds().length);\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE\");\n      dn.getFSDataset().uncache(blockIdCmd.getBlockPoolId(), blockIdCmd.getBlockIds());\n      dn.metrics.incrBlocksUncached(blockIdCmd.getBlockIds().length);\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_REGISTER:\n      // namenode requested a registration - at start or if NN lost contact\n      LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n      actor.reRegister();\n      break;\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "40eb94ade3161d93e7a762a839004748f6d0ae89": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5053. NameNode should invoke DataNode APIs to coordinate caching. (Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1523145 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/09/13 4:27 PM",
      "commitName": "40eb94ade3161d93e7a762a839004748f6d0ae89",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "23/08/13 8:41 PM",
      "commitNameOld": "b992219fa13ccee2b417d91222fd0c3e8c3ffe11",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 20.82,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,88 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     if (cmd \u003d\u003d null)\n       return true;\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n       dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         if (dn.blockScanner !\u003d null) {\n           dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n         }\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_CACHE:\n       LOG.info(\"DatanodeCommand action: DNA_CACHE\");\n       dn.getFSDataset().cache(bcmd.getBlockPoolId(), bcmd.getBlocks());\n+      dn.metrics.incrBlocksCached(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_UNCACHE:\n       LOG.info(\"DatanodeCommand action: DNA_UNCACHE\");\n       dn.getFSDataset().uncache(bcmd.getBlockPoolId(), bcmd.getBlocks());\n+      dn.metrics.incrBlocksUncached(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_REGISTER:\n       // namenode requested a registration - at start or if NN lost contact\n       LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n       actor.reRegister();\n       break;\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    if (cmd \u003d\u003d null)\n      return true;\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        if (dn.blockScanner !\u003d null) {\n          dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n        }\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE\");\n      dn.getFSDataset().cache(bcmd.getBlockPoolId(), bcmd.getBlocks());\n      dn.metrics.incrBlocksCached(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE\");\n      dn.getFSDataset().uncache(bcmd.getBlockPoolId(), bcmd.getBlocks());\n      dn.metrics.incrBlocksUncached(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_REGISTER:\n      // namenode requested a registration - at start or if NN lost contact\n      LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n      actor.reRegister();\n      break;\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "b992219fa13ccee2b417d91222fd0c3e8c3ffe11": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5050.  Add DataNode support for mlock and munlock  (contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1517106 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/08/13 8:41 PM",
      "commitName": "b992219fa13ccee2b417d91222fd0c3e8c3ffe11",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "13/08/13 2:05 PM",
      "commitNameOld": "52ccc6c6d539d0587c3fd9693709bd1f6e12619d",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 10.28,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,86 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     if (cmd \u003d\u003d null)\n       return true;\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n       dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         if (dn.blockScanner !\u003d null) {\n           dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n         }\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n+    case DatanodeProtocol.DNA_CACHE:\n+      LOG.info(\"DatanodeCommand action: DNA_CACHE\");\n+      dn.getFSDataset().cache(bcmd.getBlockPoolId(), bcmd.getBlocks());\n+      break;\n+    case DatanodeProtocol.DNA_UNCACHE:\n+      LOG.info(\"DatanodeCommand action: DNA_UNCACHE\");\n+      dn.getFSDataset().uncache(bcmd.getBlockPoolId(), bcmd.getBlocks());\n+      break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_REGISTER:\n       // namenode requested a registration - at start or if NN lost contact\n       LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n       actor.reRegister();\n       break;\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    if (cmd \u003d\u003d null)\n      return true;\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        if (dn.blockScanner !\u003d null) {\n          dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n        }\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_CACHE:\n      LOG.info(\"DatanodeCommand action: DNA_CACHE\");\n      dn.getFSDataset().cache(bcmd.getBlockPoolId(), bcmd.getBlocks());\n      break;\n    case DatanodeProtocol.DNA_UNCACHE:\n      LOG.info(\"DatanodeCommand action: DNA_UNCACHE\");\n      dn.getFSDataset().uncache(bcmd.getBlockPoolId(), bcmd.getBlocks());\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_REGISTER:\n      // namenode requested a registration - at start or if NN lost contact\n      LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n      actor.reRegister();\n      break;\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "456064d8999b8aaba32bc398ad39143e9ee1439f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4544. Error in deleting blocks should not do check disk, for all types of errors. Contributed by Arpit Agarwal.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1453436 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/03/13 9:18 AM",
      "commitName": "456064d8999b8aaba32bc398ad39143e9ee1439f",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "18/01/13 10:39 AM",
      "commitNameOld": "d3d350ef0f115e1baa9d12e35eb0f6dee21d55c3",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 46.94,
      "commitsBetweenForRepo": 175,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,78 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     if (cmd \u003d\u003d null)\n       return true;\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n       dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         if (dn.blockScanner !\u003d null) {\n           dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n         }\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n-        dn.checkDiskError();\n+        // Exceptions caught here are not expected to be disk-related.\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_REGISTER:\n       // namenode requested a registration - at start or if NN lost contact\n       LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n       actor.reRegister();\n       break;\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    if (cmd \u003d\u003d null)\n      return true;\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        if (dn.blockScanner !\u003d null) {\n          dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n        }\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        // Exceptions caught here are not expected to be disk-related.\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_REGISTER:\n      // namenode requested a registration - at start or if NN lost contact\n      LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n      actor.reRegister();\n      break;\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "380870d54453c1113d46d0f070f4e19b6cea7b8c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3832. Remove protocol methods related to DistributedUpgrade. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1376139 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/08/12 9:59 AM",
      "commitName": "380870d54453c1113d46d0f070f4e19b6cea7b8c",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "21/08/12 2:18 PM",
      "commitNameOld": "6c0ccb5989c2053f5a1ebab0dd9fdb7b4019fda8",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.82,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,82 +1,78 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     if (cmd \u003d\u003d null)\n       return true;\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n       dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         if (dn.blockScanner !\u003d null) {\n           dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n         }\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         dn.checkDiskError();\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_REGISTER:\n       // namenode requested a registration - at start or if NN lost contact\n       LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n       actor.reRegister();\n       break;\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n-    case UpgradeCommand.UC_ACTION_START_UPGRADE:\n-      // start distributed upgrade here\n-      LOG.warn(\"Distibuted upgrade is no longer supported\");\n-      break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    if (cmd \u003d\u003d null)\n      return true;\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        if (dn.blockScanner !\u003d null) {\n          dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n        }\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        dn.checkDiskError();\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_REGISTER:\n      // namenode requested a registration - at start or if NN lost contact\n      LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n      actor.reRegister();\n      break;\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "6c0ccb5989c2053f5a1ebab0dd9fdb7b4019fda8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2686. Remove DistributedUpgrade related code. Contributed by Suresh Srinivas\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1375800 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/08/12 2:18 PM",
      "commitName": "6c0ccb5989c2053f5a1ebab0dd9fdb7b4019fda8",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "06/07/12 11:59 AM",
      "commitNameOld": "fb95fce24056c0b0aa5b77683c684fe1b68c4f76",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 46.1,
      "commitsBetweenForRepo": 262,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,82 +1,82 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     if (cmd \u003d\u003d null)\n       return true;\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n       dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         if (dn.blockScanner !\u003d null) {\n           dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n         }\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         dn.checkDiskError();\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_REGISTER:\n       // namenode requested a registration - at start or if NN lost contact\n       LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n       actor.reRegister();\n       break;\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case UpgradeCommand.UC_ACTION_START_UPGRADE:\n       // start distributed upgrade here\n-      processDistributedUpgradeCommand((UpgradeCommand)cmd);\n+      LOG.warn(\"Distibuted upgrade is no longer supported\");\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    if (cmd \u003d\u003d null)\n      return true;\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        if (dn.blockScanner !\u003d null) {\n          dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n        }\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        dn.checkDiskError();\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_REGISTER:\n      // namenode requested a registration - at start or if NN lost contact\n      LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n      actor.reRegister();\n      break;\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case UpgradeCommand.UC_ACTION_START_UPGRADE:\n      // start distributed upgrade here\n      LOG.warn(\"Distibuted upgrade is no longer supported\");\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "fb95fce24056c0b0aa5b77683c684fe1b68c4f76": {
      "type": "Ybodychange",
      "commitMessage": "Fix issue with NN/DN re-registration.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1358347 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/07/12 11:59 AM",
      "commitName": "fb95fce24056c0b0aa5b77683c684fe1b68c4f76",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "25/05/12 12:04 AM",
      "commitNameOld": "befd45fcb193a944dd144a9ebeca006b2b73cb0d",
      "commitAuthorOld": "Harsh J",
      "daysBetweenCommits": 42.5,
      "commitsBetweenForRepo": 180,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,82 +1,82 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     if (cmd \u003d\u003d null)\n       return true;\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n       dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         if (dn.blockScanner !\u003d null) {\n           dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n         }\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         dn.checkDiskError();\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_REGISTER:\n       // namenode requested a registration - at start or if NN lost contact\n       LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n       actor.reRegister();\n       break;\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case UpgradeCommand.UC_ACTION_START_UPGRADE:\n       // start distributed upgrade here\n       processDistributedUpgradeCommand((UpgradeCommand)cmd);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n-        dn.blockPoolTokenSecretManager.setKeys(\n+        dn.blockPoolTokenSecretManager.addKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         LOG.info(\"Updating balance throttler bandwidth from \"\n             + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n             + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    if (cmd \u003d\u003d null)\n      return true;\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        if (dn.blockScanner !\u003d null) {\n          dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n        }\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        dn.checkDiskError();\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_REGISTER:\n      // namenode requested a registration - at start or if NN lost contact\n      LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n      actor.reRegister();\n      break;\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case UpgradeCommand.UC_ACTION_START_UPGRADE:\n      // start distributed upgrade here\n      processDistributedUpgradeCommand((UpgradeCommand)cmd);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.addKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "befd45fcb193a944dd144a9ebeca006b2b73cb0d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2391. Newly set BalancerBandwidth value is not displayed anywhere. (harsh)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1342520 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/05/12 12:04 AM",
      "commitName": "befd45fcb193a944dd144a9ebeca006b2b73cb0d",
      "commitAuthor": "Harsh J",
      "commitDateOld": "17/05/12 3:30 PM",
      "commitNameOld": "5258d6bf3fb8090739cf96f5089f96cee87393c4",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 7.36,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,79 +1,82 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     if (cmd \u003d\u003d null)\n       return true;\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n       dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         if (dn.blockScanner !\u003d null) {\n           dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n         }\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         dn.checkDiskError();\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_REGISTER:\n       // namenode requested a registration - at start or if NN lost contact\n       LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n       actor.reRegister();\n       break;\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case UpgradeCommand.UC_ACTION_START_UPGRADE:\n       // start distributed upgrade here\n       processDistributedUpgradeCommand((UpgradeCommand)cmd);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n       dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.setKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n+        LOG.info(\"Updating balance throttler bandwidth from \"\n+            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n+            + \"to: \" + bandwidth + \" bytes/s.\");\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    if (cmd \u003d\u003d null)\n      return true;\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        if (dn.blockScanner !\u003d null) {\n          dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n        }\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        dn.checkDiskError();\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_REGISTER:\n      // namenode requested a registration - at start or if NN lost contact\n      LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n      actor.reRegister();\n      break;\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case UpgradeCommand.UC_ACTION_START_UPGRADE:\n      // start distributed upgrade here\n      processDistributedUpgradeCommand((UpgradeCommand)cmd);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.setKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        LOG.info(\"Updating balance throttler bandwidth from \"\n            + dxcs.balanceThrottler.getBandwidth() + \" bytes/s \"\n            + \"to: \" + bandwidth + \" bytes/s.\");\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "5258d6bf3fb8090739cf96f5089f96cee87393c4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3391. Fix InvalidateBlocks to compare blocks including their generation stamps. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1339897 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/05/12 3:30 PM",
      "commitName": "5258d6bf3fb8090739cf96f5089f96cee87393c4",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "31/03/12 8:41 PM",
      "commitNameOld": "0663dbaac0a19719ddf9cd4290ba893bfca69da2",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 46.78,
      "commitsBetweenForRepo": 355,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,79 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     if (cmd \u003d\u003d null)\n       return true;\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n       dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         if (dn.blockScanner !\u003d null) {\n           dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n         }\n         // using global fsdataset\n         dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         dn.checkDiskError();\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_REGISTER:\n       // namenode requested a registration - at start or if NN lost contact\n       LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n       actor.reRegister();\n       break;\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case UpgradeCommand.UC_ACTION_START_UPGRADE:\n       // start distributed upgrade here\n       processDistributedUpgradeCommand((UpgradeCommand)cmd);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n-      dn.recoverBlocks(((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n+      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n+      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.setKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    if (cmd \u003d\u003d null)\n      return true;\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        if (dn.blockScanner !\u003d null) {\n          dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n        }\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        dn.checkDiskError();\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_REGISTER:\n      // namenode requested a registration - at start or if NN lost contact\n      LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n      actor.reRegister();\n      break;\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case UpgradeCommand.UC_ACTION_START_UPGRADE:\n      // start distributed upgrade here\n      processDistributedUpgradeCommand((UpgradeCommand)cmd);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      String who \u003d \"NameNode at \" + actor.getNNSocketAddress();\n      dn.recoverBlocks(who, ((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.setKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "3e582c690cb8c29267c8c8a741a21eea918f0145": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3082. Clean up FSDatasetInterface and change DataNode.data to package private. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1300392 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/03/12 3:52 PM",
      "commitName": "3e582c690cb8c29267c8c8a741a21eea918f0145",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "01/03/12 5:32 PM",
      "commitNameOld": "7be4e5bd222c6f1c40f88ee8b24b1587e157a87e",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 11.89,
      "commitsBetweenForRepo": 60,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,78 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     if (cmd \u003d\u003d null)\n       return true;\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n       dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         if (dn.blockScanner !\u003d null) {\n           dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n         }\n         // using global fsdataset\n-        dn.data.invalidate(bcmd.getBlockPoolId(), toDelete);\n+        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         dn.checkDiskError();\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n       // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_REGISTER:\n       // namenode requested a registration - at start or if NN lost contact\n       LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n       actor.reRegister();\n       break;\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case UpgradeCommand.UC_ACTION_START_UPGRADE:\n       // start distributed upgrade here\n       processDistributedUpgradeCommand((UpgradeCommand)cmd);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       dn.recoverBlocks(((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.setKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    if (cmd \u003d\u003d null)\n      return true;\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        if (dn.blockScanner !\u003d null) {\n          dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n        }\n        // using global fsdataset\n        dn.getFSDataset().invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        dn.checkDiskError();\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_REGISTER:\n      // namenode requested a registration - at start or if NN lost contact\n      LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n      actor.reRegister();\n      break;\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case UpgradeCommand.UC_ACTION_START_UPGRADE:\n      // start distributed upgrade here\n      processDistributedUpgradeCommand((UpgradeCommand)cmd);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      dn.recoverBlocks(((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.setKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    },
    "978a8050e28b2afb193a3e00d82a8475fa4d2428": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2920. fix remaining TODO items. Contributed by Aaron T. Myers and Todd Lipcon.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1294923 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/02/12 5:09 PM",
      "commitName": "978a8050e28b2afb193a3e00d82a8475fa4d2428",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "13/02/12 1:00 PM",
      "commitNameOld": "db187cf40ee307524c48cededd58710a4dfb4812",
      "commitAuthorOld": "",
      "daysBetweenCommits": 15.17,
      "commitsBetweenForRepo": 110,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,78 @@\n   private boolean processCommandFromActive(DatanodeCommand cmd,\n       BPServiceActor actor) throws IOException {\n     if (cmd \u003d\u003d null)\n       return true;\n     final BlockCommand bcmd \u003d \n       cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n \n     switch(cmd.getAction()) {\n     case DatanodeProtocol.DNA_TRANSFER:\n       // Send a copy of a block to another datanode\n       dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n       dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n       break;\n     case DatanodeProtocol.DNA_INVALIDATE:\n       //\n       // Some local block(s) are obsolete and can be \n       // safely garbage-collected.\n       //\n       Block toDelete[] \u003d bcmd.getBlocks();\n       try {\n         if (dn.blockScanner !\u003d null) {\n           dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n         }\n         // using global fsdataset\n         dn.data.invalidate(bcmd.getBlockPoolId(), toDelete);\n       } catch(IOException e) {\n         dn.checkDiskError();\n         throw e;\n       }\n       dn.metrics.incrBlocksRemoved(toDelete.length);\n       break;\n     case DatanodeProtocol.DNA_SHUTDOWN:\n       // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n+      // See HDFS-2987.\n       throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n     case DatanodeProtocol.DNA_REGISTER:\n       // namenode requested a registration - at start or if NN lost contact\n       LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n       actor.reRegister();\n       break;\n     case DatanodeProtocol.DNA_FINALIZE:\n       String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n       assert getBlockPoolId().equals(bp) :\n         \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n         \"for other block pool \" + bp;\n \n       dn.finalizeUpgradeForPool(bp);\n       break;\n     case UpgradeCommand.UC_ACTION_START_UPGRADE:\n       // start distributed upgrade here\n       processDistributedUpgradeCommand((UpgradeCommand)cmd);\n       break;\n     case DatanodeProtocol.DNA_RECOVERBLOCK:\n       dn.recoverBlocks(((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n       break;\n     case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n       if (dn.isBlockTokenEnabled) {\n         dn.blockPoolTokenSecretManager.setKeys(\n             getBlockPoolId(), \n             ((KeyUpdateCommand) cmd).getExportedKeys());\n       }\n       break;\n     case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n       LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n       long bandwidth \u003d\n                  ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n       if (bandwidth \u003e 0) {\n         DataXceiverServer dxcs \u003d\n                      (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n         dxcs.balanceThrottler.setBandwidth(bandwidth);\n       }\n       break;\n     default:\n       LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean processCommandFromActive(DatanodeCommand cmd,\n      BPServiceActor actor) throws IOException {\n    if (cmd \u003d\u003d null)\n      return true;\n    final BlockCommand bcmd \u003d \n      cmd instanceof BlockCommand? (BlockCommand)cmd: null;\n\n    switch(cmd.getAction()) {\n    case DatanodeProtocol.DNA_TRANSFER:\n      // Send a copy of a block to another datanode\n      dn.transferBlocks(bcmd.getBlockPoolId(), bcmd.getBlocks(), bcmd.getTargets());\n      dn.metrics.incrBlocksReplicated(bcmd.getBlocks().length);\n      break;\n    case DatanodeProtocol.DNA_INVALIDATE:\n      //\n      // Some local block(s) are obsolete and can be \n      // safely garbage-collected.\n      //\n      Block toDelete[] \u003d bcmd.getBlocks();\n      try {\n        if (dn.blockScanner !\u003d null) {\n          dn.blockScanner.deleteBlocks(bcmd.getBlockPoolId(), toDelete);\n        }\n        // using global fsdataset\n        dn.data.invalidate(bcmd.getBlockPoolId(), toDelete);\n      } catch(IOException e) {\n        dn.checkDiskError();\n        throw e;\n      }\n      dn.metrics.incrBlocksRemoved(toDelete.length);\n      break;\n    case DatanodeProtocol.DNA_SHUTDOWN:\n      // TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command\n      // See HDFS-2987.\n      throw new UnsupportedOperationException(\"Received unimplemented DNA_SHUTDOWN\");\n    case DatanodeProtocol.DNA_REGISTER:\n      // namenode requested a registration - at start or if NN lost contact\n      LOG.info(\"DatanodeCommand action: DNA_REGISTER\");\n      actor.reRegister();\n      break;\n    case DatanodeProtocol.DNA_FINALIZE:\n      String bp \u003d ((FinalizeCommand) cmd).getBlockPoolId(); \n      assert getBlockPoolId().equals(bp) :\n        \"BP \" + getBlockPoolId() + \" received DNA_FINALIZE \" +\n        \"for other block pool \" + bp;\n\n      dn.finalizeUpgradeForPool(bp);\n      break;\n    case UpgradeCommand.UC_ACTION_START_UPGRADE:\n      // start distributed upgrade here\n      processDistributedUpgradeCommand((UpgradeCommand)cmd);\n      break;\n    case DatanodeProtocol.DNA_RECOVERBLOCK:\n      dn.recoverBlocks(((BlockRecoveryCommand)cmd).getRecoveringBlocks());\n      break;\n    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_ACCESSKEYUPDATE\");\n      if (dn.isBlockTokenEnabled) {\n        dn.blockPoolTokenSecretManager.setKeys(\n            getBlockPoolId(), \n            ((KeyUpdateCommand) cmd).getExportedKeys());\n      }\n      break;\n    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:\n      LOG.info(\"DatanodeCommand action: DNA_BALANCERBANDWIDTHUPDATE\");\n      long bandwidth \u003d\n                 ((BalancerBandwidthCommand) cmd).getBalancerBandwidthValue();\n      if (bandwidth \u003e 0) {\n        DataXceiverServer dxcs \u003d\n                     (DataXceiverServer) dn.dataXceiverServer.getRunnable();\n        dxcs.balanceThrottler.setBandwidth(bandwidth);\n      }\n      break;\n    default:\n      LOG.warn(\"Unknown DatanodeCommand action: \" + cmd.getAction());\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java",
      "extendedDetails": {}
    }
  }
}