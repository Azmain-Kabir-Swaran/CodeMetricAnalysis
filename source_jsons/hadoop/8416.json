{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSDirDeleteOp.java",
  "functionName": "deleteForEditLog",
  "functionId": "deleteForEditLog___fsd-FSDirectory__iip-INodesInPath__mtime-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirDeleteOp.java",
  "functionStartLine": 131,
  "functionEndLine": 153,
  "numCommitsSeen": 37,
  "timeTaken": 4272,
  "changeHistory": [
    "743c2e9071f4a73e0196ad4ca005b767758642b9",
    "3565c9af17ab05bf9e7f68b71b6c6850df772bb9",
    "44f48ee96ee6b2a3909911c37bfddb0c963d5ffc",
    "a49cc74b4c72195dee1dfb6f9548e5e411dff553",
    "b2c85db86c9a62b0a03ee87547265077f664970a",
    "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
    "24315e7d374a1ddd4329b64350cf96fc9ab6f59c"
  ],
  "changeHistoryShort": {
    "743c2e9071f4a73e0196ad4ca005b767758642b9": "Ybodychange",
    "3565c9af17ab05bf9e7f68b71b6c6850df772bb9": "Ymultichange(Yparameterchange,Ybodychange)",
    "44f48ee96ee6b2a3909911c37bfddb0c963d5ffc": "Ybodychange",
    "a49cc74b4c72195dee1dfb6f9548e5e411dff553": "Ybodychange",
    "b2c85db86c9a62b0a03ee87547265077f664970a": "Ybodychange",
    "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63": "Ybodychange",
    "24315e7d374a1ddd4329b64350cf96fc9ab6f59c": "Yintroduced"
  },
  "changeHistoryDetails": {
    "743c2e9071f4a73e0196ad4ca005b767758642b9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15316. Deletion failure should not remove directory from snapshottables. Contributed by hemanthboyina\n",
      "commitDate": "13/05/20 2:31 AM",
      "commitName": "743c2e9071f4a73e0196ad4ca005b767758642b9",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "15/11/19 12:35 PM",
      "commitNameOld": "67f2c491fe3cd400605fb6082fd3504bc5e97037",
      "commitAuthorOld": "Hui Fei",
      "daysBetweenCommits": 179.54,
      "commitsBetweenForRepo": 613,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,23 @@\n   static void deleteForEditLog(FSDirectory fsd, INodesInPath iip, long mtime)\n       throws IOException {\n     assert fsd.hasWriteLock();\n     FSNamesystem fsn \u003d fsd.getFSNamesystem();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n     List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n     if (!deleteAllowed(iip)) {\n       return;\n     }\n     List\u003cINodeDirectory\u003e snapshottableDirs \u003d new ArrayList\u003c\u003e();\n     FSDirSnapshotOp.checkSnapshot(fsd, iip, snapshottableDirs);\n     boolean filesRemoved \u003d unprotectedDelete(fsd, iip,\n         new ReclaimContext(fsd.getBlockStoragePolicySuite(),\n             collectedBlocks, removedINodes, removedUCFiles),\n         mtime);\n-    fsn.removeSnapshottableDirs(snapshottableDirs);\n \n     if (filesRemoved) {\n+      fsn.removeSnapshottableDirs(snapshottableDirs);\n       fsn.removeLeasesAndINodes(removedUCFiles, removedINodes, false);\n       fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static void deleteForEditLog(FSDirectory fsd, INodesInPath iip, long mtime)\n      throws IOException {\n    assert fsd.hasWriteLock();\n    FSNamesystem fsn \u003d fsd.getFSNamesystem();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n    List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n    if (!deleteAllowed(iip)) {\n      return;\n    }\n    List\u003cINodeDirectory\u003e snapshottableDirs \u003d new ArrayList\u003c\u003e();\n    FSDirSnapshotOp.checkSnapshot(fsd, iip, snapshottableDirs);\n    boolean filesRemoved \u003d unprotectedDelete(fsd, iip,\n        new ReclaimContext(fsd.getBlockStoragePolicySuite(),\n            collectedBlocks, removedINodes, removedUCFiles),\n        mtime);\n\n    if (filesRemoved) {\n      fsn.removeSnapshottableDirs(snapshottableDirs);\n      fsn.removeLeasesAndINodes(removedUCFiles, removedINodes, false);\n      fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirDeleteOp.java",
      "extendedDetails": {}
    },
    "3565c9af17ab05bf9e7f68b71b6c6850df772bb9": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-10979. Pass IIP for FSDirDeleteOp methods. Contributed by Daryn Sharp.\n",
      "commitDate": "07/10/16 12:15 PM",
      "commitName": "3565c9af17ab05bf9e7f68b71b6c6850df772bb9",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-10979. Pass IIP for FSDirDeleteOp methods. Contributed by Daryn Sharp.\n",
          "commitDate": "07/10/16 12:15 PM",
          "commitName": "3565c9af17ab05bf9e7f68b71b6c6850df772bb9",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "04/10/16 1:05 PM",
          "commitNameOld": "44f48ee96ee6b2a3909911c37bfddb0c963d5ffc",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 2.97,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,23 @@\n-  static void deleteForEditLog(FSDirectory fsd, String src, long mtime)\n+  static void deleteForEditLog(FSDirectory fsd, INodesInPath iip, long mtime)\n       throws IOException {\n     assert fsd.hasWriteLock();\n     FSNamesystem fsn \u003d fsd.getFSNamesystem();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n     List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n-\n-    final INodesInPath iip \u003d fsd.getINodesInPath4Write(\n-        FSDirectory.normalizePath(src), false);\n-    if (!deleteAllowed(iip, src)) {\n+    if (!deleteAllowed(iip)) {\n       return;\n     }\n     List\u003cINodeDirectory\u003e snapshottableDirs \u003d new ArrayList\u003c\u003e();\n     FSDirSnapshotOp.checkSnapshot(fsd, iip, snapshottableDirs);\n     boolean filesRemoved \u003d unprotectedDelete(fsd, iip,\n         new ReclaimContext(fsd.getBlockStoragePolicySuite(),\n             collectedBlocks, removedINodes, removedUCFiles),\n         mtime);\n     fsn.removeSnapshottableDirs(snapshottableDirs);\n \n     if (filesRemoved) {\n       fsn.removeLeasesAndINodes(removedUCFiles, removedINodes, false);\n       fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static void deleteForEditLog(FSDirectory fsd, INodesInPath iip, long mtime)\n      throws IOException {\n    assert fsd.hasWriteLock();\n    FSNamesystem fsn \u003d fsd.getFSNamesystem();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n    List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n    if (!deleteAllowed(iip)) {\n      return;\n    }\n    List\u003cINodeDirectory\u003e snapshottableDirs \u003d new ArrayList\u003c\u003e();\n    FSDirSnapshotOp.checkSnapshot(fsd, iip, snapshottableDirs);\n    boolean filesRemoved \u003d unprotectedDelete(fsd, iip,\n        new ReclaimContext(fsd.getBlockStoragePolicySuite(),\n            collectedBlocks, removedINodes, removedUCFiles),\n        mtime);\n    fsn.removeSnapshottableDirs(snapshottableDirs);\n\n    if (filesRemoved) {\n      fsn.removeLeasesAndINodes(removedUCFiles, removedINodes, false);\n      fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirDeleteOp.java",
          "extendedDetails": {
            "oldValue": "[fsd-FSDirectory, src-String, mtime-long]",
            "newValue": "[fsd-FSDirectory, iip-INodesInPath, mtime-long]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10979. Pass IIP for FSDirDeleteOp methods. Contributed by Daryn Sharp.\n",
          "commitDate": "07/10/16 12:15 PM",
          "commitName": "3565c9af17ab05bf9e7f68b71b6c6850df772bb9",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "04/10/16 1:05 PM",
          "commitNameOld": "44f48ee96ee6b2a3909911c37bfddb0c963d5ffc",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 2.97,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,23 @@\n-  static void deleteForEditLog(FSDirectory fsd, String src, long mtime)\n+  static void deleteForEditLog(FSDirectory fsd, INodesInPath iip, long mtime)\n       throws IOException {\n     assert fsd.hasWriteLock();\n     FSNamesystem fsn \u003d fsd.getFSNamesystem();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n     List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n-\n-    final INodesInPath iip \u003d fsd.getINodesInPath4Write(\n-        FSDirectory.normalizePath(src), false);\n-    if (!deleteAllowed(iip, src)) {\n+    if (!deleteAllowed(iip)) {\n       return;\n     }\n     List\u003cINodeDirectory\u003e snapshottableDirs \u003d new ArrayList\u003c\u003e();\n     FSDirSnapshotOp.checkSnapshot(fsd, iip, snapshottableDirs);\n     boolean filesRemoved \u003d unprotectedDelete(fsd, iip,\n         new ReclaimContext(fsd.getBlockStoragePolicySuite(),\n             collectedBlocks, removedINodes, removedUCFiles),\n         mtime);\n     fsn.removeSnapshottableDirs(snapshottableDirs);\n \n     if (filesRemoved) {\n       fsn.removeLeasesAndINodes(removedUCFiles, removedINodes, false);\n       fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static void deleteForEditLog(FSDirectory fsd, INodesInPath iip, long mtime)\n      throws IOException {\n    assert fsd.hasWriteLock();\n    FSNamesystem fsn \u003d fsd.getFSNamesystem();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n    List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n    if (!deleteAllowed(iip)) {\n      return;\n    }\n    List\u003cINodeDirectory\u003e snapshottableDirs \u003d new ArrayList\u003c\u003e();\n    FSDirSnapshotOp.checkSnapshot(fsd, iip, snapshottableDirs);\n    boolean filesRemoved \u003d unprotectedDelete(fsd, iip,\n        new ReclaimContext(fsd.getBlockStoragePolicySuite(),\n            collectedBlocks, removedINodes, removedUCFiles),\n        mtime);\n    fsn.removeSnapshottableDirs(snapshottableDirs);\n\n    if (filesRemoved) {\n      fsn.removeLeasesAndINodes(removedUCFiles, removedINodes, false);\n      fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirDeleteOp.java",
          "extendedDetails": {}
        }
      ]
    },
    "44f48ee96ee6b2a3909911c37bfddb0c963d5ffc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10956. Remove rename/delete performance penalty when not using snapshots. Contributed by Daryn Sharp.\n",
      "commitDate": "04/10/16 1:05 PM",
      "commitName": "44f48ee96ee6b2a3909911c37bfddb0c963d5ffc",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "17/08/16 1:53 PM",
      "commitNameOld": "869393643de23dcb010cc33091c8eb398de0fd6c",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 47.97,
      "commitsBetweenForRepo": 285,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,26 @@\n   static void deleteForEditLog(FSDirectory fsd, String src, long mtime)\n       throws IOException {\n     assert fsd.hasWriteLock();\n     FSNamesystem fsn \u003d fsd.getFSNamesystem();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n     List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n \n     final INodesInPath iip \u003d fsd.getINodesInPath4Write(\n         FSDirectory.normalizePath(src), false);\n     if (!deleteAllowed(iip, src)) {\n       return;\n     }\n     List\u003cINodeDirectory\u003e snapshottableDirs \u003d new ArrayList\u003c\u003e();\n-    FSDirSnapshotOp.checkSnapshot(iip.getLastINode(), snapshottableDirs);\n+    FSDirSnapshotOp.checkSnapshot(fsd, iip, snapshottableDirs);\n     boolean filesRemoved \u003d unprotectedDelete(fsd, iip,\n         new ReclaimContext(fsd.getBlockStoragePolicySuite(),\n             collectedBlocks, removedINodes, removedUCFiles),\n         mtime);\n     fsn.removeSnapshottableDirs(snapshottableDirs);\n \n     if (filesRemoved) {\n       fsn.removeLeasesAndINodes(removedUCFiles, removedINodes, false);\n       fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static void deleteForEditLog(FSDirectory fsd, String src, long mtime)\n      throws IOException {\n    assert fsd.hasWriteLock();\n    FSNamesystem fsn \u003d fsd.getFSNamesystem();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n    List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n\n    final INodesInPath iip \u003d fsd.getINodesInPath4Write(\n        FSDirectory.normalizePath(src), false);\n    if (!deleteAllowed(iip, src)) {\n      return;\n    }\n    List\u003cINodeDirectory\u003e snapshottableDirs \u003d new ArrayList\u003c\u003e();\n    FSDirSnapshotOp.checkSnapshot(fsd, iip, snapshottableDirs);\n    boolean filesRemoved \u003d unprotectedDelete(fsd, iip,\n        new ReclaimContext(fsd.getBlockStoragePolicySuite(),\n            collectedBlocks, removedINodes, removedUCFiles),\n        mtime);\n    fsn.removeSnapshottableDirs(snapshottableDirs);\n\n    if (filesRemoved) {\n      fsn.removeLeasesAndINodes(removedUCFiles, removedINodes, false);\n      fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirDeleteOp.java",
      "extendedDetails": {}
    },
    "a49cc74b4c72195dee1dfb6f9548e5e411dff553": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9129. Move the safemode block count into BlockManager. Contributed by Mingliang Liu.\n",
      "commitDate": "01/12/15 4:09 PM",
      "commitName": "a49cc74b4c72195dee1dfb6f9548e5e411dff553",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "21/10/15 4:58 PM",
      "commitNameOld": "3dadf369d550c2ae393b751cb5a184dbfe2814df",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 41.01,
      "commitsBetweenForRepo": 316,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,26 @@\n   static void deleteForEditLog(FSDirectory fsd, String src, long mtime)\n       throws IOException {\n     assert fsd.hasWriteLock();\n     FSNamesystem fsn \u003d fsd.getFSNamesystem();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n     List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n \n     final INodesInPath iip \u003d fsd.getINodesInPath4Write(\n         FSDirectory.normalizePath(src), false);\n     if (!deleteAllowed(iip, src)) {\n       return;\n     }\n     List\u003cINodeDirectory\u003e snapshottableDirs \u003d new ArrayList\u003c\u003e();\n     FSDirSnapshotOp.checkSnapshot(iip.getLastINode(), snapshottableDirs);\n     boolean filesRemoved \u003d unprotectedDelete(fsd, iip,\n         new ReclaimContext(fsd.getBlockStoragePolicySuite(),\n             collectedBlocks, removedINodes, removedUCFiles),\n         mtime);\n     fsn.removeSnapshottableDirs(snapshottableDirs);\n \n     if (filesRemoved) {\n       fsn.removeLeasesAndINodes(removedUCFiles, removedINodes, false);\n-      fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n+      fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static void deleteForEditLog(FSDirectory fsd, String src, long mtime)\n      throws IOException {\n    assert fsd.hasWriteLock();\n    FSNamesystem fsn \u003d fsd.getFSNamesystem();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n    List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n\n    final INodesInPath iip \u003d fsd.getINodesInPath4Write(\n        FSDirectory.normalizePath(src), false);\n    if (!deleteAllowed(iip, src)) {\n      return;\n    }\n    List\u003cINodeDirectory\u003e snapshottableDirs \u003d new ArrayList\u003c\u003e();\n    FSDirSnapshotOp.checkSnapshot(iip.getLastINode(), snapshottableDirs);\n    boolean filesRemoved \u003d unprotectedDelete(fsd, iip,\n        new ReclaimContext(fsd.getBlockStoragePolicySuite(),\n            collectedBlocks, removedINodes, removedUCFiles),\n        mtime);\n    fsn.removeSnapshottableDirs(snapshottableDirs);\n\n    if (filesRemoved) {\n      fsn.removeLeasesAndINodes(removedUCFiles, removedINodes, false);\n      fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirDeleteOp.java",
      "extendedDetails": {}
    },
    "b2c85db86c9a62b0a03ee87547265077f664970a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7728. Avoid updating quota usage while loading edits. Contributed by Jing Zhao.\n",
      "commitDate": "13/05/15 9:50 PM",
      "commitName": "b2c85db86c9a62b0a03ee87547265077f664970a",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "09/05/15 10:51 PM",
      "commitNameOld": "4536399d47f6c061e149e2504600804a0f1e093d",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 3.96,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,26 @@\n   static void deleteForEditLog(FSDirectory fsd, String src, long mtime)\n       throws IOException {\n     assert fsd.hasWriteLock();\n     FSNamesystem fsn \u003d fsd.getFSNamesystem();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n     List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n \n     final INodesInPath iip \u003d fsd.getINodesInPath4Write(\n         FSDirectory.normalizePath(src), false);\n     if (!deleteAllowed(iip, src)) {\n       return;\n     }\n     List\u003cINodeDirectory\u003e snapshottableDirs \u003d new ArrayList\u003c\u003e();\n     FSDirSnapshotOp.checkSnapshot(iip.getLastINode(), snapshottableDirs);\n-    long filesRemoved \u003d unprotectedDelete(\n-        fsd, iip, collectedBlocks, removedINodes, removedUCFiles, mtime);\n+    boolean filesRemoved \u003d unprotectedDelete(fsd, iip,\n+        new ReclaimContext(fsd.getBlockStoragePolicySuite(),\n+            collectedBlocks, removedINodes, removedUCFiles),\n+        mtime);\n     fsn.removeSnapshottableDirs(snapshottableDirs);\n \n-    if (filesRemoved \u003e\u003d 0) {\n+    if (filesRemoved) {\n       fsn.removeLeasesAndINodes(removedUCFiles, removedINodes, false);\n       fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static void deleteForEditLog(FSDirectory fsd, String src, long mtime)\n      throws IOException {\n    assert fsd.hasWriteLock();\n    FSNamesystem fsn \u003d fsd.getFSNamesystem();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n    List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n\n    final INodesInPath iip \u003d fsd.getINodesInPath4Write(\n        FSDirectory.normalizePath(src), false);\n    if (!deleteAllowed(iip, src)) {\n      return;\n    }\n    List\u003cINodeDirectory\u003e snapshottableDirs \u003d new ArrayList\u003c\u003e();\n    FSDirSnapshotOp.checkSnapshot(iip.getLastINode(), snapshottableDirs);\n    boolean filesRemoved \u003d unprotectedDelete(fsd, iip,\n        new ReclaimContext(fsd.getBlockStoragePolicySuite(),\n            collectedBlocks, removedINodes, removedUCFiles),\n        mtime);\n    fsn.removeSnapshottableDirs(snapshottableDirs);\n\n    if (filesRemoved) {\n      fsn.removeLeasesAndINodes(removedUCFiles, removedINodes, false);\n      fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirDeleteOp.java",
      "extendedDetails": {}
    },
    "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6757. Simplify lease manager with INodeID. Contributed by Haohui Mai.\n",
      "commitDate": "08/05/15 11:04 PM",
      "commitName": "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/04/15 6:05 PM",
      "commitNameOld": "c79e7f7d997596e0c38ae4cddff2bd0910581c16",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 10.21,
      "commitsBetweenForRepo": 163,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,24 @@\n   static void deleteForEditLog(FSDirectory fsd, String src, long mtime)\n       throws IOException {\n     assert fsd.hasWriteLock();\n     FSNamesystem fsn \u003d fsd.getFSNamesystem();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n+    List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n \n     final INodesInPath iip \u003d fsd.getINodesInPath4Write(\n         FSDirectory.normalizePath(src), false);\n     if (!deleteAllowed(iip, src)) {\n       return;\n     }\n     List\u003cINodeDirectory\u003e snapshottableDirs \u003d new ArrayList\u003c\u003e();\n     FSDirSnapshotOp.checkSnapshot(iip.getLastINode(), snapshottableDirs);\n     long filesRemoved \u003d unprotectedDelete(\n-        fsd, iip, collectedBlocks, removedINodes, mtime);\n+        fsd, iip, collectedBlocks, removedINodes, removedUCFiles, mtime);\n     fsn.removeSnapshottableDirs(snapshottableDirs);\n \n     if (filesRemoved \u003e\u003d 0) {\n-      fsn.removeLeasesAndINodes(src, removedINodes, false);\n+      fsn.removeLeasesAndINodes(removedUCFiles, removedINodes, false);\n       fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static void deleteForEditLog(FSDirectory fsd, String src, long mtime)\n      throws IOException {\n    assert fsd.hasWriteLock();\n    FSNamesystem fsn \u003d fsd.getFSNamesystem();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n    List\u003cLong\u003e removedUCFiles \u003d new ChunkedArrayList\u003c\u003e();\n\n    final INodesInPath iip \u003d fsd.getINodesInPath4Write(\n        FSDirectory.normalizePath(src), false);\n    if (!deleteAllowed(iip, src)) {\n      return;\n    }\n    List\u003cINodeDirectory\u003e snapshottableDirs \u003d new ArrayList\u003c\u003e();\n    FSDirSnapshotOp.checkSnapshot(iip.getLastINode(), snapshottableDirs);\n    long filesRemoved \u003d unprotectedDelete(\n        fsd, iip, collectedBlocks, removedINodes, removedUCFiles, mtime);\n    fsn.removeSnapshottableDirs(snapshottableDirs);\n\n    if (filesRemoved \u003e\u003d 0) {\n      fsn.removeLeasesAndINodes(removedUCFiles, removedINodes, false);\n      fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirDeleteOp.java",
      "extendedDetails": {}
    },
    "24315e7d374a1ddd4329b64350cf96fc9ab6f59c": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7573. Consolidate the implementation of delete() into a single class. Contributed by Haohui Mai.\n",
      "commitDate": "17/01/15 12:56 PM",
      "commitName": "24315e7d374a1ddd4329b64350cf96fc9ab6f59c",
      "commitAuthor": "Haohui Mai",
      "diff": "@@ -0,0 +1,23 @@\n+  static void deleteForEditLog(FSDirectory fsd, String src, long mtime)\n+      throws IOException {\n+    assert fsd.hasWriteLock();\n+    FSNamesystem fsn \u003d fsd.getFSNamesystem();\n+    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n+    List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n+\n+    final INodesInPath iip \u003d fsd.getINodesInPath4Write(\n+        FSDirectory.normalizePath(src), false);\n+    if (!deleteAllowed(iip, src)) {\n+      return;\n+    }\n+    List\u003cINodeDirectory\u003e snapshottableDirs \u003d new ArrayList\u003c\u003e();\n+    FSDirSnapshotOp.checkSnapshot(iip.getLastINode(), snapshottableDirs);\n+    long filesRemoved \u003d unprotectedDelete(\n+        fsd, iip, collectedBlocks, removedINodes, mtime);\n+    fsn.removeSnapshottableDirs(snapshottableDirs);\n+\n+    if (filesRemoved \u003e\u003d 0) {\n+      fsn.removeLeasesAndINodes(src, removedINodes, false);\n+      fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static void deleteForEditLog(FSDirectory fsd, String src, long mtime)\n      throws IOException {\n    assert fsd.hasWriteLock();\n    FSNamesystem fsn \u003d fsd.getFSNamesystem();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    List\u003cINode\u003e removedINodes \u003d new ChunkedArrayList\u003c\u003e();\n\n    final INodesInPath iip \u003d fsd.getINodesInPath4Write(\n        FSDirectory.normalizePath(src), false);\n    if (!deleteAllowed(iip, src)) {\n      return;\n    }\n    List\u003cINodeDirectory\u003e snapshottableDirs \u003d new ArrayList\u003c\u003e();\n    FSDirSnapshotOp.checkSnapshot(iip.getLastINode(), snapshottableDirs);\n    long filesRemoved \u003d unprotectedDelete(\n        fsd, iip, collectedBlocks, removedINodes, mtime);\n    fsn.removeSnapshottableDirs(snapshottableDirs);\n\n    if (filesRemoved \u003e\u003d 0) {\n      fsn.removeLeasesAndINodes(src, removedINodes, false);\n      fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirDeleteOp.java"
    }
  }
}