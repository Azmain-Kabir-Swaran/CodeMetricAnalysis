{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "OpenFileCtx.java",
  "functionName": "streamCleanup",
  "functionId": "streamCleanup___handle-FileHandle__streamTimeout-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
  "functionStartLine": 939,
  "functionEndLine": 957,
  "numCommitsSeen": 68,
  "timeTaken": 4137,
  "changeHistory": [
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
    "d6602b5f39833611b4afa4581552f6c4c37e23a8",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f",
    "42391d260da400593812396c1ffd45d1a371d3cb",
    "3fccdec6e0a8e9305fc75921211c3745eddb9c45",
    "28e3d09230971b32f74284311931525cb7ad1b7c",
    "37f587563a943a827fbff865f5302bac6d202415"
  ],
  "changeHistoryShort": {
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": "Ybodychange",
    "d6602b5f39833611b4afa4581552f6c4c37e23a8": "Ymultichange(Yparameterchange,Ybodychange)",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": "Ybodychange",
    "42391d260da400593812396c1ffd45d1a371d3cb": "Ybodychange",
    "3fccdec6e0a8e9305fc75921211c3745eddb9c45": "Ybodychange",
    "28e3d09230971b32f74284311931525cb7ad1b7c": "Ymultichange(Ymodifierchange,Ybodychange)",
    "37f587563a943a827fbff865f5302bac6d202415": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10571. Use Log.*(Object, Throwable) overload to log exceptions.\nContributed by Andras Bokor.\n",
      "commitDate": "14/02/18 8:20 AM",
      "commitName": "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "10/10/17 10:38 AM",
      "commitNameOld": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
      "commitAuthorOld": "Jitendra Pandey",
      "daysBetweenCommits": 126.95,
      "commitsBetweenForRepo": 833,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n   public synchronized boolean streamCleanup(FileHandle handle,\n                                             long streamTimeout) {\n     Preconditions\n         .checkState(streamTimeout \u003e\u003d NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);\n     if (!activeState) {\n       return true;\n     }\n     \n     boolean flag \u003d false;\n     // Check the stream timeout\n     if (checkStreamTimeout(streamTimeout)) {\n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"stream can be closed for fileId: \"\n-            + handle.dumpFileHandle());\n+        LOG.debug(\"stream can be closed for fileId: {}\",\n+            handle.dumpFileHandle());\n       }\n       flag \u003d true;\n     }\n     return flag;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized boolean streamCleanup(FileHandle handle,\n                                            long streamTimeout) {\n    Preconditions\n        .checkState(streamTimeout \u003e\u003d NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);\n    if (!activeState) {\n      return true;\n    }\n    \n    boolean flag \u003d false;\n    // Check the stream timeout\n    if (checkStreamTimeout(streamTimeout)) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"stream can be closed for fileId: {}\",\n            handle.dumpFileHandle());\n      }\n      flag \u003d true;\n    }\n    return flag;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "d6602b5f39833611b4afa4581552f6c4c37e23a8": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-11575. Supporting HDFS NFS gateway with Federated HDFS. Contributed by Mukul Kumar Singh.\n",
      "commitDate": "10/10/17 10:38 AM",
      "commitName": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
      "commitAuthor": "Jitendra Pandey",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-11575. Supporting HDFS NFS gateway with Federated HDFS. Contributed by Mukul Kumar Singh.\n",
          "commitDate": "10/10/17 10:38 AM",
          "commitName": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
          "commitAuthor": "Jitendra Pandey",
          "commitDateOld": "31/05/17 8:09 AM",
          "commitNameOld": "13de636b4079b077890ad10389ff350dcf8086a2",
          "commitAuthorOld": "Brahma Reddy Battula",
          "daysBetweenCommits": 132.1,
          "commitsBetweenForRepo": 969,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,19 @@\n-  public synchronized boolean streamCleanup(long fileId, long streamTimeout) {\n+  public synchronized boolean streamCleanup(FileHandle handle,\n+                                            long streamTimeout) {\n     Preconditions\n         .checkState(streamTimeout \u003e\u003d NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);\n     if (!activeState) {\n       return true;\n     }\n     \n     boolean flag \u003d false;\n     // Check the stream timeout\n     if (checkStreamTimeout(streamTimeout)) {\n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"stream can be closed for fileId: \" + fileId);\n+        LOG.debug(\"stream can be closed for fileId: \"\n+            + handle.dumpFileHandle());\n       }\n       flag \u003d true;\n     }\n     return flag;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized boolean streamCleanup(FileHandle handle,\n                                            long streamTimeout) {\n    Preconditions\n        .checkState(streamTimeout \u003e\u003d NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);\n    if (!activeState) {\n      return true;\n    }\n    \n    boolean flag \u003d false;\n    // Check the stream timeout\n    if (checkStreamTimeout(streamTimeout)) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"stream can be closed for fileId: \"\n            + handle.dumpFileHandle());\n      }\n      flag \u003d true;\n    }\n    return flag;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
          "extendedDetails": {
            "oldValue": "[fileId-long, streamTimeout-long]",
            "newValue": "[handle-FileHandle, streamTimeout-long]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-11575. Supporting HDFS NFS gateway with Federated HDFS. Contributed by Mukul Kumar Singh.\n",
          "commitDate": "10/10/17 10:38 AM",
          "commitName": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
          "commitAuthor": "Jitendra Pandey",
          "commitDateOld": "31/05/17 8:09 AM",
          "commitNameOld": "13de636b4079b077890ad10389ff350dcf8086a2",
          "commitAuthorOld": "Brahma Reddy Battula",
          "daysBetweenCommits": 132.1,
          "commitsBetweenForRepo": 969,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,19 @@\n-  public synchronized boolean streamCleanup(long fileId, long streamTimeout) {\n+  public synchronized boolean streamCleanup(FileHandle handle,\n+                                            long streamTimeout) {\n     Preconditions\n         .checkState(streamTimeout \u003e\u003d NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);\n     if (!activeState) {\n       return true;\n     }\n     \n     boolean flag \u003d false;\n     // Check the stream timeout\n     if (checkStreamTimeout(streamTimeout)) {\n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"stream can be closed for fileId: \" + fileId);\n+        LOG.debug(\"stream can be closed for fileId: \"\n+            + handle.dumpFileHandle());\n       }\n       flag \u003d true;\n     }\n     return flag;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized boolean streamCleanup(FileHandle handle,\n                                            long streamTimeout) {\n    Preconditions\n        .checkState(streamTimeout \u003e\u003d NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);\n    if (!activeState) {\n      return true;\n    }\n    \n    boolean flag \u003d false;\n    // Check the stream timeout\n    if (checkStreamTimeout(streamTimeout)) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"stream can be closed for fileId: \"\n            + handle.dumpFileHandle());\n      }\n      flag \u003d true;\n    }\n    return flag;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
          "extendedDetails": {}
        }
      ]
    },
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7423. various typos and message formatting fixes in nfs daemon and doc. (Charles Lamb via yliu)\n",
      "commitDate": "28/01/15 12:56 PM",
      "commitName": "f37849188b05a6251584de1aed5e66d5dfa7da4f",
      "commitAuthor": "yliu",
      "commitDateOld": "11/12/14 3:40 PM",
      "commitNameOld": "f6f2a3f1c73266bfedd802eacde60d8b19b81015",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 47.89,
      "commitsBetweenForRepo": 279,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   public synchronized boolean streamCleanup(long fileId, long streamTimeout) {\n     Preconditions\n         .checkState(streamTimeout \u003e\u003d NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);\n     if (!activeState) {\n       return true;\n     }\n     \n     boolean flag \u003d false;\n     // Check the stream timeout\n     if (checkStreamTimeout(streamTimeout)) {\n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"stream can be closed for fileId:\" + fileId);\n+        LOG.debug(\"stream can be closed for fileId: \" + fileId);\n       }\n       flag \u003d true;\n     }\n     return flag;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized boolean streamCleanup(long fileId, long streamTimeout) {\n    Preconditions\n        .checkState(streamTimeout \u003e\u003d NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);\n    if (!activeState) {\n      return true;\n    }\n    \n    boolean flag \u003d false;\n    // Check the stream timeout\n    if (checkStreamTimeout(streamTimeout)) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"stream can be closed for fileId: \" + fileId);\n      }\n      flag \u003d true;\n    }\n    return flag;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "42391d260da400593812396c1ffd45d1a371d3cb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6056. Clean up NFS config settings. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1598782 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/05/14 4:53 PM",
      "commitName": "42391d260da400593812396c1ffd45d1a371d3cb",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "27/05/14 1:21 PM",
      "commitNameOld": "1c867b1de8a9f4c6bb118c08c7b714bd2b8356cd",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 3.15,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   public synchronized boolean streamCleanup(long fileId, long streamTimeout) {\n     Preconditions\n-        .checkState(streamTimeout \u003e\u003d Nfs3Constant.OUTPUT_STREAM_TIMEOUT_MIN_DEFAULT);\n+        .checkState(streamTimeout \u003e\u003d NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);\n     if (!activeState) {\n       return true;\n     }\n     \n     boolean flag \u003d false;\n     // Check the stream timeout\n     if (checkStreamTimeout(streamTimeout)) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"stream can be closed for fileId:\" + fileId);\n       }\n       flag \u003d true;\n     }\n     return flag;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized boolean streamCleanup(long fileId, long streamTimeout) {\n    Preconditions\n        .checkState(streamTimeout \u003e\u003d NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);\n    if (!activeState) {\n      return true;\n    }\n    \n    boolean flag \u003d false;\n    // Check the stream timeout\n    if (checkStreamTimeout(streamTimeout)) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"stream can be closed for fileId:\" + fileId);\n      }\n      flag \u003d true;\n    }\n    return flag;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "3fccdec6e0a8e9305fc75921211c3745eddb9c45": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5364. Add OpenFileCtx cache. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1539834 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/11/13 1:49 PM",
      "commitName": "3fccdec6e0a8e9305fc75921211c3745eddb9c45",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "07/11/13 10:02 AM",
      "commitNameOld": "16c6755554cc5ecd9d4e0ba74b75b10c74bb0ab4",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 0.16,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,17 @@\n   public synchronized boolean streamCleanup(long fileId, long streamTimeout) {\n-    if (streamTimeout \u003c WriteManager.MINIMIUM_STREAM_TIMEOUT) {\n-      throw new InvalidParameterException(\"StreamTimeout\" + streamTimeout\n-          + \"ms is less than MINIMIUM_STREAM_TIMEOUT \"\n-          + WriteManager.MINIMIUM_STREAM_TIMEOUT + \"ms\");\n+    Preconditions\n+        .checkState(streamTimeout \u003e\u003d Nfs3Constant.OUTPUT_STREAM_TIMEOUT_MIN_DEFAULT);\n+    if (!activeState) {\n+      return true;\n     }\n     \n     boolean flag \u003d false;\n     // Check the stream timeout\n     if (checkStreamTimeout(streamTimeout)) {\n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"closing stream for fileId:\" + fileId);\n+        LOG.debug(\"stream can be closed for fileId:\" + fileId);\n       }\n-      cleanup();\n       flag \u003d true;\n     }\n     return flag;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized boolean streamCleanup(long fileId, long streamTimeout) {\n    Preconditions\n        .checkState(streamTimeout \u003e\u003d Nfs3Constant.OUTPUT_STREAM_TIMEOUT_MIN_DEFAULT);\n    if (!activeState) {\n      return true;\n    }\n    \n    boolean flag \u003d false;\n    // Check the stream timeout\n    if (checkStreamTimeout(streamTimeout)) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"stream can be closed for fileId:\" + fileId);\n      }\n      flag \u003d true;\n    }\n    return flag;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "28e3d09230971b32f74284311931525cb7ad1b7c": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-4971. Move IO operations out of locking in OpenFileCtx. Contributed by Jing Zhao and Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1525681 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/09/13 1:02 PM",
      "commitName": "28e3d09230971b32f74284311931525cb7ad1b7c",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-4971. Move IO operations out of locking in OpenFileCtx. Contributed by Jing Zhao and Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1525681 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/09/13 1:02 PM",
          "commitName": "28e3d09230971b32f74284311931525cb7ad1b7c",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "17/09/13 11:08 PM",
          "commitNameOld": "5e18410e06dd63113c49029894007e0878312903",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 5.58,
          "commitsBetweenForRepo": 25,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,27 +1,18 @@\n-  public boolean streamCleanup(long fileId, long streamTimeout) {\n+  public synchronized boolean streamCleanup(long fileId, long streamTimeout) {\n     if (streamTimeout \u003c WriteManager.MINIMIUM_STREAM_TIMEOUT) {\n       throw new InvalidParameterException(\"StreamTimeout\" + streamTimeout\n           + \"ms is less than MINIMIUM_STREAM_TIMEOUT \"\n           + WriteManager.MINIMIUM_STREAM_TIMEOUT + \"ms\");\n     }\n     \n     boolean flag \u003d false;\n-    if (!ctxLock.tryLock()) {\n-      if (LOG.isTraceEnabled()) {\n-        LOG.trace(\"Another thread is working on it\" + ctxLock.toString());\n+    // Check the stream timeout\n+    if (checkStreamTimeout(streamTimeout)) {\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"closing stream for fileId:\" + fileId);\n       }\n-      return flag;\n-    }\n-    \n-    try {\n-      // Check the stream timeout\n-      if (checkStreamTimeout(streamTimeout)) {\n-        LOG.info(\"closing stream for fileId:\" + fileId);\n-        cleanup();\n-        flag \u003d true;\n-      }\n-    } finally {\n-      unlockCtx();\n+      cleanup();\n+      flag \u003d true;\n     }\n     return flag;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized boolean streamCleanup(long fileId, long streamTimeout) {\n    if (streamTimeout \u003c WriteManager.MINIMIUM_STREAM_TIMEOUT) {\n      throw new InvalidParameterException(\"StreamTimeout\" + streamTimeout\n          + \"ms is less than MINIMIUM_STREAM_TIMEOUT \"\n          + WriteManager.MINIMIUM_STREAM_TIMEOUT + \"ms\");\n    }\n    \n    boolean flag \u003d false;\n    // Check the stream timeout\n    if (checkStreamTimeout(streamTimeout)) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"closing stream for fileId:\" + fileId);\n      }\n      cleanup();\n      flag \u003d true;\n    }\n    return flag;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[public, synchronized]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4971. Move IO operations out of locking in OpenFileCtx. Contributed by Jing Zhao and Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1525681 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/09/13 1:02 PM",
          "commitName": "28e3d09230971b32f74284311931525cb7ad1b7c",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "17/09/13 11:08 PM",
          "commitNameOld": "5e18410e06dd63113c49029894007e0878312903",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 5.58,
          "commitsBetweenForRepo": 25,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,27 +1,18 @@\n-  public boolean streamCleanup(long fileId, long streamTimeout) {\n+  public synchronized boolean streamCleanup(long fileId, long streamTimeout) {\n     if (streamTimeout \u003c WriteManager.MINIMIUM_STREAM_TIMEOUT) {\n       throw new InvalidParameterException(\"StreamTimeout\" + streamTimeout\n           + \"ms is less than MINIMIUM_STREAM_TIMEOUT \"\n           + WriteManager.MINIMIUM_STREAM_TIMEOUT + \"ms\");\n     }\n     \n     boolean flag \u003d false;\n-    if (!ctxLock.tryLock()) {\n-      if (LOG.isTraceEnabled()) {\n-        LOG.trace(\"Another thread is working on it\" + ctxLock.toString());\n+    // Check the stream timeout\n+    if (checkStreamTimeout(streamTimeout)) {\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"closing stream for fileId:\" + fileId);\n       }\n-      return flag;\n-    }\n-    \n-    try {\n-      // Check the stream timeout\n-      if (checkStreamTimeout(streamTimeout)) {\n-        LOG.info(\"closing stream for fileId:\" + fileId);\n-        cleanup();\n-        flag \u003d true;\n-      }\n-    } finally {\n-      unlockCtx();\n+      cleanup();\n+      flag \u003d true;\n     }\n     return flag;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized boolean streamCleanup(long fileId, long streamTimeout) {\n    if (streamTimeout \u003c WriteManager.MINIMIUM_STREAM_TIMEOUT) {\n      throw new InvalidParameterException(\"StreamTimeout\" + streamTimeout\n          + \"ms is less than MINIMIUM_STREAM_TIMEOUT \"\n          + WriteManager.MINIMIUM_STREAM_TIMEOUT + \"ms\");\n    }\n    \n    boolean flag \u003d false;\n    // Check the stream timeout\n    if (checkStreamTimeout(streamTimeout)) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"closing stream for fileId:\" + fileId);\n      }\n      cleanup();\n      flag \u003d true;\n    }\n    return flag;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
          "extendedDetails": {}
        }
      ]
    },
    "37f587563a943a827fbff865f5302bac6d202415": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4762 Provide HDFS based NFSv3 and Mountd implementation. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1499029 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/07/13 10:31 AM",
      "commitName": "37f587563a943a827fbff865f5302bac6d202415",
      "commitAuthor": "Brandon Li",
      "diff": "@@ -0,0 +1,27 @@\n+  public boolean streamCleanup(long fileId, long streamTimeout) {\n+    if (streamTimeout \u003c WriteManager.MINIMIUM_STREAM_TIMEOUT) {\n+      throw new InvalidParameterException(\"StreamTimeout\" + streamTimeout\n+          + \"ms is less than MINIMIUM_STREAM_TIMEOUT \"\n+          + WriteManager.MINIMIUM_STREAM_TIMEOUT + \"ms\");\n+    }\n+    \n+    boolean flag \u003d false;\n+    if (!ctxLock.tryLock()) {\n+      if (LOG.isTraceEnabled()) {\n+        LOG.trace(\"Another thread is working on it\" + ctxLock.toString());\n+      }\n+      return flag;\n+    }\n+    \n+    try {\n+      // Check the stream timeout\n+      if (checkStreamTimeout(streamTimeout)) {\n+        LOG.info(\"closing stream for fileId:\" + fileId);\n+        cleanup();\n+        flag \u003d true;\n+      }\n+    } finally {\n+      unlockCtx();\n+    }\n+    return flag;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean streamCleanup(long fileId, long streamTimeout) {\n    if (streamTimeout \u003c WriteManager.MINIMIUM_STREAM_TIMEOUT) {\n      throw new InvalidParameterException(\"StreamTimeout\" + streamTimeout\n          + \"ms is less than MINIMIUM_STREAM_TIMEOUT \"\n          + WriteManager.MINIMIUM_STREAM_TIMEOUT + \"ms\");\n    }\n    \n    boolean flag \u003d false;\n    if (!ctxLock.tryLock()) {\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"Another thread is working on it\" + ctxLock.toString());\n      }\n      return flag;\n    }\n    \n    try {\n      // Check the stream timeout\n      if (checkStreamTimeout(streamTimeout)) {\n        LOG.info(\"closing stream for fileId:\" + fileId);\n        cleanup();\n        flag \u003d true;\n      }\n    } finally {\n      unlockCtx();\n    }\n    return flag;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java"
    }
  }
}