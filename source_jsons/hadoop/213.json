{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "OpenFileCtx.java",
  "functionName": "processCommits",
  "functionId": "processCommits___offset-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
  "functionStartLine": 1058,
  "functionEndLine": 1121,
  "numCommitsSeen": 36,
  "timeTaken": 2257,
  "changeHistory": [
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f",
    "f6f2a3f1c73266bfedd802eacde60d8b19b81015",
    "875aa797caee96572162ff59bc50cf97d1195348",
    "1c867b1de8a9f4c6bb118c08c7b714bd2b8356cd",
    "3bfd18c6b0483ae27eff6d53bda934e67dda5464",
    "5c02d2f6225144772dcb975d3144b057b71d6476"
  ],
  "changeHistoryShort": {
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": "Ybodychange",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": "Ybodychange",
    "f6f2a3f1c73266bfedd802eacde60d8b19b81015": "Ybodychange",
    "875aa797caee96572162ff59bc50cf97d1195348": "Ybodychange",
    "1c867b1de8a9f4c6bb118c08c7b714bd2b8356cd": "Ybodychange",
    "3bfd18c6b0483ae27eff6d53bda934e67dda5464": "Ybodychange",
    "5c02d2f6225144772dcb975d3144b057b71d6476": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10571. Use Log.*(Object, Throwable) overload to log exceptions.\nContributed by Andras Bokor.\n",
      "commitDate": "14/02/18 8:20 AM",
      "commitName": "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "10/10/17 10:38 AM",
      "commitNameOld": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
      "commitAuthorOld": "Jitendra Pandey",
      "daysBetweenCommits": 126.95,
      "commitsBetweenForRepo": 833,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,64 +1,64 @@\n   private void processCommits(long offset) {\n     Preconditions.checkState(offset \u003e 0);\n     long flushedOffset \u003d getFlushedOffset();\n     Entry\u003cLong, CommitCtx\u003e entry \u003d pendingCommits.firstEntry();\n \n     if (entry \u003d\u003d null || entry.getValue().offset \u003e flushedOffset) {\n       return;\n     }\n \n     // Now do sync for the ready commits\n     int status \u003d Nfs3Status.NFS3ERR_IO;\n     try {\n       // Sync file data and length\n       fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n       status \u003d Nfs3Status.NFS3_OK;\n     } catch (ClosedChannelException cce) {\n       if (!pendingWrites.isEmpty()) {\n-        LOG.error(\"Can\u0027t sync for fileId: \" + latestAttr.getFileId()\n-            + \". Channel closed with writes pending.\", cce);\n+        LOG.error(\"Can\u0027t sync for fileId: {}. \" +\n+            \"Channel closed with writes pending\", latestAttr.getFileId(), cce);\n       }\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     } catch (IOException e) {\n       LOG.error(\"Got stream error during data sync: \", e);\n       // Do nothing. Stream will be closed eventually by StreamMonitor.\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n \n     // Update latestAttr\n     try {\n       latestAttr \u003d Nfs3Utils.getFileAttr(client,\n           Nfs3Utils.getFileIdPath(latestAttr.getFileId()), iug);\n     } catch (IOException e) {\n       LOG.error(\"Can\u0027t get new file attr, fileId: \" + latestAttr.getFileId(), e);\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n \n     if (latestAttr.getSize() !\u003d offset) {\n-      LOG.error(\"After sync, the expect file size: \" + offset\n-          + \", however actual file size is: \" + latestAttr.getSize());\n+      LOG.error(\"After sync, the expect file size: {}, \" +\n+          \"however actual file size is: {}\", offset, latestAttr.getSize());\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n     WccData wccData \u003d new WccData(Nfs3Utils.getWccAttr(latestAttr), latestAttr);\n \n     // Send response for the ready commits\n     while (entry !\u003d null \u0026\u0026 entry.getValue().offset \u003c\u003d flushedOffset) {\n       pendingCommits.remove(entry.getKey());\n       CommitCtx commit \u003d entry.getValue();\n \n       COMMIT3Response response \u003d new COMMIT3Response(status, wccData,\n           Nfs3Constant.WRITE_COMMIT_VERF);\n       RpcProgramNfs3.metrics.addCommit(Nfs3Utils\n           .getElapsedTime(commit.startTime));\n       Nfs3Utils.writeChannelCommit(commit.getChannel(), response\n           .serialize(new XDR(), commit.getXid(),\n               new VerifierNone()), commit.getXid());\n-      \n+\n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"FileId: \" + latestAttr.getFileId() + \" Service time: \"\n-            + Nfs3Utils.getElapsedTime(commit.startTime)\n-            + \"ns. Sent response for commit: \" + commit);\n+        LOG.debug(\"FileId: {} Service time: {}ns. \" +\n+                \"Sent response for commit: {}\", latestAttr.getFileId(),\n+            Nfs3Utils.getElapsedTime(commit.startTime), commit);\n       }\n       entry \u003d pendingCommits.firstEntry();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processCommits(long offset) {\n    Preconditions.checkState(offset \u003e 0);\n    long flushedOffset \u003d getFlushedOffset();\n    Entry\u003cLong, CommitCtx\u003e entry \u003d pendingCommits.firstEntry();\n\n    if (entry \u003d\u003d null || entry.getValue().offset \u003e flushedOffset) {\n      return;\n    }\n\n    // Now do sync for the ready commits\n    int status \u003d Nfs3Status.NFS3ERR_IO;\n    try {\n      // Sync file data and length\n      fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n      status \u003d Nfs3Status.NFS3_OK;\n    } catch (ClosedChannelException cce) {\n      if (!pendingWrites.isEmpty()) {\n        LOG.error(\"Can\u0027t sync for fileId: {}. \" +\n            \"Channel closed with writes pending\", latestAttr.getFileId(), cce);\n      }\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    } catch (IOException e) {\n      LOG.error(\"Got stream error during data sync: \", e);\n      // Do nothing. Stream will be closed eventually by StreamMonitor.\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n\n    // Update latestAttr\n    try {\n      latestAttr \u003d Nfs3Utils.getFileAttr(client,\n          Nfs3Utils.getFileIdPath(latestAttr.getFileId()), iug);\n    } catch (IOException e) {\n      LOG.error(\"Can\u0027t get new file attr, fileId: \" + latestAttr.getFileId(), e);\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n\n    if (latestAttr.getSize() !\u003d offset) {\n      LOG.error(\"After sync, the expect file size: {}, \" +\n          \"however actual file size is: {}\", offset, latestAttr.getSize());\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n    WccData wccData \u003d new WccData(Nfs3Utils.getWccAttr(latestAttr), latestAttr);\n\n    // Send response for the ready commits\n    while (entry !\u003d null \u0026\u0026 entry.getValue().offset \u003c\u003d flushedOffset) {\n      pendingCommits.remove(entry.getKey());\n      CommitCtx commit \u003d entry.getValue();\n\n      COMMIT3Response response \u003d new COMMIT3Response(status, wccData,\n          Nfs3Constant.WRITE_COMMIT_VERF);\n      RpcProgramNfs3.metrics.addCommit(Nfs3Utils\n          .getElapsedTime(commit.startTime));\n      Nfs3Utils.writeChannelCommit(commit.getChannel(), response\n          .serialize(new XDR(), commit.getXid(),\n              new VerifierNone()), commit.getXid());\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"FileId: {} Service time: {}ns. \" +\n                \"Sent response for commit: {}\", latestAttr.getFileId(),\n            Nfs3Utils.getElapsedTime(commit.startTime), commit);\n      }\n      entry \u003d pendingCommits.firstEntry();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7423. various typos and message formatting fixes in nfs daemon and doc. (Charles Lamb via yliu)\n",
      "commitDate": "28/01/15 12:56 PM",
      "commitName": "f37849188b05a6251584de1aed5e66d5dfa7da4f",
      "commitAuthor": "yliu",
      "commitDateOld": "11/12/14 3:40 PM",
      "commitNameOld": "f6f2a3f1c73266bfedd802eacde60d8b19b81015",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 47.89,
      "commitsBetweenForRepo": 279,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,64 +1,64 @@\n   private void processCommits(long offset) {\n     Preconditions.checkState(offset \u003e 0);\n     long flushedOffset \u003d getFlushedOffset();\n     Entry\u003cLong, CommitCtx\u003e entry \u003d pendingCommits.firstEntry();\n \n     if (entry \u003d\u003d null || entry.getValue().offset \u003e flushedOffset) {\n       return;\n     }\n \n     // Now do sync for the ready commits\n     int status \u003d Nfs3Status.NFS3ERR_IO;\n     try {\n       // Sync file data and length\n       fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n       status \u003d Nfs3Status.NFS3_OK;\n     } catch (ClosedChannelException cce) {\n       if (!pendingWrites.isEmpty()) {\n         LOG.error(\"Can\u0027t sync for fileId: \" + latestAttr.getFileId()\n             + \". Channel closed with writes pending.\", cce);\n       }\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     } catch (IOException e) {\n-      LOG.error(\"Got stream error during data sync:\", e);\n+      LOG.error(\"Got stream error during data sync: \", e);\n       // Do nothing. Stream will be closed eventually by StreamMonitor.\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n \n     // Update latestAttr\n     try {\n       latestAttr \u003d Nfs3Utils.getFileAttr(client,\n           Nfs3Utils.getFileIdPath(latestAttr.getFileId()), iug);\n     } catch (IOException e) {\n       LOG.error(\"Can\u0027t get new file attr, fileId: \" + latestAttr.getFileId(), e);\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n \n     if (latestAttr.getSize() !\u003d offset) {\n       LOG.error(\"After sync, the expect file size: \" + offset\n           + \", however actual file size is: \" + latestAttr.getSize());\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n     WccData wccData \u003d new WccData(Nfs3Utils.getWccAttr(latestAttr), latestAttr);\n \n     // Send response for the ready commits\n     while (entry !\u003d null \u0026\u0026 entry.getValue().offset \u003c\u003d flushedOffset) {\n       pendingCommits.remove(entry.getKey());\n       CommitCtx commit \u003d entry.getValue();\n \n       COMMIT3Response response \u003d new COMMIT3Response(status, wccData,\n           Nfs3Constant.WRITE_COMMIT_VERF);\n       RpcProgramNfs3.metrics.addCommit(Nfs3Utils\n           .getElapsedTime(commit.startTime));\n       Nfs3Utils.writeChannelCommit(commit.getChannel(), response\n           .serialize(new XDR(), commit.getXid(),\n               new VerifierNone()), commit.getXid());\n       \n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"FileId: \" + latestAttr.getFileId() + \" Service time:\"\n+        LOG.debug(\"FileId: \" + latestAttr.getFileId() + \" Service time: \"\n             + Nfs3Utils.getElapsedTime(commit.startTime)\n-            + \"ns. Sent response for commit:\" + commit);\n+            + \"ns. Sent response for commit: \" + commit);\n       }\n       entry \u003d pendingCommits.firstEntry();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processCommits(long offset) {\n    Preconditions.checkState(offset \u003e 0);\n    long flushedOffset \u003d getFlushedOffset();\n    Entry\u003cLong, CommitCtx\u003e entry \u003d pendingCommits.firstEntry();\n\n    if (entry \u003d\u003d null || entry.getValue().offset \u003e flushedOffset) {\n      return;\n    }\n\n    // Now do sync for the ready commits\n    int status \u003d Nfs3Status.NFS3ERR_IO;\n    try {\n      // Sync file data and length\n      fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n      status \u003d Nfs3Status.NFS3_OK;\n    } catch (ClosedChannelException cce) {\n      if (!pendingWrites.isEmpty()) {\n        LOG.error(\"Can\u0027t sync for fileId: \" + latestAttr.getFileId()\n            + \". Channel closed with writes pending.\", cce);\n      }\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    } catch (IOException e) {\n      LOG.error(\"Got stream error during data sync: \", e);\n      // Do nothing. Stream will be closed eventually by StreamMonitor.\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n\n    // Update latestAttr\n    try {\n      latestAttr \u003d Nfs3Utils.getFileAttr(client,\n          Nfs3Utils.getFileIdPath(latestAttr.getFileId()), iug);\n    } catch (IOException e) {\n      LOG.error(\"Can\u0027t get new file attr, fileId: \" + latestAttr.getFileId(), e);\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n\n    if (latestAttr.getSize() !\u003d offset) {\n      LOG.error(\"After sync, the expect file size: \" + offset\n          + \", however actual file size is: \" + latestAttr.getSize());\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n    WccData wccData \u003d new WccData(Nfs3Utils.getWccAttr(latestAttr), latestAttr);\n\n    // Send response for the ready commits\n    while (entry !\u003d null \u0026\u0026 entry.getValue().offset \u003c\u003d flushedOffset) {\n      pendingCommits.remove(entry.getKey());\n      CommitCtx commit \u003d entry.getValue();\n\n      COMMIT3Response response \u003d new COMMIT3Response(status, wccData,\n          Nfs3Constant.WRITE_COMMIT_VERF);\n      RpcProgramNfs3.metrics.addCommit(Nfs3Utils\n          .getElapsedTime(commit.startTime));\n      Nfs3Utils.writeChannelCommit(commit.getChannel(), response\n          .serialize(new XDR(), commit.getXid(),\n              new VerifierNone()), commit.getXid());\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"FileId: \" + latestAttr.getFileId() + \" Service time: \"\n            + Nfs3Utils.getElapsedTime(commit.startTime)\n            + \"ns. Sent response for commit: \" + commit);\n      }\n      entry \u003d pendingCommits.firstEntry();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "f6f2a3f1c73266bfedd802eacde60d8b19b81015": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7449. Add metrics to NFS gateway. Contributed by Brandon Li\n",
      "commitDate": "11/12/14 3:40 PM",
      "commitName": "f6f2a3f1c73266bfedd802eacde60d8b19b81015",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "11/11/14 1:03 PM",
      "commitNameOld": "99d9d0c2d19b9f161b765947f3fb64619ea58090",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 30.11,
      "commitsBetweenForRepo": 214,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,64 @@\n   private void processCommits(long offset) {\n     Preconditions.checkState(offset \u003e 0);\n     long flushedOffset \u003d getFlushedOffset();\n     Entry\u003cLong, CommitCtx\u003e entry \u003d pendingCommits.firstEntry();\n \n     if (entry \u003d\u003d null || entry.getValue().offset \u003e flushedOffset) {\n       return;\n     }\n \n     // Now do sync for the ready commits\n     int status \u003d Nfs3Status.NFS3ERR_IO;\n     try {\n       // Sync file data and length\n       fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n       status \u003d Nfs3Status.NFS3_OK;\n     } catch (ClosedChannelException cce) {\n       if (!pendingWrites.isEmpty()) {\n         LOG.error(\"Can\u0027t sync for fileId: \" + latestAttr.getFileId()\n             + \". Channel closed with writes pending.\", cce);\n       }\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     } catch (IOException e) {\n       LOG.error(\"Got stream error during data sync:\", e);\n       // Do nothing. Stream will be closed eventually by StreamMonitor.\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n \n     // Update latestAttr\n     try {\n       latestAttr \u003d Nfs3Utils.getFileAttr(client,\n           Nfs3Utils.getFileIdPath(latestAttr.getFileId()), iug);\n     } catch (IOException e) {\n       LOG.error(\"Can\u0027t get new file attr, fileId: \" + latestAttr.getFileId(), e);\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n \n     if (latestAttr.getSize() !\u003d offset) {\n       LOG.error(\"After sync, the expect file size: \" + offset\n           + \", however actual file size is: \" + latestAttr.getSize());\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n     WccData wccData \u003d new WccData(Nfs3Utils.getWccAttr(latestAttr), latestAttr);\n \n     // Send response for the ready commits\n     while (entry !\u003d null \u0026\u0026 entry.getValue().offset \u003c\u003d flushedOffset) {\n       pendingCommits.remove(entry.getKey());\n       CommitCtx commit \u003d entry.getValue();\n \n       COMMIT3Response response \u003d new COMMIT3Response(status, wccData,\n           Nfs3Constant.WRITE_COMMIT_VERF);\n+      RpcProgramNfs3.metrics.addCommit(Nfs3Utils\n+          .getElapsedTime(commit.startTime));\n       Nfs3Utils.writeChannelCommit(commit.getChannel(), response\n           .serialize(new XDR(), commit.getXid(),\n               new VerifierNone()), commit.getXid());\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"FileId: \" + latestAttr.getFileId() + \" Service time:\"\n-            + (Time.monotonicNow() - commit.getStartTime())\n-            + \"ms. Sent response for commit:\" + commit);\n+            + Nfs3Utils.getElapsedTime(commit.startTime)\n+            + \"ns. Sent response for commit:\" + commit);\n       }\n       entry \u003d pendingCommits.firstEntry();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processCommits(long offset) {\n    Preconditions.checkState(offset \u003e 0);\n    long flushedOffset \u003d getFlushedOffset();\n    Entry\u003cLong, CommitCtx\u003e entry \u003d pendingCommits.firstEntry();\n\n    if (entry \u003d\u003d null || entry.getValue().offset \u003e flushedOffset) {\n      return;\n    }\n\n    // Now do sync for the ready commits\n    int status \u003d Nfs3Status.NFS3ERR_IO;\n    try {\n      // Sync file data and length\n      fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n      status \u003d Nfs3Status.NFS3_OK;\n    } catch (ClosedChannelException cce) {\n      if (!pendingWrites.isEmpty()) {\n        LOG.error(\"Can\u0027t sync for fileId: \" + latestAttr.getFileId()\n            + \". Channel closed with writes pending.\", cce);\n      }\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    } catch (IOException e) {\n      LOG.error(\"Got stream error during data sync:\", e);\n      // Do nothing. Stream will be closed eventually by StreamMonitor.\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n\n    // Update latestAttr\n    try {\n      latestAttr \u003d Nfs3Utils.getFileAttr(client,\n          Nfs3Utils.getFileIdPath(latestAttr.getFileId()), iug);\n    } catch (IOException e) {\n      LOG.error(\"Can\u0027t get new file attr, fileId: \" + latestAttr.getFileId(), e);\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n\n    if (latestAttr.getSize() !\u003d offset) {\n      LOG.error(\"After sync, the expect file size: \" + offset\n          + \", however actual file size is: \" + latestAttr.getSize());\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n    WccData wccData \u003d new WccData(Nfs3Utils.getWccAttr(latestAttr), latestAttr);\n\n    // Send response for the ready commits\n    while (entry !\u003d null \u0026\u0026 entry.getValue().offset \u003c\u003d flushedOffset) {\n      pendingCommits.remove(entry.getKey());\n      CommitCtx commit \u003d entry.getValue();\n\n      COMMIT3Response response \u003d new COMMIT3Response(status, wccData,\n          Nfs3Constant.WRITE_COMMIT_VERF);\n      RpcProgramNfs3.metrics.addCommit(Nfs3Utils\n          .getElapsedTime(commit.startTime));\n      Nfs3Utils.writeChannelCommit(commit.getChannel(), response\n          .serialize(new XDR(), commit.getXid(),\n              new VerifierNone()), commit.getXid());\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"FileId: \" + latestAttr.getFileId() + \" Service time:\"\n            + Nfs3Utils.getElapsedTime(commit.startTime)\n            + \"ns. Sent response for commit:\" + commit);\n      }\n      entry \u003d pendingCommits.firstEntry();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "875aa797caee96572162ff59bc50cf97d1195348": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6894. Add XDR parser method for each NFS response. Contributed by Brandon Li.\n",
      "commitDate": "01/10/14 1:18 PM",
      "commitName": "875aa797caee96572162ff59bc50cf97d1195348",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "18/09/14 2:57 PM",
      "commitNameOld": "70be56d093022de9953e14a92dfa1a146bd9a290",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 12.93,
      "commitsBetweenForRepo": 154,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,62 @@\n   private void processCommits(long offset) {\n     Preconditions.checkState(offset \u003e 0);\n     long flushedOffset \u003d getFlushedOffset();\n     Entry\u003cLong, CommitCtx\u003e entry \u003d pendingCommits.firstEntry();\n \n     if (entry \u003d\u003d null || entry.getValue().offset \u003e flushedOffset) {\n       return;\n     }\n \n     // Now do sync for the ready commits\n     int status \u003d Nfs3Status.NFS3ERR_IO;\n     try {\n       // Sync file data and length\n       fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n       status \u003d Nfs3Status.NFS3_OK;\n     } catch (ClosedChannelException cce) {\n       if (!pendingWrites.isEmpty()) {\n         LOG.error(\"Can\u0027t sync for fileId: \" + latestAttr.getFileId()\n             + \". Channel closed with writes pending.\", cce);\n       }\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     } catch (IOException e) {\n       LOG.error(\"Got stream error during data sync:\", e);\n       // Do nothing. Stream will be closed eventually by StreamMonitor.\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n \n     // Update latestAttr\n     try {\n       latestAttr \u003d Nfs3Utils.getFileAttr(client,\n           Nfs3Utils.getFileIdPath(latestAttr.getFileId()), iug);\n     } catch (IOException e) {\n       LOG.error(\"Can\u0027t get new file attr, fileId: \" + latestAttr.getFileId(), e);\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n \n     if (latestAttr.getSize() !\u003d offset) {\n       LOG.error(\"After sync, the expect file size: \" + offset\n           + \", however actual file size is: \" + latestAttr.getSize());\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n     WccData wccData \u003d new WccData(Nfs3Utils.getWccAttr(latestAttr), latestAttr);\n \n     // Send response for the ready commits\n     while (entry !\u003d null \u0026\u0026 entry.getValue().offset \u003c\u003d flushedOffset) {\n       pendingCommits.remove(entry.getKey());\n       CommitCtx commit \u003d entry.getValue();\n \n       COMMIT3Response response \u003d new COMMIT3Response(status, wccData,\n           Nfs3Constant.WRITE_COMMIT_VERF);\n       Nfs3Utils.writeChannelCommit(commit.getChannel(), response\n-          .writeHeaderAndResponse(new XDR(), commit.getXid(),\n+          .serialize(new XDR(), commit.getXid(),\n               new VerifierNone()), commit.getXid());\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"FileId: \" + latestAttr.getFileId() + \" Service time:\"\n             + (Time.monotonicNow() - commit.getStartTime())\n             + \"ms. Sent response for commit:\" + commit);\n       }\n       entry \u003d pendingCommits.firstEntry();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processCommits(long offset) {\n    Preconditions.checkState(offset \u003e 0);\n    long flushedOffset \u003d getFlushedOffset();\n    Entry\u003cLong, CommitCtx\u003e entry \u003d pendingCommits.firstEntry();\n\n    if (entry \u003d\u003d null || entry.getValue().offset \u003e flushedOffset) {\n      return;\n    }\n\n    // Now do sync for the ready commits\n    int status \u003d Nfs3Status.NFS3ERR_IO;\n    try {\n      // Sync file data and length\n      fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n      status \u003d Nfs3Status.NFS3_OK;\n    } catch (ClosedChannelException cce) {\n      if (!pendingWrites.isEmpty()) {\n        LOG.error(\"Can\u0027t sync for fileId: \" + latestAttr.getFileId()\n            + \". Channel closed with writes pending.\", cce);\n      }\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    } catch (IOException e) {\n      LOG.error(\"Got stream error during data sync:\", e);\n      // Do nothing. Stream will be closed eventually by StreamMonitor.\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n\n    // Update latestAttr\n    try {\n      latestAttr \u003d Nfs3Utils.getFileAttr(client,\n          Nfs3Utils.getFileIdPath(latestAttr.getFileId()), iug);\n    } catch (IOException e) {\n      LOG.error(\"Can\u0027t get new file attr, fileId: \" + latestAttr.getFileId(), e);\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n\n    if (latestAttr.getSize() !\u003d offset) {\n      LOG.error(\"After sync, the expect file size: \" + offset\n          + \", however actual file size is: \" + latestAttr.getSize());\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n    WccData wccData \u003d new WccData(Nfs3Utils.getWccAttr(latestAttr), latestAttr);\n\n    // Send response for the ready commits\n    while (entry !\u003d null \u0026\u0026 entry.getValue().offset \u003c\u003d flushedOffset) {\n      pendingCommits.remove(entry.getKey());\n      CommitCtx commit \u003d entry.getValue();\n\n      COMMIT3Response response \u003d new COMMIT3Response(status, wccData,\n          Nfs3Constant.WRITE_COMMIT_VERF);\n      Nfs3Utils.writeChannelCommit(commit.getChannel(), response\n          .serialize(new XDR(), commit.getXid(),\n              new VerifierNone()), commit.getXid());\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"FileId: \" + latestAttr.getFileId() + \" Service time:\"\n            + (Time.monotonicNow() - commit.getStartTime())\n            + \"ms. Sent response for commit:\" + commit);\n      }\n      entry \u003d pendingCommits.firstEntry();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "1c867b1de8a9f4c6bb118c08c7b714bd2b8356cd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6416. Use Time#monotonicNow in OpenFileCtx and OpenFileCtxCatch to avoid system clock bugs. Contributed by Abhiraj Butala\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1597868 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/05/14 1:21 PM",
      "commitName": "1c867b1de8a9f4c6bb118c08c7b714bd2b8356cd",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "24/03/14 1:49 PM",
      "commitNameOld": "3bfd18c6b0483ae27eff6d53bda934e67dda5464",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 63.98,
      "commitsBetweenForRepo": 376,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,62 @@\n   private void processCommits(long offset) {\n     Preconditions.checkState(offset \u003e 0);\n     long flushedOffset \u003d getFlushedOffset();\n     Entry\u003cLong, CommitCtx\u003e entry \u003d pendingCommits.firstEntry();\n \n     if (entry \u003d\u003d null || entry.getValue().offset \u003e flushedOffset) {\n       return;\n     }\n \n     // Now do sync for the ready commits\n     int status \u003d Nfs3Status.NFS3ERR_IO;\n     try {\n       // Sync file data and length\n       fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n       status \u003d Nfs3Status.NFS3_OK;\n     } catch (ClosedChannelException cce) {\n       if (!pendingWrites.isEmpty()) {\n         LOG.error(\"Can\u0027t sync for fileId: \" + latestAttr.getFileId()\n             + \". Channel closed with writes pending.\", cce);\n       }\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     } catch (IOException e) {\n       LOG.error(\"Got stream error during data sync:\", e);\n       // Do nothing. Stream will be closed eventually by StreamMonitor.\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n \n     // Update latestAttr\n     try {\n       latestAttr \u003d Nfs3Utils.getFileAttr(client,\n           Nfs3Utils.getFileIdPath(latestAttr.getFileId()), iug);\n     } catch (IOException e) {\n       LOG.error(\"Can\u0027t get new file attr, fileId: \" + latestAttr.getFileId(), e);\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n \n     if (latestAttr.getSize() !\u003d offset) {\n       LOG.error(\"After sync, the expect file size: \" + offset\n           + \", however actual file size is: \" + latestAttr.getSize());\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n     WccData wccData \u003d new WccData(Nfs3Utils.getWccAttr(latestAttr), latestAttr);\n \n     // Send response for the ready commits\n     while (entry !\u003d null \u0026\u0026 entry.getValue().offset \u003c\u003d flushedOffset) {\n       pendingCommits.remove(entry.getKey());\n       CommitCtx commit \u003d entry.getValue();\n \n       COMMIT3Response response \u003d new COMMIT3Response(status, wccData,\n           Nfs3Constant.WRITE_COMMIT_VERF);\n       Nfs3Utils.writeChannelCommit(commit.getChannel(), response\n           .writeHeaderAndResponse(new XDR(), commit.getXid(),\n               new VerifierNone()), commit.getXid());\n       \n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"FileId: \" + latestAttr.getFileId() + \" Service time:\"\n-            + (System.currentTimeMillis() - commit.getStartTime())\n+            + (Time.monotonicNow() - commit.getStartTime())\n             + \"ms. Sent response for commit:\" + commit);\n       }\n       entry \u003d pendingCommits.firstEntry();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processCommits(long offset) {\n    Preconditions.checkState(offset \u003e 0);\n    long flushedOffset \u003d getFlushedOffset();\n    Entry\u003cLong, CommitCtx\u003e entry \u003d pendingCommits.firstEntry();\n\n    if (entry \u003d\u003d null || entry.getValue().offset \u003e flushedOffset) {\n      return;\n    }\n\n    // Now do sync for the ready commits\n    int status \u003d Nfs3Status.NFS3ERR_IO;\n    try {\n      // Sync file data and length\n      fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n      status \u003d Nfs3Status.NFS3_OK;\n    } catch (ClosedChannelException cce) {\n      if (!pendingWrites.isEmpty()) {\n        LOG.error(\"Can\u0027t sync for fileId: \" + latestAttr.getFileId()\n            + \". Channel closed with writes pending.\", cce);\n      }\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    } catch (IOException e) {\n      LOG.error(\"Got stream error during data sync:\", e);\n      // Do nothing. Stream will be closed eventually by StreamMonitor.\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n\n    // Update latestAttr\n    try {\n      latestAttr \u003d Nfs3Utils.getFileAttr(client,\n          Nfs3Utils.getFileIdPath(latestAttr.getFileId()), iug);\n    } catch (IOException e) {\n      LOG.error(\"Can\u0027t get new file attr, fileId: \" + latestAttr.getFileId(), e);\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n\n    if (latestAttr.getSize() !\u003d offset) {\n      LOG.error(\"After sync, the expect file size: \" + offset\n          + \", however actual file size is: \" + latestAttr.getSize());\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n    WccData wccData \u003d new WccData(Nfs3Utils.getWccAttr(latestAttr), latestAttr);\n\n    // Send response for the ready commits\n    while (entry !\u003d null \u0026\u0026 entry.getValue().offset \u003c\u003d flushedOffset) {\n      pendingCommits.remove(entry.getKey());\n      CommitCtx commit \u003d entry.getValue();\n\n      COMMIT3Response response \u003d new COMMIT3Response(status, wccData,\n          Nfs3Constant.WRITE_COMMIT_VERF);\n      Nfs3Utils.writeChannelCommit(commit.getChannel(), response\n          .writeHeaderAndResponse(new XDR(), commit.getXid(),\n              new VerifierNone()), commit.getXid());\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"FileId: \" + latestAttr.getFileId() + \" Service time:\"\n            + (Time.monotonicNow() - commit.getStartTime())\n            + \"ms. Sent response for commit:\" + commit);\n      }\n      entry \u003d pendingCommits.firstEntry();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "3bfd18c6b0483ae27eff6d53bda934e67dda5464": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6050. NFS does not handle exceptions correctly in a few places. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1581055 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/03/14 1:49 PM",
      "commitName": "3bfd18c6b0483ae27eff6d53bda934e67dda5464",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "17/12/13 12:40 PM",
      "commitNameOld": "5792d59da390842caec86ccaa8472d5be7933837",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 97.01,
      "commitsBetweenForRepo": 719,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,62 @@\n   private void processCommits(long offset) {\n     Preconditions.checkState(offset \u003e 0);\n     long flushedOffset \u003d getFlushedOffset();\n     Entry\u003cLong, CommitCtx\u003e entry \u003d pendingCommits.firstEntry();\n \n     if (entry \u003d\u003d null || entry.getValue().offset \u003e flushedOffset) {\n       return;\n     }\n \n     // Now do sync for the ready commits\n     int status \u003d Nfs3Status.NFS3ERR_IO;\n     try {\n       // Sync file data and length\n       fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n       status \u003d Nfs3Status.NFS3_OK;\n     } catch (ClosedChannelException cce) {\n       if (!pendingWrites.isEmpty()) {\n         LOG.error(\"Can\u0027t sync for fileId: \" + latestAttr.getFileId()\n-            + \". Channel closed with writes pending\");\n+            + \". Channel closed with writes pending.\", cce);\n       }\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     } catch (IOException e) {\n-      LOG.error(\"Got stream error during data sync:\" + e);\n+      LOG.error(\"Got stream error during data sync:\", e);\n       // Do nothing. Stream will be closed eventually by StreamMonitor.\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n \n     // Update latestAttr\n     try {\n       latestAttr \u003d Nfs3Utils.getFileAttr(client,\n           Nfs3Utils.getFileIdPath(latestAttr.getFileId()), iug);\n     } catch (IOException e) {\n-      LOG.error(\"Can\u0027t get new file attr for fileId: \" + latestAttr.getFileId());\n+      LOG.error(\"Can\u0027t get new file attr, fileId: \" + latestAttr.getFileId(), e);\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n \n     if (latestAttr.getSize() !\u003d offset) {\n       LOG.error(\"After sync, the expect file size: \" + offset\n           + \", however actual file size is: \" + latestAttr.getSize());\n       status \u003d Nfs3Status.NFS3ERR_IO;\n     }\n     WccData wccData \u003d new WccData(Nfs3Utils.getWccAttr(latestAttr), latestAttr);\n \n     // Send response for the ready commits\n     while (entry !\u003d null \u0026\u0026 entry.getValue().offset \u003c\u003d flushedOffset) {\n       pendingCommits.remove(entry.getKey());\n       CommitCtx commit \u003d entry.getValue();\n \n       COMMIT3Response response \u003d new COMMIT3Response(status, wccData,\n           Nfs3Constant.WRITE_COMMIT_VERF);\n       Nfs3Utils.writeChannelCommit(commit.getChannel(), response\n           .writeHeaderAndResponse(new XDR(), commit.getXid(),\n               new VerifierNone()), commit.getXid());\n       \n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"FileId: \" + latestAttr.getFileid() + \" Service time:\"\n+        LOG.debug(\"FileId: \" + latestAttr.getFileId() + \" Service time:\"\n             + (System.currentTimeMillis() - commit.getStartTime())\n             + \"ms. Sent response for commit:\" + commit);\n       }\n       entry \u003d pendingCommits.firstEntry();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processCommits(long offset) {\n    Preconditions.checkState(offset \u003e 0);\n    long flushedOffset \u003d getFlushedOffset();\n    Entry\u003cLong, CommitCtx\u003e entry \u003d pendingCommits.firstEntry();\n\n    if (entry \u003d\u003d null || entry.getValue().offset \u003e flushedOffset) {\n      return;\n    }\n\n    // Now do sync for the ready commits\n    int status \u003d Nfs3Status.NFS3ERR_IO;\n    try {\n      // Sync file data and length\n      fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n      status \u003d Nfs3Status.NFS3_OK;\n    } catch (ClosedChannelException cce) {\n      if (!pendingWrites.isEmpty()) {\n        LOG.error(\"Can\u0027t sync for fileId: \" + latestAttr.getFileId()\n            + \". Channel closed with writes pending.\", cce);\n      }\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    } catch (IOException e) {\n      LOG.error(\"Got stream error during data sync:\", e);\n      // Do nothing. Stream will be closed eventually by StreamMonitor.\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n\n    // Update latestAttr\n    try {\n      latestAttr \u003d Nfs3Utils.getFileAttr(client,\n          Nfs3Utils.getFileIdPath(latestAttr.getFileId()), iug);\n    } catch (IOException e) {\n      LOG.error(\"Can\u0027t get new file attr, fileId: \" + latestAttr.getFileId(), e);\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n\n    if (latestAttr.getSize() !\u003d offset) {\n      LOG.error(\"After sync, the expect file size: \" + offset\n          + \", however actual file size is: \" + latestAttr.getSize());\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n    WccData wccData \u003d new WccData(Nfs3Utils.getWccAttr(latestAttr), latestAttr);\n\n    // Send response for the ready commits\n    while (entry !\u003d null \u0026\u0026 entry.getValue().offset \u003c\u003d flushedOffset) {\n      pendingCommits.remove(entry.getKey());\n      CommitCtx commit \u003d entry.getValue();\n\n      COMMIT3Response response \u003d new COMMIT3Response(status, wccData,\n          Nfs3Constant.WRITE_COMMIT_VERF);\n      Nfs3Utils.writeChannelCommit(commit.getChannel(), response\n          .writeHeaderAndResponse(new XDR(), commit.getXid(),\n              new VerifierNone()), commit.getXid());\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"FileId: \" + latestAttr.getFileId() + \" Service time:\"\n            + (System.currentTimeMillis() - commit.getStartTime())\n            + \"ms. Sent response for commit:\" + commit);\n      }\n      entry \u003d pendingCommits.firstEntry();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "5c02d2f6225144772dcb975d3144b057b71d6476": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5281. COMMIT request should not block. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1530461 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/10/13 4:40 PM",
      "commitName": "5c02d2f6225144772dcb975d3144b057b71d6476",
      "commitAuthor": "Brandon Li",
      "diff": "@@ -0,0 +1,62 @@\n+  private void processCommits(long offset) {\n+    Preconditions.checkState(offset \u003e 0);\n+    long flushedOffset \u003d getFlushedOffset();\n+    Entry\u003cLong, CommitCtx\u003e entry \u003d pendingCommits.firstEntry();\n+\n+    if (entry \u003d\u003d null || entry.getValue().offset \u003e flushedOffset) {\n+      return;\n+    }\n+\n+    // Now do sync for the ready commits\n+    int status \u003d Nfs3Status.NFS3ERR_IO;\n+    try {\n+      // Sync file data and length\n+      fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n+      status \u003d Nfs3Status.NFS3_OK;\n+    } catch (ClosedChannelException cce) {\n+      if (!pendingWrites.isEmpty()) {\n+        LOG.error(\"Can\u0027t sync for fileId: \" + latestAttr.getFileId()\n+            + \". Channel closed with writes pending\");\n+      }\n+      status \u003d Nfs3Status.NFS3ERR_IO;\n+    } catch (IOException e) {\n+      LOG.error(\"Got stream error during data sync:\" + e);\n+      // Do nothing. Stream will be closed eventually by StreamMonitor.\n+      status \u003d Nfs3Status.NFS3ERR_IO;\n+    }\n+\n+    // Update latestAttr\n+    try {\n+      latestAttr \u003d Nfs3Utils.getFileAttr(client,\n+          Nfs3Utils.getFileIdPath(latestAttr.getFileId()), iug);\n+    } catch (IOException e) {\n+      LOG.error(\"Can\u0027t get new file attr for fileId: \" + latestAttr.getFileId());\n+      status \u003d Nfs3Status.NFS3ERR_IO;\n+    }\n+\n+    if (latestAttr.getSize() !\u003d offset) {\n+      LOG.error(\"After sync, the expect file size: \" + offset\n+          + \", however actual file size is: \" + latestAttr.getSize());\n+      status \u003d Nfs3Status.NFS3ERR_IO;\n+    }\n+    WccData wccData \u003d new WccData(Nfs3Utils.getWccAttr(latestAttr), latestAttr);\n+\n+    // Send response for the ready commits\n+    while (entry !\u003d null \u0026\u0026 entry.getValue().offset \u003c\u003d flushedOffset) {\n+      pendingCommits.remove(entry.getKey());\n+      CommitCtx commit \u003d entry.getValue();\n+\n+      COMMIT3Response response \u003d new COMMIT3Response(status, wccData,\n+          Nfs3Constant.WRITE_COMMIT_VERF);\n+      Nfs3Utils.writeChannelCommit(commit.getChannel(), response\n+          .writeHeaderAndResponse(new XDR(), commit.getXid(),\n+              new VerifierNone()), commit.getXid());\n+      \n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"FileId: \" + latestAttr.getFileid() + \" Service time:\"\n+            + (System.currentTimeMillis() - commit.getStartTime())\n+            + \"ms. Sent response for commit:\" + commit);\n+      }\n+      entry \u003d pendingCommits.firstEntry();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void processCommits(long offset) {\n    Preconditions.checkState(offset \u003e 0);\n    long flushedOffset \u003d getFlushedOffset();\n    Entry\u003cLong, CommitCtx\u003e entry \u003d pendingCommits.firstEntry();\n\n    if (entry \u003d\u003d null || entry.getValue().offset \u003e flushedOffset) {\n      return;\n    }\n\n    // Now do sync for the ready commits\n    int status \u003d Nfs3Status.NFS3ERR_IO;\n    try {\n      // Sync file data and length\n      fos.hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));\n      status \u003d Nfs3Status.NFS3_OK;\n    } catch (ClosedChannelException cce) {\n      if (!pendingWrites.isEmpty()) {\n        LOG.error(\"Can\u0027t sync for fileId: \" + latestAttr.getFileId()\n            + \". Channel closed with writes pending\");\n      }\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    } catch (IOException e) {\n      LOG.error(\"Got stream error during data sync:\" + e);\n      // Do nothing. Stream will be closed eventually by StreamMonitor.\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n\n    // Update latestAttr\n    try {\n      latestAttr \u003d Nfs3Utils.getFileAttr(client,\n          Nfs3Utils.getFileIdPath(latestAttr.getFileId()), iug);\n    } catch (IOException e) {\n      LOG.error(\"Can\u0027t get new file attr for fileId: \" + latestAttr.getFileId());\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n\n    if (latestAttr.getSize() !\u003d offset) {\n      LOG.error(\"After sync, the expect file size: \" + offset\n          + \", however actual file size is: \" + latestAttr.getSize());\n      status \u003d Nfs3Status.NFS3ERR_IO;\n    }\n    WccData wccData \u003d new WccData(Nfs3Utils.getWccAttr(latestAttr), latestAttr);\n\n    // Send response for the ready commits\n    while (entry !\u003d null \u0026\u0026 entry.getValue().offset \u003c\u003d flushedOffset) {\n      pendingCommits.remove(entry.getKey());\n      CommitCtx commit \u003d entry.getValue();\n\n      COMMIT3Response response \u003d new COMMIT3Response(status, wccData,\n          Nfs3Constant.WRITE_COMMIT_VERF);\n      Nfs3Utils.writeChannelCommit(commit.getChannel(), response\n          .writeHeaderAndResponse(new XDR(), commit.getXid(),\n              new VerifierNone()), commit.getXid());\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"FileId: \" + latestAttr.getFileid() + \" Service time:\"\n            + (System.currentTimeMillis() - commit.getStartTime())\n            + \"ms. Sent response for commit:\" + commit);\n      }\n      entry \u003d pendingCommits.firstEntry();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java"
    }
  }
}