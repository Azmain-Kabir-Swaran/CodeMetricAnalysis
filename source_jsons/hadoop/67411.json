{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HadoopArchives.java",
  "functionName": "configure",
  "functionId": "configure___conf-JobConf",
  "sourceFilePath": "hadoop-tools/hadoop-archives/src/main/java/org/apache/hadoop/tools/HadoopArchives.java",
  "functionStartLine": 595,
  "functionEndLine": 626,
  "numCommitsSeen": 18,
  "timeTaken": 5320,
  "changeHistory": [
    "5af572b6443715b7a741296c1bd520a1840f9a7c",
    "94c6a4aa85e7d98e9b532b330f30783315f4334b",
    "c89977f89cb4520164c1747fe1abbaad215c42a0",
    "0201be46c298e94176ec6297e9d9cdba3afc2bbd",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "5af572b6443715b7a741296c1bd520a1840f9a7c": "Ybodychange",
    "94c6a4aa85e7d98e9b532b330f30783315f4334b": "Ybodychange",
    "c89977f89cb4520164c1747fe1abbaad215c42a0": "Ybodychange",
    "0201be46c298e94176ec6297e9d9cdba3afc2bbd": "Yfilerename",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "5af572b6443715b7a741296c1bd520a1840f9a7c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13427. Eliminate needless uses of FileSystem#{exists(), isFile(), isDirectory()}. Contributed by Steve Loughran and Mingliang Liu\n",
      "commitDate": "15/11/16 10:57 AM",
      "commitName": "5af572b6443715b7a741296c1bd520a1840f9a7c",
      "commitAuthor": "Mingliang Liu",
      "commitDateOld": "21/07/15 9:55 PM",
      "commitNameOld": "94c6a4aa85e7d98e9b532b330f30783315f4334b",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 482.58,
      "commitsBetweenForRepo": 3394,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,19 @@\n     public void configure(JobConf conf) {\n       this.conf \u003d conf;\n       tmpOutputDir \u003d FileOutputFormat.getWorkOutputPath(this.conf);\n       masterIndex \u003d new Path(tmpOutputDir, \"_masterindex\");\n       index \u003d new Path(tmpOutputDir, \"_index\");\n       replication \u003d conf.getInt(HAR_REPLICATION_LABEL, 3);\n       try {\n         fs \u003d masterIndex.getFileSystem(conf);\n-        if (fs.exists(masterIndex)) {\n-          fs.delete(masterIndex, false);\n-        }\n-        if (fs.exists(index)) {\n-          fs.delete(index, false);\n-        }\n+        fs.delete(masterIndex, false);\n+        fs.delete(index, false);\n         indexStream \u003d fs.create(index);\n         outStream \u003d fs.create(masterIndex);\n         String version \u003d VERSION + \" \\n\";\n         outStream.write(version.getBytes(Charsets.UTF_8));\n         \n       } catch(IOException e) {\n         throw new RuntimeException(e);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void configure(JobConf conf) {\n      this.conf \u003d conf;\n      tmpOutputDir \u003d FileOutputFormat.getWorkOutputPath(this.conf);\n      masterIndex \u003d new Path(tmpOutputDir, \"_masterindex\");\n      index \u003d new Path(tmpOutputDir, \"_index\");\n      replication \u003d conf.getInt(HAR_REPLICATION_LABEL, 3);\n      try {\n        fs \u003d masterIndex.getFileSystem(conf);\n        fs.delete(masterIndex, false);\n        fs.delete(index, false);\n        indexStream \u003d fs.create(index);\n        outStream \u003d fs.create(masterIndex);\n        String version \u003d VERSION + \" \\n\";\n        outStream.write(version.getBytes(Charsets.UTF_8));\n        \n      } catch(IOException e) {\n        throw new RuntimeException(e);\n      }\n    }",
      "path": "hadoop-tools/hadoop-archives/src/main/java/org/apache/hadoop/tools/HadoopArchives.java",
      "extendedDetails": {}
    },
    "94c6a4aa85e7d98e9b532b330f30783315f4334b": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12017. Hadoop archives command should use configurable replication factor when closing (Contributed by Bibin A Chundatt)\n",
      "commitDate": "21/07/15 9:55 PM",
      "commitName": "94c6a4aa85e7d98e9b532b330f30783315f4334b",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "21/07/15 12:42 AM",
      "commitNameOld": "87f29c6b8acc07cc011713a79554d51945e265ac",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.88,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,23 @@\n     public void configure(JobConf conf) {\n       this.conf \u003d conf;\n       tmpOutputDir \u003d FileOutputFormat.getWorkOutputPath(this.conf);\n       masterIndex \u003d new Path(tmpOutputDir, \"_masterindex\");\n       index \u003d new Path(tmpOutputDir, \"_index\");\n+      replication \u003d conf.getInt(HAR_REPLICATION_LABEL, 3);\n       try {\n         fs \u003d masterIndex.getFileSystem(conf);\n         if (fs.exists(masterIndex)) {\n           fs.delete(masterIndex, false);\n         }\n         if (fs.exists(index)) {\n           fs.delete(index, false);\n         }\n         indexStream \u003d fs.create(index);\n         outStream \u003d fs.create(masterIndex);\n         String version \u003d VERSION + \" \\n\";\n         outStream.write(version.getBytes(Charsets.UTF_8));\n         \n       } catch(IOException e) {\n         throw new RuntimeException(e);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void configure(JobConf conf) {\n      this.conf \u003d conf;\n      tmpOutputDir \u003d FileOutputFormat.getWorkOutputPath(this.conf);\n      masterIndex \u003d new Path(tmpOutputDir, \"_masterindex\");\n      index \u003d new Path(tmpOutputDir, \"_index\");\n      replication \u003d conf.getInt(HAR_REPLICATION_LABEL, 3);\n      try {\n        fs \u003d masterIndex.getFileSystem(conf);\n        if (fs.exists(masterIndex)) {\n          fs.delete(masterIndex, false);\n        }\n        if (fs.exists(index)) {\n          fs.delete(index, false);\n        }\n        indexStream \u003d fs.create(index);\n        outStream \u003d fs.create(masterIndex);\n        String version \u003d VERSION + \" \\n\";\n        outStream.write(version.getBytes(Charsets.UTF_8));\n        \n      } catch(IOException e) {\n        throw new RuntimeException(e);\n      }\n    }",
      "path": "hadoop-tools/hadoop-archives/src/main/java/org/apache/hadoop/tools/HadoopArchives.java",
      "extendedDetails": {}
    },
    "c89977f89cb4520164c1747fe1abbaad215c42a0": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11529. Fix findbugs warnings in hadoop-archives. Contributed by Masatake Iwasaki.\n",
      "commitDate": "03/02/15 10:53 AM",
      "commitName": "c89977f89cb4520164c1747fe1abbaad215c42a0",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "18/11/14 5:05 PM",
      "commitNameOld": "79301e80d7510f055c01a06970bb409607a4197c",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 76.74,
      "commitsBetweenForRepo": 464,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n     public void configure(JobConf conf) {\n       this.conf \u003d conf;\n       tmpOutputDir \u003d FileOutputFormat.getWorkOutputPath(this.conf);\n       masterIndex \u003d new Path(tmpOutputDir, \"_masterindex\");\n       index \u003d new Path(tmpOutputDir, \"_index\");\n       try {\n         fs \u003d masterIndex.getFileSystem(conf);\n         if (fs.exists(masterIndex)) {\n           fs.delete(masterIndex, false);\n         }\n         if (fs.exists(index)) {\n           fs.delete(index, false);\n         }\n         indexStream \u003d fs.create(index);\n         outStream \u003d fs.create(masterIndex);\n         String version \u003d VERSION + \" \\n\";\n-        outStream.write(version.getBytes());\n+        outStream.write(version.getBytes(Charsets.UTF_8));\n         \n       } catch(IOException e) {\n         throw new RuntimeException(e);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void configure(JobConf conf) {\n      this.conf \u003d conf;\n      tmpOutputDir \u003d FileOutputFormat.getWorkOutputPath(this.conf);\n      masterIndex \u003d new Path(tmpOutputDir, \"_masterindex\");\n      index \u003d new Path(tmpOutputDir, \"_index\");\n      try {\n        fs \u003d masterIndex.getFileSystem(conf);\n        if (fs.exists(masterIndex)) {\n          fs.delete(masterIndex, false);\n        }\n        if (fs.exists(index)) {\n          fs.delete(index, false);\n        }\n        indexStream \u003d fs.create(index);\n        outStream \u003d fs.create(masterIndex);\n        String version \u003d VERSION + \" \\n\";\n        outStream.write(version.getBytes(Charsets.UTF_8));\n        \n      } catch(IOException e) {\n        throw new RuntimeException(e);\n      }\n    }",
      "path": "hadoop-tools/hadoop-archives/src/main/java/org/apache/hadoop/tools/HadoopArchives.java",
      "extendedDetails": {}
    },
    "0201be46c298e94176ec6297e9d9cdba3afc2bbd": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7810. move hadoop archive to core from tools. (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213907 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/12/11 12:17 PM",
      "commitName": "0201be46c298e94176ec6297e9d9cdba3afc2bbd",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "13/12/11 10:07 AM",
      "commitNameOld": "f2f4e9341387199e04679ebc8de5e05c0fdbd437",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.09,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public void configure(JobConf conf) {\n      this.conf \u003d conf;\n      tmpOutputDir \u003d FileOutputFormat.getWorkOutputPath(this.conf);\n      masterIndex \u003d new Path(tmpOutputDir, \"_masterindex\");\n      index \u003d new Path(tmpOutputDir, \"_index\");\n      try {\n        fs \u003d masterIndex.getFileSystem(conf);\n        if (fs.exists(masterIndex)) {\n          fs.delete(masterIndex, false);\n        }\n        if (fs.exists(index)) {\n          fs.delete(index, false);\n        }\n        indexStream \u003d fs.create(index);\n        outStream \u003d fs.create(masterIndex);\n        String version \u003d VERSION + \" \\n\";\n        outStream.write(version.getBytes());\n        \n      } catch(IOException e) {\n        throw new RuntimeException(e);\n      }\n    }",
      "path": "hadoop-tools/hadoop-archives/src/main/java/org/apache/hadoop/tools/HadoopArchives.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/HadoopArchives.java",
        "newPath": "hadoop-tools/hadoop-archives/src/main/java/org/apache/hadoop/tools/HadoopArchives.java"
      }
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public void configure(JobConf conf) {\n      this.conf \u003d conf;\n      tmpOutputDir \u003d FileOutputFormat.getWorkOutputPath(this.conf);\n      masterIndex \u003d new Path(tmpOutputDir, \"_masterindex\");\n      index \u003d new Path(tmpOutputDir, \"_index\");\n      try {\n        fs \u003d masterIndex.getFileSystem(conf);\n        if (fs.exists(masterIndex)) {\n          fs.delete(masterIndex, false);\n        }\n        if (fs.exists(index)) {\n          fs.delete(index, false);\n        }\n        indexStream \u003d fs.create(index);\n        outStream \u003d fs.create(masterIndex);\n        String version \u003d VERSION + \" \\n\";\n        outStream.write(version.getBytes());\n        \n      } catch(IOException e) {\n        throw new RuntimeException(e);\n      }\n    }",
      "path": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/HadoopArchives.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/src/tools/org/apache/hadoop/tools/HadoopArchives.java",
        "newPath": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/HadoopArchives.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public void configure(JobConf conf) {\n      this.conf \u003d conf;\n      tmpOutputDir \u003d FileOutputFormat.getWorkOutputPath(this.conf);\n      masterIndex \u003d new Path(tmpOutputDir, \"_masterindex\");\n      index \u003d new Path(tmpOutputDir, \"_index\");\n      try {\n        fs \u003d masterIndex.getFileSystem(conf);\n        if (fs.exists(masterIndex)) {\n          fs.delete(masterIndex, false);\n        }\n        if (fs.exists(index)) {\n          fs.delete(index, false);\n        }\n        indexStream \u003d fs.create(index);\n        outStream \u003d fs.create(masterIndex);\n        String version \u003d VERSION + \" \\n\";\n        outStream.write(version.getBytes());\n        \n      } catch(IOException e) {\n        throw new RuntimeException(e);\n      }\n    }",
      "path": "hadoop-mapreduce/src/tools/org/apache/hadoop/tools/HadoopArchives.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/tools/org/apache/hadoop/tools/HadoopArchives.java",
        "newPath": "hadoop-mapreduce/src/tools/org/apache/hadoop/tools/HadoopArchives.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,22 @@\n+    public void configure(JobConf conf) {\n+      this.conf \u003d conf;\n+      tmpOutputDir \u003d FileOutputFormat.getWorkOutputPath(this.conf);\n+      masterIndex \u003d new Path(tmpOutputDir, \"_masterindex\");\n+      index \u003d new Path(tmpOutputDir, \"_index\");\n+      try {\n+        fs \u003d masterIndex.getFileSystem(conf);\n+        if (fs.exists(masterIndex)) {\n+          fs.delete(masterIndex, false);\n+        }\n+        if (fs.exists(index)) {\n+          fs.delete(index, false);\n+        }\n+        indexStream \u003d fs.create(index);\n+        outStream \u003d fs.create(masterIndex);\n+        String version \u003d VERSION + \" \\n\";\n+        outStream.write(version.getBytes());\n+        \n+      } catch(IOException e) {\n+        throw new RuntimeException(e);\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public void configure(JobConf conf) {\n      this.conf \u003d conf;\n      tmpOutputDir \u003d FileOutputFormat.getWorkOutputPath(this.conf);\n      masterIndex \u003d new Path(tmpOutputDir, \"_masterindex\");\n      index \u003d new Path(tmpOutputDir, \"_index\");\n      try {\n        fs \u003d masterIndex.getFileSystem(conf);\n        if (fs.exists(masterIndex)) {\n          fs.delete(masterIndex, false);\n        }\n        if (fs.exists(index)) {\n          fs.delete(index, false);\n        }\n        indexStream \u003d fs.create(index);\n        outStream \u003d fs.create(masterIndex);\n        String version \u003d VERSION + \" \\n\";\n        outStream.write(version.getBytes());\n        \n      } catch(IOException e) {\n        throw new RuntimeException(e);\n      }\n    }",
      "path": "mapreduce/src/tools/org/apache/hadoop/tools/HadoopArchives.java"
    }
  }
}