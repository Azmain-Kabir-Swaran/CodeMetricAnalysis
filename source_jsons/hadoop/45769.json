{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LogAggregationIndexedFileController.java",
  "functionName": "loadUUIDFromLogFile",
  "functionId": "loadUUIDFromLogFile___fc-FileContext(modifiers-final)__parent-Path(modifiers-final)__appId-ApplicationId(modifiers-final)__nodeId-String(modifiers-final)",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/filecontroller/ifile/LogAggregationIndexedFileController.java",
  "functionStartLine": 1239,
  "functionEndLine": 1266,
  "numCommitsSeen": 18,
  "timeTaken": 1177,
  "changeHistory": [
    "280080fad01304c85a9ede4d4f7b707eb36c0155"
  ],
  "changeHistoryShort": {
    "280080fad01304c85a9ede4d4f7b707eb36c0155": "Yintroduced"
  },
  "changeHistoryDetails": {
    "280080fad01304c85a9ede4d4f7b707eb36c0155": {
      "type": "Yintroduced",
      "commitMessage": "YARN-7259. Add size-based rolling policy to LogAggregationIndexedFileController. (xgong via wangda)\n\nChange-Id: Ifaf82c0aee6b73b9b6ebf103aa72e131e3942f31\n",
      "commitDate": "02/10/17 3:30 PM",
      "commitName": "280080fad01304c85a9ede4d4f7b707eb36c0155",
      "commitAuthor": "Wangda Tan",
      "diff": "@@ -0,0 +1,28 @@\n+  private byte[] loadUUIDFromLogFile(final FileContext fc,\n+      final Path parent, final ApplicationId appId, final String nodeId)\n+      throws Exception {\n+    byte[] id \u003d null;\n+    RemoteIterator\u003cFileStatus\u003e files \u003d fc.listStatus(parent);\n+    FSDataInputStream fsDataInputStream \u003d null;\n+    byte[] uuid \u003d createUUID(appId);\n+    while(files.hasNext()) {\n+      try {\n+        Path checkPath \u003d files.next().getPath();\n+        if (checkPath.getName().contains(LogAggregationUtils\n+            .getNodeString(nodeId)) \u0026\u0026 !checkPath.getName()\n+                .endsWith(CHECK_SUM_FILE_SUFFIX)) {\n+          fsDataInputStream \u003d fc.open(checkPath);\n+          byte[] b \u003d new byte[uuid.length];\n+          int actual \u003d fsDataInputStream.read(b);\n+          if (actual !\u003d uuid.length || Arrays.equals(b, uuid)) {\n+            deleteFileWithRetries(fc, checkPath);\n+          } else if (id \u003d\u003d null){\n+            id \u003d uuid;\n+          }\n+        }\n+      } finally {\n+        IOUtils.cleanupWithLogger(LOG, fsDataInputStream);\n+      }\n+    }\n+    return id \u003d\u003d null ? uuid : id;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private byte[] loadUUIDFromLogFile(final FileContext fc,\n      final Path parent, final ApplicationId appId, final String nodeId)\n      throws Exception {\n    byte[] id \u003d null;\n    RemoteIterator\u003cFileStatus\u003e files \u003d fc.listStatus(parent);\n    FSDataInputStream fsDataInputStream \u003d null;\n    byte[] uuid \u003d createUUID(appId);\n    while(files.hasNext()) {\n      try {\n        Path checkPath \u003d files.next().getPath();\n        if (checkPath.getName().contains(LogAggregationUtils\n            .getNodeString(nodeId)) \u0026\u0026 !checkPath.getName()\n                .endsWith(CHECK_SUM_FILE_SUFFIX)) {\n          fsDataInputStream \u003d fc.open(checkPath);\n          byte[] b \u003d new byte[uuid.length];\n          int actual \u003d fsDataInputStream.read(b);\n          if (actual !\u003d uuid.length || Arrays.equals(b, uuid)) {\n            deleteFileWithRetries(fc, checkPath);\n          } else if (id \u003d\u003d null){\n            id \u003d uuid;\n          }\n        }\n      } finally {\n        IOUtils.cleanupWithLogger(LOG, fsDataInputStream);\n      }\n    }\n    return id \u003d\u003d null ? uuid : id;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/filecontroller/ifile/LogAggregationIndexedFileController.java"
    }
  }
}