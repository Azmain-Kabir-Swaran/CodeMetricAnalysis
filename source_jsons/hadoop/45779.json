{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LogAggregationTFileController.java",
  "functionName": "readAggregatedLogs",
  "functionId": "readAggregatedLogs___logRequest-ContainerLogsRequest__os-OutputStream",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/filecontroller/tfile/LogAggregationTFileController.java",
  "functionStartLine": 162,
  "functionEndLine": 259,
  "numCommitsSeen": 12,
  "timeTaken": 2395,
  "changeHistory": [
    "460ba7fb14114f44e14a660f533f32c54e504478",
    "3fddabc2fe4fbdb8ef3f9ce7558955c4f0794dcc",
    "63231a2a3008794c5ebcbc9d3855638fc5f28216",
    "91cc070d67533ebb3325b982eba2135e0d175a82"
  ],
  "changeHistoryShort": {
    "460ba7fb14114f44e14a660f533f32c54e504478": "Ybodychange",
    "3fddabc2fe4fbdb8ef3f9ce7558955c4f0794dcc": "Ybodychange",
    "63231a2a3008794c5ebcbc9d3855638fc5f28216": "Ybodychange",
    "91cc070d67533ebb3325b982eba2135e0d175a82": "Yintroduced"
  },
  "changeHistoryDetails": {
    "460ba7fb14114f44e14a660f533f32c54e504478": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9558.  Fixed LogAggregation test cases.\n            Contributed by Prabhu Joseph\n",
      "commitDate": "23/05/19 3:38 PM",
      "commitName": "460ba7fb14114f44e14a660f533f32c54e504478",
      "commitAuthor": "Eric Yang",
      "commitDateOld": "14/05/19 10:48 AM",
      "commitNameOld": "7d831eca645f93d064975ebae35a7cbea3bbad31",
      "commitAuthorOld": "Sunil G",
      "daysBetweenCommits": 9.2,
      "commitsBetweenForRepo": 56,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,97 +1,98 @@\n   public boolean readAggregatedLogs(ContainerLogsRequest logRequest,\n       OutputStream os) throws IOException {\n     boolean findLogs \u003d false;\n     boolean createPrintStream \u003d (os \u003d\u003d null);\n     ApplicationId appId \u003d logRequest.getAppId();\n     String nodeId \u003d logRequest.getNodeId();\n     List\u003cString\u003e logTypes \u003d new ArrayList\u003c\u003e();\n     if (logRequest.getLogTypes() !\u003d null \u0026\u0026 !logRequest\n         .getLogTypes().isEmpty()) {\n       logTypes.addAll(logRequest.getLogTypes());\n     }\n     String containerIdStr \u003d logRequest.getContainerId();\n     boolean getAllContainers \u003d (containerIdStr \u003d\u003d null\n         || containerIdStr.isEmpty());\n     long size \u003d logRequest.getBytes();\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d LogAggregationUtils\n-        .getRemoteNodeFileDir(conf, appId, logRequest.getAppOwner());\n+        .getRemoteNodeFileDir(conf, appId, logRequest.getAppOwner(),\n+        remoteRootLogDir, remoteRootLogDirSuffix);\n     byte[] buf \u003d new byte[65535];\n     while (nodeFiles !\u003d null \u0026\u0026 nodeFiles.hasNext()) {\n       final FileStatus thisNodeFile \u003d nodeFiles.next();\n       String nodeName \u003d thisNodeFile.getPath().getName();\n       if (nodeName.equals(appId + \".har\")) {\n         Path p \u003d new Path(\"har:///\"\n             + thisNodeFile.getPath().toUri().getRawPath());\n         nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n         continue;\n       }\n       if ((nodeId \u003d\u003d null || nodeName.contains(LogAggregationUtils\n           .getNodeString(nodeId))) \u0026\u0026 !nodeName.endsWith(\n               LogAggregationUtils.TMP_FILE_SUFFIX)) {\n         AggregatedLogFormat.LogReader reader \u003d null;\n         try {\n           reader \u003d new AggregatedLogFormat.LogReader(conf,\n               thisNodeFile.getPath());\n           DataInputStream valueStream;\n           LogKey key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n           while (valueStream !\u003d null) {\n             if (getAllContainers || (key.toString().equals(containerIdStr))) {\n               if (createPrintStream) {\n                 os \u003d LogToolUtils.createPrintStream(\n                     logRequest.getOutputLocalDir(),\n                     thisNodeFile.getPath().getName(), key.toString());\n               }\n               try {\n                 while (true) {\n                   try {\n                     String fileType \u003d valueStream.readUTF();\n                     String fileLengthStr \u003d valueStream.readUTF();\n                     long fileLength \u003d Long.parseLong(fileLengthStr);\n                     if (logTypes \u003d\u003d null || logTypes.isEmpty() ||\n                         logTypes.contains(fileType)) {\n                       LogToolUtils.outputContainerLog(key.toString(),\n                           nodeName, fileType, fileLength, size,\n                           Times.format(thisNodeFile.getModificationTime()),\n                           valueStream, os, buf,\n                           ContainerLogAggregationType.AGGREGATED);\n                       byte[] b \u003d aggregatedLogSuffix(fileType).getBytes(\n                           Charset.forName(\"UTF-8\"));\n                       os.write(b, 0, b.length);\n                       findLogs \u003d true;\n                     } else {\n                       long totalSkipped \u003d 0;\n                       long currSkipped \u003d 0;\n                       while (currSkipped !\u003d -1 \u0026\u0026 totalSkipped \u003c fileLength) {\n                         currSkipped \u003d valueStream.skip(\n                             fileLength - totalSkipped);\n                         totalSkipped +\u003d currSkipped;\n                       }\n                     }\n                   } catch (EOFException eof) {\n                     break;\n                   }\n                 }\n               } finally {\n                 os.flush();\n                 if (createPrintStream) {\n                   closePrintStream(os);\n                 }\n               }\n               if (!getAllContainers) {\n                 break;\n               }\n             }\n             // Next container\n             key \u003d new LogKey();\n             valueStream \u003d reader.next(key);\n           }\n         } finally {\n           if (reader !\u003d null) {\n             reader.close();\n           }\n         }\n       }\n     }\n     return findLogs;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean readAggregatedLogs(ContainerLogsRequest logRequest,\n      OutputStream os) throws IOException {\n    boolean findLogs \u003d false;\n    boolean createPrintStream \u003d (os \u003d\u003d null);\n    ApplicationId appId \u003d logRequest.getAppId();\n    String nodeId \u003d logRequest.getNodeId();\n    List\u003cString\u003e logTypes \u003d new ArrayList\u003c\u003e();\n    if (logRequest.getLogTypes() !\u003d null \u0026\u0026 !logRequest\n        .getLogTypes().isEmpty()) {\n      logTypes.addAll(logRequest.getLogTypes());\n    }\n    String containerIdStr \u003d logRequest.getContainerId();\n    boolean getAllContainers \u003d (containerIdStr \u003d\u003d null\n        || containerIdStr.isEmpty());\n    long size \u003d logRequest.getBytes();\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d LogAggregationUtils\n        .getRemoteNodeFileDir(conf, appId, logRequest.getAppOwner(),\n        remoteRootLogDir, remoteRootLogDirSuffix);\n    byte[] buf \u003d new byte[65535];\n    while (nodeFiles !\u003d null \u0026\u0026 nodeFiles.hasNext()) {\n      final FileStatus thisNodeFile \u003d nodeFiles.next();\n      String nodeName \u003d thisNodeFile.getPath().getName();\n      if (nodeName.equals(appId + \".har\")) {\n        Path p \u003d new Path(\"har:///\"\n            + thisNodeFile.getPath().toUri().getRawPath());\n        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n        continue;\n      }\n      if ((nodeId \u003d\u003d null || nodeName.contains(LogAggregationUtils\n          .getNodeString(nodeId))) \u0026\u0026 !nodeName.endsWith(\n              LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d null;\n        try {\n          reader \u003d new AggregatedLogFormat.LogReader(conf,\n              thisNodeFile.getPath());\n          DataInputStream valueStream;\n          LogKey key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n          while (valueStream !\u003d null) {\n            if (getAllContainers || (key.toString().equals(containerIdStr))) {\n              if (createPrintStream) {\n                os \u003d LogToolUtils.createPrintStream(\n                    logRequest.getOutputLocalDir(),\n                    thisNodeFile.getPath().getName(), key.toString());\n              }\n              try {\n                while (true) {\n                  try {\n                    String fileType \u003d valueStream.readUTF();\n                    String fileLengthStr \u003d valueStream.readUTF();\n                    long fileLength \u003d Long.parseLong(fileLengthStr);\n                    if (logTypes \u003d\u003d null || logTypes.isEmpty() ||\n                        logTypes.contains(fileType)) {\n                      LogToolUtils.outputContainerLog(key.toString(),\n                          nodeName, fileType, fileLength, size,\n                          Times.format(thisNodeFile.getModificationTime()),\n                          valueStream, os, buf,\n                          ContainerLogAggregationType.AGGREGATED);\n                      byte[] b \u003d aggregatedLogSuffix(fileType).getBytes(\n                          Charset.forName(\"UTF-8\"));\n                      os.write(b, 0, b.length);\n                      findLogs \u003d true;\n                    } else {\n                      long totalSkipped \u003d 0;\n                      long currSkipped \u003d 0;\n                      while (currSkipped !\u003d -1 \u0026\u0026 totalSkipped \u003c fileLength) {\n                        currSkipped \u003d valueStream.skip(\n                            fileLength - totalSkipped);\n                        totalSkipped +\u003d currSkipped;\n                      }\n                    }\n                  } catch (EOFException eof) {\n                    break;\n                  }\n                }\n              } finally {\n                os.flush();\n                if (createPrintStream) {\n                  closePrintStream(os);\n                }\n              }\n              if (!getAllContainers) {\n                break;\n              }\n            }\n            // Next container\n            key \u003d new LogKey();\n            valueStream \u003d reader.next(key);\n          }\n        } finally {\n          if (reader !\u003d null) {\n            reader.close();\n          }\n        }\n      }\n    }\n    return findLogs;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/filecontroller/tfile/LogAggregationTFileController.java",
      "extendedDetails": {}
    },
    "3fddabc2fe4fbdb8ef3f9ce7558955c4f0794dcc": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7072. Add a new log aggregation file format controller. Contributed by Xuan Gong.\n",
      "commitDate": "08/09/17 3:16 PM",
      "commitName": "3fddabc2fe4fbdb8ef3f9ce7558955c4f0794dcc",
      "commitAuthor": "Junping Du",
      "commitDateOld": "06/09/17 1:19 PM",
      "commitNameOld": "63231a2a3008794c5ebcbc9d3855638fc5f28216",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 2.08,
      "commitsBetweenForRepo": 34,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,102 +1,97 @@\n   public boolean readAggregatedLogs(ContainerLogsRequest logRequest,\n       OutputStream os) throws IOException {\n     boolean findLogs \u003d false;\n     boolean createPrintStream \u003d (os \u003d\u003d null);\n     ApplicationId appId \u003d logRequest.getAppId();\n     String nodeId \u003d logRequest.getNodeId();\n     List\u003cString\u003e logTypes \u003d new ArrayList\u003c\u003e();\n     if (logRequest.getLogTypes() !\u003d null \u0026\u0026 !logRequest\n         .getLogTypes().isEmpty()) {\n       logTypes.addAll(logRequest.getLogTypes());\n     }\n     String containerIdStr \u003d logRequest.getContainerId();\n     boolean getAllContainers \u003d (containerIdStr \u003d\u003d null\n         || containerIdStr.isEmpty());\n     long size \u003d logRequest.getBytes();\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d LogAggregationUtils\n         .getRemoteNodeFileDir(conf, appId, logRequest.getAppOwner());\n     byte[] buf \u003d new byte[65535];\n     while (nodeFiles !\u003d null \u0026\u0026 nodeFiles.hasNext()) {\n       final FileStatus thisNodeFile \u003d nodeFiles.next();\n       String nodeName \u003d thisNodeFile.getPath().getName();\n       if (nodeName.equals(appId + \".har\")) {\n         Path p \u003d new Path(\"har:///\"\n             + thisNodeFile.getPath().toUri().getRawPath());\n         nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n         continue;\n       }\n       if ((nodeId \u003d\u003d null || nodeName.contains(LogAggregationUtils\n           .getNodeString(nodeId))) \u0026\u0026 !nodeName.endsWith(\n               LogAggregationUtils.TMP_FILE_SUFFIX)) {\n         AggregatedLogFormat.LogReader reader \u003d null;\n         try {\n           reader \u003d new AggregatedLogFormat.LogReader(conf,\n               thisNodeFile.getPath());\n           DataInputStream valueStream;\n           LogKey key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n           while (valueStream !\u003d null) {\n             if (getAllContainers || (key.toString().equals(containerIdStr))) {\n               if (createPrintStream) {\n-                os \u003d createPrintStream(\n+                os \u003d LogToolUtils.createPrintStream(\n                     logRequest.getOutputLocalDir(),\n                     thisNodeFile.getPath().getName(), key.toString());\n               }\n               try {\n                 while (true) {\n                   try {\n                     String fileType \u003d valueStream.readUTF();\n                     String fileLengthStr \u003d valueStream.readUTF();\n                     long fileLength \u003d Long.parseLong(fileLengthStr);\n                     if (logTypes \u003d\u003d null || logTypes.isEmpty() ||\n                         logTypes.contains(fileType)) {\n                       LogToolUtils.outputContainerLog(key.toString(),\n                           nodeName, fileType, fileLength, size,\n                           Times.format(thisNodeFile.getModificationTime()),\n                           valueStream, os, buf,\n                           ContainerLogAggregationType.AGGREGATED);\n-                      StringBuilder sb \u003d new StringBuilder();\n-                      String endOfFile \u003d \"End of LogType:\" + fileType;\n-                      sb.append(\"\\n\" + endOfFile + \"\\n\");\n-                      sb.append(StringUtils.repeat(\"*\", endOfFile.length() + 50)\n-                          + \"\\n\\n\");\n-                      byte[] b \u003d sb.toString().getBytes(\n+                      byte[] b \u003d aggregatedLogSuffix(fileType).getBytes(\n                           Charset.forName(\"UTF-8\"));\n                       os.write(b, 0, b.length);\n                       findLogs \u003d true;\n                     } else {\n                       long totalSkipped \u003d 0;\n                       long currSkipped \u003d 0;\n                       while (currSkipped !\u003d -1 \u0026\u0026 totalSkipped \u003c fileLength) {\n                         currSkipped \u003d valueStream.skip(\n                             fileLength - totalSkipped);\n                         totalSkipped +\u003d currSkipped;\n                       }\n                     }\n                   } catch (EOFException eof) {\n                     break;\n                   }\n                 }\n               } finally {\n                 os.flush();\n                 if (createPrintStream) {\n                   closePrintStream(os);\n                 }\n               }\n               if (!getAllContainers) {\n                 break;\n               }\n             }\n             // Next container\n             key \u003d new LogKey();\n             valueStream \u003d reader.next(key);\n           }\n         } finally {\n           if (reader !\u003d null) {\n             reader.close();\n           }\n         }\n       }\n     }\n     return findLogs;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean readAggregatedLogs(ContainerLogsRequest logRequest,\n      OutputStream os) throws IOException {\n    boolean findLogs \u003d false;\n    boolean createPrintStream \u003d (os \u003d\u003d null);\n    ApplicationId appId \u003d logRequest.getAppId();\n    String nodeId \u003d logRequest.getNodeId();\n    List\u003cString\u003e logTypes \u003d new ArrayList\u003c\u003e();\n    if (logRequest.getLogTypes() !\u003d null \u0026\u0026 !logRequest\n        .getLogTypes().isEmpty()) {\n      logTypes.addAll(logRequest.getLogTypes());\n    }\n    String containerIdStr \u003d logRequest.getContainerId();\n    boolean getAllContainers \u003d (containerIdStr \u003d\u003d null\n        || containerIdStr.isEmpty());\n    long size \u003d logRequest.getBytes();\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d LogAggregationUtils\n        .getRemoteNodeFileDir(conf, appId, logRequest.getAppOwner());\n    byte[] buf \u003d new byte[65535];\n    while (nodeFiles !\u003d null \u0026\u0026 nodeFiles.hasNext()) {\n      final FileStatus thisNodeFile \u003d nodeFiles.next();\n      String nodeName \u003d thisNodeFile.getPath().getName();\n      if (nodeName.equals(appId + \".har\")) {\n        Path p \u003d new Path(\"har:///\"\n            + thisNodeFile.getPath().toUri().getRawPath());\n        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n        continue;\n      }\n      if ((nodeId \u003d\u003d null || nodeName.contains(LogAggregationUtils\n          .getNodeString(nodeId))) \u0026\u0026 !nodeName.endsWith(\n              LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d null;\n        try {\n          reader \u003d new AggregatedLogFormat.LogReader(conf,\n              thisNodeFile.getPath());\n          DataInputStream valueStream;\n          LogKey key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n          while (valueStream !\u003d null) {\n            if (getAllContainers || (key.toString().equals(containerIdStr))) {\n              if (createPrintStream) {\n                os \u003d LogToolUtils.createPrintStream(\n                    logRequest.getOutputLocalDir(),\n                    thisNodeFile.getPath().getName(), key.toString());\n              }\n              try {\n                while (true) {\n                  try {\n                    String fileType \u003d valueStream.readUTF();\n                    String fileLengthStr \u003d valueStream.readUTF();\n                    long fileLength \u003d Long.parseLong(fileLengthStr);\n                    if (logTypes \u003d\u003d null || logTypes.isEmpty() ||\n                        logTypes.contains(fileType)) {\n                      LogToolUtils.outputContainerLog(key.toString(),\n                          nodeName, fileType, fileLength, size,\n                          Times.format(thisNodeFile.getModificationTime()),\n                          valueStream, os, buf,\n                          ContainerLogAggregationType.AGGREGATED);\n                      byte[] b \u003d aggregatedLogSuffix(fileType).getBytes(\n                          Charset.forName(\"UTF-8\"));\n                      os.write(b, 0, b.length);\n                      findLogs \u003d true;\n                    } else {\n                      long totalSkipped \u003d 0;\n                      long currSkipped \u003d 0;\n                      while (currSkipped !\u003d -1 \u0026\u0026 totalSkipped \u003c fileLength) {\n                        currSkipped \u003d valueStream.skip(\n                            fileLength - totalSkipped);\n                        totalSkipped +\u003d currSkipped;\n                      }\n                    }\n                  } catch (EOFException eof) {\n                    break;\n                  }\n                }\n              } finally {\n                os.flush();\n                if (createPrintStream) {\n                  closePrintStream(os);\n                }\n              }\n              if (!getAllContainers) {\n                break;\n              }\n            }\n            // Next container\n            key \u003d new LogKey();\n            valueStream \u003d reader.next(key);\n          }\n        } finally {\n          if (reader !\u003d null) {\n            reader.close();\n          }\n        }\n      }\n    }\n    return findLogs;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/filecontroller/tfile/LogAggregationTFileController.java",
      "extendedDetails": {}
    },
    "63231a2a3008794c5ebcbc9d3855638fc5f28216": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7148. TestLogsCLI fails in trunk and branch-2 and javadoc error. Contributed by Xuan Gong.\n",
      "commitDate": "06/09/17 1:19 PM",
      "commitName": "63231a2a3008794c5ebcbc9d3855638fc5f28216",
      "commitAuthor": "Junping Du",
      "commitDateOld": "31/08/17 4:41 PM",
      "commitNameOld": "91cc070d67533ebb3325b982eba2135e0d175a82",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 5.86,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,103 +1,102 @@\n   public boolean readAggregatedLogs(ContainerLogsRequest logRequest,\n       OutputStream os) throws IOException {\n     boolean findLogs \u003d false;\n     boolean createPrintStream \u003d (os \u003d\u003d null);\n     ApplicationId appId \u003d logRequest.getAppId();\n     String nodeId \u003d logRequest.getNodeId();\n     List\u003cString\u003e logTypes \u003d new ArrayList\u003c\u003e();\n     if (logRequest.getLogTypes() !\u003d null \u0026\u0026 !logRequest\n         .getLogTypes().isEmpty()) {\n       logTypes.addAll(logRequest.getLogTypes());\n     }\n     String containerIdStr \u003d logRequest.getContainerId();\n     boolean getAllContainers \u003d (containerIdStr \u003d\u003d null\n         || containerIdStr.isEmpty());\n     long size \u003d logRequest.getBytes();\n     RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d LogAggregationUtils\n         .getRemoteNodeFileDir(conf, appId, logRequest.getAppOwner());\n     byte[] buf \u003d new byte[65535];\n     while (nodeFiles !\u003d null \u0026\u0026 nodeFiles.hasNext()) {\n       final FileStatus thisNodeFile \u003d nodeFiles.next();\n-      LOG.error(thisNodeFile.getPath().toString());\n       String nodeName \u003d thisNodeFile.getPath().getName();\n       if (nodeName.equals(appId + \".har\")) {\n         Path p \u003d new Path(\"har:///\"\n             + thisNodeFile.getPath().toUri().getRawPath());\n         nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n         continue;\n       }\n       if ((nodeId \u003d\u003d null || nodeName.contains(LogAggregationUtils\n           .getNodeString(nodeId))) \u0026\u0026 !nodeName.endsWith(\n               LogAggregationUtils.TMP_FILE_SUFFIX)) {\n         AggregatedLogFormat.LogReader reader \u003d null;\n         try {\n           reader \u003d new AggregatedLogFormat.LogReader(conf,\n               thisNodeFile.getPath());\n           DataInputStream valueStream;\n           LogKey key \u003d new LogKey();\n           valueStream \u003d reader.next(key);\n           while (valueStream !\u003d null) {\n             if (getAllContainers || (key.toString().equals(containerIdStr))) {\n               if (createPrintStream) {\n                 os \u003d createPrintStream(\n                     logRequest.getOutputLocalDir(),\n                     thisNodeFile.getPath().getName(), key.toString());\n               }\n               try {\n                 while (true) {\n                   try {\n                     String fileType \u003d valueStream.readUTF();\n                     String fileLengthStr \u003d valueStream.readUTF();\n                     long fileLength \u003d Long.parseLong(fileLengthStr);\n                     if (logTypes \u003d\u003d null || logTypes.isEmpty() ||\n                         logTypes.contains(fileType)) {\n                       LogToolUtils.outputContainerLog(key.toString(),\n                           nodeName, fileType, fileLength, size,\n                           Times.format(thisNodeFile.getModificationTime()),\n                           valueStream, os, buf,\n                           ContainerLogAggregationType.AGGREGATED);\n                       StringBuilder sb \u003d new StringBuilder();\n                       String endOfFile \u003d \"End of LogType:\" + fileType;\n                       sb.append(\"\\n\" + endOfFile + \"\\n\");\n                       sb.append(StringUtils.repeat(\"*\", endOfFile.length() + 50)\n                           + \"\\n\\n\");\n                       byte[] b \u003d sb.toString().getBytes(\n                           Charset.forName(\"UTF-8\"));\n                       os.write(b, 0, b.length);\n                       findLogs \u003d true;\n                     } else {\n                       long totalSkipped \u003d 0;\n                       long currSkipped \u003d 0;\n                       while (currSkipped !\u003d -1 \u0026\u0026 totalSkipped \u003c fileLength) {\n                         currSkipped \u003d valueStream.skip(\n                             fileLength - totalSkipped);\n                         totalSkipped +\u003d currSkipped;\n                       }\n                     }\n                   } catch (EOFException eof) {\n                     break;\n                   }\n                 }\n               } finally {\n                 os.flush();\n                 if (createPrintStream) {\n                   closePrintStream(os);\n                 }\n               }\n               if (!getAllContainers) {\n                 break;\n               }\n             }\n             // Next container\n             key \u003d new LogKey();\n             valueStream \u003d reader.next(key);\n           }\n         } finally {\n           if (reader !\u003d null) {\n             reader.close();\n           }\n         }\n       }\n     }\n     return findLogs;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean readAggregatedLogs(ContainerLogsRequest logRequest,\n      OutputStream os) throws IOException {\n    boolean findLogs \u003d false;\n    boolean createPrintStream \u003d (os \u003d\u003d null);\n    ApplicationId appId \u003d logRequest.getAppId();\n    String nodeId \u003d logRequest.getNodeId();\n    List\u003cString\u003e logTypes \u003d new ArrayList\u003c\u003e();\n    if (logRequest.getLogTypes() !\u003d null \u0026\u0026 !logRequest\n        .getLogTypes().isEmpty()) {\n      logTypes.addAll(logRequest.getLogTypes());\n    }\n    String containerIdStr \u003d logRequest.getContainerId();\n    boolean getAllContainers \u003d (containerIdStr \u003d\u003d null\n        || containerIdStr.isEmpty());\n    long size \u003d logRequest.getBytes();\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d LogAggregationUtils\n        .getRemoteNodeFileDir(conf, appId, logRequest.getAppOwner());\n    byte[] buf \u003d new byte[65535];\n    while (nodeFiles !\u003d null \u0026\u0026 nodeFiles.hasNext()) {\n      final FileStatus thisNodeFile \u003d nodeFiles.next();\n      String nodeName \u003d thisNodeFile.getPath().getName();\n      if (nodeName.equals(appId + \".har\")) {\n        Path p \u003d new Path(\"har:///\"\n            + thisNodeFile.getPath().toUri().getRawPath());\n        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n        continue;\n      }\n      if ((nodeId \u003d\u003d null || nodeName.contains(LogAggregationUtils\n          .getNodeString(nodeId))) \u0026\u0026 !nodeName.endsWith(\n              LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d null;\n        try {\n          reader \u003d new AggregatedLogFormat.LogReader(conf,\n              thisNodeFile.getPath());\n          DataInputStream valueStream;\n          LogKey key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n          while (valueStream !\u003d null) {\n            if (getAllContainers || (key.toString().equals(containerIdStr))) {\n              if (createPrintStream) {\n                os \u003d createPrintStream(\n                    logRequest.getOutputLocalDir(),\n                    thisNodeFile.getPath().getName(), key.toString());\n              }\n              try {\n                while (true) {\n                  try {\n                    String fileType \u003d valueStream.readUTF();\n                    String fileLengthStr \u003d valueStream.readUTF();\n                    long fileLength \u003d Long.parseLong(fileLengthStr);\n                    if (logTypes \u003d\u003d null || logTypes.isEmpty() ||\n                        logTypes.contains(fileType)) {\n                      LogToolUtils.outputContainerLog(key.toString(),\n                          nodeName, fileType, fileLength, size,\n                          Times.format(thisNodeFile.getModificationTime()),\n                          valueStream, os, buf,\n                          ContainerLogAggregationType.AGGREGATED);\n                      StringBuilder sb \u003d new StringBuilder();\n                      String endOfFile \u003d \"End of LogType:\" + fileType;\n                      sb.append(\"\\n\" + endOfFile + \"\\n\");\n                      sb.append(StringUtils.repeat(\"*\", endOfFile.length() + 50)\n                          + \"\\n\\n\");\n                      byte[] b \u003d sb.toString().getBytes(\n                          Charset.forName(\"UTF-8\"));\n                      os.write(b, 0, b.length);\n                      findLogs \u003d true;\n                    } else {\n                      long totalSkipped \u003d 0;\n                      long currSkipped \u003d 0;\n                      while (currSkipped !\u003d -1 \u0026\u0026 totalSkipped \u003c fileLength) {\n                        currSkipped \u003d valueStream.skip(\n                            fileLength - totalSkipped);\n                        totalSkipped +\u003d currSkipped;\n                      }\n                    }\n                  } catch (EOFException eof) {\n                    break;\n                  }\n                }\n              } finally {\n                os.flush();\n                if (createPrintStream) {\n                  closePrintStream(os);\n                }\n              }\n              if (!getAllContainers) {\n                break;\n              }\n            }\n            // Next container\n            key \u003d new LogKey();\n            valueStream \u003d reader.next(key);\n          }\n        } finally {\n          if (reader !\u003d null) {\n            reader.close();\n          }\n        }\n      }\n    }\n    return findLogs;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/filecontroller/tfile/LogAggregationTFileController.java",
      "extendedDetails": {}
    },
    "91cc070d67533ebb3325b982eba2135e0d175a82": {
      "type": "Yintroduced",
      "commitMessage": "YARN-6877. Create an abstract log reader for extendability. Contributed by Xuan Gong.\n",
      "commitDate": "31/08/17 4:41 PM",
      "commitName": "91cc070d67533ebb3325b982eba2135e0d175a82",
      "commitAuthor": "Junping Du",
      "diff": "@@ -0,0 +1,103 @@\n+  public boolean readAggregatedLogs(ContainerLogsRequest logRequest,\n+      OutputStream os) throws IOException {\n+    boolean findLogs \u003d false;\n+    boolean createPrintStream \u003d (os \u003d\u003d null);\n+    ApplicationId appId \u003d logRequest.getAppId();\n+    String nodeId \u003d logRequest.getNodeId();\n+    List\u003cString\u003e logTypes \u003d new ArrayList\u003c\u003e();\n+    if (logRequest.getLogTypes() !\u003d null \u0026\u0026 !logRequest\n+        .getLogTypes().isEmpty()) {\n+      logTypes.addAll(logRequest.getLogTypes());\n+    }\n+    String containerIdStr \u003d logRequest.getContainerId();\n+    boolean getAllContainers \u003d (containerIdStr \u003d\u003d null\n+        || containerIdStr.isEmpty());\n+    long size \u003d logRequest.getBytes();\n+    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d LogAggregationUtils\n+        .getRemoteNodeFileDir(conf, appId, logRequest.getAppOwner());\n+    byte[] buf \u003d new byte[65535];\n+    while (nodeFiles !\u003d null \u0026\u0026 nodeFiles.hasNext()) {\n+      final FileStatus thisNodeFile \u003d nodeFiles.next();\n+      LOG.error(thisNodeFile.getPath().toString());\n+      String nodeName \u003d thisNodeFile.getPath().getName();\n+      if (nodeName.equals(appId + \".har\")) {\n+        Path p \u003d new Path(\"har:///\"\n+            + thisNodeFile.getPath().toUri().getRawPath());\n+        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n+        continue;\n+      }\n+      if ((nodeId \u003d\u003d null || nodeName.contains(LogAggregationUtils\n+          .getNodeString(nodeId))) \u0026\u0026 !nodeName.endsWith(\n+              LogAggregationUtils.TMP_FILE_SUFFIX)) {\n+        AggregatedLogFormat.LogReader reader \u003d null;\n+        try {\n+          reader \u003d new AggregatedLogFormat.LogReader(conf,\n+              thisNodeFile.getPath());\n+          DataInputStream valueStream;\n+          LogKey key \u003d new LogKey();\n+          valueStream \u003d reader.next(key);\n+          while (valueStream !\u003d null) {\n+            if (getAllContainers || (key.toString().equals(containerIdStr))) {\n+              if (createPrintStream) {\n+                os \u003d createPrintStream(\n+                    logRequest.getOutputLocalDir(),\n+                    thisNodeFile.getPath().getName(), key.toString());\n+              }\n+              try {\n+                while (true) {\n+                  try {\n+                    String fileType \u003d valueStream.readUTF();\n+                    String fileLengthStr \u003d valueStream.readUTF();\n+                    long fileLength \u003d Long.parseLong(fileLengthStr);\n+                    if (logTypes \u003d\u003d null || logTypes.isEmpty() ||\n+                        logTypes.contains(fileType)) {\n+                      LogToolUtils.outputContainerLog(key.toString(),\n+                          nodeName, fileType, fileLength, size,\n+                          Times.format(thisNodeFile.getModificationTime()),\n+                          valueStream, os, buf,\n+                          ContainerLogAggregationType.AGGREGATED);\n+                      StringBuilder sb \u003d new StringBuilder();\n+                      String endOfFile \u003d \"End of LogType:\" + fileType;\n+                      sb.append(\"\\n\" + endOfFile + \"\\n\");\n+                      sb.append(StringUtils.repeat(\"*\", endOfFile.length() + 50)\n+                          + \"\\n\\n\");\n+                      byte[] b \u003d sb.toString().getBytes(\n+                          Charset.forName(\"UTF-8\"));\n+                      os.write(b, 0, b.length);\n+                      findLogs \u003d true;\n+                    } else {\n+                      long totalSkipped \u003d 0;\n+                      long currSkipped \u003d 0;\n+                      while (currSkipped !\u003d -1 \u0026\u0026 totalSkipped \u003c fileLength) {\n+                        currSkipped \u003d valueStream.skip(\n+                            fileLength - totalSkipped);\n+                        totalSkipped +\u003d currSkipped;\n+                      }\n+                    }\n+                  } catch (EOFException eof) {\n+                    break;\n+                  }\n+                }\n+              } finally {\n+                os.flush();\n+                if (createPrintStream) {\n+                  closePrintStream(os);\n+                }\n+              }\n+              if (!getAllContainers) {\n+                break;\n+              }\n+            }\n+            // Next container\n+            key \u003d new LogKey();\n+            valueStream \u003d reader.next(key);\n+          }\n+        } finally {\n+          if (reader !\u003d null) {\n+            reader.close();\n+          }\n+        }\n+      }\n+    }\n+    return findLogs;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean readAggregatedLogs(ContainerLogsRequest logRequest,\n      OutputStream os) throws IOException {\n    boolean findLogs \u003d false;\n    boolean createPrintStream \u003d (os \u003d\u003d null);\n    ApplicationId appId \u003d logRequest.getAppId();\n    String nodeId \u003d logRequest.getNodeId();\n    List\u003cString\u003e logTypes \u003d new ArrayList\u003c\u003e();\n    if (logRequest.getLogTypes() !\u003d null \u0026\u0026 !logRequest\n        .getLogTypes().isEmpty()) {\n      logTypes.addAll(logRequest.getLogTypes());\n    }\n    String containerIdStr \u003d logRequest.getContainerId();\n    boolean getAllContainers \u003d (containerIdStr \u003d\u003d null\n        || containerIdStr.isEmpty());\n    long size \u003d logRequest.getBytes();\n    RemoteIterator\u003cFileStatus\u003e nodeFiles \u003d LogAggregationUtils\n        .getRemoteNodeFileDir(conf, appId, logRequest.getAppOwner());\n    byte[] buf \u003d new byte[65535];\n    while (nodeFiles !\u003d null \u0026\u0026 nodeFiles.hasNext()) {\n      final FileStatus thisNodeFile \u003d nodeFiles.next();\n      LOG.error(thisNodeFile.getPath().toString());\n      String nodeName \u003d thisNodeFile.getPath().getName();\n      if (nodeName.equals(appId + \".har\")) {\n        Path p \u003d new Path(\"har:///\"\n            + thisNodeFile.getPath().toUri().getRawPath());\n        nodeFiles \u003d HarFs.get(p.toUri(), conf).listStatusIterator(p);\n        continue;\n      }\n      if ((nodeId \u003d\u003d null || nodeName.contains(LogAggregationUtils\n          .getNodeString(nodeId))) \u0026\u0026 !nodeName.endsWith(\n              LogAggregationUtils.TMP_FILE_SUFFIX)) {\n        AggregatedLogFormat.LogReader reader \u003d null;\n        try {\n          reader \u003d new AggregatedLogFormat.LogReader(conf,\n              thisNodeFile.getPath());\n          DataInputStream valueStream;\n          LogKey key \u003d new LogKey();\n          valueStream \u003d reader.next(key);\n          while (valueStream !\u003d null) {\n            if (getAllContainers || (key.toString().equals(containerIdStr))) {\n              if (createPrintStream) {\n                os \u003d createPrintStream(\n                    logRequest.getOutputLocalDir(),\n                    thisNodeFile.getPath().getName(), key.toString());\n              }\n              try {\n                while (true) {\n                  try {\n                    String fileType \u003d valueStream.readUTF();\n                    String fileLengthStr \u003d valueStream.readUTF();\n                    long fileLength \u003d Long.parseLong(fileLengthStr);\n                    if (logTypes \u003d\u003d null || logTypes.isEmpty() ||\n                        logTypes.contains(fileType)) {\n                      LogToolUtils.outputContainerLog(key.toString(),\n                          nodeName, fileType, fileLength, size,\n                          Times.format(thisNodeFile.getModificationTime()),\n                          valueStream, os, buf,\n                          ContainerLogAggregationType.AGGREGATED);\n                      StringBuilder sb \u003d new StringBuilder();\n                      String endOfFile \u003d \"End of LogType:\" + fileType;\n                      sb.append(\"\\n\" + endOfFile + \"\\n\");\n                      sb.append(StringUtils.repeat(\"*\", endOfFile.length() + 50)\n                          + \"\\n\\n\");\n                      byte[] b \u003d sb.toString().getBytes(\n                          Charset.forName(\"UTF-8\"));\n                      os.write(b, 0, b.length);\n                      findLogs \u003d true;\n                    } else {\n                      long totalSkipped \u003d 0;\n                      long currSkipped \u003d 0;\n                      while (currSkipped !\u003d -1 \u0026\u0026 totalSkipped \u003c fileLength) {\n                        currSkipped \u003d valueStream.skip(\n                            fileLength - totalSkipped);\n                        totalSkipped +\u003d currSkipped;\n                      }\n                    }\n                  } catch (EOFException eof) {\n                    break;\n                  }\n                }\n              } finally {\n                os.flush();\n                if (createPrintStream) {\n                  closePrintStream(os);\n                }\n              }\n              if (!getAllContainers) {\n                break;\n              }\n            }\n            // Next container\n            key \u003d new LogKey();\n            valueStream \u003d reader.next(key);\n          }\n        } finally {\n          if (reader !\u003d null) {\n            reader.close();\n          }\n        }\n      }\n    }\n    return findLogs;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/filecontroller/tfile/LogAggregationTFileController.java"
    }
  }
}