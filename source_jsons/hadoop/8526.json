{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImage.java",
  "functionName": "saveFSImageInAllDirs",
  "functionId": "saveFSImageInAllDirs___source-FSNamesystem__txid-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
  "functionStartLine": 1193,
  "functionEndLine": 1203,
  "numCommitsSeen": 139,
  "timeTaken": 6816,
  "changeHistory": [
    "d3268c4b10a0f728b554ddb6d69b666a9ca13f12",
    "4f9bbaa301194e3d20972a10f51638c7f4d121f0",
    "15ddb6634f8bdab37ce43f99f8338d84422c7232",
    "646e855f6ef058b636a5fc85637a3f8e17fddaba",
    "06e84a1bca19bd01568a3095e33944d4d6387fd3",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "d3268c4b10a0f728b554ddb6d69b666a9ca13f12": "Ybodychange",
    "4f9bbaa301194e3d20972a10f51638c7f4d121f0": "Ybodychange",
    "15ddb6634f8bdab37ce43f99f8338d84422c7232": "Ybodychange",
    "646e855f6ef058b636a5fc85637a3f8e17fddaba": "Ymultichange(Ymodifierchange,Ybodychange)",
    "06e84a1bca19bd01568a3095e33944d4d6387fd3": "Ymultichange(Yparameterchange,Ybodychange)",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": "Ymultichange(Yrename,Yparameterchange,Ymodifierchange,Ybodychange)",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d3268c4b10a0f728b554ddb6d69b666a9ca13f12": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3519. Checkpoint upload may interfere with a concurrent saveNamespace. Contributed by Ming Ma.\n",
      "commitDate": "22/01/15 4:26 PM",
      "commitName": "d3268c4b10a0f728b554ddb6d69b666a9ca13f12",
      "commitAuthor": "cnauroth",
      "commitDateOld": "01/12/14 9:48 PM",
      "commitNameOld": "042699401ebe5186fa5556a79f8f9a206e5ebcd7",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 51.78,
      "commitsBetweenForRepo": 321,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,11 @@\n   protected synchronized void saveFSImageInAllDirs(FSNamesystem source, long txid)\n       throws IOException {\n-    saveFSImageInAllDirs(source, NameNodeFile.IMAGE, txid, null);\n+    if (!addToCheckpointing(txid)) {\n+      throw new IOException((\"FS image is being downloaded from another NN\"));\n+    }\n+    try {\n+      saveFSImageInAllDirs(source, NameNodeFile.IMAGE, txid, null);\n+    } finally {\n+      removeFromCheckpointing(txid);\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized void saveFSImageInAllDirs(FSNamesystem source, long txid)\n      throws IOException {\n    if (!addToCheckpointing(txid)) {\n      throw new IOException((\"FS image is being downloaded from another NN\"));\n    }\n    try {\n      saveFSImageInAllDirs(source, NameNodeFile.IMAGE, txid, null);\n    } finally {\n      removeFromCheckpointing(txid);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "4f9bbaa301194e3d20972a10f51638c7f4d121f0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5889. When starting rolling upgrade, create a fs image for rollback so that the standby namenode can create checkpoints during upgrade.  Contributed by szetszwo \u0026 jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1567861 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/02/14 12:04 AM",
      "commitName": "4f9bbaa301194e3d20972a10f51638c7f4d121f0",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "06/02/14 6:08 PM",
      "commitNameOld": "c780454413caffbc37a02c4252eb5ec7abe57f97",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 6.25,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,4 @@\n   protected synchronized void saveFSImageInAllDirs(FSNamesystem source, long txid)\n       throws IOException {\n-    saveFSImageInAllDirs(source, txid, null);\n+    saveFSImageInAllDirs(source, NameNodeFile.IMAGE, txid, null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized void saveFSImageInAllDirs(FSNamesystem source, long txid)\n      throws IOException {\n    saveFSImageInAllDirs(source, NameNodeFile.IMAGE, txid, null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "15ddb6634f8bdab37ce43f99f8338d84422c7232": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2800. Fix cancellation of checkpoints in the standby node to be more reliable. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1339745 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/05/12 10:49 AM",
      "commitName": "15ddb6634f8bdab37ce43f99f8338d84422c7232",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "14/05/12 5:41 PM",
      "commitNameOld": "95710c15b7a724897bcde826e112df6d4b4fe56b",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 2.71,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,4 @@\n   protected synchronized void saveFSImageInAllDirs(FSNamesystem source, long txid)\n-      throws IOException {    \n-    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n-      throw new IOException(\"No image directories available!\");\n-    }\n-    \n-    SaveNamespaceContext ctx \u003d new SaveNamespaceContext(\n-        source, txid);\n-    curSaveNamespaceContext \u003d ctx;\n-    \n-    try {\n-      List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n-      // save images into current\n-      for (Iterator\u003cStorageDirectory\u003e it\n-             \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n-        StorageDirectory sd \u003d it.next();\n-        FSImageSaver saver \u003d new FSImageSaver(ctx, sd);\n-        Thread saveThread \u003d new Thread(saver, saver.toString());\n-        saveThreads.add(saveThread);\n-        saveThread.start();\n-      }\n-      waitForThreads(saveThreads);\n-      saveThreads.clear();\n-      storage.reportErrorsOnDirectories(ctx.getErrorSDs());\n-  \n-      if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n-        throw new IOException(\n-          \"Failed to save in any storage directories while saving namespace.\");\n-      }\n-      if (ctx.isCancelled()) {\n-        deleteCancelledCheckpoint(txid);\n-        ctx.checkCancelled(); // throws\n-        assert false : \"should have thrown above!\";\n-      }\n-  \n-      renameCheckpoint(txid);\n-  \n-      // Since we now have a new checkpoint, we can clean up some\n-      // old edit logs and checkpoints.\n-      purgeOldStorage();\n-    } finally {\n-      // Notify any threads waiting on the checkpoint to be canceled\n-      // that it is complete.\n-      ctx.markComplete();\n-      ctx \u003d null;\n-    }\n+      throws IOException {\n+    saveFSImageInAllDirs(source, txid, null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized void saveFSImageInAllDirs(FSNamesystem source, long txid)\n      throws IOException {\n    saveFSImageInAllDirs(source, txid, null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "646e855f6ef058b636a5fc85637a3f8e17fddaba": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-2507. Allow saveNamespace operations to be canceled. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1190060 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/10/11 3:11 PM",
      "commitName": "646e855f6ef058b636a5fc85637a3f8e17fddaba",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-2507. Allow saveNamespace operations to be canceled. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1190060 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/10/11 3:11 PM",
          "commitName": "646e855f6ef058b636a5fc85637a3f8e17fddaba",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "17/10/11 1:23 PM",
          "commitNameOld": "8d4842383ede2aceec11c33f6314aa50b0c5ae55",
          "commitAuthorOld": "Jitendra Nath Pandey",
          "daysBetweenCommits": 10.07,
          "commitsBetweenForRepo": 97,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,34 +1,47 @@\n-  protected void saveFSImageInAllDirs(FSNamesystem source, long txid)\n-      throws IOException {\n+  protected synchronized void saveFSImageInAllDirs(FSNamesystem source, long txid)\n+      throws IOException {    \n     if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n       throw new IOException(\"No image directories available!\");\n     }\n     \n-    List\u003cStorageDirectory\u003e errorSDs \u003d\n-      Collections.synchronizedList(new ArrayList\u003cStorageDirectory\u003e());\n-\n-    List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n-    // save images into current\n-    for (Iterator\u003cStorageDirectory\u003e it\n-           \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n-      StorageDirectory sd \u003d it.next();\n-      FSImageSaver saver \u003d new FSImageSaver(source, sd, errorSDs, txid);\n-      Thread saveThread \u003d new Thread(saver, saver.toString());\n-      saveThreads.add(saveThread);\n-      saveThread.start();\n-    }\n-    waitForThreads(saveThreads);\n-    saveThreads.clear();\n-    storage.reportErrorsOnDirectories(errorSDs);\n-\n-    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n-      throw new IOException(\n-        \"Failed to save in any storage directories while saving namespace.\");\n-    }\n-\n-    renameCheckpoint(txid);\n+    SaveNamespaceContext ctx \u003d new SaveNamespaceContext(\n+        source, txid);\n+    curSaveNamespaceContext \u003d ctx;\n     \n-    // Since we now have a new checkpoint, we can clean up some\n-    // old edit logs and checkpoints.\n-    purgeOldStorage();\n+    try {\n+      List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n+      // save images into current\n+      for (Iterator\u003cStorageDirectory\u003e it\n+             \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n+        StorageDirectory sd \u003d it.next();\n+        FSImageSaver saver \u003d new FSImageSaver(ctx, sd);\n+        Thread saveThread \u003d new Thread(saver, saver.toString());\n+        saveThreads.add(saveThread);\n+        saveThread.start();\n+      }\n+      waitForThreads(saveThreads);\n+      saveThreads.clear();\n+      storage.reportErrorsOnDirectories(ctx.getErrorSDs());\n+  \n+      if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n+        throw new IOException(\n+          \"Failed to save in any storage directories while saving namespace.\");\n+      }\n+      if (ctx.isCancelled()) {\n+        deleteCancelledCheckpoint(txid);\n+        ctx.checkCancelled(); // throws\n+        assert false : \"should have thrown above!\";\n+      }\n+  \n+      renameCheckpoint(txid);\n+  \n+      // Since we now have a new checkpoint, we can clean up some\n+      // old edit logs and checkpoints.\n+      purgeOldStorage();\n+    } finally {\n+      // Notify any threads waiting on the checkpoint to be canceled\n+      // that it is complete.\n+      ctx.markComplete();\n+      ctx \u003d null;\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected synchronized void saveFSImageInAllDirs(FSNamesystem source, long txid)\n      throws IOException {    \n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\"No image directories available!\");\n    }\n    \n    SaveNamespaceContext ctx \u003d new SaveNamespaceContext(\n        source, txid);\n    curSaveNamespaceContext \u003d ctx;\n    \n    try {\n      List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n      // save images into current\n      for (Iterator\u003cStorageDirectory\u003e it\n             \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n        StorageDirectory sd \u003d it.next();\n        FSImageSaver saver \u003d new FSImageSaver(ctx, sd);\n        Thread saveThread \u003d new Thread(saver, saver.toString());\n        saveThreads.add(saveThread);\n        saveThread.start();\n      }\n      waitForThreads(saveThreads);\n      saveThreads.clear();\n      storage.reportErrorsOnDirectories(ctx.getErrorSDs());\n  \n      if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n        throw new IOException(\n          \"Failed to save in any storage directories while saving namespace.\");\n      }\n      if (ctx.isCancelled()) {\n        deleteCancelledCheckpoint(txid);\n        ctx.checkCancelled(); // throws\n        assert false : \"should have thrown above!\";\n      }\n  \n      renameCheckpoint(txid);\n  \n      // Since we now have a new checkpoint, we can clean up some\n      // old edit logs and checkpoints.\n      purgeOldStorage();\n    } finally {\n      // Notify any threads waiting on the checkpoint to be canceled\n      // that it is complete.\n      ctx.markComplete();\n      ctx \u003d null;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {
            "oldValue": "[protected]",
            "newValue": "[protected, synchronized]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2507. Allow saveNamespace operations to be canceled. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1190060 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/10/11 3:11 PM",
          "commitName": "646e855f6ef058b636a5fc85637a3f8e17fddaba",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "17/10/11 1:23 PM",
          "commitNameOld": "8d4842383ede2aceec11c33f6314aa50b0c5ae55",
          "commitAuthorOld": "Jitendra Nath Pandey",
          "daysBetweenCommits": 10.07,
          "commitsBetweenForRepo": 97,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,34 +1,47 @@\n-  protected void saveFSImageInAllDirs(FSNamesystem source, long txid)\n-      throws IOException {\n+  protected synchronized void saveFSImageInAllDirs(FSNamesystem source, long txid)\n+      throws IOException {    \n     if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n       throw new IOException(\"No image directories available!\");\n     }\n     \n-    List\u003cStorageDirectory\u003e errorSDs \u003d\n-      Collections.synchronizedList(new ArrayList\u003cStorageDirectory\u003e());\n-\n-    List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n-    // save images into current\n-    for (Iterator\u003cStorageDirectory\u003e it\n-           \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n-      StorageDirectory sd \u003d it.next();\n-      FSImageSaver saver \u003d new FSImageSaver(source, sd, errorSDs, txid);\n-      Thread saveThread \u003d new Thread(saver, saver.toString());\n-      saveThreads.add(saveThread);\n-      saveThread.start();\n-    }\n-    waitForThreads(saveThreads);\n-    saveThreads.clear();\n-    storage.reportErrorsOnDirectories(errorSDs);\n-\n-    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n-      throw new IOException(\n-        \"Failed to save in any storage directories while saving namespace.\");\n-    }\n-\n-    renameCheckpoint(txid);\n+    SaveNamespaceContext ctx \u003d new SaveNamespaceContext(\n+        source, txid);\n+    curSaveNamespaceContext \u003d ctx;\n     \n-    // Since we now have a new checkpoint, we can clean up some\n-    // old edit logs and checkpoints.\n-    purgeOldStorage();\n+    try {\n+      List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n+      // save images into current\n+      for (Iterator\u003cStorageDirectory\u003e it\n+             \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n+        StorageDirectory sd \u003d it.next();\n+        FSImageSaver saver \u003d new FSImageSaver(ctx, sd);\n+        Thread saveThread \u003d new Thread(saver, saver.toString());\n+        saveThreads.add(saveThread);\n+        saveThread.start();\n+      }\n+      waitForThreads(saveThreads);\n+      saveThreads.clear();\n+      storage.reportErrorsOnDirectories(ctx.getErrorSDs());\n+  \n+      if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n+        throw new IOException(\n+          \"Failed to save in any storage directories while saving namespace.\");\n+      }\n+      if (ctx.isCancelled()) {\n+        deleteCancelledCheckpoint(txid);\n+        ctx.checkCancelled(); // throws\n+        assert false : \"should have thrown above!\";\n+      }\n+  \n+      renameCheckpoint(txid);\n+  \n+      // Since we now have a new checkpoint, we can clean up some\n+      // old edit logs and checkpoints.\n+      purgeOldStorage();\n+    } finally {\n+      // Notify any threads waiting on the checkpoint to be canceled\n+      // that it is complete.\n+      ctx.markComplete();\n+      ctx \u003d null;\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected synchronized void saveFSImageInAllDirs(FSNamesystem source, long txid)\n      throws IOException {    \n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\"No image directories available!\");\n    }\n    \n    SaveNamespaceContext ctx \u003d new SaveNamespaceContext(\n        source, txid);\n    curSaveNamespaceContext \u003d ctx;\n    \n    try {\n      List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n      // save images into current\n      for (Iterator\u003cStorageDirectory\u003e it\n             \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n        StorageDirectory sd \u003d it.next();\n        FSImageSaver saver \u003d new FSImageSaver(ctx, sd);\n        Thread saveThread \u003d new Thread(saver, saver.toString());\n        saveThreads.add(saveThread);\n        saveThread.start();\n      }\n      waitForThreads(saveThreads);\n      saveThreads.clear();\n      storage.reportErrorsOnDirectories(ctx.getErrorSDs());\n  \n      if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n        throw new IOException(\n          \"Failed to save in any storage directories while saving namespace.\");\n      }\n      if (ctx.isCancelled()) {\n        deleteCancelledCheckpoint(txid);\n        ctx.checkCancelled(); // throws\n        assert false : \"should have thrown above!\";\n      }\n  \n      renameCheckpoint(txid);\n  \n      // Since we now have a new checkpoint, we can clean up some\n      // old edit logs and checkpoints.\n      purgeOldStorage();\n    } finally {\n      // Notify any threads waiting on the checkpoint to be canceled\n      // that it is complete.\n      ctx.markComplete();\n      ctx \u003d null;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {}
        }
      ]
    },
    "06e84a1bca19bd01568a3095e33944d4d6387fd3": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-2223. Untangle depencencies between NN components. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1166466 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/09/11 4:23 PM",
      "commitName": "06e84a1bca19bd01568a3095e33944d4d6387fd3",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2223. Untangle depencencies between NN components. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1166466 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/09/11 4:23 PM",
          "commitName": "06e84a1bca19bd01568a3095e33944d4d6387fd3",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "06/09/11 1:27 PM",
          "commitNameOld": "bdc3720d5b67a1c8fc2dfb29be16e4155c0e7f15",
          "commitAuthorOld": "Jitendra Nath Pandey",
          "daysBetweenCommits": 1.12,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,34 @@\n-  protected void saveFSImageInAllDirs(long txid) throws IOException {\n+  protected void saveFSImageInAllDirs(FSNamesystem source, long txid)\n+      throws IOException {\n     if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n       throw new IOException(\"No image directories available!\");\n     }\n     \n     List\u003cStorageDirectory\u003e errorSDs \u003d\n       Collections.synchronizedList(new ArrayList\u003cStorageDirectory\u003e());\n \n     List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n     // save images into current\n     for (Iterator\u003cStorageDirectory\u003e it\n            \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n       StorageDirectory sd \u003d it.next();\n-      FSImageSaver saver \u003d new FSImageSaver(sd, errorSDs, txid);\n+      FSImageSaver saver \u003d new FSImageSaver(source, sd, errorSDs, txid);\n       Thread saveThread \u003d new Thread(saver, saver.toString());\n       saveThreads.add(saveThread);\n       saveThread.start();\n     }\n     waitForThreads(saveThreads);\n     saveThreads.clear();\n     storage.reportErrorsOnDirectories(errorSDs);\n \n     if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n       throw new IOException(\n         \"Failed to save in any storage directories while saving namespace.\");\n     }\n \n     renameCheckpoint(txid);\n     \n     // Since we now have a new checkpoint, we can clean up some\n     // old edit logs and checkpoints.\n     purgeOldStorage();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void saveFSImageInAllDirs(FSNamesystem source, long txid)\n      throws IOException {\n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\"No image directories available!\");\n    }\n    \n    List\u003cStorageDirectory\u003e errorSDs \u003d\n      Collections.synchronizedList(new ArrayList\u003cStorageDirectory\u003e());\n\n    List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n    // save images into current\n    for (Iterator\u003cStorageDirectory\u003e it\n           \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      FSImageSaver saver \u003d new FSImageSaver(source, sd, errorSDs, txid);\n      Thread saveThread \u003d new Thread(saver, saver.toString());\n      saveThreads.add(saveThread);\n      saveThread.start();\n    }\n    waitForThreads(saveThreads);\n    saveThreads.clear();\n    storage.reportErrorsOnDirectories(errorSDs);\n\n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\n        \"Failed to save in any storage directories while saving namespace.\");\n    }\n\n    renameCheckpoint(txid);\n    \n    // Since we now have a new checkpoint, we can clean up some\n    // old edit logs and checkpoints.\n    purgeOldStorage();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {
            "oldValue": "[txid-long]",
            "newValue": "[source-FSNamesystem, txid-long]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2223. Untangle depencencies between NN components. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1166466 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/09/11 4:23 PM",
          "commitName": "06e84a1bca19bd01568a3095e33944d4d6387fd3",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "06/09/11 1:27 PM",
          "commitNameOld": "bdc3720d5b67a1c8fc2dfb29be16e4155c0e7f15",
          "commitAuthorOld": "Jitendra Nath Pandey",
          "daysBetweenCommits": 1.12,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,34 @@\n-  protected void saveFSImageInAllDirs(long txid) throws IOException {\n+  protected void saveFSImageInAllDirs(FSNamesystem source, long txid)\n+      throws IOException {\n     if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n       throw new IOException(\"No image directories available!\");\n     }\n     \n     List\u003cStorageDirectory\u003e errorSDs \u003d\n       Collections.synchronizedList(new ArrayList\u003cStorageDirectory\u003e());\n \n     List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n     // save images into current\n     for (Iterator\u003cStorageDirectory\u003e it\n            \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n       StorageDirectory sd \u003d it.next();\n-      FSImageSaver saver \u003d new FSImageSaver(sd, errorSDs, txid);\n+      FSImageSaver saver \u003d new FSImageSaver(source, sd, errorSDs, txid);\n       Thread saveThread \u003d new Thread(saver, saver.toString());\n       saveThreads.add(saveThread);\n       saveThread.start();\n     }\n     waitForThreads(saveThreads);\n     saveThreads.clear();\n     storage.reportErrorsOnDirectories(errorSDs);\n \n     if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n       throw new IOException(\n         \"Failed to save in any storage directories while saving namespace.\");\n     }\n \n     renameCheckpoint(txid);\n     \n     // Since we now have a new checkpoint, we can clean up some\n     // old edit logs and checkpoints.\n     purgeOldStorage();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void saveFSImageInAllDirs(FSNamesystem source, long txid)\n      throws IOException {\n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\"No image directories available!\");\n    }\n    \n    List\u003cStorageDirectory\u003e errorSDs \u003d\n      Collections.synchronizedList(new ArrayList\u003cStorageDirectory\u003e());\n\n    List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n    // save images into current\n    for (Iterator\u003cStorageDirectory\u003e it\n           \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      FSImageSaver saver \u003d new FSImageSaver(source, sd, errorSDs, txid);\n      Thread saveThread \u003d new Thread(saver, saver.toString());\n      saveThreads.add(saveThread);\n      saveThread.start();\n    }\n    waitForThreads(saveThreads);\n    saveThreads.clear();\n    storage.reportErrorsOnDirectories(errorSDs);\n\n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\n        \"Failed to save in any storage directories while saving namespace.\");\n    }\n\n    renameCheckpoint(txid);\n    \n    // Since we now have a new checkpoint, we can clean up some\n    // old edit logs and checkpoints.\n    purgeOldStorage();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected void saveFSImageInAllDirs(long txid) throws IOException {\n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\"No image directories available!\");\n    }\n    \n    List\u003cStorageDirectory\u003e errorSDs \u003d\n      Collections.synchronizedList(new ArrayList\u003cStorageDirectory\u003e());\n\n    List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n    // save images into current\n    for (Iterator\u003cStorageDirectory\u003e it\n           \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      FSImageSaver saver \u003d new FSImageSaver(sd, errorSDs, txid);\n      Thread saveThread \u003d new Thread(saver, saver.toString());\n      saveThreads.add(saveThread);\n      saveThread.start();\n    }\n    waitForThreads(saveThreads);\n    saveThreads.clear();\n    storage.reportErrorsOnDirectories(errorSDs);\n\n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\n        \"Failed to save in any storage directories while saving namespace.\");\n    }\n\n    renameCheckpoint(txid);\n    \n    // Since we now have a new checkpoint, we can clean up some\n    // old edit logs and checkpoints.\n    purgeOldStorage();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected void saveFSImageInAllDirs(long txid) throws IOException {\n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\"No image directories available!\");\n    }\n    \n    List\u003cStorageDirectory\u003e errorSDs \u003d\n      Collections.synchronizedList(new ArrayList\u003cStorageDirectory\u003e());\n\n    List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n    // save images into current\n    for (Iterator\u003cStorageDirectory\u003e it\n           \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      FSImageSaver saver \u003d new FSImageSaver(sd, errorSDs, txid);\n      Thread saveThread \u003d new Thread(saver, saver.toString());\n      saveThreads.add(saveThread);\n      saveThread.start();\n    }\n    waitForThreads(saveThreads);\n    saveThreads.clear();\n    storage.reportErrorsOnDirectories(errorSDs);\n\n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\n        \"Failed to save in any storage directories while saving namespace.\");\n    }\n\n    renameCheckpoint(txid);\n    \n    // Since we now have a new checkpoint, we can clean up some\n    // old edit logs and checkpoints.\n    purgeOldStorage();\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java"
      }
    },
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": {
      "type": "Ymultichange(Yrename,Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/11 9:28 AM",
      "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/07/11 9:28 AM",
          "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "27/07/11 8:19 PM",
          "commitNameOld": "ffbe9e5972bf3eee9037e2602c1330e0dc744646",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 1.55,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,33 @@\n-  void saveFSImage(File newFile) throws IOException {\n-    FSImageFormat.Saver saver \u003d new FSImageFormat.Saver();\n-    FSImageCompression compression \u003d FSImageCompression.createCompression(conf);\n-    saver.save(newFile, getFSNamesystem(), compression);\n-    storage.setImageDigest(saver.getSavedDigest());\n+  protected void saveFSImageInAllDirs(long txid) throws IOException {\n+    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n+      throw new IOException(\"No image directories available!\");\n+    }\n+    \n+    List\u003cStorageDirectory\u003e errorSDs \u003d\n+      Collections.synchronizedList(new ArrayList\u003cStorageDirectory\u003e());\n+\n+    List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n+    // save images into current\n+    for (Iterator\u003cStorageDirectory\u003e it\n+           \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n+      StorageDirectory sd \u003d it.next();\n+      FSImageSaver saver \u003d new FSImageSaver(sd, errorSDs, txid);\n+      Thread saveThread \u003d new Thread(saver, saver.toString());\n+      saveThreads.add(saveThread);\n+      saveThread.start();\n+    }\n+    waitForThreads(saveThreads);\n+    saveThreads.clear();\n+    storage.reportErrorsOnDirectories(errorSDs);\n+\n+    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n+      throw new IOException(\n+        \"Failed to save in any storage directories while saving namespace.\");\n+    }\n+\n+    renameCheckpoint(txid);\n+    \n+    // Since we now have a new checkpoint, we can clean up some\n+    // old edit logs and checkpoints.\n+    purgeOldStorage();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void saveFSImageInAllDirs(long txid) throws IOException {\n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\"No image directories available!\");\n    }\n    \n    List\u003cStorageDirectory\u003e errorSDs \u003d\n      Collections.synchronizedList(new ArrayList\u003cStorageDirectory\u003e());\n\n    List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n    // save images into current\n    for (Iterator\u003cStorageDirectory\u003e it\n           \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      FSImageSaver saver \u003d new FSImageSaver(sd, errorSDs, txid);\n      Thread saveThread \u003d new Thread(saver, saver.toString());\n      saveThreads.add(saveThread);\n      saveThread.start();\n    }\n    waitForThreads(saveThreads);\n    saveThreads.clear();\n    storage.reportErrorsOnDirectories(errorSDs);\n\n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\n        \"Failed to save in any storage directories while saving namespace.\");\n    }\n\n    renameCheckpoint(txid);\n    \n    // Since we now have a new checkpoint, we can clean up some\n    // old edit logs and checkpoints.\n    purgeOldStorage();\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {
            "oldValue": "saveFSImage",
            "newValue": "saveFSImageInAllDirs"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/07/11 9:28 AM",
          "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "27/07/11 8:19 PM",
          "commitNameOld": "ffbe9e5972bf3eee9037e2602c1330e0dc744646",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 1.55,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,33 @@\n-  void saveFSImage(File newFile) throws IOException {\n-    FSImageFormat.Saver saver \u003d new FSImageFormat.Saver();\n-    FSImageCompression compression \u003d FSImageCompression.createCompression(conf);\n-    saver.save(newFile, getFSNamesystem(), compression);\n-    storage.setImageDigest(saver.getSavedDigest());\n+  protected void saveFSImageInAllDirs(long txid) throws IOException {\n+    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n+      throw new IOException(\"No image directories available!\");\n+    }\n+    \n+    List\u003cStorageDirectory\u003e errorSDs \u003d\n+      Collections.synchronizedList(new ArrayList\u003cStorageDirectory\u003e());\n+\n+    List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n+    // save images into current\n+    for (Iterator\u003cStorageDirectory\u003e it\n+           \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n+      StorageDirectory sd \u003d it.next();\n+      FSImageSaver saver \u003d new FSImageSaver(sd, errorSDs, txid);\n+      Thread saveThread \u003d new Thread(saver, saver.toString());\n+      saveThreads.add(saveThread);\n+      saveThread.start();\n+    }\n+    waitForThreads(saveThreads);\n+    saveThreads.clear();\n+    storage.reportErrorsOnDirectories(errorSDs);\n+\n+    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n+      throw new IOException(\n+        \"Failed to save in any storage directories while saving namespace.\");\n+    }\n+\n+    renameCheckpoint(txid);\n+    \n+    // Since we now have a new checkpoint, we can clean up some\n+    // old edit logs and checkpoints.\n+    purgeOldStorage();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void saveFSImageInAllDirs(long txid) throws IOException {\n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\"No image directories available!\");\n    }\n    \n    List\u003cStorageDirectory\u003e errorSDs \u003d\n      Collections.synchronizedList(new ArrayList\u003cStorageDirectory\u003e());\n\n    List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n    // save images into current\n    for (Iterator\u003cStorageDirectory\u003e it\n           \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      FSImageSaver saver \u003d new FSImageSaver(sd, errorSDs, txid);\n      Thread saveThread \u003d new Thread(saver, saver.toString());\n      saveThreads.add(saveThread);\n      saveThread.start();\n    }\n    waitForThreads(saveThreads);\n    saveThreads.clear();\n    storage.reportErrorsOnDirectories(errorSDs);\n\n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\n        \"Failed to save in any storage directories while saving namespace.\");\n    }\n\n    renameCheckpoint(txid);\n    \n    // Since we now have a new checkpoint, we can clean up some\n    // old edit logs and checkpoints.\n    purgeOldStorage();\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {
            "oldValue": "[newFile-File]",
            "newValue": "[txid-long]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/07/11 9:28 AM",
          "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "27/07/11 8:19 PM",
          "commitNameOld": "ffbe9e5972bf3eee9037e2602c1330e0dc744646",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 1.55,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,33 @@\n-  void saveFSImage(File newFile) throws IOException {\n-    FSImageFormat.Saver saver \u003d new FSImageFormat.Saver();\n-    FSImageCompression compression \u003d FSImageCompression.createCompression(conf);\n-    saver.save(newFile, getFSNamesystem(), compression);\n-    storage.setImageDigest(saver.getSavedDigest());\n+  protected void saveFSImageInAllDirs(long txid) throws IOException {\n+    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n+      throw new IOException(\"No image directories available!\");\n+    }\n+    \n+    List\u003cStorageDirectory\u003e errorSDs \u003d\n+      Collections.synchronizedList(new ArrayList\u003cStorageDirectory\u003e());\n+\n+    List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n+    // save images into current\n+    for (Iterator\u003cStorageDirectory\u003e it\n+           \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n+      StorageDirectory sd \u003d it.next();\n+      FSImageSaver saver \u003d new FSImageSaver(sd, errorSDs, txid);\n+      Thread saveThread \u003d new Thread(saver, saver.toString());\n+      saveThreads.add(saveThread);\n+      saveThread.start();\n+    }\n+    waitForThreads(saveThreads);\n+    saveThreads.clear();\n+    storage.reportErrorsOnDirectories(errorSDs);\n+\n+    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n+      throw new IOException(\n+        \"Failed to save in any storage directories while saving namespace.\");\n+    }\n+\n+    renameCheckpoint(txid);\n+    \n+    // Since we now have a new checkpoint, we can clean up some\n+    // old edit logs and checkpoints.\n+    purgeOldStorage();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void saveFSImageInAllDirs(long txid) throws IOException {\n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\"No image directories available!\");\n    }\n    \n    List\u003cStorageDirectory\u003e errorSDs \u003d\n      Collections.synchronizedList(new ArrayList\u003cStorageDirectory\u003e());\n\n    List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n    // save images into current\n    for (Iterator\u003cStorageDirectory\u003e it\n           \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      FSImageSaver saver \u003d new FSImageSaver(sd, errorSDs, txid);\n      Thread saveThread \u003d new Thread(saver, saver.toString());\n      saveThreads.add(saveThread);\n      saveThread.start();\n    }\n    waitForThreads(saveThreads);\n    saveThreads.clear();\n    storage.reportErrorsOnDirectories(errorSDs);\n\n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\n        \"Failed to save in any storage directories while saving namespace.\");\n    }\n\n    renameCheckpoint(txid);\n    \n    // Since we now have a new checkpoint, we can clean up some\n    // old edit logs and checkpoints.\n    purgeOldStorage();\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[protected]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/07/11 9:28 AM",
          "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "27/07/11 8:19 PM",
          "commitNameOld": "ffbe9e5972bf3eee9037e2602c1330e0dc744646",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 1.55,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,33 @@\n-  void saveFSImage(File newFile) throws IOException {\n-    FSImageFormat.Saver saver \u003d new FSImageFormat.Saver();\n-    FSImageCompression compression \u003d FSImageCompression.createCompression(conf);\n-    saver.save(newFile, getFSNamesystem(), compression);\n-    storage.setImageDigest(saver.getSavedDigest());\n+  protected void saveFSImageInAllDirs(long txid) throws IOException {\n+    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n+      throw new IOException(\"No image directories available!\");\n+    }\n+    \n+    List\u003cStorageDirectory\u003e errorSDs \u003d\n+      Collections.synchronizedList(new ArrayList\u003cStorageDirectory\u003e());\n+\n+    List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n+    // save images into current\n+    for (Iterator\u003cStorageDirectory\u003e it\n+           \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n+      StorageDirectory sd \u003d it.next();\n+      FSImageSaver saver \u003d new FSImageSaver(sd, errorSDs, txid);\n+      Thread saveThread \u003d new Thread(saver, saver.toString());\n+      saveThreads.add(saveThread);\n+      saveThread.start();\n+    }\n+    waitForThreads(saveThreads);\n+    saveThreads.clear();\n+    storage.reportErrorsOnDirectories(errorSDs);\n+\n+    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n+      throw new IOException(\n+        \"Failed to save in any storage directories while saving namespace.\");\n+    }\n+\n+    renameCheckpoint(txid);\n+    \n+    // Since we now have a new checkpoint, we can clean up some\n+    // old edit logs and checkpoints.\n+    purgeOldStorage();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void saveFSImageInAllDirs(long txid) throws IOException {\n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\"No image directories available!\");\n    }\n    \n    List\u003cStorageDirectory\u003e errorSDs \u003d\n      Collections.synchronizedList(new ArrayList\u003cStorageDirectory\u003e());\n\n    List\u003cThread\u003e saveThreads \u003d new ArrayList\u003cThread\u003e();\n    // save images into current\n    for (Iterator\u003cStorageDirectory\u003e it\n           \u003d storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      FSImageSaver saver \u003d new FSImageSaver(sd, errorSDs, txid);\n      Thread saveThread \u003d new Thread(saver, saver.toString());\n      saveThreads.add(saveThread);\n      saveThread.start();\n    }\n    waitForThreads(saveThreads);\n    saveThreads.clear();\n    storage.reportErrorsOnDirectories(errorSDs);\n\n    if (storage.getNumStorageDirs(NameNodeDirType.IMAGE) \u003d\u003d 0) {\n      throw new IOException(\n        \"Failed to save in any storage directories while saving namespace.\");\n    }\n\n    renameCheckpoint(txid);\n    \n    // Since we now have a new checkpoint, we can clean up some\n    // old edit logs and checkpoints.\n    purgeOldStorage();\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {}
        }
      ]
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,6 @@\n+  void saveFSImage(File newFile) throws IOException {\n+    FSImageFormat.Saver saver \u003d new FSImageFormat.Saver();\n+    FSImageCompression compression \u003d FSImageCompression.createCompression(conf);\n+    saver.save(newFile, getFSNamesystem(), compression);\n+    storage.setImageDigest(saver.getSavedDigest());\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void saveFSImage(File newFile) throws IOException {\n    FSImageFormat.Saver saver \u003d new FSImageFormat.Saver();\n    FSImageCompression compression \u003d FSImageCompression.createCompression(conf);\n    saver.save(newFile, getFSNamesystem(), compression);\n    storage.setImageDigest(saver.getSavedDigest());\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java"
    }
  }
}