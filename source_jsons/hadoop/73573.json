{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Client.java",
  "functionName": "readResponse",
  "functionId": "readResponse",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java",
  "functionStartLine": 1880,
  "functionEndLine": 1900,
  "numCommitsSeen": 125,
  "timeTaken": 1409,
  "changeHistory": [
    "d4d076876a8d0002bd3a73491d8459d11cb4896c"
  ],
  "changeHistoryShort": {
    "d4d076876a8d0002bd3a73491d8459d11cb4896c": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d4d076876a8d0002bd3a73491d8459d11cb4896c": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-10940. RPC client does no bounds checking of responses. Contributed by Daryn Sharp.\n",
      "commitDate": "09/09/16 8:39 AM",
      "commitName": "d4d076876a8d0002bd3a73491d8459d11cb4896c",
      "commitAuthor": "Kihwal Lee",
      "diff": "@@ -0,0 +1,21 @@\n+    public ByteBuffer readResponse() throws IOException {\n+      int length \u003d in.readInt();\n+      if (firstResponse) {\n+        firstResponse \u003d false;\n+        // pre-rpcv9 exception, almost certainly a version mismatch.\n+        if (length \u003d\u003d -1) {\n+          in.readInt(); // ignore fatal/error status, it\u0027s fatal for us.\n+          throw new RemoteException(WritableUtils.readString(in),\n+                                    WritableUtils.readString(in));\n+        }\n+      }\n+      if (length \u003c\u003d 0) {\n+        throw new RpcException(\"RPC response has invalid length\");\n+      }\n+      if (maxResponseLength \u003e 0 \u0026\u0026 length \u003e maxResponseLength) {\n+        throw new RpcException(\"RPC response exceeds maximum data length\");\n+      }\n+      ByteBuffer bb \u003d ByteBuffer.allocate(length);\n+      in.readFully(bb.array());\n+      return bb;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public ByteBuffer readResponse() throws IOException {\n      int length \u003d in.readInt();\n      if (firstResponse) {\n        firstResponse \u003d false;\n        // pre-rpcv9 exception, almost certainly a version mismatch.\n        if (length \u003d\u003d -1) {\n          in.readInt(); // ignore fatal/error status, it\u0027s fatal for us.\n          throw new RemoteException(WritableUtils.readString(in),\n                                    WritableUtils.readString(in));\n        }\n      }\n      if (length \u003c\u003d 0) {\n        throw new RpcException(\"RPC response has invalid length\");\n      }\n      if (maxResponseLength \u003e 0 \u0026\u0026 length \u003e maxResponseLength) {\n        throw new RpcException(\"RPC response exceeds maximum data length\");\n      }\n      ByteBuffer bb \u003d ByteBuffer.allocate(length);\n      in.readFully(bb.array());\n      return bb;\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java"
    }
  }
}