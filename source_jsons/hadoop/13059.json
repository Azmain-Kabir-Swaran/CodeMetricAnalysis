{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPlacementPolicyWithNodeGroup.java",
  "functionName": "addToExcludedNodes",
  "functionId": "addToExcludedNodes___chosenNode-DatanodeDescriptor__excludedNodes-Set__Node__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
  "functionStartLine": 283,
  "functionEndLine": 298,
  "numCommitsSeen": 36,
  "timeTaken": 2097,
  "changeHistory": [
    "b2f65c276da2c4420a0974a7e2d75e081abf5d63",
    "f98c343c7f11c165bcc0f7cdbaa2a3998b12cfd2",
    "d01caeee77f4ea00173db7f20a945f6cbfd0c9f7",
    "8f7c92094dfc3ea692e5f893126b89987fce2006"
  ],
  "changeHistoryShort": {
    "b2f65c276da2c4420a0974a7e2d75e081abf5d63": "Ybodychange",
    "f98c343c7f11c165bcc0f7cdbaa2a3998b12cfd2": "Ymultichange(Yparameterchange,Ybodychange)",
    "d01caeee77f4ea00173db7f20a945f6cbfd0c9f7": "Ymultichange(Yparameterchange,Ybodychange)",
    "8f7c92094dfc3ea692e5f893126b89987fce2006": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b2f65c276da2c4420a0974a7e2d75e081abf5d63": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5168. Add cross node dependency support to BlockPlacementPolicy.  Contributed by Nikola Vujic\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1592179 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/05/14 4:02 AM",
      "commitName": "b2f65c276da2c4420a0974a7e2d75e081abf5d63",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "21/01/14 3:11 PM",
      "commitNameOld": "83280a45de15d8089e25ae45954643eb5f4dc16c",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 101.49,
      "commitsBetweenForRepo": 795,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,16 @@\n   protected int addToExcludedNodes(DatanodeDescriptor chosenNode,\n       Set\u003cNode\u003e excludedNodes) {\n     int countOfExcludedNodes \u003d 0;\n     String nodeGroupScope \u003d chosenNode.getNetworkLocation();\n     List\u003cNode\u003e leafNodes \u003d clusterMap.getLeaves(nodeGroupScope);\n     for (Node leafNode : leafNodes) {\n       if (excludedNodes.add(leafNode)) {\n         // not a existing node in excludedNodes\n         countOfExcludedNodes++;\n       }\n     }\n+    \n+    countOfExcludedNodes +\u003d addDependentNodesToExcludedNodes(\n+        chosenNode, excludedNodes);\n     return countOfExcludedNodes;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected int addToExcludedNodes(DatanodeDescriptor chosenNode,\n      Set\u003cNode\u003e excludedNodes) {\n    int countOfExcludedNodes \u003d 0;\n    String nodeGroupScope \u003d chosenNode.getNetworkLocation();\n    List\u003cNode\u003e leafNodes \u003d clusterMap.getLeaves(nodeGroupScope);\n    for (Node leafNode : leafNodes) {\n      if (excludedNodes.add(leafNode)) {\n        // not a existing node in excludedNodes\n        countOfExcludedNodes++;\n      }\n    }\n    \n    countOfExcludedNodes +\u003d addDependentNodesToExcludedNodes(\n        chosenNode, excludedNodes);\n    return countOfExcludedNodes;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
      "extendedDetails": {}
    },
    "f98c343c7f11c165bcc0f7cdbaa2a3998b12cfd2": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5207. In BlockPlacementPolicy.chooseTarget(..), change the writer and the excludedNodes parameter types respectively to Node and Set.  Contributed by Junping Du\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1523875 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/09/13 7:38 PM",
      "commitName": "f98c343c7f11c165bcc0f7cdbaa2a3998b12cfd2",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5207. In BlockPlacementPolicy.chooseTarget(..), change the writer and the excludedNodes parameter types respectively to Node and Set.  Contributed by Junping Du\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1523875 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "16/09/13 7:38 PM",
          "commitName": "f98c343c7f11c165bcc0f7cdbaa2a3998b12cfd2",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "14/09/13 9:15 PM",
          "commitNameOld": "d01caeee77f4ea00173db7f20a945f6cbfd0c9f7",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 1.93,
          "commitsBetweenForRepo": 12,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,13 @@\n   protected int addToExcludedNodes(DatanodeDescriptor chosenNode,\n-      Map\u003cNode, Node\u003e excludedNodes) {\n+      Set\u003cNode\u003e excludedNodes) {\n     int countOfExcludedNodes \u003d 0;\n     String nodeGroupScope \u003d chosenNode.getNetworkLocation();\n     List\u003cNode\u003e leafNodes \u003d clusterMap.getLeaves(nodeGroupScope);\n     for (Node leafNode : leafNodes) {\n-      Node node \u003d excludedNodes.put(leafNode, leafNode);\n-      if (node \u003d\u003d null) {\n+      if (excludedNodes.add(leafNode)) {\n         // not a existing node in excludedNodes\n         countOfExcludedNodes++;\n       }\n     }\n     return countOfExcludedNodes;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected int addToExcludedNodes(DatanodeDescriptor chosenNode,\n      Set\u003cNode\u003e excludedNodes) {\n    int countOfExcludedNodes \u003d 0;\n    String nodeGroupScope \u003d chosenNode.getNetworkLocation();\n    List\u003cNode\u003e leafNodes \u003d clusterMap.getLeaves(nodeGroupScope);\n    for (Node leafNode : leafNodes) {\n      if (excludedNodes.add(leafNode)) {\n        // not a existing node in excludedNodes\n        countOfExcludedNodes++;\n      }\n    }\n    return countOfExcludedNodes;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {
            "oldValue": "[chosenNode-DatanodeDescriptor, excludedNodes-Map\u003cNode,Node\u003e]",
            "newValue": "[chosenNode-DatanodeDescriptor, excludedNodes-Set\u003cNode\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5207. In BlockPlacementPolicy.chooseTarget(..), change the writer and the excludedNodes parameter types respectively to Node and Set.  Contributed by Junping Du\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1523875 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "16/09/13 7:38 PM",
          "commitName": "f98c343c7f11c165bcc0f7cdbaa2a3998b12cfd2",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "14/09/13 9:15 PM",
          "commitNameOld": "d01caeee77f4ea00173db7f20a945f6cbfd0c9f7",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 1.93,
          "commitsBetweenForRepo": 12,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,13 @@\n   protected int addToExcludedNodes(DatanodeDescriptor chosenNode,\n-      Map\u003cNode, Node\u003e excludedNodes) {\n+      Set\u003cNode\u003e excludedNodes) {\n     int countOfExcludedNodes \u003d 0;\n     String nodeGroupScope \u003d chosenNode.getNetworkLocation();\n     List\u003cNode\u003e leafNodes \u003d clusterMap.getLeaves(nodeGroupScope);\n     for (Node leafNode : leafNodes) {\n-      Node node \u003d excludedNodes.put(leafNode, leafNode);\n-      if (node \u003d\u003d null) {\n+      if (excludedNodes.add(leafNode)) {\n         // not a existing node in excludedNodes\n         countOfExcludedNodes++;\n       }\n     }\n     return countOfExcludedNodes;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected int addToExcludedNodes(DatanodeDescriptor chosenNode,\n      Set\u003cNode\u003e excludedNodes) {\n    int countOfExcludedNodes \u003d 0;\n    String nodeGroupScope \u003d chosenNode.getNetworkLocation();\n    List\u003cNode\u003e leafNodes \u003d clusterMap.getLeaves(nodeGroupScope);\n    for (Node leafNode : leafNodes) {\n      if (excludedNodes.add(leafNode)) {\n        // not a existing node in excludedNodes\n        countOfExcludedNodes++;\n      }\n    }\n    return countOfExcludedNodes;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {}
        }
      ]
    },
    "d01caeee77f4ea00173db7f20a945f6cbfd0c9f7": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5188. In BlockPlacementPolicy, reduce the number of chooseTarget(..) methods; replace HashMap with Map in parameter declarations and cleanup some related code.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1523400 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/09/13 9:15 PM",
      "commitName": "d01caeee77f4ea00173db7f20a945f6cbfd0c9f7",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5188. In BlockPlacementPolicy, reduce the number of chooseTarget(..) methods; replace HashMap with Map in parameter declarations and cleanup some related code.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1523400 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/09/13 9:15 PM",
          "commitName": "d01caeee77f4ea00173db7f20a945f6cbfd0c9f7",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "14/08/13 9:52 PM",
          "commitNameOld": "0182ea16d359b41c065bf9cbf740f8b23f6381e3",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 30.97,
          "commitsBetweenForRepo": 162,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,14 @@\n-  protected int addToExcludedNodes(DatanodeDescriptor localMachine,\n-      HashMap\u003cNode, Node\u003e excludedNodes) {\n+  protected int addToExcludedNodes(DatanodeDescriptor chosenNode,\n+      Map\u003cNode, Node\u003e excludedNodes) {\n     int countOfExcludedNodes \u003d 0;\n-    String nodeGroupScope \u003d localMachine.getNetworkLocation();\n+    String nodeGroupScope \u003d chosenNode.getNetworkLocation();\n     List\u003cNode\u003e leafNodes \u003d clusterMap.getLeaves(nodeGroupScope);\n     for (Node leafNode : leafNodes) {\n       Node node \u003d excludedNodes.put(leafNode, leafNode);\n       if (node \u003d\u003d null) {\n         // not a existing node in excludedNodes\n         countOfExcludedNodes++;\n       }\n     }\n     return countOfExcludedNodes;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected int addToExcludedNodes(DatanodeDescriptor chosenNode,\n      Map\u003cNode, Node\u003e excludedNodes) {\n    int countOfExcludedNodes \u003d 0;\n    String nodeGroupScope \u003d chosenNode.getNetworkLocation();\n    List\u003cNode\u003e leafNodes \u003d clusterMap.getLeaves(nodeGroupScope);\n    for (Node leafNode : leafNodes) {\n      Node node \u003d excludedNodes.put(leafNode, leafNode);\n      if (node \u003d\u003d null) {\n        // not a existing node in excludedNodes\n        countOfExcludedNodes++;\n      }\n    }\n    return countOfExcludedNodes;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {
            "oldValue": "[localMachine-DatanodeDescriptor, excludedNodes-HashMap\u003cNode,Node\u003e]",
            "newValue": "[chosenNode-DatanodeDescriptor, excludedNodes-Map\u003cNode,Node\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5188. In BlockPlacementPolicy, reduce the number of chooseTarget(..) methods; replace HashMap with Map in parameter declarations and cleanup some related code.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1523400 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/09/13 9:15 PM",
          "commitName": "d01caeee77f4ea00173db7f20a945f6cbfd0c9f7",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "14/08/13 9:52 PM",
          "commitNameOld": "0182ea16d359b41c065bf9cbf740f8b23f6381e3",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 30.97,
          "commitsBetweenForRepo": 162,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,14 @@\n-  protected int addToExcludedNodes(DatanodeDescriptor localMachine,\n-      HashMap\u003cNode, Node\u003e excludedNodes) {\n+  protected int addToExcludedNodes(DatanodeDescriptor chosenNode,\n+      Map\u003cNode, Node\u003e excludedNodes) {\n     int countOfExcludedNodes \u003d 0;\n-    String nodeGroupScope \u003d localMachine.getNetworkLocation();\n+    String nodeGroupScope \u003d chosenNode.getNetworkLocation();\n     List\u003cNode\u003e leafNodes \u003d clusterMap.getLeaves(nodeGroupScope);\n     for (Node leafNode : leafNodes) {\n       Node node \u003d excludedNodes.put(leafNode, leafNode);\n       if (node \u003d\u003d null) {\n         // not a existing node in excludedNodes\n         countOfExcludedNodes++;\n       }\n     }\n     return countOfExcludedNodes;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected int addToExcludedNodes(DatanodeDescriptor chosenNode,\n      Map\u003cNode, Node\u003e excludedNodes) {\n    int countOfExcludedNodes \u003d 0;\n    String nodeGroupScope \u003d chosenNode.getNetworkLocation();\n    List\u003cNode\u003e leafNodes \u003d clusterMap.getLeaves(nodeGroupScope);\n    for (Node leafNode : leafNodes) {\n      Node node \u003d excludedNodes.put(leafNode, leafNode);\n      if (node \u003d\u003d null) {\n        // not a existing node in excludedNodes\n        countOfExcludedNodes++;\n      }\n    }\n    return countOfExcludedNodes;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {}
        }
      ]
    },
    "8f7c92094dfc3ea692e5f893126b89987fce2006": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4240. For nodegroup-aware block placement, when a node is excluded, the nodes in the same nodegroup should also be excluded.  Contributed by Junping Du\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1416691 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/12/12 1:59 PM",
      "commitName": "8f7c92094dfc3ea692e5f893126b89987fce2006",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,14 @@\n+  protected int addToExcludedNodes(DatanodeDescriptor localMachine,\n+      HashMap\u003cNode, Node\u003e excludedNodes) {\n+    int countOfExcludedNodes \u003d 0;\n+    String nodeGroupScope \u003d localMachine.getNetworkLocation();\n+    List\u003cNode\u003e leafNodes \u003d clusterMap.getLeaves(nodeGroupScope);\n+    for (Node leafNode : leafNodes) {\n+      Node node \u003d excludedNodes.put(leafNode, leafNode);\n+      if (node \u003d\u003d null) {\n+        // not a existing node in excludedNodes\n+        countOfExcludedNodes++;\n+      }\n+    }\n+    return countOfExcludedNodes;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected int addToExcludedNodes(DatanodeDescriptor localMachine,\n      HashMap\u003cNode, Node\u003e excludedNodes) {\n    int countOfExcludedNodes \u003d 0;\n    String nodeGroupScope \u003d localMachine.getNetworkLocation();\n    List\u003cNode\u003e leafNodes \u003d clusterMap.getLeaves(nodeGroupScope);\n    for (Node leafNode : leafNodes) {\n      Node node \u003d excludedNodes.put(leafNode, leafNode);\n      if (node \u003d\u003d null) {\n        // not a existing node in excludedNodes\n        countOfExcludedNodes++;\n      }\n    }\n    return countOfExcludedNodes;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java"
    }
  }
}