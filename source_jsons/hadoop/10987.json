{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataXceiverServer.java",
  "functionName": "kill",
  "functionId": "kill",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java",
  "functionStartLine": 296,
  "functionEndLine": 311,
  "numCommitsSeen": 39,
  "timeTaken": 7442,
  "changeHistory": [
    "235e3da90a4212d0c204afaef09db3408abfab82",
    "dde0ab55aadcf7c9cf71dbe36d90e97da6bc9498",
    "1c6b5d2b5841e5219a98937088cde4ae63869f80",
    "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7",
    "837e17b2eac1471d93e2eff395272063b265fee7",
    "239b2742d0e80d13c970fd062af4930e672fe903",
    "0663dbaac0a19719ddf9cd4290ba893bfca69da2",
    "513718f92dc572da22a995830fe203b969f23493",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f",
    "3af51887b40df8de7482040cf8a90600a2c4305f",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "235e3da90a4212d0c204afaef09db3408abfab82": "Ybodychange",
    "dde0ab55aadcf7c9cf71dbe36d90e97da6bc9498": "Ybodychange",
    "1c6b5d2b5841e5219a98937088cde4ae63869f80": "Ybodychange",
    "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7": "Ybodychange",
    "837e17b2eac1471d93e2eff395272063b265fee7": "Ybodychange",
    "239b2742d0e80d13c970fd062af4930e672fe903": "Ybodychange",
    "0663dbaac0a19719ddf9cd4290ba893bfca69da2": "Ybodychange",
    "513718f92dc572da22a995830fe203b969f23493": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f": "Ybodychange",
    "3af51887b40df8de7482040cf8a90600a2c4305f": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "235e3da90a4212d0c204afaef09db3408abfab82": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14287. DataXceiverServer May Double-Close PeerServer. Contributed by BELUGA BEHR.\n",
      "commitDate": "18/02/19 11:00 AM",
      "commitName": "235e3da90a4212d0c204afaef09db3408abfab82",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "15/02/19 4:32 PM",
      "commitNameOld": "dde0ab55aadcf7c9cf71dbe36d90e97da6bc9498",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 2.77,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,16 @@\n   void kill() {\n     assert (datanode.shouldRun \u003d\u003d false || datanode.shutdownForUpgrade) :\n       \"shoudRun should be set to false or restarting should be true\"\n       + \" before killing\";\n+    lock.lock();\n     try {\n-      this.peerServer.close();\n-      this.closed \u003d true;\n+      if (!closed) {\n+        peerServer.close();\n+        closed \u003d true;\n+      }\n     } catch (IOException ie) {\n       LOG.warn(\"{}:DataXceiverServer.kill()\", datanode.getDisplayName(), ie);\n+    } finally {\n+      lock.unlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void kill() {\n    assert (datanode.shouldRun \u003d\u003d false || datanode.shutdownForUpgrade) :\n      \"shoudRun should be set to false or restarting should be true\"\n      + \" before killing\";\n    lock.lock();\n    try {\n      if (!closed) {\n        peerServer.close();\n        closed \u003d true;\n      }\n    } catch (IOException ie) {\n      LOG.warn(\"{}:DataXceiverServer.kill()\", datanode.getDisplayName(), ie);\n    } finally {\n      lock.unlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java",
      "extendedDetails": {}
    },
    "dde0ab55aadcf7c9cf71dbe36d90e97da6bc9498": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14258. Introduce Java Concurrent Package To DataXceiverServer Class. Contributed by BELUGA BEHR.\n",
      "commitDate": "15/02/19 4:32 PM",
      "commitName": "dde0ab55aadcf7c9cf71dbe36d90e97da6bc9498",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "23/06/16 2:13 PM",
      "commitNameOld": "dca298d79e46e27bdf008be53dd77448d7a9c0c6",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 967.14,
      "commitsBetweenForRepo": 7428,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n   void kill() {\n     assert (datanode.shouldRun \u003d\u003d false || datanode.shutdownForUpgrade) :\n       \"shoudRun should be set to false or restarting should be true\"\n       + \" before killing\";\n     try {\n       this.peerServer.close();\n       this.closed \u003d true;\n     } catch (IOException ie) {\n-      LOG.warn(datanode.getDisplayName() + \":DataXceiverServer.kill(): \", ie);\n+      LOG.warn(\"{}:DataXceiverServer.kill()\", datanode.getDisplayName(), ie);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void kill() {\n    assert (datanode.shouldRun \u003d\u003d false || datanode.shutdownForUpgrade) :\n      \"shoudRun should be set to false or restarting should be true\"\n      + \" before killing\";\n    try {\n      this.peerServer.close();\n      this.closed \u003d true;\n    } catch (IOException ie) {\n      LOG.warn(\"{}:DataXceiverServer.kill()\", datanode.getDisplayName(), ie);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java",
      "extendedDetails": {}
    },
    "1c6b5d2b5841e5219a98937088cde4ae63869f80": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5583. Make DN send an OOB Ack on shutdown before restarting. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1571491 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/02/14 3:38 PM",
      "commitName": "1c6b5d2b5841e5219a98937088cde4ae63869f80",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "09/01/13 1:34 PM",
      "commitNameOld": "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 411.09,
      "commitsBetweenForRepo": 2591,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,11 @@\n   void kill() {\n-    assert datanode.shouldRun \u003d\u003d false :\n-      \"shoudRun should be set to false before killing\";\n+    assert (datanode.shouldRun \u003d\u003d false || datanode.shutdownForUpgrade) :\n+      \"shoudRun should be set to false or restarting should be true\"\n+      + \" before killing\";\n     try {\n       this.peerServer.close();\n+      this.closed \u003d true;\n     } catch (IOException ie) {\n       LOG.warn(datanode.getDisplayName() + \":DataXceiverServer.kill(): \", ie);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void kill() {\n    assert (datanode.shouldRun \u003d\u003d false || datanode.shutdownForUpgrade) :\n      \"shoudRun should be set to false or restarting should be true\"\n      + \" before killing\";\n    try {\n      this.peerServer.close();\n      this.closed \u003d true;\n    } catch (IOException ie) {\n      LOG.warn(datanode.getDisplayName() + \":DataXceiverServer.kill(): \", ie);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java",
      "extendedDetails": {}
    },
    "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4353. Encapsulate connections to peers in Peer and PeerServer classes. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1431097 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/13 1:34 PM",
      "commitName": "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "08/01/13 6:39 PM",
      "commitNameOld": "837e17b2eac1471d93e2eff395272063b265fee7",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.79,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,9 @@\n   void kill() {\n     assert datanode.shouldRun \u003d\u003d false :\n       \"shoudRun should be set to false before killing\";\n     try {\n-      this.ss.close();\n+      this.peerServer.close();\n     } catch (IOException ie) {\n       LOG.warn(datanode.getDisplayName() + \":DataXceiverServer.kill(): \", ie);\n     }\n-\n-    // close all the sockets that were accepted earlier\n-    synchronized (childSockets) {\n-      for (Iterator\u003cSocket\u003e it \u003d childSockets.iterator();\n-           it.hasNext();) {\n-        Socket thissock \u003d it.next();\n-        try {\n-          thissock.close();\n-        } catch (IOException e) {\n-        }\n-      }\n-    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void kill() {\n    assert datanode.shouldRun \u003d\u003d false :\n      \"shoudRun should be set to false before killing\";\n    try {\n      this.peerServer.close();\n    } catch (IOException ie) {\n      LOG.warn(datanode.getDisplayName() + \":DataXceiverServer.kill(): \", ie);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java",
      "extendedDetails": {}
    },
    "837e17b2eac1471d93e2eff395272063b265fee7": {
      "type": "Ybodychange",
      "commitMessage": "svn merge -c -1430507 . for reverting HDFS-4353. Encapsulate connections to peers in Peer and PeerServer classes\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1430662 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/01/13 6:39 PM",
      "commitName": "837e17b2eac1471d93e2eff395272063b265fee7",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "08/01/13 12:44 PM",
      "commitNameOld": "239b2742d0e80d13c970fd062af4930e672fe903",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.25,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,21 @@\n   void kill() {\n     assert datanode.shouldRun \u003d\u003d false :\n       \"shoudRun should be set to false before killing\";\n     try {\n-      this.peerServer.close();\n+      this.ss.close();\n     } catch (IOException ie) {\n       LOG.warn(datanode.getDisplayName() + \":DataXceiverServer.kill(): \", ie);\n     }\n+\n+    // close all the sockets that were accepted earlier\n+    synchronized (childSockets) {\n+      for (Iterator\u003cSocket\u003e it \u003d childSockets.iterator();\n+           it.hasNext();) {\n+        Socket thissock \u003d it.next();\n+        try {\n+          thissock.close();\n+        } catch (IOException e) {\n+        }\n+      }\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void kill() {\n    assert datanode.shouldRun \u003d\u003d false :\n      \"shoudRun should be set to false before killing\";\n    try {\n      this.ss.close();\n    } catch (IOException ie) {\n      LOG.warn(datanode.getDisplayName() + \":DataXceiverServer.kill(): \", ie);\n    }\n\n    // close all the sockets that were accepted earlier\n    synchronized (childSockets) {\n      for (Iterator\u003cSocket\u003e it \u003d childSockets.iterator();\n           it.hasNext();) {\n        Socket thissock \u003d it.next();\n        try {\n          thissock.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java",
      "extendedDetails": {}
    },
    "239b2742d0e80d13c970fd062af4930e672fe903": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4353. Encapsulate connections to peers in Peer and PeerServer classes. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1430507 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/01/13 12:44 PM",
      "commitName": "239b2742d0e80d13c970fd062af4930e672fe903",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "04/05/12 11:50 AM",
      "commitNameOld": "a701c792f880c43ba807f00a92a99dadf89eab0c",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 249.08,
      "commitsBetweenForRepo": 1300,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,9 @@\n   void kill() {\n     assert datanode.shouldRun \u003d\u003d false :\n       \"shoudRun should be set to false before killing\";\n     try {\n-      this.ss.close();\n+      this.peerServer.close();\n     } catch (IOException ie) {\n       LOG.warn(datanode.getDisplayName() + \":DataXceiverServer.kill(): \", ie);\n     }\n-\n-    // close all the sockets that were accepted earlier\n-    synchronized (childSockets) {\n-      for (Iterator\u003cSocket\u003e it \u003d childSockets.iterator();\n-           it.hasNext();) {\n-        Socket thissock \u003d it.next();\n-        try {\n-          thissock.close();\n-        } catch (IOException e) {\n-        }\n-      }\n-    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void kill() {\n    assert datanode.shouldRun \u003d\u003d false :\n      \"shoudRun should be set to false before killing\";\n    try {\n      this.peerServer.close();\n    } catch (IOException ie) {\n      LOG.warn(datanode.getDisplayName() + \":DataXceiverServer.kill(): \", ie);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java",
      "extendedDetails": {}
    },
    "0663dbaac0a19719ddf9cd4290ba893bfca69da2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3171. The DatanodeID \"name\" field is overloaded. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308014 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/03/12 8:41 PM",
      "commitName": "0663dbaac0a19719ddf9cd4290ba893bfca69da2",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "04/01/12 6:15 AM",
      "commitNameOld": "075122690c5c17ac443a8eb3fb7387001e4907c0",
      "commitAuthorOld": "Harsh J",
      "daysBetweenCommits": 87.56,
      "commitsBetweenForRepo": 658,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   void kill() {\n     assert datanode.shouldRun \u003d\u003d false :\n       \"shoudRun should be set to false before killing\";\n     try {\n       this.ss.close();\n     } catch (IOException ie) {\n-      LOG.warn(datanode.getMachineName() + \":DataXceiverServer.kill(): \", ie);\n+      LOG.warn(datanode.getDisplayName() + \":DataXceiverServer.kill(): \", ie);\n     }\n \n     // close all the sockets that were accepted earlier\n     synchronized (childSockets) {\n       for (Iterator\u003cSocket\u003e it \u003d childSockets.iterator();\n            it.hasNext();) {\n         Socket thissock \u003d it.next();\n         try {\n           thissock.close();\n         } catch (IOException e) {\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void kill() {\n    assert datanode.shouldRun \u003d\u003d false :\n      \"shoudRun should be set to false before killing\";\n    try {\n      this.ss.close();\n    } catch (IOException ie) {\n      LOG.warn(datanode.getDisplayName() + \":DataXceiverServer.kill(): \", ie);\n    }\n\n    // close all the sockets that were accepted earlier\n    synchronized (childSockets) {\n      for (Iterator\u003cSocket\u003e it \u003d childSockets.iterator();\n           it.hasNext();) {\n        Socket thissock \u003d it.next();\n        try {\n          thissock.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java",
      "extendedDetails": {}
    },
    "513718f92dc572da22a995830fe203b969f23493": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2568. Use a set to manage child sockets in XceiverServer. Contributed by Harsh J\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1204122 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/11/11 8:13 PM",
      "commitName": "513718f92dc572da22a995830fe203b969f23493",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "23/10/11 1:17 PM",
      "commitNameOld": "6e0991704ffda5cf4cff758f0e7086523fa7bcb4",
      "commitAuthorOld": "Konstantin Shvachko",
      "daysBetweenCommits": 27.33,
      "commitsBetweenForRepo": 198,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   void kill() {\n     assert datanode.shouldRun \u003d\u003d false :\n       \"shoudRun should be set to false before killing\";\n     try {\n       this.ss.close();\n     } catch (IOException ie) {\n       LOG.warn(datanode.getMachineName() + \":DataXceiverServer.kill(): \", ie);\n     }\n \n     // close all the sockets that were accepted earlier\n     synchronized (childSockets) {\n-      for (Iterator\u003cSocket\u003e it \u003d childSockets.values().iterator();\n+      for (Iterator\u003cSocket\u003e it \u003d childSockets.iterator();\n            it.hasNext();) {\n         Socket thissock \u003d it.next();\n         try {\n           thissock.close();\n         } catch (IOException e) {\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void kill() {\n    assert datanode.shouldRun \u003d\u003d false :\n      \"shoudRun should be set to false before killing\";\n    try {\n      this.ss.close();\n    } catch (IOException ie) {\n      LOG.warn(datanode.getMachineName() + \":DataXceiverServer.kill(): \", ie);\n    }\n\n    // close all the sockets that were accepted earlier\n    synchronized (childSockets) {\n      for (Iterator\u003cSocket\u003e it \u003d childSockets.iterator();\n           it.hasNext();) {\n        Socket thissock \u003d it.next();\n        try {\n          thissock.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  void kill() {\n    assert datanode.shouldRun \u003d\u003d false :\n      \"shoudRun should be set to false before killing\";\n    try {\n      this.ss.close();\n    } catch (IOException ie) {\n      LOG.warn(datanode.getMachineName() + \":DataXceiverServer.kill(): \", ie);\n    }\n\n    // close all the sockets that were accepted earlier\n    synchronized (childSockets) {\n      for (Iterator\u003cSocket\u003e it \u003d childSockets.values().iterator();\n           it.hasNext();) {\n        Socket thissock \u003d it.next();\n        try {\n          thissock.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  void kill() {\n    assert datanode.shouldRun \u003d\u003d false :\n      \"shoudRun should be set to false before killing\";\n    try {\n      this.ss.close();\n    } catch (IOException ie) {\n      LOG.warn(datanode.getMachineName() + \":DataXceiverServer.kill(): \", ie);\n    }\n\n    // close all the sockets that were accepted earlier\n    synchronized (childSockets) {\n      for (Iterator\u003cSocket\u003e it \u003d childSockets.values().iterator();\n           it.hasNext();) {\n        Socket thissock \u003d it.next();\n        try {\n          thissock.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java"
      }
    },
    "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1977. Stop using StringUtils.stringifyException(). Contributed by Bharath Mundlapudi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1145834 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/07/11 6:11 PM",
      "commitName": "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f",
      "commitAuthor": "Jitendra Nath Pandey",
      "commitDateOld": "30/06/11 1:56 PM",
      "commitNameOld": "3af51887b40df8de7482040cf8a90600a2c4305f",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 12.18,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,21 @@\n   void kill() {\n     assert datanode.shouldRun \u003d\u003d false :\n       \"shoudRun should be set to false before killing\";\n     try {\n       this.ss.close();\n     } catch (IOException ie) {\n-      LOG.warn(datanode.getMachineName() + \":DataXceiverServer.kill(): \"\n-                              + StringUtils.stringifyException(ie));\n+      LOG.warn(datanode.getMachineName() + \":DataXceiverServer.kill(): \", ie);\n     }\n \n     // close all the sockets that were accepted earlier\n     synchronized (childSockets) {\n       for (Iterator\u003cSocket\u003e it \u003d childSockets.values().iterator();\n            it.hasNext();) {\n         Socket thissock \u003d it.next();\n         try {\n           thissock.close();\n         } catch (IOException e) {\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void kill() {\n    assert datanode.shouldRun \u003d\u003d false :\n      \"shoudRun should be set to false before killing\";\n    try {\n      this.ss.close();\n    } catch (IOException ie) {\n      LOG.warn(datanode.getMachineName() + \":DataXceiverServer.kill(): \", ie);\n    }\n\n    // close all the sockets that were accepted earlier\n    synchronized (childSockets) {\n      for (Iterator\u003cSocket\u003e it \u003d childSockets.values().iterator();\n           it.hasNext();) {\n        Socket thissock \u003d it.next();\n        try {\n          thissock.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java",
      "extendedDetails": {}
    },
    "3af51887b40df8de7482040cf8a90600a2c4305f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2118. Couple dfs data dir improvements. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1141713 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/06/11 1:56 PM",
      "commitName": "3af51887b40df8de7482040cf8a90600a2c4305f",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "23/06/11 4:57 PM",
      "commitNameOld": "2f48fae72aa52e6ec42264cad24fab36b6a426c2",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 6.87,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   void kill() {\n     assert datanode.shouldRun \u003d\u003d false :\n       \"shoudRun should be set to false before killing\";\n     try {\n       this.ss.close();\n     } catch (IOException ie) {\n-      LOG.warn(datanode.getMachineName() + \":DataXceiveServer.kill(): \" \n+      LOG.warn(datanode.getMachineName() + \":DataXceiverServer.kill(): \"\n                               + StringUtils.stringifyException(ie));\n     }\n \n     // close all the sockets that were accepted earlier\n     synchronized (childSockets) {\n       for (Iterator\u003cSocket\u003e it \u003d childSockets.values().iterator();\n            it.hasNext();) {\n         Socket thissock \u003d it.next();\n         try {\n           thissock.close();\n         } catch (IOException e) {\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void kill() {\n    assert datanode.shouldRun \u003d\u003d false :\n      \"shoudRun should be set to false before killing\";\n    try {\n      this.ss.close();\n    } catch (IOException ie) {\n      LOG.warn(datanode.getMachineName() + \":DataXceiverServer.kill(): \"\n                              + StringUtils.stringifyException(ie));\n    }\n\n    // close all the sockets that were accepted earlier\n    synchronized (childSockets) {\n      for (Iterator\u003cSocket\u003e it \u003d childSockets.values().iterator();\n           it.hasNext();) {\n        Socket thissock \u003d it.next();\n        try {\n          thissock.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,22 @@\n+  void kill() {\n+    assert datanode.shouldRun \u003d\u003d false :\n+      \"shoudRun should be set to false before killing\";\n+    try {\n+      this.ss.close();\n+    } catch (IOException ie) {\n+      LOG.warn(datanode.getMachineName() + \":DataXceiveServer.kill(): \" \n+                              + StringUtils.stringifyException(ie));\n+    }\n+\n+    // close all the sockets that were accepted earlier\n+    synchronized (childSockets) {\n+      for (Iterator\u003cSocket\u003e it \u003d childSockets.values().iterator();\n+           it.hasNext();) {\n+        Socket thissock \u003d it.next();\n+        try {\n+          thissock.close();\n+        } catch (IOException e) {\n+        }\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void kill() {\n    assert datanode.shouldRun \u003d\u003d false :\n      \"shoudRun should be set to false before killing\";\n    try {\n      this.ss.close();\n    } catch (IOException ie) {\n      LOG.warn(datanode.getMachineName() + \":DataXceiveServer.kill(): \" \n                              + StringUtils.stringifyException(ie));\n    }\n\n    // close all the sockets that were accepted earlier\n    synchronized (childSockets) {\n      for (Iterator\u003cSocket\u003e it \u003d childSockets.values().iterator();\n           it.hasNext();) {\n        Socket thissock \u003d it.next();\n        try {\n          thissock.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java"
    }
  }
}