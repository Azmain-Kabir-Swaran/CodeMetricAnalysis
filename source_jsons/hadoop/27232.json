{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FileSystemTimelineReaderImpl.java",
  "functionName": "getEntityTypes",
  "functionId": "getEntityTypes___context-TimelineReaderContext",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/FileSystemTimelineReaderImpl.java",
  "functionStartLine": 429,
  "functionEndLine": 449,
  "numCommitsSeen": 20,
  "timeTaken": 1710,
  "changeHistory": [
    "bc27f7fb6da76b1b83e410de2bb8c1ecbd11b7f9",
    "bca928d3c7b88f39e9bc1784889596f0b00964d4",
    "4481561e4a3433197dd8e73f38856eef84f0fd03"
  ],
  "changeHistoryShort": {
    "bc27f7fb6da76b1b83e410de2bb8c1ecbd11b7f9": "Ybodychange",
    "bca928d3c7b88f39e9bc1784889596f0b00964d4": "Ybodychange",
    "4481561e4a3433197dd8e73f38856eef84f0fd03": "Yintroduced"
  },
  "changeHistoryDetails": {
    "bc27f7fb6da76b1b83e410de2bb8c1ecbd11b7f9": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7982. Do ACLs check while retrieving entity-types per application. Contribued by Prabhu Joseph.\n",
      "commitDate": "01/09/19 9:45 PM",
      "commitName": "bc27f7fb6da76b1b83e410de2bb8c1ecbd11b7f9",
      "commitAuthor": "Abhishek Modi",
      "commitDateOld": "30/05/19 9:58 PM",
      "commitNameOld": "e49162f4b3791dbf51079e3b19dd0c8bc2a85158",
      "commitAuthorOld": "Sunil G",
      "daysBetweenCommits": 93.99,
      "commitsBetweenForRepo": 823,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,21 @@\n   @Override public Set\u003cString\u003e getEntityTypes(TimelineReaderContext context)\n       throws IOException {\n     Set\u003cString\u003e result \u003d new TreeSet\u003c\u003e();\n     String flowRunPathStr \u003d getFlowRunPath(context.getUserId(),\n         context.getClusterId(), context.getFlowName(), context.getFlowRunId(),\n         context.getAppId());\n+    if (context.getUserId() \u003d\u003d null) {\n+      context.setUserId(new Path(flowRunPathStr).getParent().getParent().\n+          getName());\n+    }\n     Path clusterIdPath \u003d new Path(entitiesPath, context.getClusterId());\n     Path flowRunPath \u003d new Path(clusterIdPath, flowRunPathStr);\n     Path appIdPath \u003d new Path(flowRunPath, context.getAppId());\n     FileStatus[] fileStatuses \u003d fs.listStatus(appIdPath);\n     for (FileStatus fileStatus : fileStatuses) {\n       if (fileStatus.isDirectory()) {\n         result.add(fileStatus.getPath().getName());\n       }\n     }\n     return result;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  @Override public Set\u003cString\u003e getEntityTypes(TimelineReaderContext context)\n      throws IOException {\n    Set\u003cString\u003e result \u003d new TreeSet\u003c\u003e();\n    String flowRunPathStr \u003d getFlowRunPath(context.getUserId(),\n        context.getClusterId(), context.getFlowName(), context.getFlowRunId(),\n        context.getAppId());\n    if (context.getUserId() \u003d\u003d null) {\n      context.setUserId(new Path(flowRunPathStr).getParent().getParent().\n          getName());\n    }\n    Path clusterIdPath \u003d new Path(entitiesPath, context.getClusterId());\n    Path flowRunPath \u003d new Path(clusterIdPath, flowRunPathStr);\n    Path appIdPath \u003d new Path(flowRunPath, context.getAppId());\n    FileStatus[] fileStatuses \u003d fs.listStatus(appIdPath);\n    for (FileStatus fileStatus : fileStatuses) {\n      if (fileStatus.isDirectory()) {\n        result.add(fileStatus.getPath().getName());\n      }\n    }\n    return result;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/FileSystemTimelineReaderImpl.java",
      "extendedDetails": {}
    },
    "bca928d3c7b88f39e9bc1784889596f0b00964d4": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3879 [Storage implementation] Create HDFS backing storage implementation for ATS reads. Contributed by Abhishek Modi.\n",
      "commitDate": "11/10/18 9:14 PM",
      "commitName": "bca928d3c7b88f39e9bc1784889596f0b00964d4",
      "commitAuthor": "Vrushali C",
      "commitDateOld": "29/08/17 10:59 PM",
      "commitNameOld": "4481561e4a3433197dd8e73f38856eef84f0fd03",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 407.93,
      "commitsBetweenForRepo": 3724,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,17 @@\n   @Override public Set\u003cString\u003e getEntityTypes(TimelineReaderContext context)\n       throws IOException {\n     Set\u003cString\u003e result \u003d new TreeSet\u003c\u003e();\n-    String flowRunPath \u003d getFlowRunPath(context.getUserId(),\n+    String flowRunPathStr \u003d getFlowRunPath(context.getUserId(),\n         context.getClusterId(), context.getFlowName(), context.getFlowRunId(),\n         context.getAppId());\n-    File dir \u003d new File(new File(rootPath, ENTITIES_DIR),\n-        context.getClusterId() + File.separator + flowRunPath\n-            + File.separator + context.getAppId());\n-    File[] fileList \u003d dir.listFiles();\n-    if (fileList !\u003d null) {\n-      for (File f : fileList) {\n-        if (f.isDirectory()) {\n-          result.add(f.getName());\n-        }\n+    Path clusterIdPath \u003d new Path(entitiesPath, context.getClusterId());\n+    Path flowRunPath \u003d new Path(clusterIdPath, flowRunPathStr);\n+    Path appIdPath \u003d new Path(flowRunPath, context.getAppId());\n+    FileStatus[] fileStatuses \u003d fs.listStatus(appIdPath);\n+    for (FileStatus fileStatus : fileStatuses) {\n+      if (fileStatus.isDirectory()) {\n+        result.add(fileStatus.getPath().getName());\n       }\n     }\n     return result;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  @Override public Set\u003cString\u003e getEntityTypes(TimelineReaderContext context)\n      throws IOException {\n    Set\u003cString\u003e result \u003d new TreeSet\u003c\u003e();\n    String flowRunPathStr \u003d getFlowRunPath(context.getUserId(),\n        context.getClusterId(), context.getFlowName(), context.getFlowRunId(),\n        context.getAppId());\n    Path clusterIdPath \u003d new Path(entitiesPath, context.getClusterId());\n    Path flowRunPath \u003d new Path(clusterIdPath, flowRunPathStr);\n    Path appIdPath \u003d new Path(flowRunPath, context.getAppId());\n    FileStatus[] fileStatuses \u003d fs.listStatus(appIdPath);\n    for (FileStatus fileStatus : fileStatuses) {\n      if (fileStatus.isDirectory()) {\n        result.add(fileStatus.getPath().getName());\n      }\n    }\n    return result;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/FileSystemTimelineReaderImpl.java",
      "extendedDetails": {}
    },
    "4481561e4a3433197dd8e73f38856eef84f0fd03": {
      "type": "Yintroduced",
      "commitMessage": "YARN-5739. Provide timeline reader API to list available timeline entity types for one application. Contributed by Li Lu.\n",
      "commitDate": "29/08/17 10:59 PM",
      "commitName": "4481561e4a3433197dd8e73f38856eef84f0fd03",
      "commitAuthor": "Sangjin Lee",
      "diff": "@@ -0,0 +1,19 @@\n+  @Override public Set\u003cString\u003e getEntityTypes(TimelineReaderContext context)\n+      throws IOException {\n+    Set\u003cString\u003e result \u003d new TreeSet\u003c\u003e();\n+    String flowRunPath \u003d getFlowRunPath(context.getUserId(),\n+        context.getClusterId(), context.getFlowName(), context.getFlowRunId(),\n+        context.getAppId());\n+    File dir \u003d new File(new File(rootPath, ENTITIES_DIR),\n+        context.getClusterId() + File.separator + flowRunPath\n+            + File.separator + context.getAppId());\n+    File[] fileList \u003d dir.listFiles();\n+    if (fileList !\u003d null) {\n+      for (File f : fileList) {\n+        if (f.isDirectory()) {\n+          result.add(f.getName());\n+        }\n+      }\n+    }\n+    return result;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  @Override public Set\u003cString\u003e getEntityTypes(TimelineReaderContext context)\n      throws IOException {\n    Set\u003cString\u003e result \u003d new TreeSet\u003c\u003e();\n    String flowRunPath \u003d getFlowRunPath(context.getUserId(),\n        context.getClusterId(), context.getFlowName(), context.getFlowRunId(),\n        context.getAppId());\n    File dir \u003d new File(new File(rootPath, ENTITIES_DIR),\n        context.getClusterId() + File.separator + flowRunPath\n            + File.separator + context.getAppId());\n    File[] fileList \u003d dir.listFiles();\n    if (fileList !\u003d null) {\n      for (File f : fileList) {\n        if (f.isDirectory()) {\n          result.add(f.getName());\n        }\n      }\n    }\n    return result;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/FileSystemTimelineReaderImpl.java"
    }
  }
}