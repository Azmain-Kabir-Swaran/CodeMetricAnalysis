{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeDescriptor.java",
  "functionName": "chooseStorage4Block",
  "functionId": "chooseStorage4Block___t-StorageType__blockSize-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
  "functionStartLine": 759,
  "functionEndLine": 785,
  "numCommitsSeen": 118,
  "timeTaken": 2563,
  "changeHistory": [
    "5bf7e594d7d54e5295fe4240c3d60c08d4755ab7",
    "0f336bab9c070e0cdc935df4305084a036e2def7",
    "8fa41d9dd4b923bf4141f019414a1a8b079124c6"
  ],
  "changeHistoryShort": {
    "5bf7e594d7d54e5295fe4240c3d60c08d4755ab7": "Ybodychange",
    "0f336bab9c070e0cdc935df4305084a036e2def7": "Ybodychange",
    "8fa41d9dd4b923bf4141f019414a1a8b079124c6": "Yintroduced"
  },
  "changeHistoryDetails": {
    "5bf7e594d7d54e5295fe4240c3d60c08d4755ab7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9023. When NN is not able to identify DN for replication, reason behind it can be logged.\n",
      "commitDate": "28/12/17 11:54 AM",
      "commitName": "5bf7e594d7d54e5295fe4240c3d60c08d4755ab7",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "fb996a32a98a25c0fe34a8ebb28563b53cd6e20e",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 12.75,
      "commitsBetweenForRepo": 41,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,27 @@\n   public DatanodeStorageInfo chooseStorage4Block(StorageType t,\n       long blockSize) {\n     final long requiredSize \u003d\n         blockSize * HdfsServerConstants.MIN_BLOCKS_FOR_WRITE;\n     final long scheduledSize \u003d blockSize * getBlocksScheduled(t);\n     long remaining \u003d 0;\n     DatanodeStorageInfo storage \u003d null;\n     for (DatanodeStorageInfo s : getStorageInfos()) {\n       if (s.getState() \u003d\u003d State.NORMAL \u0026\u0026 s.getStorageType() \u003d\u003d t) {\n         if (storage \u003d\u003d null) {\n           storage \u003d s;\n         }\n         long r \u003d s.getRemaining();\n         if (r \u003e\u003d requiredSize) {\n           remaining +\u003d r;\n         }\n       }\n     }\n     if (requiredSize \u003e remaining - scheduledSize) {\n-      LOG.debug(\n+      BlockPlacementPolicy.LOG.debug(\n           \"The node {} does not have enough {} space (required\u003d{},\"\n           + \" scheduled\u003d{}, remaining\u003d{}).\",\n           this, t, requiredSize, scheduledSize, remaining);\n       return null;\n     }\n     return storage;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeStorageInfo chooseStorage4Block(StorageType t,\n      long blockSize) {\n    final long requiredSize \u003d\n        blockSize * HdfsServerConstants.MIN_BLOCKS_FOR_WRITE;\n    final long scheduledSize \u003d blockSize * getBlocksScheduled(t);\n    long remaining \u003d 0;\n    DatanodeStorageInfo storage \u003d null;\n    for (DatanodeStorageInfo s : getStorageInfos()) {\n      if (s.getState() \u003d\u003d State.NORMAL \u0026\u0026 s.getStorageType() \u003d\u003d t) {\n        if (storage \u003d\u003d null) {\n          storage \u003d s;\n        }\n        long r \u003d s.getRemaining();\n        if (r \u003e\u003d requiredSize) {\n          remaining +\u003d r;\n        }\n      }\n    }\n    if (requiredSize \u003e remaining - scheduledSize) {\n      BlockPlacementPolicy.LOG.debug(\n          \"The node {} does not have enough {} space (required\u003d{},\"\n          + \" scheduled\u003d{}, remaining\u003d{}).\",\n          this, t, requiredSize, scheduledSize, remaining);\n      return null;\n    }\n    return storage;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "0f336bab9c070e0cdc935df4305084a036e2def7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11494. Log message when DN is not selected for block replication. Contributed by Yiqun Lin\n",
      "commitDate": "03/03/17 6:47 PM",
      "commitName": "0f336bab9c070e0cdc935df4305084a036e2def7",
      "commitAuthor": "Mingliang Liu",
      "commitDateOld": "02/03/17 9:21 AM",
      "commitNameOld": "eeca8b0c4e2804b0fee5b012ea14b58383425ec3",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 1.39,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,27 @@\n   public DatanodeStorageInfo chooseStorage4Block(StorageType t,\n       long blockSize) {\n     final long requiredSize \u003d\n         blockSize * HdfsServerConstants.MIN_BLOCKS_FOR_WRITE;\n     final long scheduledSize \u003d blockSize * getBlocksScheduled(t);\n     long remaining \u003d 0;\n     DatanodeStorageInfo storage \u003d null;\n     for (DatanodeStorageInfo s : getStorageInfos()) {\n       if (s.getState() \u003d\u003d State.NORMAL \u0026\u0026 s.getStorageType() \u003d\u003d t) {\n         if (storage \u003d\u003d null) {\n           storage \u003d s;\n         }\n         long r \u003d s.getRemaining();\n         if (r \u003e\u003d requiredSize) {\n           remaining +\u003d r;\n         }\n       }\n     }\n     if (requiredSize \u003e remaining - scheduledSize) {\n+      LOG.debug(\n+          \"The node {} does not have enough {} space (required\u003d{},\"\n+          + \" scheduled\u003d{}, remaining\u003d{}).\",\n+          this, t, requiredSize, scheduledSize, remaining);\n       return null;\n     }\n     return storage;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeStorageInfo chooseStorage4Block(StorageType t,\n      long blockSize) {\n    final long requiredSize \u003d\n        blockSize * HdfsServerConstants.MIN_BLOCKS_FOR_WRITE;\n    final long scheduledSize \u003d blockSize * getBlocksScheduled(t);\n    long remaining \u003d 0;\n    DatanodeStorageInfo storage \u003d null;\n    for (DatanodeStorageInfo s : getStorageInfos()) {\n      if (s.getState() \u003d\u003d State.NORMAL \u0026\u0026 s.getStorageType() \u003d\u003d t) {\n        if (storage \u003d\u003d null) {\n          storage \u003d s;\n        }\n        long r \u003d s.getRemaining();\n        if (r \u003e\u003d requiredSize) {\n          remaining +\u003d r;\n        }\n      }\n    }\n    if (requiredSize \u003e remaining - scheduledSize) {\n      LOG.debug(\n          \"The node {} does not have enough {} space (required\u003d{},\"\n          + \" scheduled\u003d{}, remaining\u003d{}).\",\n          this, t, requiredSize, scheduledSize, remaining);\n      return null;\n    }\n    return storage;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "8fa41d9dd4b923bf4141f019414a1a8b079124c6": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-8946. Improve choosing datanode storage for block placement. (yliu)\n",
      "commitDate": "31/08/15 5:52 PM",
      "commitName": "8fa41d9dd4b923bf4141f019414a1a8b079124c6",
      "commitAuthor": "yliu",
      "diff": "@@ -0,0 +1,24 @@\n+  public DatanodeStorageInfo chooseStorage4Block(StorageType t,\n+      long blockSize) {\n+    final long requiredSize \u003d\n+        blockSize * HdfsServerConstants.MIN_BLOCKS_FOR_WRITE;\n+    final long scheduledSize \u003d blockSize * getBlocksScheduled(t);\n+    long remaining \u003d 0;\n+    DatanodeStorageInfo storage \u003d null;\n+    for (DatanodeStorageInfo s : getStorageInfos()) {\n+      if (s.getState() \u003d\u003d State.NORMAL \u0026\u0026\n+          s.getStorageType() \u003d\u003d t) {\n+        if (storage \u003d\u003d null) {\n+          storage \u003d s;\n+        }\n+        long r \u003d s.getRemaining();\n+        if (r \u003e\u003d requiredSize) {\n+          remaining +\u003d r;\n+        }\n+      }\n+    }\n+    if (requiredSize \u003e remaining - scheduledSize) {\n+      return null;\n+    }\n+    return storage;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeStorageInfo chooseStorage4Block(StorageType t,\n      long blockSize) {\n    final long requiredSize \u003d\n        blockSize * HdfsServerConstants.MIN_BLOCKS_FOR_WRITE;\n    final long scheduledSize \u003d blockSize * getBlocksScheduled(t);\n    long remaining \u003d 0;\n    DatanodeStorageInfo storage \u003d null;\n    for (DatanodeStorageInfo s : getStorageInfos()) {\n      if (s.getState() \u003d\u003d State.NORMAL \u0026\u0026\n          s.getStorageType() \u003d\u003d t) {\n        if (storage \u003d\u003d null) {\n          storage \u003d s;\n        }\n        long r \u003d s.getRemaining();\n        if (r \u003e\u003d requiredSize) {\n          remaining +\u003d r;\n        }\n      }\n    }\n    if (requiredSize \u003e remaining - scheduledSize) {\n      return null;\n    }\n    return storage;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java"
    }
  }
}