{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "chooseTarget4NewBlock",
  "functionId": "chooseTarget4NewBlock___src-String(modifiers-final)__numOfReplicas-int(modifiers-final)__client-Node(modifiers-final)__excludedNodes-Set__Node__(modifiers-final)__blocksize-long(modifiers-final)__favoredNodes-List__String__(modifiers-final)__storagePolicyID-byte(modifiers-final)__blockType-BlockType(modifiers-final)__ecPolicy-ErasureCodingPolicy(modifiers-final)__flags-EnumSet__AddBlockFlag__(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 2289,
  "functionEndLine": 2326,
  "numCommitsSeen": 2315,
  "timeTaken": 14728,
  "changeHistory": [
    "fbe06b58805aac4861fb27dfa273914b69e8bdc6",
    "de9994bd893af70fffdd68af6252fc45020e0e69",
    "3e6d0ca2b2f79bfa87faa7bbd46d814a48334fbd",
    "a2a5d7b5bca715835d92816e7b267b59f7270708",
    "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7"
  ],
  "changeHistoryShort": {
    "fbe06b58805aac4861fb27dfa273914b69e8bdc6": "Ymultichange(Yparameterchange,Ybodychange)",
    "de9994bd893af70fffdd68af6252fc45020e0e69": "Ymultichange(Yparameterchange,Ybodychange)",
    "3e6d0ca2b2f79bfa87faa7bbd46d814a48334fbd": "Ymultichange(Yparameterchange,Ybodychange)",
    "a2a5d7b5bca715835d92816e7b267b59f7270708": "Ymultichange(Yparameterchange,Ybodychange)",
    "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7": "Ymultichange(Yparameterchange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "fbe06b58805aac4861fb27dfa273914b69e8bdc6": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-12349. Improve log message when it could not alloc enough blocks for EC. (Lei (Eddy) Xu)\n",
      "commitDate": "15/09/17 12:12 PM",
      "commitName": "fbe06b58805aac4861fb27dfa273914b69e8bdc6",
      "commitAuthor": "Lei Xu",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-12349. Improve log message when it could not alloc enough blocks for EC. (Lei (Eddy) Xu)\n",
          "commitDate": "15/09/17 12:12 PM",
          "commitName": "fbe06b58805aac4861fb27dfa273914b69e8bdc6",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "11/09/17 10:06 AM",
          "commitNameOld": "de9994bd893af70fffdd68af6252fc45020e0e69",
          "commitAuthorOld": "Lei Xu",
          "daysBetweenCommits": 4.09,
          "commitsBetweenForRepo": 94,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,38 @@\n   public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n       final int numOfReplicas, final Node client,\n       final Set\u003cNode\u003e excludedNodes,\n       final long blocksize,\n       final List\u003cString\u003e favoredNodes,\n       final byte storagePolicyID,\n       final BlockType blockType,\n+      final ErasureCodingPolicy ecPolicy,\n       final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n     List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n         getDatanodeDescriptors(favoredNodes);\n     final BlockStoragePolicy storagePolicy \u003d\n         storagePolicySuite.getPolicy(storagePolicyID);\n     final BlockPlacementPolicy blockplacement \u003d\n         placementPolicies.getPolicy(blockType);\n     final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n         numOfReplicas, client, excludedNodes, blocksize, \n         favoredDatanodeDescriptors, storagePolicy, flags);\n-    if (targets.length \u003c minReplication) {\n-      throw new IOException(\"File \" + src + \" could only be replicated to \"\n-          + targets.length + \" nodes instead of minReplication (\u003d\"\n-          + minReplication + \").  There are \"\n-          + getDatanodeManager().getNetworkTopology().getNumOfLeaves()\n-          + \" datanode(s) running and \"\n-          + (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())\n-          + \" node(s) are excluded in this operation.\");\n+\n+    final String errorMessage \u003d \"File %s could only be written to %d of \" +\n+        \"the %d %s. There are %d datanode(s) running and %s \"\n+        + \"node(s) are excluded in this operation.\";\n+    if (blockType \u003d\u003d BlockType.CONTIGUOUS \u0026\u0026 targets.length \u003c minReplication) {\n+      throw new IOException(String.format(errorMessage, src,\n+          targets.length, minReplication, \"minReplication nodes\",\n+          getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n+          (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())));\n+    } else if (blockType \u003d\u003d BlockType.STRIPED \u0026\u0026\n+        targets.length \u003c ecPolicy.getNumDataUnits()) {\n+      throw new IOException(\n+          String.format(errorMessage, src, targets.length,\n+              ecPolicy.getNumDataUnits(),\n+              String.format(\"required nodes for %s\", ecPolicy.getName()),\n+              getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n+              (excludedNodes \u003d\u003d null ? \"no\" : excludedNodes.size())));\n     }\n     return targets;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n      final int numOfReplicas, final Node client,\n      final Set\u003cNode\u003e excludedNodes,\n      final long blocksize,\n      final List\u003cString\u003e favoredNodes,\n      final byte storagePolicyID,\n      final BlockType blockType,\n      final ErasureCodingPolicy ecPolicy,\n      final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n    List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n        getDatanodeDescriptors(favoredNodes);\n    final BlockStoragePolicy storagePolicy \u003d\n        storagePolicySuite.getPolicy(storagePolicyID);\n    final BlockPlacementPolicy blockplacement \u003d\n        placementPolicies.getPolicy(blockType);\n    final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n        numOfReplicas, client, excludedNodes, blocksize, \n        favoredDatanodeDescriptors, storagePolicy, flags);\n\n    final String errorMessage \u003d \"File %s could only be written to %d of \" +\n        \"the %d %s. There are %d datanode(s) running and %s \"\n        + \"node(s) are excluded in this operation.\";\n    if (blockType \u003d\u003d BlockType.CONTIGUOUS \u0026\u0026 targets.length \u003c minReplication) {\n      throw new IOException(String.format(errorMessage, src,\n          targets.length, minReplication, \"minReplication nodes\",\n          getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n          (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())));\n    } else if (blockType \u003d\u003d BlockType.STRIPED \u0026\u0026\n        targets.length \u003c ecPolicy.getNumDataUnits()) {\n      throw new IOException(\n          String.format(errorMessage, src, targets.length,\n              ecPolicy.getNumDataUnits(),\n              String.format(\"required nodes for %s\", ecPolicy.getName()),\n              getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n              (excludedNodes \u003d\u003d null ? \"no\" : excludedNodes.size())));\n    }\n    return targets;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "[src-String(modifiers-final), numOfReplicas-int(modifiers-final), client-Node(modifiers-final), excludedNodes-Set\u003cNode\u003e(modifiers-final), blocksize-long(modifiers-final), favoredNodes-List\u003cString\u003e(modifiers-final), storagePolicyID-byte(modifiers-final), blockType-BlockType(modifiers-final), flags-EnumSet\u003cAddBlockFlag\u003e(modifiers-final)]",
            "newValue": "[src-String(modifiers-final), numOfReplicas-int(modifiers-final), client-Node(modifiers-final), excludedNodes-Set\u003cNode\u003e(modifiers-final), blocksize-long(modifiers-final), favoredNodes-List\u003cString\u003e(modifiers-final), storagePolicyID-byte(modifiers-final), blockType-BlockType(modifiers-final), ecPolicy-ErasureCodingPolicy(modifiers-final), flags-EnumSet\u003cAddBlockFlag\u003e(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-12349. Improve log message when it could not alloc enough blocks for EC. (Lei (Eddy) Xu)\n",
          "commitDate": "15/09/17 12:12 PM",
          "commitName": "fbe06b58805aac4861fb27dfa273914b69e8bdc6",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "11/09/17 10:06 AM",
          "commitNameOld": "de9994bd893af70fffdd68af6252fc45020e0e69",
          "commitAuthorOld": "Lei Xu",
          "daysBetweenCommits": 4.09,
          "commitsBetweenForRepo": 94,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,38 @@\n   public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n       final int numOfReplicas, final Node client,\n       final Set\u003cNode\u003e excludedNodes,\n       final long blocksize,\n       final List\u003cString\u003e favoredNodes,\n       final byte storagePolicyID,\n       final BlockType blockType,\n+      final ErasureCodingPolicy ecPolicy,\n       final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n     List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n         getDatanodeDescriptors(favoredNodes);\n     final BlockStoragePolicy storagePolicy \u003d\n         storagePolicySuite.getPolicy(storagePolicyID);\n     final BlockPlacementPolicy blockplacement \u003d\n         placementPolicies.getPolicy(blockType);\n     final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n         numOfReplicas, client, excludedNodes, blocksize, \n         favoredDatanodeDescriptors, storagePolicy, flags);\n-    if (targets.length \u003c minReplication) {\n-      throw new IOException(\"File \" + src + \" could only be replicated to \"\n-          + targets.length + \" nodes instead of minReplication (\u003d\"\n-          + minReplication + \").  There are \"\n-          + getDatanodeManager().getNetworkTopology().getNumOfLeaves()\n-          + \" datanode(s) running and \"\n-          + (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())\n-          + \" node(s) are excluded in this operation.\");\n+\n+    final String errorMessage \u003d \"File %s could only be written to %d of \" +\n+        \"the %d %s. There are %d datanode(s) running and %s \"\n+        + \"node(s) are excluded in this operation.\";\n+    if (blockType \u003d\u003d BlockType.CONTIGUOUS \u0026\u0026 targets.length \u003c minReplication) {\n+      throw new IOException(String.format(errorMessage, src,\n+          targets.length, minReplication, \"minReplication nodes\",\n+          getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n+          (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())));\n+    } else if (blockType \u003d\u003d BlockType.STRIPED \u0026\u0026\n+        targets.length \u003c ecPolicy.getNumDataUnits()) {\n+      throw new IOException(\n+          String.format(errorMessage, src, targets.length,\n+              ecPolicy.getNumDataUnits(),\n+              String.format(\"required nodes for %s\", ecPolicy.getName()),\n+              getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n+              (excludedNodes \u003d\u003d null ? \"no\" : excludedNodes.size())));\n     }\n     return targets;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n      final int numOfReplicas, final Node client,\n      final Set\u003cNode\u003e excludedNodes,\n      final long blocksize,\n      final List\u003cString\u003e favoredNodes,\n      final byte storagePolicyID,\n      final BlockType blockType,\n      final ErasureCodingPolicy ecPolicy,\n      final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n    List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n        getDatanodeDescriptors(favoredNodes);\n    final BlockStoragePolicy storagePolicy \u003d\n        storagePolicySuite.getPolicy(storagePolicyID);\n    final BlockPlacementPolicy blockplacement \u003d\n        placementPolicies.getPolicy(blockType);\n    final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n        numOfReplicas, client, excludedNodes, blocksize, \n        favoredDatanodeDescriptors, storagePolicy, flags);\n\n    final String errorMessage \u003d \"File %s could only be written to %d of \" +\n        \"the %d %s. There are %d datanode(s) running and %s \"\n        + \"node(s) are excluded in this operation.\";\n    if (blockType \u003d\u003d BlockType.CONTIGUOUS \u0026\u0026 targets.length \u003c minReplication) {\n      throw new IOException(String.format(errorMessage, src,\n          targets.length, minReplication, \"minReplication nodes\",\n          getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n          (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())));\n    } else if (blockType \u003d\u003d BlockType.STRIPED \u0026\u0026\n        targets.length \u003c ecPolicy.getNumDataUnits()) {\n      throw new IOException(\n          String.format(errorMessage, src, targets.length,\n              ecPolicy.getNumDataUnits(),\n              String.format(\"required nodes for %s\", ecPolicy.getName()),\n              getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n              (excludedNodes \u003d\u003d null ? \"no\" : excludedNodes.size())));\n    }\n    return targets;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "de9994bd893af70fffdd68af6252fc45020e0e69": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "Revert \"HDFS-12349. Improve log message when it could not alloc enough blocks for EC. (lei)\"\n\nThis reverts commit 3e6d0ca2b2f79bfa87faa7bbd46d814a48334fbd.\n",
      "commitDate": "11/09/17 10:06 AM",
      "commitName": "de9994bd893af70fffdd68af6252fc45020e0e69",
      "commitAuthor": "Lei Xu",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "Revert \"HDFS-12349. Improve log message when it could not alloc enough blocks for EC. (lei)\"\n\nThis reverts commit 3e6d0ca2b2f79bfa87faa7bbd46d814a48334fbd.\n",
          "commitDate": "11/09/17 10:06 AM",
          "commitName": "de9994bd893af70fffdd68af6252fc45020e0e69",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "07/09/17 6:01 PM",
          "commitNameOld": "3e6d0ca2b2f79bfa87faa7bbd46d814a48334fbd",
          "commitAuthorOld": "Lei Xu",
          "daysBetweenCommits": 3.67,
          "commitsBetweenForRepo": 19,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,28 @@\n   public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n       final int numOfReplicas, final Node client,\n       final Set\u003cNode\u003e excludedNodes,\n       final long blocksize,\n       final List\u003cString\u003e favoredNodes,\n       final byte storagePolicyID,\n       final BlockType blockType,\n-      final ErasureCodingPolicy ecPolicy,\n       final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n     List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n         getDatanodeDescriptors(favoredNodes);\n     final BlockStoragePolicy storagePolicy \u003d\n         storagePolicySuite.getPolicy(storagePolicyID);\n     final BlockPlacementPolicy blockplacement \u003d\n         placementPolicies.getPolicy(blockType);\n     final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n         numOfReplicas, client, excludedNodes, blocksize, \n         favoredDatanodeDescriptors, storagePolicy, flags);\n-\n-    final String ERROR_MESSAGE \u003d \"File %s could only be written to %d of \" +\n-        \"the %d %s. There are %d datanode(s) running and %s \"\n-        + \"node(s) are excluded in this operation.\";\n-    if (blockType \u003d\u003d BlockType.CONTIGUOUS \u0026\u0026 targets.length \u003c minReplication) {\n-      throw new IOException(String.format(ERROR_MESSAGE, src,\n-          targets.length, minReplication, \"minReplication\", minReplication,\n-          getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n-          (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())));\n-    } else if (blockType \u003d\u003d BlockType.STRIPED \u0026\u0026\n-        targets.length \u003c ecPolicy.getNumDataUnits()) {\n-      throw new IOException(\n-          String.format(ERROR_MESSAGE, src, targets.length,\n-              ecPolicy.getNumDataUnits(),\n-              String.format(\"required nodes for %s\", ecPolicy.getName()),\n-              getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n-              (excludedNodes \u003d\u003d null ? \"no\" : excludedNodes.size())));\n+    if (targets.length \u003c minReplication) {\n+      throw new IOException(\"File \" + src + \" could only be replicated to \"\n+          + targets.length + \" nodes instead of minReplication (\u003d\"\n+          + minReplication + \").  There are \"\n+          + getDatanodeManager().getNetworkTopology().getNumOfLeaves()\n+          + \" datanode(s) running and \"\n+          + (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())\n+          + \" node(s) are excluded in this operation.\");\n     }\n     return targets;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n      final int numOfReplicas, final Node client,\n      final Set\u003cNode\u003e excludedNodes,\n      final long blocksize,\n      final List\u003cString\u003e favoredNodes,\n      final byte storagePolicyID,\n      final BlockType blockType,\n      final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n    List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n        getDatanodeDescriptors(favoredNodes);\n    final BlockStoragePolicy storagePolicy \u003d\n        storagePolicySuite.getPolicy(storagePolicyID);\n    final BlockPlacementPolicy blockplacement \u003d\n        placementPolicies.getPolicy(blockType);\n    final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n        numOfReplicas, client, excludedNodes, blocksize, \n        favoredDatanodeDescriptors, storagePolicy, flags);\n    if (targets.length \u003c minReplication) {\n      throw new IOException(\"File \" + src + \" could only be replicated to \"\n          + targets.length + \" nodes instead of minReplication (\u003d\"\n          + minReplication + \").  There are \"\n          + getDatanodeManager().getNetworkTopology().getNumOfLeaves()\n          + \" datanode(s) running and \"\n          + (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())\n          + \" node(s) are excluded in this operation.\");\n    }\n    return targets;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "[src-String(modifiers-final), numOfReplicas-int(modifiers-final), client-Node(modifiers-final), excludedNodes-Set\u003cNode\u003e(modifiers-final), blocksize-long(modifiers-final), favoredNodes-List\u003cString\u003e(modifiers-final), storagePolicyID-byte(modifiers-final), blockType-BlockType(modifiers-final), ecPolicy-ErasureCodingPolicy(modifiers-final), flags-EnumSet\u003cAddBlockFlag\u003e(modifiers-final)]",
            "newValue": "[src-String(modifiers-final), numOfReplicas-int(modifiers-final), client-Node(modifiers-final), excludedNodes-Set\u003cNode\u003e(modifiers-final), blocksize-long(modifiers-final), favoredNodes-List\u003cString\u003e(modifiers-final), storagePolicyID-byte(modifiers-final), blockType-BlockType(modifiers-final), flags-EnumSet\u003cAddBlockFlag\u003e(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "Revert \"HDFS-12349. Improve log message when it could not alloc enough blocks for EC. (lei)\"\n\nThis reverts commit 3e6d0ca2b2f79bfa87faa7bbd46d814a48334fbd.\n",
          "commitDate": "11/09/17 10:06 AM",
          "commitName": "de9994bd893af70fffdd68af6252fc45020e0e69",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "07/09/17 6:01 PM",
          "commitNameOld": "3e6d0ca2b2f79bfa87faa7bbd46d814a48334fbd",
          "commitAuthorOld": "Lei Xu",
          "daysBetweenCommits": 3.67,
          "commitsBetweenForRepo": 19,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,28 @@\n   public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n       final int numOfReplicas, final Node client,\n       final Set\u003cNode\u003e excludedNodes,\n       final long blocksize,\n       final List\u003cString\u003e favoredNodes,\n       final byte storagePolicyID,\n       final BlockType blockType,\n-      final ErasureCodingPolicy ecPolicy,\n       final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n     List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n         getDatanodeDescriptors(favoredNodes);\n     final BlockStoragePolicy storagePolicy \u003d\n         storagePolicySuite.getPolicy(storagePolicyID);\n     final BlockPlacementPolicy blockplacement \u003d\n         placementPolicies.getPolicy(blockType);\n     final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n         numOfReplicas, client, excludedNodes, blocksize, \n         favoredDatanodeDescriptors, storagePolicy, flags);\n-\n-    final String ERROR_MESSAGE \u003d \"File %s could only be written to %d of \" +\n-        \"the %d %s. There are %d datanode(s) running and %s \"\n-        + \"node(s) are excluded in this operation.\";\n-    if (blockType \u003d\u003d BlockType.CONTIGUOUS \u0026\u0026 targets.length \u003c minReplication) {\n-      throw new IOException(String.format(ERROR_MESSAGE, src,\n-          targets.length, minReplication, \"minReplication\", minReplication,\n-          getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n-          (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())));\n-    } else if (blockType \u003d\u003d BlockType.STRIPED \u0026\u0026\n-        targets.length \u003c ecPolicy.getNumDataUnits()) {\n-      throw new IOException(\n-          String.format(ERROR_MESSAGE, src, targets.length,\n-              ecPolicy.getNumDataUnits(),\n-              String.format(\"required nodes for %s\", ecPolicy.getName()),\n-              getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n-              (excludedNodes \u003d\u003d null ? \"no\" : excludedNodes.size())));\n+    if (targets.length \u003c minReplication) {\n+      throw new IOException(\"File \" + src + \" could only be replicated to \"\n+          + targets.length + \" nodes instead of minReplication (\u003d\"\n+          + minReplication + \").  There are \"\n+          + getDatanodeManager().getNetworkTopology().getNumOfLeaves()\n+          + \" datanode(s) running and \"\n+          + (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())\n+          + \" node(s) are excluded in this operation.\");\n     }\n     return targets;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n      final int numOfReplicas, final Node client,\n      final Set\u003cNode\u003e excludedNodes,\n      final long blocksize,\n      final List\u003cString\u003e favoredNodes,\n      final byte storagePolicyID,\n      final BlockType blockType,\n      final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n    List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n        getDatanodeDescriptors(favoredNodes);\n    final BlockStoragePolicy storagePolicy \u003d\n        storagePolicySuite.getPolicy(storagePolicyID);\n    final BlockPlacementPolicy blockplacement \u003d\n        placementPolicies.getPolicy(blockType);\n    final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n        numOfReplicas, client, excludedNodes, blocksize, \n        favoredDatanodeDescriptors, storagePolicy, flags);\n    if (targets.length \u003c minReplication) {\n      throw new IOException(\"File \" + src + \" could only be replicated to \"\n          + targets.length + \" nodes instead of minReplication (\u003d\"\n          + minReplication + \").  There are \"\n          + getDatanodeManager().getNetworkTopology().getNumOfLeaves()\n          + \" datanode(s) running and \"\n          + (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())\n          + \" node(s) are excluded in this operation.\");\n    }\n    return targets;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "3e6d0ca2b2f79bfa87faa7bbd46d814a48334fbd": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-12349. Improve log message when it could not alloc enough blocks for EC. (lei)\n",
      "commitDate": "07/09/17 6:01 PM",
      "commitName": "3e6d0ca2b2f79bfa87faa7bbd46d814a48334fbd",
      "commitAuthor": "Lei Xu",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-12349. Improve log message when it could not alloc enough blocks for EC. (lei)\n",
          "commitDate": "07/09/17 6:01 PM",
          "commitName": "3e6d0ca2b2f79bfa87faa7bbd46d814a48334fbd",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "07/09/17 4:57 PM",
          "commitNameOld": "4e50dc976a92a9560630c87cfc4e4513916e5735",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,38 @@\n   public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n       final int numOfReplicas, final Node client,\n       final Set\u003cNode\u003e excludedNodes,\n       final long blocksize,\n       final List\u003cString\u003e favoredNodes,\n       final byte storagePolicyID,\n       final BlockType blockType,\n+      final ErasureCodingPolicy ecPolicy,\n       final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n     List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n         getDatanodeDescriptors(favoredNodes);\n     final BlockStoragePolicy storagePolicy \u003d\n         storagePolicySuite.getPolicy(storagePolicyID);\n     final BlockPlacementPolicy blockplacement \u003d\n         placementPolicies.getPolicy(blockType);\n     final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n         numOfReplicas, client, excludedNodes, blocksize, \n         favoredDatanodeDescriptors, storagePolicy, flags);\n-    if (targets.length \u003c minReplication) {\n-      throw new IOException(\"File \" + src + \" could only be replicated to \"\n-          + targets.length + \" nodes instead of minReplication (\u003d\"\n-          + minReplication + \").  There are \"\n-          + getDatanodeManager().getNetworkTopology().getNumOfLeaves()\n-          + \" datanode(s) running and \"\n-          + (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())\n-          + \" node(s) are excluded in this operation.\");\n+\n+    final String ERROR_MESSAGE \u003d \"File %s could only be written to %d of \" +\n+        \"the %d %s. There are %d datanode(s) running and %s \"\n+        + \"node(s) are excluded in this operation.\";\n+    if (blockType \u003d\u003d BlockType.CONTIGUOUS \u0026\u0026 targets.length \u003c minReplication) {\n+      throw new IOException(String.format(ERROR_MESSAGE, src,\n+          targets.length, minReplication, \"minReplication\", minReplication,\n+          getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n+          (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())));\n+    } else if (blockType \u003d\u003d BlockType.STRIPED \u0026\u0026\n+        targets.length \u003c ecPolicy.getNumDataUnits()) {\n+      throw new IOException(\n+          String.format(ERROR_MESSAGE, src, targets.length,\n+              ecPolicy.getNumDataUnits(),\n+              String.format(\"required nodes for %s\", ecPolicy.getName()),\n+              getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n+              (excludedNodes \u003d\u003d null ? \"no\" : excludedNodes.size())));\n     }\n     return targets;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n      final int numOfReplicas, final Node client,\n      final Set\u003cNode\u003e excludedNodes,\n      final long blocksize,\n      final List\u003cString\u003e favoredNodes,\n      final byte storagePolicyID,\n      final BlockType blockType,\n      final ErasureCodingPolicy ecPolicy,\n      final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n    List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n        getDatanodeDescriptors(favoredNodes);\n    final BlockStoragePolicy storagePolicy \u003d\n        storagePolicySuite.getPolicy(storagePolicyID);\n    final BlockPlacementPolicy blockplacement \u003d\n        placementPolicies.getPolicy(blockType);\n    final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n        numOfReplicas, client, excludedNodes, blocksize, \n        favoredDatanodeDescriptors, storagePolicy, flags);\n\n    final String ERROR_MESSAGE \u003d \"File %s could only be written to %d of \" +\n        \"the %d %s. There are %d datanode(s) running and %s \"\n        + \"node(s) are excluded in this operation.\";\n    if (blockType \u003d\u003d BlockType.CONTIGUOUS \u0026\u0026 targets.length \u003c minReplication) {\n      throw new IOException(String.format(ERROR_MESSAGE, src,\n          targets.length, minReplication, \"minReplication\", minReplication,\n          getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n          (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())));\n    } else if (blockType \u003d\u003d BlockType.STRIPED \u0026\u0026\n        targets.length \u003c ecPolicy.getNumDataUnits()) {\n      throw new IOException(\n          String.format(ERROR_MESSAGE, src, targets.length,\n              ecPolicy.getNumDataUnits(),\n              String.format(\"required nodes for %s\", ecPolicy.getName()),\n              getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n              (excludedNodes \u003d\u003d null ? \"no\" : excludedNodes.size())));\n    }\n    return targets;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "[src-String(modifiers-final), numOfReplicas-int(modifiers-final), client-Node(modifiers-final), excludedNodes-Set\u003cNode\u003e(modifiers-final), blocksize-long(modifiers-final), favoredNodes-List\u003cString\u003e(modifiers-final), storagePolicyID-byte(modifiers-final), blockType-BlockType(modifiers-final), flags-EnumSet\u003cAddBlockFlag\u003e(modifiers-final)]",
            "newValue": "[src-String(modifiers-final), numOfReplicas-int(modifiers-final), client-Node(modifiers-final), excludedNodes-Set\u003cNode\u003e(modifiers-final), blocksize-long(modifiers-final), favoredNodes-List\u003cString\u003e(modifiers-final), storagePolicyID-byte(modifiers-final), blockType-BlockType(modifiers-final), ecPolicy-ErasureCodingPolicy(modifiers-final), flags-EnumSet\u003cAddBlockFlag\u003e(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-12349. Improve log message when it could not alloc enough blocks for EC. (lei)\n",
          "commitDate": "07/09/17 6:01 PM",
          "commitName": "3e6d0ca2b2f79bfa87faa7bbd46d814a48334fbd",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "07/09/17 4:57 PM",
          "commitNameOld": "4e50dc976a92a9560630c87cfc4e4513916e5735",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,38 @@\n   public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n       final int numOfReplicas, final Node client,\n       final Set\u003cNode\u003e excludedNodes,\n       final long blocksize,\n       final List\u003cString\u003e favoredNodes,\n       final byte storagePolicyID,\n       final BlockType blockType,\n+      final ErasureCodingPolicy ecPolicy,\n       final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n     List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n         getDatanodeDescriptors(favoredNodes);\n     final BlockStoragePolicy storagePolicy \u003d\n         storagePolicySuite.getPolicy(storagePolicyID);\n     final BlockPlacementPolicy blockplacement \u003d\n         placementPolicies.getPolicy(blockType);\n     final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n         numOfReplicas, client, excludedNodes, blocksize, \n         favoredDatanodeDescriptors, storagePolicy, flags);\n-    if (targets.length \u003c minReplication) {\n-      throw new IOException(\"File \" + src + \" could only be replicated to \"\n-          + targets.length + \" nodes instead of minReplication (\u003d\"\n-          + minReplication + \").  There are \"\n-          + getDatanodeManager().getNetworkTopology().getNumOfLeaves()\n-          + \" datanode(s) running and \"\n-          + (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())\n-          + \" node(s) are excluded in this operation.\");\n+\n+    final String ERROR_MESSAGE \u003d \"File %s could only be written to %d of \" +\n+        \"the %d %s. There are %d datanode(s) running and %s \"\n+        + \"node(s) are excluded in this operation.\";\n+    if (blockType \u003d\u003d BlockType.CONTIGUOUS \u0026\u0026 targets.length \u003c minReplication) {\n+      throw new IOException(String.format(ERROR_MESSAGE, src,\n+          targets.length, minReplication, \"minReplication\", minReplication,\n+          getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n+          (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())));\n+    } else if (blockType \u003d\u003d BlockType.STRIPED \u0026\u0026\n+        targets.length \u003c ecPolicy.getNumDataUnits()) {\n+      throw new IOException(\n+          String.format(ERROR_MESSAGE, src, targets.length,\n+              ecPolicy.getNumDataUnits(),\n+              String.format(\"required nodes for %s\", ecPolicy.getName()),\n+              getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n+              (excludedNodes \u003d\u003d null ? \"no\" : excludedNodes.size())));\n     }\n     return targets;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n      final int numOfReplicas, final Node client,\n      final Set\u003cNode\u003e excludedNodes,\n      final long blocksize,\n      final List\u003cString\u003e favoredNodes,\n      final byte storagePolicyID,\n      final BlockType blockType,\n      final ErasureCodingPolicy ecPolicy,\n      final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n    List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n        getDatanodeDescriptors(favoredNodes);\n    final BlockStoragePolicy storagePolicy \u003d\n        storagePolicySuite.getPolicy(storagePolicyID);\n    final BlockPlacementPolicy blockplacement \u003d\n        placementPolicies.getPolicy(blockType);\n    final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n        numOfReplicas, client, excludedNodes, blocksize, \n        favoredDatanodeDescriptors, storagePolicy, flags);\n\n    final String ERROR_MESSAGE \u003d \"File %s could only be written to %d of \" +\n        \"the %d %s. There are %d datanode(s) running and %s \"\n        + \"node(s) are excluded in this operation.\";\n    if (blockType \u003d\u003d BlockType.CONTIGUOUS \u0026\u0026 targets.length \u003c minReplication) {\n      throw new IOException(String.format(ERROR_MESSAGE, src,\n          targets.length, minReplication, \"minReplication\", minReplication,\n          getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n          (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())));\n    } else if (blockType \u003d\u003d BlockType.STRIPED \u0026\u0026\n        targets.length \u003c ecPolicy.getNumDataUnits()) {\n      throw new IOException(\n          String.format(ERROR_MESSAGE, src, targets.length,\n              ecPolicy.getNumDataUnits(),\n              String.format(\"required nodes for %s\", ecPolicy.getName()),\n              getDatanodeManager().getNetworkTopology().getNumOfLeaves(),\n              (excludedNodes \u003d\u003d null ? \"no\" : excludedNodes.size())));\n    }\n    return targets;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "a2a5d7b5bca715835d92816e7b267b59f7270708": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-10759. Change fsimage bool isStriped from boolean to an enum. Contributed by Ewan Higgs.\n",
      "commitDate": "18/01/17 1:31 PM",
      "commitName": "a2a5d7b5bca715835d92816e7b267b59f7270708",
      "commitAuthor": "Andrew Wang",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-10759. Change fsimage bool isStriped from boolean to an enum. Contributed by Ewan Higgs.\n",
          "commitDate": "18/01/17 1:31 PM",
          "commitName": "a2a5d7b5bca715835d92816e7b267b59f7270708",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "05/12/16 10:54 AM",
          "commitNameOld": "1b5cceaffbdde50a87ede81552dc380832db8e79",
          "commitAuthorOld": "Wei-Chiu Chuang",
          "daysBetweenCommits": 44.11,
          "commitsBetweenForRepo": 218,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,28 @@\n   public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n       final int numOfReplicas, final Node client,\n       final Set\u003cNode\u003e excludedNodes,\n       final long blocksize,\n       final List\u003cString\u003e favoredNodes,\n       final byte storagePolicyID,\n-      final boolean isStriped,\n+      final BlockType blockType,\n       final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n     List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n         getDatanodeDescriptors(favoredNodes);\n-    final BlockStoragePolicy storagePolicy \u003d storagePolicySuite.getPolicy(storagePolicyID);\n-    final BlockPlacementPolicy blockplacement \u003d placementPolicies.getPolicy(isStriped);\n+    final BlockStoragePolicy storagePolicy \u003d\n+        storagePolicySuite.getPolicy(storagePolicyID);\n+    final BlockPlacementPolicy blockplacement \u003d\n+        placementPolicies.getPolicy(blockType);\n     final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n         numOfReplicas, client, excludedNodes, blocksize, \n         favoredDatanodeDescriptors, storagePolicy, flags);\n     if (targets.length \u003c minReplication) {\n       throw new IOException(\"File \" + src + \" could only be replicated to \"\n           + targets.length + \" nodes instead of minReplication (\u003d\"\n           + minReplication + \").  There are \"\n           + getDatanodeManager().getNetworkTopology().getNumOfLeaves()\n           + \" datanode(s) running and \"\n           + (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())\n           + \" node(s) are excluded in this operation.\");\n     }\n     return targets;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n      final int numOfReplicas, final Node client,\n      final Set\u003cNode\u003e excludedNodes,\n      final long blocksize,\n      final List\u003cString\u003e favoredNodes,\n      final byte storagePolicyID,\n      final BlockType blockType,\n      final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n    List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n        getDatanodeDescriptors(favoredNodes);\n    final BlockStoragePolicy storagePolicy \u003d\n        storagePolicySuite.getPolicy(storagePolicyID);\n    final BlockPlacementPolicy blockplacement \u003d\n        placementPolicies.getPolicy(blockType);\n    final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n        numOfReplicas, client, excludedNodes, blocksize, \n        favoredDatanodeDescriptors, storagePolicy, flags);\n    if (targets.length \u003c minReplication) {\n      throw new IOException(\"File \" + src + \" could only be replicated to \"\n          + targets.length + \" nodes instead of minReplication (\u003d\"\n          + minReplication + \").  There are \"\n          + getDatanodeManager().getNetworkTopology().getNumOfLeaves()\n          + \" datanode(s) running and \"\n          + (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())\n          + \" node(s) are excluded in this operation.\");\n    }\n    return targets;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "[src-String(modifiers-final), numOfReplicas-int(modifiers-final), client-Node(modifiers-final), excludedNodes-Set\u003cNode\u003e(modifiers-final), blocksize-long(modifiers-final), favoredNodes-List\u003cString\u003e(modifiers-final), storagePolicyID-byte(modifiers-final), isStriped-boolean(modifiers-final), flags-EnumSet\u003cAddBlockFlag\u003e(modifiers-final)]",
            "newValue": "[src-String(modifiers-final), numOfReplicas-int(modifiers-final), client-Node(modifiers-final), excludedNodes-Set\u003cNode\u003e(modifiers-final), blocksize-long(modifiers-final), favoredNodes-List\u003cString\u003e(modifiers-final), storagePolicyID-byte(modifiers-final), blockType-BlockType(modifiers-final), flags-EnumSet\u003cAddBlockFlag\u003e(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10759. Change fsimage bool isStriped from boolean to an enum. Contributed by Ewan Higgs.\n",
          "commitDate": "18/01/17 1:31 PM",
          "commitName": "a2a5d7b5bca715835d92816e7b267b59f7270708",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "05/12/16 10:54 AM",
          "commitNameOld": "1b5cceaffbdde50a87ede81552dc380832db8e79",
          "commitAuthorOld": "Wei-Chiu Chuang",
          "daysBetweenCommits": 44.11,
          "commitsBetweenForRepo": 218,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,28 @@\n   public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n       final int numOfReplicas, final Node client,\n       final Set\u003cNode\u003e excludedNodes,\n       final long blocksize,\n       final List\u003cString\u003e favoredNodes,\n       final byte storagePolicyID,\n-      final boolean isStriped,\n+      final BlockType blockType,\n       final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n     List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n         getDatanodeDescriptors(favoredNodes);\n-    final BlockStoragePolicy storagePolicy \u003d storagePolicySuite.getPolicy(storagePolicyID);\n-    final BlockPlacementPolicy blockplacement \u003d placementPolicies.getPolicy(isStriped);\n+    final BlockStoragePolicy storagePolicy \u003d\n+        storagePolicySuite.getPolicy(storagePolicyID);\n+    final BlockPlacementPolicy blockplacement \u003d\n+        placementPolicies.getPolicy(blockType);\n     final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n         numOfReplicas, client, excludedNodes, blocksize, \n         favoredDatanodeDescriptors, storagePolicy, flags);\n     if (targets.length \u003c minReplication) {\n       throw new IOException(\"File \" + src + \" could only be replicated to \"\n           + targets.length + \" nodes instead of minReplication (\u003d\"\n           + minReplication + \").  There are \"\n           + getDatanodeManager().getNetworkTopology().getNumOfLeaves()\n           + \" datanode(s) running and \"\n           + (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())\n           + \" node(s) are excluded in this operation.\");\n     }\n     return targets;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n      final int numOfReplicas, final Node client,\n      final Set\u003cNode\u003e excludedNodes,\n      final long blocksize,\n      final List\u003cString\u003e favoredNodes,\n      final byte storagePolicyID,\n      final BlockType blockType,\n      final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n    List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n        getDatanodeDescriptors(favoredNodes);\n    final BlockStoragePolicy storagePolicy \u003d\n        storagePolicySuite.getPolicy(storagePolicyID);\n    final BlockPlacementPolicy blockplacement \u003d\n        placementPolicies.getPolicy(blockType);\n    final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n        numOfReplicas, client, excludedNodes, blocksize, \n        favoredDatanodeDescriptors, storagePolicy, flags);\n    if (targets.length \u003c minReplication) {\n      throw new IOException(\"File \" + src + \" could only be replicated to \"\n          + targets.length + \" nodes instead of minReplication (\u003d\"\n          + minReplication + \").  There are \"\n          + getDatanodeManager().getNetworkTopology().getNumOfLeaves()\n          + \" datanode(s) running and \"\n          + (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())\n          + \" node(s) are excluded in this operation.\");\n    }\n    return targets;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-3702. Add an option for NOT writing the blocks locally if there is a datanode on the same box as the client. (Contributed by Lei (Eddy) Xu)\n",
      "commitDate": "27/04/16 2:22 PM",
      "commitName": "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
      "commitAuthor": "Lei Xu",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-3702. Add an option for NOT writing the blocks locally if there is a datanode on the same box as the client. (Contributed by Lei (Eddy) Xu)\n",
          "commitDate": "27/04/16 2:22 PM",
          "commitName": "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "27/04/16 6:19 AM",
          "commitNameOld": "919a1d824a0a61145dc7ae59cfba3f34d91f2681",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,26 @@\n   public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n       final int numOfReplicas, final Node client,\n       final Set\u003cNode\u003e excludedNodes,\n       final long blocksize,\n       final List\u003cString\u003e favoredNodes,\n       final byte storagePolicyID,\n-      final boolean isStriped) throws IOException {\n+      final boolean isStriped,\n+      final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n     List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n         getDatanodeDescriptors(favoredNodes);\n     final BlockStoragePolicy storagePolicy \u003d storagePolicySuite.getPolicy(storagePolicyID);\n     final BlockPlacementPolicy blockplacement \u003d placementPolicies.getPolicy(isStriped);\n     final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n         numOfReplicas, client, excludedNodes, blocksize, \n-        favoredDatanodeDescriptors, storagePolicy);\n+        favoredDatanodeDescriptors, storagePolicy, flags);\n     if (targets.length \u003c minReplication) {\n       throw new IOException(\"File \" + src + \" could only be replicated to \"\n           + targets.length + \" nodes instead of minReplication (\u003d\"\n           + minReplication + \").  There are \"\n           + getDatanodeManager().getNetworkTopology().getNumOfLeaves()\n           + \" datanode(s) running and \"\n           + (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())\n           + \" node(s) are excluded in this operation.\");\n     }\n     return targets;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n      final int numOfReplicas, final Node client,\n      final Set\u003cNode\u003e excludedNodes,\n      final long blocksize,\n      final List\u003cString\u003e favoredNodes,\n      final byte storagePolicyID,\n      final boolean isStriped,\n      final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n    List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n        getDatanodeDescriptors(favoredNodes);\n    final BlockStoragePolicy storagePolicy \u003d storagePolicySuite.getPolicy(storagePolicyID);\n    final BlockPlacementPolicy blockplacement \u003d placementPolicies.getPolicy(isStriped);\n    final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n        numOfReplicas, client, excludedNodes, blocksize, \n        favoredDatanodeDescriptors, storagePolicy, flags);\n    if (targets.length \u003c minReplication) {\n      throw new IOException(\"File \" + src + \" could only be replicated to \"\n          + targets.length + \" nodes instead of minReplication (\u003d\"\n          + minReplication + \").  There are \"\n          + getDatanodeManager().getNetworkTopology().getNumOfLeaves()\n          + \" datanode(s) running and \"\n          + (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())\n          + \" node(s) are excluded in this operation.\");\n    }\n    return targets;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "[src-String(modifiers-final), numOfReplicas-int(modifiers-final), client-Node(modifiers-final), excludedNodes-Set\u003cNode\u003e(modifiers-final), blocksize-long(modifiers-final), favoredNodes-List\u003cString\u003e(modifiers-final), storagePolicyID-byte(modifiers-final), isStriped-boolean(modifiers-final)]",
            "newValue": "[src-String(modifiers-final), numOfReplicas-int(modifiers-final), client-Node(modifiers-final), excludedNodes-Set\u003cNode\u003e(modifiers-final), blocksize-long(modifiers-final), favoredNodes-List\u003cString\u003e(modifiers-final), storagePolicyID-byte(modifiers-final), isStriped-boolean(modifiers-final), flags-EnumSet\u003cAddBlockFlag\u003e(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3702. Add an option for NOT writing the blocks locally if there is a datanode on the same box as the client. (Contributed by Lei (Eddy) Xu)\n",
          "commitDate": "27/04/16 2:22 PM",
          "commitName": "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "27/04/16 6:19 AM",
          "commitNameOld": "919a1d824a0a61145dc7ae59cfba3f34d91f2681",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,26 @@\n   public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n       final int numOfReplicas, final Node client,\n       final Set\u003cNode\u003e excludedNodes,\n       final long blocksize,\n       final List\u003cString\u003e favoredNodes,\n       final byte storagePolicyID,\n-      final boolean isStriped) throws IOException {\n+      final boolean isStriped,\n+      final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n     List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n         getDatanodeDescriptors(favoredNodes);\n     final BlockStoragePolicy storagePolicy \u003d storagePolicySuite.getPolicy(storagePolicyID);\n     final BlockPlacementPolicy blockplacement \u003d placementPolicies.getPolicy(isStriped);\n     final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n         numOfReplicas, client, excludedNodes, blocksize, \n-        favoredDatanodeDescriptors, storagePolicy);\n+        favoredDatanodeDescriptors, storagePolicy, flags);\n     if (targets.length \u003c minReplication) {\n       throw new IOException(\"File \" + src + \" could only be replicated to \"\n           + targets.length + \" nodes instead of minReplication (\u003d\"\n           + minReplication + \").  There are \"\n           + getDatanodeManager().getNetworkTopology().getNumOfLeaves()\n           + \" datanode(s) running and \"\n           + (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())\n           + \" node(s) are excluded in this operation.\");\n     }\n     return targets;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DatanodeStorageInfo[] chooseTarget4NewBlock(final String src,\n      final int numOfReplicas, final Node client,\n      final Set\u003cNode\u003e excludedNodes,\n      final long blocksize,\n      final List\u003cString\u003e favoredNodes,\n      final byte storagePolicyID,\n      final boolean isStriped,\n      final EnumSet\u003cAddBlockFlag\u003e flags) throws IOException {\n    List\u003cDatanodeDescriptor\u003e favoredDatanodeDescriptors \u003d \n        getDatanodeDescriptors(favoredNodes);\n    final BlockStoragePolicy storagePolicy \u003d storagePolicySuite.getPolicy(storagePolicyID);\n    final BlockPlacementPolicy blockplacement \u003d placementPolicies.getPolicy(isStriped);\n    final DatanodeStorageInfo[] targets \u003d blockplacement.chooseTarget(src,\n        numOfReplicas, client, excludedNodes, blocksize, \n        favoredDatanodeDescriptors, storagePolicy, flags);\n    if (targets.length \u003c minReplication) {\n      throw new IOException(\"File \" + src + \" could only be replicated to \"\n          + targets.length + \" nodes instead of minReplication (\u003d\"\n          + minReplication + \").  There are \"\n          + getDatanodeManager().getNetworkTopology().getNumOfLeaves()\n          + \" datanode(s) running and \"\n          + (excludedNodes \u003d\u003d null? \"no\": excludedNodes.size())\n          + \" node(s) are excluded in this operation.\");\n    }\n    return targets;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}