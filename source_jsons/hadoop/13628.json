{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeAdminBackoffMonitor.java",
  "functionName": "processMaintenanceNodes",
  "functionId": "processMaintenanceNodes",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminBackoffMonitor.java",
  "functionStartLine": 310,
  "functionEndLine": 331,
  "numCommitsSeen": 1,
  "timeTaken": 822,
  "changeHistory": [
    "c93cb6790e0f1c64efd03d859f907a0522010894"
  ],
  "changeHistoryShort": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-14854. Create improved decommission monitor implementation. Contributed by Stephen O\u0027Donnell.\n\nReviewed-by: Inigo Goiri \u003cinigoiri@apache.org\u003e\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "10/12/19 5:16 PM",
      "commitName": "c93cb6790e0f1c64efd03d859f907a0522010894",
      "commitAuthor": "Stephen O\u0027Donnell",
      "diff": "@@ -0,0 +1,22 @@\n+  private void processMaintenanceNodes() {\n+    // Check for any maintenance state nodes which need to be expired\n+    namesystem.writeLock();\n+    try {\n+      for (DatanodeDescriptor dn : outOfServiceNodeBlocks.keySet()) {\n+        if (dn.isMaintenance() \u0026\u0026 dn.maintenanceExpired()) {\n+          // If maintenance expires, stop tracking it. This can be an\n+          // expensive call, as it may need to invalidate blocks. Therefore\n+          // we can yield and retake the write lock after each node\n+          //\n+          // The call to stopMaintenance makes a call to stopTrackingNode()\n+          // which added the node to the cancelled list. Therefore expired\n+          // maintenance nodes do not need to be added to the toRemove list.\n+          dnAdmin.stopMaintenance(dn);\n+          namesystem.writeUnlock();\n+          namesystem.writeLock();\n+        }\n+      }\n+    } finally {\n+      namesystem.writeUnlock();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void processMaintenanceNodes() {\n    // Check for any maintenance state nodes which need to be expired\n    namesystem.writeLock();\n    try {\n      for (DatanodeDescriptor dn : outOfServiceNodeBlocks.keySet()) {\n        if (dn.isMaintenance() \u0026\u0026 dn.maintenanceExpired()) {\n          // If maintenance expires, stop tracking it. This can be an\n          // expensive call, as it may need to invalidate blocks. Therefore\n          // we can yield and retake the write lock after each node\n          //\n          // The call to stopMaintenance makes a call to stopTrackingNode()\n          // which added the node to the cancelled list. Therefore expired\n          // maintenance nodes do not need to be added to the toRemove list.\n          dnAdmin.stopMaintenance(dn);\n          namesystem.writeUnlock();\n          namesystem.writeLock();\n        }\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminBackoffMonitor.java"
    }
  }
}