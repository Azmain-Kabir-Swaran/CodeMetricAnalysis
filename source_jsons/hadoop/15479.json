{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AtomicFileOutputStream.java",
  "functionName": "close",
  "functionId": "close",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/AtomicFileOutputStream.java",
  "functionStartLine": 64,
  "functionEndLine": 100,
  "numCommitsSeen": 6,
  "timeTaken": 2242,
  "changeHistory": [
    "9f9a2222a2e142a47537bc57ca98fb07a7a78ad4",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63"
  ],
  "changeHistoryShort": {
    "9f9a2222a2e142a47537bc57ca98fb07a7a78ad4": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9f9a2222a2e142a47537bc57ca98fb07a7a78ad4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7119. Split error checks in AtomicFileOutputStream#close into separate conditions to improve diagnostics. Contributed by Chris Nauroth.\n",
      "commitDate": "25/09/14 1:33 PM",
      "commitName": "9f9a2222a2e142a47537bc57ca98fb07a7a78ad4",
      "commitAuthor": "cnauroth",
      "commitDateOld": "02/07/12 4:59 PM",
      "commitNameOld": "8dd3148e734fa9d1db761ce65410fdc49c0fe1d5",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 814.86,
      "commitsBetweenForRepo": 5337,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,37 @@\n   public void close() throws IOException {\n     boolean triedToClose \u003d false, success \u003d false;\n     try {\n       flush();\n       ((FileOutputStream)out).getChannel().force(true);\n \n       triedToClose \u003d true;\n       super.close();\n       success \u003d true;\n     } finally {\n       if (success) {\n         boolean renamed \u003d tmpFile.renameTo(origFile);\n         if (!renamed) {\n           // On windows, renameTo does not replace.\n-          if (!origFile.delete() || !tmpFile.renameTo(origFile)) {\n-            throw new IOException(\"Could not rename temporary file \" +\n-                tmpFile + \" to \" + origFile);\n+          if (origFile.exists() \u0026\u0026 !origFile.delete()) {\n+            throw new IOException(\"Could not delete original file \" + origFile);\n+          }\n+          try {\n+            NativeIO.renameTo(tmpFile, origFile);\n+          } catch (NativeIOException e) {\n+            throw new IOException(\"Could not rename temporary file \" + tmpFile\n+              + \" to \" + origFile + \" due to failure in native rename. \"\n+              + e.toString());\n           }\n         }\n       } else {\n         if (!triedToClose) {\n           // If we failed when flushing, try to close it to not leak an FD\n           IOUtils.closeStream(out);\n         }\n         // close wasn\u0027t successful, try to delete the tmp file\n         if (!tmpFile.delete()) {\n           LOG.warn(\"Unable to delete tmp file \" + tmpFile);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void close() throws IOException {\n    boolean triedToClose \u003d false, success \u003d false;\n    try {\n      flush();\n      ((FileOutputStream)out).getChannel().force(true);\n\n      triedToClose \u003d true;\n      super.close();\n      success \u003d true;\n    } finally {\n      if (success) {\n        boolean renamed \u003d tmpFile.renameTo(origFile);\n        if (!renamed) {\n          // On windows, renameTo does not replace.\n          if (origFile.exists() \u0026\u0026 !origFile.delete()) {\n            throw new IOException(\"Could not delete original file \" + origFile);\n          }\n          try {\n            NativeIO.renameTo(tmpFile, origFile);\n          } catch (NativeIOException e) {\n            throw new IOException(\"Could not rename temporary file \" + tmpFile\n              + \" to \" + origFile + \" due to failure in native rename. \"\n              + e.toString());\n          }\n        }\n      } else {\n        if (!triedToClose) {\n          // If we failed when flushing, try to close it to not leak an FD\n          IOUtils.closeStream(out);\n        }\n        // close wasn\u0027t successful, try to delete the tmp file\n        if (!tmpFile.delete()) {\n          LOG.warn(\"Unable to delete tmp file \" + tmpFile);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/AtomicFileOutputStream.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void close() throws IOException {\n    boolean triedToClose \u003d false, success \u003d false;\n    try {\n      flush();\n      ((FileOutputStream)out).getChannel().force(true);\n\n      triedToClose \u003d true;\n      super.close();\n      success \u003d true;\n    } finally {\n      if (success) {\n        boolean renamed \u003d tmpFile.renameTo(origFile);\n        if (!renamed) {\n          // On windows, renameTo does not replace.\n          if (!origFile.delete() || !tmpFile.renameTo(origFile)) {\n            throw new IOException(\"Could not rename temporary file \" +\n                tmpFile + \" to \" + origFile);\n          }\n        }\n      } else {\n        if (!triedToClose) {\n          // If we failed when flushing, try to close it to not leak an FD\n          IOUtils.closeStream(out);\n        }\n        // close wasn\u0027t successful, try to delete the tmp file\n        if (!tmpFile.delete()) {\n          LOG.warn(\"Unable to delete tmp file \" + tmpFile);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/AtomicFileOutputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/AtomicFileOutputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/AtomicFileOutputStream.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void close() throws IOException {\n    boolean triedToClose \u003d false, success \u003d false;\n    try {\n      flush();\n      ((FileOutputStream)out).getChannel().force(true);\n\n      triedToClose \u003d true;\n      super.close();\n      success \u003d true;\n    } finally {\n      if (success) {\n        boolean renamed \u003d tmpFile.renameTo(origFile);\n        if (!renamed) {\n          // On windows, renameTo does not replace.\n          if (!origFile.delete() || !tmpFile.renameTo(origFile)) {\n            throw new IOException(\"Could not rename temporary file \" +\n                tmpFile + \" to \" + origFile);\n          }\n        }\n      } else {\n        if (!triedToClose) {\n          // If we failed when flushing, try to close it to not leak an FD\n          IOUtils.closeStream(out);\n        }\n        // close wasn\u0027t successful, try to delete the tmp file\n        if (!tmpFile.delete()) {\n          LOG.warn(\"Unable to delete tmp file \" + tmpFile);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/AtomicFileOutputStream.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/util/AtomicFileOutputStream.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/AtomicFileOutputStream.java"
      }
    },
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/11 9:28 AM",
      "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,31 @@\n+  public void close() throws IOException {\n+    boolean triedToClose \u003d false, success \u003d false;\n+    try {\n+      flush();\n+      ((FileOutputStream)out).getChannel().force(true);\n+\n+      triedToClose \u003d true;\n+      super.close();\n+      success \u003d true;\n+    } finally {\n+      if (success) {\n+        boolean renamed \u003d tmpFile.renameTo(origFile);\n+        if (!renamed) {\n+          // On windows, renameTo does not replace.\n+          if (!origFile.delete() || !tmpFile.renameTo(origFile)) {\n+            throw new IOException(\"Could not rename temporary file \" +\n+                tmpFile + \" to \" + origFile);\n+          }\n+        }\n+      } else {\n+        if (!triedToClose) {\n+          // If we failed when flushing, try to close it to not leak an FD\n+          IOUtils.closeStream(out);\n+        }\n+        // close wasn\u0027t successful, try to delete the tmp file\n+        if (!tmpFile.delete()) {\n+          LOG.warn(\"Unable to delete tmp file \" + tmpFile);\n+        }\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void close() throws IOException {\n    boolean triedToClose \u003d false, success \u003d false;\n    try {\n      flush();\n      ((FileOutputStream)out).getChannel().force(true);\n\n      triedToClose \u003d true;\n      super.close();\n      success \u003d true;\n    } finally {\n      if (success) {\n        boolean renamed \u003d tmpFile.renameTo(origFile);\n        if (!renamed) {\n          // On windows, renameTo does not replace.\n          if (!origFile.delete() || !tmpFile.renameTo(origFile)) {\n            throw new IOException(\"Could not rename temporary file \" +\n                tmpFile + \" to \" + origFile);\n          }\n        }\n      } else {\n        if (!triedToClose) {\n          // If we failed when flushing, try to close it to not leak an FD\n          IOUtils.closeStream(out);\n        }\n        // close wasn\u0027t successful, try to delete the tmp file\n        if (!tmpFile.delete()) {\n          LOG.warn(\"Unable to delete tmp file \" + tmpFile);\n        }\n      }\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/util/AtomicFileOutputStream.java"
    }
  }
}