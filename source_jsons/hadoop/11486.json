{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FsVolumeList.java",
  "functionName": "addVolume",
  "functionId": "addVolume___ref-FsVolumeReference",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java",
  "functionStartLine": 291,
  "functionEndLine": 306,
  "numCommitsSeen": 63,
  "timeTaken": 4596,
  "changeHistory": [
    "96b12662ea76e3ded4ef13944fc8df206cfb4613",
    "86c9862bec0248d671e657aa56094a2919b8ac14",
    "533a2be5ac7c7f0473fdd24d6201582d08964e21",
    "24d3a2d4fdd836ac9a5bc755a7fb9354f7a582b1",
    "ef591b1d6a08f08358b19763a874de6010227307",
    "b49c3a1813aa8c5b05fe6c02a653286c573137ca",
    "6e62a1a6728b1f782f64065424f92b292c3f163a",
    "b7f4a3156c0f5c600816c469637237ba6c9b330c",
    "3b173d95171d01ab55042b1162569d1cf14a8d43",
    "d758be1f35f6c1c7e9edd491af559721a3b8b8f8"
  ],
  "changeHistoryShort": {
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": "Ybodychange",
    "86c9862bec0248d671e657aa56094a2919b8ac14": "Ybodychange",
    "533a2be5ac7c7f0473fdd24d6201582d08964e21": "Ybodychange",
    "24d3a2d4fdd836ac9a5bc755a7fb9354f7a582b1": "Ybodychange",
    "ef591b1d6a08f08358b19763a874de6010227307": "Ybodychange",
    "b49c3a1813aa8c5b05fe6c02a653286c573137ca": "Ybodychange",
    "6e62a1a6728b1f782f64065424f92b292c3f163a": "Ymultichange(Yparameterchange,Ybodychange)",
    "b7f4a3156c0f5c600816c469637237ba6c9b330c": "Ybodychange",
    "3b173d95171d01ab55042b1162569d1cf14a8d43": "Ymultichange(Ymodifierchange,Ybodychange)",
    "d758be1f35f6c1c7e9edd491af559721a3b8b8f8": "Yintroduced"
  },
  "changeHistoryDetails": {
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10637. Modifications to remove the assumption that FsVolumes are backed by java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "10/10/16 3:30 PM",
      "commitName": "96b12662ea76e3ded4ef13944fc8df206cfb4613",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "16/09/16 12:08 AM",
      "commitNameOld": "b09a03cd7d26cf96ec26a81ba11f00778241eb3e",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 24.64,
      "commitsBetweenForRepo": 171,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n   void addVolume(FsVolumeReference ref) {\n     FsVolumeImpl volume \u003d (FsVolumeImpl) ref.getVolume();\n     volumes.add(volume);\n     if (blockScanner !\u003d null) {\n       blockScanner.addVolumeScanner(ref);\n     } else {\n       // If the volume is not put into a volume scanner, it does not need to\n       // hold the reference.\n       IOUtils.cleanup(null, ref);\n     }\n     // If the volume is used to replace a failed volume, it needs to reset the\n     // volume failure info for this volume.\n-    removeVolumeFailureInfo(new File(volume.getBasePath()));\n+    removeVolumeFailureInfo(volume.getStorageLocation());\n     FsDatasetImpl.LOG.info(\"Added new volume: \" +\n         volume.getStorageID());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addVolume(FsVolumeReference ref) {\n    FsVolumeImpl volume \u003d (FsVolumeImpl) ref.getVolume();\n    volumes.add(volume);\n    if (blockScanner !\u003d null) {\n      blockScanner.addVolumeScanner(ref);\n    } else {\n      // If the volume is not put into a volume scanner, it does not need to\n      // hold the reference.\n      IOUtils.cleanup(null, ref);\n    }\n    // If the volume is used to replace a failed volume, it needs to reset the\n    // volume failure info for this volume.\n    removeVolumeFailureInfo(volume.getStorageLocation());\n    FsDatasetImpl.LOG.info(\"Added new volume: \" +\n        volume.getStorageID());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java",
      "extendedDetails": {}
    },
    "86c9862bec0248d671e657aa56094a2919b8ac14": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "13/09/16 12:54 PM",
      "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "10/09/16 6:22 PM",
      "commitNameOld": "a99bf26a0899bcc4307c3a242c8414eaef555aa7",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 2.77,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n   void addVolume(FsVolumeReference ref) {\n     FsVolumeImpl volume \u003d (FsVolumeImpl) ref.getVolume();\n     volumes.add(volume);\n     if (blockScanner !\u003d null) {\n       blockScanner.addVolumeScanner(ref);\n     } else {\n       // If the volume is not put into a volume scanner, it does not need to\n       // hold the reference.\n-      IOUtils.cleanup(FsDatasetImpl.LOG, ref);\n+      IOUtils.cleanup(null, ref);\n     }\n     // If the volume is used to replace a failed volume, it needs to reset the\n     // volume failure info for this volume.\n     removeVolumeFailureInfo(new File(volume.getBasePath()));\n     FsDatasetImpl.LOG.info(\"Added new volume: \" +\n         volume.getStorageID());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addVolume(FsVolumeReference ref) {\n    FsVolumeImpl volume \u003d (FsVolumeImpl) ref.getVolume();\n    volumes.add(volume);\n    if (blockScanner !\u003d null) {\n      blockScanner.addVolumeScanner(ref);\n    } else {\n      // If the volume is not put into a volume scanner, it does not need to\n      // hold the reference.\n      IOUtils.cleanup(null, ref);\n    }\n    // If the volume is used to replace a failed volume, it needs to reset the\n    // volume failure info for this volume.\n    removeVolumeFailureInfo(new File(volume.getBasePath()));\n    FsDatasetImpl.LOG.info(\"Added new volume: \" +\n        volume.getStorageID());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java",
      "extendedDetails": {}
    },
    "533a2be5ac7c7f0473fdd24d6201582d08964e21": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9264. Minor cleanup of operations on FsVolumeList#volumes.  (Walter Su via lei)\n",
      "commitDate": "23/10/15 1:52 PM",
      "commitName": "533a2be5ac7c7f0473fdd24d6201582d08964e21",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "05/05/15 11:08 AM",
      "commitNameOld": "24d3a2d4fdd836ac9a5bc755a7fb9354f7a582b1",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 171.11,
      "commitsBetweenForRepo": 1435,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,16 @@\n   void addVolume(FsVolumeReference ref) {\n     FsVolumeImpl volume \u003d (FsVolumeImpl) ref.getVolume();\n-    while (true) {\n-      final FsVolumeImpl[] curVolumes \u003d volumes.get();\n-      final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n-      volumeList.add(volume);\n-      if (volumes.compareAndSet(curVolumes,\n-          volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n-        break;\n-      } else {\n-        if (FsDatasetImpl.LOG.isDebugEnabled()) {\n-          FsDatasetImpl.LOG.debug(\n-              \"The volume list has been changed concurrently, \" +\n-                  \"retry to remove volume: \" + ref.getVolume().getStorageID());\n-        }\n-      }\n-    }\n+    volumes.add(volume);\n     if (blockScanner !\u003d null) {\n       blockScanner.addVolumeScanner(ref);\n     } else {\n       // If the volume is not put into a volume scanner, it does not need to\n       // hold the reference.\n       IOUtils.cleanup(FsDatasetImpl.LOG, ref);\n     }\n     // If the volume is used to replace a failed volume, it needs to reset the\n     // volume failure info for this volume.\n     removeVolumeFailureInfo(new File(volume.getBasePath()));\n     FsDatasetImpl.LOG.info(\"Added new volume: \" +\n         volume.getStorageID());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addVolume(FsVolumeReference ref) {\n    FsVolumeImpl volume \u003d (FsVolumeImpl) ref.getVolume();\n    volumes.add(volume);\n    if (blockScanner !\u003d null) {\n      blockScanner.addVolumeScanner(ref);\n    } else {\n      // If the volume is not put into a volume scanner, it does not need to\n      // hold the reference.\n      IOUtils.cleanup(FsDatasetImpl.LOG, ref);\n    }\n    // If the volume is used to replace a failed volume, it needs to reset the\n    // volume failure info for this volume.\n    removeVolumeFailureInfo(new File(volume.getBasePath()));\n    FsDatasetImpl.LOG.info(\"Added new volume: \" +\n        volume.getStorageID());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java",
      "extendedDetails": {}
    },
    "24d3a2d4fdd836ac9a5bc755a7fb9354f7a582b1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7758. Retire FsDatasetSpi#getVolumes() and use FsDatasetSpi#getVolumeRefs() instead (Lei (Eddy) Xu via Colin P. McCabe)\n",
      "commitDate": "05/05/15 11:08 AM",
      "commitName": "24d3a2d4fdd836ac9a5bc755a7fb9354f7a582b1",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "03/04/15 4:34 PM",
      "commitNameOld": "ef591b1d6a08f08358b19763a874de6010227307",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 31.77,
      "commitsBetweenForRepo": 264,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,30 @@\n   void addVolume(FsVolumeReference ref) {\n+    FsVolumeImpl volume \u003d (FsVolumeImpl) ref.getVolume();\n     while (true) {\n       final FsVolumeImpl[] curVolumes \u003d volumes.get();\n       final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n-      volumeList.add((FsVolumeImpl)ref.getVolume());\n+      volumeList.add(volume);\n       if (volumes.compareAndSet(curVolumes,\n           volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n         break;\n       } else {\n         if (FsDatasetImpl.LOG.isDebugEnabled()) {\n           FsDatasetImpl.LOG.debug(\n               \"The volume list has been changed concurrently, \" +\n                   \"retry to remove volume: \" + ref.getVolume().getStorageID());\n         }\n       }\n     }\n     if (blockScanner !\u003d null) {\n       blockScanner.addVolumeScanner(ref);\n     } else {\n       // If the volume is not put into a volume scanner, it does not need to\n       // hold the reference.\n       IOUtils.cleanup(FsDatasetImpl.LOG, ref);\n     }\n     // If the volume is used to replace a failed volume, it needs to reset the\n     // volume failure info for this volume.\n-    removeVolumeFailureInfo(new File(ref.getVolume().getBasePath()));\n+    removeVolumeFailureInfo(new File(volume.getBasePath()));\n     FsDatasetImpl.LOG.info(\"Added new volume: \" +\n-        ref.getVolume().getStorageID());\n+        volume.getStorageID());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addVolume(FsVolumeReference ref) {\n    FsVolumeImpl volume \u003d (FsVolumeImpl) ref.getVolume();\n    while (true) {\n      final FsVolumeImpl[] curVolumes \u003d volumes.get();\n      final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n      volumeList.add(volume);\n      if (volumes.compareAndSet(curVolumes,\n          volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n        break;\n      } else {\n        if (FsDatasetImpl.LOG.isDebugEnabled()) {\n          FsDatasetImpl.LOG.debug(\n              \"The volume list has been changed concurrently, \" +\n                  \"retry to remove volume: \" + ref.getVolume().getStorageID());\n        }\n      }\n    }\n    if (blockScanner !\u003d null) {\n      blockScanner.addVolumeScanner(ref);\n    } else {\n      // If the volume is not put into a volume scanner, it does not need to\n      // hold the reference.\n      IOUtils.cleanup(FsDatasetImpl.LOG, ref);\n    }\n    // If the volume is used to replace a failed volume, it needs to reset the\n    // volume failure info for this volume.\n    removeVolumeFailureInfo(new File(volume.getBasePath()));\n    FsDatasetImpl.LOG.info(\"Added new volume: \" +\n        volume.getStorageID());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java",
      "extendedDetails": {}
    },
    "ef591b1d6a08f08358b19763a874de6010227307": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8051. FsVolumeList#addVolume should release volume reference if not put it into BlockScanner. (Lei (Eddy) Xu via Colin P. McCabe)\n",
      "commitDate": "03/04/15 4:34 PM",
      "commitName": "ef591b1d6a08f08358b19763a874de6010227307",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "25/03/15 12:42 PM",
      "commitNameOld": "fc1031af749435dc95efea6745b1b2300ce29446",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 9.16,
      "commitsBetweenForRepo": 82,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,29 @@\n   void addVolume(FsVolumeReference ref) {\n     while (true) {\n       final FsVolumeImpl[] curVolumes \u003d volumes.get();\n       final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n       volumeList.add((FsVolumeImpl)ref.getVolume());\n       if (volumes.compareAndSet(curVolumes,\n           volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n         break;\n       } else {\n         if (FsDatasetImpl.LOG.isDebugEnabled()) {\n           FsDatasetImpl.LOG.debug(\n               \"The volume list has been changed concurrently, \" +\n                   \"retry to remove volume: \" + ref.getVolume().getStorageID());\n         }\n       }\n     }\n     if (blockScanner !\u003d null) {\n       blockScanner.addVolumeScanner(ref);\n+    } else {\n+      // If the volume is not put into a volume scanner, it does not need to\n+      // hold the reference.\n+      IOUtils.cleanup(FsDatasetImpl.LOG, ref);\n     }\n     // If the volume is used to replace a failed volume, it needs to reset the\n     // volume failure info for this volume.\n     removeVolumeFailureInfo(new File(ref.getVolume().getBasePath()));\n     FsDatasetImpl.LOG.info(\"Added new volume: \" +\n         ref.getVolume().getStorageID());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addVolume(FsVolumeReference ref) {\n    while (true) {\n      final FsVolumeImpl[] curVolumes \u003d volumes.get();\n      final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n      volumeList.add((FsVolumeImpl)ref.getVolume());\n      if (volumes.compareAndSet(curVolumes,\n          volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n        break;\n      } else {\n        if (FsDatasetImpl.LOG.isDebugEnabled()) {\n          FsDatasetImpl.LOG.debug(\n              \"The volume list has been changed concurrently, \" +\n                  \"retry to remove volume: \" + ref.getVolume().getStorageID());\n        }\n      }\n    }\n    if (blockScanner !\u003d null) {\n      blockScanner.addVolumeScanner(ref);\n    } else {\n      // If the volume is not put into a volume scanner, it does not need to\n      // hold the reference.\n      IOUtils.cleanup(FsDatasetImpl.LOG, ref);\n    }\n    // If the volume is used to replace a failed volume, it needs to reset the\n    // volume failure info for this volume.\n    removeVolumeFailureInfo(new File(ref.getVolume().getBasePath()));\n    FsDatasetImpl.LOG.info(\"Added new volume: \" +\n        ref.getVolume().getStorageID());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java",
      "extendedDetails": {}
    },
    "b49c3a1813aa8c5b05fe6c02a653286c573137ca": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7722. DataNode#checkDiskError should also remove Storage when error is found. (Lei Xu via Colin P. McCabe)\n",
      "commitDate": "12/03/15 12:00 PM",
      "commitName": "b49c3a1813aa8c5b05fe6c02a653286c573137ca",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "21/02/15 3:38 PM",
      "commitNameOld": "8b465b4b8caed31ca9daeaae108f9a868a30a455",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 18.81,
      "commitsBetweenForRepo": 143,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,25 @@\n   void addVolume(FsVolumeReference ref) {\n     while (true) {\n       final FsVolumeImpl[] curVolumes \u003d volumes.get();\n       final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n       volumeList.add((FsVolumeImpl)ref.getVolume());\n       if (volumes.compareAndSet(curVolumes,\n           volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n         break;\n       } else {\n         if (FsDatasetImpl.LOG.isDebugEnabled()) {\n           FsDatasetImpl.LOG.debug(\n               \"The volume list has been changed concurrently, \" +\n                   \"retry to remove volume: \" + ref.getVolume().getStorageID());\n         }\n       }\n     }\n     if (blockScanner !\u003d null) {\n       blockScanner.addVolumeScanner(ref);\n     }\n+    // If the volume is used to replace a failed volume, it needs to reset the\n+    // volume failure info for this volume.\n+    removeVolumeFailureInfo(new File(ref.getVolume().getBasePath()));\n     FsDatasetImpl.LOG.info(\"Added new volume: \" +\n         ref.getVolume().getStorageID());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addVolume(FsVolumeReference ref) {\n    while (true) {\n      final FsVolumeImpl[] curVolumes \u003d volumes.get();\n      final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n      volumeList.add((FsVolumeImpl)ref.getVolume());\n      if (volumes.compareAndSet(curVolumes,\n          volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n        break;\n      } else {\n        if (FsDatasetImpl.LOG.isDebugEnabled()) {\n          FsDatasetImpl.LOG.debug(\n              \"The volume list has been changed concurrently, \" +\n                  \"retry to remove volume: \" + ref.getVolume().getStorageID());\n        }\n      }\n    }\n    if (blockScanner !\u003d null) {\n      blockScanner.addVolumeScanner(ref);\n    }\n    // If the volume is used to replace a failed volume, it needs to reset the\n    // volume failure info for this volume.\n    removeVolumeFailureInfo(new File(ref.getVolume().getBasePath()));\n    FsDatasetImpl.LOG.info(\"Added new volume: \" +\n        ref.getVolume().getStorageID());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java",
      "extendedDetails": {}
    },
    "6e62a1a6728b1f782f64065424f92b292c3f163a": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7430. Refactor the BlockScanner to use O(1) memory and use multiple threads (cmccabe)\n",
      "commitDate": "21/01/15 7:00 PM",
      "commitName": "6e62a1a6728b1f782f64065424f92b292c3f163a",
      "commitAuthor": "Colin Patrick Mccabe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7430. Refactor the BlockScanner to use O(1) memory and use multiple threads (cmccabe)\n",
          "commitDate": "21/01/15 7:00 PM",
          "commitName": "6e62a1a6728b1f782f64065424f92b292c3f163a",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "20/01/15 8:11 PM",
          "commitNameOld": "a17584936cc5141e3f5612ac3ecf35e27968e439",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 0.95,
          "commitsBetweenForRepo": 14,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,22 @@\n-  void addVolume(FsVolumeImpl newVolume) {\n+  void addVolume(FsVolumeReference ref) {\n     while (true) {\n       final FsVolumeImpl[] curVolumes \u003d volumes.get();\n       final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n-      volumeList.add(newVolume);\n+      volumeList.add((FsVolumeImpl)ref.getVolume());\n       if (volumes.compareAndSet(curVolumes,\n           volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n         break;\n       } else {\n         if (FsDatasetImpl.LOG.isDebugEnabled()) {\n           FsDatasetImpl.LOG.debug(\n               \"The volume list has been changed concurrently, \" +\n-                  \"retry to remove volume: \" + newVolume);\n+                  \"retry to remove volume: \" + ref.getVolume().getStorageID());\n         }\n       }\n     }\n-\n-    FsDatasetImpl.LOG.info(\"Added new volume: \" + newVolume.toString());\n+    if (blockScanner !\u003d null) {\n+      blockScanner.addVolumeScanner(ref);\n+    }\n+    FsDatasetImpl.LOG.info(\"Added new volume: \" +\n+        ref.getVolume().getStorageID());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void addVolume(FsVolumeReference ref) {\n    while (true) {\n      final FsVolumeImpl[] curVolumes \u003d volumes.get();\n      final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n      volumeList.add((FsVolumeImpl)ref.getVolume());\n      if (volumes.compareAndSet(curVolumes,\n          volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n        break;\n      } else {\n        if (FsDatasetImpl.LOG.isDebugEnabled()) {\n          FsDatasetImpl.LOG.debug(\n              \"The volume list has been changed concurrently, \" +\n                  \"retry to remove volume: \" + ref.getVolume().getStorageID());\n        }\n      }\n    }\n    if (blockScanner !\u003d null) {\n      blockScanner.addVolumeScanner(ref);\n    }\n    FsDatasetImpl.LOG.info(\"Added new volume: \" +\n        ref.getVolume().getStorageID());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java",
          "extendedDetails": {
            "oldValue": "[newVolume-FsVolumeImpl]",
            "newValue": "[ref-FsVolumeReference]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7430. Refactor the BlockScanner to use O(1) memory and use multiple threads (cmccabe)\n",
          "commitDate": "21/01/15 7:00 PM",
          "commitName": "6e62a1a6728b1f782f64065424f92b292c3f163a",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "20/01/15 8:11 PM",
          "commitNameOld": "a17584936cc5141e3f5612ac3ecf35e27968e439",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 0.95,
          "commitsBetweenForRepo": 14,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,22 @@\n-  void addVolume(FsVolumeImpl newVolume) {\n+  void addVolume(FsVolumeReference ref) {\n     while (true) {\n       final FsVolumeImpl[] curVolumes \u003d volumes.get();\n       final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n-      volumeList.add(newVolume);\n+      volumeList.add((FsVolumeImpl)ref.getVolume());\n       if (volumes.compareAndSet(curVolumes,\n           volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n         break;\n       } else {\n         if (FsDatasetImpl.LOG.isDebugEnabled()) {\n           FsDatasetImpl.LOG.debug(\n               \"The volume list has been changed concurrently, \" +\n-                  \"retry to remove volume: \" + newVolume);\n+                  \"retry to remove volume: \" + ref.getVolume().getStorageID());\n         }\n       }\n     }\n-\n-    FsDatasetImpl.LOG.info(\"Added new volume: \" + newVolume.toString());\n+    if (blockScanner !\u003d null) {\n+      blockScanner.addVolumeScanner(ref);\n+    }\n+    FsDatasetImpl.LOG.info(\"Added new volume: \" +\n+        ref.getVolume().getStorageID());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void addVolume(FsVolumeReference ref) {\n    while (true) {\n      final FsVolumeImpl[] curVolumes \u003d volumes.get();\n      final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n      volumeList.add((FsVolumeImpl)ref.getVolume());\n      if (volumes.compareAndSet(curVolumes,\n          volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n        break;\n      } else {\n        if (FsDatasetImpl.LOG.isDebugEnabled()) {\n          FsDatasetImpl.LOG.debug(\n              \"The volume list has been changed concurrently, \" +\n                  \"retry to remove volume: \" + ref.getVolume().getStorageID());\n        }\n      }\n    }\n    if (blockScanner !\u003d null) {\n      blockScanner.addVolumeScanner(ref);\n    }\n    FsDatasetImpl.LOG.info(\"Added new volume: \" +\n        ref.getVolume().getStorageID());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java",
          "extendedDetails": {}
        }
      ]
    },
    "b7f4a3156c0f5c600816c469637237ba6c9b330c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7496. Fix FsVolume removal race conditions on the DataNode by reference-counting the volume instances (lei via cmccabe)\n",
      "commitDate": "20/01/15 7:05 PM",
      "commitName": "b7f4a3156c0f5c600816c469637237ba6c9b330c",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "19/12/14 11:13 AM",
      "commitNameOld": "a4876c130f1627e59ef055e586640d1933fc49af",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 32.33,
      "commitsBetweenForRepo": 151,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,19 @@\n   void addVolume(FsVolumeImpl newVolume) {\n-    // Make a copy of volumes to add new volumes.\n     while (true) {\n       final FsVolumeImpl[] curVolumes \u003d volumes.get();\n       final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n       volumeList.add(newVolume);\n       if (volumes.compareAndSet(curVolumes,\n           volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n         break;\n       } else {\n         if (FsDatasetImpl.LOG.isDebugEnabled()) {\n           FsDatasetImpl.LOG.debug(\n               \"The volume list has been changed concurrently, \" +\n                   \"retry to remove volume: \" + newVolume);\n         }\n       }\n     }\n \n     FsDatasetImpl.LOG.info(\"Added new volume: \" + newVolume.toString());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void addVolume(FsVolumeImpl newVolume) {\n    while (true) {\n      final FsVolumeImpl[] curVolumes \u003d volumes.get();\n      final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n      volumeList.add(newVolume);\n      if (volumes.compareAndSet(curVolumes,\n          volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n        break;\n      } else {\n        if (FsDatasetImpl.LOG.isDebugEnabled()) {\n          FsDatasetImpl.LOG.debug(\n              \"The volume list has been changed concurrently, \" +\n                  \"retry to remove volume: \" + newVolume);\n        }\n      }\n    }\n\n    FsDatasetImpl.LOG.info(\"Added new volume: \" + newVolume.toString());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java",
      "extendedDetails": {}
    },
    "3b173d95171d01ab55042b1162569d1cf14a8d43": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-7531. Improve the concurrent access on FsVolumeList (Lei Xu via Colin P. McCabe)\n",
      "commitDate": "17/12/14 4:41 PM",
      "commitName": "3b173d95171d01ab55042b1162569d1cf14a8d43",
      "commitAuthor": "Colin Patrick Mccabe",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-7531. Improve the concurrent access on FsVolumeList (Lei Xu via Colin P. McCabe)\n",
          "commitDate": "17/12/14 4:41 PM",
          "commitName": "3b173d95171d01ab55042b1162569d1cf14a8d43",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "09/12/14 10:56 AM",
          "commitNameOld": "d8352b9b2b99aa46679c5880a724ba3f0ceb41ff",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 8.24,
          "commitsBetweenForRepo": 70,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,20 @@\n-  synchronized void addVolume(FsVolumeImpl newVolume) {\n+  void addVolume(FsVolumeImpl newVolume) {\n     // Make a copy of volumes to add new volumes.\n-    final List\u003cFsVolumeImpl\u003e volumeList \u003d volumes \u003d\u003d null ?\n-        new ArrayList\u003cFsVolumeImpl\u003e() :\n-        new ArrayList\u003cFsVolumeImpl\u003e(volumes);\n-    volumeList.add(newVolume);\n-    volumes \u003d Collections.unmodifiableList(volumeList);\n+    while (true) {\n+      final FsVolumeImpl[] curVolumes \u003d volumes.get();\n+      final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n+      volumeList.add(newVolume);\n+      if (volumes.compareAndSet(curVolumes,\n+          volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n+        break;\n+      } else {\n+        if (FsDatasetImpl.LOG.isDebugEnabled()) {\n+          FsDatasetImpl.LOG.debug(\n+              \"The volume list has been changed concurrently, \" +\n+                  \"retry to remove volume: \" + newVolume);\n+        }\n+      }\n+    }\n+\n     FsDatasetImpl.LOG.info(\"Added new volume: \" + newVolume.toString());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void addVolume(FsVolumeImpl newVolume) {\n    // Make a copy of volumes to add new volumes.\n    while (true) {\n      final FsVolumeImpl[] curVolumes \u003d volumes.get();\n      final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n      volumeList.add(newVolume);\n      if (volumes.compareAndSet(curVolumes,\n          volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n        break;\n      } else {\n        if (FsDatasetImpl.LOG.isDebugEnabled()) {\n          FsDatasetImpl.LOG.debug(\n              \"The volume list has been changed concurrently, \" +\n                  \"retry to remove volume: \" + newVolume);\n        }\n      }\n    }\n\n    FsDatasetImpl.LOG.info(\"Added new volume: \" + newVolume.toString());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java",
          "extendedDetails": {
            "oldValue": "[synchronized]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7531. Improve the concurrent access on FsVolumeList (Lei Xu via Colin P. McCabe)\n",
          "commitDate": "17/12/14 4:41 PM",
          "commitName": "3b173d95171d01ab55042b1162569d1cf14a8d43",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "09/12/14 10:56 AM",
          "commitNameOld": "d8352b9b2b99aa46679c5880a724ba3f0ceb41ff",
          "commitAuthorOld": "Colin Patrick Mccabe",
          "daysBetweenCommits": 8.24,
          "commitsBetweenForRepo": 70,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,20 @@\n-  synchronized void addVolume(FsVolumeImpl newVolume) {\n+  void addVolume(FsVolumeImpl newVolume) {\n     // Make a copy of volumes to add new volumes.\n-    final List\u003cFsVolumeImpl\u003e volumeList \u003d volumes \u003d\u003d null ?\n-        new ArrayList\u003cFsVolumeImpl\u003e() :\n-        new ArrayList\u003cFsVolumeImpl\u003e(volumes);\n-    volumeList.add(newVolume);\n-    volumes \u003d Collections.unmodifiableList(volumeList);\n+    while (true) {\n+      final FsVolumeImpl[] curVolumes \u003d volumes.get();\n+      final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n+      volumeList.add(newVolume);\n+      if (volumes.compareAndSet(curVolumes,\n+          volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n+        break;\n+      } else {\n+        if (FsDatasetImpl.LOG.isDebugEnabled()) {\n+          FsDatasetImpl.LOG.debug(\n+              \"The volume list has been changed concurrently, \" +\n+                  \"retry to remove volume: \" + newVolume);\n+        }\n+      }\n+    }\n+\n     FsDatasetImpl.LOG.info(\"Added new volume: \" + newVolume.toString());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void addVolume(FsVolumeImpl newVolume) {\n    // Make a copy of volumes to add new volumes.\n    while (true) {\n      final FsVolumeImpl[] curVolumes \u003d volumes.get();\n      final List\u003cFsVolumeImpl\u003e volumeList \u003d Lists.newArrayList(curVolumes);\n      volumeList.add(newVolume);\n      if (volumes.compareAndSet(curVolumes,\n          volumeList.toArray(new FsVolumeImpl[volumeList.size()]))) {\n        break;\n      } else {\n        if (FsDatasetImpl.LOG.isDebugEnabled()) {\n          FsDatasetImpl.LOG.debug(\n              \"The volume list has been changed concurrently, \" +\n                  \"retry to remove volume: \" + newVolume);\n        }\n      }\n    }\n\n    FsDatasetImpl.LOG.info(\"Added new volume: \" + newVolume.toString());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java",
          "extendedDetails": {}
        }
      ]
    },
    "d758be1f35f6c1c7e9edd491af559721a3b8b8f8": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6740. Make FSDataset support adding data volumes dynamically. Contributed by Lei Xu.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616623 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/14 3:59 PM",
      "commitName": "d758be1f35f6c1c7e9edd491af559721a3b8b8f8",
      "commitAuthor": "Aaron Myers",
      "diff": "@@ -0,0 +1,9 @@\n+  synchronized void addVolume(FsVolumeImpl newVolume) {\n+    // Make a copy of volumes to add new volumes.\n+    final List\u003cFsVolumeImpl\u003e volumeList \u003d volumes \u003d\u003d null ?\n+        new ArrayList\u003cFsVolumeImpl\u003e() :\n+        new ArrayList\u003cFsVolumeImpl\u003e(volumes);\n+    volumeList.add(newVolume);\n+    volumes \u003d Collections.unmodifiableList(volumeList);\n+    FsDatasetImpl.LOG.info(\"Added new volume: \" + newVolume.toString());\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void addVolume(FsVolumeImpl newVolume) {\n    // Make a copy of volumes to add new volumes.\n    final List\u003cFsVolumeImpl\u003e volumeList \u003d volumes \u003d\u003d null ?\n        new ArrayList\u003cFsVolumeImpl\u003e() :\n        new ArrayList\u003cFsVolumeImpl\u003e(volumes);\n    volumeList.add(newVolume);\n    volumes \u003d Collections.unmodifiableList(volumeList);\n    FsDatasetImpl.LOG.info(\"Added new volume: \" + newVolume.toString());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java"
    }
  }
}