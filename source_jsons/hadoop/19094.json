{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "TaskLog.java",
  "functionName": "getLogFileDetail",
  "functionId": "getLogFileDetail___taskid-TaskAttemptID__filter-LogName__isCleanup-boolean",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/TaskLog.java",
  "functionStartLine": 110,
  "functionEndLine": 161,
  "numCommitsSeen": 18,
  "timeTaken": 5100,
  "changeHistory": [
    "178751ed8c9d47038acf8616c226f1f52e884feb",
    "905b17876c44634545a68300ff2f2d73fb86d3b7",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "7e18c90d396e51b2dbf9f647822dc233c73518fc",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "178751ed8c9d47038acf8616c226f1f52e884feb": "Ybodychange",
    "905b17876c44634545a68300ff2f2d73fb86d3b7": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "7e18c90d396e51b2dbf9f647822dc233c73518fc": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "178751ed8c9d47038acf8616c226f1f52e884feb": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6983. Moving logging APIs over to slf4j in hadoop-mapreduce-client-core. Contributed by Jinjiang Ling.\n",
      "commitDate": "02/11/17 1:43 AM",
      "commitName": "178751ed8c9d47038acf8616c226f1f52e884feb",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "29/05/17 10:48 PM",
      "commitNameOld": "d4015f8628dd973c7433639451a9acc3e741d2a2",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 156.12,
      "commitsBetweenForRepo": 1119,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,52 +1,52 @@\n   private static LogFileDetail getLogFileDetail(TaskAttemptID taskid, \n                                                 LogName filter,\n                                                 boolean isCleanup) \n   throws IOException {\n     File indexFile \u003d getIndexFile(taskid, isCleanup);\n     BufferedReader fis \u003d new BufferedReader(new InputStreamReader(\n       SecureIOUtils.openForRead(indexFile, obtainLogDirOwner(taskid), null),\n       Charsets.UTF_8));\n     //the format of the index file is\n     //LOG_DIR: \u003cthe dir where the task logs are really stored\u003e\n     //stdout:\u003cstart-offset in the stdout file\u003e \u003clength\u003e\n     //stderr:\u003cstart-offset in the stderr file\u003e \u003clength\u003e\n     //syslog:\u003cstart-offset in the syslog file\u003e \u003clength\u003e\n     LogFileDetail l \u003d new LogFileDetail();\n     String str \u003d null;\n     try {\n       str \u003d fis.readLine();\n       if (str \u003d\u003d null) { // the file doesn\u0027t have anything\n         throw new IOException(\"Index file for the log of \" + taskid\n             + \" doesn\u0027t exist.\");\n       }\n       l.location \u003d str.substring(str.indexOf(LogFileDetail.LOCATION)\n           + LogFileDetail.LOCATION.length());\n       // special cases are the debugout and profile.out files. They are\n       // guaranteed\n       // to be associated with each task attempt since jvm reuse is disabled\n       // when profiling/debugging is enabled\n       if (filter.equals(LogName.DEBUGOUT) || filter.equals(LogName.PROFILE)) {\n         l.length \u003d new File(l.location, filter.toString()).length();\n         l.start \u003d 0;\n         fis.close();\n         return l;\n       }\n       str \u003d fis.readLine();\n       while (str !\u003d null) {\n         // look for the exact line containing the logname\n         if (str.contains(filter.toString())) {\n           str \u003d str.substring(filter.toString().length() + 1);\n           String[] startAndLen \u003d str.split(\" \");\n           l.start \u003d Long.parseLong(startAndLen[0]);\n           l.length \u003d Long.parseLong(startAndLen[1]);\n           break;\n         }\n         str \u003d fis.readLine();\n       }\n       fis.close();\n       fis \u003d null;\n     } finally {\n-      IOUtils.cleanup(LOG, fis);\n+      IOUtils.cleanupWithLogger(LOG, fis);\n     }\n     return l;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static LogFileDetail getLogFileDetail(TaskAttemptID taskid, \n                                                LogName filter,\n                                                boolean isCleanup) \n  throws IOException {\n    File indexFile \u003d getIndexFile(taskid, isCleanup);\n    BufferedReader fis \u003d new BufferedReader(new InputStreamReader(\n      SecureIOUtils.openForRead(indexFile, obtainLogDirOwner(taskid), null),\n      Charsets.UTF_8));\n    //the format of the index file is\n    //LOG_DIR: \u003cthe dir where the task logs are really stored\u003e\n    //stdout:\u003cstart-offset in the stdout file\u003e \u003clength\u003e\n    //stderr:\u003cstart-offset in the stderr file\u003e \u003clength\u003e\n    //syslog:\u003cstart-offset in the syslog file\u003e \u003clength\u003e\n    LogFileDetail l \u003d new LogFileDetail();\n    String str \u003d null;\n    try {\n      str \u003d fis.readLine();\n      if (str \u003d\u003d null) { // the file doesn\u0027t have anything\n        throw new IOException(\"Index file for the log of \" + taskid\n            + \" doesn\u0027t exist.\");\n      }\n      l.location \u003d str.substring(str.indexOf(LogFileDetail.LOCATION)\n          + LogFileDetail.LOCATION.length());\n      // special cases are the debugout and profile.out files. They are\n      // guaranteed\n      // to be associated with each task attempt since jvm reuse is disabled\n      // when profiling/debugging is enabled\n      if (filter.equals(LogName.DEBUGOUT) || filter.equals(LogName.PROFILE)) {\n        l.length \u003d new File(l.location, filter.toString()).length();\n        l.start \u003d 0;\n        fis.close();\n        return l;\n      }\n      str \u003d fis.readLine();\n      while (str !\u003d null) {\n        // look for the exact line containing the logname\n        if (str.contains(filter.toString())) {\n          str \u003d str.substring(filter.toString().length() + 1);\n          String[] startAndLen \u003d str.split(\" \");\n          l.start \u003d Long.parseLong(startAndLen[0]);\n          l.length \u003d Long.parseLong(startAndLen[1]);\n          break;\n        }\n        str \u003d fis.readLine();\n      }\n      fis.close();\n      fis \u003d null;\n    } finally {\n      IOUtils.cleanupWithLogger(LOG, fis);\n    }\n    return l;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/TaskLog.java",
      "extendedDetails": {}
    },
    "905b17876c44634545a68300ff2f2d73fb86d3b7": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4723. Fix warnings found by findbugs 2. Contributed by Sandy Ryza\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1409601 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/11/12 4:16 PM",
      "commitName": "905b17876c44634545a68300ff2f2d73fb86d3b7",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "17/07/12 12:14 PM",
      "commitNameOld": "603418c1738a507d0d90ec3f48791575effb3d51",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 120.21,
      "commitsBetweenForRepo": 711,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,52 @@\n   private static LogFileDetail getLogFileDetail(TaskAttemptID taskid, \n                                                 LogName filter,\n                                                 boolean isCleanup) \n   throws IOException {\n     File indexFile \u003d getIndexFile(taskid, isCleanup);\n     BufferedReader fis \u003d new BufferedReader(new InputStreamReader(\n-      SecureIOUtils.openForRead(indexFile, obtainLogDirOwner(taskid), null)));\n+      SecureIOUtils.openForRead(indexFile, obtainLogDirOwner(taskid), null),\n+      Charsets.UTF_8));\n     //the format of the index file is\n     //LOG_DIR: \u003cthe dir where the task logs are really stored\u003e\n     //stdout:\u003cstart-offset in the stdout file\u003e \u003clength\u003e\n     //stderr:\u003cstart-offset in the stderr file\u003e \u003clength\u003e\n     //syslog:\u003cstart-offset in the syslog file\u003e \u003clength\u003e\n     LogFileDetail l \u003d new LogFileDetail();\n     String str \u003d null;\n     try {\n       str \u003d fis.readLine();\n       if (str \u003d\u003d null) { // the file doesn\u0027t have anything\n         throw new IOException(\"Index file for the log of \" + taskid\n             + \" doesn\u0027t exist.\");\n       }\n       l.location \u003d str.substring(str.indexOf(LogFileDetail.LOCATION)\n           + LogFileDetail.LOCATION.length());\n       // special cases are the debugout and profile.out files. They are\n       // guaranteed\n       // to be associated with each task attempt since jvm reuse is disabled\n       // when profiling/debugging is enabled\n       if (filter.equals(LogName.DEBUGOUT) || filter.equals(LogName.PROFILE)) {\n         l.length \u003d new File(l.location, filter.toString()).length();\n         l.start \u003d 0;\n         fis.close();\n         return l;\n       }\n       str \u003d fis.readLine();\n       while (str !\u003d null) {\n         // look for the exact line containing the logname\n         if (str.contains(filter.toString())) {\n           str \u003d str.substring(filter.toString().length() + 1);\n           String[] startAndLen \u003d str.split(\" \");\n           l.start \u003d Long.parseLong(startAndLen[0]);\n           l.length \u003d Long.parseLong(startAndLen[1]);\n           break;\n         }\n         str \u003d fis.readLine();\n       }\n       fis.close();\n       fis \u003d null;\n     } finally {\n       IOUtils.cleanup(LOG, fis);\n     }\n     return l;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static LogFileDetail getLogFileDetail(TaskAttemptID taskid, \n                                                LogName filter,\n                                                boolean isCleanup) \n  throws IOException {\n    File indexFile \u003d getIndexFile(taskid, isCleanup);\n    BufferedReader fis \u003d new BufferedReader(new InputStreamReader(\n      SecureIOUtils.openForRead(indexFile, obtainLogDirOwner(taskid), null),\n      Charsets.UTF_8));\n    //the format of the index file is\n    //LOG_DIR: \u003cthe dir where the task logs are really stored\u003e\n    //stdout:\u003cstart-offset in the stdout file\u003e \u003clength\u003e\n    //stderr:\u003cstart-offset in the stderr file\u003e \u003clength\u003e\n    //syslog:\u003cstart-offset in the syslog file\u003e \u003clength\u003e\n    LogFileDetail l \u003d new LogFileDetail();\n    String str \u003d null;\n    try {\n      str \u003d fis.readLine();\n      if (str \u003d\u003d null) { // the file doesn\u0027t have anything\n        throw new IOException(\"Index file for the log of \" + taskid\n            + \" doesn\u0027t exist.\");\n      }\n      l.location \u003d str.substring(str.indexOf(LogFileDetail.LOCATION)\n          + LogFileDetail.LOCATION.length());\n      // special cases are the debugout and profile.out files. They are\n      // guaranteed\n      // to be associated with each task attempt since jvm reuse is disabled\n      // when profiling/debugging is enabled\n      if (filter.equals(LogName.DEBUGOUT) || filter.equals(LogName.PROFILE)) {\n        l.length \u003d new File(l.location, filter.toString()).length();\n        l.start \u003d 0;\n        fis.close();\n        return l;\n      }\n      str \u003d fis.readLine();\n      while (str !\u003d null) {\n        // look for the exact line containing the logname\n        if (str.contains(filter.toString())) {\n          str \u003d str.substring(filter.toString().length() + 1);\n          String[] startAndLen \u003d str.split(\" \");\n          l.start \u003d Long.parseLong(startAndLen[0]);\n          l.length \u003d Long.parseLong(startAndLen[1]);\n          break;\n        }\n        str \u003d fis.readLine();\n      }\n      fis.close();\n      fis \u003d null;\n    } finally {\n      IOUtils.cleanup(LOG, fis);\n    }\n    return l;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/TaskLog.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private static LogFileDetail getLogFileDetail(TaskAttemptID taskid, \n                                                LogName filter,\n                                                boolean isCleanup) \n  throws IOException {\n    File indexFile \u003d getIndexFile(taskid, isCleanup);\n    BufferedReader fis \u003d new BufferedReader(new InputStreamReader(\n      SecureIOUtils.openForRead(indexFile, obtainLogDirOwner(taskid), null)));\n    //the format of the index file is\n    //LOG_DIR: \u003cthe dir where the task logs are really stored\u003e\n    //stdout:\u003cstart-offset in the stdout file\u003e \u003clength\u003e\n    //stderr:\u003cstart-offset in the stderr file\u003e \u003clength\u003e\n    //syslog:\u003cstart-offset in the syslog file\u003e \u003clength\u003e\n    LogFileDetail l \u003d new LogFileDetail();\n    String str \u003d null;\n    try {\n      str \u003d fis.readLine();\n      if (str \u003d\u003d null) { // the file doesn\u0027t have anything\n        throw new IOException(\"Index file for the log of \" + taskid\n            + \" doesn\u0027t exist.\");\n      }\n      l.location \u003d str.substring(str.indexOf(LogFileDetail.LOCATION)\n          + LogFileDetail.LOCATION.length());\n      // special cases are the debugout and profile.out files. They are\n      // guaranteed\n      // to be associated with each task attempt since jvm reuse is disabled\n      // when profiling/debugging is enabled\n      if (filter.equals(LogName.DEBUGOUT) || filter.equals(LogName.PROFILE)) {\n        l.length \u003d new File(l.location, filter.toString()).length();\n        l.start \u003d 0;\n        fis.close();\n        return l;\n      }\n      str \u003d fis.readLine();\n      while (str !\u003d null) {\n        // look for the exact line containing the logname\n        if (str.contains(filter.toString())) {\n          str \u003d str.substring(filter.toString().length() + 1);\n          String[] startAndLen \u003d str.split(\" \");\n          l.start \u003d Long.parseLong(startAndLen[0]);\n          l.length \u003d Long.parseLong(startAndLen[1]);\n          break;\n        }\n        str \u003d fis.readLine();\n      }\n      fis.close();\n      fis \u003d null;\n    } finally {\n      IOUtils.cleanup(LOG, fis);\n    }\n    return l;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/TaskLog.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/TaskLog.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/TaskLog.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private static LogFileDetail getLogFileDetail(TaskAttemptID taskid, \n                                                LogName filter,\n                                                boolean isCleanup) \n  throws IOException {\n    File indexFile \u003d getIndexFile(taskid, isCleanup);\n    BufferedReader fis \u003d new BufferedReader(new InputStreamReader(\n      SecureIOUtils.openForRead(indexFile, obtainLogDirOwner(taskid), null)));\n    //the format of the index file is\n    //LOG_DIR: \u003cthe dir where the task logs are really stored\u003e\n    //stdout:\u003cstart-offset in the stdout file\u003e \u003clength\u003e\n    //stderr:\u003cstart-offset in the stderr file\u003e \u003clength\u003e\n    //syslog:\u003cstart-offset in the syslog file\u003e \u003clength\u003e\n    LogFileDetail l \u003d new LogFileDetail();\n    String str \u003d null;\n    try {\n      str \u003d fis.readLine();\n      if (str \u003d\u003d null) { // the file doesn\u0027t have anything\n        throw new IOException(\"Index file for the log of \" + taskid\n            + \" doesn\u0027t exist.\");\n      }\n      l.location \u003d str.substring(str.indexOf(LogFileDetail.LOCATION)\n          + LogFileDetail.LOCATION.length());\n      // special cases are the debugout and profile.out files. They are\n      // guaranteed\n      // to be associated with each task attempt since jvm reuse is disabled\n      // when profiling/debugging is enabled\n      if (filter.equals(LogName.DEBUGOUT) || filter.equals(LogName.PROFILE)) {\n        l.length \u003d new File(l.location, filter.toString()).length();\n        l.start \u003d 0;\n        fis.close();\n        return l;\n      }\n      str \u003d fis.readLine();\n      while (str !\u003d null) {\n        // look for the exact line containing the logname\n        if (str.contains(filter.toString())) {\n          str \u003d str.substring(filter.toString().length() + 1);\n          String[] startAndLen \u003d str.split(\" \");\n          l.start \u003d Long.parseLong(startAndLen[0]);\n          l.length \u003d Long.parseLong(startAndLen[1]);\n          break;\n        }\n        str \u003d fis.readLine();\n      }\n      fis.close();\n      fis \u003d null;\n    } finally {\n      IOUtils.cleanup(LOG, fis);\n    }\n    return l;\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/TaskLog.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/java/org/apache/hadoop/mapred/TaskLog.java",
        "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/TaskLog.java"
      }
    },
    "7e18c90d396e51b2dbf9f647822dc233c73518fc": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2243. Close streams propely in a finally-block to avoid leakage in CompletedJobStatusStore, TaskLog, EventWriter and TotalOrderPartitioner.  Contributed by Devaraj K\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152787 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/08/11 7:11 AM",
      "commitName": "7e18c90d396e51b2dbf9f647822dc233c73518fc",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "12/06/11 3:00 PM",
      "commitNameOld": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 49.67,
      "commitsBetweenForRepo": 168,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,51 @@\n   private static LogFileDetail getLogFileDetail(TaskAttemptID taskid, \n                                                 LogName filter,\n                                                 boolean isCleanup) \n   throws IOException {\n     File indexFile \u003d getIndexFile(taskid, isCleanup);\n     BufferedReader fis \u003d new BufferedReader(new InputStreamReader(\n       SecureIOUtils.openForRead(indexFile, obtainLogDirOwner(taskid), null)));\n     //the format of the index file is\n     //LOG_DIR: \u003cthe dir where the task logs are really stored\u003e\n     //stdout:\u003cstart-offset in the stdout file\u003e \u003clength\u003e\n     //stderr:\u003cstart-offset in the stderr file\u003e \u003clength\u003e\n     //syslog:\u003cstart-offset in the syslog file\u003e \u003clength\u003e\n     LogFileDetail l \u003d new LogFileDetail();\n-    String str \u003d fis.readLine();\n-    if (str \u003d\u003d null) { //the file doesn\u0027t have anything\n-      throw new IOException (\"Index file for the log of \" + taskid+\" doesn\u0027t exist.\");\n-    }\n-    l.location \u003d str.substring(str.indexOf(LogFileDetail.LOCATION)+\n-        LogFileDetail.LOCATION.length());\n-    //special cases are the debugout and profile.out files. They are guaranteed\n-    //to be associated with each task attempt since jvm reuse is disabled\n-    //when profiling/debugging is enabled\n-    if (filter.equals(LogName.DEBUGOUT) || filter.equals(LogName.PROFILE)) {\n-      l.length \u003d new File(l.location, filter.toString()).length();\n-      l.start \u003d 0;\n-      fis.close();\n-      return l;\n-    }\n-    str \u003d fis.readLine();\n-    while (str !\u003d null) {\n-      //look for the exact line containing the logname\n-      if (str.contains(filter.toString())) {\n-        str \u003d str.substring(filter.toString().length()+1);\n-        String[] startAndLen \u003d str.split(\" \");\n-        l.start \u003d Long.parseLong(startAndLen[0]);\n-        l.length \u003d Long.parseLong(startAndLen[1]);\n-        break;\n+    String str \u003d null;\n+    try {\n+      str \u003d fis.readLine();\n+      if (str \u003d\u003d null) { // the file doesn\u0027t have anything\n+        throw new IOException(\"Index file for the log of \" + taskid\n+            + \" doesn\u0027t exist.\");\n+      }\n+      l.location \u003d str.substring(str.indexOf(LogFileDetail.LOCATION)\n+          + LogFileDetail.LOCATION.length());\n+      // special cases are the debugout and profile.out files. They are\n+      // guaranteed\n+      // to be associated with each task attempt since jvm reuse is disabled\n+      // when profiling/debugging is enabled\n+      if (filter.equals(LogName.DEBUGOUT) || filter.equals(LogName.PROFILE)) {\n+        l.length \u003d new File(l.location, filter.toString()).length();\n+        l.start \u003d 0;\n+        fis.close();\n+        return l;\n       }\n       str \u003d fis.readLine();\n+      while (str !\u003d null) {\n+        // look for the exact line containing the logname\n+        if (str.contains(filter.toString())) {\n+          str \u003d str.substring(filter.toString().length() + 1);\n+          String[] startAndLen \u003d str.split(\" \");\n+          l.start \u003d Long.parseLong(startAndLen[0]);\n+          l.length \u003d Long.parseLong(startAndLen[1]);\n+          break;\n+        }\n+        str \u003d fis.readLine();\n+      }\n+      fis.close();\n+      fis \u003d null;\n+    } finally {\n+      IOUtils.cleanup(LOG, fis);\n     }\n-    fis.close();\n     return l;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static LogFileDetail getLogFileDetail(TaskAttemptID taskid, \n                                                LogName filter,\n                                                boolean isCleanup) \n  throws IOException {\n    File indexFile \u003d getIndexFile(taskid, isCleanup);\n    BufferedReader fis \u003d new BufferedReader(new InputStreamReader(\n      SecureIOUtils.openForRead(indexFile, obtainLogDirOwner(taskid), null)));\n    //the format of the index file is\n    //LOG_DIR: \u003cthe dir where the task logs are really stored\u003e\n    //stdout:\u003cstart-offset in the stdout file\u003e \u003clength\u003e\n    //stderr:\u003cstart-offset in the stderr file\u003e \u003clength\u003e\n    //syslog:\u003cstart-offset in the syslog file\u003e \u003clength\u003e\n    LogFileDetail l \u003d new LogFileDetail();\n    String str \u003d null;\n    try {\n      str \u003d fis.readLine();\n      if (str \u003d\u003d null) { // the file doesn\u0027t have anything\n        throw new IOException(\"Index file for the log of \" + taskid\n            + \" doesn\u0027t exist.\");\n      }\n      l.location \u003d str.substring(str.indexOf(LogFileDetail.LOCATION)\n          + LogFileDetail.LOCATION.length());\n      // special cases are the debugout and profile.out files. They are\n      // guaranteed\n      // to be associated with each task attempt since jvm reuse is disabled\n      // when profiling/debugging is enabled\n      if (filter.equals(LogName.DEBUGOUT) || filter.equals(LogName.PROFILE)) {\n        l.length \u003d new File(l.location, filter.toString()).length();\n        l.start \u003d 0;\n        fis.close();\n        return l;\n      }\n      str \u003d fis.readLine();\n      while (str !\u003d null) {\n        // look for the exact line containing the logname\n        if (str.contains(filter.toString())) {\n          str \u003d str.substring(filter.toString().length() + 1);\n          String[] startAndLen \u003d str.split(\" \");\n          l.start \u003d Long.parseLong(startAndLen[0]);\n          l.length \u003d Long.parseLong(startAndLen[1]);\n          break;\n        }\n        str \u003d fis.readLine();\n      }\n      fis.close();\n      fis \u003d null;\n    } finally {\n      IOUtils.cleanup(LOG, fis);\n    }\n    return l;\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapred/TaskLog.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,43 @@\n+  private static LogFileDetail getLogFileDetail(TaskAttemptID taskid, \n+                                                LogName filter,\n+                                                boolean isCleanup) \n+  throws IOException {\n+    File indexFile \u003d getIndexFile(taskid, isCleanup);\n+    BufferedReader fis \u003d new BufferedReader(new InputStreamReader(\n+      SecureIOUtils.openForRead(indexFile, obtainLogDirOwner(taskid), null)));\n+    //the format of the index file is\n+    //LOG_DIR: \u003cthe dir where the task logs are really stored\u003e\n+    //stdout:\u003cstart-offset in the stdout file\u003e \u003clength\u003e\n+    //stderr:\u003cstart-offset in the stderr file\u003e \u003clength\u003e\n+    //syslog:\u003cstart-offset in the syslog file\u003e \u003clength\u003e\n+    LogFileDetail l \u003d new LogFileDetail();\n+    String str \u003d fis.readLine();\n+    if (str \u003d\u003d null) { //the file doesn\u0027t have anything\n+      throw new IOException (\"Index file for the log of \" + taskid+\" doesn\u0027t exist.\");\n+    }\n+    l.location \u003d str.substring(str.indexOf(LogFileDetail.LOCATION)+\n+        LogFileDetail.LOCATION.length());\n+    //special cases are the debugout and profile.out files. They are guaranteed\n+    //to be associated with each task attempt since jvm reuse is disabled\n+    //when profiling/debugging is enabled\n+    if (filter.equals(LogName.DEBUGOUT) || filter.equals(LogName.PROFILE)) {\n+      l.length \u003d new File(l.location, filter.toString()).length();\n+      l.start \u003d 0;\n+      fis.close();\n+      return l;\n+    }\n+    str \u003d fis.readLine();\n+    while (str !\u003d null) {\n+      //look for the exact line containing the logname\n+      if (str.contains(filter.toString())) {\n+        str \u003d str.substring(filter.toString().length()+1);\n+        String[] startAndLen \u003d str.split(\" \");\n+        l.start \u003d Long.parseLong(startAndLen[0]);\n+        l.length \u003d Long.parseLong(startAndLen[1]);\n+        break;\n+      }\n+      str \u003d fis.readLine();\n+    }\n+    fis.close();\n+    return l;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static LogFileDetail getLogFileDetail(TaskAttemptID taskid, \n                                                LogName filter,\n                                                boolean isCleanup) \n  throws IOException {\n    File indexFile \u003d getIndexFile(taskid, isCleanup);\n    BufferedReader fis \u003d new BufferedReader(new InputStreamReader(\n      SecureIOUtils.openForRead(indexFile, obtainLogDirOwner(taskid), null)));\n    //the format of the index file is\n    //LOG_DIR: \u003cthe dir where the task logs are really stored\u003e\n    //stdout:\u003cstart-offset in the stdout file\u003e \u003clength\u003e\n    //stderr:\u003cstart-offset in the stderr file\u003e \u003clength\u003e\n    //syslog:\u003cstart-offset in the syslog file\u003e \u003clength\u003e\n    LogFileDetail l \u003d new LogFileDetail();\n    String str \u003d fis.readLine();\n    if (str \u003d\u003d null) { //the file doesn\u0027t have anything\n      throw new IOException (\"Index file for the log of \" + taskid+\" doesn\u0027t exist.\");\n    }\n    l.location \u003d str.substring(str.indexOf(LogFileDetail.LOCATION)+\n        LogFileDetail.LOCATION.length());\n    //special cases are the debugout and profile.out files. They are guaranteed\n    //to be associated with each task attempt since jvm reuse is disabled\n    //when profiling/debugging is enabled\n    if (filter.equals(LogName.DEBUGOUT) || filter.equals(LogName.PROFILE)) {\n      l.length \u003d new File(l.location, filter.toString()).length();\n      l.start \u003d 0;\n      fis.close();\n      return l;\n    }\n    str \u003d fis.readLine();\n    while (str !\u003d null) {\n      //look for the exact line containing the logname\n      if (str.contains(filter.toString())) {\n        str \u003d str.substring(filter.toString().length()+1);\n        String[] startAndLen \u003d str.split(\" \");\n        l.start \u003d Long.parseLong(startAndLen[0]);\n        l.length \u003d Long.parseLong(startAndLen[1]);\n        break;\n      }\n      str \u003d fis.readLine();\n    }\n    fis.close();\n    return l;\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapred/TaskLog.java"
    }
  }
}