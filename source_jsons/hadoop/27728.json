{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LocalityMulticastAMRMProxyPolicy.java",
  "functionName": "reinitialize",
  "functionId": "reinitialize___activeSubclusters-Map__SubClusterId,SubClusterInfo____timedOutSubClusters-Set__SubClusterId__",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/federation/policies/amrmproxy/LocalityMulticastAMRMProxyPolicy.java",
  "functionStartLine": 512,
  "functionEndLine": 571,
  "numCommitsSeen": 19,
  "timeTaken": 3876,
  "changeHistory": [
    "b5ec85d96615e8214c14b57f8980a1dee6197ffa",
    "7ed458b255e492fd5bc2ca36f216ff1b16054db7",
    "e0f6ffdbad6f43fd43ec57fb68ebf5275b8b9ba0",
    "8623644f4599f51d34ba79c4c1453b3997205d8f",
    "1dadd0b45a6a605da72eb304808edb49fc66da45"
  ],
  "changeHistoryShort": {
    "b5ec85d96615e8214c14b57f8980a1dee6197ffa": "Ymultichange(Yparameterchange,Ybodychange)",
    "7ed458b255e492fd5bc2ca36f216ff1b16054db7": "Ybodychange",
    "e0f6ffdbad6f43fd43ec57fb68ebf5275b8b9ba0": "Ybodychange",
    "8623644f4599f51d34ba79c4c1453b3997205d8f": "Ybodychange",
    "1dadd0b45a6a605da72eb304808edb49fc66da45": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b5ec85d96615e8214c14b57f8980a1dee6197ffa": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-8933. [AMRMProxy] Fix potential empty fields in allocation response, move SubClusterTimeout to FederationInterceptor. Contributed by Botong Huang.\n",
      "commitDate": "11/11/18 11:12 AM",
      "commitName": "b5ec85d96615e8214c14b57f8980a1dee6197ffa",
      "commitAuthor": "Botong Huang",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-8933. [AMRMProxy] Fix potential empty fields in allocation response, move SubClusterTimeout to FederationInterceptor. Contributed by Botong Huang.\n",
          "commitDate": "11/11/18 11:12 AM",
          "commitName": "b5ec85d96615e8214c14b57f8980a1dee6197ffa",
          "commitAuthor": "Botong Huang",
          "commitDateOld": "28/08/18 4:01 PM",
          "commitNameOld": "7ed458b255e492fd5bc2ca36f216ff1b16054db7",
          "commitAuthorOld": "Giovanni Matteo Fumarola",
          "daysBetweenCommits": 74.84,
          "commitsBetweenForRepo": 697,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,69 +1,60 @@\n     private void reinitialize(\n-        Map\u003cSubClusterId, SubClusterInfo\u003e activeSubclusters)\n-        throws YarnException {\n+        Map\u003cSubClusterId, SubClusterInfo\u003e activeSubclusters,\n+        Set\u003cSubClusterId\u003e timedOutSubClusters) throws YarnException {\n       if (activeSubclusters \u003d\u003d null) {\n         throw new YarnRuntimeException(\"null activeSubclusters received\");\n       }\n \n       // reset data structures\n       answer.clear();\n       maskForRackDeletion.clear();\n       countContainersPerRM.clear();\n       totNumLocalizedContainers.clear();\n       activeAndEnabledSC.clear();\n       totHeadroomMemory \u003d 0;\n       totHeadRoomEnabledRMs \u003d 0;\n       // save the reference locally in case the weights get reinitialized\n       // concurrently\n       policyWeights \u003d weights;\n       totPolicyWeight \u003d 0;\n \n       for (Map.Entry\u003cSubClusterId, Float\u003e entry : policyWeights.entrySet()) {\n         if (entry.getValue() \u003e 0\n             \u0026\u0026 activeSubclusters.containsKey(entry.getKey())) {\n           activeAndEnabledSC.add(entry.getKey());\n         }\n       }\n \n       if (activeAndEnabledSC.size() \u003c 1) {\n         throw new NoActiveSubclustersException(\n             \"None of the subclusters enabled in this policy (weight\u003e0) are \"\n                 + \"currently active we cannot forward the ResourceRequest(s)\");\n       }\n \n       Set\u003cSubClusterId\u003e tmpSCSet \u003d new HashSet\u003c\u003e(activeAndEnabledSC);\n-      for (Map.Entry\u003cSubClusterId, Long\u003e entry : lastHeartbeatTimeStamp\n-          .entrySet()) {\n-        long duration \u003d System.currentTimeMillis() - entry.getValue();\n-        if (duration \u003e subClusterTimeOut) {\n-          LOG.warn(\n-              \"Subcluster {} does not have a success heartbeat for {}s, \"\n-                  + \"skip routing asks there for this request\",\n-              entry.getKey(), (double) duration / 1000);\n-          tmpSCSet.remove(entry.getKey());\n-        }\n-      }\n+      tmpSCSet.removeAll(timedOutSubClusters);\n+\n       if (tmpSCSet.size() \u003c 1) {\n         LOG.warn(\"All active and enabled subclusters have expired last \"\n             + \"heartbeat time. Ignore the expiry check for this request\");\n       } else {\n         activeAndEnabledSC \u003d tmpSCSet;\n       }\n \n       LOG.info(\"{} subcluster active, {} subclusters active and enabled\",\n           activeSubclusters.size(), activeAndEnabledSC.size());\n \n       // pre-compute the set of subclusters that are both active and enabled by\n       // the policy weights, and accumulate their total weight\n       for (SubClusterId sc : activeAndEnabledSC) {\n         totPolicyWeight +\u003d policyWeights.get(sc);\n       }\n \n       // pre-compute headroom-based weights for active/enabled subclusters\n       for (Map.Entry\u003cSubClusterId, Resource\u003e r : headroom.entrySet()) {\n         if (activeAndEnabledSC.contains(r.getKey())) {\n           totHeadroomMemory +\u003d r.getValue().getMemorySize();\n           totHeadRoomEnabledRMs++;\n         }\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void reinitialize(\n        Map\u003cSubClusterId, SubClusterInfo\u003e activeSubclusters,\n        Set\u003cSubClusterId\u003e timedOutSubClusters) throws YarnException {\n      if (activeSubclusters \u003d\u003d null) {\n        throw new YarnRuntimeException(\"null activeSubclusters received\");\n      }\n\n      // reset data structures\n      answer.clear();\n      maskForRackDeletion.clear();\n      countContainersPerRM.clear();\n      totNumLocalizedContainers.clear();\n      activeAndEnabledSC.clear();\n      totHeadroomMemory \u003d 0;\n      totHeadRoomEnabledRMs \u003d 0;\n      // save the reference locally in case the weights get reinitialized\n      // concurrently\n      policyWeights \u003d weights;\n      totPolicyWeight \u003d 0;\n\n      for (Map.Entry\u003cSubClusterId, Float\u003e entry : policyWeights.entrySet()) {\n        if (entry.getValue() \u003e 0\n            \u0026\u0026 activeSubclusters.containsKey(entry.getKey())) {\n          activeAndEnabledSC.add(entry.getKey());\n        }\n      }\n\n      if (activeAndEnabledSC.size() \u003c 1) {\n        throw new NoActiveSubclustersException(\n            \"None of the subclusters enabled in this policy (weight\u003e0) are \"\n                + \"currently active we cannot forward the ResourceRequest(s)\");\n      }\n\n      Set\u003cSubClusterId\u003e tmpSCSet \u003d new HashSet\u003c\u003e(activeAndEnabledSC);\n      tmpSCSet.removeAll(timedOutSubClusters);\n\n      if (tmpSCSet.size() \u003c 1) {\n        LOG.warn(\"All active and enabled subclusters have expired last \"\n            + \"heartbeat time. Ignore the expiry check for this request\");\n      } else {\n        activeAndEnabledSC \u003d tmpSCSet;\n      }\n\n      LOG.info(\"{} subcluster active, {} subclusters active and enabled\",\n          activeSubclusters.size(), activeAndEnabledSC.size());\n\n      // pre-compute the set of subclusters that are both active and enabled by\n      // the policy weights, and accumulate their total weight\n      for (SubClusterId sc : activeAndEnabledSC) {\n        totPolicyWeight +\u003d policyWeights.get(sc);\n      }\n\n      // pre-compute headroom-based weights for active/enabled subclusters\n      for (Map.Entry\u003cSubClusterId, Resource\u003e r : headroom.entrySet()) {\n        if (activeAndEnabledSC.contains(r.getKey())) {\n          totHeadroomMemory +\u003d r.getValue().getMemorySize();\n          totHeadRoomEnabledRMs++;\n        }\n      }\n    }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/federation/policies/amrmproxy/LocalityMulticastAMRMProxyPolicy.java",
          "extendedDetails": {
            "oldValue": "[activeSubclusters-Map\u003cSubClusterId,SubClusterInfo\u003e]",
            "newValue": "[activeSubclusters-Map\u003cSubClusterId,SubClusterInfo\u003e, timedOutSubClusters-Set\u003cSubClusterId\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-8933. [AMRMProxy] Fix potential empty fields in allocation response, move SubClusterTimeout to FederationInterceptor. Contributed by Botong Huang.\n",
          "commitDate": "11/11/18 11:12 AM",
          "commitName": "b5ec85d96615e8214c14b57f8980a1dee6197ffa",
          "commitAuthor": "Botong Huang",
          "commitDateOld": "28/08/18 4:01 PM",
          "commitNameOld": "7ed458b255e492fd5bc2ca36f216ff1b16054db7",
          "commitAuthorOld": "Giovanni Matteo Fumarola",
          "daysBetweenCommits": 74.84,
          "commitsBetweenForRepo": 697,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,69 +1,60 @@\n     private void reinitialize(\n-        Map\u003cSubClusterId, SubClusterInfo\u003e activeSubclusters)\n-        throws YarnException {\n+        Map\u003cSubClusterId, SubClusterInfo\u003e activeSubclusters,\n+        Set\u003cSubClusterId\u003e timedOutSubClusters) throws YarnException {\n       if (activeSubclusters \u003d\u003d null) {\n         throw new YarnRuntimeException(\"null activeSubclusters received\");\n       }\n \n       // reset data structures\n       answer.clear();\n       maskForRackDeletion.clear();\n       countContainersPerRM.clear();\n       totNumLocalizedContainers.clear();\n       activeAndEnabledSC.clear();\n       totHeadroomMemory \u003d 0;\n       totHeadRoomEnabledRMs \u003d 0;\n       // save the reference locally in case the weights get reinitialized\n       // concurrently\n       policyWeights \u003d weights;\n       totPolicyWeight \u003d 0;\n \n       for (Map.Entry\u003cSubClusterId, Float\u003e entry : policyWeights.entrySet()) {\n         if (entry.getValue() \u003e 0\n             \u0026\u0026 activeSubclusters.containsKey(entry.getKey())) {\n           activeAndEnabledSC.add(entry.getKey());\n         }\n       }\n \n       if (activeAndEnabledSC.size() \u003c 1) {\n         throw new NoActiveSubclustersException(\n             \"None of the subclusters enabled in this policy (weight\u003e0) are \"\n                 + \"currently active we cannot forward the ResourceRequest(s)\");\n       }\n \n       Set\u003cSubClusterId\u003e tmpSCSet \u003d new HashSet\u003c\u003e(activeAndEnabledSC);\n-      for (Map.Entry\u003cSubClusterId, Long\u003e entry : lastHeartbeatTimeStamp\n-          .entrySet()) {\n-        long duration \u003d System.currentTimeMillis() - entry.getValue();\n-        if (duration \u003e subClusterTimeOut) {\n-          LOG.warn(\n-              \"Subcluster {} does not have a success heartbeat for {}s, \"\n-                  + \"skip routing asks there for this request\",\n-              entry.getKey(), (double) duration / 1000);\n-          tmpSCSet.remove(entry.getKey());\n-        }\n-      }\n+      tmpSCSet.removeAll(timedOutSubClusters);\n+\n       if (tmpSCSet.size() \u003c 1) {\n         LOG.warn(\"All active and enabled subclusters have expired last \"\n             + \"heartbeat time. Ignore the expiry check for this request\");\n       } else {\n         activeAndEnabledSC \u003d tmpSCSet;\n       }\n \n       LOG.info(\"{} subcluster active, {} subclusters active and enabled\",\n           activeSubclusters.size(), activeAndEnabledSC.size());\n \n       // pre-compute the set of subclusters that are both active and enabled by\n       // the policy weights, and accumulate their total weight\n       for (SubClusterId sc : activeAndEnabledSC) {\n         totPolicyWeight +\u003d policyWeights.get(sc);\n       }\n \n       // pre-compute headroom-based weights for active/enabled subclusters\n       for (Map.Entry\u003cSubClusterId, Resource\u003e r : headroom.entrySet()) {\n         if (activeAndEnabledSC.contains(r.getKey())) {\n           totHeadroomMemory +\u003d r.getValue().getMemorySize();\n           totHeadRoomEnabledRMs++;\n         }\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void reinitialize(\n        Map\u003cSubClusterId, SubClusterInfo\u003e activeSubclusters,\n        Set\u003cSubClusterId\u003e timedOutSubClusters) throws YarnException {\n      if (activeSubclusters \u003d\u003d null) {\n        throw new YarnRuntimeException(\"null activeSubclusters received\");\n      }\n\n      // reset data structures\n      answer.clear();\n      maskForRackDeletion.clear();\n      countContainersPerRM.clear();\n      totNumLocalizedContainers.clear();\n      activeAndEnabledSC.clear();\n      totHeadroomMemory \u003d 0;\n      totHeadRoomEnabledRMs \u003d 0;\n      // save the reference locally in case the weights get reinitialized\n      // concurrently\n      policyWeights \u003d weights;\n      totPolicyWeight \u003d 0;\n\n      for (Map.Entry\u003cSubClusterId, Float\u003e entry : policyWeights.entrySet()) {\n        if (entry.getValue() \u003e 0\n            \u0026\u0026 activeSubclusters.containsKey(entry.getKey())) {\n          activeAndEnabledSC.add(entry.getKey());\n        }\n      }\n\n      if (activeAndEnabledSC.size() \u003c 1) {\n        throw new NoActiveSubclustersException(\n            \"None of the subclusters enabled in this policy (weight\u003e0) are \"\n                + \"currently active we cannot forward the ResourceRequest(s)\");\n      }\n\n      Set\u003cSubClusterId\u003e tmpSCSet \u003d new HashSet\u003c\u003e(activeAndEnabledSC);\n      tmpSCSet.removeAll(timedOutSubClusters);\n\n      if (tmpSCSet.size() \u003c 1) {\n        LOG.warn(\"All active and enabled subclusters have expired last \"\n            + \"heartbeat time. Ignore the expiry check for this request\");\n      } else {\n        activeAndEnabledSC \u003d tmpSCSet;\n      }\n\n      LOG.info(\"{} subcluster active, {} subclusters active and enabled\",\n          activeSubclusters.size(), activeAndEnabledSC.size());\n\n      // pre-compute the set of subclusters that are both active and enabled by\n      // the policy weights, and accumulate their total weight\n      for (SubClusterId sc : activeAndEnabledSC) {\n        totPolicyWeight +\u003d policyWeights.get(sc);\n      }\n\n      // pre-compute headroom-based weights for active/enabled subclusters\n      for (Map.Entry\u003cSubClusterId, Resource\u003e r : headroom.entrySet()) {\n        if (activeAndEnabledSC.contains(r.getKey())) {\n          totHeadroomMemory +\u003d r.getValue().getMemorySize();\n          totHeadRoomEnabledRMs++;\n        }\n      }\n    }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/federation/policies/amrmproxy/LocalityMulticastAMRMProxyPolicy.java",
          "extendedDetails": {}
        }
      ]
    },
    "7ed458b255e492fd5bc2ca36f216ff1b16054db7": {
      "type": "Ybodychange",
      "commitMessage": "YARN-8697. LocalityMulticastAMRMProxyPolicy should fallback to random sub-cluster when cannot resolve resource. Contributed by Botong Huang.\n",
      "commitDate": "28/08/18 4:01 PM",
      "commitName": "7ed458b255e492fd5bc2ca36f216ff1b16054db7",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "20/08/18 2:33 PM",
      "commitNameOld": "e0f6ffdbad6f43fd43ec57fb68ebf5275b8b9ba0",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 8.06,
      "commitsBetweenForRepo": 48,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,69 @@\n     private void reinitialize(\n         Map\u003cSubClusterId, SubClusterInfo\u003e activeSubclusters)\n         throws YarnException {\n       if (activeSubclusters \u003d\u003d null) {\n         throw new YarnRuntimeException(\"null activeSubclusters received\");\n       }\n \n       // reset data structures\n       answer.clear();\n+      maskForRackDeletion.clear();\n       countContainersPerRM.clear();\n       totNumLocalizedContainers.clear();\n       activeAndEnabledSC.clear();\n       totHeadroomMemory \u003d 0;\n       totHeadRoomEnabledRMs \u003d 0;\n       // save the reference locally in case the weights get reinitialized\n       // concurrently\n       policyWeights \u003d weights;\n       totPolicyWeight \u003d 0;\n \n       for (Map.Entry\u003cSubClusterId, Float\u003e entry : policyWeights.entrySet()) {\n         if (entry.getValue() \u003e 0\n             \u0026\u0026 activeSubclusters.containsKey(entry.getKey())) {\n           activeAndEnabledSC.add(entry.getKey());\n         }\n       }\n \n       if (activeAndEnabledSC.size() \u003c 1) {\n         throw new NoActiveSubclustersException(\n             \"None of the subclusters enabled in this policy (weight\u003e0) are \"\n                 + \"currently active we cannot forward the ResourceRequest(s)\");\n       }\n \n       Set\u003cSubClusterId\u003e tmpSCSet \u003d new HashSet\u003c\u003e(activeAndEnabledSC);\n       for (Map.Entry\u003cSubClusterId, Long\u003e entry : lastHeartbeatTimeStamp\n           .entrySet()) {\n         long duration \u003d System.currentTimeMillis() - entry.getValue();\n         if (duration \u003e subClusterTimeOut) {\n           LOG.warn(\n               \"Subcluster {} does not have a success heartbeat for {}s, \"\n                   + \"skip routing asks there for this request\",\n               entry.getKey(), (double) duration / 1000);\n           tmpSCSet.remove(entry.getKey());\n         }\n       }\n       if (tmpSCSet.size() \u003c 1) {\n         LOG.warn(\"All active and enabled subclusters have expired last \"\n             + \"heartbeat time. Ignore the expiry check for this request\");\n       } else {\n         activeAndEnabledSC \u003d tmpSCSet;\n       }\n \n       LOG.info(\"{} subcluster active, {} subclusters active and enabled\",\n           activeSubclusters.size(), activeAndEnabledSC.size());\n \n       // pre-compute the set of subclusters that are both active and enabled by\n       // the policy weights, and accumulate their total weight\n       for (SubClusterId sc : activeAndEnabledSC) {\n         totPolicyWeight +\u003d policyWeights.get(sc);\n       }\n \n       // pre-compute headroom-based weights for active/enabled subclusters\n       for (Map.Entry\u003cSubClusterId, Resource\u003e r : headroom.entrySet()) {\n         if (activeAndEnabledSC.contains(r.getKey())) {\n           totHeadroomMemory +\u003d r.getValue().getMemorySize();\n           totHeadRoomEnabledRMs++;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void reinitialize(\n        Map\u003cSubClusterId, SubClusterInfo\u003e activeSubclusters)\n        throws YarnException {\n      if (activeSubclusters \u003d\u003d null) {\n        throw new YarnRuntimeException(\"null activeSubclusters received\");\n      }\n\n      // reset data structures\n      answer.clear();\n      maskForRackDeletion.clear();\n      countContainersPerRM.clear();\n      totNumLocalizedContainers.clear();\n      activeAndEnabledSC.clear();\n      totHeadroomMemory \u003d 0;\n      totHeadRoomEnabledRMs \u003d 0;\n      // save the reference locally in case the weights get reinitialized\n      // concurrently\n      policyWeights \u003d weights;\n      totPolicyWeight \u003d 0;\n\n      for (Map.Entry\u003cSubClusterId, Float\u003e entry : policyWeights.entrySet()) {\n        if (entry.getValue() \u003e 0\n            \u0026\u0026 activeSubclusters.containsKey(entry.getKey())) {\n          activeAndEnabledSC.add(entry.getKey());\n        }\n      }\n\n      if (activeAndEnabledSC.size() \u003c 1) {\n        throw new NoActiveSubclustersException(\n            \"None of the subclusters enabled in this policy (weight\u003e0) are \"\n                + \"currently active we cannot forward the ResourceRequest(s)\");\n      }\n\n      Set\u003cSubClusterId\u003e tmpSCSet \u003d new HashSet\u003c\u003e(activeAndEnabledSC);\n      for (Map.Entry\u003cSubClusterId, Long\u003e entry : lastHeartbeatTimeStamp\n          .entrySet()) {\n        long duration \u003d System.currentTimeMillis() - entry.getValue();\n        if (duration \u003e subClusterTimeOut) {\n          LOG.warn(\n              \"Subcluster {} does not have a success heartbeat for {}s, \"\n                  + \"skip routing asks there for this request\",\n              entry.getKey(), (double) duration / 1000);\n          tmpSCSet.remove(entry.getKey());\n        }\n      }\n      if (tmpSCSet.size() \u003c 1) {\n        LOG.warn(\"All active and enabled subclusters have expired last \"\n            + \"heartbeat time. Ignore the expiry check for this request\");\n      } else {\n        activeAndEnabledSC \u003d tmpSCSet;\n      }\n\n      LOG.info(\"{} subcluster active, {} subclusters active and enabled\",\n          activeSubclusters.size(), activeAndEnabledSC.size());\n\n      // pre-compute the set of subclusters that are both active and enabled by\n      // the policy weights, and accumulate their total weight\n      for (SubClusterId sc : activeAndEnabledSC) {\n        totPolicyWeight +\u003d policyWeights.get(sc);\n      }\n\n      // pre-compute headroom-based weights for active/enabled subclusters\n      for (Map.Entry\u003cSubClusterId, Resource\u003e r : headroom.entrySet()) {\n        if (activeAndEnabledSC.contains(r.getKey())) {\n          totHeadroomMemory +\u003d r.getValue().getMemorySize();\n          totHeadRoomEnabledRMs++;\n        }\n      }\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/federation/policies/amrmproxy/LocalityMulticastAMRMProxyPolicy.java",
      "extendedDetails": {}
    },
    "e0f6ffdbad6f43fd43ec57fb68ebf5275b8b9ba0": {
      "type": "Ybodychange",
      "commitMessage": "YARN-8581. [AMRMProxy] Add sub-cluster timeout in LocalityMulticastAMRMProxyPolicy. Contributed by Botong Huang.\n",
      "commitDate": "20/08/18 2:33 PM",
      "commitName": "e0f6ffdbad6f43fd43ec57fb68ebf5275b8b9ba0",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "21/06/18 6:24 PM",
      "commitNameOld": "99948565cb5d5706241d7a8fc591e1617c499e03",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 59.84,
      "commitsBetweenForRepo": 435,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,68 @@\n     private void reinitialize(\n         Map\u003cSubClusterId, SubClusterInfo\u003e activeSubclusters)\n         throws YarnException {\n       if (activeSubclusters \u003d\u003d null) {\n         throw new YarnRuntimeException(\"null activeSubclusters received\");\n       }\n \n       // reset data structures\n       answer.clear();\n       countContainersPerRM.clear();\n       totNumLocalizedContainers.clear();\n       activeAndEnabledSC.clear();\n       totHeadroomMemory \u003d 0;\n       totHeadRoomEnabledRMs \u003d 0;\n       // save the reference locally in case the weights get reinitialized\n       // concurrently\n       policyWeights \u003d weights;\n       totPolicyWeight \u003d 0;\n \n-      // pre-compute the set of subclusters that are both active and enabled by\n-      // the policy weights, and accumulate their total weight\n       for (Map.Entry\u003cSubClusterId, Float\u003e entry : policyWeights.entrySet()) {\n         if (entry.getValue() \u003e 0\n             \u0026\u0026 activeSubclusters.containsKey(entry.getKey())) {\n           activeAndEnabledSC.add(entry.getKey());\n-          totPolicyWeight +\u003d entry.getValue();\n         }\n       }\n \n       if (activeAndEnabledSC.size() \u003c 1) {\n         throw new NoActiveSubclustersException(\n             \"None of the subclusters enabled in this policy (weight\u003e0) are \"\n                 + \"currently active we cannot forward the ResourceRequest(s)\");\n       }\n \n+      Set\u003cSubClusterId\u003e tmpSCSet \u003d new HashSet\u003c\u003e(activeAndEnabledSC);\n+      for (Map.Entry\u003cSubClusterId, Long\u003e entry : lastHeartbeatTimeStamp\n+          .entrySet()) {\n+        long duration \u003d System.currentTimeMillis() - entry.getValue();\n+        if (duration \u003e subClusterTimeOut) {\n+          LOG.warn(\n+              \"Subcluster {} does not have a success heartbeat for {}s, \"\n+                  + \"skip routing asks there for this request\",\n+              entry.getKey(), (double) duration / 1000);\n+          tmpSCSet.remove(entry.getKey());\n+        }\n+      }\n+      if (tmpSCSet.size() \u003c 1) {\n+        LOG.warn(\"All active and enabled subclusters have expired last \"\n+            + \"heartbeat time. Ignore the expiry check for this request\");\n+      } else {\n+        activeAndEnabledSC \u003d tmpSCSet;\n+      }\n+\n+      LOG.info(\"{} subcluster active, {} subclusters active and enabled\",\n+          activeSubclusters.size(), activeAndEnabledSC.size());\n+\n+      // pre-compute the set of subclusters that are both active and enabled by\n+      // the policy weights, and accumulate their total weight\n+      for (SubClusterId sc : activeAndEnabledSC) {\n+        totPolicyWeight +\u003d policyWeights.get(sc);\n+      }\n+\n       // pre-compute headroom-based weights for active/enabled subclusters\n       for (Map.Entry\u003cSubClusterId, Resource\u003e r : headroom.entrySet()) {\n         if (activeAndEnabledSC.contains(r.getKey())) {\n           totHeadroomMemory +\u003d r.getValue().getMemorySize();\n           totHeadRoomEnabledRMs++;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void reinitialize(\n        Map\u003cSubClusterId, SubClusterInfo\u003e activeSubclusters)\n        throws YarnException {\n      if (activeSubclusters \u003d\u003d null) {\n        throw new YarnRuntimeException(\"null activeSubclusters received\");\n      }\n\n      // reset data structures\n      answer.clear();\n      countContainersPerRM.clear();\n      totNumLocalizedContainers.clear();\n      activeAndEnabledSC.clear();\n      totHeadroomMemory \u003d 0;\n      totHeadRoomEnabledRMs \u003d 0;\n      // save the reference locally in case the weights get reinitialized\n      // concurrently\n      policyWeights \u003d weights;\n      totPolicyWeight \u003d 0;\n\n      for (Map.Entry\u003cSubClusterId, Float\u003e entry : policyWeights.entrySet()) {\n        if (entry.getValue() \u003e 0\n            \u0026\u0026 activeSubclusters.containsKey(entry.getKey())) {\n          activeAndEnabledSC.add(entry.getKey());\n        }\n      }\n\n      if (activeAndEnabledSC.size() \u003c 1) {\n        throw new NoActiveSubclustersException(\n            \"None of the subclusters enabled in this policy (weight\u003e0) are \"\n                + \"currently active we cannot forward the ResourceRequest(s)\");\n      }\n\n      Set\u003cSubClusterId\u003e tmpSCSet \u003d new HashSet\u003c\u003e(activeAndEnabledSC);\n      for (Map.Entry\u003cSubClusterId, Long\u003e entry : lastHeartbeatTimeStamp\n          .entrySet()) {\n        long duration \u003d System.currentTimeMillis() - entry.getValue();\n        if (duration \u003e subClusterTimeOut) {\n          LOG.warn(\n              \"Subcluster {} does not have a success heartbeat for {}s, \"\n                  + \"skip routing asks there for this request\",\n              entry.getKey(), (double) duration / 1000);\n          tmpSCSet.remove(entry.getKey());\n        }\n      }\n      if (tmpSCSet.size() \u003c 1) {\n        LOG.warn(\"All active and enabled subclusters have expired last \"\n            + \"heartbeat time. Ignore the expiry check for this request\");\n      } else {\n        activeAndEnabledSC \u003d tmpSCSet;\n      }\n\n      LOG.info(\"{} subcluster active, {} subclusters active and enabled\",\n          activeSubclusters.size(), activeAndEnabledSC.size());\n\n      // pre-compute the set of subclusters that are both active and enabled by\n      // the policy weights, and accumulate their total weight\n      for (SubClusterId sc : activeAndEnabledSC) {\n        totPolicyWeight +\u003d policyWeights.get(sc);\n      }\n\n      // pre-compute headroom-based weights for active/enabled subclusters\n      for (Map.Entry\u003cSubClusterId, Resource\u003e r : headroom.entrySet()) {\n        if (activeAndEnabledSC.contains(r.getKey())) {\n          totHeadroomMemory +\u003d r.getValue().getMemorySize();\n          totHeadRoomEnabledRMs++;\n        }\n      }\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/federation/policies/amrmproxy/LocalityMulticastAMRMProxyPolicy.java",
      "extendedDetails": {}
    },
    "8623644f4599f51d34ba79c4c1453b3997205d8f": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6190. Validation and synchronization fixes in LocalityMulticastAMRMProxyPolicy. (Botong Huang via curino)\n\n(cherry picked from commit 5c486961cd3a175b122ef86275c99b72964f2c50)\n",
      "commitDate": "01/08/17 5:28 PM",
      "commitName": "8623644f4599f51d34ba79c4c1453b3997205d8f",
      "commitAuthor": "Carlo Curino",
      "commitDateOld": "01/08/17 5:28 PM",
      "commitNameOld": "1dadd0b45a6a605da72eb304808edb49fc66da45",
      "commitAuthorOld": "Subru Krishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,43 @@\n     private void reinitialize(\n         Map\u003cSubClusterId, SubClusterInfo\u003e activeSubclusters)\n         throws YarnException {\n+      if (activeSubclusters \u003d\u003d null) {\n+        throw new YarnRuntimeException(\"null activeSubclusters received\");\n+      }\n \n       // reset data structures\n       answer.clear();\n       countContainersPerRM.clear();\n+      totNumLocalizedContainers.clear();\n       activeAndEnabledSC.clear();\n-      totNumLocalizedContainers \u003d 0;\n       totHeadroomMemory \u003d 0;\n       totHeadRoomEnabledRMs \u003d 0;\n+      // save the reference locally in case the weights get reinitialized\n+      // concurrently\n+      policyWeights \u003d weights;\n       totPolicyWeight \u003d 0;\n \n       // pre-compute the set of subclusters that are both active and enabled by\n       // the policy weights, and accumulate their total weight\n-      for (Map.Entry\u003cSubClusterId, Float\u003e entry : weights.entrySet()) {\n+      for (Map.Entry\u003cSubClusterId, Float\u003e entry : policyWeights.entrySet()) {\n         if (entry.getValue() \u003e 0\n             \u0026\u0026 activeSubclusters.containsKey(entry.getKey())) {\n           activeAndEnabledSC.add(entry.getKey());\n           totPolicyWeight +\u003d entry.getValue();\n         }\n       }\n \n       if (activeAndEnabledSC.size() \u003c 1) {\n         throw new NoActiveSubclustersException(\n             \"None of the subclusters enabled in this policy (weight\u003e0) are \"\n                 + \"currently active we cannot forward the ResourceRequest(s)\");\n       }\n \n       // pre-compute headroom-based weights for active/enabled subclusters\n       for (Map.Entry\u003cSubClusterId, Resource\u003e r : headroom.entrySet()) {\n         if (activeAndEnabledSC.contains(r.getKey())) {\n           totHeadroomMemory +\u003d r.getValue().getMemorySize();\n           totHeadRoomEnabledRMs++;\n         }\n       }\n-\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void reinitialize(\n        Map\u003cSubClusterId, SubClusterInfo\u003e activeSubclusters)\n        throws YarnException {\n      if (activeSubclusters \u003d\u003d null) {\n        throw new YarnRuntimeException(\"null activeSubclusters received\");\n      }\n\n      // reset data structures\n      answer.clear();\n      countContainersPerRM.clear();\n      totNumLocalizedContainers.clear();\n      activeAndEnabledSC.clear();\n      totHeadroomMemory \u003d 0;\n      totHeadRoomEnabledRMs \u003d 0;\n      // save the reference locally in case the weights get reinitialized\n      // concurrently\n      policyWeights \u003d weights;\n      totPolicyWeight \u003d 0;\n\n      // pre-compute the set of subclusters that are both active and enabled by\n      // the policy weights, and accumulate their total weight\n      for (Map.Entry\u003cSubClusterId, Float\u003e entry : policyWeights.entrySet()) {\n        if (entry.getValue() \u003e 0\n            \u0026\u0026 activeSubclusters.containsKey(entry.getKey())) {\n          activeAndEnabledSC.add(entry.getKey());\n          totPolicyWeight +\u003d entry.getValue();\n        }\n      }\n\n      if (activeAndEnabledSC.size() \u003c 1) {\n        throw new NoActiveSubclustersException(\n            \"None of the subclusters enabled in this policy (weight\u003e0) are \"\n                + \"currently active we cannot forward the ResourceRequest(s)\");\n      }\n\n      // pre-compute headroom-based weights for active/enabled subclusters\n      for (Map.Entry\u003cSubClusterId, Resource\u003e r : headroom.entrySet()) {\n        if (activeAndEnabledSC.contains(r.getKey())) {\n          totHeadroomMemory +\u003d r.getValue().getMemorySize();\n          totHeadRoomEnabledRMs++;\n        }\n      }\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/federation/policies/amrmproxy/LocalityMulticastAMRMProxyPolicy.java",
      "extendedDetails": {}
    },
    "1dadd0b45a6a605da72eb304808edb49fc66da45": {
      "type": "Yintroduced",
      "commitMessage": "YARN-5325. Stateless ARMRMProxy policies implementation. (Carlo Curino via Subru).\n\n(cherry picked from commit 11c5336522d3504598fb94eee288d54df73418c6)\n",
      "commitDate": "01/08/17 5:28 PM",
      "commitName": "1dadd0b45a6a605da72eb304808edb49fc66da45",
      "commitAuthor": "Subru Krishnan",
      "diff": "@@ -0,0 +1,38 @@\n+    private void reinitialize(\n+        Map\u003cSubClusterId, SubClusterInfo\u003e activeSubclusters)\n+        throws YarnException {\n+\n+      // reset data structures\n+      answer.clear();\n+      countContainersPerRM.clear();\n+      activeAndEnabledSC.clear();\n+      totNumLocalizedContainers \u003d 0;\n+      totHeadroomMemory \u003d 0;\n+      totHeadRoomEnabledRMs \u003d 0;\n+      totPolicyWeight \u003d 0;\n+\n+      // pre-compute the set of subclusters that are both active and enabled by\n+      // the policy weights, and accumulate their total weight\n+      for (Map.Entry\u003cSubClusterId, Float\u003e entry : weights.entrySet()) {\n+        if (entry.getValue() \u003e 0\n+            \u0026\u0026 activeSubclusters.containsKey(entry.getKey())) {\n+          activeAndEnabledSC.add(entry.getKey());\n+          totPolicyWeight +\u003d entry.getValue();\n+        }\n+      }\n+\n+      if (activeAndEnabledSC.size() \u003c 1) {\n+        throw new NoActiveSubclustersException(\n+            \"None of the subclusters enabled in this policy (weight\u003e0) are \"\n+                + \"currently active we cannot forward the ResourceRequest(s)\");\n+      }\n+\n+      // pre-compute headroom-based weights for active/enabled subclusters\n+      for (Map.Entry\u003cSubClusterId, Resource\u003e r : headroom.entrySet()) {\n+        if (activeAndEnabledSC.contains(r.getKey())) {\n+          totHeadroomMemory +\u003d r.getValue().getMemorySize();\n+          totHeadRoomEnabledRMs++;\n+        }\n+      }\n+\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private void reinitialize(\n        Map\u003cSubClusterId, SubClusterInfo\u003e activeSubclusters)\n        throws YarnException {\n\n      // reset data structures\n      answer.clear();\n      countContainersPerRM.clear();\n      activeAndEnabledSC.clear();\n      totNumLocalizedContainers \u003d 0;\n      totHeadroomMemory \u003d 0;\n      totHeadRoomEnabledRMs \u003d 0;\n      totPolicyWeight \u003d 0;\n\n      // pre-compute the set of subclusters that are both active and enabled by\n      // the policy weights, and accumulate their total weight\n      for (Map.Entry\u003cSubClusterId, Float\u003e entry : weights.entrySet()) {\n        if (entry.getValue() \u003e 0\n            \u0026\u0026 activeSubclusters.containsKey(entry.getKey())) {\n          activeAndEnabledSC.add(entry.getKey());\n          totPolicyWeight +\u003d entry.getValue();\n        }\n      }\n\n      if (activeAndEnabledSC.size() \u003c 1) {\n        throw new NoActiveSubclustersException(\n            \"None of the subclusters enabled in this policy (weight\u003e0) are \"\n                + \"currently active we cannot forward the ResourceRequest(s)\");\n      }\n\n      // pre-compute headroom-based weights for active/enabled subclusters\n      for (Map.Entry\u003cSubClusterId, Resource\u003e r : headroom.entrySet()) {\n        if (activeAndEnabledSC.contains(r.getKey())) {\n          totHeadroomMemory +\u003d r.getValue().getMemorySize();\n          totHeadRoomEnabledRMs++;\n        }\n      }\n\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/federation/policies/amrmproxy/LocalityMulticastAMRMProxyPolicy.java"
    }
  }
}