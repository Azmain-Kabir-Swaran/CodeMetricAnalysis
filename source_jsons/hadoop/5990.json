{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NamenodeFsck.java",
  "functionName": "printDatanodeReplicaStatus",
  "functionId": "printDatanodeReplicaStatus___block-Block__corruptionRecord-Collection__DatanodeDescriptor____dn-DatanodeDescriptor",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
  "functionStartLine": 347,
  "functionEndLine": 366,
  "numCommitsSeen": 120,
  "timeTaken": 1050,
  "changeHistory": [
    "7806403842ddd0f5b339e3dca42688b970cae267"
  ],
  "changeHistoryShort": {
    "7806403842ddd0f5b339e3dca42688b970cae267": "Yintroduced"
  },
  "changeHistoryDetails": {
    "7806403842ddd0f5b339e3dca42688b970cae267": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-14266. EC : Fsck -blockId shows null for EC Blocks if One Block Is Not Available. Contributed by Ayush Saxena.\n",
      "commitDate": "12/02/19 8:27 AM",
      "commitName": "7806403842ddd0f5b339e3dca42688b970cae267",
      "commitAuthor": "Vinayakumar B",
      "diff": "@@ -0,0 +1,20 @@\n+  private void printDatanodeReplicaStatus(Block block,\n+      Collection\u003cDatanodeDescriptor\u003e corruptionRecord, DatanodeDescriptor dn) {\n+    out.print(\"Block replica on datanode/rack: \" + dn.getHostName() +\n+        dn.getNetworkLocation() + \" \");\n+    if (corruptionRecord !\u003d null \u0026\u0026 corruptionRecord.contains(dn)) {\n+      out.print(CORRUPT_STATUS + \"\\t ReasonCode: \" +\n+          blockManager.getCorruptReason(block, dn));\n+    } else if (dn.isDecommissioned()){\n+      out.print(DECOMMISSIONED_STATUS);\n+    } else if (dn.isDecommissionInProgress()) {\n+      out.print(DECOMMISSIONING_STATUS);\n+    } else if (this.showMaintenanceState \u0026\u0026 dn.isEnteringMaintenance()) {\n+      out.print(ENTERING_MAINTENANCE_STATUS);\n+    } else if (this.showMaintenanceState \u0026\u0026 dn.isInMaintenance()) {\n+      out.print(IN_MAINTENANCE_STATUS);\n+    } else {\n+      out.print(HEALTHY_STATUS);\n+    }\n+    out.print(\"\\n\");\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void printDatanodeReplicaStatus(Block block,\n      Collection\u003cDatanodeDescriptor\u003e corruptionRecord, DatanodeDescriptor dn) {\n    out.print(\"Block replica on datanode/rack: \" + dn.getHostName() +\n        dn.getNetworkLocation() + \" \");\n    if (corruptionRecord !\u003d null \u0026\u0026 corruptionRecord.contains(dn)) {\n      out.print(CORRUPT_STATUS + \"\\t ReasonCode: \" +\n          blockManager.getCorruptReason(block, dn));\n    } else if (dn.isDecommissioned()){\n      out.print(DECOMMISSIONED_STATUS);\n    } else if (dn.isDecommissionInProgress()) {\n      out.print(DECOMMISSIONING_STATUS);\n    } else if (this.showMaintenanceState \u0026\u0026 dn.isEnteringMaintenance()) {\n      out.print(ENTERING_MAINTENANCE_STATUS);\n    } else if (this.showMaintenanceState \u0026\u0026 dn.isInMaintenance()) {\n      out.print(IN_MAINTENANCE_STATUS);\n    } else {\n      out.print(HEALTHY_STATUS);\n    }\n    out.print(\"\\n\");\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java"
    }
  }
}