{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "invalidateWorkForOneNode",
  "functionId": "invalidateWorkForOneNode___dn-DatanodeInfo",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 4672,
  "functionEndLine": 4704,
  "numCommitsSeen": 638,
  "timeTaken": 20939,
  "changeHistory": [
    "a7f085d6bf499edf23e650a4f7211c53a442da0e",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
    "d311a38a6b32bbb210bd8748cfb65463e9c0740e",
    "3ae38ec7dfa1aaf451cf889cec6cf862379af32a",
    "406c09ad1150c4971c2b7675fcb0263d40517fbf",
    "9a0fcae5bc9e481201e101c3c98e23b6e827774e",
    "db71de2e11cfa56a254ef4c92fea5ef4f8c19100",
    "b7887f31fbe28d35005abdc439b2771b58c91225",
    "31c91706f7d17da006ef2d6c541f8dd092fae077",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "513f17d115564e49124bb744cecf36d16a144ffc",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "cc875f0124d1951a4aab0565442242dac3dd35c8",
    "969a263188f7015261719fe45fa1505121ebb80e",
    "09b6f98de431628c80bc8a6faf0070eeaf72ff2a",
    "97b6ca4dd7d1233e8f8c90b1c01e47228c044e13",
    "1bcfe45e47775b98cce5541f328c4fd46e5eb13d",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "a7f085d6bf499edf23e650a4f7211c53a442da0e": "Ybodychange",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": "Ybodychange",
    "d311a38a6b32bbb210bd8748cfb65463e9c0740e": "Ybodychange",
    "3ae38ec7dfa1aaf451cf889cec6cf862379af32a": "Ybodychange",
    "406c09ad1150c4971c2b7675fcb0263d40517fbf": "Ybodychange",
    "9a0fcae5bc9e481201e101c3c98e23b6e827774e": "Ymultichange(Yparameterchange,Ybodychange)",
    "db71de2e11cfa56a254ef4c92fea5ef4f8c19100": "Ybodychange",
    "b7887f31fbe28d35005abdc439b2771b58c91225": "Ybodychange",
    "31c91706f7d17da006ef2d6c541f8dd092fae077": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "513f17d115564e49124bb744cecf36d16a144ffc": "Ybodychange",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "cc875f0124d1951a4aab0565442242dac3dd35c8": "Ybodychange",
    "969a263188f7015261719fe45fa1505121ebb80e": "Ybodychange",
    "09b6f98de431628c80bc8a6faf0070eeaf72ff2a": "Yfilerename",
    "97b6ca4dd7d1233e8f8c90b1c01e47228c044e13": "Yfilerename",
    "1bcfe45e47775b98cce5541f328c4fd46e5eb13d": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "a7f085d6bf499edf23e650a4f7211c53a442da0e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11832. Switch leftover logs to slf4j format in BlockManager.java. Contributed by Hui Xu and Chen Liang.\n",
      "commitDate": "29/05/17 1:30 AM",
      "commitName": "a7f085d6bf499edf23e650a4f7211c53a442da0e",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "25/05/17 7:35 AM",
      "commitNameOld": "2e41f8803dd46d1bab16c1b206c71be72ea260a1",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 3.75,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,33 @@\n   private int invalidateWorkForOneNode(DatanodeInfo dn) {\n     final List\u003cBlock\u003e toInvalidate;\n     \n     namesystem.writeLock();\n     try {\n       // blocks should not be replicated or removed if safe mode is on\n       if (namesystem.isInSafeMode()) {\n         LOG.debug(\"In safemode, not computing reconstruction work\");\n         return 0;\n       }\n       try {\n         DatanodeDescriptor dnDescriptor \u003d datanodeManager.getDatanode(dn);\n         if (dnDescriptor \u003d\u003d null) {\n-          LOG.warn(\"DataNode \" + dn + \" cannot be found with UUID \" +\n-              dn.getDatanodeUuid() + \", removing block invalidation work.\");\n+          LOG.warn(\"DataNode {} cannot be found with UUID {}\" +\n+              \", removing block invalidation work.\", dn, dn.getDatanodeUuid());\n           invalidateBlocks.remove(dn);\n           return 0;\n         }\n         toInvalidate \u003d invalidateBlocks.invalidateWork(dnDescriptor);\n         \n         if (toInvalidate \u003d\u003d null) {\n           return 0;\n         }\n       } catch(UnregisteredNodeException une) {\n         return 0;\n       }\n     } finally {\n       namesystem.writeUnlock();\n     }\n     blockLog.debug(\"BLOCK* {}: ask {} to delete {}\", getClass().getSimpleName(),\n         dn, toInvalidate);\n     return toInvalidate.size();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int invalidateWorkForOneNode(DatanodeInfo dn) {\n    final List\u003cBlock\u003e toInvalidate;\n    \n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode()) {\n        LOG.debug(\"In safemode, not computing reconstruction work\");\n        return 0;\n      }\n      try {\n        DatanodeDescriptor dnDescriptor \u003d datanodeManager.getDatanode(dn);\n        if (dnDescriptor \u003d\u003d null) {\n          LOG.warn(\"DataNode {} cannot be found with UUID {}\" +\n              \", removing block invalidation work.\", dn, dn.getDatanodeUuid());\n          invalidateBlocks.remove(dn);\n          return 0;\n        }\n        toInvalidate \u003d invalidateBlocks.invalidateWork(dnDescriptor);\n        \n        if (toInvalidate \u003d\u003d null) {\n          return 0;\n        }\n      } catch(UnregisteredNodeException une) {\n        return 0;\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n    blockLog.debug(\"BLOCK* {}: ask {} to delete {}\", getClass().getSimpleName(),\n        dn, toInvalidate);\n    return toInvalidate.size();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9857. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-1]. Contributed by Rakesh R.\n",
      "commitDate": "16/03/16 4:53 PM",
      "commitName": "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "10/03/16 7:03 PM",
      "commitNameOld": "e01c6ea688e62f25c4310e771a0cd85b53a5fb87",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 5.87,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,33 @@\n   private int invalidateWorkForOneNode(DatanodeInfo dn) {\n     final List\u003cBlock\u003e toInvalidate;\n     \n     namesystem.writeLock();\n     try {\n       // blocks should not be replicated or removed if safe mode is on\n       if (namesystem.isInSafeMode()) {\n-        LOG.debug(\"In safemode, not computing replication work\");\n+        LOG.debug(\"In safemode, not computing reconstruction work\");\n         return 0;\n       }\n       try {\n         DatanodeDescriptor dnDescriptor \u003d datanodeManager.getDatanode(dn);\n         if (dnDescriptor \u003d\u003d null) {\n           LOG.warn(\"DataNode \" + dn + \" cannot be found with UUID \" +\n               dn.getDatanodeUuid() + \", removing block invalidation work.\");\n           invalidateBlocks.remove(dn);\n           return 0;\n         }\n         toInvalidate \u003d invalidateBlocks.invalidateWork(dnDescriptor);\n         \n         if (toInvalidate \u003d\u003d null) {\n           return 0;\n         }\n       } catch(UnregisteredNodeException une) {\n         return 0;\n       }\n     } finally {\n       namesystem.writeUnlock();\n     }\n     blockLog.debug(\"BLOCK* {}: ask {} to delete {}\", getClass().getSimpleName(),\n         dn, toInvalidate);\n     return toInvalidate.size();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int invalidateWorkForOneNode(DatanodeInfo dn) {\n    final List\u003cBlock\u003e toInvalidate;\n    \n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode()) {\n        LOG.debug(\"In safemode, not computing reconstruction work\");\n        return 0;\n      }\n      try {\n        DatanodeDescriptor dnDescriptor \u003d datanodeManager.getDatanode(dn);\n        if (dnDescriptor \u003d\u003d null) {\n          LOG.warn(\"DataNode \" + dn + \" cannot be found with UUID \" +\n              dn.getDatanodeUuid() + \", removing block invalidation work.\");\n          invalidateBlocks.remove(dn);\n          return 0;\n        }\n        toInvalidate \u003d invalidateBlocks.invalidateWork(dnDescriptor);\n        \n        if (toInvalidate \u003d\u003d null) {\n          return 0;\n        }\n      } catch(UnregisteredNodeException une) {\n        return 0;\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n    blockLog.debug(\"BLOCK* {}: ask {} to delete {}\", getClass().getSimpleName(),\n        dn, toInvalidate);\n    return toInvalidate.size();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "d311a38a6b32bbb210bd8748cfb65463e9c0740e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6860. BlockStateChange logs are too noisy. Contributed by Chang Li and Xiaoyu Yao.\n",
      "commitDate": "31/07/15 4:15 PM",
      "commitName": "d311a38a6b32bbb210bd8748cfb65463e9c0740e",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "29/07/15 12:48 AM",
      "commitNameOld": "2a1d656196cf9750fa482cb10893684e8a2ce7c3",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 2.64,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,33 @@\n   private int invalidateWorkForOneNode(DatanodeInfo dn) {\n     final List\u003cBlock\u003e toInvalidate;\n     \n     namesystem.writeLock();\n     try {\n       // blocks should not be replicated or removed if safe mode is on\n       if (namesystem.isInSafeMode()) {\n         LOG.debug(\"In safemode, not computing replication work\");\n         return 0;\n       }\n       try {\n         DatanodeDescriptor dnDescriptor \u003d datanodeManager.getDatanode(dn);\n         if (dnDescriptor \u003d\u003d null) {\n           LOG.warn(\"DataNode \" + dn + \" cannot be found with UUID \" +\n               dn.getDatanodeUuid() + \", removing block invalidation work.\");\n           invalidateBlocks.remove(dn);\n           return 0;\n         }\n         toInvalidate \u003d invalidateBlocks.invalidateWork(dnDescriptor);\n         \n         if (toInvalidate \u003d\u003d null) {\n           return 0;\n         }\n       } catch(UnregisteredNodeException une) {\n         return 0;\n       }\n     } finally {\n       namesystem.writeUnlock();\n     }\n-    blockLog.info(\"BLOCK* {}: ask {} to delete {}\", getClass().getSimpleName(),\n+    blockLog.debug(\"BLOCK* {}: ask {} to delete {}\", getClass().getSimpleName(),\n         dn, toInvalidate);\n     return toInvalidate.size();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int invalidateWorkForOneNode(DatanodeInfo dn) {\n    final List\u003cBlock\u003e toInvalidate;\n    \n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode()) {\n        LOG.debug(\"In safemode, not computing replication work\");\n        return 0;\n      }\n      try {\n        DatanodeDescriptor dnDescriptor \u003d datanodeManager.getDatanode(dn);\n        if (dnDescriptor \u003d\u003d null) {\n          LOG.warn(\"DataNode \" + dn + \" cannot be found with UUID \" +\n              dn.getDatanodeUuid() + \", removing block invalidation work.\");\n          invalidateBlocks.remove(dn);\n          return 0;\n        }\n        toInvalidate \u003d invalidateBlocks.invalidateWork(dnDescriptor);\n        \n        if (toInvalidate \u003d\u003d null) {\n          return 0;\n        }\n      } catch(UnregisteredNodeException une) {\n        return 0;\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n    blockLog.debug(\"BLOCK* {}: ask {} to delete {}\", getClass().getSimpleName(),\n        dn, toInvalidate);\n    return toInvalidate.size();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "3ae38ec7dfa1aaf451cf889cec6cf862379af32a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7712. Switch blockStateChangeLog to use slf4j.\n",
      "commitDate": "03/02/15 3:01 PM",
      "commitName": "3ae38ec7dfa1aaf451cf889cec6cf862379af32a",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "30/01/15 11:33 AM",
      "commitNameOld": "951b3608a8cb1d9063b9be9c740b524c137b816f",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 4.14,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,33 @@\n   private int invalidateWorkForOneNode(DatanodeInfo dn) {\n     final List\u003cBlock\u003e toInvalidate;\n     \n     namesystem.writeLock();\n     try {\n       // blocks should not be replicated or removed if safe mode is on\n       if (namesystem.isInSafeMode()) {\n         LOG.debug(\"In safemode, not computing replication work\");\n         return 0;\n       }\n       try {\n         DatanodeDescriptor dnDescriptor \u003d datanodeManager.getDatanode(dn);\n         if (dnDescriptor \u003d\u003d null) {\n           LOG.warn(\"DataNode \" + dn + \" cannot be found with UUID \" +\n               dn.getDatanodeUuid() + \", removing block invalidation work.\");\n           invalidateBlocks.remove(dn);\n           return 0;\n         }\n         toInvalidate \u003d invalidateBlocks.invalidateWork(dnDescriptor);\n         \n         if (toInvalidate \u003d\u003d null) {\n           return 0;\n         }\n       } catch(UnregisteredNodeException une) {\n         return 0;\n       }\n     } finally {\n       namesystem.writeUnlock();\n     }\n-    if (blockLog.isInfoEnabled()) {\n-      blockLog.info(\"BLOCK* \" + getClass().getSimpleName()\n-          + \": ask \" + dn + \" to delete \" + toInvalidate);\n-    }\n+    blockLog.info(\"BLOCK* {}: ask {} to delete {}\", getClass().getSimpleName(),\n+        dn, toInvalidate);\n     return toInvalidate.size();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int invalidateWorkForOneNode(DatanodeInfo dn) {\n    final List\u003cBlock\u003e toInvalidate;\n    \n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode()) {\n        LOG.debug(\"In safemode, not computing replication work\");\n        return 0;\n      }\n      try {\n        DatanodeDescriptor dnDescriptor \u003d datanodeManager.getDatanode(dn);\n        if (dnDescriptor \u003d\u003d null) {\n          LOG.warn(\"DataNode \" + dn + \" cannot be found with UUID \" +\n              dn.getDatanodeUuid() + \", removing block invalidation work.\");\n          invalidateBlocks.remove(dn);\n          return 0;\n        }\n        toInvalidate \u003d invalidateBlocks.invalidateWork(dnDescriptor);\n        \n        if (toInvalidate \u003d\u003d null) {\n          return 0;\n        }\n      } catch(UnregisteredNodeException une) {\n        return 0;\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n    blockLog.info(\"BLOCK* {}: ask {} to delete {}\", getClass().getSimpleName(),\n        dn, toInvalidate);\n    return toInvalidate.size();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "406c09ad1150c4971c2b7675fcb0263d40517fbf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7225. Remove stale block invalidation work when DN re-registers with different UUID. (Zhe Zhang and Andrew Wang)\n",
      "commitDate": "18/11/14 10:14 PM",
      "commitName": "406c09ad1150c4971c2b7675fcb0263d40517fbf",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "11/11/14 6:22 PM",
      "commitNameOld": "46f6f9d60d0a2c1f441a0e81a071b08c24dbd6d6",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 7.16,
      "commitsBetweenForRepo": 62,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,35 @@\n   private int invalidateWorkForOneNode(DatanodeInfo dn) {\n     final List\u003cBlock\u003e toInvalidate;\n     \n     namesystem.writeLock();\n     try {\n       // blocks should not be replicated or removed if safe mode is on\n       if (namesystem.isInSafeMode()) {\n         LOG.debug(\"In safemode, not computing replication work\");\n         return 0;\n       }\n       try {\n-        toInvalidate \u003d invalidateBlocks.invalidateWork(datanodeManager.getDatanode(dn));\n+        DatanodeDescriptor dnDescriptor \u003d datanodeManager.getDatanode(dn);\n+        if (dnDescriptor \u003d\u003d null) {\n+          LOG.warn(\"DataNode \" + dn + \" cannot be found with UUID \" +\n+              dn.getDatanodeUuid() + \", removing block invalidation work.\");\n+          invalidateBlocks.remove(dn);\n+          return 0;\n+        }\n+        toInvalidate \u003d invalidateBlocks.invalidateWork(dnDescriptor);\n         \n         if (toInvalidate \u003d\u003d null) {\n           return 0;\n         }\n       } catch(UnregisteredNodeException une) {\n         return 0;\n       }\n     } finally {\n       namesystem.writeUnlock();\n     }\n     if (blockLog.isInfoEnabled()) {\n       blockLog.info(\"BLOCK* \" + getClass().getSimpleName()\n           + \": ask \" + dn + \" to delete \" + toInvalidate);\n     }\n     return toInvalidate.size();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int invalidateWorkForOneNode(DatanodeInfo dn) {\n    final List\u003cBlock\u003e toInvalidate;\n    \n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode()) {\n        LOG.debug(\"In safemode, not computing replication work\");\n        return 0;\n      }\n      try {\n        DatanodeDescriptor dnDescriptor \u003d datanodeManager.getDatanode(dn);\n        if (dnDescriptor \u003d\u003d null) {\n          LOG.warn(\"DataNode \" + dn + \" cannot be found with UUID \" +\n              dn.getDatanodeUuid() + \", removing block invalidation work.\");\n          invalidateBlocks.remove(dn);\n          return 0;\n        }\n        toInvalidate \u003d invalidateBlocks.invalidateWork(dnDescriptor);\n        \n        if (toInvalidate \u003d\u003d null) {\n          return 0;\n        }\n      } catch(UnregisteredNodeException une) {\n        return 0;\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n    if (blockLog.isInfoEnabled()) {\n      blockLog.info(\"BLOCK* \" + getClass().getSimpleName()\n          + \": ask \" + dn + \" to delete \" + toInvalidate);\n    }\n    return toInvalidate.size();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "9a0fcae5bc9e481201e101c3c98e23b6e827774e": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6362. InvalidateBlocks is inconsistent in usage of DatanodeUuid and StorageID. (Arpit Agarwal)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1595056 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/05/14 2:30 PM",
      "commitName": "9a0fcae5bc9e481201e101c3c98e23b6e827774e",
      "commitAuthor": "Arpit Agarwal",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6362. InvalidateBlocks is inconsistent in usage of DatanodeUuid and StorageID. (Arpit Agarwal)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1595056 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "15/05/14 2:30 PM",
          "commitName": "9a0fcae5bc9e481201e101c3c98e23b6e827774e",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "13/05/14 11:22 AM",
          "commitNameOld": "8e5b5165c14486af6d5d73e7b4e591d4787ad8f2",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 2.13,
          "commitsBetweenForRepo": 24,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,31 +1,28 @@\n-  private int invalidateWorkForOneNode(String nodeId) {\n+  private int invalidateWorkForOneNode(DatanodeInfo dn) {\n     final List\u003cBlock\u003e toInvalidate;\n-    final DatanodeDescriptor dn;\n     \n     namesystem.writeLock();\n     try {\n       // blocks should not be replicated or removed if safe mode is on\n       if (namesystem.isInSafeMode()) {\n         LOG.debug(\"In safemode, not computing replication work\");\n         return 0;\n       }\n-      // get blocks to invalidate for the nodeId\n-      assert nodeId !\u003d null;\n-      dn \u003d datanodeManager.getDatanode(nodeId);\n-      if (dn \u003d\u003d null) {\n-        invalidateBlocks.remove(nodeId);\n-        return 0;\n-      }\n-      toInvalidate \u003d invalidateBlocks.invalidateWork(nodeId, dn);\n-      if (toInvalidate \u003d\u003d null) {\n+      try {\n+        toInvalidate \u003d invalidateBlocks.invalidateWork(datanodeManager.getDatanode(dn));\n+        \n+        if (toInvalidate \u003d\u003d null) {\n+          return 0;\n+        }\n+      } catch(UnregisteredNodeException une) {\n         return 0;\n       }\n     } finally {\n       namesystem.writeUnlock();\n     }\n     if (blockLog.isInfoEnabled()) {\n       blockLog.info(\"BLOCK* \" + getClass().getSimpleName()\n           + \": ask \" + dn + \" to delete \" + toInvalidate);\n     }\n     return toInvalidate.size();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int invalidateWorkForOneNode(DatanodeInfo dn) {\n    final List\u003cBlock\u003e toInvalidate;\n    \n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode()) {\n        LOG.debug(\"In safemode, not computing replication work\");\n        return 0;\n      }\n      try {\n        toInvalidate \u003d invalidateBlocks.invalidateWork(datanodeManager.getDatanode(dn));\n        \n        if (toInvalidate \u003d\u003d null) {\n          return 0;\n        }\n      } catch(UnregisteredNodeException une) {\n        return 0;\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n    if (blockLog.isInfoEnabled()) {\n      blockLog.info(\"BLOCK* \" + getClass().getSimpleName()\n          + \": ask \" + dn + \" to delete \" + toInvalidate);\n    }\n    return toInvalidate.size();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "[nodeId-String]",
            "newValue": "[dn-DatanodeInfo]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6362. InvalidateBlocks is inconsistent in usage of DatanodeUuid and StorageID. (Arpit Agarwal)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1595056 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "15/05/14 2:30 PM",
          "commitName": "9a0fcae5bc9e481201e101c3c98e23b6e827774e",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "13/05/14 11:22 AM",
          "commitNameOld": "8e5b5165c14486af6d5d73e7b4e591d4787ad8f2",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 2.13,
          "commitsBetweenForRepo": 24,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,31 +1,28 @@\n-  private int invalidateWorkForOneNode(String nodeId) {\n+  private int invalidateWorkForOneNode(DatanodeInfo dn) {\n     final List\u003cBlock\u003e toInvalidate;\n-    final DatanodeDescriptor dn;\n     \n     namesystem.writeLock();\n     try {\n       // blocks should not be replicated or removed if safe mode is on\n       if (namesystem.isInSafeMode()) {\n         LOG.debug(\"In safemode, not computing replication work\");\n         return 0;\n       }\n-      // get blocks to invalidate for the nodeId\n-      assert nodeId !\u003d null;\n-      dn \u003d datanodeManager.getDatanode(nodeId);\n-      if (dn \u003d\u003d null) {\n-        invalidateBlocks.remove(nodeId);\n-        return 0;\n-      }\n-      toInvalidate \u003d invalidateBlocks.invalidateWork(nodeId, dn);\n-      if (toInvalidate \u003d\u003d null) {\n+      try {\n+        toInvalidate \u003d invalidateBlocks.invalidateWork(datanodeManager.getDatanode(dn));\n+        \n+        if (toInvalidate \u003d\u003d null) {\n+          return 0;\n+        }\n+      } catch(UnregisteredNodeException une) {\n         return 0;\n       }\n     } finally {\n       namesystem.writeUnlock();\n     }\n     if (blockLog.isInfoEnabled()) {\n       blockLog.info(\"BLOCK* \" + getClass().getSimpleName()\n           + \": ask \" + dn + \" to delete \" + toInvalidate);\n     }\n     return toInvalidate.size();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int invalidateWorkForOneNode(DatanodeInfo dn) {\n    final List\u003cBlock\u003e toInvalidate;\n    \n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode()) {\n        LOG.debug(\"In safemode, not computing replication work\");\n        return 0;\n      }\n      try {\n        toInvalidate \u003d invalidateBlocks.invalidateWork(datanodeManager.getDatanode(dn));\n        \n        if (toInvalidate \u003d\u003d null) {\n          return 0;\n        }\n      } catch(UnregisteredNodeException une) {\n        return 0;\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n    if (blockLog.isInfoEnabled()) {\n      blockLog.info(\"BLOCK* \" + getClass().getSimpleName()\n          + \": ask \" + dn + \" to delete \" + toInvalidate);\n    }\n    return toInvalidate.size();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "db71de2e11cfa56a254ef4c92fea5ef4f8c19100": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4080. Add a separate logger for block state change logs to enable turning off those logs. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1407566 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/11/12 10:07 AM",
      "commitName": "db71de2e11cfa56a254ef4c92fea5ef4f8c19100",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "06/11/12 11:27 AM",
      "commitNameOld": "54b70db347c2ebf577919f2c42f171c6801e9ba1",
      "commitAuthorOld": "Daryn Sharp",
      "daysBetweenCommits": 2.94,
      "commitsBetweenForRepo": 28,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n   private int invalidateWorkForOneNode(String nodeId) {\n     final List\u003cBlock\u003e toInvalidate;\n     final DatanodeDescriptor dn;\n     \n     namesystem.writeLock();\n     try {\n       // blocks should not be replicated or removed if safe mode is on\n       if (namesystem.isInSafeMode()) {\n         LOG.debug(\"In safemode, not computing replication work\");\n         return 0;\n       }\n       // get blocks to invalidate for the nodeId\n       assert nodeId !\u003d null;\n       dn \u003d datanodeManager.getDatanode(nodeId);\n       if (dn \u003d\u003d null) {\n         invalidateBlocks.remove(nodeId);\n         return 0;\n       }\n       toInvalidate \u003d invalidateBlocks.invalidateWork(nodeId, dn);\n       if (toInvalidate \u003d\u003d null) {\n         return 0;\n       }\n     } finally {\n       namesystem.writeUnlock();\n     }\n-    if (NameNode.stateChangeLog.isInfoEnabled()) {\n-      NameNode.stateChangeLog.info(\"BLOCK* \" + getClass().getSimpleName()\n+    if (blockLog.isInfoEnabled()) {\n+      blockLog.info(\"BLOCK* \" + getClass().getSimpleName()\n           + \": ask \" + dn + \" to delete \" + toInvalidate);\n     }\n     return toInvalidate.size();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int invalidateWorkForOneNode(String nodeId) {\n    final List\u003cBlock\u003e toInvalidate;\n    final DatanodeDescriptor dn;\n    \n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode()) {\n        LOG.debug(\"In safemode, not computing replication work\");\n        return 0;\n      }\n      // get blocks to invalidate for the nodeId\n      assert nodeId !\u003d null;\n      dn \u003d datanodeManager.getDatanode(nodeId);\n      if (dn \u003d\u003d null) {\n        invalidateBlocks.remove(nodeId);\n        return 0;\n      }\n      toInvalidate \u003d invalidateBlocks.invalidateWork(nodeId, dn);\n      if (toInvalidate \u003d\u003d null) {\n        return 0;\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n    if (blockLog.isInfoEnabled()) {\n      blockLog.info(\"BLOCK* \" + getClass().getSimpleName()\n          + \": ask \" + dn + \" to delete \" + toInvalidate);\n    }\n    return toInvalidate.size();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "b7887f31fbe28d35005abdc439b2771b58c91225": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4052. BlockManager#invalidateWork should print log outside the lock. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1398631 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/10/12 8:37 PM",
      "commitName": "b7887f31fbe28d35005abdc439b2771b58c91225",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "15/10/12 6:48 AM",
      "commitNameOld": "ad06a087131d69d173d8e03dce5c97650a530f2e",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.58,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,31 @@\n   private int invalidateWorkForOneNode(String nodeId) {\n+    final List\u003cBlock\u003e toInvalidate;\n+    final DatanodeDescriptor dn;\n+    \n     namesystem.writeLock();\n     try {\n       // blocks should not be replicated or removed if safe mode is on\n       if (namesystem.isInSafeMode()) {\n         LOG.debug(\"In safemode, not computing replication work\");\n         return 0;\n       }\n       // get blocks to invalidate for the nodeId\n       assert nodeId !\u003d null;\n-      return invalidateBlocks.invalidateWork(nodeId);\n+      dn \u003d datanodeManager.getDatanode(nodeId);\n+      if (dn \u003d\u003d null) {\n+        invalidateBlocks.remove(nodeId);\n+        return 0;\n+      }\n+      toInvalidate \u003d invalidateBlocks.invalidateWork(nodeId, dn);\n+      if (toInvalidate \u003d\u003d null) {\n+        return 0;\n+      }\n     } finally {\n       namesystem.writeUnlock();\n     }\n+    if (NameNode.stateChangeLog.isInfoEnabled()) {\n+      NameNode.stateChangeLog.info(\"BLOCK* \" + getClass().getSimpleName()\n+          + \": ask \" + dn + \" to delete \" + toInvalidate);\n+    }\n+    return toInvalidate.size();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int invalidateWorkForOneNode(String nodeId) {\n    final List\u003cBlock\u003e toInvalidate;\n    final DatanodeDescriptor dn;\n    \n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode()) {\n        LOG.debug(\"In safemode, not computing replication work\");\n        return 0;\n      }\n      // get blocks to invalidate for the nodeId\n      assert nodeId !\u003d null;\n      dn \u003d datanodeManager.getDatanode(nodeId);\n      if (dn \u003d\u003d null) {\n        invalidateBlocks.remove(nodeId);\n        return 0;\n      }\n      toInvalidate \u003d invalidateBlocks.invalidateWork(nodeId, dn);\n      if (toInvalidate \u003d\u003d null) {\n        return 0;\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n    if (NameNode.stateChangeLog.isInfoEnabled()) {\n      NameNode.stateChangeLog.info(\"BLOCK* \" + getClass().getSimpleName()\n          + \": ask \" + dn + \" to delete \" + toInvalidate);\n    }\n    return toInvalidate.size();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "31c91706f7d17da006ef2d6c541f8dd092fae077": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1972. Fencing mechanism for block invalidations and replications. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1221608 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/12/11 8:32 PM",
      "commitName": "31c91706f7d17da006ef2d6c541f8dd092fae077",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "20/12/11 7:03 PM",
      "commitNameOld": "36d1c49486587c2dbb193e8538b1d4510c462fa6",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.06,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,15 @@\n   private int invalidateWorkForOneNode(String nodeId) {\n     namesystem.writeLock();\n     try {\n       // blocks should not be replicated or removed if safe mode is on\n-      if (namesystem.isInSafeMode())\n+      if (namesystem.isInSafeMode()) {\n+        LOG.debug(\"In safemode, not computing replication work\");\n         return 0;\n+      }\n       // get blocks to invalidate for the nodeId\n       assert nodeId !\u003d null;\n       return invalidateBlocks.invalidateWork(nodeId);\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int invalidateWorkForOneNode(String nodeId) {\n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode()) {\n        LOG.debug(\"In safemode, not computing replication work\");\n        return 0;\n      }\n      // get blocks to invalidate for the nodeId\n      assert nodeId !\u003d null;\n      return invalidateBlocks.invalidateWork(nodeId);\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private int invalidateWorkForOneNode(String nodeId) {\n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode())\n        return 0;\n      // get blocks to invalidate for the nodeId\n      assert nodeId !\u003d null;\n      return invalidateBlocks.invalidateWork(nodeId);\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
      }
    },
    "513f17d115564e49124bb744cecf36d16a144ffc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2273.  Refactor BlockManager.recentInvalidateSets to a new class.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1160475 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/08/11 3:28 PM",
      "commitName": "513f17d115564e49124bb744cecf36d16a144ffc",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "19/08/11 10:36 AM",
      "commitNameOld": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 3.2,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,55 +1,13 @@\n   private int invalidateWorkForOneNode(String nodeId) {\n     namesystem.writeLock();\n     try {\n       // blocks should not be replicated or removed if safe mode is on\n       if (namesystem.isInSafeMode())\n         return 0;\n       // get blocks to invalidate for the nodeId\n       assert nodeId !\u003d null;\n-      final DatanodeDescriptor dn \u003d datanodeManager.getDatanode(nodeId);\n-      if (dn \u003d\u003d null) {\n-        removeFromInvalidates(nodeId);\n-        return 0;\n-      }\n-\n-      Collection\u003cBlock\u003e invalidateSet;\n-      ArrayList\u003cBlock\u003e blocksToInvalidate;\n-      synchronized(recentInvalidateSets) {\n-        invalidateSet \u003d recentInvalidateSets.get(nodeId);\n-        if (invalidateSet \u003d\u003d null)\n-          return 0;\n-\n-        blocksToInvalidate \u003d new ArrayList\u003cBlock\u003e(\n-          getDatanodeManager().blockInvalidateLimit);\n-\n-        // # blocks that can be sent in one message is limited\n-        Iterator\u003cBlock\u003e it \u003d invalidateSet.iterator();\n-        for (int blkCount \u003d 0; blkCount \u003c getDatanodeManager().blockInvalidateLimit\n-            \u0026\u0026 it.hasNext(); blkCount++) {\n-          blocksToInvalidate.add(it.next());\n-          it.remove();\n-        }\n-\n-        // If we send everything in this message, remove this node entry\n-        if (!it.hasNext()) {\n-          removeFromInvalidates(nodeId);\n-        }\n-\n-        dn.addBlocksToBeInvalidated(blocksToInvalidate);\n-\n-        if (NameNode.stateChangeLog.isInfoEnabled()) {\n-          StringBuilder blockList \u003d new StringBuilder();\n-          for (Block blk : blocksToInvalidate) {\n-            blockList.append(\u0027 \u0027);\n-            blockList.append(blk);\n-          }\n-          NameNode.stateChangeLog.info(\"BLOCK* ask \" + dn.getName()\n-              + \" to delete \" + blockList);\n-        }\n-        pendingDeletionBlocksCount -\u003d blocksToInvalidate.size();\n-        return blocksToInvalidate.size();\n-      }\n+      return invalidateBlocks.invalidateWork(nodeId);\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int invalidateWorkForOneNode(String nodeId) {\n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode())\n        return 0;\n      // get blocks to invalidate for the nodeId\n      assert nodeId !\u003d null;\n      return invalidateBlocks.invalidateWork(nodeId);\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private int invalidateWorkForOneNode(String nodeId) {\n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode())\n        return 0;\n      // get blocks to invalidate for the nodeId\n      assert nodeId !\u003d null;\n      final DatanodeDescriptor dn \u003d datanodeManager.getDatanode(nodeId);\n      if (dn \u003d\u003d null) {\n        removeFromInvalidates(nodeId);\n        return 0;\n      }\n\n      Collection\u003cBlock\u003e invalidateSet;\n      ArrayList\u003cBlock\u003e blocksToInvalidate;\n      synchronized(recentInvalidateSets) {\n        invalidateSet \u003d recentInvalidateSets.get(nodeId);\n        if (invalidateSet \u003d\u003d null)\n          return 0;\n\n        blocksToInvalidate \u003d new ArrayList\u003cBlock\u003e(\n          getDatanodeManager().blockInvalidateLimit);\n\n        // # blocks that can be sent in one message is limited\n        Iterator\u003cBlock\u003e it \u003d invalidateSet.iterator();\n        for (int blkCount \u003d 0; blkCount \u003c getDatanodeManager().blockInvalidateLimit\n            \u0026\u0026 it.hasNext(); blkCount++) {\n          blocksToInvalidate.add(it.next());\n          it.remove();\n        }\n\n        // If we send everything in this message, remove this node entry\n        if (!it.hasNext()) {\n          removeFromInvalidates(nodeId);\n        }\n\n        dn.addBlocksToBeInvalidated(blocksToInvalidate);\n\n        if (NameNode.stateChangeLog.isInfoEnabled()) {\n          StringBuilder blockList \u003d new StringBuilder();\n          for (Block blk : blocksToInvalidate) {\n            blockList.append(\u0027 \u0027);\n            blockList.append(blk);\n          }\n          NameNode.stateChangeLog.info(\"BLOCK* ask \" + dn.getName()\n              + \" to delete \" + blockList);\n        }\n        pendingDeletionBlocksCount -\u003d blocksToInvalidate.size();\n        return blocksToInvalidate.size();\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
      }
    },
    "cc875f0124d1951a4aab0565442242dac3dd35c8": {
      "type": "Ybodychange",
      "commitMessage": "DFS-1257. Fix a race condition on BlockManager.recentInvalidateSets.  Contributed by Eric Payne\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1158933 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/08/11 3:00 PM",
      "commitName": "cc875f0124d1951a4aab0565442242dac3dd35c8",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "17/08/11 7:34 AM",
      "commitNameOld": "b0944651681337e81b41250f43bd1e8eebc78125",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.31,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,55 @@\n   private int invalidateWorkForOneNode(String nodeId) {\n     namesystem.writeLock();\n     try {\n       // blocks should not be replicated or removed if safe mode is on\n       if (namesystem.isInSafeMode())\n         return 0;\n       // get blocks to invalidate for the nodeId\n       assert nodeId !\u003d null;\n       final DatanodeDescriptor dn \u003d datanodeManager.getDatanode(nodeId);\n       if (dn \u003d\u003d null) {\n         removeFromInvalidates(nodeId);\n         return 0;\n       }\n \n-      Collection\u003cBlock\u003e invalidateSet \u003d recentInvalidateSets.get(nodeId);\n-      if (invalidateSet \u003d\u003d null)\n-        return 0;\n+      Collection\u003cBlock\u003e invalidateSet;\n+      ArrayList\u003cBlock\u003e blocksToInvalidate;\n+      synchronized(recentInvalidateSets) {\n+        invalidateSet \u003d recentInvalidateSets.get(nodeId);\n+        if (invalidateSet \u003d\u003d null)\n+          return 0;\n \n-      ArrayList\u003cBlock\u003e blocksToInvalidate \u003d new ArrayList\u003cBlock\u003e(\n+        blocksToInvalidate \u003d new ArrayList\u003cBlock\u003e(\n           getDatanodeManager().blockInvalidateLimit);\n \n-      // # blocks that can be sent in one message is limited\n-      Iterator\u003cBlock\u003e it \u003d invalidateSet.iterator();\n-      for (int blkCount \u003d 0; blkCount \u003c getDatanodeManager().blockInvalidateLimit\n-          \u0026\u0026 it.hasNext(); blkCount++) {\n-        blocksToInvalidate.add(it.next());\n-        it.remove();\n-      }\n-\n-      // If we send everything in this message, remove this node entry\n-      if (!it.hasNext()) {\n-        removeFromInvalidates(nodeId);\n-      }\n-\n-      dn.addBlocksToBeInvalidated(blocksToInvalidate);\n-\n-      if (NameNode.stateChangeLog.isInfoEnabled()) {\n-        StringBuilder blockList \u003d new StringBuilder();\n-        for (Block blk : blocksToInvalidate) {\n-          blockList.append(\u0027 \u0027);\n-          blockList.append(blk);\n+        // # blocks that can be sent in one message is limited\n+        Iterator\u003cBlock\u003e it \u003d invalidateSet.iterator();\n+        for (int blkCount \u003d 0; blkCount \u003c getDatanodeManager().blockInvalidateLimit\n+            \u0026\u0026 it.hasNext(); blkCount++) {\n+          blocksToInvalidate.add(it.next());\n+          it.remove();\n         }\n-        NameNode.stateChangeLog.info(\"BLOCK* ask \" + dn.getName()\n-            + \" to delete \" + blockList);\n+\n+        // If we send everything in this message, remove this node entry\n+        if (!it.hasNext()) {\n+          removeFromInvalidates(nodeId);\n+        }\n+\n+        dn.addBlocksToBeInvalidated(blocksToInvalidate);\n+\n+        if (NameNode.stateChangeLog.isInfoEnabled()) {\n+          StringBuilder blockList \u003d new StringBuilder();\n+          for (Block blk : blocksToInvalidate) {\n+            blockList.append(\u0027 \u0027);\n+            blockList.append(blk);\n+          }\n+          NameNode.stateChangeLog.info(\"BLOCK* ask \" + dn.getName()\n+              + \" to delete \" + blockList);\n+        }\n+        pendingDeletionBlocksCount -\u003d blocksToInvalidate.size();\n+        return blocksToInvalidate.size();\n       }\n-      pendingDeletionBlocksCount -\u003d blocksToInvalidate.size();\n-      return blocksToInvalidate.size();\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int invalidateWorkForOneNode(String nodeId) {\n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode())\n        return 0;\n      // get blocks to invalidate for the nodeId\n      assert nodeId !\u003d null;\n      final DatanodeDescriptor dn \u003d datanodeManager.getDatanode(nodeId);\n      if (dn \u003d\u003d null) {\n        removeFromInvalidates(nodeId);\n        return 0;\n      }\n\n      Collection\u003cBlock\u003e invalidateSet;\n      ArrayList\u003cBlock\u003e blocksToInvalidate;\n      synchronized(recentInvalidateSets) {\n        invalidateSet \u003d recentInvalidateSets.get(nodeId);\n        if (invalidateSet \u003d\u003d null)\n          return 0;\n\n        blocksToInvalidate \u003d new ArrayList\u003cBlock\u003e(\n          getDatanodeManager().blockInvalidateLimit);\n\n        // # blocks that can be sent in one message is limited\n        Iterator\u003cBlock\u003e it \u003d invalidateSet.iterator();\n        for (int blkCount \u003d 0; blkCount \u003c getDatanodeManager().blockInvalidateLimit\n            \u0026\u0026 it.hasNext(); blkCount++) {\n          blocksToInvalidate.add(it.next());\n          it.remove();\n        }\n\n        // If we send everything in this message, remove this node entry\n        if (!it.hasNext()) {\n          removeFromInvalidates(nodeId);\n        }\n\n        dn.addBlocksToBeInvalidated(blocksToInvalidate);\n\n        if (NameNode.stateChangeLog.isInfoEnabled()) {\n          StringBuilder blockList \u003d new StringBuilder();\n          for (Block blk : blocksToInvalidate) {\n            blockList.append(\u0027 \u0027);\n            blockList.append(blk);\n          }\n          NameNode.stateChangeLog.info(\"BLOCK* ask \" + dn.getName()\n              + \" to delete \" + blockList);\n        }\n        pendingDeletionBlocksCount -\u003d blocksToInvalidate.size();\n        return blocksToInvalidate.size();\n      }\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "969a263188f7015261719fe45fa1505121ebb80e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2191.  Move datanodeMap from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1151339 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/07/11 10:46 PM",
      "commitName": "969a263188f7015261719fe45fa1505121ebb80e",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "22/07/11 6:01 PM",
      "commitNameOld": "89537b7710b23db7abcd2a77f03818c06a5f5fa7",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 4.2,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,51 @@\n   private int invalidateWorkForOneNode(String nodeId) {\n     namesystem.writeLock();\n     try {\n       // blocks should not be replicated or removed if safe mode is on\n       if (namesystem.isInSafeMode())\n         return 0;\n       // get blocks to invalidate for the nodeId\n       assert nodeId !\u003d null;\n-      DatanodeDescriptor dn \u003d namesystem.getDatanode(nodeId);\n+      final DatanodeDescriptor dn \u003d datanodeManager.getDatanode(nodeId);\n       if (dn \u003d\u003d null) {\n         removeFromInvalidates(nodeId);\n         return 0;\n       }\n \n       Collection\u003cBlock\u003e invalidateSet \u003d recentInvalidateSets.get(nodeId);\n       if (invalidateSet \u003d\u003d null)\n         return 0;\n \n       ArrayList\u003cBlock\u003e blocksToInvalidate \u003d new ArrayList\u003cBlock\u003e(\n-          namesystem.blockInvalidateLimit);\n+          getDatanodeManager().blockInvalidateLimit);\n \n       // # blocks that can be sent in one message is limited\n       Iterator\u003cBlock\u003e it \u003d invalidateSet.iterator();\n-      for (int blkCount \u003d 0; blkCount \u003c namesystem.blockInvalidateLimit\n+      for (int blkCount \u003d 0; blkCount \u003c getDatanodeManager().blockInvalidateLimit\n           \u0026\u0026 it.hasNext(); blkCount++) {\n         blocksToInvalidate.add(it.next());\n         it.remove();\n       }\n \n       // If we send everything in this message, remove this node entry\n       if (!it.hasNext()) {\n         removeFromInvalidates(nodeId);\n       }\n \n       dn.addBlocksToBeInvalidated(blocksToInvalidate);\n \n       if (NameNode.stateChangeLog.isInfoEnabled()) {\n         StringBuilder blockList \u003d new StringBuilder();\n         for (Block blk : blocksToInvalidate) {\n           blockList.append(\u0027 \u0027);\n           blockList.append(blk);\n         }\n         NameNode.stateChangeLog.info(\"BLOCK* ask \" + dn.getName()\n             + \" to delete \" + blockList);\n       }\n       pendingDeletionBlocksCount -\u003d blocksToInvalidate.size();\n       return blocksToInvalidate.size();\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private int invalidateWorkForOneNode(String nodeId) {\n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode())\n        return 0;\n      // get blocks to invalidate for the nodeId\n      assert nodeId !\u003d null;\n      final DatanodeDescriptor dn \u003d datanodeManager.getDatanode(nodeId);\n      if (dn \u003d\u003d null) {\n        removeFromInvalidates(nodeId);\n        return 0;\n      }\n\n      Collection\u003cBlock\u003e invalidateSet \u003d recentInvalidateSets.get(nodeId);\n      if (invalidateSet \u003d\u003d null)\n        return 0;\n\n      ArrayList\u003cBlock\u003e blocksToInvalidate \u003d new ArrayList\u003cBlock\u003e(\n          getDatanodeManager().blockInvalidateLimit);\n\n      // # blocks that can be sent in one message is limited\n      Iterator\u003cBlock\u003e it \u003d invalidateSet.iterator();\n      for (int blkCount \u003d 0; blkCount \u003c getDatanodeManager().blockInvalidateLimit\n          \u0026\u0026 it.hasNext(); blkCount++) {\n        blocksToInvalidate.add(it.next());\n        it.remove();\n      }\n\n      // If we send everything in this message, remove this node entry\n      if (!it.hasNext()) {\n        removeFromInvalidates(nodeId);\n      }\n\n      dn.addBlocksToBeInvalidated(blocksToInvalidate);\n\n      if (NameNode.stateChangeLog.isInfoEnabled()) {\n        StringBuilder blockList \u003d new StringBuilder();\n        for (Block blk : blocksToInvalidate) {\n          blockList.append(\u0027 \u0027);\n          blockList.append(blk);\n        }\n        NameNode.stateChangeLog.info(\"BLOCK* ask \" + dn.getName()\n            + \" to delete \" + blockList);\n      }\n      pendingDeletionBlocksCount -\u003d blocksToInvalidate.size();\n      return blocksToInvalidate.size();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "09b6f98de431628c80bc8a6faf0070eeaf72ff2a": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2107. Move block management code from o.a.h.h.s.namenode to a new package o.a.h.h.s.blockmanagement.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1140939 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/06/11 6:31 PM",
      "commitName": "09b6f98de431628c80bc8a6faf0070eeaf72ff2a",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "28/06/11 5:26 PM",
      "commitNameOld": "97b6ca4dd7d1233e8f8c90b1c01e47228c044e13",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private int invalidateWorkForOneNode(String nodeId) {\n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode())\n        return 0;\n      // get blocks to invalidate for the nodeId\n      assert nodeId !\u003d null;\n      DatanodeDescriptor dn \u003d namesystem.getDatanode(nodeId);\n      if (dn \u003d\u003d null) {\n        removeFromInvalidates(nodeId);\n        return 0;\n      }\n\n      Collection\u003cBlock\u003e invalidateSet \u003d recentInvalidateSets.get(nodeId);\n      if (invalidateSet \u003d\u003d null)\n        return 0;\n\n      ArrayList\u003cBlock\u003e blocksToInvalidate \u003d new ArrayList\u003cBlock\u003e(\n          namesystem.blockInvalidateLimit);\n\n      // # blocks that can be sent in one message is limited\n      Iterator\u003cBlock\u003e it \u003d invalidateSet.iterator();\n      for (int blkCount \u003d 0; blkCount \u003c namesystem.blockInvalidateLimit\n          \u0026\u0026 it.hasNext(); blkCount++) {\n        blocksToInvalidate.add(it.next());\n        it.remove();\n      }\n\n      // If we send everything in this message, remove this node entry\n      if (!it.hasNext()) {\n        removeFromInvalidates(nodeId);\n      }\n\n      dn.addBlocksToBeInvalidated(blocksToInvalidate);\n\n      if (NameNode.stateChangeLog.isInfoEnabled()) {\n        StringBuilder blockList \u003d new StringBuilder();\n        for (Block blk : blocksToInvalidate) {\n          blockList.append(\u0027 \u0027);\n          blockList.append(blk);\n        }\n        NameNode.stateChangeLog.info(\"BLOCK* ask \" + dn.getName()\n            + \" to delete \" + blockList);\n      }\n      pendingDeletionBlocksCount -\u003d blocksToInvalidate.size();\n      return blocksToInvalidate.size();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/BlockManager.java",
        "newPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
      }
    },
    "97b6ca4dd7d1233e8f8c90b1c01e47228c044e13": {
      "type": "Yfilerename",
      "commitMessage": "Revert 1140913 and 1140909 for HDFS-2107.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1140920 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/06/11 5:26 PM",
      "commitName": "97b6ca4dd7d1233e8f8c90b1c01e47228c044e13",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "28/06/11 4:57 PM",
      "commitNameOld": "d58e3efe9269efe00c309ed0e9726d2f94bcd03a",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private int invalidateWorkForOneNode(String nodeId) {\n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode())\n        return 0;\n      // get blocks to invalidate for the nodeId\n      assert nodeId !\u003d null;\n      DatanodeDescriptor dn \u003d namesystem.getDatanode(nodeId);\n      if (dn \u003d\u003d null) {\n        removeFromInvalidates(nodeId);\n        return 0;\n      }\n\n      Collection\u003cBlock\u003e invalidateSet \u003d recentInvalidateSets.get(nodeId);\n      if (invalidateSet \u003d\u003d null)\n        return 0;\n\n      ArrayList\u003cBlock\u003e blocksToInvalidate \u003d new ArrayList\u003cBlock\u003e(\n          namesystem.blockInvalidateLimit);\n\n      // # blocks that can be sent in one message is limited\n      Iterator\u003cBlock\u003e it \u003d invalidateSet.iterator();\n      for (int blkCount \u003d 0; blkCount \u003c namesystem.blockInvalidateLimit\n          \u0026\u0026 it.hasNext(); blkCount++) {\n        blocksToInvalidate.add(it.next());\n        it.remove();\n      }\n\n      // If we send everything in this message, remove this node entry\n      if (!it.hasNext()) {\n        removeFromInvalidates(nodeId);\n      }\n\n      dn.addBlocksToBeInvalidated(blocksToInvalidate);\n\n      if (NameNode.stateChangeLog.isInfoEnabled()) {\n        StringBuilder blockList \u003d new StringBuilder();\n        for (Block blk : blocksToInvalidate) {\n          blockList.append(\u0027 \u0027);\n          blockList.append(blk);\n        }\n        NameNode.stateChangeLog.info(\"BLOCK* ask \" + dn.getName()\n            + \" to delete \" + blockList);\n      }\n      pendingDeletionBlocksCount -\u003d blocksToInvalidate.size();\n      return blocksToInvalidate.size();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/BlockManager.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
        "newPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/BlockManager.java"
      }
    },
    "1bcfe45e47775b98cce5541f328c4fd46e5eb13d": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2106. Move block management code from o.a.h.h.s.namenode to a new package o.a.h.h.s.blockmanagement.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1140909 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/06/11 4:43 PM",
      "commitName": "1bcfe45e47775b98cce5541f328c4fd46e5eb13d",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "28/06/11 9:21 AM",
      "commitNameOld": "1834fb99f516b2f2cd5e0ab1f89d407f98a7237a",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.31,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private int invalidateWorkForOneNode(String nodeId) {\n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode())\n        return 0;\n      // get blocks to invalidate for the nodeId\n      assert nodeId !\u003d null;\n      DatanodeDescriptor dn \u003d namesystem.getDatanode(nodeId);\n      if (dn \u003d\u003d null) {\n        removeFromInvalidates(nodeId);\n        return 0;\n      }\n\n      Collection\u003cBlock\u003e invalidateSet \u003d recentInvalidateSets.get(nodeId);\n      if (invalidateSet \u003d\u003d null)\n        return 0;\n\n      ArrayList\u003cBlock\u003e blocksToInvalidate \u003d new ArrayList\u003cBlock\u003e(\n          namesystem.blockInvalidateLimit);\n\n      // # blocks that can be sent in one message is limited\n      Iterator\u003cBlock\u003e it \u003d invalidateSet.iterator();\n      for (int blkCount \u003d 0; blkCount \u003c namesystem.blockInvalidateLimit\n          \u0026\u0026 it.hasNext(); blkCount++) {\n        blocksToInvalidate.add(it.next());\n        it.remove();\n      }\n\n      // If we send everything in this message, remove this node entry\n      if (!it.hasNext()) {\n        removeFromInvalidates(nodeId);\n      }\n\n      dn.addBlocksToBeInvalidated(blocksToInvalidate);\n\n      if (NameNode.stateChangeLog.isInfoEnabled()) {\n        StringBuilder blockList \u003d new StringBuilder();\n        for (Block blk : blocksToInvalidate) {\n          blockList.append(\u0027 \u0027);\n          blockList.append(blk);\n        }\n        NameNode.stateChangeLog.info(\"BLOCK* ask \" + dn.getName()\n            + \" to delete \" + blockList);\n      }\n      pendingDeletionBlocksCount -\u003d blocksToInvalidate.size();\n      return blocksToInvalidate.size();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/BlockManager.java",
        "newPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,51 @@\n+  private int invalidateWorkForOneNode(String nodeId) {\n+    namesystem.writeLock();\n+    try {\n+      // blocks should not be replicated or removed if safe mode is on\n+      if (namesystem.isInSafeMode())\n+        return 0;\n+      // get blocks to invalidate for the nodeId\n+      assert nodeId !\u003d null;\n+      DatanodeDescriptor dn \u003d namesystem.getDatanode(nodeId);\n+      if (dn \u003d\u003d null) {\n+        removeFromInvalidates(nodeId);\n+        return 0;\n+      }\n+\n+      Collection\u003cBlock\u003e invalidateSet \u003d recentInvalidateSets.get(nodeId);\n+      if (invalidateSet \u003d\u003d null)\n+        return 0;\n+\n+      ArrayList\u003cBlock\u003e blocksToInvalidate \u003d new ArrayList\u003cBlock\u003e(\n+          namesystem.blockInvalidateLimit);\n+\n+      // # blocks that can be sent in one message is limited\n+      Iterator\u003cBlock\u003e it \u003d invalidateSet.iterator();\n+      for (int blkCount \u003d 0; blkCount \u003c namesystem.blockInvalidateLimit\n+          \u0026\u0026 it.hasNext(); blkCount++) {\n+        blocksToInvalidate.add(it.next());\n+        it.remove();\n+      }\n+\n+      // If we send everything in this message, remove this node entry\n+      if (!it.hasNext()) {\n+        removeFromInvalidates(nodeId);\n+      }\n+\n+      dn.addBlocksToBeInvalidated(blocksToInvalidate);\n+\n+      if (NameNode.stateChangeLog.isInfoEnabled()) {\n+        StringBuilder blockList \u003d new StringBuilder();\n+        for (Block blk : blocksToInvalidate) {\n+          blockList.append(\u0027 \u0027);\n+          blockList.append(blk);\n+        }\n+        NameNode.stateChangeLog.info(\"BLOCK* ask \" + dn.getName()\n+            + \" to delete \" + blockList);\n+      }\n+      pendingDeletionBlocksCount -\u003d blocksToInvalidate.size();\n+      return blocksToInvalidate.size();\n+    } finally {\n+      namesystem.writeUnlock();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private int invalidateWorkForOneNode(String nodeId) {\n    namesystem.writeLock();\n    try {\n      // blocks should not be replicated or removed if safe mode is on\n      if (namesystem.isInSafeMode())\n        return 0;\n      // get blocks to invalidate for the nodeId\n      assert nodeId !\u003d null;\n      DatanodeDescriptor dn \u003d namesystem.getDatanode(nodeId);\n      if (dn \u003d\u003d null) {\n        removeFromInvalidates(nodeId);\n        return 0;\n      }\n\n      Collection\u003cBlock\u003e invalidateSet \u003d recentInvalidateSets.get(nodeId);\n      if (invalidateSet \u003d\u003d null)\n        return 0;\n\n      ArrayList\u003cBlock\u003e blocksToInvalidate \u003d new ArrayList\u003cBlock\u003e(\n          namesystem.blockInvalidateLimit);\n\n      // # blocks that can be sent in one message is limited\n      Iterator\u003cBlock\u003e it \u003d invalidateSet.iterator();\n      for (int blkCount \u003d 0; blkCount \u003c namesystem.blockInvalidateLimit\n          \u0026\u0026 it.hasNext(); blkCount++) {\n        blocksToInvalidate.add(it.next());\n        it.remove();\n      }\n\n      // If we send everything in this message, remove this node entry\n      if (!it.hasNext()) {\n        removeFromInvalidates(nodeId);\n      }\n\n      dn.addBlocksToBeInvalidated(blocksToInvalidate);\n\n      if (NameNode.stateChangeLog.isInfoEnabled()) {\n        StringBuilder blockList \u003d new StringBuilder();\n        for (Block blk : blocksToInvalidate) {\n          blockList.append(\u0027 \u0027);\n          blockList.append(blk);\n        }\n        NameNode.stateChangeLog.info(\"BLOCK* ask \" + dn.getName()\n            + \" to delete \" + blockList);\n      }\n      pendingDeletionBlocksCount -\u003d blocksToInvalidate.size();\n      return blocksToInvalidate.size();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/BlockManager.java"
    }
  }
}