{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CacheManager.java",
  "functionName": "load",
  "functionId": "load___in-DataInput",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
  "functionStartLine": 1189,
  "functionEndLine": 1194,
  "numCommitsSeen": 89,
  "timeTaken": 2946,
  "changeHistory": [
    "a506df8e483cdd27629cfcbc2b0e1aecd27e448a",
    "13edb391d06c479720202eb5ac81f1c71fe64748",
    "dcb0b853332046f8bf5bb02b8ddbba5b3464fe8f",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2"
  ],
  "changeHistoryShort": {
    "a506df8e483cdd27629cfcbc2b0e1aecd27e448a": "Ymultichange(Yrename,Ymodifierchange)",
    "13edb391d06c479720202eb5ac81f1c71fe64748": "Ybodychange",
    "dcb0b853332046f8bf5bb02b8ddbba5b3464fe8f": "Ybodychange",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": "Ymultichange(Ymodifierchange,Ybodychange)",
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2": "Yintroduced"
  },
  "changeHistoryDetails": {
    "a506df8e483cdd27629cfcbc2b0e1aecd27e448a": {
      "type": "Ymultichange(Yrename,Ymodifierchange)",
      "commitMessage": "HDFS-5775. Consolidate the code for serialization in CacheManager. Contributed by Haohui Mai\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1558599 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/01/14 3:15 PM",
      "commitName": "a506df8e483cdd27629cfcbc2b0e1aecd27e448a",
      "commitAuthor": "Brandon Li",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-5775. Consolidate the code for serialization in CacheManager. Contributed by Haohui Mai\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1558599 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "15/01/14 3:15 PM",
          "commitName": "a506df8e483cdd27629cfcbc2b0e1aecd27e448a",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "07/01/14 12:52 PM",
          "commitNameOld": "70cff9e2f0c8f78c1dc54a064182971bb2106795",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 8.1,
          "commitsBetweenForRepo": 45,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,6 @@\n-  public void loadState(DataInput in) throws IOException {\n-    nextDirectiveId \u003d in.readLong();\n-    // pools need to be loaded first since directives point to their parent pool\n-    loadPools(in);\n-    loadDirectives(in);\n-  }\n\\ No newline at end of file\n+    private void load(DataInput in) throws IOException {\n+      nextDirectiveId \u003d in.readLong();\n+      // pools need to be loaded first since directives point to their parent pool\n+      loadPools(in);\n+      loadDirectives(in);\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    private void load(DataInput in) throws IOException {\n      nextDirectiveId \u003d in.readLong();\n      // pools need to be loaded first since directives point to their parent pool\n      loadPools(in);\n      loadDirectives(in);\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "loadState",
            "newValue": "load"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-5775. Consolidate the code for serialization in CacheManager. Contributed by Haohui Mai\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1558599 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "15/01/14 3:15 PM",
          "commitName": "a506df8e483cdd27629cfcbc2b0e1aecd27e448a",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "07/01/14 12:52 PM",
          "commitNameOld": "70cff9e2f0c8f78c1dc54a064182971bb2106795",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 8.1,
          "commitsBetweenForRepo": 45,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,6 @@\n-  public void loadState(DataInput in) throws IOException {\n-    nextDirectiveId \u003d in.readLong();\n-    // pools need to be loaded first since directives point to their parent pool\n-    loadPools(in);\n-    loadDirectives(in);\n-  }\n\\ No newline at end of file\n+    private void load(DataInput in) throws IOException {\n+      nextDirectiveId \u003d in.readLong();\n+      // pools need to be loaded first since directives point to their parent pool\n+      loadPools(in);\n+      loadDirectives(in);\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    private void load(DataInput in) throws IOException {\n      nextDirectiveId \u003d in.readLong();\n      // pools need to be loaded first since directives point to their parent pool\n      loadPools(in);\n      loadDirectives(in);\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[private]"
          }
        }
      ]
    },
    "13edb391d06c479720202eb5ac81f1c71fe64748": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5556. Add some more NameNode cache statistics, cache pool stats (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546143 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/11/13 9:55 AM",
      "commitName": "13edb391d06c479720202eb5ac81f1c71fe64748",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "21/11/13 9:12 AM",
      "commitNameOld": "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 6.03,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,6 @@\n   public void loadState(DataInput in) throws IOException {\n-    nextEntryId \u003d in.readLong();\n-    // pools need to be loaded first since entries point to their parent pool\n+    nextDirectiveId \u003d in.readLong();\n+    // pools need to be loaded first since directives point to their parent pool\n     loadPools(in);\n-    loadEntries(in);\n+    loadDirectives(in);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void loadState(DataInput in) throws IOException {\n    nextDirectiveId \u003d in.readLong();\n    // pools need to be loaded first since directives point to their parent pool\n    loadPools(in);\n    loadDirectives(in);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "dcb0b853332046f8bf5bb02b8ddbba5b3464fe8f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5383. fix broken caching unit tests (Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1533253 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/10/13 1:31 PM",
      "commitName": "dcb0b853332046f8bf5bb02b8ddbba5b3464fe8f",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "16/10/13 3:15 PM",
      "commitNameOld": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 0.93,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,6 @@\n   public void loadState(DataInput in) throws IOException {\n-    assert namesystem.hasWriteLock();\n     nextEntryId \u003d in.readLong();\n     // pools need to be loaded first since entries point to their parent pool\n     loadPools(in);\n     loadEntries(in);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void loadState(DataInput in) throws IOException {\n    nextEntryId \u003d in.readLong();\n    // pools need to be loaded first since entries point to their parent pool\n    loadPools(in);\n    loadEntries(in);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
      "extendedDetails": {}
    },
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 3:15 PM",
      "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "16/10/13 3:15 PM",
          "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "14/10/13 3:56 PM",
          "commitNameOld": "efe545b0c219eeba61ac5259aee4d518beb74316",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 1.97,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,7 @@\n-  public synchronized void loadState(DataInput in) throws IOException {\n+  public void loadState(DataInput in) throws IOException {\n+    assert namesystem.hasWriteLock();\n     nextEntryId \u003d in.readLong();\n     // pools need to be loaded first since entries point to their parent pool\n     loadPools(in);\n     loadEntries(in);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void loadState(DataInput in) throws IOException {\n    assert namesystem.hasWriteLock();\n    nextEntryId \u003d in.readLong();\n    // pools need to be loaded first since entries point to their parent pool\n    loadPools(in);\n    loadEntries(in);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {
            "oldValue": "[public, synchronized]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "16/10/13 3:15 PM",
          "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "14/10/13 3:56 PM",
          "commitNameOld": "efe545b0c219eeba61ac5259aee4d518beb74316",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 1.97,
          "commitsBetweenForRepo": 4,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,7 @@\n-  public synchronized void loadState(DataInput in) throws IOException {\n+  public void loadState(DataInput in) throws IOException {\n+    assert namesystem.hasWriteLock();\n     nextEntryId \u003d in.readLong();\n     // pools need to be loaded first since entries point to their parent pool\n     loadPools(in);\n     loadEntries(in);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void loadState(DataInput in) throws IOException {\n    assert namesystem.hasWriteLock();\n    nextEntryId \u003d in.readLong();\n    // pools need to be loaded first since entries point to their parent pool\n    loadPools(in);\n    loadEntries(in);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5119. Persist CacheManager state in the edit log. (Contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1529238 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/10/13 10:46 AM",
      "commitName": "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2",
      "commitAuthor": "Andrew Wang",
      "diff": "@@ -0,0 +1,6 @@\n+  public synchronized void loadState(DataInput in) throws IOException {\n+    nextEntryId \u003d in.readLong();\n+    // pools need to be loaded first since entries point to their parent pool\n+    loadPools(in);\n+    loadEntries(in);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void loadState(DataInput in) throws IOException {\n    nextEntryId \u003d in.readLong();\n    // pools need to be loaded first since entries point to their parent pool\n    loadPools(in);\n    loadEntries(in);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java"
    }
  }
}