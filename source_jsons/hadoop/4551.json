{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PBHelper.java",
  "functionName": "convertSlowDiskInfo",
  "functionId": "convertSlowDiskInfo___slowDiskProtos-List__SlowDiskReportProto__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
  "functionStartLine": 918,
  "functionEndLine": 950,
  "numCommitsSeen": 195,
  "timeTaken": 1835,
  "changeHistory": [
    "e7c8da614c37e36fb8081234f4c639d6054f6082"
  ],
  "changeHistoryShort": {
    "e7c8da614c37e36fb8081234f4c639d6054f6082": "Yintroduced"
  },
  "changeHistoryDetails": {
    "e7c8da614c37e36fb8081234f4c639d6054f6082": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11545. Propagate DataNode\u0027s slow disks info to the NameNode via Heartbeats. Contributed by Hanisha Koneru.\n",
      "commitDate": "20/03/17 9:54 PM",
      "commitName": "e7c8da614c37e36fb8081234f4c639d6054f6082",
      "commitAuthor": "Arpit Agarwal",
      "diff": "@@ -0,0 +1,33 @@\n+  public static SlowDiskReports convertSlowDiskInfo(\n+      List\u003cSlowDiskReportProto\u003e slowDiskProtos) {\n+\n+    // No slow disks, or possibly an older DataNode.\n+    if (slowDiskProtos \u003d\u003d null || slowDiskProtos.size() \u003d\u003d 0) {\n+      return SlowDiskReports.EMPTY_REPORT;\n+    }\n+\n+    Map\u003cString, Map\u003cSlowDiskReports.DiskOp, Double\u003e\u003e slowDisksMap \u003d\n+        new HashMap\u003c\u003e(slowDiskProtos.size());\n+    for (SlowDiskReportProto proto : slowDiskProtos) {\n+      if (!proto.hasBasePath()) {\n+        // The disk basePath should be reported.\n+        continue;\n+      }\n+      Map\u003cSlowDiskReports.DiskOp, Double\u003e latencyMap \u003d new HashMap\u003c\u003e();\n+      if (proto.hasMeanMetadataOpLatency()) {\n+        latencyMap.put(SlowDiskReports.DiskOp.METADATA,\n+            proto.getMeanMetadataOpLatency());\n+      }\n+      if (proto.hasMeanReadIoLatency()) {\n+        latencyMap.put(SlowDiskReports.DiskOp.READ,\n+            proto.getMeanReadIoLatency());\n+      }\n+      if (proto.hasMeanWriteIoLatency()) {\n+        latencyMap.put(SlowDiskReports.DiskOp.WRITE,\n+            proto.getMeanWriteIoLatency());\n+      }\n+\n+      slowDisksMap.put(proto.getBasePath(), latencyMap);\n+    }\n+    return SlowDiskReports.create(slowDisksMap);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static SlowDiskReports convertSlowDiskInfo(\n      List\u003cSlowDiskReportProto\u003e slowDiskProtos) {\n\n    // No slow disks, or possibly an older DataNode.\n    if (slowDiskProtos \u003d\u003d null || slowDiskProtos.size() \u003d\u003d 0) {\n      return SlowDiskReports.EMPTY_REPORT;\n    }\n\n    Map\u003cString, Map\u003cSlowDiskReports.DiskOp, Double\u003e\u003e slowDisksMap \u003d\n        new HashMap\u003c\u003e(slowDiskProtos.size());\n    for (SlowDiskReportProto proto : slowDiskProtos) {\n      if (!proto.hasBasePath()) {\n        // The disk basePath should be reported.\n        continue;\n      }\n      Map\u003cSlowDiskReports.DiskOp, Double\u003e latencyMap \u003d new HashMap\u003c\u003e();\n      if (proto.hasMeanMetadataOpLatency()) {\n        latencyMap.put(SlowDiskReports.DiskOp.METADATA,\n            proto.getMeanMetadataOpLatency());\n      }\n      if (proto.hasMeanReadIoLatency()) {\n        latencyMap.put(SlowDiskReports.DiskOp.READ,\n            proto.getMeanReadIoLatency());\n      }\n      if (proto.hasMeanWriteIoLatency()) {\n        latencyMap.put(SlowDiskReports.DiskOp.WRITE,\n            proto.getMeanWriteIoLatency());\n      }\n\n      slowDisksMap.put(proto.getBasePath(), latencyMap);\n    }\n    return SlowDiskReports.create(slowDisksMap);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java"
    }
  }
}