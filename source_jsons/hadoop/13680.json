{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPlacementPolicyDefault.java",
  "functionName": "chooseTarget",
  "functionId": "chooseTarget___numOfReplicas-int__writer-Node__excludedNodes-Set__Node__(modifiers-final)__blocksize-long(modifiers-final)__maxNodesPerRack-int(modifiers-final)__results-List__DatanodeStorageInfo__(modifiers-final)__avoidStaleNodes-boolean(modifiers-final)__storagePolicy-BlockStoragePolicy(modifiers-final)__unavailableStorages-EnumSet__StorageType__(modifiers-final)__newBlock-boolean(modifiers-final)__storageTypes-EnumMap__StorageType,Integer__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
  "functionStartLine": 420,
  "functionEndLine": 512,
  "numCommitsSeen": 231,
  "timeTaken": 5556,
  "changeHistory": [
    "f5ecc0bc080cb8a64c6d4632fc1c121f93d95c5e",
    "c1caab40f27e3e4f58ff1b5ef3e93efc56bbecbe",
    "0f5f9846edab3ea7e80f35000072136f998bcd46",
    "d505c8acd30d6f40d0632fe9c93c886a4499a9fc",
    "ed841dd9a96e54cb84d9cae5507e47ff1c8cdf6e",
    "22a41dce4af4d5b533ba875b322551db1c152878",
    "e08701ec71f7c10d8f15122d90c35f9f22e40837",
    "e69954d22cc97eb3818c8ee7c3f623a5d0497b54",
    "ac5e8aed7ca1e9493f96f8795d0caafd5282b9a7"
  ],
  "changeHistoryShort": {
    "f5ecc0bc080cb8a64c6d4632fc1c121f93d95c5e": "Ybodychange",
    "c1caab40f27e3e4f58ff1b5ef3e93efc56bbecbe": "Ymultichange(Yparameterchange,Ybodychange)",
    "0f5f9846edab3ea7e80f35000072136f998bcd46": "Ybodychange",
    "d505c8acd30d6f40d0632fe9c93c886a4499a9fc": "Ybodychange",
    "ed841dd9a96e54cb84d9cae5507e47ff1c8cdf6e": "Ybodychange",
    "22a41dce4af4d5b533ba875b322551db1c152878": "Ybodychange",
    "e08701ec71f7c10d8f15122d90c35f9f22e40837": "Ybodychange",
    "e69954d22cc97eb3818c8ee7c3f623a5d0497b54": "Ybodychange",
    "ac5e8aed7ca1e9493f96f8795d0caafd5282b9a7": "Ymultichange(Yparameterchange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "f5ecc0bc080cb8a64c6d4632fc1c121f93d95c5e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14103. Review Logging of BlockPlacementPolicyDefault. Contributed by David Mollitor.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "19/06/19 10:06 AM",
      "commitName": "f5ecc0bc080cb8a64c6d4632fc1c121f93d95c5e",
      "commitAuthor": "David Mollitor",
      "commitDateOld": "06/06/19 10:20 AM",
      "commitNameOld": "944adc61b1830388d520d4052fc7eb6c7ba2790d",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 12.99,
      "commitsBetweenForRepo": 103,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,98 +1,93 @@\n   private Node chooseTarget(int numOfReplicas,\n                             Node writer,\n                             final Set\u003cNode\u003e excludedNodes,\n                             final long blocksize,\n                             final int maxNodesPerRack,\n                             final List\u003cDatanodeStorageInfo\u003e results,\n                             final boolean avoidStaleNodes,\n                             final BlockStoragePolicy storagePolicy,\n                             final EnumSet\u003cStorageType\u003e unavailableStorages,\n                             final boolean newBlock,\n                             EnumMap\u003cStorageType, Integer\u003e storageTypes) {\n     if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n       return (writer instanceof DatanodeDescriptor) ? writer : null;\n     }\n     final int numOfResults \u003d results.size();\n     final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n     if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n       writer \u003d results.get(0).getDatanodeDescriptor();\n     }\n \n     // Keep a copy of original excludedNodes\n     final Set\u003cNode\u003e oldExcludedNodes \u003d new HashSet\u003c\u003e(excludedNodes);\n \n     // choose storage types; use fallbacks for unavailable storages\n     final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n         .chooseStorageTypes((short) totalReplicasExpected,\n             DatanodeStorageInfo.toStorageTypes(results),\n             unavailableStorages, newBlock);\n     if (storageTypes \u003d\u003d null) {\n       storageTypes \u003d getRequiredStorageTypes(requiredStorageTypes);\n     }\n-    if (LOG.isTraceEnabled()) {\n-      LOG.trace(\"storageTypes\u003d\" + storageTypes);\n-    }\n+    LOG.trace(\"storageTypes\u003d{}\", storageTypes);\n \n     try {\n       if ((numOfReplicas \u003d requiredStorageTypes.size()) \u003d\u003d 0) {\n         throw new NotEnoughReplicasException(\n             \"All required storage types are unavailable: \"\n             + \" unavailableStorages\u003d\" + unavailableStorages\n             + \", storagePolicy\u003d\" + storagePolicy);\n       }\n       writer \u003d chooseTargetInOrder(numOfReplicas, writer, excludedNodes, blocksize,\n           maxNodesPerRack, results, avoidStaleNodes, newBlock, storageTypes);\n     } catch (NotEnoughReplicasException e) {\n       final String message \u003d \"Failed to place enough replicas, still in need of \"\n           + (totalReplicasExpected - results.size()) + \" to reach \"\n           + totalReplicasExpected\n           + \" (unavailableStorages\u003d\" + unavailableStorages\n           + \", storagePolicy\u003d\" + storagePolicy\n           + \", newBlock\u003d\" + newBlock + \")\";\n \n-      if (LOG.isTraceEnabled()) {\n-        LOG.trace(message, e);\n-      } else {\n-        LOG.warn(message + \" \" + e.getMessage());\n-      }\n+      LOG.trace(message, e);\n+      LOG.warn(message + \" \" + e.getMessage());\n \n       if (avoidStaleNodes) {\n         // Retry chooseTarget again, this time not avoiding stale nodes.\n \n         // excludedNodes contains the initial excludedNodes and nodes that were\n         // not chosen because they were stale, decommissioned, etc.\n         // We need to additionally exclude the nodes that were added to the \n         // result list in the successful calls to choose*() above.\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n         }\n         // Set numOfReplicas, since it can get out of sync with the result list\n         // if the NotEnoughReplicasException was thrown in chooseRandom().\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n             newBlock, null);\n       }\n \n       boolean retry \u003d false;\n       // simply add all the remaining types into unavailableStorages and give\n       // another try. No best effort is guaranteed here.\n       for (StorageType type : storageTypes.keySet()) {\n         if (!unavailableStorages.contains(type)) {\n           unavailableStorages.add(type);\n           retry \u003d true;\n         }\n       }\n       if (retry) {\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n               oldExcludedNodes);\n         }\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n             newBlock, null);\n       }\n     }\n     return writer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Node chooseTarget(int numOfReplicas,\n                            Node writer,\n                            final Set\u003cNode\u003e excludedNodes,\n                            final long blocksize,\n                            final int maxNodesPerRack,\n                            final List\u003cDatanodeStorageInfo\u003e results,\n                            final boolean avoidStaleNodes,\n                            final BlockStoragePolicy storagePolicy,\n                            final EnumSet\u003cStorageType\u003e unavailableStorages,\n                            final boolean newBlock,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes) {\n    if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n      return (writer instanceof DatanodeDescriptor) ? writer : null;\n    }\n    final int numOfResults \u003d results.size();\n    final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n    if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n      writer \u003d results.get(0).getDatanodeDescriptor();\n    }\n\n    // Keep a copy of original excludedNodes\n    final Set\u003cNode\u003e oldExcludedNodes \u003d new HashSet\u003c\u003e(excludedNodes);\n\n    // choose storage types; use fallbacks for unavailable storages\n    final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n        .chooseStorageTypes((short) totalReplicasExpected,\n            DatanodeStorageInfo.toStorageTypes(results),\n            unavailableStorages, newBlock);\n    if (storageTypes \u003d\u003d null) {\n      storageTypes \u003d getRequiredStorageTypes(requiredStorageTypes);\n    }\n    LOG.trace(\"storageTypes\u003d{}\", storageTypes);\n\n    try {\n      if ((numOfReplicas \u003d requiredStorageTypes.size()) \u003d\u003d 0) {\n        throw new NotEnoughReplicasException(\n            \"All required storage types are unavailable: \"\n            + \" unavailableStorages\u003d\" + unavailableStorages\n            + \", storagePolicy\u003d\" + storagePolicy);\n      }\n      writer \u003d chooseTargetInOrder(numOfReplicas, writer, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, newBlock, storageTypes);\n    } catch (NotEnoughReplicasException e) {\n      final String message \u003d \"Failed to place enough replicas, still in need of \"\n          + (totalReplicasExpected - results.size()) + \" to reach \"\n          + totalReplicasExpected\n          + \" (unavailableStorages\u003d\" + unavailableStorages\n          + \", storagePolicy\u003d\" + storagePolicy\n          + \", newBlock\u003d\" + newBlock + \")\";\n\n      LOG.trace(message, e);\n      LOG.warn(message + \" \" + e.getMessage());\n\n      if (avoidStaleNodes) {\n        // Retry chooseTarget again, this time not avoiding stale nodes.\n\n        // excludedNodes contains the initial excludedNodes and nodes that were\n        // not chosen because they were stale, decommissioned, etc.\n        // We need to additionally exclude the nodes that were added to the \n        // result list in the successful calls to choose*() above.\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n        }\n        // Set numOfReplicas, since it can get out of sync with the result list\n        // if the NotEnoughReplicasException was thrown in chooseRandom().\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock, null);\n      }\n\n      boolean retry \u003d false;\n      // simply add all the remaining types into unavailableStorages and give\n      // another try. No best effort is guaranteed here.\n      for (StorageType type : storageTypes.keySet()) {\n        if (!unavailableStorages.contains(type)) {\n          unavailableStorages.add(type);\n          retry \u003d true;\n        }\n      }\n      if (retry) {\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n              oldExcludedNodes);\n        }\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock, null);\n      }\n    }\n    return writer;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "c1caab40f27e3e4f58ff1b5ef3e93efc56bbecbe": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-14512. ONE_SSD policy will be violated while write data with DistributedFileSystem.create(....favoredNodes). Contributed by Ayush Saxena.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "29/05/19 8:56 PM",
      "commitName": "c1caab40f27e3e4f58ff1b5ef3e93efc56bbecbe",
      "commitAuthor": "Ayush Saxena",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-14512. ONE_SSD policy will be violated while write data with DistributedFileSystem.create(....favoredNodes). Contributed by Ayush Saxena.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
          "commitDate": "29/05/19 8:56 PM",
          "commitName": "c1caab40f27e3e4f58ff1b5ef3e93efc56bbecbe",
          "commitAuthor": "Ayush Saxena",
          "commitDateOld": "13/03/19 1:15 PM",
          "commitNameOld": "66357574ae1da09ced735da36bf7d80a40c3fa1b",
          "commitAuthorOld": "Erik Krogen",
          "daysBetweenCommits": 77.32,
          "commitsBetweenForRepo": 467,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,96 +1,98 @@\n   private Node chooseTarget(int numOfReplicas,\n                             Node writer,\n                             final Set\u003cNode\u003e excludedNodes,\n                             final long blocksize,\n                             final int maxNodesPerRack,\n                             final List\u003cDatanodeStorageInfo\u003e results,\n                             final boolean avoidStaleNodes,\n                             final BlockStoragePolicy storagePolicy,\n                             final EnumSet\u003cStorageType\u003e unavailableStorages,\n-                            final boolean newBlock) {\n+                            final boolean newBlock,\n+                            EnumMap\u003cStorageType, Integer\u003e storageTypes) {\n     if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n       return (writer instanceof DatanodeDescriptor) ? writer : null;\n     }\n     final int numOfResults \u003d results.size();\n     final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n     if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n       writer \u003d results.get(0).getDatanodeDescriptor();\n     }\n \n     // Keep a copy of original excludedNodes\n     final Set\u003cNode\u003e oldExcludedNodes \u003d new HashSet\u003c\u003e(excludedNodes);\n \n     // choose storage types; use fallbacks for unavailable storages\n     final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n         .chooseStorageTypes((short) totalReplicasExpected,\n             DatanodeStorageInfo.toStorageTypes(results),\n             unavailableStorages, newBlock);\n-    final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n-        getRequiredStorageTypes(requiredStorageTypes);\n+    if (storageTypes \u003d\u003d null) {\n+      storageTypes \u003d getRequiredStorageTypes(requiredStorageTypes);\n+    }\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"storageTypes\u003d\" + storageTypes);\n     }\n \n     try {\n       if ((numOfReplicas \u003d requiredStorageTypes.size()) \u003d\u003d 0) {\n         throw new NotEnoughReplicasException(\n             \"All required storage types are unavailable: \"\n             + \" unavailableStorages\u003d\" + unavailableStorages\n             + \", storagePolicy\u003d\" + storagePolicy);\n       }\n       writer \u003d chooseTargetInOrder(numOfReplicas, writer, excludedNodes, blocksize,\n           maxNodesPerRack, results, avoidStaleNodes, newBlock, storageTypes);\n     } catch (NotEnoughReplicasException e) {\n       final String message \u003d \"Failed to place enough replicas, still in need of \"\n           + (totalReplicasExpected - results.size()) + \" to reach \"\n           + totalReplicasExpected\n           + \" (unavailableStorages\u003d\" + unavailableStorages\n           + \", storagePolicy\u003d\" + storagePolicy\n           + \", newBlock\u003d\" + newBlock + \")\";\n \n       if (LOG.isTraceEnabled()) {\n         LOG.trace(message, e);\n       } else {\n         LOG.warn(message + \" \" + e.getMessage());\n       }\n \n       if (avoidStaleNodes) {\n         // Retry chooseTarget again, this time not avoiding stale nodes.\n \n         // excludedNodes contains the initial excludedNodes and nodes that were\n         // not chosen because they were stale, decommissioned, etc.\n         // We need to additionally exclude the nodes that were added to the \n         // result list in the successful calls to choose*() above.\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n         }\n         // Set numOfReplicas, since it can get out of sync with the result list\n         // if the NotEnoughReplicasException was thrown in chooseRandom().\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n-            newBlock);\n+            newBlock, null);\n       }\n \n       boolean retry \u003d false;\n       // simply add all the remaining types into unavailableStorages and give\n       // another try. No best effort is guaranteed here.\n       for (StorageType type : storageTypes.keySet()) {\n         if (!unavailableStorages.contains(type)) {\n           unavailableStorages.add(type);\n           retry \u003d true;\n         }\n       }\n       if (retry) {\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n               oldExcludedNodes);\n         }\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n-            newBlock);\n+            newBlock, null);\n       }\n     }\n     return writer;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Node chooseTarget(int numOfReplicas,\n                            Node writer,\n                            final Set\u003cNode\u003e excludedNodes,\n                            final long blocksize,\n                            final int maxNodesPerRack,\n                            final List\u003cDatanodeStorageInfo\u003e results,\n                            final boolean avoidStaleNodes,\n                            final BlockStoragePolicy storagePolicy,\n                            final EnumSet\u003cStorageType\u003e unavailableStorages,\n                            final boolean newBlock,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes) {\n    if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n      return (writer instanceof DatanodeDescriptor) ? writer : null;\n    }\n    final int numOfResults \u003d results.size();\n    final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n    if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n      writer \u003d results.get(0).getDatanodeDescriptor();\n    }\n\n    // Keep a copy of original excludedNodes\n    final Set\u003cNode\u003e oldExcludedNodes \u003d new HashSet\u003c\u003e(excludedNodes);\n\n    // choose storage types; use fallbacks for unavailable storages\n    final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n        .chooseStorageTypes((short) totalReplicasExpected,\n            DatanodeStorageInfo.toStorageTypes(results),\n            unavailableStorages, newBlock);\n    if (storageTypes \u003d\u003d null) {\n      storageTypes \u003d getRequiredStorageTypes(requiredStorageTypes);\n    }\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"storageTypes\u003d\" + storageTypes);\n    }\n\n    try {\n      if ((numOfReplicas \u003d requiredStorageTypes.size()) \u003d\u003d 0) {\n        throw new NotEnoughReplicasException(\n            \"All required storage types are unavailable: \"\n            + \" unavailableStorages\u003d\" + unavailableStorages\n            + \", storagePolicy\u003d\" + storagePolicy);\n      }\n      writer \u003d chooseTargetInOrder(numOfReplicas, writer, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, newBlock, storageTypes);\n    } catch (NotEnoughReplicasException e) {\n      final String message \u003d \"Failed to place enough replicas, still in need of \"\n          + (totalReplicasExpected - results.size()) + \" to reach \"\n          + totalReplicasExpected\n          + \" (unavailableStorages\u003d\" + unavailableStorages\n          + \", storagePolicy\u003d\" + storagePolicy\n          + \", newBlock\u003d\" + newBlock + \")\";\n\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(message, e);\n      } else {\n        LOG.warn(message + \" \" + e.getMessage());\n      }\n\n      if (avoidStaleNodes) {\n        // Retry chooseTarget again, this time not avoiding stale nodes.\n\n        // excludedNodes contains the initial excludedNodes and nodes that were\n        // not chosen because they were stale, decommissioned, etc.\n        // We need to additionally exclude the nodes that were added to the \n        // result list in the successful calls to choose*() above.\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n        }\n        // Set numOfReplicas, since it can get out of sync with the result list\n        // if the NotEnoughReplicasException was thrown in chooseRandom().\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock, null);\n      }\n\n      boolean retry \u003d false;\n      // simply add all the remaining types into unavailableStorages and give\n      // another try. No best effort is guaranteed here.\n      for (StorageType type : storageTypes.keySet()) {\n        if (!unavailableStorages.contains(type)) {\n          unavailableStorages.add(type);\n          retry \u003d true;\n        }\n      }\n      if (retry) {\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n              oldExcludedNodes);\n        }\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock, null);\n      }\n    }\n    return writer;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
          "extendedDetails": {
            "oldValue": "[numOfReplicas-int, writer-Node, excludedNodes-Set\u003cNode\u003e(modifiers-final), blocksize-long(modifiers-final), maxNodesPerRack-int(modifiers-final), results-List\u003cDatanodeStorageInfo\u003e(modifiers-final), avoidStaleNodes-boolean(modifiers-final), storagePolicy-BlockStoragePolicy(modifiers-final), unavailableStorages-EnumSet\u003cStorageType\u003e(modifiers-final), newBlock-boolean(modifiers-final)]",
            "newValue": "[numOfReplicas-int, writer-Node, excludedNodes-Set\u003cNode\u003e(modifiers-final), blocksize-long(modifiers-final), maxNodesPerRack-int(modifiers-final), results-List\u003cDatanodeStorageInfo\u003e(modifiers-final), avoidStaleNodes-boolean(modifiers-final), storagePolicy-BlockStoragePolicy(modifiers-final), unavailableStorages-EnumSet\u003cStorageType\u003e(modifiers-final), newBlock-boolean(modifiers-final), storageTypes-EnumMap\u003cStorageType,Integer\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-14512. ONE_SSD policy will be violated while write data with DistributedFileSystem.create(....favoredNodes). Contributed by Ayush Saxena.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
          "commitDate": "29/05/19 8:56 PM",
          "commitName": "c1caab40f27e3e4f58ff1b5ef3e93efc56bbecbe",
          "commitAuthor": "Ayush Saxena",
          "commitDateOld": "13/03/19 1:15 PM",
          "commitNameOld": "66357574ae1da09ced735da36bf7d80a40c3fa1b",
          "commitAuthorOld": "Erik Krogen",
          "daysBetweenCommits": 77.32,
          "commitsBetweenForRepo": 467,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,96 +1,98 @@\n   private Node chooseTarget(int numOfReplicas,\n                             Node writer,\n                             final Set\u003cNode\u003e excludedNodes,\n                             final long blocksize,\n                             final int maxNodesPerRack,\n                             final List\u003cDatanodeStorageInfo\u003e results,\n                             final boolean avoidStaleNodes,\n                             final BlockStoragePolicy storagePolicy,\n                             final EnumSet\u003cStorageType\u003e unavailableStorages,\n-                            final boolean newBlock) {\n+                            final boolean newBlock,\n+                            EnumMap\u003cStorageType, Integer\u003e storageTypes) {\n     if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n       return (writer instanceof DatanodeDescriptor) ? writer : null;\n     }\n     final int numOfResults \u003d results.size();\n     final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n     if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n       writer \u003d results.get(0).getDatanodeDescriptor();\n     }\n \n     // Keep a copy of original excludedNodes\n     final Set\u003cNode\u003e oldExcludedNodes \u003d new HashSet\u003c\u003e(excludedNodes);\n \n     // choose storage types; use fallbacks for unavailable storages\n     final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n         .chooseStorageTypes((short) totalReplicasExpected,\n             DatanodeStorageInfo.toStorageTypes(results),\n             unavailableStorages, newBlock);\n-    final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n-        getRequiredStorageTypes(requiredStorageTypes);\n+    if (storageTypes \u003d\u003d null) {\n+      storageTypes \u003d getRequiredStorageTypes(requiredStorageTypes);\n+    }\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"storageTypes\u003d\" + storageTypes);\n     }\n \n     try {\n       if ((numOfReplicas \u003d requiredStorageTypes.size()) \u003d\u003d 0) {\n         throw new NotEnoughReplicasException(\n             \"All required storage types are unavailable: \"\n             + \" unavailableStorages\u003d\" + unavailableStorages\n             + \", storagePolicy\u003d\" + storagePolicy);\n       }\n       writer \u003d chooseTargetInOrder(numOfReplicas, writer, excludedNodes, blocksize,\n           maxNodesPerRack, results, avoidStaleNodes, newBlock, storageTypes);\n     } catch (NotEnoughReplicasException e) {\n       final String message \u003d \"Failed to place enough replicas, still in need of \"\n           + (totalReplicasExpected - results.size()) + \" to reach \"\n           + totalReplicasExpected\n           + \" (unavailableStorages\u003d\" + unavailableStorages\n           + \", storagePolicy\u003d\" + storagePolicy\n           + \", newBlock\u003d\" + newBlock + \")\";\n \n       if (LOG.isTraceEnabled()) {\n         LOG.trace(message, e);\n       } else {\n         LOG.warn(message + \" \" + e.getMessage());\n       }\n \n       if (avoidStaleNodes) {\n         // Retry chooseTarget again, this time not avoiding stale nodes.\n \n         // excludedNodes contains the initial excludedNodes and nodes that were\n         // not chosen because they were stale, decommissioned, etc.\n         // We need to additionally exclude the nodes that were added to the \n         // result list in the successful calls to choose*() above.\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n         }\n         // Set numOfReplicas, since it can get out of sync with the result list\n         // if the NotEnoughReplicasException was thrown in chooseRandom().\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n-            newBlock);\n+            newBlock, null);\n       }\n \n       boolean retry \u003d false;\n       // simply add all the remaining types into unavailableStorages and give\n       // another try. No best effort is guaranteed here.\n       for (StorageType type : storageTypes.keySet()) {\n         if (!unavailableStorages.contains(type)) {\n           unavailableStorages.add(type);\n           retry \u003d true;\n         }\n       }\n       if (retry) {\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n               oldExcludedNodes);\n         }\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n-            newBlock);\n+            newBlock, null);\n       }\n     }\n     return writer;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Node chooseTarget(int numOfReplicas,\n                            Node writer,\n                            final Set\u003cNode\u003e excludedNodes,\n                            final long blocksize,\n                            final int maxNodesPerRack,\n                            final List\u003cDatanodeStorageInfo\u003e results,\n                            final boolean avoidStaleNodes,\n                            final BlockStoragePolicy storagePolicy,\n                            final EnumSet\u003cStorageType\u003e unavailableStorages,\n                            final boolean newBlock,\n                            EnumMap\u003cStorageType, Integer\u003e storageTypes) {\n    if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n      return (writer instanceof DatanodeDescriptor) ? writer : null;\n    }\n    final int numOfResults \u003d results.size();\n    final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n    if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n      writer \u003d results.get(0).getDatanodeDescriptor();\n    }\n\n    // Keep a copy of original excludedNodes\n    final Set\u003cNode\u003e oldExcludedNodes \u003d new HashSet\u003c\u003e(excludedNodes);\n\n    // choose storage types; use fallbacks for unavailable storages\n    final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n        .chooseStorageTypes((short) totalReplicasExpected,\n            DatanodeStorageInfo.toStorageTypes(results),\n            unavailableStorages, newBlock);\n    if (storageTypes \u003d\u003d null) {\n      storageTypes \u003d getRequiredStorageTypes(requiredStorageTypes);\n    }\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"storageTypes\u003d\" + storageTypes);\n    }\n\n    try {\n      if ((numOfReplicas \u003d requiredStorageTypes.size()) \u003d\u003d 0) {\n        throw new NotEnoughReplicasException(\n            \"All required storage types are unavailable: \"\n            + \" unavailableStorages\u003d\" + unavailableStorages\n            + \", storagePolicy\u003d\" + storagePolicy);\n      }\n      writer \u003d chooseTargetInOrder(numOfReplicas, writer, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, newBlock, storageTypes);\n    } catch (NotEnoughReplicasException e) {\n      final String message \u003d \"Failed to place enough replicas, still in need of \"\n          + (totalReplicasExpected - results.size()) + \" to reach \"\n          + totalReplicasExpected\n          + \" (unavailableStorages\u003d\" + unavailableStorages\n          + \", storagePolicy\u003d\" + storagePolicy\n          + \", newBlock\u003d\" + newBlock + \")\";\n\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(message, e);\n      } else {\n        LOG.warn(message + \" \" + e.getMessage());\n      }\n\n      if (avoidStaleNodes) {\n        // Retry chooseTarget again, this time not avoiding stale nodes.\n\n        // excludedNodes contains the initial excludedNodes and nodes that were\n        // not chosen because they were stale, decommissioned, etc.\n        // We need to additionally exclude the nodes that were added to the \n        // result list in the successful calls to choose*() above.\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n        }\n        // Set numOfReplicas, since it can get out of sync with the result list\n        // if the NotEnoughReplicasException was thrown in chooseRandom().\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock, null);\n      }\n\n      boolean retry \u003d false;\n      // simply add all the remaining types into unavailableStorages and give\n      // another try. No best effort is guaranteed here.\n      for (StorageType type : storageTypes.keySet()) {\n        if (!unavailableStorages.contains(type)) {\n          unavailableStorages.add(type);\n          retry \u003d true;\n        }\n      }\n      if (retry) {\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n              oldExcludedNodes);\n        }\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock, null);\n      }\n    }\n    return writer;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
          "extendedDetails": {}
        }
      ]
    },
    "0f5f9846edab3ea7e80f35000072136f998bcd46": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9006. Provide BlockPlacementPolicy that supports upgrade domain. (Ming Ma via lei)\n",
      "commitDate": "12/10/15 4:24 PM",
      "commitName": "0f5f9846edab3ea7e80f35000072136f998bcd46",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "31/08/15 5:52 PM",
      "commitNameOld": "8fa41d9dd4b923bf4141f019414a1a8b079124c6",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 41.94,
      "commitsBetweenForRepo": 298,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,96 +1,96 @@\n   private Node chooseTarget(int numOfReplicas,\n                             Node writer,\n                             final Set\u003cNode\u003e excludedNodes,\n                             final long blocksize,\n                             final int maxNodesPerRack,\n                             final List\u003cDatanodeStorageInfo\u003e results,\n                             final boolean avoidStaleNodes,\n                             final BlockStoragePolicy storagePolicy,\n                             final EnumSet\u003cStorageType\u003e unavailableStorages,\n                             final boolean newBlock) {\n     if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n       return (writer instanceof DatanodeDescriptor) ? writer : null;\n     }\n     final int numOfResults \u003d results.size();\n     final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n     if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n       writer \u003d results.get(0).getDatanodeDescriptor();\n     }\n \n     // Keep a copy of original excludedNodes\n-    final Set\u003cNode\u003e oldExcludedNodes \u003d new HashSet\u003cNode\u003e(excludedNodes);\n+    final Set\u003cNode\u003e oldExcludedNodes \u003d new HashSet\u003c\u003e(excludedNodes);\n \n     // choose storage types; use fallbacks for unavailable storages\n     final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n         .chooseStorageTypes((short) totalReplicasExpected,\n             DatanodeStorageInfo.toStorageTypes(results),\n             unavailableStorages, newBlock);\n     final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n         getRequiredStorageTypes(requiredStorageTypes);\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"storageTypes\u003d\" + storageTypes);\n     }\n \n     try {\n       if ((numOfReplicas \u003d requiredStorageTypes.size()) \u003d\u003d 0) {\n         throw new NotEnoughReplicasException(\n             \"All required storage types are unavailable: \"\n             + \" unavailableStorages\u003d\" + unavailableStorages\n             + \", storagePolicy\u003d\" + storagePolicy);\n       }\n       writer \u003d chooseTargetInOrder(numOfReplicas, writer, excludedNodes, blocksize,\n           maxNodesPerRack, results, avoidStaleNodes, newBlock, storageTypes);\n     } catch (NotEnoughReplicasException e) {\n       final String message \u003d \"Failed to place enough replicas, still in need of \"\n           + (totalReplicasExpected - results.size()) + \" to reach \"\n           + totalReplicasExpected\n           + \" (unavailableStorages\u003d\" + unavailableStorages\n           + \", storagePolicy\u003d\" + storagePolicy\n           + \", newBlock\u003d\" + newBlock + \")\";\n \n       if (LOG.isTraceEnabled()) {\n         LOG.trace(message, e);\n       } else {\n         LOG.warn(message + \" \" + e.getMessage());\n       }\n \n       if (avoidStaleNodes) {\n         // Retry chooseTarget again, this time not avoiding stale nodes.\n \n         // excludedNodes contains the initial excludedNodes and nodes that were\n         // not chosen because they were stale, decommissioned, etc.\n         // We need to additionally exclude the nodes that were added to the \n         // result list in the successful calls to choose*() above.\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n         }\n         // Set numOfReplicas, since it can get out of sync with the result list\n         // if the NotEnoughReplicasException was thrown in chooseRandom().\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n             newBlock);\n       }\n \n       boolean retry \u003d false;\n       // simply add all the remaining types into unavailableStorages and give\n       // another try. No best effort is guaranteed here.\n       for (StorageType type : storageTypes.keySet()) {\n         if (!unavailableStorages.contains(type)) {\n           unavailableStorages.add(type);\n           retry \u003d true;\n         }\n       }\n       if (retry) {\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n               oldExcludedNodes);\n         }\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n             newBlock);\n       }\n     }\n     return writer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Node chooseTarget(int numOfReplicas,\n                            Node writer,\n                            final Set\u003cNode\u003e excludedNodes,\n                            final long blocksize,\n                            final int maxNodesPerRack,\n                            final List\u003cDatanodeStorageInfo\u003e results,\n                            final boolean avoidStaleNodes,\n                            final BlockStoragePolicy storagePolicy,\n                            final EnumSet\u003cStorageType\u003e unavailableStorages,\n                            final boolean newBlock) {\n    if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n      return (writer instanceof DatanodeDescriptor) ? writer : null;\n    }\n    final int numOfResults \u003d results.size();\n    final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n    if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n      writer \u003d results.get(0).getDatanodeDescriptor();\n    }\n\n    // Keep a copy of original excludedNodes\n    final Set\u003cNode\u003e oldExcludedNodes \u003d new HashSet\u003c\u003e(excludedNodes);\n\n    // choose storage types; use fallbacks for unavailable storages\n    final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n        .chooseStorageTypes((short) totalReplicasExpected,\n            DatanodeStorageInfo.toStorageTypes(results),\n            unavailableStorages, newBlock);\n    final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n        getRequiredStorageTypes(requiredStorageTypes);\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"storageTypes\u003d\" + storageTypes);\n    }\n\n    try {\n      if ((numOfReplicas \u003d requiredStorageTypes.size()) \u003d\u003d 0) {\n        throw new NotEnoughReplicasException(\n            \"All required storage types are unavailable: \"\n            + \" unavailableStorages\u003d\" + unavailableStorages\n            + \", storagePolicy\u003d\" + storagePolicy);\n      }\n      writer \u003d chooseTargetInOrder(numOfReplicas, writer, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, newBlock, storageTypes);\n    } catch (NotEnoughReplicasException e) {\n      final String message \u003d \"Failed to place enough replicas, still in need of \"\n          + (totalReplicasExpected - results.size()) + \" to reach \"\n          + totalReplicasExpected\n          + \" (unavailableStorages\u003d\" + unavailableStorages\n          + \", storagePolicy\u003d\" + storagePolicy\n          + \", newBlock\u003d\" + newBlock + \")\";\n\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(message, e);\n      } else {\n        LOG.warn(message + \" \" + e.getMessage());\n      }\n\n      if (avoidStaleNodes) {\n        // Retry chooseTarget again, this time not avoiding stale nodes.\n\n        // excludedNodes contains the initial excludedNodes and nodes that were\n        // not chosen because they were stale, decommissioned, etc.\n        // We need to additionally exclude the nodes that were added to the \n        // result list in the successful calls to choose*() above.\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n        }\n        // Set numOfReplicas, since it can get out of sync with the result list\n        // if the NotEnoughReplicasException was thrown in chooseRandom().\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock);\n      }\n\n      boolean retry \u003d false;\n      // simply add all the remaining types into unavailableStorages and give\n      // another try. No best effort is guaranteed here.\n      for (StorageType type : storageTypes.keySet()) {\n        if (!unavailableStorages.contains(type)) {\n          unavailableStorages.add(type);\n          retry \u003d true;\n        }\n      }\n      if (retry) {\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n              oldExcludedNodes);\n        }\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock);\n      }\n    }\n    return writer;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "d505c8acd30d6f40d0632fe9c93c886a4499a9fc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8073. Split BlockPlacementPolicyDefault.chooseTarget(..) so it can be easily overrided. (Contributed by Walter Su)\n",
      "commitDate": "07/04/15 9:26 PM",
      "commitName": "d505c8acd30d6f40d0632fe9c93c886a4499a9fc",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "20/03/15 12:02 PM",
      "commitNameOld": "75ead273bea8a7dad61c4f99c3a16cab2697c498",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 18.39,
      "commitsBetweenForRepo": 154,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,129 +1,96 @@\n   private Node chooseTarget(int numOfReplicas,\n                             Node writer,\n                             final Set\u003cNode\u003e excludedNodes,\n                             final long blocksize,\n                             final int maxNodesPerRack,\n                             final List\u003cDatanodeStorageInfo\u003e results,\n                             final boolean avoidStaleNodes,\n                             final BlockStoragePolicy storagePolicy,\n                             final EnumSet\u003cStorageType\u003e unavailableStorages,\n                             final boolean newBlock) {\n     if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n       return (writer instanceof DatanodeDescriptor) ? writer : null;\n     }\n     final int numOfResults \u003d results.size();\n     final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n     if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n       writer \u003d results.get(0).getDatanodeDescriptor();\n     }\n \n     // Keep a copy of original excludedNodes\n     final Set\u003cNode\u003e oldExcludedNodes \u003d new HashSet\u003cNode\u003e(excludedNodes);\n \n     // choose storage types; use fallbacks for unavailable storages\n     final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n         .chooseStorageTypes((short) totalReplicasExpected,\n             DatanodeStorageInfo.toStorageTypes(results),\n             unavailableStorages, newBlock);\n     final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n         getRequiredStorageTypes(requiredStorageTypes);\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"storageTypes\u003d\" + storageTypes);\n     }\n \n     try {\n       if ((numOfReplicas \u003d requiredStorageTypes.size()) \u003d\u003d 0) {\n         throw new NotEnoughReplicasException(\n             \"All required storage types are unavailable: \"\n             + \" unavailableStorages\u003d\" + unavailableStorages\n             + \", storagePolicy\u003d\" + storagePolicy);\n       }\n-\n-      if (numOfResults \u003d\u003d 0) {\n-        writer \u003d chooseLocalStorage(writer, excludedNodes, blocksize,\n-            maxNodesPerRack, results, avoidStaleNodes, storageTypes, true)\n-                .getDatanodeDescriptor();\n-        if (--numOfReplicas \u003d\u003d 0) {\n-          return writer;\n-        }\n-      }\n-      final DatanodeDescriptor dn0 \u003d results.get(0).getDatanodeDescriptor();\n-      if (numOfResults \u003c\u003d 1) {\n-        chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n-            results, avoidStaleNodes, storageTypes);\n-        if (--numOfReplicas \u003d\u003d 0) {\n-          return writer;\n-        }\n-      }\n-      if (numOfResults \u003c\u003d 2) {\n-        final DatanodeDescriptor dn1 \u003d results.get(1).getDatanodeDescriptor();\n-        if (clusterMap.isOnSameRack(dn0, dn1)) {\n-          chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n-              results, avoidStaleNodes, storageTypes);\n-        } else if (newBlock){\n-          chooseLocalRack(dn1, excludedNodes, blocksize, maxNodesPerRack,\n-              results, avoidStaleNodes, storageTypes);\n-        } else {\n-          chooseLocalRack(writer, excludedNodes, blocksize, maxNodesPerRack,\n-              results, avoidStaleNodes, storageTypes);\n-        }\n-        if (--numOfReplicas \u003d\u003d 0) {\n-          return writer;\n-        }\n-      }\n-      chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,\n-          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n+      writer \u003d chooseTargetInOrder(numOfReplicas, writer, excludedNodes, blocksize,\n+          maxNodesPerRack, results, avoidStaleNodes, newBlock, storageTypes);\n     } catch (NotEnoughReplicasException e) {\n       final String message \u003d \"Failed to place enough replicas, still in need of \"\n           + (totalReplicasExpected - results.size()) + \" to reach \"\n           + totalReplicasExpected\n           + \" (unavailableStorages\u003d\" + unavailableStorages\n           + \", storagePolicy\u003d\" + storagePolicy\n           + \", newBlock\u003d\" + newBlock + \")\";\n \n       if (LOG.isTraceEnabled()) {\n         LOG.trace(message, e);\n       } else {\n         LOG.warn(message + \" \" + e.getMessage());\n       }\n \n       if (avoidStaleNodes) {\n         // Retry chooseTarget again, this time not avoiding stale nodes.\n \n         // excludedNodes contains the initial excludedNodes and nodes that were\n         // not chosen because they were stale, decommissioned, etc.\n         // We need to additionally exclude the nodes that were added to the \n         // result list in the successful calls to choose*() above.\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n         }\n         // Set numOfReplicas, since it can get out of sync with the result list\n         // if the NotEnoughReplicasException was thrown in chooseRandom().\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n             newBlock);\n       }\n \n       boolean retry \u003d false;\n       // simply add all the remaining types into unavailableStorages and give\n       // another try. No best effort is guaranteed here.\n       for (StorageType type : storageTypes.keySet()) {\n         if (!unavailableStorages.contains(type)) {\n           unavailableStorages.add(type);\n           retry \u003d true;\n         }\n       }\n       if (retry) {\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n               oldExcludedNodes);\n         }\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n             newBlock);\n       }\n     }\n     return writer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Node chooseTarget(int numOfReplicas,\n                            Node writer,\n                            final Set\u003cNode\u003e excludedNodes,\n                            final long blocksize,\n                            final int maxNodesPerRack,\n                            final List\u003cDatanodeStorageInfo\u003e results,\n                            final boolean avoidStaleNodes,\n                            final BlockStoragePolicy storagePolicy,\n                            final EnumSet\u003cStorageType\u003e unavailableStorages,\n                            final boolean newBlock) {\n    if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n      return (writer instanceof DatanodeDescriptor) ? writer : null;\n    }\n    final int numOfResults \u003d results.size();\n    final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n    if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n      writer \u003d results.get(0).getDatanodeDescriptor();\n    }\n\n    // Keep a copy of original excludedNodes\n    final Set\u003cNode\u003e oldExcludedNodes \u003d new HashSet\u003cNode\u003e(excludedNodes);\n\n    // choose storage types; use fallbacks for unavailable storages\n    final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n        .chooseStorageTypes((short) totalReplicasExpected,\n            DatanodeStorageInfo.toStorageTypes(results),\n            unavailableStorages, newBlock);\n    final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n        getRequiredStorageTypes(requiredStorageTypes);\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"storageTypes\u003d\" + storageTypes);\n    }\n\n    try {\n      if ((numOfReplicas \u003d requiredStorageTypes.size()) \u003d\u003d 0) {\n        throw new NotEnoughReplicasException(\n            \"All required storage types are unavailable: \"\n            + \" unavailableStorages\u003d\" + unavailableStorages\n            + \", storagePolicy\u003d\" + storagePolicy);\n      }\n      writer \u003d chooseTargetInOrder(numOfReplicas, writer, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, newBlock, storageTypes);\n    } catch (NotEnoughReplicasException e) {\n      final String message \u003d \"Failed to place enough replicas, still in need of \"\n          + (totalReplicasExpected - results.size()) + \" to reach \"\n          + totalReplicasExpected\n          + \" (unavailableStorages\u003d\" + unavailableStorages\n          + \", storagePolicy\u003d\" + storagePolicy\n          + \", newBlock\u003d\" + newBlock + \")\";\n\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(message, e);\n      } else {\n        LOG.warn(message + \" \" + e.getMessage());\n      }\n\n      if (avoidStaleNodes) {\n        // Retry chooseTarget again, this time not avoiding stale nodes.\n\n        // excludedNodes contains the initial excludedNodes and nodes that were\n        // not chosen because they were stale, decommissioned, etc.\n        // We need to additionally exclude the nodes that were added to the \n        // result list in the successful calls to choose*() above.\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n        }\n        // Set numOfReplicas, since it can get out of sync with the result list\n        // if the NotEnoughReplicasException was thrown in chooseRandom().\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock);\n      }\n\n      boolean retry \u003d false;\n      // simply add all the remaining types into unavailableStorages and give\n      // another try. No best effort is guaranteed here.\n      for (StorageType type : storageTypes.keySet()) {\n        if (!unavailableStorages.contains(type)) {\n          unavailableStorages.add(type);\n          retry \u003d true;\n        }\n      }\n      if (retry) {\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n              oldExcludedNodes);\n        }\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock);\n      }\n    }\n    return writer;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "ed841dd9a96e54cb84d9cae5507e47ff1c8cdf6e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6995. Block should be placed in the client\u0027s \u0027rack-local\u0027 node if \u0027client-local\u0027 node is not available (vinayakumarb)\n",
      "commitDate": "06/10/14 2:01 AM",
      "commitName": "ed841dd9a96e54cb84d9cae5507e47ff1c8cdf6e",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "24/09/14 10:05 AM",
      "commitNameOld": "073bbd805c6680f47bbfcc6e8efd708ad729bca4",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 11.66,
      "commitsBetweenForRepo": 131,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,129 +1,129 @@\n   private Node chooseTarget(int numOfReplicas,\n                             Node writer,\n                             final Set\u003cNode\u003e excludedNodes,\n                             final long blocksize,\n                             final int maxNodesPerRack,\n                             final List\u003cDatanodeStorageInfo\u003e results,\n                             final boolean avoidStaleNodes,\n                             final BlockStoragePolicy storagePolicy,\n                             final EnumSet\u003cStorageType\u003e unavailableStorages,\n                             final boolean newBlock) {\n     if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n-      return writer;\n+      return (writer instanceof DatanodeDescriptor) ? writer : null;\n     }\n     final int numOfResults \u003d results.size();\n     final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n     if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n       writer \u003d results.get(0).getDatanodeDescriptor();\n     }\n \n     // Keep a copy of original excludedNodes\n     final Set\u003cNode\u003e oldExcludedNodes \u003d new HashSet\u003cNode\u003e(excludedNodes);\n \n     // choose storage types; use fallbacks for unavailable storages\n     final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n         .chooseStorageTypes((short) totalReplicasExpected,\n             DatanodeStorageInfo.toStorageTypes(results),\n             unavailableStorages, newBlock);\n     final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n         getRequiredStorageTypes(requiredStorageTypes);\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"storageTypes\u003d\" + storageTypes);\n     }\n \n     try {\n       if ((numOfReplicas \u003d requiredStorageTypes.size()) \u003d\u003d 0) {\n         throw new NotEnoughReplicasException(\n             \"All required storage types are unavailable: \"\n             + \" unavailableStorages\u003d\" + unavailableStorages\n             + \", storagePolicy\u003d\" + storagePolicy);\n       }\n \n       if (numOfResults \u003d\u003d 0) {\n         writer \u003d chooseLocalStorage(writer, excludedNodes, blocksize,\n             maxNodesPerRack, results, avoidStaleNodes, storageTypes, true)\n                 .getDatanodeDescriptor();\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n       final DatanodeDescriptor dn0 \u003d results.get(0).getDatanodeDescriptor();\n       if (numOfResults \u003c\u003d 1) {\n         chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n             results, avoidStaleNodes, storageTypes);\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n       if (numOfResults \u003c\u003d 2) {\n         final DatanodeDescriptor dn1 \u003d results.get(1).getDatanodeDescriptor();\n         if (clusterMap.isOnSameRack(dn0, dn1)) {\n           chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n               results, avoidStaleNodes, storageTypes);\n         } else if (newBlock){\n           chooseLocalRack(dn1, excludedNodes, blocksize, maxNodesPerRack,\n               results, avoidStaleNodes, storageTypes);\n         } else {\n           chooseLocalRack(writer, excludedNodes, blocksize, maxNodesPerRack,\n               results, avoidStaleNodes, storageTypes);\n         }\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n       chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,\n           maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n     } catch (NotEnoughReplicasException e) {\n       final String message \u003d \"Failed to place enough replicas, still in need of \"\n           + (totalReplicasExpected - results.size()) + \" to reach \"\n           + totalReplicasExpected\n           + \" (unavailableStorages\u003d\" + unavailableStorages\n           + \", storagePolicy\u003d\" + storagePolicy\n           + \", newBlock\u003d\" + newBlock + \")\";\n \n       if (LOG.isTraceEnabled()) {\n         LOG.trace(message, e);\n       } else {\n         LOG.warn(message + \" \" + e.getMessage());\n       }\n \n       if (avoidStaleNodes) {\n         // Retry chooseTarget again, this time not avoiding stale nodes.\n \n         // excludedNodes contains the initial excludedNodes and nodes that were\n         // not chosen because they were stale, decommissioned, etc.\n         // We need to additionally exclude the nodes that were added to the \n         // result list in the successful calls to choose*() above.\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n         }\n         // Set numOfReplicas, since it can get out of sync with the result list\n         // if the NotEnoughReplicasException was thrown in chooseRandom().\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n             newBlock);\n       }\n \n       boolean retry \u003d false;\n       // simply add all the remaining types into unavailableStorages and give\n       // another try. No best effort is guaranteed here.\n       for (StorageType type : storageTypes.keySet()) {\n         if (!unavailableStorages.contains(type)) {\n           unavailableStorages.add(type);\n           retry \u003d true;\n         }\n       }\n       if (retry) {\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n               oldExcludedNodes);\n         }\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n             newBlock);\n       }\n     }\n     return writer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Node chooseTarget(int numOfReplicas,\n                            Node writer,\n                            final Set\u003cNode\u003e excludedNodes,\n                            final long blocksize,\n                            final int maxNodesPerRack,\n                            final List\u003cDatanodeStorageInfo\u003e results,\n                            final boolean avoidStaleNodes,\n                            final BlockStoragePolicy storagePolicy,\n                            final EnumSet\u003cStorageType\u003e unavailableStorages,\n                            final boolean newBlock) {\n    if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n      return (writer instanceof DatanodeDescriptor) ? writer : null;\n    }\n    final int numOfResults \u003d results.size();\n    final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n    if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n      writer \u003d results.get(0).getDatanodeDescriptor();\n    }\n\n    // Keep a copy of original excludedNodes\n    final Set\u003cNode\u003e oldExcludedNodes \u003d new HashSet\u003cNode\u003e(excludedNodes);\n\n    // choose storage types; use fallbacks for unavailable storages\n    final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n        .chooseStorageTypes((short) totalReplicasExpected,\n            DatanodeStorageInfo.toStorageTypes(results),\n            unavailableStorages, newBlock);\n    final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n        getRequiredStorageTypes(requiredStorageTypes);\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"storageTypes\u003d\" + storageTypes);\n    }\n\n    try {\n      if ((numOfReplicas \u003d requiredStorageTypes.size()) \u003d\u003d 0) {\n        throw new NotEnoughReplicasException(\n            \"All required storage types are unavailable: \"\n            + \" unavailableStorages\u003d\" + unavailableStorages\n            + \", storagePolicy\u003d\" + storagePolicy);\n      }\n\n      if (numOfResults \u003d\u003d 0) {\n        writer \u003d chooseLocalStorage(writer, excludedNodes, blocksize,\n            maxNodesPerRack, results, avoidStaleNodes, storageTypes, true)\n                .getDatanodeDescriptor();\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      final DatanodeDescriptor dn0 \u003d results.get(0).getDatanodeDescriptor();\n      if (numOfResults \u003c\u003d 1) {\n        chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n            results, avoidStaleNodes, storageTypes);\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      if (numOfResults \u003c\u003d 2) {\n        final DatanodeDescriptor dn1 \u003d results.get(1).getDatanodeDescriptor();\n        if (clusterMap.isOnSameRack(dn0, dn1)) {\n          chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, storageTypes);\n        } else if (newBlock){\n          chooseLocalRack(dn1, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, storageTypes);\n        } else {\n          chooseLocalRack(writer, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, storageTypes);\n        }\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    } catch (NotEnoughReplicasException e) {\n      final String message \u003d \"Failed to place enough replicas, still in need of \"\n          + (totalReplicasExpected - results.size()) + \" to reach \"\n          + totalReplicasExpected\n          + \" (unavailableStorages\u003d\" + unavailableStorages\n          + \", storagePolicy\u003d\" + storagePolicy\n          + \", newBlock\u003d\" + newBlock + \")\";\n\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(message, e);\n      } else {\n        LOG.warn(message + \" \" + e.getMessage());\n      }\n\n      if (avoidStaleNodes) {\n        // Retry chooseTarget again, this time not avoiding stale nodes.\n\n        // excludedNodes contains the initial excludedNodes and nodes that were\n        // not chosen because they were stale, decommissioned, etc.\n        // We need to additionally exclude the nodes that were added to the \n        // result list in the successful calls to choose*() above.\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n        }\n        // Set numOfReplicas, since it can get out of sync with the result list\n        // if the NotEnoughReplicasException was thrown in chooseRandom().\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock);\n      }\n\n      boolean retry \u003d false;\n      // simply add all the remaining types into unavailableStorages and give\n      // another try. No best effort is guaranteed here.\n      for (StorageType type : storageTypes.keySet()) {\n        if (!unavailableStorages.contains(type)) {\n          unavailableStorages.add(type);\n          retry \u003d true;\n        }\n      }\n      if (retry) {\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n              oldExcludedNodes);\n        }\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock);\n      }\n    }\n    return writer;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "22a41dce4af4d5b533ba875b322551db1c152878": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6997: add more tests for data migration and replicaion.\n",
      "commitDate": "06/09/14 4:44 PM",
      "commitName": "22a41dce4af4d5b533ba875b322551db1c152878",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "04/09/14 2:19 PM",
      "commitNameOld": "e08701ec71f7c10d8f15122d90c35f9f22e40837",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 2.1,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,122 +1,129 @@\n   private Node chooseTarget(int numOfReplicas,\n                             Node writer,\n                             final Set\u003cNode\u003e excludedNodes,\n                             final long blocksize,\n                             final int maxNodesPerRack,\n                             final List\u003cDatanodeStorageInfo\u003e results,\n                             final boolean avoidStaleNodes,\n                             final BlockStoragePolicy storagePolicy,\n                             final EnumSet\u003cStorageType\u003e unavailableStorages,\n                             final boolean newBlock) {\n     if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n       return writer;\n     }\n     final int numOfResults \u003d results.size();\n     final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n     if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n       writer \u003d results.get(0).getDatanodeDescriptor();\n     }\n \n     // Keep a copy of original excludedNodes\n     final Set\u003cNode\u003e oldExcludedNodes \u003d new HashSet\u003cNode\u003e(excludedNodes);\n \n     // choose storage types; use fallbacks for unavailable storages\n     final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n         .chooseStorageTypes((short) totalReplicasExpected,\n             DatanodeStorageInfo.toStorageTypes(results),\n             unavailableStorages, newBlock);\n     final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n         getRequiredStorageTypes(requiredStorageTypes);\n+    if (LOG.isTraceEnabled()) {\n+      LOG.trace(\"storageTypes\u003d\" + storageTypes);\n+    }\n \n     try {\n       if ((numOfReplicas \u003d requiredStorageTypes.size()) \u003d\u003d 0) {\n         throw new NotEnoughReplicasException(\n             \"All required storage types are unavailable: \"\n             + \" unavailableStorages\u003d\" + unavailableStorages\n             + \", storagePolicy\u003d\" + storagePolicy);\n       }\n \n       if (numOfResults \u003d\u003d 0) {\n         writer \u003d chooseLocalStorage(writer, excludedNodes, blocksize,\n             maxNodesPerRack, results, avoidStaleNodes, storageTypes, true)\n                 .getDatanodeDescriptor();\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n       final DatanodeDescriptor dn0 \u003d results.get(0).getDatanodeDescriptor();\n       if (numOfResults \u003c\u003d 1) {\n         chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n             results, avoidStaleNodes, storageTypes);\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n       if (numOfResults \u003c\u003d 2) {\n         final DatanodeDescriptor dn1 \u003d results.get(1).getDatanodeDescriptor();\n         if (clusterMap.isOnSameRack(dn0, dn1)) {\n           chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n               results, avoidStaleNodes, storageTypes);\n         } else if (newBlock){\n           chooseLocalRack(dn1, excludedNodes, blocksize, maxNodesPerRack,\n               results, avoidStaleNodes, storageTypes);\n         } else {\n           chooseLocalRack(writer, excludedNodes, blocksize, maxNodesPerRack,\n               results, avoidStaleNodes, storageTypes);\n         }\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n       chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,\n           maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n     } catch (NotEnoughReplicasException e) {\n       final String message \u003d \"Failed to place enough replicas, still in need of \"\n           + (totalReplicasExpected - results.size()) + \" to reach \"\n-          + totalReplicasExpected + \".\";\n+          + totalReplicasExpected\n+          + \" (unavailableStorages\u003d\" + unavailableStorages\n+          + \", storagePolicy\u003d\" + storagePolicy\n+          + \", newBlock\u003d\" + newBlock + \")\";\n+\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(message, e);\n       } else {\n         LOG.warn(message + \" \" + e.getMessage());\n       }\n \n       if (avoidStaleNodes) {\n         // Retry chooseTarget again, this time not avoiding stale nodes.\n \n         // excludedNodes contains the initial excludedNodes and nodes that were\n         // not chosen because they were stale, decommissioned, etc.\n         // We need to additionally exclude the nodes that were added to the \n         // result list in the successful calls to choose*() above.\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n         }\n         // Set numOfReplicas, since it can get out of sync with the result list\n         // if the NotEnoughReplicasException was thrown in chooseRandom().\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n             newBlock);\n       }\n \n       boolean retry \u003d false;\n       // simply add all the remaining types into unavailableStorages and give\n       // another try. No best effort is guaranteed here.\n       for (StorageType type : storageTypes.keySet()) {\n         if (!unavailableStorages.contains(type)) {\n           unavailableStorages.add(type);\n           retry \u003d true;\n         }\n       }\n       if (retry) {\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n               oldExcludedNodes);\n         }\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n             newBlock);\n       }\n     }\n     return writer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Node chooseTarget(int numOfReplicas,\n                            Node writer,\n                            final Set\u003cNode\u003e excludedNodes,\n                            final long blocksize,\n                            final int maxNodesPerRack,\n                            final List\u003cDatanodeStorageInfo\u003e results,\n                            final boolean avoidStaleNodes,\n                            final BlockStoragePolicy storagePolicy,\n                            final EnumSet\u003cStorageType\u003e unavailableStorages,\n                            final boolean newBlock) {\n    if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n      return writer;\n    }\n    final int numOfResults \u003d results.size();\n    final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n    if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n      writer \u003d results.get(0).getDatanodeDescriptor();\n    }\n\n    // Keep a copy of original excludedNodes\n    final Set\u003cNode\u003e oldExcludedNodes \u003d new HashSet\u003cNode\u003e(excludedNodes);\n\n    // choose storage types; use fallbacks for unavailable storages\n    final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n        .chooseStorageTypes((short) totalReplicasExpected,\n            DatanodeStorageInfo.toStorageTypes(results),\n            unavailableStorages, newBlock);\n    final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n        getRequiredStorageTypes(requiredStorageTypes);\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"storageTypes\u003d\" + storageTypes);\n    }\n\n    try {\n      if ((numOfReplicas \u003d requiredStorageTypes.size()) \u003d\u003d 0) {\n        throw new NotEnoughReplicasException(\n            \"All required storage types are unavailable: \"\n            + \" unavailableStorages\u003d\" + unavailableStorages\n            + \", storagePolicy\u003d\" + storagePolicy);\n      }\n\n      if (numOfResults \u003d\u003d 0) {\n        writer \u003d chooseLocalStorage(writer, excludedNodes, blocksize,\n            maxNodesPerRack, results, avoidStaleNodes, storageTypes, true)\n                .getDatanodeDescriptor();\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      final DatanodeDescriptor dn0 \u003d results.get(0).getDatanodeDescriptor();\n      if (numOfResults \u003c\u003d 1) {\n        chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n            results, avoidStaleNodes, storageTypes);\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      if (numOfResults \u003c\u003d 2) {\n        final DatanodeDescriptor dn1 \u003d results.get(1).getDatanodeDescriptor();\n        if (clusterMap.isOnSameRack(dn0, dn1)) {\n          chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, storageTypes);\n        } else if (newBlock){\n          chooseLocalRack(dn1, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, storageTypes);\n        } else {\n          chooseLocalRack(writer, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, storageTypes);\n        }\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    } catch (NotEnoughReplicasException e) {\n      final String message \u003d \"Failed to place enough replicas, still in need of \"\n          + (totalReplicasExpected - results.size()) + \" to reach \"\n          + totalReplicasExpected\n          + \" (unavailableStorages\u003d\" + unavailableStorages\n          + \", storagePolicy\u003d\" + storagePolicy\n          + \", newBlock\u003d\" + newBlock + \")\";\n\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(message, e);\n      } else {\n        LOG.warn(message + \" \" + e.getMessage());\n      }\n\n      if (avoidStaleNodes) {\n        // Retry chooseTarget again, this time not avoiding stale nodes.\n\n        // excludedNodes contains the initial excludedNodes and nodes that were\n        // not chosen because they were stale, decommissioned, etc.\n        // We need to additionally exclude the nodes that were added to the \n        // result list in the successful calls to choose*() above.\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n        }\n        // Set numOfReplicas, since it can get out of sync with the result list\n        // if the NotEnoughReplicasException was thrown in chooseRandom().\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock);\n      }\n\n      boolean retry \u003d false;\n      // simply add all the remaining types into unavailableStorages and give\n      // another try. No best effort is guaranteed here.\n      for (StorageType type : storageTypes.keySet()) {\n        if (!unavailableStorages.contains(type)) {\n          unavailableStorages.add(type);\n          retry \u003d true;\n        }\n      }\n      if (retry) {\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n              oldExcludedNodes);\n        }\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock);\n      }\n    }\n    return writer;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "e08701ec71f7c10d8f15122d90c35f9f22e40837": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6961. Archival Storage: BlockPlacementPolicy#chooseTarget should check each valid storage type in each choosing round.\n",
      "commitDate": "04/09/14 2:19 PM",
      "commitName": "e08701ec71f7c10d8f15122d90c35f9f22e40837",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "27/08/14 2:08 PM",
      "commitNameOld": "b7ded466b00db0fe273058b844d56d810e0f8cc2",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 8.01,
      "commitsBetweenForRepo": 50,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,113 +1,122 @@\n   private Node chooseTarget(int numOfReplicas,\n                             Node writer,\n                             final Set\u003cNode\u003e excludedNodes,\n                             final long blocksize,\n                             final int maxNodesPerRack,\n                             final List\u003cDatanodeStorageInfo\u003e results,\n                             final boolean avoidStaleNodes,\n                             final BlockStoragePolicy storagePolicy,\n                             final EnumSet\u003cStorageType\u003e unavailableStorages,\n                             final boolean newBlock) {\n     if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n       return writer;\n     }\n     final int numOfResults \u003d results.size();\n     final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n     if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n       writer \u003d results.get(0).getDatanodeDescriptor();\n     }\n \n     // Keep a copy of original excludedNodes\n-    final Set\u003cNode\u003e oldExcludedNodes \u003d avoidStaleNodes ? \n-        new HashSet\u003cNode\u003e(excludedNodes) : null;\n+    final Set\u003cNode\u003e oldExcludedNodes \u003d new HashSet\u003cNode\u003e(excludedNodes);\n \n     // choose storage types; use fallbacks for unavailable storages\n-    final List\u003cStorageType\u003e storageTypes \u003d storagePolicy.chooseStorageTypes(\n-        (short)totalReplicasExpected, DatanodeStorageInfo.toStorageTypes(results),\n-        unavailableStorages, newBlock);\n+    final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n+        .chooseStorageTypes((short) totalReplicasExpected,\n+            DatanodeStorageInfo.toStorageTypes(results),\n+            unavailableStorages, newBlock);\n+    final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n+        getRequiredStorageTypes(requiredStorageTypes);\n \n-    StorageType curStorageType \u003d null;\n     try {\n-      if ((numOfReplicas \u003d storageTypes.size()) \u003d\u003d 0) {\n+      if ((numOfReplicas \u003d requiredStorageTypes.size()) \u003d\u003d 0) {\n         throw new NotEnoughReplicasException(\n             \"All required storage types are unavailable: \"\n             + \" unavailableStorages\u003d\" + unavailableStorages\n             + \", storagePolicy\u003d\" + storagePolicy);\n       }\n \n       if (numOfResults \u003d\u003d 0) {\n-        curStorageType \u003d storageTypes.remove(0);\n         writer \u003d chooseLocalStorage(writer, excludedNodes, blocksize,\n-            maxNodesPerRack, results, avoidStaleNodes, curStorageType, true)\n+            maxNodesPerRack, results, avoidStaleNodes, storageTypes, true)\n                 .getDatanodeDescriptor();\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n       final DatanodeDescriptor dn0 \u003d results.get(0).getDatanodeDescriptor();\n       if (numOfResults \u003c\u003d 1) {\n-        curStorageType \u003d storageTypes.remove(0);\n         chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n-            results, avoidStaleNodes, curStorageType);\n+            results, avoidStaleNodes, storageTypes);\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n       if (numOfResults \u003c\u003d 2) {\n         final DatanodeDescriptor dn1 \u003d results.get(1).getDatanodeDescriptor();\n-        curStorageType \u003d storageTypes.remove(0);\n         if (clusterMap.isOnSameRack(dn0, dn1)) {\n           chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n-              results, avoidStaleNodes, curStorageType);\n+              results, avoidStaleNodes, storageTypes);\n         } else if (newBlock){\n           chooseLocalRack(dn1, excludedNodes, blocksize, maxNodesPerRack,\n-              results, avoidStaleNodes, curStorageType);\n+              results, avoidStaleNodes, storageTypes);\n         } else {\n           chooseLocalRack(writer, excludedNodes, blocksize, maxNodesPerRack,\n-              results, avoidStaleNodes, curStorageType);\n+              results, avoidStaleNodes, storageTypes);\n         }\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n-      curStorageType \u003d storageTypes.remove(0);\n       chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,\n-          maxNodesPerRack, results, avoidStaleNodes, curStorageType);\n+          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n     } catch (NotEnoughReplicasException e) {\n       final String message \u003d \"Failed to place enough replicas, still in need of \"\n           + (totalReplicasExpected - results.size()) + \" to reach \"\n           + totalReplicasExpected + \".\";\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(message, e);\n       } else {\n         LOG.warn(message + \" \" + e.getMessage());\n       }\n \n       if (avoidStaleNodes) {\n         // Retry chooseTarget again, this time not avoiding stale nodes.\n \n         // excludedNodes contains the initial excludedNodes and nodes that were\n         // not chosen because they were stale, decommissioned, etc.\n         // We need to additionally exclude the nodes that were added to the \n         // result list in the successful calls to choose*() above.\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n         }\n         // Set numOfReplicas, since it can get out of sync with the result list\n         // if the NotEnoughReplicasException was thrown in chooseRandom().\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n             newBlock);\n       }\n \n-      if (storageTypes.size() \u003e 0) {\n-        // Retry chooseTarget with fallback storage types\n-        unavailableStorages.add(curStorageType);\n-        return chooseTarget(numOfReplicas, writer, excludedNodes, blocksize,\n+      boolean retry \u003d false;\n+      // simply add all the remaining types into unavailableStorages and give\n+      // another try. No best effort is guaranteed here.\n+      for (StorageType type : storageTypes.keySet()) {\n+        if (!unavailableStorages.contains(type)) {\n+          unavailableStorages.add(type);\n+          retry \u003d true;\n+        }\n+      }\n+      if (retry) {\n+        for (DatanodeStorageInfo resultStorage : results) {\n+          addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n+              oldExcludedNodes);\n+        }\n+        numOfReplicas \u003d totalReplicasExpected - results.size();\n+        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n             newBlock);\n       }\n     }\n     return writer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Node chooseTarget(int numOfReplicas,\n                            Node writer,\n                            final Set\u003cNode\u003e excludedNodes,\n                            final long blocksize,\n                            final int maxNodesPerRack,\n                            final List\u003cDatanodeStorageInfo\u003e results,\n                            final boolean avoidStaleNodes,\n                            final BlockStoragePolicy storagePolicy,\n                            final EnumSet\u003cStorageType\u003e unavailableStorages,\n                            final boolean newBlock) {\n    if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n      return writer;\n    }\n    final int numOfResults \u003d results.size();\n    final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n    if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n      writer \u003d results.get(0).getDatanodeDescriptor();\n    }\n\n    // Keep a copy of original excludedNodes\n    final Set\u003cNode\u003e oldExcludedNodes \u003d new HashSet\u003cNode\u003e(excludedNodes);\n\n    // choose storage types; use fallbacks for unavailable storages\n    final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n        .chooseStorageTypes((short) totalReplicasExpected,\n            DatanodeStorageInfo.toStorageTypes(results),\n            unavailableStorages, newBlock);\n    final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n        getRequiredStorageTypes(requiredStorageTypes);\n\n    try {\n      if ((numOfReplicas \u003d requiredStorageTypes.size()) \u003d\u003d 0) {\n        throw new NotEnoughReplicasException(\n            \"All required storage types are unavailable: \"\n            + \" unavailableStorages\u003d\" + unavailableStorages\n            + \", storagePolicy\u003d\" + storagePolicy);\n      }\n\n      if (numOfResults \u003d\u003d 0) {\n        writer \u003d chooseLocalStorage(writer, excludedNodes, blocksize,\n            maxNodesPerRack, results, avoidStaleNodes, storageTypes, true)\n                .getDatanodeDescriptor();\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      final DatanodeDescriptor dn0 \u003d results.get(0).getDatanodeDescriptor();\n      if (numOfResults \u003c\u003d 1) {\n        chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n            results, avoidStaleNodes, storageTypes);\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      if (numOfResults \u003c\u003d 2) {\n        final DatanodeDescriptor dn1 \u003d results.get(1).getDatanodeDescriptor();\n        if (clusterMap.isOnSameRack(dn0, dn1)) {\n          chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, storageTypes);\n        } else if (newBlock){\n          chooseLocalRack(dn1, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, storageTypes);\n        } else {\n          chooseLocalRack(writer, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, storageTypes);\n        }\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    } catch (NotEnoughReplicasException e) {\n      final String message \u003d \"Failed to place enough replicas, still in need of \"\n          + (totalReplicasExpected - results.size()) + \" to reach \"\n          + totalReplicasExpected + \".\";\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(message, e);\n      } else {\n        LOG.warn(message + \" \" + e.getMessage());\n      }\n\n      if (avoidStaleNodes) {\n        // Retry chooseTarget again, this time not avoiding stale nodes.\n\n        // excludedNodes contains the initial excludedNodes and nodes that were\n        // not chosen because they were stale, decommissioned, etc.\n        // We need to additionally exclude the nodes that were added to the \n        // result list in the successful calls to choose*() above.\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n        }\n        // Set numOfReplicas, since it can get out of sync with the result list\n        // if the NotEnoughReplicasException was thrown in chooseRandom().\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock);\n      }\n\n      boolean retry \u003d false;\n      // simply add all the remaining types into unavailableStorages and give\n      // another try. No best effort is guaranteed here.\n      for (StorageType type : storageTypes.keySet()) {\n        if (!unavailableStorages.contains(type)) {\n          unavailableStorages.add(type);\n          retry \u003d true;\n        }\n      }\n      if (retry) {\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(),\n              oldExcludedNodes);\n        }\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock);\n      }\n    }\n    return writer;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "e69954d22cc97eb3818c8ee7c3f623a5d0497b54": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6906. Archival Storage: Add more tests for BlockStoragePolicy. Contributed by Tsz Wo Nicholas Sze.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-6584@1619628 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/08/14 4:42 PM",
      "commitName": "e69954d22cc97eb3818c8ee7c3f623a5d0497b54",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "23/07/14 10:25 AM",
      "commitNameOld": "ac5e8aed7ca1e9493f96f8795d0caafd5282b9a7",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 29.26,
      "commitsBetweenForRepo": 251,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,113 +1,113 @@\n   private Node chooseTarget(int numOfReplicas,\n                             Node writer,\n                             final Set\u003cNode\u003e excludedNodes,\n                             final long blocksize,\n                             final int maxNodesPerRack,\n                             final List\u003cDatanodeStorageInfo\u003e results,\n                             final boolean avoidStaleNodes,\n                             final BlockStoragePolicy storagePolicy,\n                             final EnumSet\u003cStorageType\u003e unavailableStorages,\n                             final boolean newBlock) {\n     if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n       return writer;\n     }\n     final int numOfResults \u003d results.size();\n     final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n     if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n       writer \u003d results.get(0).getDatanodeDescriptor();\n     }\n \n     // Keep a copy of original excludedNodes\n     final Set\u003cNode\u003e oldExcludedNodes \u003d avoidStaleNodes ? \n         new HashSet\u003cNode\u003e(excludedNodes) : null;\n \n     // choose storage types; use fallbacks for unavailable storages\n-    final List\u003cStorageType\u003e storageTypes \u003d selectStorageTypes(storagePolicy,\n+    final List\u003cStorageType\u003e storageTypes \u003d storagePolicy.chooseStorageTypes(\n         (short)totalReplicasExpected, DatanodeStorageInfo.toStorageTypes(results),\n         unavailableStorages, newBlock);\n \n     StorageType curStorageType \u003d null;\n     try {\n       if ((numOfReplicas \u003d storageTypes.size()) \u003d\u003d 0) {\n         throw new NotEnoughReplicasException(\n             \"All required storage types are unavailable: \"\n             + \" unavailableStorages\u003d\" + unavailableStorages\n             + \", storagePolicy\u003d\" + storagePolicy);\n       }\n \n       if (numOfResults \u003d\u003d 0) {\n         curStorageType \u003d storageTypes.remove(0);\n         writer \u003d chooseLocalStorage(writer, excludedNodes, blocksize,\n             maxNodesPerRack, results, avoidStaleNodes, curStorageType, true)\n                 .getDatanodeDescriptor();\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n       final DatanodeDescriptor dn0 \u003d results.get(0).getDatanodeDescriptor();\n       if (numOfResults \u003c\u003d 1) {\n         curStorageType \u003d storageTypes.remove(0);\n         chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n             results, avoidStaleNodes, curStorageType);\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n       if (numOfResults \u003c\u003d 2) {\n         final DatanodeDescriptor dn1 \u003d results.get(1).getDatanodeDescriptor();\n         curStorageType \u003d storageTypes.remove(0);\n         if (clusterMap.isOnSameRack(dn0, dn1)) {\n           chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n               results, avoidStaleNodes, curStorageType);\n         } else if (newBlock){\n           chooseLocalRack(dn1, excludedNodes, blocksize, maxNodesPerRack,\n               results, avoidStaleNodes, curStorageType);\n         } else {\n           chooseLocalRack(writer, excludedNodes, blocksize, maxNodesPerRack,\n               results, avoidStaleNodes, curStorageType);\n         }\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n       curStorageType \u003d storageTypes.remove(0);\n       chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,\n           maxNodesPerRack, results, avoidStaleNodes, curStorageType);\n     } catch (NotEnoughReplicasException e) {\n       final String message \u003d \"Failed to place enough replicas, still in need of \"\n           + (totalReplicasExpected - results.size()) + \" to reach \"\n           + totalReplicasExpected + \".\";\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(message, e);\n       } else {\n         LOG.warn(message + \" \" + e.getMessage());\n       }\n \n       if (avoidStaleNodes) {\n         // Retry chooseTarget again, this time not avoiding stale nodes.\n \n         // excludedNodes contains the initial excludedNodes and nodes that were\n         // not chosen because they were stale, decommissioned, etc.\n         // We need to additionally exclude the nodes that were added to the \n         // result list in the successful calls to choose*() above.\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n         }\n         // Set numOfReplicas, since it can get out of sync with the result list\n         // if the NotEnoughReplicasException was thrown in chooseRandom().\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n             newBlock);\n       }\n \n       if (storageTypes.size() \u003e 0) {\n         // Retry chooseTarget with fallback storage types\n         unavailableStorages.add(curStorageType);\n         return chooseTarget(numOfReplicas, writer, excludedNodes, blocksize,\n             maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n             newBlock);\n       }\n     }\n     return writer;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Node chooseTarget(int numOfReplicas,\n                            Node writer,\n                            final Set\u003cNode\u003e excludedNodes,\n                            final long blocksize,\n                            final int maxNodesPerRack,\n                            final List\u003cDatanodeStorageInfo\u003e results,\n                            final boolean avoidStaleNodes,\n                            final BlockStoragePolicy storagePolicy,\n                            final EnumSet\u003cStorageType\u003e unavailableStorages,\n                            final boolean newBlock) {\n    if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n      return writer;\n    }\n    final int numOfResults \u003d results.size();\n    final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n    if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n      writer \u003d results.get(0).getDatanodeDescriptor();\n    }\n\n    // Keep a copy of original excludedNodes\n    final Set\u003cNode\u003e oldExcludedNodes \u003d avoidStaleNodes ? \n        new HashSet\u003cNode\u003e(excludedNodes) : null;\n\n    // choose storage types; use fallbacks for unavailable storages\n    final List\u003cStorageType\u003e storageTypes \u003d storagePolicy.chooseStorageTypes(\n        (short)totalReplicasExpected, DatanodeStorageInfo.toStorageTypes(results),\n        unavailableStorages, newBlock);\n\n    StorageType curStorageType \u003d null;\n    try {\n      if ((numOfReplicas \u003d storageTypes.size()) \u003d\u003d 0) {\n        throw new NotEnoughReplicasException(\n            \"All required storage types are unavailable: \"\n            + \" unavailableStorages\u003d\" + unavailableStorages\n            + \", storagePolicy\u003d\" + storagePolicy);\n      }\n\n      if (numOfResults \u003d\u003d 0) {\n        curStorageType \u003d storageTypes.remove(0);\n        writer \u003d chooseLocalStorage(writer, excludedNodes, blocksize,\n            maxNodesPerRack, results, avoidStaleNodes, curStorageType, true)\n                .getDatanodeDescriptor();\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      final DatanodeDescriptor dn0 \u003d results.get(0).getDatanodeDescriptor();\n      if (numOfResults \u003c\u003d 1) {\n        curStorageType \u003d storageTypes.remove(0);\n        chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n            results, avoidStaleNodes, curStorageType);\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      if (numOfResults \u003c\u003d 2) {\n        final DatanodeDescriptor dn1 \u003d results.get(1).getDatanodeDescriptor();\n        curStorageType \u003d storageTypes.remove(0);\n        if (clusterMap.isOnSameRack(dn0, dn1)) {\n          chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, curStorageType);\n        } else if (newBlock){\n          chooseLocalRack(dn1, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, curStorageType);\n        } else {\n          chooseLocalRack(writer, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, curStorageType);\n        }\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      curStorageType \u003d storageTypes.remove(0);\n      chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, curStorageType);\n    } catch (NotEnoughReplicasException e) {\n      final String message \u003d \"Failed to place enough replicas, still in need of \"\n          + (totalReplicasExpected - results.size()) + \" to reach \"\n          + totalReplicasExpected + \".\";\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(message, e);\n      } else {\n        LOG.warn(message + \" \" + e.getMessage());\n      }\n\n      if (avoidStaleNodes) {\n        // Retry chooseTarget again, this time not avoiding stale nodes.\n\n        // excludedNodes contains the initial excludedNodes and nodes that were\n        // not chosen because they were stale, decommissioned, etc.\n        // We need to additionally exclude the nodes that were added to the \n        // result list in the successful calls to choose*() above.\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n        }\n        // Set numOfReplicas, since it can get out of sync with the result list\n        // if the NotEnoughReplicasException was thrown in chooseRandom().\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock);\n      }\n\n      if (storageTypes.size() \u003e 0) {\n        // Retry chooseTarget with fallback storage types\n        unavailableStorages.add(curStorageType);\n        return chooseTarget(numOfReplicas, writer, excludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock);\n      }\n    }\n    return writer;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "ac5e8aed7ca1e9493f96f8795d0caafd5282b9a7": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6686. Change BlockPlacementPolicy to use fallback when some storage types are unavailable.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-6584@1612880 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/07/14 10:25 AM",
      "commitName": "ac5e8aed7ca1e9493f96f8795d0caafd5282b9a7",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6686. Change BlockPlacementPolicy to use fallback when some storage types are unavailable.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-6584@1612880 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/07/14 10:25 AM",
          "commitName": "ac5e8aed7ca1e9493f96f8795d0caafd5282b9a7",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/07/14 4:37 PM",
          "commitNameOld": "3de6c61f860c6494ed7843e0858c1d7a6a0918a2",
          "commitAuthorOld": "",
          "daysBetweenCommits": 1.74,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,88 +1,113 @@\n   private Node chooseTarget(int numOfReplicas,\n                             Node writer,\n                             final Set\u003cNode\u003e excludedNodes,\n                             final long blocksize,\n                             final int maxNodesPerRack,\n                             final List\u003cDatanodeStorageInfo\u003e results,\n                             final boolean avoidStaleNodes,\n-                            final BlockStoragePolicy storagePolicy) {\n+                            final BlockStoragePolicy storagePolicy,\n+                            final EnumSet\u003cStorageType\u003e unavailableStorages,\n+                            final boolean newBlock) {\n     if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n       return writer;\n     }\n-    int totalReplicasExpected \u003d numOfReplicas + results.size();\n-      \n-    int numOfResults \u003d results.size();\n-    boolean newBlock \u003d (numOfResults\u003d\u003d0);\n+    final int numOfResults \u003d results.size();\n+    final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n     if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n       writer \u003d results.get(0).getDatanodeDescriptor();\n     }\n \n     // Keep a copy of original excludedNodes\n     final Set\u003cNode\u003e oldExcludedNodes \u003d avoidStaleNodes ? \n         new HashSet\u003cNode\u003e(excludedNodes) : null;\n-    final List\u003cStorageType\u003e storageTypes \u003d storagePolicy.chooseStorageTypes(\n-        (short)totalReplicasExpected, DatanodeStorageInfo.toStorageTypes(results));\n+\n+    // choose storage types; use fallbacks for unavailable storages\n+    final List\u003cStorageType\u003e storageTypes \u003d selectStorageTypes(storagePolicy,\n+        (short)totalReplicasExpected, DatanodeStorageInfo.toStorageTypes(results),\n+        unavailableStorages, newBlock);\n+\n+    StorageType curStorageType \u003d null;\n     try {\n+      if ((numOfReplicas \u003d storageTypes.size()) \u003d\u003d 0) {\n+        throw new NotEnoughReplicasException(\n+            \"All required storage types are unavailable: \"\n+            + \" unavailableStorages\u003d\" + unavailableStorages\n+            + \", storagePolicy\u003d\" + storagePolicy);\n+      }\n+\n       if (numOfResults \u003d\u003d 0) {\n+        curStorageType \u003d storageTypes.remove(0);\n         writer \u003d chooseLocalStorage(writer, excludedNodes, blocksize,\n-            maxNodesPerRack, results, avoidStaleNodes, storageTypes.remove(0), true)\n+            maxNodesPerRack, results, avoidStaleNodes, curStorageType, true)\n                 .getDatanodeDescriptor();\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n       final DatanodeDescriptor dn0 \u003d results.get(0).getDatanodeDescriptor();\n       if (numOfResults \u003c\u003d 1) {\n+        curStorageType \u003d storageTypes.remove(0);\n         chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n-            results, avoidStaleNodes, storageTypes.remove(0));\n+            results, avoidStaleNodes, curStorageType);\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n       if (numOfResults \u003c\u003d 2) {\n         final DatanodeDescriptor dn1 \u003d results.get(1).getDatanodeDescriptor();\n+        curStorageType \u003d storageTypes.remove(0);\n         if (clusterMap.isOnSameRack(dn0, dn1)) {\n           chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n-              results, avoidStaleNodes, storageTypes.remove(0));\n+              results, avoidStaleNodes, curStorageType);\n         } else if (newBlock){\n           chooseLocalRack(dn1, excludedNodes, blocksize, maxNodesPerRack,\n-              results, avoidStaleNodes, storageTypes.remove(0));\n+              results, avoidStaleNodes, curStorageType);\n         } else {\n           chooseLocalRack(writer, excludedNodes, blocksize, maxNodesPerRack,\n-              results, avoidStaleNodes, storageTypes.remove(0));\n+              results, avoidStaleNodes, curStorageType);\n         }\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n+      curStorageType \u003d storageTypes.remove(0);\n       chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,\n-          maxNodesPerRack, results, avoidStaleNodes, storageTypes.remove(0));\n+          maxNodesPerRack, results, avoidStaleNodes, curStorageType);\n     } catch (NotEnoughReplicasException e) {\n       final String message \u003d \"Failed to place enough replicas, still in need of \"\n           + (totalReplicasExpected - results.size()) + \" to reach \"\n           + totalReplicasExpected + \".\";\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(message, e);\n       } else {\n         LOG.warn(message + \" \" + e.getMessage());\n       }\n \n       if (avoidStaleNodes) {\n         // Retry chooseTarget again, this time not avoiding stale nodes.\n \n         // excludedNodes contains the initial excludedNodes and nodes that were\n         // not chosen because they were stale, decommissioned, etc.\n         // We need to additionally exclude the nodes that were added to the \n         // result list in the successful calls to choose*() above.\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n         }\n         // Set numOfReplicas, since it can get out of sync with the result list\n         // if the NotEnoughReplicasException was thrown in chooseRandom().\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n-            maxNodesPerRack, results, false, storagePolicy);\n+            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n+            newBlock);\n+      }\n+\n+      if (storageTypes.size() \u003e 0) {\n+        // Retry chooseTarget with fallback storage types\n+        unavailableStorages.add(curStorageType);\n+        return chooseTarget(numOfReplicas, writer, excludedNodes, blocksize,\n+            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n+            newBlock);\n       }\n     }\n     return writer;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Node chooseTarget(int numOfReplicas,\n                            Node writer,\n                            final Set\u003cNode\u003e excludedNodes,\n                            final long blocksize,\n                            final int maxNodesPerRack,\n                            final List\u003cDatanodeStorageInfo\u003e results,\n                            final boolean avoidStaleNodes,\n                            final BlockStoragePolicy storagePolicy,\n                            final EnumSet\u003cStorageType\u003e unavailableStorages,\n                            final boolean newBlock) {\n    if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n      return writer;\n    }\n    final int numOfResults \u003d results.size();\n    final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n    if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n      writer \u003d results.get(0).getDatanodeDescriptor();\n    }\n\n    // Keep a copy of original excludedNodes\n    final Set\u003cNode\u003e oldExcludedNodes \u003d avoidStaleNodes ? \n        new HashSet\u003cNode\u003e(excludedNodes) : null;\n\n    // choose storage types; use fallbacks for unavailable storages\n    final List\u003cStorageType\u003e storageTypes \u003d selectStorageTypes(storagePolicy,\n        (short)totalReplicasExpected, DatanodeStorageInfo.toStorageTypes(results),\n        unavailableStorages, newBlock);\n\n    StorageType curStorageType \u003d null;\n    try {\n      if ((numOfReplicas \u003d storageTypes.size()) \u003d\u003d 0) {\n        throw new NotEnoughReplicasException(\n            \"All required storage types are unavailable: \"\n            + \" unavailableStorages\u003d\" + unavailableStorages\n            + \", storagePolicy\u003d\" + storagePolicy);\n      }\n\n      if (numOfResults \u003d\u003d 0) {\n        curStorageType \u003d storageTypes.remove(0);\n        writer \u003d chooseLocalStorage(writer, excludedNodes, blocksize,\n            maxNodesPerRack, results, avoidStaleNodes, curStorageType, true)\n                .getDatanodeDescriptor();\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      final DatanodeDescriptor dn0 \u003d results.get(0).getDatanodeDescriptor();\n      if (numOfResults \u003c\u003d 1) {\n        curStorageType \u003d storageTypes.remove(0);\n        chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n            results, avoidStaleNodes, curStorageType);\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      if (numOfResults \u003c\u003d 2) {\n        final DatanodeDescriptor dn1 \u003d results.get(1).getDatanodeDescriptor();\n        curStorageType \u003d storageTypes.remove(0);\n        if (clusterMap.isOnSameRack(dn0, dn1)) {\n          chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, curStorageType);\n        } else if (newBlock){\n          chooseLocalRack(dn1, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, curStorageType);\n        } else {\n          chooseLocalRack(writer, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, curStorageType);\n        }\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      curStorageType \u003d storageTypes.remove(0);\n      chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, curStorageType);\n    } catch (NotEnoughReplicasException e) {\n      final String message \u003d \"Failed to place enough replicas, still in need of \"\n          + (totalReplicasExpected - results.size()) + \" to reach \"\n          + totalReplicasExpected + \".\";\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(message, e);\n      } else {\n        LOG.warn(message + \" \" + e.getMessage());\n      }\n\n      if (avoidStaleNodes) {\n        // Retry chooseTarget again, this time not avoiding stale nodes.\n\n        // excludedNodes contains the initial excludedNodes and nodes that were\n        // not chosen because they were stale, decommissioned, etc.\n        // We need to additionally exclude the nodes that were added to the \n        // result list in the successful calls to choose*() above.\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n        }\n        // Set numOfReplicas, since it can get out of sync with the result list\n        // if the NotEnoughReplicasException was thrown in chooseRandom().\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock);\n      }\n\n      if (storageTypes.size() \u003e 0) {\n        // Retry chooseTarget with fallback storage types\n        unavailableStorages.add(curStorageType);\n        return chooseTarget(numOfReplicas, writer, excludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock);\n      }\n    }\n    return writer;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
          "extendedDetails": {
            "oldValue": "[numOfReplicas-int, writer-Node, excludedNodes-Set\u003cNode\u003e(modifiers-final), blocksize-long(modifiers-final), maxNodesPerRack-int(modifiers-final), results-List\u003cDatanodeStorageInfo\u003e(modifiers-final), avoidStaleNodes-boolean(modifiers-final), storagePolicy-BlockStoragePolicy(modifiers-final)]",
            "newValue": "[numOfReplicas-int, writer-Node, excludedNodes-Set\u003cNode\u003e(modifiers-final), blocksize-long(modifiers-final), maxNodesPerRack-int(modifiers-final), results-List\u003cDatanodeStorageInfo\u003e(modifiers-final), avoidStaleNodes-boolean(modifiers-final), storagePolicy-BlockStoragePolicy(modifiers-final), unavailableStorages-EnumSet\u003cStorageType\u003e(modifiers-final), newBlock-boolean(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6686. Change BlockPlacementPolicy to use fallback when some storage types are unavailable.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-6584@1612880 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/07/14 10:25 AM",
          "commitName": "ac5e8aed7ca1e9493f96f8795d0caafd5282b9a7",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/07/14 4:37 PM",
          "commitNameOld": "3de6c61f860c6494ed7843e0858c1d7a6a0918a2",
          "commitAuthorOld": "",
          "daysBetweenCommits": 1.74,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,88 +1,113 @@\n   private Node chooseTarget(int numOfReplicas,\n                             Node writer,\n                             final Set\u003cNode\u003e excludedNodes,\n                             final long blocksize,\n                             final int maxNodesPerRack,\n                             final List\u003cDatanodeStorageInfo\u003e results,\n                             final boolean avoidStaleNodes,\n-                            final BlockStoragePolicy storagePolicy) {\n+                            final BlockStoragePolicy storagePolicy,\n+                            final EnumSet\u003cStorageType\u003e unavailableStorages,\n+                            final boolean newBlock) {\n     if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n       return writer;\n     }\n-    int totalReplicasExpected \u003d numOfReplicas + results.size();\n-      \n-    int numOfResults \u003d results.size();\n-    boolean newBlock \u003d (numOfResults\u003d\u003d0);\n+    final int numOfResults \u003d results.size();\n+    final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n     if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n       writer \u003d results.get(0).getDatanodeDescriptor();\n     }\n \n     // Keep a copy of original excludedNodes\n     final Set\u003cNode\u003e oldExcludedNodes \u003d avoidStaleNodes ? \n         new HashSet\u003cNode\u003e(excludedNodes) : null;\n-    final List\u003cStorageType\u003e storageTypes \u003d storagePolicy.chooseStorageTypes(\n-        (short)totalReplicasExpected, DatanodeStorageInfo.toStorageTypes(results));\n+\n+    // choose storage types; use fallbacks for unavailable storages\n+    final List\u003cStorageType\u003e storageTypes \u003d selectStorageTypes(storagePolicy,\n+        (short)totalReplicasExpected, DatanodeStorageInfo.toStorageTypes(results),\n+        unavailableStorages, newBlock);\n+\n+    StorageType curStorageType \u003d null;\n     try {\n+      if ((numOfReplicas \u003d storageTypes.size()) \u003d\u003d 0) {\n+        throw new NotEnoughReplicasException(\n+            \"All required storage types are unavailable: \"\n+            + \" unavailableStorages\u003d\" + unavailableStorages\n+            + \", storagePolicy\u003d\" + storagePolicy);\n+      }\n+\n       if (numOfResults \u003d\u003d 0) {\n+        curStorageType \u003d storageTypes.remove(0);\n         writer \u003d chooseLocalStorage(writer, excludedNodes, blocksize,\n-            maxNodesPerRack, results, avoidStaleNodes, storageTypes.remove(0), true)\n+            maxNodesPerRack, results, avoidStaleNodes, curStorageType, true)\n                 .getDatanodeDescriptor();\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n       final DatanodeDescriptor dn0 \u003d results.get(0).getDatanodeDescriptor();\n       if (numOfResults \u003c\u003d 1) {\n+        curStorageType \u003d storageTypes.remove(0);\n         chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n-            results, avoidStaleNodes, storageTypes.remove(0));\n+            results, avoidStaleNodes, curStorageType);\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n       if (numOfResults \u003c\u003d 2) {\n         final DatanodeDescriptor dn1 \u003d results.get(1).getDatanodeDescriptor();\n+        curStorageType \u003d storageTypes.remove(0);\n         if (clusterMap.isOnSameRack(dn0, dn1)) {\n           chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n-              results, avoidStaleNodes, storageTypes.remove(0));\n+              results, avoidStaleNodes, curStorageType);\n         } else if (newBlock){\n           chooseLocalRack(dn1, excludedNodes, blocksize, maxNodesPerRack,\n-              results, avoidStaleNodes, storageTypes.remove(0));\n+              results, avoidStaleNodes, curStorageType);\n         } else {\n           chooseLocalRack(writer, excludedNodes, blocksize, maxNodesPerRack,\n-              results, avoidStaleNodes, storageTypes.remove(0));\n+              results, avoidStaleNodes, curStorageType);\n         }\n         if (--numOfReplicas \u003d\u003d 0) {\n           return writer;\n         }\n       }\n+      curStorageType \u003d storageTypes.remove(0);\n       chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,\n-          maxNodesPerRack, results, avoidStaleNodes, storageTypes.remove(0));\n+          maxNodesPerRack, results, avoidStaleNodes, curStorageType);\n     } catch (NotEnoughReplicasException e) {\n       final String message \u003d \"Failed to place enough replicas, still in need of \"\n           + (totalReplicasExpected - results.size()) + \" to reach \"\n           + totalReplicasExpected + \".\";\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(message, e);\n       } else {\n         LOG.warn(message + \" \" + e.getMessage());\n       }\n \n       if (avoidStaleNodes) {\n         // Retry chooseTarget again, this time not avoiding stale nodes.\n \n         // excludedNodes contains the initial excludedNodes and nodes that were\n         // not chosen because they were stale, decommissioned, etc.\n         // We need to additionally exclude the nodes that were added to the \n         // result list in the successful calls to choose*() above.\n         for (DatanodeStorageInfo resultStorage : results) {\n           addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n         }\n         // Set numOfReplicas, since it can get out of sync with the result list\n         // if the NotEnoughReplicasException was thrown in chooseRandom().\n         numOfReplicas \u003d totalReplicasExpected - results.size();\n         return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n-            maxNodesPerRack, results, false, storagePolicy);\n+            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n+            newBlock);\n+      }\n+\n+      if (storageTypes.size() \u003e 0) {\n+        // Retry chooseTarget with fallback storage types\n+        unavailableStorages.add(curStorageType);\n+        return chooseTarget(numOfReplicas, writer, excludedNodes, blocksize,\n+            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n+            newBlock);\n       }\n     }\n     return writer;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Node chooseTarget(int numOfReplicas,\n                            Node writer,\n                            final Set\u003cNode\u003e excludedNodes,\n                            final long blocksize,\n                            final int maxNodesPerRack,\n                            final List\u003cDatanodeStorageInfo\u003e results,\n                            final boolean avoidStaleNodes,\n                            final BlockStoragePolicy storagePolicy,\n                            final EnumSet\u003cStorageType\u003e unavailableStorages,\n                            final boolean newBlock) {\n    if (numOfReplicas \u003d\u003d 0 || clusterMap.getNumOfLeaves()\u003d\u003d0) {\n      return writer;\n    }\n    final int numOfResults \u003d results.size();\n    final int totalReplicasExpected \u003d numOfReplicas + numOfResults;\n    if ((writer \u003d\u003d null || !(writer instanceof DatanodeDescriptor)) \u0026\u0026 !newBlock) {\n      writer \u003d results.get(0).getDatanodeDescriptor();\n    }\n\n    // Keep a copy of original excludedNodes\n    final Set\u003cNode\u003e oldExcludedNodes \u003d avoidStaleNodes ? \n        new HashSet\u003cNode\u003e(excludedNodes) : null;\n\n    // choose storage types; use fallbacks for unavailable storages\n    final List\u003cStorageType\u003e storageTypes \u003d selectStorageTypes(storagePolicy,\n        (short)totalReplicasExpected, DatanodeStorageInfo.toStorageTypes(results),\n        unavailableStorages, newBlock);\n\n    StorageType curStorageType \u003d null;\n    try {\n      if ((numOfReplicas \u003d storageTypes.size()) \u003d\u003d 0) {\n        throw new NotEnoughReplicasException(\n            \"All required storage types are unavailable: \"\n            + \" unavailableStorages\u003d\" + unavailableStorages\n            + \", storagePolicy\u003d\" + storagePolicy);\n      }\n\n      if (numOfResults \u003d\u003d 0) {\n        curStorageType \u003d storageTypes.remove(0);\n        writer \u003d chooseLocalStorage(writer, excludedNodes, blocksize,\n            maxNodesPerRack, results, avoidStaleNodes, curStorageType, true)\n                .getDatanodeDescriptor();\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      final DatanodeDescriptor dn0 \u003d results.get(0).getDatanodeDescriptor();\n      if (numOfResults \u003c\u003d 1) {\n        curStorageType \u003d storageTypes.remove(0);\n        chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n            results, avoidStaleNodes, curStorageType);\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      if (numOfResults \u003c\u003d 2) {\n        final DatanodeDescriptor dn1 \u003d results.get(1).getDatanodeDescriptor();\n        curStorageType \u003d storageTypes.remove(0);\n        if (clusterMap.isOnSameRack(dn0, dn1)) {\n          chooseRemoteRack(1, dn0, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, curStorageType);\n        } else if (newBlock){\n          chooseLocalRack(dn1, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, curStorageType);\n        } else {\n          chooseLocalRack(writer, excludedNodes, blocksize, maxNodesPerRack,\n              results, avoidStaleNodes, curStorageType);\n        }\n        if (--numOfReplicas \u003d\u003d 0) {\n          return writer;\n        }\n      }\n      curStorageType \u003d storageTypes.remove(0);\n      chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, curStorageType);\n    } catch (NotEnoughReplicasException e) {\n      final String message \u003d \"Failed to place enough replicas, still in need of \"\n          + (totalReplicasExpected - results.size()) + \" to reach \"\n          + totalReplicasExpected + \".\";\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(message, e);\n      } else {\n        LOG.warn(message + \" \" + e.getMessage());\n      }\n\n      if (avoidStaleNodes) {\n        // Retry chooseTarget again, this time not avoiding stale nodes.\n\n        // excludedNodes contains the initial excludedNodes and nodes that were\n        // not chosen because they were stale, decommissioned, etc.\n        // We need to additionally exclude the nodes that were added to the \n        // result list in the successful calls to choose*() above.\n        for (DatanodeStorageInfo resultStorage : results) {\n          addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);\n        }\n        // Set numOfReplicas, since it can get out of sync with the result list\n        // if the NotEnoughReplicasException was thrown in chooseRandom().\n        numOfReplicas \u003d totalReplicasExpected - results.size();\n        return chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock);\n      }\n\n      if (storageTypes.size() \u003e 0) {\n        // Retry chooseTarget with fallback storage types\n        unavailableStorages.add(curStorageType);\n        return chooseTarget(numOfReplicas, writer, excludedNodes, blocksize,\n            maxNodesPerRack, results, false, storagePolicy, unavailableStorages,\n            newBlock);\n      }\n    }\n    return writer;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}