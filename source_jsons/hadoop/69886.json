{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AbfsHttpOperation.java",
  "functionName": "sendRequest",
  "functionId": "sendRequest___buffer-byte[]__offset-int__length-int",
  "sourceFilePath": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java",
  "functionStartLine": 269,
  "functionEndLine": 297,
  "numCommitsSeen": 11,
  "timeTaken": 551,
  "changeHistory": [
    "f044deedbbfee0812316d587139cb828f27172e9"
  ],
  "changeHistoryShort": {
    "f044deedbbfee0812316d587139cb828f27172e9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f044deedbbfee0812316d587139cb828f27172e9": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-15407. HADOOP-15540. Support Windows Azure Storage - Blob file system \"ABFS\" in Hadoop: Core Commit.\n\nContributed by Shane Mainali, Thomas Marquardt, Zichen Sun, Georgi Chalakov, Esfandiar Manii, Amit Singh, Dana Kaban, Da Zhou, Junhua Gu, Saher Ahwal, Saurabh Pant, James Baker, Shaoyu Zhang, Lawrence Chen, Kevin Chen and Steve Loughran\n",
      "commitDate": "17/09/18 12:54 PM",
      "commitName": "f044deedbbfee0812316d587139cb828f27172e9",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,29 @@\n+  public void sendRequest(byte[] buffer, int offset, int length) throws IOException {\n+    this.connection.setDoOutput(true);\n+    this.connection.setFixedLengthStreamingMode(length);\n+    if (buffer \u003d\u003d null) {\n+      // An empty buffer is sent to set the \"Content-Length: 0\" header, which\n+      // is required by our endpoint.\n+      buffer \u003d new byte[]{};\n+      offset \u003d 0;\n+      length \u003d 0;\n+    }\n+\n+    // send the request body\n+\n+    long startTime \u003d 0;\n+    if (this.isTraceEnabled) {\n+      startTime \u003d System.nanoTime();\n+    }\n+    try (OutputStream outputStream \u003d this.connection.getOutputStream()) {\n+      // update bytes sent before they are sent so we may observe\n+      // attempted sends as well as successful sends via the\n+      // accompanying statusCode\n+      this.bytesSent \u003d length;\n+      outputStream.write(buffer, offset, length);\n+    } finally {\n+      if (this.isTraceEnabled) {\n+        this.sendRequestTimeMs \u003d elapsedTimeMs(startTime);\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void sendRequest(byte[] buffer, int offset, int length) throws IOException {\n    this.connection.setDoOutput(true);\n    this.connection.setFixedLengthStreamingMode(length);\n    if (buffer \u003d\u003d null) {\n      // An empty buffer is sent to set the \"Content-Length: 0\" header, which\n      // is required by our endpoint.\n      buffer \u003d new byte[]{};\n      offset \u003d 0;\n      length \u003d 0;\n    }\n\n    // send the request body\n\n    long startTime \u003d 0;\n    if (this.isTraceEnabled) {\n      startTime \u003d System.nanoTime();\n    }\n    try (OutputStream outputStream \u003d this.connection.getOutputStream()) {\n      // update bytes sent before they are sent so we may observe\n      // attempted sends as well as successful sends via the\n      // accompanying statusCode\n      this.bytesSent \u003d length;\n      outputStream.write(buffer, offset, length);\n    } finally {\n      if (this.isTraceEnabled) {\n        this.sendRequestTimeMs \u003d elapsedTimeMs(startTime);\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java"
    }
  }
}