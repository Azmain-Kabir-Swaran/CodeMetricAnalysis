{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LowRedundancyBlocks.java",
  "functionName": "getPriorityContiguous",
  "functionId": "getPriorityContiguous___curReplicas-int__readOnlyReplicas-int__outOfServiceReplicas-int__expectedReplicas-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java",
  "functionStartLine": 228,
  "functionEndLine": 255,
  "numCommitsSeen": 45,
  "timeTaken": 4083,
  "changeHistory": [
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
    "5411dc559d5f73e4153e76fdff94a26869c17a37"
  ],
  "changeHistoryShort": {
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": "Ymultichange(Yparameterchange,Ybodychange)",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": "Ymultichange(Yfilerename,Ybodychange)",
    "5411dc559d5f73e4153e76fdff94a26869c17a37": "Ymultichange(Yparameterchange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
      "commitDate": "17/10/16 5:45 PM",
      "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
      "commitAuthor": "Ming Ma",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
          "commitDate": "17/10/16 5:45 PM",
          "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
          "commitAuthor": "Ming Ma",
          "commitDateOld": "16/03/16 4:53 PM",
          "commitNameOld": "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
          "commitAuthorOld": "Zhe Zhang",
          "daysBetweenCommits": 215.04,
          "commitsBetweenForRepo": 1525,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,28 @@\n   private int getPriorityContiguous(int curReplicas, int readOnlyReplicas,\n-      int decommissionedReplicas, int expectedReplicas) {\n+      int outOfServiceReplicas, int expectedReplicas) {\n     if (curReplicas \u003d\u003d 0) {\n       // If there are zero non-decommissioned replicas but there are\n-      // some decommissioned replicas, then assign them highest priority\n-      if (decommissionedReplicas \u003e 0) {\n+      // some out of service replicas, then assign them highest priority\n+      if (outOfServiceReplicas \u003e 0) {\n         return QUEUE_HIGHEST_PRIORITY;\n       }\n       if (readOnlyReplicas \u003e 0) {\n         // only has read-only replicas, highest risk\n         // since the read-only replicas may go down all together.\n         return QUEUE_HIGHEST_PRIORITY;\n       }\n       //all we have are corrupt blocks\n       return QUEUE_WITH_CORRUPT_BLOCKS;\n     } else if (curReplicas \u003d\u003d 1) {\n       // only one replica, highest risk of loss\n       // highest priority\n       return QUEUE_HIGHEST_PRIORITY;\n     } else if ((curReplicas * 3) \u003c expectedReplicas) {\n       //can only afford one replica loss\n       //this is considered very insufficiently redundant blocks.\n       return QUEUE_VERY_LOW_REDUNDANCY;\n     } else {\n       //add to the normal queue for insufficiently redundant blocks\n       return QUEUE_LOW_REDUNDANCY;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int getPriorityContiguous(int curReplicas, int readOnlyReplicas,\n      int outOfServiceReplicas, int expectedReplicas) {\n    if (curReplicas \u003d\u003d 0) {\n      // If there are zero non-decommissioned replicas but there are\n      // some out of service replicas, then assign them highest priority\n      if (outOfServiceReplicas \u003e 0) {\n        return QUEUE_HIGHEST_PRIORITY;\n      }\n      if (readOnlyReplicas \u003e 0) {\n        // only has read-only replicas, highest risk\n        // since the read-only replicas may go down all together.\n        return QUEUE_HIGHEST_PRIORITY;\n      }\n      //all we have are corrupt blocks\n      return QUEUE_WITH_CORRUPT_BLOCKS;\n    } else if (curReplicas \u003d\u003d 1) {\n      // only one replica, highest risk of loss\n      // highest priority\n      return QUEUE_HIGHEST_PRIORITY;\n    } else if ((curReplicas * 3) \u003c expectedReplicas) {\n      //can only afford one replica loss\n      //this is considered very insufficiently redundant blocks.\n      return QUEUE_VERY_LOW_REDUNDANCY;\n    } else {\n      //add to the normal queue for insufficiently redundant blocks\n      return QUEUE_LOW_REDUNDANCY;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java",
          "extendedDetails": {
            "oldValue": "[curReplicas-int, readOnlyReplicas-int, decommissionedReplicas-int, expectedReplicas-int]",
            "newValue": "[curReplicas-int, readOnlyReplicas-int, outOfServiceReplicas-int, expectedReplicas-int]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
          "commitDate": "17/10/16 5:45 PM",
          "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
          "commitAuthor": "Ming Ma",
          "commitDateOld": "16/03/16 4:53 PM",
          "commitNameOld": "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
          "commitAuthorOld": "Zhe Zhang",
          "daysBetweenCommits": 215.04,
          "commitsBetweenForRepo": 1525,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,28 @@\n   private int getPriorityContiguous(int curReplicas, int readOnlyReplicas,\n-      int decommissionedReplicas, int expectedReplicas) {\n+      int outOfServiceReplicas, int expectedReplicas) {\n     if (curReplicas \u003d\u003d 0) {\n       // If there are zero non-decommissioned replicas but there are\n-      // some decommissioned replicas, then assign them highest priority\n-      if (decommissionedReplicas \u003e 0) {\n+      // some out of service replicas, then assign them highest priority\n+      if (outOfServiceReplicas \u003e 0) {\n         return QUEUE_HIGHEST_PRIORITY;\n       }\n       if (readOnlyReplicas \u003e 0) {\n         // only has read-only replicas, highest risk\n         // since the read-only replicas may go down all together.\n         return QUEUE_HIGHEST_PRIORITY;\n       }\n       //all we have are corrupt blocks\n       return QUEUE_WITH_CORRUPT_BLOCKS;\n     } else if (curReplicas \u003d\u003d 1) {\n       // only one replica, highest risk of loss\n       // highest priority\n       return QUEUE_HIGHEST_PRIORITY;\n     } else if ((curReplicas * 3) \u003c expectedReplicas) {\n       //can only afford one replica loss\n       //this is considered very insufficiently redundant blocks.\n       return QUEUE_VERY_LOW_REDUNDANCY;\n     } else {\n       //add to the normal queue for insufficiently redundant blocks\n       return QUEUE_LOW_REDUNDANCY;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int getPriorityContiguous(int curReplicas, int readOnlyReplicas,\n      int outOfServiceReplicas, int expectedReplicas) {\n    if (curReplicas \u003d\u003d 0) {\n      // If there are zero non-decommissioned replicas but there are\n      // some out of service replicas, then assign them highest priority\n      if (outOfServiceReplicas \u003e 0) {\n        return QUEUE_HIGHEST_PRIORITY;\n      }\n      if (readOnlyReplicas \u003e 0) {\n        // only has read-only replicas, highest risk\n        // since the read-only replicas may go down all together.\n        return QUEUE_HIGHEST_PRIORITY;\n      }\n      //all we have are corrupt blocks\n      return QUEUE_WITH_CORRUPT_BLOCKS;\n    } else if (curReplicas \u003d\u003d 1) {\n      // only one replica, highest risk of loss\n      // highest priority\n      return QUEUE_HIGHEST_PRIORITY;\n    } else if ((curReplicas * 3) \u003c expectedReplicas) {\n      //can only afford one replica loss\n      //this is considered very insufficiently redundant blocks.\n      return QUEUE_VERY_LOW_REDUNDANCY;\n    } else {\n      //add to the normal queue for insufficiently redundant blocks\n      return QUEUE_LOW_REDUNDANCY;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java",
          "extendedDetails": {}
        }
      ]
    },
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "HDFS-9857. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-1]. Contributed by Rakesh R.\n",
      "commitDate": "16/03/16 4:53 PM",
      "commitName": "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
      "commitAuthor": "Zhe Zhang",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "HDFS-9857. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-1]. Contributed by Rakesh R.\n",
          "commitDate": "16/03/16 4:53 PM",
          "commitName": "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
          "commitAuthor": "Zhe Zhang",
          "commitDateOld": "16/03/16 7:35 AM",
          "commitNameOld": "605fdcbb81687c73ba91a3bd0d607cabd3dc5a67",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 0.39,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,28 @@\n   private int getPriorityContiguous(int curReplicas, int readOnlyReplicas,\n       int decommissionedReplicas, int expectedReplicas) {\n     if (curReplicas \u003d\u003d 0) {\n       // If there are zero non-decommissioned replicas but there are\n       // some decommissioned replicas, then assign them highest priority\n       if (decommissionedReplicas \u003e 0) {\n         return QUEUE_HIGHEST_PRIORITY;\n       }\n       if (readOnlyReplicas \u003e 0) {\n         // only has read-only replicas, highest risk\n         // since the read-only replicas may go down all together.\n         return QUEUE_HIGHEST_PRIORITY;\n       }\n       //all we have are corrupt blocks\n       return QUEUE_WITH_CORRUPT_BLOCKS;\n     } else if (curReplicas \u003d\u003d 1) {\n       // only one replica, highest risk of loss\n       // highest priority\n       return QUEUE_HIGHEST_PRIORITY;\n     } else if ((curReplicas * 3) \u003c expectedReplicas) {\n-      //there is less than a third as many blocks as requested;\n-      //this is considered very under-replicated\n-      return QUEUE_VERY_UNDER_REPLICATED;\n+      //can only afford one replica loss\n+      //this is considered very insufficiently redundant blocks.\n+      return QUEUE_VERY_LOW_REDUNDANCY;\n     } else {\n-      //add to the normal queue for under replicated blocks\n-      return QUEUE_UNDER_REPLICATED;\n+      //add to the normal queue for insufficiently redundant blocks\n+      return QUEUE_LOW_REDUNDANCY;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int getPriorityContiguous(int curReplicas, int readOnlyReplicas,\n      int decommissionedReplicas, int expectedReplicas) {\n    if (curReplicas \u003d\u003d 0) {\n      // If there are zero non-decommissioned replicas but there are\n      // some decommissioned replicas, then assign them highest priority\n      if (decommissionedReplicas \u003e 0) {\n        return QUEUE_HIGHEST_PRIORITY;\n      }\n      if (readOnlyReplicas \u003e 0) {\n        // only has read-only replicas, highest risk\n        // since the read-only replicas may go down all together.\n        return QUEUE_HIGHEST_PRIORITY;\n      }\n      //all we have are corrupt blocks\n      return QUEUE_WITH_CORRUPT_BLOCKS;\n    } else if (curReplicas \u003d\u003d 1) {\n      // only one replica, highest risk of loss\n      // highest priority\n      return QUEUE_HIGHEST_PRIORITY;\n    } else if ((curReplicas * 3) \u003c expectedReplicas) {\n      //can only afford one replica loss\n      //this is considered very insufficiently redundant blocks.\n      return QUEUE_VERY_LOW_REDUNDANCY;\n    } else {\n      //add to the normal queue for insufficiently redundant blocks\n      return QUEUE_LOW_REDUNDANCY;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9857. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-1]. Contributed by Rakesh R.\n",
          "commitDate": "16/03/16 4:53 PM",
          "commitName": "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
          "commitAuthor": "Zhe Zhang",
          "commitDateOld": "16/03/16 7:35 AM",
          "commitNameOld": "605fdcbb81687c73ba91a3bd0d607cabd3dc5a67",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 0.39,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,28 @@\n   private int getPriorityContiguous(int curReplicas, int readOnlyReplicas,\n       int decommissionedReplicas, int expectedReplicas) {\n     if (curReplicas \u003d\u003d 0) {\n       // If there are zero non-decommissioned replicas but there are\n       // some decommissioned replicas, then assign them highest priority\n       if (decommissionedReplicas \u003e 0) {\n         return QUEUE_HIGHEST_PRIORITY;\n       }\n       if (readOnlyReplicas \u003e 0) {\n         // only has read-only replicas, highest risk\n         // since the read-only replicas may go down all together.\n         return QUEUE_HIGHEST_PRIORITY;\n       }\n       //all we have are corrupt blocks\n       return QUEUE_WITH_CORRUPT_BLOCKS;\n     } else if (curReplicas \u003d\u003d 1) {\n       // only one replica, highest risk of loss\n       // highest priority\n       return QUEUE_HIGHEST_PRIORITY;\n     } else if ((curReplicas * 3) \u003c expectedReplicas) {\n-      //there is less than a third as many blocks as requested;\n-      //this is considered very under-replicated\n-      return QUEUE_VERY_UNDER_REPLICATED;\n+      //can only afford one replica loss\n+      //this is considered very insufficiently redundant blocks.\n+      return QUEUE_VERY_LOW_REDUNDANCY;\n     } else {\n-      //add to the normal queue for under replicated blocks\n-      return QUEUE_UNDER_REPLICATED;\n+      //add to the normal queue for insufficiently redundant blocks\n+      return QUEUE_LOW_REDUNDANCY;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int getPriorityContiguous(int curReplicas, int readOnlyReplicas,\n      int decommissionedReplicas, int expectedReplicas) {\n    if (curReplicas \u003d\u003d 0) {\n      // If there are zero non-decommissioned replicas but there are\n      // some decommissioned replicas, then assign them highest priority\n      if (decommissionedReplicas \u003e 0) {\n        return QUEUE_HIGHEST_PRIORITY;\n      }\n      if (readOnlyReplicas \u003e 0) {\n        // only has read-only replicas, highest risk\n        // since the read-only replicas may go down all together.\n        return QUEUE_HIGHEST_PRIORITY;\n      }\n      //all we have are corrupt blocks\n      return QUEUE_WITH_CORRUPT_BLOCKS;\n    } else if (curReplicas \u003d\u003d 1) {\n      // only one replica, highest risk of loss\n      // highest priority\n      return QUEUE_HIGHEST_PRIORITY;\n    } else if ((curReplicas * 3) \u003c expectedReplicas) {\n      //can only afford one replica loss\n      //this is considered very insufficiently redundant blocks.\n      return QUEUE_VERY_LOW_REDUNDANCY;\n    } else {\n      //add to the normal queue for insufficiently redundant blocks\n      return QUEUE_LOW_REDUNDANCY;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java",
          "extendedDetails": {}
        }
      ]
    },
    "5411dc559d5f73e4153e76fdff94a26869c17a37": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-9205. Do not schedule corrupt blocks for replication.  (szetszwo)\n",
      "commitDate": "15/10/15 3:07 AM",
      "commitName": "5411dc559d5f73e4153e76fdff94a26869c17a37",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9205. Do not schedule corrupt blocks for replication.  (szetszwo)\n",
          "commitDate": "15/10/15 3:07 AM",
          "commitName": "5411dc559d5f73e4153e76fdff94a26869c17a37",
          "commitAuthor": "Tsz-Wo Nicholas Sze",
          "commitDateOld": "24/08/15 12:59 PM",
          "commitNameOld": "6b6a63bbbda920315d3d24b61ed3344a78a981b6",
          "commitAuthorOld": "",
          "daysBetweenCommits": 51.59,
          "commitsBetweenForRepo": 371,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,28 @@\n-  private int getPriorityContiguous(int curReplicas, int decommissionedReplicas,\n-      int expectedReplicas) {\n+  private int getPriorityContiguous(int curReplicas, int readOnlyReplicas,\n+      int decommissionedReplicas, int expectedReplicas) {\n     if (curReplicas \u003d\u003d 0) {\n       // If there are zero non-decommissioned replicas but there are\n       // some decommissioned replicas, then assign them highest priority\n       if (decommissionedReplicas \u003e 0) {\n         return QUEUE_HIGHEST_PRIORITY;\n       }\n+      if (readOnlyReplicas \u003e 0) {\n+        // only has read-only replicas, highest risk\n+        // since the read-only replicas may go down all together.\n+        return QUEUE_HIGHEST_PRIORITY;\n+      }\n       //all we have are corrupt blocks\n       return QUEUE_WITH_CORRUPT_BLOCKS;\n     } else if (curReplicas \u003d\u003d 1) {\n       // only one replica, highest risk of loss\n       // highest priority\n       return QUEUE_HIGHEST_PRIORITY;\n     } else if ((curReplicas * 3) \u003c expectedReplicas) {\n       //there is less than a third as many blocks as requested;\n       //this is considered very under-replicated\n       return QUEUE_VERY_UNDER_REPLICATED;\n     } else {\n       //add to the normal queue for under replicated blocks\n       return QUEUE_UNDER_REPLICATED;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int getPriorityContiguous(int curReplicas, int readOnlyReplicas,\n      int decommissionedReplicas, int expectedReplicas) {\n    if (curReplicas \u003d\u003d 0) {\n      // If there are zero non-decommissioned replicas but there are\n      // some decommissioned replicas, then assign them highest priority\n      if (decommissionedReplicas \u003e 0) {\n        return QUEUE_HIGHEST_PRIORITY;\n      }\n      if (readOnlyReplicas \u003e 0) {\n        // only has read-only replicas, highest risk\n        // since the read-only replicas may go down all together.\n        return QUEUE_HIGHEST_PRIORITY;\n      }\n      //all we have are corrupt blocks\n      return QUEUE_WITH_CORRUPT_BLOCKS;\n    } else if (curReplicas \u003d\u003d 1) {\n      // only one replica, highest risk of loss\n      // highest priority\n      return QUEUE_HIGHEST_PRIORITY;\n    } else if ((curReplicas * 3) \u003c expectedReplicas) {\n      //there is less than a third as many blocks as requested;\n      //this is considered very under-replicated\n      return QUEUE_VERY_UNDER_REPLICATED;\n    } else {\n      //add to the normal queue for under replicated blocks\n      return QUEUE_UNDER_REPLICATED;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks.java",
          "extendedDetails": {
            "oldValue": "[curReplicas-int, decommissionedReplicas-int, expectedReplicas-int]",
            "newValue": "[curReplicas-int, readOnlyReplicas-int, decommissionedReplicas-int, expectedReplicas-int]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9205. Do not schedule corrupt blocks for replication.  (szetszwo)\n",
          "commitDate": "15/10/15 3:07 AM",
          "commitName": "5411dc559d5f73e4153e76fdff94a26869c17a37",
          "commitAuthor": "Tsz-Wo Nicholas Sze",
          "commitDateOld": "24/08/15 12:59 PM",
          "commitNameOld": "6b6a63bbbda920315d3d24b61ed3344a78a981b6",
          "commitAuthorOld": "",
          "daysBetweenCommits": 51.59,
          "commitsBetweenForRepo": 371,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,28 @@\n-  private int getPriorityContiguous(int curReplicas, int decommissionedReplicas,\n-      int expectedReplicas) {\n+  private int getPriorityContiguous(int curReplicas, int readOnlyReplicas,\n+      int decommissionedReplicas, int expectedReplicas) {\n     if (curReplicas \u003d\u003d 0) {\n       // If there are zero non-decommissioned replicas but there are\n       // some decommissioned replicas, then assign them highest priority\n       if (decommissionedReplicas \u003e 0) {\n         return QUEUE_HIGHEST_PRIORITY;\n       }\n+      if (readOnlyReplicas \u003e 0) {\n+        // only has read-only replicas, highest risk\n+        // since the read-only replicas may go down all together.\n+        return QUEUE_HIGHEST_PRIORITY;\n+      }\n       //all we have are corrupt blocks\n       return QUEUE_WITH_CORRUPT_BLOCKS;\n     } else if (curReplicas \u003d\u003d 1) {\n       // only one replica, highest risk of loss\n       // highest priority\n       return QUEUE_HIGHEST_PRIORITY;\n     } else if ((curReplicas * 3) \u003c expectedReplicas) {\n       //there is less than a third as many blocks as requested;\n       //this is considered very under-replicated\n       return QUEUE_VERY_UNDER_REPLICATED;\n     } else {\n       //add to the normal queue for under replicated blocks\n       return QUEUE_UNDER_REPLICATED;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private int getPriorityContiguous(int curReplicas, int readOnlyReplicas,\n      int decommissionedReplicas, int expectedReplicas) {\n    if (curReplicas \u003d\u003d 0) {\n      // If there are zero non-decommissioned replicas but there are\n      // some decommissioned replicas, then assign them highest priority\n      if (decommissionedReplicas \u003e 0) {\n        return QUEUE_HIGHEST_PRIORITY;\n      }\n      if (readOnlyReplicas \u003e 0) {\n        // only has read-only replicas, highest risk\n        // since the read-only replicas may go down all together.\n        return QUEUE_HIGHEST_PRIORITY;\n      }\n      //all we have are corrupt blocks\n      return QUEUE_WITH_CORRUPT_BLOCKS;\n    } else if (curReplicas \u003d\u003d 1) {\n      // only one replica, highest risk of loss\n      // highest priority\n      return QUEUE_HIGHEST_PRIORITY;\n    } else if ((curReplicas * 3) \u003c expectedReplicas) {\n      //there is less than a third as many blocks as requested;\n      //this is considered very under-replicated\n      return QUEUE_VERY_UNDER_REPLICATED;\n    } else {\n      //add to the normal queue for under replicated blocks\n      return QUEUE_UNDER_REPLICATED;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}