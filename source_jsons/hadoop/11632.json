{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPoolSlice.java",
  "functionName": "selectReplicaToDelete",
  "functionId": "selectReplicaToDelete___replica1-ReplicaInfo(modifiers-final)__replica2-ReplicaInfo(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
  "functionStartLine": 756,
  "functionEndLine": 786,
  "numCommitsSeen": 58,
  "timeTaken": 1996,
  "changeHistory": [
    "86c9862bec0248d671e657aa56094a2919b8ac14",
    "03fb5c642589dec4e663479771d0ae1782038b63"
  ],
  "changeHistoryShort": {
    "86c9862bec0248d671e657aa56094a2919b8ac14": "Ybodychange",
    "03fb5c642589dec4e663479771d0ae1782038b63": "Yintroduced"
  },
  "changeHistoryDetails": {
    "86c9862bec0248d671e657aa56094a2919b8ac14": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "13/09/16 12:54 PM",
      "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "20/04/16 1:39 PM",
      "commitNameOld": "63ac2db59af2b50e74dc892cae1dbc4d2e061423",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 145.97,
      "commitsBetweenForRepo": 1086,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n   static ReplicaInfo selectReplicaToDelete(final ReplicaInfo replica1,\n       final ReplicaInfo replica2) {\n     ReplicaInfo replicaToKeep;\n     ReplicaInfo replicaToDelete;\n \n     // it\u0027s the same block so don\u0027t ever delete it, even if GS or size\n     // differs.  caller should keep the one it just discovered on disk\n-    if (replica1.getBlockFile().equals(replica2.getBlockFile())) {\n+    if (replica1.getBlockURI().equals(replica2.getBlockURI())) {\n       return null;\n     }\n     if (replica1.getGenerationStamp() !\u003d replica2.getGenerationStamp()) {\n       replicaToKeep \u003d replica1.getGenerationStamp() \u003e replica2.getGenerationStamp()\n           ? replica1 : replica2;\n     } else if (replica1.getNumBytes() !\u003d replica2.getNumBytes()) {\n       replicaToKeep \u003d replica1.getNumBytes() \u003e replica2.getNumBytes() ?\n           replica1 : replica2;\n     } else if (replica1.getVolume().isTransientStorage() \u0026\u0026\n                !replica2.getVolume().isTransientStorage()) {\n       replicaToKeep \u003d replica2;\n     } else {\n       replicaToKeep \u003d replica1;\n     }\n \n     replicaToDelete \u003d (replicaToKeep \u003d\u003d replica1) ? replica2 : replica1;\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"resolveDuplicateReplicas decide to keep \" + replicaToKeep\n           + \".  Will try to delete \" + replicaToDelete);\n     }\n     return replicaToDelete;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static ReplicaInfo selectReplicaToDelete(final ReplicaInfo replica1,\n      final ReplicaInfo replica2) {\n    ReplicaInfo replicaToKeep;\n    ReplicaInfo replicaToDelete;\n\n    // it\u0027s the same block so don\u0027t ever delete it, even if GS or size\n    // differs.  caller should keep the one it just discovered on disk\n    if (replica1.getBlockURI().equals(replica2.getBlockURI())) {\n      return null;\n    }\n    if (replica1.getGenerationStamp() !\u003d replica2.getGenerationStamp()) {\n      replicaToKeep \u003d replica1.getGenerationStamp() \u003e replica2.getGenerationStamp()\n          ? replica1 : replica2;\n    } else if (replica1.getNumBytes() !\u003d replica2.getNumBytes()) {\n      replicaToKeep \u003d replica1.getNumBytes() \u003e replica2.getNumBytes() ?\n          replica1 : replica2;\n    } else if (replica1.getVolume().isTransientStorage() \u0026\u0026\n               !replica2.getVolume().isTransientStorage()) {\n      replicaToKeep \u003d replica2;\n    } else {\n      replicaToKeep \u003d replica1;\n    }\n\n    replicaToDelete \u003d (replicaToKeep \u003d\u003d replica1) ? replica2 : replica1;\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"resolveDuplicateReplicas decide to keep \" + replicaToKeep\n          + \".  Will try to delete \" + replicaToDelete);\n    }\n    return replicaToDelete;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java",
      "extendedDetails": {}
    },
    "03fb5c642589dec4e663479771d0ae1782038b63": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-8486. DN startup may cause severe data loss (Daryn Sharp via Colin P.  McCabe)\n",
      "commitDate": "02/06/15 11:40 AM",
      "commitName": "03fb5c642589dec4e663479771d0ae1782038b63",
      "commitAuthor": "Colin Patrick Mccabe",
      "diff": "@@ -0,0 +1,31 @@\n+  static ReplicaInfo selectReplicaToDelete(final ReplicaInfo replica1,\n+      final ReplicaInfo replica2) {\n+    ReplicaInfo replicaToKeep;\n+    ReplicaInfo replicaToDelete;\n+\n+    // it\u0027s the same block so don\u0027t ever delete it, even if GS or size\n+    // differs.  caller should keep the one it just discovered on disk\n+    if (replica1.getBlockFile().equals(replica2.getBlockFile())) {\n+      return null;\n+    }\n+    if (replica1.getGenerationStamp() !\u003d replica2.getGenerationStamp()) {\n+      replicaToKeep \u003d replica1.getGenerationStamp() \u003e replica2.getGenerationStamp()\n+          ? replica1 : replica2;\n+    } else if (replica1.getNumBytes() !\u003d replica2.getNumBytes()) {\n+      replicaToKeep \u003d replica1.getNumBytes() \u003e replica2.getNumBytes() ?\n+          replica1 : replica2;\n+    } else if (replica1.getVolume().isTransientStorage() \u0026\u0026\n+               !replica2.getVolume().isTransientStorage()) {\n+      replicaToKeep \u003d replica2;\n+    } else {\n+      replicaToKeep \u003d replica1;\n+    }\n+\n+    replicaToDelete \u003d (replicaToKeep \u003d\u003d replica1) ? replica2 : replica1;\n+\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"resolveDuplicateReplicas decide to keep \" + replicaToKeep\n+          + \".  Will try to delete \" + replicaToDelete);\n+    }\n+    return replicaToDelete;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static ReplicaInfo selectReplicaToDelete(final ReplicaInfo replica1,\n      final ReplicaInfo replica2) {\n    ReplicaInfo replicaToKeep;\n    ReplicaInfo replicaToDelete;\n\n    // it\u0027s the same block so don\u0027t ever delete it, even if GS or size\n    // differs.  caller should keep the one it just discovered on disk\n    if (replica1.getBlockFile().equals(replica2.getBlockFile())) {\n      return null;\n    }\n    if (replica1.getGenerationStamp() !\u003d replica2.getGenerationStamp()) {\n      replicaToKeep \u003d replica1.getGenerationStamp() \u003e replica2.getGenerationStamp()\n          ? replica1 : replica2;\n    } else if (replica1.getNumBytes() !\u003d replica2.getNumBytes()) {\n      replicaToKeep \u003d replica1.getNumBytes() \u003e replica2.getNumBytes() ?\n          replica1 : replica2;\n    } else if (replica1.getVolume().isTransientStorage() \u0026\u0026\n               !replica2.getVolume().isTransientStorage()) {\n      replicaToKeep \u003d replica2;\n    } else {\n      replicaToKeep \u003d replica1;\n    }\n\n    replicaToDelete \u003d (replicaToKeep \u003d\u003d replica1) ? replica2 : replica1;\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"resolveDuplicateReplicas decide to keep \" + replicaToKeep\n          + \".  Will try to delete \" + replicaToDelete);\n    }\n    return replicaToDelete;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java"
    }
  }
}