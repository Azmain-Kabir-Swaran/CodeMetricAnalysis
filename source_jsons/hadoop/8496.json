{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImage.java",
  "functionName": "recoverStorageDirs",
  "functionId": "recoverStorageDirs___startOpt-StartupOption__storage-NNStorage__dataDirStates-Map__StorageDirectory,StorageState__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
  "functionStartLine": 368,
  "functionEndLine": 417,
  "numCommitsSeen": 224,
  "timeTaken": 5362,
  "changeHistory": [
    "fddd55279d0bdd08b3b40aba6fe2ded1d2e0d846",
    "18620649f96d9e378fb7ea40de216284a9d525c7",
    "280bdb9a16a898118421aee16db11f52eed9bdae",
    "edb6dc5f303093c2604cd07b0c0dacf12dbce5de",
    "978a8050e28b2afb193a3e00d82a8475fa4d2428",
    "f87a4b40bc99e76602a75906df31747cfdbff78a",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63"
  ],
  "changeHistoryShort": {
    "fddd55279d0bdd08b3b40aba6fe2ded1d2e0d846": "Ymultichange(Yparameterchange,Ymodifierchange)",
    "18620649f96d9e378fb7ea40de216284a9d525c7": "Ybodychange",
    "280bdb9a16a898118421aee16db11f52eed9bdae": "Ybodychange",
    "edb6dc5f303093c2604cd07b0c0dacf12dbce5de": "Ybodychange",
    "978a8050e28b2afb193a3e00d82a8475fa4d2428": "Ybodychange",
    "f87a4b40bc99e76602a75906df31747cfdbff78a": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": "Yintroduced"
  },
  "changeHistoryDetails": {
    "fddd55279d0bdd08b3b40aba6fe2ded1d2e0d846": {
      "type": "Ymultichange(Yparameterchange,Ymodifierchange)",
      "commitMessage": "HDFS-8127. NameNode Failover during HA upgrade can cause DataNode to finalize upgrade. Contributed by Jing Zhao.\n",
      "commitDate": "14/04/15 3:05 PM",
      "commitName": "fddd55279d0bdd08b3b40aba6fe2ded1d2e0d846",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-8127. NameNode Failover during HA upgrade can cause DataNode to finalize upgrade. Contributed by Jing Zhao.\n",
          "commitDate": "14/04/15 3:05 PM",
          "commitName": "fddd55279d0bdd08b3b40aba6fe2ded1d2e0d846",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "09/04/15 10:42 PM",
          "commitNameOld": "987c9e12e184b35a5abab49f4188e22509ad63a5",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 4.68,
          "commitsBetweenForRepo": 33,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,49 +1,50 @@\n-  private boolean recoverStorageDirs(StartupOption startOpt,\n-      Map\u003cStorageDirectory, StorageState\u003e dataDirStates) throws IOException {\n+  public static boolean recoverStorageDirs(StartupOption startOpt,\n+      NNStorage storage, Map\u003cStorageDirectory, StorageState\u003e dataDirStates)\n+      throws IOException {\n     boolean isFormatted \u003d false;\n     // This loop needs to be over all storage dirs, even shared dirs, to make\n     // sure that we properly examine their state, but we make sure we don\u0027t\n     // mutate the shared dir below in the actual loop.\n     for (Iterator\u003cStorageDirectory\u003e it \u003d \n                       storage.dirIterator(); it.hasNext();) {\n       StorageDirectory sd \u003d it.next();\n       StorageState curState;\n       if (startOpt \u003d\u003d StartupOption.METADATAVERSION) {\n         /* All we need is the layout version. */\n         storage.readProperties(sd);\n         return true;\n       }\n \n       try {\n         curState \u003d sd.analyzeStorage(startOpt, storage);\n         // sd is locked but not opened\n         switch(curState) {\n         case NON_EXISTENT:\n           // name-node fails if any of the configured storage dirs are missing\n           throw new InconsistentFSStateException(sd.getRoot(),\n                       \"storage directory does not exist or is not accessible.\");\n         case NOT_FORMATTED:\n           break;\n         case NORMAL:\n           break;\n         default:  // recovery is possible\n           sd.doRecover(curState);\n         }\n         if (curState !\u003d StorageState.NOT_FORMATTED \n             \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n           // read and verify consistency with other directories\n           storage.readProperties(sd, startOpt);\n           isFormatted \u003d true;\n         }\n         if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n           // import of a checkpoint is allowed only into empty image directories\n           throw new IOException(\"Cannot import image from a checkpoint. \" \n               + \" NameNode already contains an image in \" + sd.getRoot());\n       } catch (IOException ioe) {\n         sd.unlock();\n         throw ioe;\n       }\n       dataDirStates.put(sd,curState);\n     }\n     return isFormatted;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static boolean recoverStorageDirs(StartupOption startOpt,\n      NNStorage storage, Map\u003cStorageDirectory, StorageState\u003e dataDirStates)\n      throws IOException {\n    boolean isFormatted \u003d false;\n    // This loop needs to be over all storage dirs, even shared dirs, to make\n    // sure that we properly examine their state, but we make sure we don\u0027t\n    // mutate the shared dir below in the actual loop.\n    for (Iterator\u003cStorageDirectory\u003e it \u003d \n                      storage.dirIterator(); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      StorageState curState;\n      if (startOpt \u003d\u003d StartupOption.METADATAVERSION) {\n        /* All we need is the layout version. */\n        storage.readProperties(sd);\n        return true;\n      }\n\n      try {\n        curState \u003d sd.analyzeStorage(startOpt, storage);\n        // sd is locked but not opened\n        switch(curState) {\n        case NON_EXISTENT:\n          // name-node fails if any of the configured storage dirs are missing\n          throw new InconsistentFSStateException(sd.getRoot(),\n                      \"storage directory does not exist or is not accessible.\");\n        case NOT_FORMATTED:\n          break;\n        case NORMAL:\n          break;\n        default:  // recovery is possible\n          sd.doRecover(curState);\n        }\n        if (curState !\u003d StorageState.NOT_FORMATTED \n            \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n          // read and verify consistency with other directories\n          storage.readProperties(sd, startOpt);\n          isFormatted \u003d true;\n        }\n        if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n          // import of a checkpoint is allowed only into empty image directories\n          throw new IOException(\"Cannot import image from a checkpoint. \" \n              + \" NameNode already contains an image in \" + sd.getRoot());\n      } catch (IOException ioe) {\n        sd.unlock();\n        throw ioe;\n      }\n      dataDirStates.put(sd,curState);\n    }\n    return isFormatted;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {
            "oldValue": "[startOpt-StartupOption, dataDirStates-Map\u003cStorageDirectory,StorageState\u003e]",
            "newValue": "[startOpt-StartupOption, storage-NNStorage, dataDirStates-Map\u003cStorageDirectory,StorageState\u003e]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-8127. NameNode Failover during HA upgrade can cause DataNode to finalize upgrade. Contributed by Jing Zhao.\n",
          "commitDate": "14/04/15 3:05 PM",
          "commitName": "fddd55279d0bdd08b3b40aba6fe2ded1d2e0d846",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "09/04/15 10:42 PM",
          "commitNameOld": "987c9e12e184b35a5abab49f4188e22509ad63a5",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 4.68,
          "commitsBetweenForRepo": 33,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,49 +1,50 @@\n-  private boolean recoverStorageDirs(StartupOption startOpt,\n-      Map\u003cStorageDirectory, StorageState\u003e dataDirStates) throws IOException {\n+  public static boolean recoverStorageDirs(StartupOption startOpt,\n+      NNStorage storage, Map\u003cStorageDirectory, StorageState\u003e dataDirStates)\n+      throws IOException {\n     boolean isFormatted \u003d false;\n     // This loop needs to be over all storage dirs, even shared dirs, to make\n     // sure that we properly examine their state, but we make sure we don\u0027t\n     // mutate the shared dir below in the actual loop.\n     for (Iterator\u003cStorageDirectory\u003e it \u003d \n                       storage.dirIterator(); it.hasNext();) {\n       StorageDirectory sd \u003d it.next();\n       StorageState curState;\n       if (startOpt \u003d\u003d StartupOption.METADATAVERSION) {\n         /* All we need is the layout version. */\n         storage.readProperties(sd);\n         return true;\n       }\n \n       try {\n         curState \u003d sd.analyzeStorage(startOpt, storage);\n         // sd is locked but not opened\n         switch(curState) {\n         case NON_EXISTENT:\n           // name-node fails if any of the configured storage dirs are missing\n           throw new InconsistentFSStateException(sd.getRoot(),\n                       \"storage directory does not exist or is not accessible.\");\n         case NOT_FORMATTED:\n           break;\n         case NORMAL:\n           break;\n         default:  // recovery is possible\n           sd.doRecover(curState);\n         }\n         if (curState !\u003d StorageState.NOT_FORMATTED \n             \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n           // read and verify consistency with other directories\n           storage.readProperties(sd, startOpt);\n           isFormatted \u003d true;\n         }\n         if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n           // import of a checkpoint is allowed only into empty image directories\n           throw new IOException(\"Cannot import image from a checkpoint. \" \n               + \" NameNode already contains an image in \" + sd.getRoot());\n       } catch (IOException ioe) {\n         sd.unlock();\n         throw ioe;\n       }\n       dataDirStates.put(sd,curState);\n     }\n     return isFormatted;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static boolean recoverStorageDirs(StartupOption startOpt,\n      NNStorage storage, Map\u003cStorageDirectory, StorageState\u003e dataDirStates)\n      throws IOException {\n    boolean isFormatted \u003d false;\n    // This loop needs to be over all storage dirs, even shared dirs, to make\n    // sure that we properly examine their state, but we make sure we don\u0027t\n    // mutate the shared dir below in the actual loop.\n    for (Iterator\u003cStorageDirectory\u003e it \u003d \n                      storage.dirIterator(); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      StorageState curState;\n      if (startOpt \u003d\u003d StartupOption.METADATAVERSION) {\n        /* All we need is the layout version. */\n        storage.readProperties(sd);\n        return true;\n      }\n\n      try {\n        curState \u003d sd.analyzeStorage(startOpt, storage);\n        // sd is locked but not opened\n        switch(curState) {\n        case NON_EXISTENT:\n          // name-node fails if any of the configured storage dirs are missing\n          throw new InconsistentFSStateException(sd.getRoot(),\n                      \"storage directory does not exist or is not accessible.\");\n        case NOT_FORMATTED:\n          break;\n        case NORMAL:\n          break;\n        default:  // recovery is possible\n          sd.doRecover(curState);\n        }\n        if (curState !\u003d StorageState.NOT_FORMATTED \n            \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n          // read and verify consistency with other directories\n          storage.readProperties(sd, startOpt);\n          isFormatted \u003d true;\n        }\n        if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n          // import of a checkpoint is allowed only into empty image directories\n          throw new IOException(\"Cannot import image from a checkpoint. \" \n              + \" NameNode already contains an image in \" + sd.getRoot());\n      } catch (IOException ioe) {\n        sd.unlock();\n        throw ioe;\n      }\n      dataDirStates.put(sd,curState);\n    }\n    return isFormatted;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[public, static]"
          }
        }
      ]
    },
    "18620649f96d9e378fb7ea40de216284a9d525c7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7185. The active NameNode will not accept an fsimage sent from the standby during rolling upgrade. Contributed by Jing Zhao.\n",
      "commitDate": "15/10/14 10:27 AM",
      "commitName": "18620649f96d9e378fb7ea40de216284a9d525c7",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "18/07/14 10:14 AM",
      "commitNameOld": "5f9e52f7459d3dc4ac3a5febd1dc6e00829d30ed",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 89.01,
      "commitsBetweenForRepo": 875,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,49 @@\n   private boolean recoverStorageDirs(StartupOption startOpt,\n       Map\u003cStorageDirectory, StorageState\u003e dataDirStates) throws IOException {\n     boolean isFormatted \u003d false;\n     // This loop needs to be over all storage dirs, even shared dirs, to make\n     // sure that we properly examine their state, but we make sure we don\u0027t\n     // mutate the shared dir below in the actual loop.\n     for (Iterator\u003cStorageDirectory\u003e it \u003d \n                       storage.dirIterator(); it.hasNext();) {\n       StorageDirectory sd \u003d it.next();\n       StorageState curState;\n       if (startOpt \u003d\u003d StartupOption.METADATAVERSION) {\n         /* All we need is the layout version. */\n         storage.readProperties(sd);\n         return true;\n       }\n \n       try {\n         curState \u003d sd.analyzeStorage(startOpt, storage);\n         // sd is locked but not opened\n         switch(curState) {\n         case NON_EXISTENT:\n           // name-node fails if any of the configured storage dirs are missing\n           throw new InconsistentFSStateException(sd.getRoot(),\n                       \"storage directory does not exist or is not accessible.\");\n         case NOT_FORMATTED:\n           break;\n         case NORMAL:\n           break;\n         default:  // recovery is possible\n           sd.doRecover(curState);\n         }\n         if (curState !\u003d StorageState.NOT_FORMATTED \n             \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n           // read and verify consistency with other directories\n-          storage.readProperties(sd);\n+          storage.readProperties(sd, startOpt);\n           isFormatted \u003d true;\n         }\n         if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n           // import of a checkpoint is allowed only into empty image directories\n           throw new IOException(\"Cannot import image from a checkpoint. \" \n               + \" NameNode already contains an image in \" + sd.getRoot());\n       } catch (IOException ioe) {\n         sd.unlock();\n         throw ioe;\n       }\n       dataDirStates.put(sd,curState);\n     }\n     return isFormatted;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean recoverStorageDirs(StartupOption startOpt,\n      Map\u003cStorageDirectory, StorageState\u003e dataDirStates) throws IOException {\n    boolean isFormatted \u003d false;\n    // This loop needs to be over all storage dirs, even shared dirs, to make\n    // sure that we properly examine their state, but we make sure we don\u0027t\n    // mutate the shared dir below in the actual loop.\n    for (Iterator\u003cStorageDirectory\u003e it \u003d \n                      storage.dirIterator(); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      StorageState curState;\n      if (startOpt \u003d\u003d StartupOption.METADATAVERSION) {\n        /* All we need is the layout version. */\n        storage.readProperties(sd);\n        return true;\n      }\n\n      try {\n        curState \u003d sd.analyzeStorage(startOpt, storage);\n        // sd is locked but not opened\n        switch(curState) {\n        case NON_EXISTENT:\n          // name-node fails if any of the configured storage dirs are missing\n          throw new InconsistentFSStateException(sd.getRoot(),\n                      \"storage directory does not exist or is not accessible.\");\n        case NOT_FORMATTED:\n          break;\n        case NORMAL:\n          break;\n        default:  // recovery is possible\n          sd.doRecover(curState);\n        }\n        if (curState !\u003d StorageState.NOT_FORMATTED \n            \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n          // read and verify consistency with other directories\n          storage.readProperties(sd, startOpt);\n          isFormatted \u003d true;\n        }\n        if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n          // import of a checkpoint is allowed only into empty image directories\n          throw new IOException(\"Cannot import image from a checkpoint. \" \n              + \" NameNode already contains an image in \" + sd.getRoot());\n      } catch (IOException ioe) {\n        sd.unlock();\n        throw ioe;\n      }\n      dataDirStates.put(sd,curState);\n    }\n    return isFormatted;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "280bdb9a16a898118421aee16db11f52eed9bdae": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6572. Add an option to the NameNode that prints the software and on-disk image versions. Contributed by Charles Lamb.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1605928 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/06/14 4:12 PM",
      "commitName": "280bdb9a16a898118421aee16db11f52eed9bdae",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "20/06/14 11:54 AM",
      "commitNameOld": "9ca79e8d327e95845ef9794396afd43a52bc3d40",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 6.18,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,49 @@\n   private boolean recoverStorageDirs(StartupOption startOpt,\n       Map\u003cStorageDirectory, StorageState\u003e dataDirStates) throws IOException {\n     boolean isFormatted \u003d false;\n     // This loop needs to be over all storage dirs, even shared dirs, to make\n     // sure that we properly examine their state, but we make sure we don\u0027t\n     // mutate the shared dir below in the actual loop.\n     for (Iterator\u003cStorageDirectory\u003e it \u003d \n                       storage.dirIterator(); it.hasNext();) {\n       StorageDirectory sd \u003d it.next();\n       StorageState curState;\n+      if (startOpt \u003d\u003d StartupOption.METADATAVERSION) {\n+        /* All we need is the layout version. */\n+        storage.readProperties(sd);\n+        return true;\n+      }\n+\n       try {\n         curState \u003d sd.analyzeStorage(startOpt, storage);\n         // sd is locked but not opened\n         switch(curState) {\n         case NON_EXISTENT:\n           // name-node fails if any of the configured storage dirs are missing\n           throw new InconsistentFSStateException(sd.getRoot(),\n                       \"storage directory does not exist or is not accessible.\");\n         case NOT_FORMATTED:\n           break;\n         case NORMAL:\n           break;\n         default:  // recovery is possible\n           sd.doRecover(curState);\n         }\n         if (curState !\u003d StorageState.NOT_FORMATTED \n             \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n           // read and verify consistency with other directories\n           storage.readProperties(sd);\n           isFormatted \u003d true;\n         }\n         if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n           // import of a checkpoint is allowed only into empty image directories\n           throw new IOException(\"Cannot import image from a checkpoint. \" \n               + \" NameNode already contains an image in \" + sd.getRoot());\n       } catch (IOException ioe) {\n         sd.unlock();\n         throw ioe;\n       }\n       dataDirStates.put(sd,curState);\n     }\n     return isFormatted;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean recoverStorageDirs(StartupOption startOpt,\n      Map\u003cStorageDirectory, StorageState\u003e dataDirStates) throws IOException {\n    boolean isFormatted \u003d false;\n    // This loop needs to be over all storage dirs, even shared dirs, to make\n    // sure that we properly examine their state, but we make sure we don\u0027t\n    // mutate the shared dir below in the actual loop.\n    for (Iterator\u003cStorageDirectory\u003e it \u003d \n                      storage.dirIterator(); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      StorageState curState;\n      if (startOpt \u003d\u003d StartupOption.METADATAVERSION) {\n        /* All we need is the layout version. */\n        storage.readProperties(sd);\n        return true;\n      }\n\n      try {\n        curState \u003d sd.analyzeStorage(startOpt, storage);\n        // sd is locked but not opened\n        switch(curState) {\n        case NON_EXISTENT:\n          // name-node fails if any of the configured storage dirs are missing\n          throw new InconsistentFSStateException(sd.getRoot(),\n                      \"storage directory does not exist or is not accessible.\");\n        case NOT_FORMATTED:\n          break;\n        case NORMAL:\n          break;\n        default:  // recovery is possible\n          sd.doRecover(curState);\n        }\n        if (curState !\u003d StorageState.NOT_FORMATTED \n            \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n          // read and verify consistency with other directories\n          storage.readProperties(sd);\n          isFormatted \u003d true;\n        }\n        if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n          // import of a checkpoint is allowed only into empty image directories\n          throw new IOException(\"Cannot import image from a checkpoint. \" \n              + \" NameNode already contains an image in \" + sd.getRoot());\n      } catch (IOException ioe) {\n        sd.unlock();\n        throw ioe;\n      }\n      dataDirStates.put(sd,curState);\n    }\n    return isFormatted;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "edb6dc5f303093c2604cd07b0c0dacf12dbce5de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5138. Support HDFS upgrade in HA. Contributed by Aaron T. Myers.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1561381 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/01/14 12:01 PM",
      "commitName": "edb6dc5f303093c2604cd07b0c0dacf12dbce5de",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "07/01/14 12:52 PM",
      "commitNameOld": "70cff9e2f0c8f78c1dc54a064182971bb2106795",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 17.96,
      "commitsBetweenForRepo": 91,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,45 +1,43 @@\n   private boolean recoverStorageDirs(StartupOption startOpt,\n       Map\u003cStorageDirectory, StorageState\u003e dataDirStates) throws IOException {\n     boolean isFormatted \u003d false;\n+    // This loop needs to be over all storage dirs, even shared dirs, to make\n+    // sure that we properly examine their state, but we make sure we don\u0027t\n+    // mutate the shared dir below in the actual loop.\n     for (Iterator\u003cStorageDirectory\u003e it \u003d \n                       storage.dirIterator(); it.hasNext();) {\n       StorageDirectory sd \u003d it.next();\n       StorageState curState;\n       try {\n         curState \u003d sd.analyzeStorage(startOpt, storage);\n-        String nameserviceId \u003d DFSUtil.getNamenodeNameServiceId(conf);\n-        if (curState !\u003d StorageState.NORMAL \u0026\u0026 HAUtil.isHAEnabled(conf, nameserviceId)) {\n-          throw new IOException(\"Cannot start an HA namenode with name dirs \" +\n-              \"that need recovery. Dir: \" + sd + \" state: \" + curState);\n-        }\n         // sd is locked but not opened\n         switch(curState) {\n         case NON_EXISTENT:\n           // name-node fails if any of the configured storage dirs are missing\n           throw new InconsistentFSStateException(sd.getRoot(),\n                       \"storage directory does not exist or is not accessible.\");\n         case NOT_FORMATTED:\n           break;\n         case NORMAL:\n           break;\n         default:  // recovery is possible\n-          sd.doRecover(curState);      \n+          sd.doRecover(curState);\n         }\n         if (curState !\u003d StorageState.NOT_FORMATTED \n             \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n           // read and verify consistency with other directories\n           storage.readProperties(sd);\n           isFormatted \u003d true;\n         }\n         if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n           // import of a checkpoint is allowed only into empty image directories\n           throw new IOException(\"Cannot import image from a checkpoint. \" \n               + \" NameNode already contains an image in \" + sd.getRoot());\n       } catch (IOException ioe) {\n         sd.unlock();\n         throw ioe;\n       }\n       dataDirStates.put(sd,curState);\n     }\n     return isFormatted;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean recoverStorageDirs(StartupOption startOpt,\n      Map\u003cStorageDirectory, StorageState\u003e dataDirStates) throws IOException {\n    boolean isFormatted \u003d false;\n    // This loop needs to be over all storage dirs, even shared dirs, to make\n    // sure that we properly examine their state, but we make sure we don\u0027t\n    // mutate the shared dir below in the actual loop.\n    for (Iterator\u003cStorageDirectory\u003e it \u003d \n                      storage.dirIterator(); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      StorageState curState;\n      try {\n        curState \u003d sd.analyzeStorage(startOpt, storage);\n        // sd is locked but not opened\n        switch(curState) {\n        case NON_EXISTENT:\n          // name-node fails if any of the configured storage dirs are missing\n          throw new InconsistentFSStateException(sd.getRoot(),\n                      \"storage directory does not exist or is not accessible.\");\n        case NOT_FORMATTED:\n          break;\n        case NORMAL:\n          break;\n        default:  // recovery is possible\n          sd.doRecover(curState);\n        }\n        if (curState !\u003d StorageState.NOT_FORMATTED \n            \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n          // read and verify consistency with other directories\n          storage.readProperties(sd);\n          isFormatted \u003d true;\n        }\n        if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n          // import of a checkpoint is allowed only into empty image directories\n          throw new IOException(\"Cannot import image from a checkpoint. \" \n              + \" NameNode already contains an image in \" + sd.getRoot());\n      } catch (IOException ioe) {\n        sd.unlock();\n        throw ioe;\n      }\n      dataDirStates.put(sd,curState);\n    }\n    return isFormatted;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "978a8050e28b2afb193a3e00d82a8475fa4d2428": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2920. fix remaining TODO items. Contributed by Aaron T. Myers and Todd Lipcon.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1294923 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/02/12 5:09 PM",
      "commitName": "978a8050e28b2afb193a3e00d82a8475fa4d2428",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "17/02/12 11:12 PM",
      "commitNameOld": "41e56dfecee0db1975c9859017c0de1226afb4b5",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 10.75,
      "commitsBetweenForRepo": 63,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,45 @@\n   private boolean recoverStorageDirs(StartupOption startOpt,\n       Map\u003cStorageDirectory, StorageState\u003e dataDirStates) throws IOException {\n     boolean isFormatted \u003d false;\n     for (Iterator\u003cStorageDirectory\u003e it \u003d \n                       storage.dirIterator(); it.hasNext();) {\n       StorageDirectory sd \u003d it.next();\n       StorageState curState;\n       try {\n         curState \u003d sd.analyzeStorage(startOpt, storage);\n-        // TODO(HA): Fix this.\n         String nameserviceId \u003d DFSUtil.getNamenodeNameServiceId(conf);\n         if (curState !\u003d StorageState.NORMAL \u0026\u0026 HAUtil.isHAEnabled(conf, nameserviceId)) {\n           throw new IOException(\"Cannot start an HA namenode with name dirs \" +\n               \"that need recovery. Dir: \" + sd + \" state: \" + curState);\n         }\n         // sd is locked but not opened\n         switch(curState) {\n         case NON_EXISTENT:\n           // name-node fails if any of the configured storage dirs are missing\n           throw new InconsistentFSStateException(sd.getRoot(),\n                       \"storage directory does not exist or is not accessible.\");\n         case NOT_FORMATTED:\n           break;\n         case NORMAL:\n           break;\n         default:  // recovery is possible\n           sd.doRecover(curState);      \n         }\n         if (curState !\u003d StorageState.NOT_FORMATTED \n             \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n           // read and verify consistency with other directories\n           storage.readProperties(sd);\n           isFormatted \u003d true;\n         }\n         if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n           // import of a checkpoint is allowed only into empty image directories\n           throw new IOException(\"Cannot import image from a checkpoint. \" \n               + \" NameNode already contains an image in \" + sd.getRoot());\n       } catch (IOException ioe) {\n         sd.unlock();\n         throw ioe;\n       }\n       dataDirStates.put(sd,curState);\n     }\n     return isFormatted;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean recoverStorageDirs(StartupOption startOpt,\n      Map\u003cStorageDirectory, StorageState\u003e dataDirStates) throws IOException {\n    boolean isFormatted \u003d false;\n    for (Iterator\u003cStorageDirectory\u003e it \u003d \n                      storage.dirIterator(); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      StorageState curState;\n      try {\n        curState \u003d sd.analyzeStorage(startOpt, storage);\n        String nameserviceId \u003d DFSUtil.getNamenodeNameServiceId(conf);\n        if (curState !\u003d StorageState.NORMAL \u0026\u0026 HAUtil.isHAEnabled(conf, nameserviceId)) {\n          throw new IOException(\"Cannot start an HA namenode with name dirs \" +\n              \"that need recovery. Dir: \" + sd + \" state: \" + curState);\n        }\n        // sd is locked but not opened\n        switch(curState) {\n        case NON_EXISTENT:\n          // name-node fails if any of the configured storage dirs are missing\n          throw new InconsistentFSStateException(sd.getRoot(),\n                      \"storage directory does not exist or is not accessible.\");\n        case NOT_FORMATTED:\n          break;\n        case NORMAL:\n          break;\n        default:  // recovery is possible\n          sd.doRecover(curState);      \n        }\n        if (curState !\u003d StorageState.NOT_FORMATTED \n            \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n          // read and verify consistency with other directories\n          storage.readProperties(sd);\n          isFormatted \u003d true;\n        }\n        if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n          // import of a checkpoint is allowed only into empty image directories\n          throw new IOException(\"Cannot import image from a checkpoint. \" \n              + \" NameNode already contains an image in \" + sd.getRoot());\n      } catch (IOException ioe) {\n        sd.unlock();\n        throw ioe;\n      }\n      dataDirStates.put(sd,curState);\n    }\n    return isFormatted;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "f87a4b40bc99e76602a75906df31747cfdbff78a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1975. Support for sharing the namenode state from active to standby. Contributed by Jitendra Nath Pandey, Aaron T Myers, and Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1208813 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/11/11 1:46 PM",
      "commitName": "f87a4b40bc99e76602a75906df31747cfdbff78a",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "01/11/11 9:44 AM",
      "commitNameOld": "496144158443078f5fc7c8930d971601f2b08dff",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 29.21,
      "commitsBetweenForRepo": 147,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,46 @@\n   private boolean recoverStorageDirs(StartupOption startOpt,\n       Map\u003cStorageDirectory, StorageState\u003e dataDirStates) throws IOException {\n     boolean isFormatted \u003d false;\n     for (Iterator\u003cStorageDirectory\u003e it \u003d \n                       storage.dirIterator(); it.hasNext();) {\n       StorageDirectory sd \u003d it.next();\n       StorageState curState;\n       try {\n         curState \u003d sd.analyzeStorage(startOpt, storage);\n+        // TODO(HA): Fix this.\n+        String nameserviceId \u003d DFSUtil.getNamenodeNameServiceId(conf);\n+        if (curState !\u003d StorageState.NORMAL \u0026\u0026 HAUtil.isHAEnabled(conf, nameserviceId)) {\n+          throw new IOException(\"Cannot start an HA namenode with name dirs \" +\n+              \"that need recovery. Dir: \" + sd + \" state: \" + curState);\n+        }\n         // sd is locked but not opened\n         switch(curState) {\n         case NON_EXISTENT:\n           // name-node fails if any of the configured storage dirs are missing\n           throw new InconsistentFSStateException(sd.getRoot(),\n                       \"storage directory does not exist or is not accessible.\");\n         case NOT_FORMATTED:\n           break;\n         case NORMAL:\n           break;\n         default:  // recovery is possible\n           sd.doRecover(curState);      \n         }\n         if (curState !\u003d StorageState.NOT_FORMATTED \n             \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n           // read and verify consistency with other directories\n           storage.readProperties(sd);\n           isFormatted \u003d true;\n         }\n         if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n           // import of a checkpoint is allowed only into empty image directories\n           throw new IOException(\"Cannot import image from a checkpoint. \" \n               + \" NameNode already contains an image in \" + sd.getRoot());\n       } catch (IOException ioe) {\n         sd.unlock();\n         throw ioe;\n       }\n       dataDirStates.put(sd,curState);\n     }\n     return isFormatted;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean recoverStorageDirs(StartupOption startOpt,\n      Map\u003cStorageDirectory, StorageState\u003e dataDirStates) throws IOException {\n    boolean isFormatted \u003d false;\n    for (Iterator\u003cStorageDirectory\u003e it \u003d \n                      storage.dirIterator(); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      StorageState curState;\n      try {\n        curState \u003d sd.analyzeStorage(startOpt, storage);\n        // TODO(HA): Fix this.\n        String nameserviceId \u003d DFSUtil.getNamenodeNameServiceId(conf);\n        if (curState !\u003d StorageState.NORMAL \u0026\u0026 HAUtil.isHAEnabled(conf, nameserviceId)) {\n          throw new IOException(\"Cannot start an HA namenode with name dirs \" +\n              \"that need recovery. Dir: \" + sd + \" state: \" + curState);\n        }\n        // sd is locked but not opened\n        switch(curState) {\n        case NON_EXISTENT:\n          // name-node fails if any of the configured storage dirs are missing\n          throw new InconsistentFSStateException(sd.getRoot(),\n                      \"storage directory does not exist or is not accessible.\");\n        case NOT_FORMATTED:\n          break;\n        case NORMAL:\n          break;\n        default:  // recovery is possible\n          sd.doRecover(curState);      \n        }\n        if (curState !\u003d StorageState.NOT_FORMATTED \n            \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n          // read and verify consistency with other directories\n          storage.readProperties(sd);\n          isFormatted \u003d true;\n        }\n        if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n          // import of a checkpoint is allowed only into empty image directories\n          throw new IOException(\"Cannot import image from a checkpoint. \" \n              + \" NameNode already contains an image in \" + sd.getRoot());\n      } catch (IOException ioe) {\n        sd.unlock();\n        throw ioe;\n      }\n      dataDirStates.put(sd,curState);\n    }\n    return isFormatted;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private boolean recoverStorageDirs(StartupOption startOpt,\n      Map\u003cStorageDirectory, StorageState\u003e dataDirStates) throws IOException {\n    boolean isFormatted \u003d false;\n    for (Iterator\u003cStorageDirectory\u003e it \u003d \n                      storage.dirIterator(); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      StorageState curState;\n      try {\n        curState \u003d sd.analyzeStorage(startOpt, storage);\n        // sd is locked but not opened\n        switch(curState) {\n        case NON_EXISTENT:\n          // name-node fails if any of the configured storage dirs are missing\n          throw new InconsistentFSStateException(sd.getRoot(),\n                      \"storage directory does not exist or is not accessible.\");\n        case NOT_FORMATTED:\n          break;\n        case NORMAL:\n          break;\n        default:  // recovery is possible\n          sd.doRecover(curState);      \n        }\n        if (curState !\u003d StorageState.NOT_FORMATTED \n            \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n          // read and verify consistency with other directories\n          storage.readProperties(sd);\n          isFormatted \u003d true;\n        }\n        if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n          // import of a checkpoint is allowed only into empty image directories\n          throw new IOException(\"Cannot import image from a checkpoint. \" \n              + \" NameNode already contains an image in \" + sd.getRoot());\n      } catch (IOException ioe) {\n        sd.unlock();\n        throw ioe;\n      }\n      dataDirStates.put(sd,curState);\n    }\n    return isFormatted;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private boolean recoverStorageDirs(StartupOption startOpt,\n      Map\u003cStorageDirectory, StorageState\u003e dataDirStates) throws IOException {\n    boolean isFormatted \u003d false;\n    for (Iterator\u003cStorageDirectory\u003e it \u003d \n                      storage.dirIterator(); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      StorageState curState;\n      try {\n        curState \u003d sd.analyzeStorage(startOpt, storage);\n        // sd is locked but not opened\n        switch(curState) {\n        case NON_EXISTENT:\n          // name-node fails if any of the configured storage dirs are missing\n          throw new InconsistentFSStateException(sd.getRoot(),\n                      \"storage directory does not exist or is not accessible.\");\n        case NOT_FORMATTED:\n          break;\n        case NORMAL:\n          break;\n        default:  // recovery is possible\n          sd.doRecover(curState);      \n        }\n        if (curState !\u003d StorageState.NOT_FORMATTED \n            \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n          // read and verify consistency with other directories\n          storage.readProperties(sd);\n          isFormatted \u003d true;\n        }\n        if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n          // import of a checkpoint is allowed only into empty image directories\n          throw new IOException(\"Cannot import image from a checkpoint. \" \n              + \" NameNode already contains an image in \" + sd.getRoot());\n      } catch (IOException ioe) {\n        sd.unlock();\n        throw ioe;\n      }\n      dataDirStates.put(sd,curState);\n    }\n    return isFormatted;\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java"
      }
    },
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/11 9:28 AM",
      "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,40 @@\n+  private boolean recoverStorageDirs(StartupOption startOpt,\n+      Map\u003cStorageDirectory, StorageState\u003e dataDirStates) throws IOException {\n+    boolean isFormatted \u003d false;\n+    for (Iterator\u003cStorageDirectory\u003e it \u003d \n+                      storage.dirIterator(); it.hasNext();) {\n+      StorageDirectory sd \u003d it.next();\n+      StorageState curState;\n+      try {\n+        curState \u003d sd.analyzeStorage(startOpt, storage);\n+        // sd is locked but not opened\n+        switch(curState) {\n+        case NON_EXISTENT:\n+          // name-node fails if any of the configured storage dirs are missing\n+          throw new InconsistentFSStateException(sd.getRoot(),\n+                      \"storage directory does not exist or is not accessible.\");\n+        case NOT_FORMATTED:\n+          break;\n+        case NORMAL:\n+          break;\n+        default:  // recovery is possible\n+          sd.doRecover(curState);      \n+        }\n+        if (curState !\u003d StorageState.NOT_FORMATTED \n+            \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n+          // read and verify consistency with other directories\n+          storage.readProperties(sd);\n+          isFormatted \u003d true;\n+        }\n+        if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n+          // import of a checkpoint is allowed only into empty image directories\n+          throw new IOException(\"Cannot import image from a checkpoint. \" \n+              + \" NameNode already contains an image in \" + sd.getRoot());\n+      } catch (IOException ioe) {\n+        sd.unlock();\n+        throw ioe;\n+      }\n+      dataDirStates.put(sd,curState);\n+    }\n+    return isFormatted;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean recoverStorageDirs(StartupOption startOpt,\n      Map\u003cStorageDirectory, StorageState\u003e dataDirStates) throws IOException {\n    boolean isFormatted \u003d false;\n    for (Iterator\u003cStorageDirectory\u003e it \u003d \n                      storage.dirIterator(); it.hasNext();) {\n      StorageDirectory sd \u003d it.next();\n      StorageState curState;\n      try {\n        curState \u003d sd.analyzeStorage(startOpt, storage);\n        // sd is locked but not opened\n        switch(curState) {\n        case NON_EXISTENT:\n          // name-node fails if any of the configured storage dirs are missing\n          throw new InconsistentFSStateException(sd.getRoot(),\n                      \"storage directory does not exist or is not accessible.\");\n        case NOT_FORMATTED:\n          break;\n        case NORMAL:\n          break;\n        default:  // recovery is possible\n          sd.doRecover(curState);      \n        }\n        if (curState !\u003d StorageState.NOT_FORMATTED \n            \u0026\u0026 startOpt !\u003d StartupOption.ROLLBACK) {\n          // read and verify consistency with other directories\n          storage.readProperties(sd);\n          isFormatted \u003d true;\n        }\n        if (startOpt \u003d\u003d StartupOption.IMPORT \u0026\u0026 isFormatted)\n          // import of a checkpoint is allowed only into empty image directories\n          throw new IOException(\"Cannot import image from a checkpoint. \" \n              + \" NameNode already contains an image in \" + sd.getRoot());\n      } catch (IOException ioe) {\n        sd.unlock();\n        throw ioe;\n      }\n      dataDirStates.put(sd,curState);\n    }\n    return isFormatted;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java"
    }
  }
}