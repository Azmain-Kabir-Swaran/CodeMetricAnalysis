{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AzureNativeFileSystemStore.java",
  "functionName": "buildUpList",
  "functionId": "buildUpList___aCloudBlobDirectory-CloudBlobDirectoryWrapper__metadataHashMap-HashMap__String,FileMetadata____maxListingCount-int(modifiers-final)__maxListingDepth-int(modifiers-final)",
  "sourceFilePath": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
  "functionStartLine": 2430,
  "functionEndLine": 2589,
  "numCommitsSeen": 99,
  "timeTaken": 3796,
  "changeHistory": [
    "45d9568aaaf532a6da11bd7c1844ff81bf66bab1",
    "15dd1f3381069c5fdc6690e3ab1907a133ba14bf",
    "2217e2f8ff418b88eac6ad36cafe3a9795a11f40",
    "81bc395deb3ba00567dc067d6ca71bacf9e3bc82"
  ],
  "changeHistoryShort": {
    "45d9568aaaf532a6da11bd7c1844ff81bf66bab1": "Ymultichange(Yparameterchange,Ybodychange)",
    "15dd1f3381069c5fdc6690e3ab1907a133ba14bf": "Ybodychange",
    "2217e2f8ff418b88eac6ad36cafe3a9795a11f40": "Ybodychange",
    "81bc395deb3ba00567dc067d6ca71bacf9e3bc82": "Yintroduced"
  },
  "changeHistoryDetails": {
    "45d9568aaaf532a6da11bd7c1844ff81bf66bab1": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HADOOP-15547/ WASB: improve listStatus performance.\nContributed by Thomas Marquardt.\n\n(cherry picked from commit 749fff577ed9afb4ef8a54b8948f74be083cc620)\n",
      "commitDate": "19/07/18 12:31 PM",
      "commitName": "45d9568aaaf532a6da11bd7c1844ff81bf66bab1",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-15547/ WASB: improve listStatus performance.\nContributed by Thomas Marquardt.\n\n(cherry picked from commit 749fff577ed9afb4ef8a54b8948f74be083cc620)\n",
          "commitDate": "19/07/18 12:31 PM",
          "commitName": "45d9568aaaf532a6da11bd7c1844ff81bf66bab1",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "27/06/18 10:37 PM",
          "commitNameOld": "2b2399d623539ab68e71a38fa9fbfc9a405bddb8",
          "commitAuthorOld": "Akira Ajisaka",
          "daysBetweenCommits": 21.58,
          "commitsBetweenForRepo": 124,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,142 +1,160 @@\n   private void buildUpList(CloudBlobDirectoryWrapper aCloudBlobDirectory,\n-      ArrayList\u003cFileMetadata\u003e aFileMetadataList, final int maxListingCount,\n-      final int maxListingDepth) throws Exception {\n+                           HashMap\u003cString, FileMetadata\u003e metadataHashMap, final int maxListingCount,\n+                           final int maxListingDepth) throws Exception {\n \n     // Push the blob directory onto the stack.\n     //\n     AzureLinkedStack\u003cIterator\u003cListBlobItem\u003e\u003e dirIteratorStack \u003d\n         new AzureLinkedStack\u003cIterator\u003cListBlobItem\u003e\u003e();\n \n     Iterable\u003cListBlobItem\u003e blobItems \u003d aCloudBlobDirectory.listBlobs(null,\n         false, EnumSet.of(BlobListingDetails.METADATA), null,\n         getInstrumentedContext());\n     Iterator\u003cListBlobItem\u003e blobItemIterator \u003d blobItems.iterator();\n \n     if (0 \u003d\u003d maxListingDepth || 0 \u003d\u003d maxListingCount) {\n       // Recurrence depth and listing count are already exhausted. Return\n       // immediately.\n       return;\n     }\n \n     // The directory listing depth is unbounded if the maximum listing depth\n     // is negative.\n     final boolean isUnboundedDepth \u003d (maxListingDepth \u003c 0);\n \n     // Reset the current directory listing depth.\n     int listingDepth \u003d 1;\n \n     // Loop until all directories have been traversed in-order. Loop only\n     // the following conditions are satisfied:\n     // (1) The stack is not empty, and\n     // (2) maxListingCount \u003e 0 implies that the number of items in the\n     // metadata list is less than the max listing count.\n     while (null !\u003d blobItemIterator\n-        \u0026\u0026 (maxListingCount \u003c\u003d 0 || aFileMetadataList.size() \u003c maxListingCount)) {\n+        \u0026\u0026 (maxListingCount \u003c\u003d 0 || metadataHashMap.size() \u003c maxListingCount)) {\n       while (blobItemIterator.hasNext()) {\n         // Check if the count of items on the list exhausts the maximum\n         // listing count.\n         //\n-        if (0 \u003c maxListingCount \u0026\u0026 aFileMetadataList.size() \u003e\u003d maxListingCount) {\n+        if (0 \u003c maxListingCount \u0026\u0026 metadataHashMap.size() \u003e\u003d maxListingCount) {\n           break;\n         }\n \n         ListBlobItem blobItem \u003d blobItemIterator.next();\n \n         // Add the file metadata to the list if this is not a blob\n         // directory item.\n         //\n         if (blobItem instanceof CloudBlockBlobWrapper || blobItem instanceof CloudPageBlobWrapper) {\n           String blobKey \u003d null;\n           CloudBlobWrapper blob \u003d (CloudBlobWrapper) blobItem;\n           BlobProperties properties \u003d blob.getProperties();\n \n           // Determine format of the blob name depending on whether an absolute\n           // path is being used or not.\n           blobKey \u003d normalizeKey(blob);\n \n           FileMetadata metadata;\n           if (retrieveFolderAttribute(blob)) {\n             metadata \u003d new FileMetadata(blobKey,\n                 properties.getLastModified().getTime(),\n                 getPermissionStatus(blob),\n-                BlobMaterialization.Explicit);\n+                BlobMaterialization.Explicit,\n+                hadoopBlockSize);\n           } else {\n             metadata \u003d new FileMetadata(\n                 blobKey,\n                 getDataLength(blob, properties),\n                 properties.getLastModified().getTime(),\n-                getPermissionStatus(blob));\n+                getPermissionStatus(blob),\n+                hadoopBlockSize);\n           }\n \n-          // Add the directory metadata to the list only if it\u0027s not already\n-          // there.\n-          FileMetadata existing \u003d getFileMetadataInList(aFileMetadataList, blobKey);\n-          if (existing !\u003d null) {\n-            aFileMetadataList.remove(existing);\n-          }\n-          aFileMetadataList.add(metadata);\n+          // Add the metadata but remove duplicates.  Note that the azure\n+          // storage java SDK returns two types of entries: CloudBlobWrappter\n+          // and CloudDirectoryWrapper.  In the case where WASB generated the\n+          // data, there will be an empty blob for each \"directory\", and we will\n+          // receive a CloudBlobWrapper.  If there are also files within this\n+          // \"directory\", we will also receive a CloudDirectoryWrapper.  To\n+          // complicate matters, the data may not be generated by WASB, in\n+          // which case we may not have an empty blob for each \"directory\".\n+          // So, sometimes we receive both a CloudBlobWrapper and a\n+          // CloudDirectoryWrapper for each directory, and sometimes we receive\n+          // one or the other but not both.  We remove duplicates, but\n+          // prefer CloudBlobWrapper over CloudDirectoryWrapper.\n+          // Furthermore, it is very unfortunate that the list results are not\n+          // ordered, and it is a partial list which uses continuation.  So\n+          // the HashMap is the best structure to remove the duplicates, despite\n+          // its potential large size.\n+          metadataHashMap.put(blobKey, metadata);\n         } else if (blobItem instanceof CloudBlobDirectoryWrapper) {\n           CloudBlobDirectoryWrapper directory \u003d (CloudBlobDirectoryWrapper) blobItem;\n \n           // This is a directory blob, push the current iterator onto\n           // the stack of iterators and start iterating through the current\n           // directory.\n           if (isUnboundedDepth || maxListingDepth \u003e listingDepth) {\n             // Push the current directory on the stack and increment the listing\n             // depth.\n             dirIteratorStack.push(blobItemIterator);\n             ++listingDepth;\n \n             // The current blob item represents the new directory. Get\n             // an iterator for this directory and continue by iterating through\n             // this directory.\n             blobItems \u003d directory.listBlobs(null, false,\n                 EnumSet.noneOf(BlobListingDetails.class), null,\n                 getInstrumentedContext());\n             blobItemIterator \u003d blobItems.iterator();\n           } else {\n             // Determine format of directory name depending on whether an\n             // absolute path is being used or not.\n             String dirKey \u003d normalizeKey(directory);\n \n-            if (getFileMetadataInList(aFileMetadataList, dirKey) \u003d\u003d null) {\n+            // Add the directory metadata to the list only if it\u0027s not already\n+            // there.  See earlier note, we prefer CloudBlobWrapper over\n+            // CloudDirectoryWrapper because it may have additional metadata (\n+            // properties and ACLs).\n+            if (!metadataHashMap.containsKey(dirKey)) {\n+\n               // Reached the targeted listing depth. Return metadata for the\n               // directory using default permissions.\n               //\n               // Note: Something smarter should be done about permissions. Maybe\n               // inherit the permissions of the first non-directory blob.\n               // Also, getting a proper value for last-modified is tricky.\n               //\n               FileMetadata directoryMetadata \u003d new FileMetadata(dirKey,\n                   0,\n                   defaultPermissionNoBlobMetadata(),\n-                  BlobMaterialization.Implicit);\n+                  BlobMaterialization.Implicit,\n+                  hadoopBlockSize);\n \n               // Add the directory metadata to the list.\n-              aFileMetadataList.add(directoryMetadata);\n+              metadataHashMap.put(dirKey, directoryMetadata);\n             }\n           }\n         }\n       }\n \n       // Traversal of directory tree\n \n       // Check if the iterator stack is empty. If it is set the next blob\n       // iterator to null. This will act as a terminator for the for-loop.\n       // Otherwise pop the next iterator from the stack and continue looping.\n       //\n       if (dirIteratorStack.isEmpty()) {\n         blobItemIterator \u003d null;\n       } else {\n         // Pop the next directory item from the stack and decrement the\n         // depth.\n         blobItemIterator \u003d dirIteratorStack.pop();\n         --listingDepth;\n \n         // Assertion: Listing depth should not be less than zero.\n         if (listingDepth \u003c 0) {\n           throw new AssertionError(\"Non-negative listing depth expected\");\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void buildUpList(CloudBlobDirectoryWrapper aCloudBlobDirectory,\n                           HashMap\u003cString, FileMetadata\u003e metadataHashMap, final int maxListingCount,\n                           final int maxListingDepth) throws Exception {\n\n    // Push the blob directory onto the stack.\n    //\n    AzureLinkedStack\u003cIterator\u003cListBlobItem\u003e\u003e dirIteratorStack \u003d\n        new AzureLinkedStack\u003cIterator\u003cListBlobItem\u003e\u003e();\n\n    Iterable\u003cListBlobItem\u003e blobItems \u003d aCloudBlobDirectory.listBlobs(null,\n        false, EnumSet.of(BlobListingDetails.METADATA), null,\n        getInstrumentedContext());\n    Iterator\u003cListBlobItem\u003e blobItemIterator \u003d blobItems.iterator();\n\n    if (0 \u003d\u003d maxListingDepth || 0 \u003d\u003d maxListingCount) {\n      // Recurrence depth and listing count are already exhausted. Return\n      // immediately.\n      return;\n    }\n\n    // The directory listing depth is unbounded if the maximum listing depth\n    // is negative.\n    final boolean isUnboundedDepth \u003d (maxListingDepth \u003c 0);\n\n    // Reset the current directory listing depth.\n    int listingDepth \u003d 1;\n\n    // Loop until all directories have been traversed in-order. Loop only\n    // the following conditions are satisfied:\n    // (1) The stack is not empty, and\n    // (2) maxListingCount \u003e 0 implies that the number of items in the\n    // metadata list is less than the max listing count.\n    while (null !\u003d blobItemIterator\n        \u0026\u0026 (maxListingCount \u003c\u003d 0 || metadataHashMap.size() \u003c maxListingCount)) {\n      while (blobItemIterator.hasNext()) {\n        // Check if the count of items on the list exhausts the maximum\n        // listing count.\n        //\n        if (0 \u003c maxListingCount \u0026\u0026 metadataHashMap.size() \u003e\u003d maxListingCount) {\n          break;\n        }\n\n        ListBlobItem blobItem \u003d blobItemIterator.next();\n\n        // Add the file metadata to the list if this is not a blob\n        // directory item.\n        //\n        if (blobItem instanceof CloudBlockBlobWrapper || blobItem instanceof CloudPageBlobWrapper) {\n          String blobKey \u003d null;\n          CloudBlobWrapper blob \u003d (CloudBlobWrapper) blobItem;\n          BlobProperties properties \u003d blob.getProperties();\n\n          // Determine format of the blob name depending on whether an absolute\n          // path is being used or not.\n          blobKey \u003d normalizeKey(blob);\n\n          FileMetadata metadata;\n          if (retrieveFolderAttribute(blob)) {\n            metadata \u003d new FileMetadata(blobKey,\n                properties.getLastModified().getTime(),\n                getPermissionStatus(blob),\n                BlobMaterialization.Explicit,\n                hadoopBlockSize);\n          } else {\n            metadata \u003d new FileMetadata(\n                blobKey,\n                getDataLength(blob, properties),\n                properties.getLastModified().getTime(),\n                getPermissionStatus(blob),\n                hadoopBlockSize);\n          }\n\n          // Add the metadata but remove duplicates.  Note that the azure\n          // storage java SDK returns two types of entries: CloudBlobWrappter\n          // and CloudDirectoryWrapper.  In the case where WASB generated the\n          // data, there will be an empty blob for each \"directory\", and we will\n          // receive a CloudBlobWrapper.  If there are also files within this\n          // \"directory\", we will also receive a CloudDirectoryWrapper.  To\n          // complicate matters, the data may not be generated by WASB, in\n          // which case we may not have an empty blob for each \"directory\".\n          // So, sometimes we receive both a CloudBlobWrapper and a\n          // CloudDirectoryWrapper for each directory, and sometimes we receive\n          // one or the other but not both.  We remove duplicates, but\n          // prefer CloudBlobWrapper over CloudDirectoryWrapper.\n          // Furthermore, it is very unfortunate that the list results are not\n          // ordered, and it is a partial list which uses continuation.  So\n          // the HashMap is the best structure to remove the duplicates, despite\n          // its potential large size.\n          metadataHashMap.put(blobKey, metadata);\n        } else if (blobItem instanceof CloudBlobDirectoryWrapper) {\n          CloudBlobDirectoryWrapper directory \u003d (CloudBlobDirectoryWrapper) blobItem;\n\n          // This is a directory blob, push the current iterator onto\n          // the stack of iterators and start iterating through the current\n          // directory.\n          if (isUnboundedDepth || maxListingDepth \u003e listingDepth) {\n            // Push the current directory on the stack and increment the listing\n            // depth.\n            dirIteratorStack.push(blobItemIterator);\n            ++listingDepth;\n\n            // The current blob item represents the new directory. Get\n            // an iterator for this directory and continue by iterating through\n            // this directory.\n            blobItems \u003d directory.listBlobs(null, false,\n                EnumSet.noneOf(BlobListingDetails.class), null,\n                getInstrumentedContext());\n            blobItemIterator \u003d blobItems.iterator();\n          } else {\n            // Determine format of directory name depending on whether an\n            // absolute path is being used or not.\n            String dirKey \u003d normalizeKey(directory);\n\n            // Add the directory metadata to the list only if it\u0027s not already\n            // there.  See earlier note, we prefer CloudBlobWrapper over\n            // CloudDirectoryWrapper because it may have additional metadata (\n            // properties and ACLs).\n            if (!metadataHashMap.containsKey(dirKey)) {\n\n              // Reached the targeted listing depth. Return metadata for the\n              // directory using default permissions.\n              //\n              // Note: Something smarter should be done about permissions. Maybe\n              // inherit the permissions of the first non-directory blob.\n              // Also, getting a proper value for last-modified is tricky.\n              //\n              FileMetadata directoryMetadata \u003d new FileMetadata(dirKey,\n                  0,\n                  defaultPermissionNoBlobMetadata(),\n                  BlobMaterialization.Implicit,\n                  hadoopBlockSize);\n\n              // Add the directory metadata to the list.\n              metadataHashMap.put(dirKey, directoryMetadata);\n            }\n          }\n        }\n      }\n\n      // Traversal of directory tree\n\n      // Check if the iterator stack is empty. If it is set the next blob\n      // iterator to null. This will act as a terminator for the for-loop.\n      // Otherwise pop the next iterator from the stack and continue looping.\n      //\n      if (dirIteratorStack.isEmpty()) {\n        blobItemIterator \u003d null;\n      } else {\n        // Pop the next directory item from the stack and decrement the\n        // depth.\n        blobItemIterator \u003d dirIteratorStack.pop();\n        --listingDepth;\n\n        // Assertion: Listing depth should not be less than zero.\n        if (listingDepth \u003c 0) {\n          throw new AssertionError(\"Non-negative listing depth expected\");\n        }\n      }\n    }\n  }",
          "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
          "extendedDetails": {
            "oldValue": "[aCloudBlobDirectory-CloudBlobDirectoryWrapper, aFileMetadataList-ArrayList\u003cFileMetadata\u003e, maxListingCount-int(modifiers-final), maxListingDepth-int(modifiers-final)]",
            "newValue": "[aCloudBlobDirectory-CloudBlobDirectoryWrapper, metadataHashMap-HashMap\u003cString,FileMetadata\u003e, maxListingCount-int(modifiers-final), maxListingDepth-int(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-15547/ WASB: improve listStatus performance.\nContributed by Thomas Marquardt.\n\n(cherry picked from commit 749fff577ed9afb4ef8a54b8948f74be083cc620)\n",
          "commitDate": "19/07/18 12:31 PM",
          "commitName": "45d9568aaaf532a6da11bd7c1844ff81bf66bab1",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "27/06/18 10:37 PM",
          "commitNameOld": "2b2399d623539ab68e71a38fa9fbfc9a405bddb8",
          "commitAuthorOld": "Akira Ajisaka",
          "daysBetweenCommits": 21.58,
          "commitsBetweenForRepo": 124,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,142 +1,160 @@\n   private void buildUpList(CloudBlobDirectoryWrapper aCloudBlobDirectory,\n-      ArrayList\u003cFileMetadata\u003e aFileMetadataList, final int maxListingCount,\n-      final int maxListingDepth) throws Exception {\n+                           HashMap\u003cString, FileMetadata\u003e metadataHashMap, final int maxListingCount,\n+                           final int maxListingDepth) throws Exception {\n \n     // Push the blob directory onto the stack.\n     //\n     AzureLinkedStack\u003cIterator\u003cListBlobItem\u003e\u003e dirIteratorStack \u003d\n         new AzureLinkedStack\u003cIterator\u003cListBlobItem\u003e\u003e();\n \n     Iterable\u003cListBlobItem\u003e blobItems \u003d aCloudBlobDirectory.listBlobs(null,\n         false, EnumSet.of(BlobListingDetails.METADATA), null,\n         getInstrumentedContext());\n     Iterator\u003cListBlobItem\u003e blobItemIterator \u003d blobItems.iterator();\n \n     if (0 \u003d\u003d maxListingDepth || 0 \u003d\u003d maxListingCount) {\n       // Recurrence depth and listing count are already exhausted. Return\n       // immediately.\n       return;\n     }\n \n     // The directory listing depth is unbounded if the maximum listing depth\n     // is negative.\n     final boolean isUnboundedDepth \u003d (maxListingDepth \u003c 0);\n \n     // Reset the current directory listing depth.\n     int listingDepth \u003d 1;\n \n     // Loop until all directories have been traversed in-order. Loop only\n     // the following conditions are satisfied:\n     // (1) The stack is not empty, and\n     // (2) maxListingCount \u003e 0 implies that the number of items in the\n     // metadata list is less than the max listing count.\n     while (null !\u003d blobItemIterator\n-        \u0026\u0026 (maxListingCount \u003c\u003d 0 || aFileMetadataList.size() \u003c maxListingCount)) {\n+        \u0026\u0026 (maxListingCount \u003c\u003d 0 || metadataHashMap.size() \u003c maxListingCount)) {\n       while (blobItemIterator.hasNext()) {\n         // Check if the count of items on the list exhausts the maximum\n         // listing count.\n         //\n-        if (0 \u003c maxListingCount \u0026\u0026 aFileMetadataList.size() \u003e\u003d maxListingCount) {\n+        if (0 \u003c maxListingCount \u0026\u0026 metadataHashMap.size() \u003e\u003d maxListingCount) {\n           break;\n         }\n \n         ListBlobItem blobItem \u003d blobItemIterator.next();\n \n         // Add the file metadata to the list if this is not a blob\n         // directory item.\n         //\n         if (blobItem instanceof CloudBlockBlobWrapper || blobItem instanceof CloudPageBlobWrapper) {\n           String blobKey \u003d null;\n           CloudBlobWrapper blob \u003d (CloudBlobWrapper) blobItem;\n           BlobProperties properties \u003d blob.getProperties();\n \n           // Determine format of the blob name depending on whether an absolute\n           // path is being used or not.\n           blobKey \u003d normalizeKey(blob);\n \n           FileMetadata metadata;\n           if (retrieveFolderAttribute(blob)) {\n             metadata \u003d new FileMetadata(blobKey,\n                 properties.getLastModified().getTime(),\n                 getPermissionStatus(blob),\n-                BlobMaterialization.Explicit);\n+                BlobMaterialization.Explicit,\n+                hadoopBlockSize);\n           } else {\n             metadata \u003d new FileMetadata(\n                 blobKey,\n                 getDataLength(blob, properties),\n                 properties.getLastModified().getTime(),\n-                getPermissionStatus(blob));\n+                getPermissionStatus(blob),\n+                hadoopBlockSize);\n           }\n \n-          // Add the directory metadata to the list only if it\u0027s not already\n-          // there.\n-          FileMetadata existing \u003d getFileMetadataInList(aFileMetadataList, blobKey);\n-          if (existing !\u003d null) {\n-            aFileMetadataList.remove(existing);\n-          }\n-          aFileMetadataList.add(metadata);\n+          // Add the metadata but remove duplicates.  Note that the azure\n+          // storage java SDK returns two types of entries: CloudBlobWrappter\n+          // and CloudDirectoryWrapper.  In the case where WASB generated the\n+          // data, there will be an empty blob for each \"directory\", and we will\n+          // receive a CloudBlobWrapper.  If there are also files within this\n+          // \"directory\", we will also receive a CloudDirectoryWrapper.  To\n+          // complicate matters, the data may not be generated by WASB, in\n+          // which case we may not have an empty blob for each \"directory\".\n+          // So, sometimes we receive both a CloudBlobWrapper and a\n+          // CloudDirectoryWrapper for each directory, and sometimes we receive\n+          // one or the other but not both.  We remove duplicates, but\n+          // prefer CloudBlobWrapper over CloudDirectoryWrapper.\n+          // Furthermore, it is very unfortunate that the list results are not\n+          // ordered, and it is a partial list which uses continuation.  So\n+          // the HashMap is the best structure to remove the duplicates, despite\n+          // its potential large size.\n+          metadataHashMap.put(blobKey, metadata);\n         } else if (blobItem instanceof CloudBlobDirectoryWrapper) {\n           CloudBlobDirectoryWrapper directory \u003d (CloudBlobDirectoryWrapper) blobItem;\n \n           // This is a directory blob, push the current iterator onto\n           // the stack of iterators and start iterating through the current\n           // directory.\n           if (isUnboundedDepth || maxListingDepth \u003e listingDepth) {\n             // Push the current directory on the stack and increment the listing\n             // depth.\n             dirIteratorStack.push(blobItemIterator);\n             ++listingDepth;\n \n             // The current blob item represents the new directory. Get\n             // an iterator for this directory and continue by iterating through\n             // this directory.\n             blobItems \u003d directory.listBlobs(null, false,\n                 EnumSet.noneOf(BlobListingDetails.class), null,\n                 getInstrumentedContext());\n             blobItemIterator \u003d blobItems.iterator();\n           } else {\n             // Determine format of directory name depending on whether an\n             // absolute path is being used or not.\n             String dirKey \u003d normalizeKey(directory);\n \n-            if (getFileMetadataInList(aFileMetadataList, dirKey) \u003d\u003d null) {\n+            // Add the directory metadata to the list only if it\u0027s not already\n+            // there.  See earlier note, we prefer CloudBlobWrapper over\n+            // CloudDirectoryWrapper because it may have additional metadata (\n+            // properties and ACLs).\n+            if (!metadataHashMap.containsKey(dirKey)) {\n+\n               // Reached the targeted listing depth. Return metadata for the\n               // directory using default permissions.\n               //\n               // Note: Something smarter should be done about permissions. Maybe\n               // inherit the permissions of the first non-directory blob.\n               // Also, getting a proper value for last-modified is tricky.\n               //\n               FileMetadata directoryMetadata \u003d new FileMetadata(dirKey,\n                   0,\n                   defaultPermissionNoBlobMetadata(),\n-                  BlobMaterialization.Implicit);\n+                  BlobMaterialization.Implicit,\n+                  hadoopBlockSize);\n \n               // Add the directory metadata to the list.\n-              aFileMetadataList.add(directoryMetadata);\n+              metadataHashMap.put(dirKey, directoryMetadata);\n             }\n           }\n         }\n       }\n \n       // Traversal of directory tree\n \n       // Check if the iterator stack is empty. If it is set the next blob\n       // iterator to null. This will act as a terminator for the for-loop.\n       // Otherwise pop the next iterator from the stack and continue looping.\n       //\n       if (dirIteratorStack.isEmpty()) {\n         blobItemIterator \u003d null;\n       } else {\n         // Pop the next directory item from the stack and decrement the\n         // depth.\n         blobItemIterator \u003d dirIteratorStack.pop();\n         --listingDepth;\n \n         // Assertion: Listing depth should not be less than zero.\n         if (listingDepth \u003c 0) {\n           throw new AssertionError(\"Non-negative listing depth expected\");\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void buildUpList(CloudBlobDirectoryWrapper aCloudBlobDirectory,\n                           HashMap\u003cString, FileMetadata\u003e metadataHashMap, final int maxListingCount,\n                           final int maxListingDepth) throws Exception {\n\n    // Push the blob directory onto the stack.\n    //\n    AzureLinkedStack\u003cIterator\u003cListBlobItem\u003e\u003e dirIteratorStack \u003d\n        new AzureLinkedStack\u003cIterator\u003cListBlobItem\u003e\u003e();\n\n    Iterable\u003cListBlobItem\u003e blobItems \u003d aCloudBlobDirectory.listBlobs(null,\n        false, EnumSet.of(BlobListingDetails.METADATA), null,\n        getInstrumentedContext());\n    Iterator\u003cListBlobItem\u003e blobItemIterator \u003d blobItems.iterator();\n\n    if (0 \u003d\u003d maxListingDepth || 0 \u003d\u003d maxListingCount) {\n      // Recurrence depth and listing count are already exhausted. Return\n      // immediately.\n      return;\n    }\n\n    // The directory listing depth is unbounded if the maximum listing depth\n    // is negative.\n    final boolean isUnboundedDepth \u003d (maxListingDepth \u003c 0);\n\n    // Reset the current directory listing depth.\n    int listingDepth \u003d 1;\n\n    // Loop until all directories have been traversed in-order. Loop only\n    // the following conditions are satisfied:\n    // (1) The stack is not empty, and\n    // (2) maxListingCount \u003e 0 implies that the number of items in the\n    // metadata list is less than the max listing count.\n    while (null !\u003d blobItemIterator\n        \u0026\u0026 (maxListingCount \u003c\u003d 0 || metadataHashMap.size() \u003c maxListingCount)) {\n      while (blobItemIterator.hasNext()) {\n        // Check if the count of items on the list exhausts the maximum\n        // listing count.\n        //\n        if (0 \u003c maxListingCount \u0026\u0026 metadataHashMap.size() \u003e\u003d maxListingCount) {\n          break;\n        }\n\n        ListBlobItem blobItem \u003d blobItemIterator.next();\n\n        // Add the file metadata to the list if this is not a blob\n        // directory item.\n        //\n        if (blobItem instanceof CloudBlockBlobWrapper || blobItem instanceof CloudPageBlobWrapper) {\n          String blobKey \u003d null;\n          CloudBlobWrapper blob \u003d (CloudBlobWrapper) blobItem;\n          BlobProperties properties \u003d blob.getProperties();\n\n          // Determine format of the blob name depending on whether an absolute\n          // path is being used or not.\n          blobKey \u003d normalizeKey(blob);\n\n          FileMetadata metadata;\n          if (retrieveFolderAttribute(blob)) {\n            metadata \u003d new FileMetadata(blobKey,\n                properties.getLastModified().getTime(),\n                getPermissionStatus(blob),\n                BlobMaterialization.Explicit,\n                hadoopBlockSize);\n          } else {\n            metadata \u003d new FileMetadata(\n                blobKey,\n                getDataLength(blob, properties),\n                properties.getLastModified().getTime(),\n                getPermissionStatus(blob),\n                hadoopBlockSize);\n          }\n\n          // Add the metadata but remove duplicates.  Note that the azure\n          // storage java SDK returns two types of entries: CloudBlobWrappter\n          // and CloudDirectoryWrapper.  In the case where WASB generated the\n          // data, there will be an empty blob for each \"directory\", and we will\n          // receive a CloudBlobWrapper.  If there are also files within this\n          // \"directory\", we will also receive a CloudDirectoryWrapper.  To\n          // complicate matters, the data may not be generated by WASB, in\n          // which case we may not have an empty blob for each \"directory\".\n          // So, sometimes we receive both a CloudBlobWrapper and a\n          // CloudDirectoryWrapper for each directory, and sometimes we receive\n          // one or the other but not both.  We remove duplicates, but\n          // prefer CloudBlobWrapper over CloudDirectoryWrapper.\n          // Furthermore, it is very unfortunate that the list results are not\n          // ordered, and it is a partial list which uses continuation.  So\n          // the HashMap is the best structure to remove the duplicates, despite\n          // its potential large size.\n          metadataHashMap.put(blobKey, metadata);\n        } else if (blobItem instanceof CloudBlobDirectoryWrapper) {\n          CloudBlobDirectoryWrapper directory \u003d (CloudBlobDirectoryWrapper) blobItem;\n\n          // This is a directory blob, push the current iterator onto\n          // the stack of iterators and start iterating through the current\n          // directory.\n          if (isUnboundedDepth || maxListingDepth \u003e listingDepth) {\n            // Push the current directory on the stack and increment the listing\n            // depth.\n            dirIteratorStack.push(blobItemIterator);\n            ++listingDepth;\n\n            // The current blob item represents the new directory. Get\n            // an iterator for this directory and continue by iterating through\n            // this directory.\n            blobItems \u003d directory.listBlobs(null, false,\n                EnumSet.noneOf(BlobListingDetails.class), null,\n                getInstrumentedContext());\n            blobItemIterator \u003d blobItems.iterator();\n          } else {\n            // Determine format of directory name depending on whether an\n            // absolute path is being used or not.\n            String dirKey \u003d normalizeKey(directory);\n\n            // Add the directory metadata to the list only if it\u0027s not already\n            // there.  See earlier note, we prefer CloudBlobWrapper over\n            // CloudDirectoryWrapper because it may have additional metadata (\n            // properties and ACLs).\n            if (!metadataHashMap.containsKey(dirKey)) {\n\n              // Reached the targeted listing depth. Return metadata for the\n              // directory using default permissions.\n              //\n              // Note: Something smarter should be done about permissions. Maybe\n              // inherit the permissions of the first non-directory blob.\n              // Also, getting a proper value for last-modified is tricky.\n              //\n              FileMetadata directoryMetadata \u003d new FileMetadata(dirKey,\n                  0,\n                  defaultPermissionNoBlobMetadata(),\n                  BlobMaterialization.Implicit,\n                  hadoopBlockSize);\n\n              // Add the directory metadata to the list.\n              metadataHashMap.put(dirKey, directoryMetadata);\n            }\n          }\n        }\n      }\n\n      // Traversal of directory tree\n\n      // Check if the iterator stack is empty. If it is set the next blob\n      // iterator to null. This will act as a terminator for the for-loop.\n      // Otherwise pop the next iterator from the stack and continue looping.\n      //\n      if (dirIteratorStack.isEmpty()) {\n        blobItemIterator \u003d null;\n      } else {\n        // Pop the next directory item from the stack and decrement the\n        // depth.\n        blobItemIterator \u003d dirIteratorStack.pop();\n        --listingDepth;\n\n        // Assertion: Listing depth should not be less than zero.\n        if (listingDepth \u003c 0) {\n          throw new AssertionError(\"Non-negative listing depth expected\");\n        }\n      }\n    }\n  }",
          "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
          "extendedDetails": {}
        }
      ]
    },
    "15dd1f3381069c5fdc6690e3ab1907a133ba14bf": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13675. Bug in return value for delete() calls in WASB. Contributed by Dushyanth\n",
      "commitDate": "05/12/16 12:04 PM",
      "commitName": "15dd1f3381069c5fdc6690e3ab1907a133ba14bf",
      "commitAuthor": "Mingliang Liu",
      "commitDateOld": "27/10/16 4:09 PM",
      "commitNameOld": "5877f20f9c3f6f0afa505715e9a2ee312475af17",
      "commitAuthorOld": "Robert Kanter",
      "daysBetweenCommits": 38.87,
      "commitsBetweenForRepo": 283,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,142 +1,142 @@\n   private void buildUpList(CloudBlobDirectoryWrapper aCloudBlobDirectory,\n       ArrayList\u003cFileMetadata\u003e aFileMetadataList, final int maxListingCount,\n       final int maxListingDepth) throws Exception {\n \n     // Push the blob directory onto the stack.\n     //\n     AzureLinkedStack\u003cIterator\u003cListBlobItem\u003e\u003e dirIteratorStack \u003d\n         new AzureLinkedStack\u003cIterator\u003cListBlobItem\u003e\u003e();\n \n     Iterable\u003cListBlobItem\u003e blobItems \u003d aCloudBlobDirectory.listBlobs(null,\n         false, EnumSet.of(BlobListingDetails.METADATA), null,\n         getInstrumentedContext());\n     Iterator\u003cListBlobItem\u003e blobItemIterator \u003d blobItems.iterator();\n \n     if (0 \u003d\u003d maxListingDepth || 0 \u003d\u003d maxListingCount) {\n       // Recurrence depth and listing count are already exhausted. Return\n       // immediately.\n       return;\n     }\n \n     // The directory listing depth is unbounded if the maximum listing depth\n     // is negative.\n     final boolean isUnboundedDepth \u003d (maxListingDepth \u003c 0);\n \n     // Reset the current directory listing depth.\n     int listingDepth \u003d 1;\n \n     // Loop until all directories have been traversed in-order. Loop only\n     // the following conditions are satisfied:\n     // (1) The stack is not empty, and\n     // (2) maxListingCount \u003e 0 implies that the number of items in the\n     // metadata list is less than the max listing count.\n     while (null !\u003d blobItemIterator\n         \u0026\u0026 (maxListingCount \u003c\u003d 0 || aFileMetadataList.size() \u003c maxListingCount)) {\n       while (blobItemIterator.hasNext()) {\n         // Check if the count of items on the list exhausts the maximum\n         // listing count.\n         //\n         if (0 \u003c maxListingCount \u0026\u0026 aFileMetadataList.size() \u003e\u003d maxListingCount) {\n           break;\n         }\n \n         ListBlobItem blobItem \u003d blobItemIterator.next();\n \n         // Add the file metadata to the list if this is not a blob\n         // directory item.\n         //\n         if (blobItem instanceof CloudBlockBlobWrapper || blobItem instanceof CloudPageBlobWrapper) {\n           String blobKey \u003d null;\n           CloudBlobWrapper blob \u003d (CloudBlobWrapper) blobItem;\n           BlobProperties properties \u003d blob.getProperties();\n \n           // Determine format of the blob name depending on whether an absolute\n           // path is being used or not.\n           blobKey \u003d normalizeKey(blob);\n \n           FileMetadata metadata;\n           if (retrieveFolderAttribute(blob)) {\n             metadata \u003d new FileMetadata(blobKey,\n                 properties.getLastModified().getTime(),\n                 getPermissionStatus(blob),\n                 BlobMaterialization.Explicit);\n           } else {\n             metadata \u003d new FileMetadata(\n                 blobKey,\n                 getDataLength(blob, properties),\n                 properties.getLastModified().getTime(),\n                 getPermissionStatus(blob));\n           }\n \n           // Add the directory metadata to the list only if it\u0027s not already\n           // there.\n-          FileMetadata existing \u003d getDirectoryInList(aFileMetadataList, blobKey);\n+          FileMetadata existing \u003d getFileMetadataInList(aFileMetadataList, blobKey);\n           if (existing !\u003d null) {\n             aFileMetadataList.remove(existing);\n           }\n           aFileMetadataList.add(metadata);\n         } else if (blobItem instanceof CloudBlobDirectoryWrapper) {\n           CloudBlobDirectoryWrapper directory \u003d (CloudBlobDirectoryWrapper) blobItem;\n \n           // This is a directory blob, push the current iterator onto\n           // the stack of iterators and start iterating through the current\n           // directory.\n           if (isUnboundedDepth || maxListingDepth \u003e listingDepth) {\n             // Push the current directory on the stack and increment the listing\n             // depth.\n             dirIteratorStack.push(blobItemIterator);\n             ++listingDepth;\n \n             // The current blob item represents the new directory. Get\n             // an iterator for this directory and continue by iterating through\n             // this directory.\n             blobItems \u003d directory.listBlobs(null, false,\n                 EnumSet.noneOf(BlobListingDetails.class), null,\n                 getInstrumentedContext());\n             blobItemIterator \u003d blobItems.iterator();\n           } else {\n             // Determine format of directory name depending on whether an\n             // absolute path is being used or not.\n             String dirKey \u003d normalizeKey(directory);\n \n-            if (getDirectoryInList(aFileMetadataList, dirKey) \u003d\u003d null) {\n+            if (getFileMetadataInList(aFileMetadataList, dirKey) \u003d\u003d null) {\n               // Reached the targeted listing depth. Return metadata for the\n               // directory using default permissions.\n               //\n               // Note: Something smarter should be done about permissions. Maybe\n               // inherit the permissions of the first non-directory blob.\n               // Also, getting a proper value for last-modified is tricky.\n               //\n               FileMetadata directoryMetadata \u003d new FileMetadata(dirKey,\n                   0,\n                   defaultPermissionNoBlobMetadata(),\n                   BlobMaterialization.Implicit);\n \n               // Add the directory metadata to the list.\n               aFileMetadataList.add(directoryMetadata);\n             }\n           }\n         }\n       }\n \n       // Traversal of directory tree\n \n       // Check if the iterator stack is empty. If it is set the next blob\n       // iterator to null. This will act as a terminator for the for-loop.\n       // Otherwise pop the next iterator from the stack and continue looping.\n       //\n       if (dirIteratorStack.isEmpty()) {\n         blobItemIterator \u003d null;\n       } else {\n         // Pop the next directory item from the stack and decrement the\n         // depth.\n         blobItemIterator \u003d dirIteratorStack.pop();\n         --listingDepth;\n \n         // Assertion: Listing depth should not be less than zero.\n         if (listingDepth \u003c 0) {\n           throw new AssertionError(\"Non-negative listing depth expected\");\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void buildUpList(CloudBlobDirectoryWrapper aCloudBlobDirectory,\n      ArrayList\u003cFileMetadata\u003e aFileMetadataList, final int maxListingCount,\n      final int maxListingDepth) throws Exception {\n\n    // Push the blob directory onto the stack.\n    //\n    AzureLinkedStack\u003cIterator\u003cListBlobItem\u003e\u003e dirIteratorStack \u003d\n        new AzureLinkedStack\u003cIterator\u003cListBlobItem\u003e\u003e();\n\n    Iterable\u003cListBlobItem\u003e blobItems \u003d aCloudBlobDirectory.listBlobs(null,\n        false, EnumSet.of(BlobListingDetails.METADATA), null,\n        getInstrumentedContext());\n    Iterator\u003cListBlobItem\u003e blobItemIterator \u003d blobItems.iterator();\n\n    if (0 \u003d\u003d maxListingDepth || 0 \u003d\u003d maxListingCount) {\n      // Recurrence depth and listing count are already exhausted. Return\n      // immediately.\n      return;\n    }\n\n    // The directory listing depth is unbounded if the maximum listing depth\n    // is negative.\n    final boolean isUnboundedDepth \u003d (maxListingDepth \u003c 0);\n\n    // Reset the current directory listing depth.\n    int listingDepth \u003d 1;\n\n    // Loop until all directories have been traversed in-order. Loop only\n    // the following conditions are satisfied:\n    // (1) The stack is not empty, and\n    // (2) maxListingCount \u003e 0 implies that the number of items in the\n    // metadata list is less than the max listing count.\n    while (null !\u003d blobItemIterator\n        \u0026\u0026 (maxListingCount \u003c\u003d 0 || aFileMetadataList.size() \u003c maxListingCount)) {\n      while (blobItemIterator.hasNext()) {\n        // Check if the count of items on the list exhausts the maximum\n        // listing count.\n        //\n        if (0 \u003c maxListingCount \u0026\u0026 aFileMetadataList.size() \u003e\u003d maxListingCount) {\n          break;\n        }\n\n        ListBlobItem blobItem \u003d blobItemIterator.next();\n\n        // Add the file metadata to the list if this is not a blob\n        // directory item.\n        //\n        if (blobItem instanceof CloudBlockBlobWrapper || blobItem instanceof CloudPageBlobWrapper) {\n          String blobKey \u003d null;\n          CloudBlobWrapper blob \u003d (CloudBlobWrapper) blobItem;\n          BlobProperties properties \u003d blob.getProperties();\n\n          // Determine format of the blob name depending on whether an absolute\n          // path is being used or not.\n          blobKey \u003d normalizeKey(blob);\n\n          FileMetadata metadata;\n          if (retrieveFolderAttribute(blob)) {\n            metadata \u003d new FileMetadata(blobKey,\n                properties.getLastModified().getTime(),\n                getPermissionStatus(blob),\n                BlobMaterialization.Explicit);\n          } else {\n            metadata \u003d new FileMetadata(\n                blobKey,\n                getDataLength(blob, properties),\n                properties.getLastModified().getTime(),\n                getPermissionStatus(blob));\n          }\n\n          // Add the directory metadata to the list only if it\u0027s not already\n          // there.\n          FileMetadata existing \u003d getFileMetadataInList(aFileMetadataList, blobKey);\n          if (existing !\u003d null) {\n            aFileMetadataList.remove(existing);\n          }\n          aFileMetadataList.add(metadata);\n        } else if (blobItem instanceof CloudBlobDirectoryWrapper) {\n          CloudBlobDirectoryWrapper directory \u003d (CloudBlobDirectoryWrapper) blobItem;\n\n          // This is a directory blob, push the current iterator onto\n          // the stack of iterators and start iterating through the current\n          // directory.\n          if (isUnboundedDepth || maxListingDepth \u003e listingDepth) {\n            // Push the current directory on the stack and increment the listing\n            // depth.\n            dirIteratorStack.push(blobItemIterator);\n            ++listingDepth;\n\n            // The current blob item represents the new directory. Get\n            // an iterator for this directory and continue by iterating through\n            // this directory.\n            blobItems \u003d directory.listBlobs(null, false,\n                EnumSet.noneOf(BlobListingDetails.class), null,\n                getInstrumentedContext());\n            blobItemIterator \u003d blobItems.iterator();\n          } else {\n            // Determine format of directory name depending on whether an\n            // absolute path is being used or not.\n            String dirKey \u003d normalizeKey(directory);\n\n            if (getFileMetadataInList(aFileMetadataList, dirKey) \u003d\u003d null) {\n              // Reached the targeted listing depth. Return metadata for the\n              // directory using default permissions.\n              //\n              // Note: Something smarter should be done about permissions. Maybe\n              // inherit the permissions of the first non-directory blob.\n              // Also, getting a proper value for last-modified is tricky.\n              //\n              FileMetadata directoryMetadata \u003d new FileMetadata(dirKey,\n                  0,\n                  defaultPermissionNoBlobMetadata(),\n                  BlobMaterialization.Implicit);\n\n              // Add the directory metadata to the list.\n              aFileMetadataList.add(directoryMetadata);\n            }\n          }\n        }\n      }\n\n      // Traversal of directory tree\n\n      // Check if the iterator stack is empty. If it is set the next blob\n      // iterator to null. This will act as a terminator for the for-loop.\n      // Otherwise pop the next iterator from the stack and continue looping.\n      //\n      if (dirIteratorStack.isEmpty()) {\n        blobItemIterator \u003d null;\n      } else {\n        // Pop the next directory item from the stack and decrement the\n        // depth.\n        blobItemIterator \u003d dirIteratorStack.pop();\n        --listingDepth;\n\n        // Assertion: Listing depth should not be less than zero.\n        if (listingDepth \u003c 0) {\n          throw new AssertionError(\"Non-negative listing depth expected\");\n        }\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
      "extendedDetails": {}
    },
    "2217e2f8ff418b88eac6ad36cafe3a9795a11f40": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10809. hadoop-azure: page blob support. Contributed by Dexter Bradshaw, Mostafa Elhemali, Eric Hanson, and Mike Liddell.\n",
      "commitDate": "08/10/14 2:20 PM",
      "commitName": "2217e2f8ff418b88eac6ad36cafe3a9795a11f40",
      "commitAuthor": "cnauroth",
      "commitDateOld": "24/06/14 1:52 PM",
      "commitNameOld": "0d91576ec31f63402f2db6107a04155368e2632d",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 106.02,
      "commitsBetweenForRepo": 1005,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,134 +1,142 @@\n   private void buildUpList(CloudBlobDirectoryWrapper aCloudBlobDirectory,\n       ArrayList\u003cFileMetadata\u003e aFileMetadataList, final int maxListingCount,\n       final int maxListingDepth) throws Exception {\n \n     // Push the blob directory onto the stack.\n-    LinkedList\u003cIterator\u003cListBlobItem\u003e\u003e dirIteratorStack \u003d new LinkedList\u003cIterator\u003cListBlobItem\u003e\u003e();\n+    //\n+    AzureLinkedStack\u003cIterator\u003cListBlobItem\u003e\u003e dirIteratorStack \u003d\n+        new AzureLinkedStack\u003cIterator\u003cListBlobItem\u003e\u003e();\n \n     Iterable\u003cListBlobItem\u003e blobItems \u003d aCloudBlobDirectory.listBlobs(null,\n         false, EnumSet.of(BlobListingDetails.METADATA), null,\n         getInstrumentedContext());\n     Iterator\u003cListBlobItem\u003e blobItemIterator \u003d blobItems.iterator();\n \n     if (0 \u003d\u003d maxListingDepth || 0 \u003d\u003d maxListingCount) {\n       // Recurrence depth and listing count are already exhausted. Return\n       // immediately.\n       return;\n     }\n \n     // The directory listing depth is unbounded if the maximum listing depth\n     // is negative.\n     final boolean isUnboundedDepth \u003d (maxListingDepth \u003c 0);\n \n     // Reset the current directory listing depth.\n     int listingDepth \u003d 1;\n \n     // Loop until all directories have been traversed in-order. Loop only\n     // the following conditions are satisfied:\n     // (1) The stack is not empty, and\n     // (2) maxListingCount \u003e 0 implies that the number of items in the\n     // metadata list is less than the max listing count.\n     while (null !\u003d blobItemIterator\n         \u0026\u0026 (maxListingCount \u003c\u003d 0 || aFileMetadataList.size() \u003c maxListingCount)) {\n       while (blobItemIterator.hasNext()) {\n         // Check if the count of items on the list exhausts the maximum\n         // listing count.\n         //\n         if (0 \u003c maxListingCount \u0026\u0026 aFileMetadataList.size() \u003e\u003d maxListingCount) {\n           break;\n         }\n \n         ListBlobItem blobItem \u003d blobItemIterator.next();\n \n         // Add the file metadata to the list if this is not a blob\n         // directory item.\n-        if (blobItem instanceof CloudBlockBlobWrapper) {\n+        //\n+        if (blobItem instanceof CloudBlockBlobWrapper || blobItem instanceof CloudPageBlobWrapper) {\n           String blobKey \u003d null;\n-          CloudBlockBlobWrapper blob \u003d (CloudBlockBlobWrapper) blobItem;\n+          CloudBlobWrapper blob \u003d (CloudBlobWrapper) blobItem;\n           BlobProperties properties \u003d blob.getProperties();\n \n           // Determine format of the blob name depending on whether an absolute\n           // path is being used or not.\n           blobKey \u003d normalizeKey(blob);\n \n           FileMetadata metadata;\n           if (retrieveFolderAttribute(blob)) {\n-            metadata \u003d new FileMetadata(blobKey, properties.getLastModified()\n-                .getTime(), getPermissionStatus(blob),\n+            metadata \u003d new FileMetadata(blobKey,\n+                properties.getLastModified().getTime(),\n+                getPermissionStatus(blob),\n                 BlobMaterialization.Explicit);\n           } else {\n-            metadata \u003d new FileMetadata(blobKey, properties.getLength(),\n+            metadata \u003d new FileMetadata(\n+                blobKey,\n+                getDataLength(blob, properties),\n                 properties.getLastModified().getTime(),\n                 getPermissionStatus(blob));\n           }\n \n           // Add the directory metadata to the list only if it\u0027s not already\n           // there.\n           FileMetadata existing \u003d getDirectoryInList(aFileMetadataList, blobKey);\n           if (existing !\u003d null) {\n             aFileMetadataList.remove(existing);\n           }\n           aFileMetadataList.add(metadata);\n         } else if (blobItem instanceof CloudBlobDirectoryWrapper) {\n           CloudBlobDirectoryWrapper directory \u003d (CloudBlobDirectoryWrapper) blobItem;\n \n           // This is a directory blob, push the current iterator onto\n           // the stack of iterators and start iterating through the current\n           // directory.\n           if (isUnboundedDepth || maxListingDepth \u003e listingDepth) {\n             // Push the current directory on the stack and increment the listing\n             // depth.\n             dirIteratorStack.push(blobItemIterator);\n             ++listingDepth;\n \n             // The current blob item represents the new directory. Get\n             // an iterator for this directory and continue by iterating through\n             // this directory.\n             blobItems \u003d directory.listBlobs(null, false,\n                 EnumSet.noneOf(BlobListingDetails.class), null,\n                 getInstrumentedContext());\n             blobItemIterator \u003d blobItems.iterator();\n           } else {\n             // Determine format of directory name depending on whether an\n             // absolute path is being used or not.\n             String dirKey \u003d normalizeKey(directory);\n \n             if (getDirectoryInList(aFileMetadataList, dirKey) \u003d\u003d null) {\n               // Reached the targeted listing depth. Return metadata for the\n               // directory using default permissions.\n               //\n               // Note: Something smarter should be done about permissions. Maybe\n               // inherit the permissions of the first non-directory blob.\n               // Also, getting a proper value for last-modified is tricky.\n-              FileMetadata directoryMetadata \u003d new FileMetadata(dirKey, 0,\n+              //\n+              FileMetadata directoryMetadata \u003d new FileMetadata(dirKey,\n+                  0,\n                   defaultPermissionNoBlobMetadata(),\n                   BlobMaterialization.Implicit);\n \n               // Add the directory metadata to the list.\n               aFileMetadataList.add(directoryMetadata);\n             }\n           }\n         }\n       }\n \n       // Traversal of directory tree\n \n       // Check if the iterator stack is empty. If it is set the next blob\n       // iterator to null. This will act as a terminator for the for-loop.\n       // Otherwise pop the next iterator from the stack and continue looping.\n       //\n       if (dirIteratorStack.isEmpty()) {\n         blobItemIterator \u003d null;\n       } else {\n         // Pop the next directory item from the stack and decrement the\n         // depth.\n         blobItemIterator \u003d dirIteratorStack.pop();\n         --listingDepth;\n \n         // Assertion: Listing depth should not be less than zero.\n         if (listingDepth \u003c 0) {\n           throw new AssertionError(\"Non-negative listing depth expected\");\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void buildUpList(CloudBlobDirectoryWrapper aCloudBlobDirectory,\n      ArrayList\u003cFileMetadata\u003e aFileMetadataList, final int maxListingCount,\n      final int maxListingDepth) throws Exception {\n\n    // Push the blob directory onto the stack.\n    //\n    AzureLinkedStack\u003cIterator\u003cListBlobItem\u003e\u003e dirIteratorStack \u003d\n        new AzureLinkedStack\u003cIterator\u003cListBlobItem\u003e\u003e();\n\n    Iterable\u003cListBlobItem\u003e blobItems \u003d aCloudBlobDirectory.listBlobs(null,\n        false, EnumSet.of(BlobListingDetails.METADATA), null,\n        getInstrumentedContext());\n    Iterator\u003cListBlobItem\u003e blobItemIterator \u003d blobItems.iterator();\n\n    if (0 \u003d\u003d maxListingDepth || 0 \u003d\u003d maxListingCount) {\n      // Recurrence depth and listing count are already exhausted. Return\n      // immediately.\n      return;\n    }\n\n    // The directory listing depth is unbounded if the maximum listing depth\n    // is negative.\n    final boolean isUnboundedDepth \u003d (maxListingDepth \u003c 0);\n\n    // Reset the current directory listing depth.\n    int listingDepth \u003d 1;\n\n    // Loop until all directories have been traversed in-order. Loop only\n    // the following conditions are satisfied:\n    // (1) The stack is not empty, and\n    // (2) maxListingCount \u003e 0 implies that the number of items in the\n    // metadata list is less than the max listing count.\n    while (null !\u003d blobItemIterator\n        \u0026\u0026 (maxListingCount \u003c\u003d 0 || aFileMetadataList.size() \u003c maxListingCount)) {\n      while (blobItemIterator.hasNext()) {\n        // Check if the count of items on the list exhausts the maximum\n        // listing count.\n        //\n        if (0 \u003c maxListingCount \u0026\u0026 aFileMetadataList.size() \u003e\u003d maxListingCount) {\n          break;\n        }\n\n        ListBlobItem blobItem \u003d blobItemIterator.next();\n\n        // Add the file metadata to the list if this is not a blob\n        // directory item.\n        //\n        if (blobItem instanceof CloudBlockBlobWrapper || blobItem instanceof CloudPageBlobWrapper) {\n          String blobKey \u003d null;\n          CloudBlobWrapper blob \u003d (CloudBlobWrapper) blobItem;\n          BlobProperties properties \u003d blob.getProperties();\n\n          // Determine format of the blob name depending on whether an absolute\n          // path is being used or not.\n          blobKey \u003d normalizeKey(blob);\n\n          FileMetadata metadata;\n          if (retrieveFolderAttribute(blob)) {\n            metadata \u003d new FileMetadata(blobKey,\n                properties.getLastModified().getTime(),\n                getPermissionStatus(blob),\n                BlobMaterialization.Explicit);\n          } else {\n            metadata \u003d new FileMetadata(\n                blobKey,\n                getDataLength(blob, properties),\n                properties.getLastModified().getTime(),\n                getPermissionStatus(blob));\n          }\n\n          // Add the directory metadata to the list only if it\u0027s not already\n          // there.\n          FileMetadata existing \u003d getDirectoryInList(aFileMetadataList, blobKey);\n          if (existing !\u003d null) {\n            aFileMetadataList.remove(existing);\n          }\n          aFileMetadataList.add(metadata);\n        } else if (blobItem instanceof CloudBlobDirectoryWrapper) {\n          CloudBlobDirectoryWrapper directory \u003d (CloudBlobDirectoryWrapper) blobItem;\n\n          // This is a directory blob, push the current iterator onto\n          // the stack of iterators and start iterating through the current\n          // directory.\n          if (isUnboundedDepth || maxListingDepth \u003e listingDepth) {\n            // Push the current directory on the stack and increment the listing\n            // depth.\n            dirIteratorStack.push(blobItemIterator);\n            ++listingDepth;\n\n            // The current blob item represents the new directory. Get\n            // an iterator for this directory and continue by iterating through\n            // this directory.\n            blobItems \u003d directory.listBlobs(null, false,\n                EnumSet.noneOf(BlobListingDetails.class), null,\n                getInstrumentedContext());\n            blobItemIterator \u003d blobItems.iterator();\n          } else {\n            // Determine format of directory name depending on whether an\n            // absolute path is being used or not.\n            String dirKey \u003d normalizeKey(directory);\n\n            if (getDirectoryInList(aFileMetadataList, dirKey) \u003d\u003d null) {\n              // Reached the targeted listing depth. Return metadata for the\n              // directory using default permissions.\n              //\n              // Note: Something smarter should be done about permissions. Maybe\n              // inherit the permissions of the first non-directory blob.\n              // Also, getting a proper value for last-modified is tricky.\n              //\n              FileMetadata directoryMetadata \u003d new FileMetadata(dirKey,\n                  0,\n                  defaultPermissionNoBlobMetadata(),\n                  BlobMaterialization.Implicit);\n\n              // Add the directory metadata to the list.\n              aFileMetadataList.add(directoryMetadata);\n            }\n          }\n        }\n      }\n\n      // Traversal of directory tree\n\n      // Check if the iterator stack is empty. If it is set the next blob\n      // iterator to null. This will act as a terminator for the for-loop.\n      // Otherwise pop the next iterator from the stack and continue looping.\n      //\n      if (dirIteratorStack.isEmpty()) {\n        blobItemIterator \u003d null;\n      } else {\n        // Pop the next directory item from the stack and decrement the\n        // depth.\n        blobItemIterator \u003d dirIteratorStack.pop();\n        --listingDepth;\n\n        // Assertion: Listing depth should not be less than zero.\n        if (listingDepth \u003c 0) {\n          throw new AssertionError(\"Non-negative listing depth expected\");\n        }\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
      "extendedDetails": {}
    },
    "81bc395deb3ba00567dc067d6ca71bacf9e3bc82": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-9629. Support Windows Azure Storage - Blob as a file system in Hadoop. Contributed by Dexter Bradshaw, Mostafa Elhemali, Xi Fang, Johannes Klein, David Lao, Mike Liddell, Chuan Liu, Lengning Liu, Ivan Mitic, Michael Rys, Alexander Stojanovic, Brian Swan, and Min Wei.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1601781 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/06/14 3:26 PM",
      "commitName": "81bc395deb3ba00567dc067d6ca71bacf9e3bc82",
      "commitAuthor": "Chris Nauroth",
      "diff": "@@ -0,0 +1,134 @@\n+  private void buildUpList(CloudBlobDirectoryWrapper aCloudBlobDirectory,\n+      ArrayList\u003cFileMetadata\u003e aFileMetadataList, final int maxListingCount,\n+      final int maxListingDepth) throws Exception {\n+\n+    // Push the blob directory onto the stack.\n+    LinkedList\u003cIterator\u003cListBlobItem\u003e\u003e dirIteratorStack \u003d new LinkedList\u003cIterator\u003cListBlobItem\u003e\u003e();\n+\n+    Iterable\u003cListBlobItem\u003e blobItems \u003d aCloudBlobDirectory.listBlobs(null,\n+        false, EnumSet.of(BlobListingDetails.METADATA), null,\n+        getInstrumentedContext());\n+    Iterator\u003cListBlobItem\u003e blobItemIterator \u003d blobItems.iterator();\n+\n+    if (0 \u003d\u003d maxListingDepth || 0 \u003d\u003d maxListingCount) {\n+      // Recurrence depth and listing count are already exhausted. Return\n+      // immediately.\n+      return;\n+    }\n+\n+    // The directory listing depth is unbounded if the maximum listing depth\n+    // is negative.\n+    final boolean isUnboundedDepth \u003d (maxListingDepth \u003c 0);\n+\n+    // Reset the current directory listing depth.\n+    int listingDepth \u003d 1;\n+\n+    // Loop until all directories have been traversed in-order. Loop only\n+    // the following conditions are satisfied:\n+    // (1) The stack is not empty, and\n+    // (2) maxListingCount \u003e 0 implies that the number of items in the\n+    // metadata list is less than the max listing count.\n+    while (null !\u003d blobItemIterator\n+        \u0026\u0026 (maxListingCount \u003c\u003d 0 || aFileMetadataList.size() \u003c maxListingCount)) {\n+      while (blobItemIterator.hasNext()) {\n+        // Check if the count of items on the list exhausts the maximum\n+        // listing count.\n+        //\n+        if (0 \u003c maxListingCount \u0026\u0026 aFileMetadataList.size() \u003e\u003d maxListingCount) {\n+          break;\n+        }\n+\n+        ListBlobItem blobItem \u003d blobItemIterator.next();\n+\n+        // Add the file metadata to the list if this is not a blob\n+        // directory item.\n+        if (blobItem instanceof CloudBlockBlobWrapper) {\n+          String blobKey \u003d null;\n+          CloudBlockBlobWrapper blob \u003d (CloudBlockBlobWrapper) blobItem;\n+          BlobProperties properties \u003d blob.getProperties();\n+\n+          // Determine format of the blob name depending on whether an absolute\n+          // path is being used or not.\n+          blobKey \u003d normalizeKey(blob);\n+\n+          FileMetadata metadata;\n+          if (retrieveFolderAttribute(blob)) {\n+            metadata \u003d new FileMetadata(blobKey, properties.getLastModified()\n+                .getTime(), getPermissionStatus(blob),\n+                BlobMaterialization.Explicit);\n+          } else {\n+            metadata \u003d new FileMetadata(blobKey, properties.getLength(),\n+                properties.getLastModified().getTime(),\n+                getPermissionStatus(blob));\n+          }\n+\n+          // Add the directory metadata to the list only if it\u0027s not already\n+          // there.\n+          FileMetadata existing \u003d getDirectoryInList(aFileMetadataList, blobKey);\n+          if (existing !\u003d null) {\n+            aFileMetadataList.remove(existing);\n+          }\n+          aFileMetadataList.add(metadata);\n+        } else if (blobItem instanceof CloudBlobDirectoryWrapper) {\n+          CloudBlobDirectoryWrapper directory \u003d (CloudBlobDirectoryWrapper) blobItem;\n+\n+          // This is a directory blob, push the current iterator onto\n+          // the stack of iterators and start iterating through the current\n+          // directory.\n+          if (isUnboundedDepth || maxListingDepth \u003e listingDepth) {\n+            // Push the current directory on the stack and increment the listing\n+            // depth.\n+            dirIteratorStack.push(blobItemIterator);\n+            ++listingDepth;\n+\n+            // The current blob item represents the new directory. Get\n+            // an iterator for this directory and continue by iterating through\n+            // this directory.\n+            blobItems \u003d directory.listBlobs(null, false,\n+                EnumSet.noneOf(BlobListingDetails.class), null,\n+                getInstrumentedContext());\n+            blobItemIterator \u003d blobItems.iterator();\n+          } else {\n+            // Determine format of directory name depending on whether an\n+            // absolute path is being used or not.\n+            String dirKey \u003d normalizeKey(directory);\n+\n+            if (getDirectoryInList(aFileMetadataList, dirKey) \u003d\u003d null) {\n+              // Reached the targeted listing depth. Return metadata for the\n+              // directory using default permissions.\n+              //\n+              // Note: Something smarter should be done about permissions. Maybe\n+              // inherit the permissions of the first non-directory blob.\n+              // Also, getting a proper value for last-modified is tricky.\n+              FileMetadata directoryMetadata \u003d new FileMetadata(dirKey, 0,\n+                  defaultPermissionNoBlobMetadata(),\n+                  BlobMaterialization.Implicit);\n+\n+              // Add the directory metadata to the list.\n+              aFileMetadataList.add(directoryMetadata);\n+            }\n+          }\n+        }\n+      }\n+\n+      // Traversal of directory tree\n+\n+      // Check if the iterator stack is empty. If it is set the next blob\n+      // iterator to null. This will act as a terminator for the for-loop.\n+      // Otherwise pop the next iterator from the stack and continue looping.\n+      //\n+      if (dirIteratorStack.isEmpty()) {\n+        blobItemIterator \u003d null;\n+      } else {\n+        // Pop the next directory item from the stack and decrement the\n+        // depth.\n+        blobItemIterator \u003d dirIteratorStack.pop();\n+        --listingDepth;\n+\n+        // Assertion: Listing depth should not be less than zero.\n+        if (listingDepth \u003c 0) {\n+          throw new AssertionError(\"Non-negative listing depth expected\");\n+        }\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void buildUpList(CloudBlobDirectoryWrapper aCloudBlobDirectory,\n      ArrayList\u003cFileMetadata\u003e aFileMetadataList, final int maxListingCount,\n      final int maxListingDepth) throws Exception {\n\n    // Push the blob directory onto the stack.\n    LinkedList\u003cIterator\u003cListBlobItem\u003e\u003e dirIteratorStack \u003d new LinkedList\u003cIterator\u003cListBlobItem\u003e\u003e();\n\n    Iterable\u003cListBlobItem\u003e blobItems \u003d aCloudBlobDirectory.listBlobs(null,\n        false, EnumSet.of(BlobListingDetails.METADATA), null,\n        getInstrumentedContext());\n    Iterator\u003cListBlobItem\u003e blobItemIterator \u003d blobItems.iterator();\n\n    if (0 \u003d\u003d maxListingDepth || 0 \u003d\u003d maxListingCount) {\n      // Recurrence depth and listing count are already exhausted. Return\n      // immediately.\n      return;\n    }\n\n    // The directory listing depth is unbounded if the maximum listing depth\n    // is negative.\n    final boolean isUnboundedDepth \u003d (maxListingDepth \u003c 0);\n\n    // Reset the current directory listing depth.\n    int listingDepth \u003d 1;\n\n    // Loop until all directories have been traversed in-order. Loop only\n    // the following conditions are satisfied:\n    // (1) The stack is not empty, and\n    // (2) maxListingCount \u003e 0 implies that the number of items in the\n    // metadata list is less than the max listing count.\n    while (null !\u003d blobItemIterator\n        \u0026\u0026 (maxListingCount \u003c\u003d 0 || aFileMetadataList.size() \u003c maxListingCount)) {\n      while (blobItemIterator.hasNext()) {\n        // Check if the count of items on the list exhausts the maximum\n        // listing count.\n        //\n        if (0 \u003c maxListingCount \u0026\u0026 aFileMetadataList.size() \u003e\u003d maxListingCount) {\n          break;\n        }\n\n        ListBlobItem blobItem \u003d blobItemIterator.next();\n\n        // Add the file metadata to the list if this is not a blob\n        // directory item.\n        if (blobItem instanceof CloudBlockBlobWrapper) {\n          String blobKey \u003d null;\n          CloudBlockBlobWrapper blob \u003d (CloudBlockBlobWrapper) blobItem;\n          BlobProperties properties \u003d blob.getProperties();\n\n          // Determine format of the blob name depending on whether an absolute\n          // path is being used or not.\n          blobKey \u003d normalizeKey(blob);\n\n          FileMetadata metadata;\n          if (retrieveFolderAttribute(blob)) {\n            metadata \u003d new FileMetadata(blobKey, properties.getLastModified()\n                .getTime(), getPermissionStatus(blob),\n                BlobMaterialization.Explicit);\n          } else {\n            metadata \u003d new FileMetadata(blobKey, properties.getLength(),\n                properties.getLastModified().getTime(),\n                getPermissionStatus(blob));\n          }\n\n          // Add the directory metadata to the list only if it\u0027s not already\n          // there.\n          FileMetadata existing \u003d getDirectoryInList(aFileMetadataList, blobKey);\n          if (existing !\u003d null) {\n            aFileMetadataList.remove(existing);\n          }\n          aFileMetadataList.add(metadata);\n        } else if (blobItem instanceof CloudBlobDirectoryWrapper) {\n          CloudBlobDirectoryWrapper directory \u003d (CloudBlobDirectoryWrapper) blobItem;\n\n          // This is a directory blob, push the current iterator onto\n          // the stack of iterators and start iterating through the current\n          // directory.\n          if (isUnboundedDepth || maxListingDepth \u003e listingDepth) {\n            // Push the current directory on the stack and increment the listing\n            // depth.\n            dirIteratorStack.push(blobItemIterator);\n            ++listingDepth;\n\n            // The current blob item represents the new directory. Get\n            // an iterator for this directory and continue by iterating through\n            // this directory.\n            blobItems \u003d directory.listBlobs(null, false,\n                EnumSet.noneOf(BlobListingDetails.class), null,\n                getInstrumentedContext());\n            blobItemIterator \u003d blobItems.iterator();\n          } else {\n            // Determine format of directory name depending on whether an\n            // absolute path is being used or not.\n            String dirKey \u003d normalizeKey(directory);\n\n            if (getDirectoryInList(aFileMetadataList, dirKey) \u003d\u003d null) {\n              // Reached the targeted listing depth. Return metadata for the\n              // directory using default permissions.\n              //\n              // Note: Something smarter should be done about permissions. Maybe\n              // inherit the permissions of the first non-directory blob.\n              // Also, getting a proper value for last-modified is tricky.\n              FileMetadata directoryMetadata \u003d new FileMetadata(dirKey, 0,\n                  defaultPermissionNoBlobMetadata(),\n                  BlobMaterialization.Implicit);\n\n              // Add the directory metadata to the list.\n              aFileMetadataList.add(directoryMetadata);\n            }\n          }\n        }\n      }\n\n      // Traversal of directory tree\n\n      // Check if the iterator stack is empty. If it is set the next blob\n      // iterator to null. This will act as a terminator for the for-loop.\n      // Otherwise pop the next iterator from the stack and continue looping.\n      //\n      if (dirIteratorStack.isEmpty()) {\n        blobItemIterator \u003d null;\n      } else {\n        // Pop the next directory item from the stack and decrement the\n        // depth.\n        blobItemIterator \u003d dirIteratorStack.pop();\n        --listingDepth;\n\n        // Assertion: Listing depth should not be less than zero.\n        if (listingDepth \u003c 0) {\n          throw new AssertionError(\"Non-negative listing depth expected\");\n        }\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java"
    }
  }
}