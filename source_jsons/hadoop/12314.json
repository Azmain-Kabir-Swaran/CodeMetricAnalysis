{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "VolumeScanner.java",
  "functionName": "enableBlockPoolId",
  "functionId": "enableBlockPoolId___bpid-String",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/VolumeScanner.java",
  "functionStartLine": 729,
  "functionEndLine": 753,
  "numCommitsSeen": 20,
  "timeTaken": 1786,
  "changeHistory": [
    "6e62a1a6728b1f782f64065424f92b292c3f163a"
  ],
  "changeHistoryShort": {
    "6e62a1a6728b1f782f64065424f92b292c3f163a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6e62a1a6728b1f782f64065424f92b292c3f163a": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7430. Refactor the BlockScanner to use O(1) memory and use multiple threads (cmccabe)\n",
      "commitDate": "21/01/15 7:00 PM",
      "commitName": "6e62a1a6728b1f782f64065424f92b292c3f163a",
      "commitAuthor": "Colin Patrick Mccabe",
      "diff": "@@ -0,0 +1,25 @@\n+  public synchronized void enableBlockPoolId(String bpid) {\n+    for (BlockIterator iter : blockIters) {\n+      if (iter.getBlockPoolId().equals(bpid)) {\n+        LOG.warn(\"{}: already enabled scanning on block pool {}\", this, bpid);\n+        return;\n+      }\n+    }\n+    BlockIterator iter \u003d null;\n+    try {\n+      // Load a block iterator for the next block pool on the volume.\n+      iter \u003d volume.loadBlockIterator(bpid, BLOCK_ITERATOR_NAME);\n+      LOG.trace(\"{}: loaded block iterator for {}.\", this, bpid);\n+    } catch (FileNotFoundException e) {\n+      LOG.debug(\"{}: failed to load block iterator: \" + e.getMessage(), this);\n+    } catch (IOException e) {\n+      LOG.warn(\"{}: failed to load block iterator.\", this, e);\n+    }\n+    if (iter \u003d\u003d null) {\n+      iter \u003d volume.newBlockIterator(bpid, BLOCK_ITERATOR_NAME);\n+      LOG.trace(\"{}: created new block iterator for {}.\", this, bpid);\n+    }\n+    iter.setMaxStalenessMs(conf.maxStalenessMs);\n+    blockIters.add(iter);\n+    notify();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void enableBlockPoolId(String bpid) {\n    for (BlockIterator iter : blockIters) {\n      if (iter.getBlockPoolId().equals(bpid)) {\n        LOG.warn(\"{}: already enabled scanning on block pool {}\", this, bpid);\n        return;\n      }\n    }\n    BlockIterator iter \u003d null;\n    try {\n      // Load a block iterator for the next block pool on the volume.\n      iter \u003d volume.loadBlockIterator(bpid, BLOCK_ITERATOR_NAME);\n      LOG.trace(\"{}: loaded block iterator for {}.\", this, bpid);\n    } catch (FileNotFoundException e) {\n      LOG.debug(\"{}: failed to load block iterator: \" + e.getMessage(), this);\n    } catch (IOException e) {\n      LOG.warn(\"{}: failed to load block iterator.\", this, e);\n    }\n    if (iter \u003d\u003d null) {\n      iter \u003d volume.newBlockIterator(bpid, BLOCK_ITERATOR_NAME);\n      LOG.trace(\"{}: created new block iterator for {}.\", this, bpid);\n    }\n    iter.setMaxStalenessMs(conf.maxStalenessMs);\n    blockIters.add(iter);\n    notify();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/VolumeScanner.java"
    }
  }
}