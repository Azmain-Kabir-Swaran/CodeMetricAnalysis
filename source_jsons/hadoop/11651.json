{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FsDatasetCache.java",
  "functionName": "getCachedBlocks",
  "functionId": "getCachedBlocks___bpid-String",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetCache.java",
  "functionStartLine": 255,
  "functionEndLine": 267,
  "numCommitsSeen": 31,
  "timeTaken": 1939,
  "changeHistory": [
    "f0d64a078da7e932b9509734f75170e3e525e68c",
    "97199baea1c41a66bd2a88bda31742ef6ddcb5dc",
    "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
    "40eb94ade3161d93e7a762a839004748f6d0ae89",
    "b992219fa13ccee2b417d91222fd0c3e8c3ffe11"
  ],
  "changeHistoryShort": {
    "f0d64a078da7e932b9509734f75170e3e525e68c": "Ybodychange",
    "97199baea1c41a66bd2a88bda31742ef6ddcb5dc": "Ymultichange(Ymodifierchange,Ybodychange)",
    "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48": "Ymultichange(Yreturntypechange,Ybodychange)",
    "40eb94ade3161d93e7a762a839004748f6d0ae89": "Ybodychange",
    "b992219fa13ccee2b417d91222fd0c3e8c3ffe11": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f0d64a078da7e932b9509734f75170e3e525e68c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5940.  Minor cleanups to ShortCircuitReplica, FsDatasetCache, and DomainSocketWatcher (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1567835 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/02/14 7:10 PM",
      "commitName": "f0d64a078da7e932b9509734f75170e3e525e68c",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "27/11/13 9:55 AM",
      "commitNameOld": "13edb391d06c479720202eb5ac81f1c71fe64748",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 77.39,
      "commitsBetweenForRepo": 431,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   synchronized List\u003cLong\u003e getCachedBlocks(String bpid) {\n     List\u003cLong\u003e blocks \u003d new ArrayList\u003cLong\u003e();\n-    for (Iterator\u003cEntry\u003cKey, Value\u003e\u003e iter \u003d\n+    for (Iterator\u003cEntry\u003cExtendedBlockId, Value\u003e\u003e iter \u003d\n         mappableBlockMap.entrySet().iterator(); iter.hasNext(); ) {\n-      Entry\u003cKey, Value\u003e entry \u003d iter.next();\n-      if (entry.getKey().bpid.equals(bpid)) {\n+      Entry\u003cExtendedBlockId, Value\u003e entry \u003d iter.next();\n+      if (entry.getKey().getBlockPoolId().equals(bpid)) {\n         if (entry.getValue().state.shouldAdvertise()) {\n-          blocks.add(entry.getKey().id);\n+          blocks.add(entry.getKey().getBlockId());\n         }\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized List\u003cLong\u003e getCachedBlocks(String bpid) {\n    List\u003cLong\u003e blocks \u003d new ArrayList\u003cLong\u003e();\n    for (Iterator\u003cEntry\u003cExtendedBlockId, Value\u003e\u003e iter \u003d\n        mappableBlockMap.entrySet().iterator(); iter.hasNext(); ) {\n      Entry\u003cExtendedBlockId, Value\u003e entry \u003d iter.next();\n      if (entry.getKey().getBlockPoolId().equals(bpid)) {\n        if (entry.getValue().state.shouldAdvertise()) {\n          blocks.add(entry.getKey().getBlockId());\n        }\n      }\n    }\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetCache.java",
      "extendedDetails": {}
    },
    "97199baea1c41a66bd2a88bda31742ef6ddcb5dc": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-5394: Fix race conditions in DN caching and uncaching (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1539909 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/11/13 7:00 PM",
      "commitName": "97199baea1c41a66bd2a88bda31742ef6ddcb5dc",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-5394: Fix race conditions in DN caching and uncaching (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1539909 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/11/13 7:00 PM",
          "commitName": "97199baea1c41a66bd2a88bda31742ef6ddcb5dc",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "21/10/13 12:29 PM",
          "commitNameOld": "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 17.31,
          "commitsBetweenForRepo": 77,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,13 @@\n-  List\u003cLong\u003e getCachedBlocks(String bpid) {\n+  synchronized List\u003cLong\u003e getCachedBlocks(String bpid) {\n     List\u003cLong\u003e blocks \u003d new ArrayList\u003cLong\u003e();\n-    // ConcurrentHashMap iteration doesn\u0027t see latest updates, which is okay\n-    Iterator\u003cMappableBlock\u003e it \u003d cachedBlocks.values().iterator();\n-    while (it.hasNext()) {\n-      MappableBlock mapBlock \u003d it.next();\n-      if (mapBlock.getBlockPoolId().equals(bpid)) {\n-        blocks.add(mapBlock.getBlock().getBlockId());\n+    for (Iterator\u003cEntry\u003cKey, Value\u003e\u003e iter \u003d\n+        mappableBlockMap.entrySet().iterator(); iter.hasNext(); ) {\n+      Entry\u003cKey, Value\u003e entry \u003d iter.next();\n+      if (entry.getKey().bpid.equals(bpid)) {\n+        if (entry.getValue().state.shouldAdvertise()) {\n+          blocks.add(entry.getKey().id);\n+        }\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized List\u003cLong\u003e getCachedBlocks(String bpid) {\n    List\u003cLong\u003e blocks \u003d new ArrayList\u003cLong\u003e();\n    for (Iterator\u003cEntry\u003cKey, Value\u003e\u003e iter \u003d\n        mappableBlockMap.entrySet().iterator(); iter.hasNext(); ) {\n      Entry\u003cKey, Value\u003e entry \u003d iter.next();\n      if (entry.getKey().bpid.equals(bpid)) {\n        if (entry.getValue().state.shouldAdvertise()) {\n          blocks.add(entry.getKey().id);\n        }\n      }\n    }\n    return blocks;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetCache.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[synchronized]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5394: Fix race conditions in DN caching and uncaching (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1539909 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/11/13 7:00 PM",
          "commitName": "97199baea1c41a66bd2a88bda31742ef6ddcb5dc",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "21/10/13 12:29 PM",
          "commitNameOld": "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 17.31,
          "commitsBetweenForRepo": 77,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,13 @@\n-  List\u003cLong\u003e getCachedBlocks(String bpid) {\n+  synchronized List\u003cLong\u003e getCachedBlocks(String bpid) {\n     List\u003cLong\u003e blocks \u003d new ArrayList\u003cLong\u003e();\n-    // ConcurrentHashMap iteration doesn\u0027t see latest updates, which is okay\n-    Iterator\u003cMappableBlock\u003e it \u003d cachedBlocks.values().iterator();\n-    while (it.hasNext()) {\n-      MappableBlock mapBlock \u003d it.next();\n-      if (mapBlock.getBlockPoolId().equals(bpid)) {\n-        blocks.add(mapBlock.getBlock().getBlockId());\n+    for (Iterator\u003cEntry\u003cKey, Value\u003e\u003e iter \u003d\n+        mappableBlockMap.entrySet().iterator(); iter.hasNext(); ) {\n+      Entry\u003cKey, Value\u003e entry \u003d iter.next();\n+      if (entry.getKey().bpid.equals(bpid)) {\n+        if (entry.getValue().state.shouldAdvertise()) {\n+          blocks.add(entry.getKey().id);\n+        }\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized List\u003cLong\u003e getCachedBlocks(String bpid) {\n    List\u003cLong\u003e blocks \u003d new ArrayList\u003cLong\u003e();\n    for (Iterator\u003cEntry\u003cKey, Value\u003e\u003e iter \u003d\n        mappableBlockMap.entrySet().iterator(); iter.hasNext(); ) {\n      Entry\u003cKey, Value\u003e entry \u003d iter.next();\n      if (entry.getKey().bpid.equals(bpid)) {\n        if (entry.getValue().state.shouldAdvertise()) {\n          blocks.add(entry.getKey().id);\n        }\n      }\n    }\n    return blocks;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetCache.java",
          "extendedDetails": {}
        }
      ]
    },
    "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-5378. In CacheReport, don\u0027t send genstamp and length on the wire (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1534334 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/10/13 12:29 PM",
      "commitName": "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-5378. In CacheReport, don\u0027t send genstamp and length on the wire (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1534334 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/10/13 12:29 PM",
          "commitName": "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "16/10/13 3:15 PM",
          "commitNameOld": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 4.88,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,12 @@\n-  List\u003cBlock\u003e getCachedBlocks(String bpid) {\n-    List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n+  List\u003cLong\u003e getCachedBlocks(String bpid) {\n+    List\u003cLong\u003e blocks \u003d new ArrayList\u003cLong\u003e();\n     // ConcurrentHashMap iteration doesn\u0027t see latest updates, which is okay\n     Iterator\u003cMappableBlock\u003e it \u003d cachedBlocks.values().iterator();\n     while (it.hasNext()) {\n       MappableBlock mapBlock \u003d it.next();\n       if (mapBlock.getBlockPoolId().equals(bpid)) {\n-        blocks.add(mapBlock.getBlock());\n+        blocks.add(mapBlock.getBlock().getBlockId());\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  List\u003cLong\u003e getCachedBlocks(String bpid) {\n    List\u003cLong\u003e blocks \u003d new ArrayList\u003cLong\u003e();\n    // ConcurrentHashMap iteration doesn\u0027t see latest updates, which is okay\n    Iterator\u003cMappableBlock\u003e it \u003d cachedBlocks.values().iterator();\n    while (it.hasNext()) {\n      MappableBlock mapBlock \u003d it.next();\n      if (mapBlock.getBlockPoolId().equals(bpid)) {\n        blocks.add(mapBlock.getBlock().getBlockId());\n      }\n    }\n    return blocks;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetCache.java",
          "extendedDetails": {
            "oldValue": "List\u003cBlock\u003e",
            "newValue": "List\u003cLong\u003e"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5378. In CacheReport, don\u0027t send genstamp and length on the wire (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1534334 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/10/13 12:29 PM",
          "commitName": "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "16/10/13 3:15 PM",
          "commitNameOld": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 4.88,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,12 +1,12 @@\n-  List\u003cBlock\u003e getCachedBlocks(String bpid) {\n-    List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n+  List\u003cLong\u003e getCachedBlocks(String bpid) {\n+    List\u003cLong\u003e blocks \u003d new ArrayList\u003cLong\u003e();\n     // ConcurrentHashMap iteration doesn\u0027t see latest updates, which is okay\n     Iterator\u003cMappableBlock\u003e it \u003d cachedBlocks.values().iterator();\n     while (it.hasNext()) {\n       MappableBlock mapBlock \u003d it.next();\n       if (mapBlock.getBlockPoolId().equals(bpid)) {\n-        blocks.add(mapBlock.getBlock());\n+        blocks.add(mapBlock.getBlock().getBlockId());\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  List\u003cLong\u003e getCachedBlocks(String bpid) {\n    List\u003cLong\u003e blocks \u003d new ArrayList\u003cLong\u003e();\n    // ConcurrentHashMap iteration doesn\u0027t see latest updates, which is okay\n    Iterator\u003cMappableBlock\u003e it \u003d cachedBlocks.values().iterator();\n    while (it.hasNext()) {\n      MappableBlock mapBlock \u003d it.next();\n      if (mapBlock.getBlockPoolId().equals(bpid)) {\n        blocks.add(mapBlock.getBlock().getBlockId());\n      }\n    }\n    return blocks;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetCache.java",
          "extendedDetails": {}
        }
      ]
    },
    "40eb94ade3161d93e7a762a839004748f6d0ae89": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5053. NameNode should invoke DataNode APIs to coordinate caching. (Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1523145 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/09/13 4:27 PM",
      "commitName": "40eb94ade3161d93e7a762a839004748f6d0ae89",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "23/08/13 8:41 PM",
      "commitNameOld": "b992219fa13ccee2b417d91222fd0c3e8c3ffe11",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 20.82,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   List\u003cBlock\u003e getCachedBlocks(String bpid) {\n     List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n-    MappableBlock mapBlock \u003d null;\n     // ConcurrentHashMap iteration doesn\u0027t see latest updates, which is okay\n-    for (Iterator\u003cMappableBlock\u003e it \u003d cachedBlocks.values().iterator();\n-        it.hasNext(); mapBlock \u003d it.next()) {\n+    Iterator\u003cMappableBlock\u003e it \u003d cachedBlocks.values().iterator();\n+    while (it.hasNext()) {\n+      MappableBlock mapBlock \u003d it.next();\n       if (mapBlock.getBlockPoolId().equals(bpid)) {\n         blocks.add(mapBlock.getBlock());\n       }\n     }\n     return blocks;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  List\u003cBlock\u003e getCachedBlocks(String bpid) {\n    List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n    // ConcurrentHashMap iteration doesn\u0027t see latest updates, which is okay\n    Iterator\u003cMappableBlock\u003e it \u003d cachedBlocks.values().iterator();\n    while (it.hasNext()) {\n      MappableBlock mapBlock \u003d it.next();\n      if (mapBlock.getBlockPoolId().equals(bpid)) {\n        blocks.add(mapBlock.getBlock());\n      }\n    }\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetCache.java",
      "extendedDetails": {}
    },
    "b992219fa13ccee2b417d91222fd0c3e8c3ffe11": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5050.  Add DataNode support for mlock and munlock  (contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1517106 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/08/13 8:41 PM",
      "commitName": "b992219fa13ccee2b417d91222fd0c3e8c3ffe11",
      "commitAuthor": "Colin McCabe",
      "diff": "@@ -0,0 +1,12 @@\n+  List\u003cBlock\u003e getCachedBlocks(String bpid) {\n+    List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n+    MappableBlock mapBlock \u003d null;\n+    // ConcurrentHashMap iteration doesn\u0027t see latest updates, which is okay\n+    for (Iterator\u003cMappableBlock\u003e it \u003d cachedBlocks.values().iterator();\n+        it.hasNext(); mapBlock \u003d it.next()) {\n+      if (mapBlock.getBlockPoolId().equals(bpid)) {\n+        blocks.add(mapBlock.getBlock());\n+      }\n+    }\n+    return blocks;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  List\u003cBlock\u003e getCachedBlocks(String bpid) {\n    List\u003cBlock\u003e blocks \u003d new ArrayList\u003cBlock\u003e();\n    MappableBlock mapBlock \u003d null;\n    // ConcurrentHashMap iteration doesn\u0027t see latest updates, which is okay\n    for (Iterator\u003cMappableBlock\u003e it \u003d cachedBlocks.values().iterator();\n        it.hasNext(); mapBlock \u003d it.next()) {\n      if (mapBlock.getBlockPoolId().equals(bpid)) {\n        blocks.add(mapBlock.getBlock());\n      }\n    }\n    return blocks;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetCache.java"
    }
  }
}