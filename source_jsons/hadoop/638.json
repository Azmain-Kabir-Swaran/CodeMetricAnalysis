{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockReaderLocalLegacy.java",
  "functionName": "read",
  "functionId": "read___buf-ByteBuffer",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java",
  "functionStartLine": 406,
  "functionEndLine": 479,
  "numCommitsSeen": 30,
  "timeTaken": 2157,
  "changeHistory": [
    "f308561f1d885491b88db73ac63003202056d661",
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
    "e2c9b288b223b9fd82dc12018936e13128413492",
    "694a6721316aea14c1244447974231abc8dff0cb"
  ],
  "changeHistoryShort": {
    "f308561f1d885491b88db73ac63003202056d661": "Yfilerename",
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": "Ybodychange",
    "e2c9b288b223b9fd82dc12018936e13128413492": "Yfilerename",
    "694a6721316aea14c1244447974231abc8dff0cb": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f308561f1d885491b88db73ac63003202056d661": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8057 Move BlockReader implementation to the client implementation package.  Contributed by Takanobu Asanuma\n",
      "commitDate": "25/04/16 12:01 PM",
      "commitName": "f308561f1d885491b88db73ac63003202056d661",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "25/04/16 9:38 AM",
      "commitNameOld": "10f0f7851a3255caab775777e8fb6c2781d97062",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public synchronized int read(ByteBuffer buf) throws IOException {\n    int nRead \u003d 0;\n    if (verifyChecksum) {\n      // A \u0027direct\u0027 read actually has three phases. The first drains any\n      // remaining bytes from the slow read buffer. After this the read is\n      // guaranteed to be on a checksum chunk boundary. If there are still bytes\n      // to read, the fast direct path is used for as many remaining bytes as\n      // possible, up to a multiple of the checksum chunk size. Finally, any\n      // \u0027odd\u0027 bytes remaining at the end of the read cause another slow read to\n      // be issued, which involves an extra copy.\n\n      // Every \u0027slow\u0027 read tries to fill the slow read buffer in one go for\n      // efficiency\u0027s sake. As described above, all non-checksum-chunk-aligned\n      // reads will be served from the slower read path.\n\n      if (slowReadBuff.hasRemaining()) {\n        // There are remaining bytes from a small read available. This usually\n        // means this read is unaligned, which falls back to the slow path.\n        int fromSlowReadBuff \u003d Math.min(buf.remaining(),\n            slowReadBuff.remaining());\n        writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n        nRead +\u003d fromSlowReadBuff;\n      }\n\n      if (buf.remaining() \u003e\u003d bytesPerChecksum \u0026\u0026 offsetFromChunkBoundary \u003d\u003d 0) {\n        // Since we have drained the \u0027small read\u0027 buffer, we are guaranteed to\n        // be chunk-aligned\n        int len \u003d buf.remaining() - (buf.remaining() % bytesPerChecksum);\n\n        // There\u0027s only enough checksum buffer space available to checksum one\n        // entire slow read buffer. This saves keeping the number of checksum\n        // chunks around.\n        len \u003d Math.min(len, slowReadBuff.capacity());\n        int oldlimit \u003d buf.limit();\n        buf.limit(buf.position() + len);\n        int readResult \u003d 0;\n        try {\n          readResult \u003d doByteBufferRead(buf);\n        } finally {\n          buf.limit(oldlimit);\n        }\n        if (readResult \u003d\u003d -1) {\n          return nRead;\n        } else {\n          nRead +\u003d readResult;\n          buf.position(buf.position() + readResult);\n        }\n      }\n\n      // offsetFromChunkBoundary \u003e 0 \u003d\u003e unaligned read, use slow path to read\n      // until chunk boundary\n      if ((buf.remaining() \u003e 0 \u0026\u0026 buf.remaining() \u003c bytesPerChecksum) ||\n          offsetFromChunkBoundary \u003e 0) {\n        int toRead \u003d Math.min(buf.remaining(),\n            bytesPerChecksum - offsetFromChunkBoundary);\n        int readResult \u003d fillSlowReadBuffer(toRead);\n        if (readResult \u003d\u003d -1) {\n          return nRead;\n        } else {\n          int fromSlowReadBuff \u003d Math.min(readResult, buf.remaining());\n          writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n          nRead +\u003d fromSlowReadBuff;\n        }\n      }\n    } else {\n      // Non-checksummed reads are much easier; we can just fill the buffer\n      // directly.\n      nRead \u003d doByteBufferRead(buf);\n      if (nRead \u003e 0) {\n        buf.position(buf.position() + nRead);\n      }\n    }\n    return nRead;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java"
      }
    },
    "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8979. Clean up checkstyle warnings in hadoop-hdfs-client module. Contributed by Mingliang Liu.\n",
      "commitDate": "03/10/15 11:38 AM",
      "commitName": "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "30/09/15 8:39 AM",
      "commitNameOld": "6c17d315287020368689fa078a40a1eaedf89d5b",
      "commitAuthorOld": "",
      "daysBetweenCommits": 3.12,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,74 @@\n   public synchronized int read(ByteBuffer buf) throws IOException {\n     int nRead \u003d 0;\n     if (verifyChecksum) {\n       // A \u0027direct\u0027 read actually has three phases. The first drains any\n       // remaining bytes from the slow read buffer. After this the read is\n       // guaranteed to be on a checksum chunk boundary. If there are still bytes\n       // to read, the fast direct path is used for as many remaining bytes as\n       // possible, up to a multiple of the checksum chunk size. Finally, any\n       // \u0027odd\u0027 bytes remaining at the end of the read cause another slow read to\n       // be issued, which involves an extra copy.\n \n       // Every \u0027slow\u0027 read tries to fill the slow read buffer in one go for\n       // efficiency\u0027s sake. As described above, all non-checksum-chunk-aligned\n       // reads will be served from the slower read path.\n \n       if (slowReadBuff.hasRemaining()) {\n         // There are remaining bytes from a small read available. This usually\n         // means this read is unaligned, which falls back to the slow path.\n-        int fromSlowReadBuff \u003d Math.min(buf.remaining(), slowReadBuff.remaining());\n+        int fromSlowReadBuff \u003d Math.min(buf.remaining(),\n+            slowReadBuff.remaining());\n         writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n         nRead +\u003d fromSlowReadBuff;\n       }\n \n       if (buf.remaining() \u003e\u003d bytesPerChecksum \u0026\u0026 offsetFromChunkBoundary \u003d\u003d 0) {\n         // Since we have drained the \u0027small read\u0027 buffer, we are guaranteed to\n         // be chunk-aligned\n         int len \u003d buf.remaining() - (buf.remaining() % bytesPerChecksum);\n \n         // There\u0027s only enough checksum buffer space available to checksum one\n         // entire slow read buffer. This saves keeping the number of checksum\n         // chunks around.\n         len \u003d Math.min(len, slowReadBuff.capacity());\n         int oldlimit \u003d buf.limit();\n         buf.limit(buf.position() + len);\n         int readResult \u003d 0;\n         try {\n           readResult \u003d doByteBufferRead(buf);\n         } finally {\n           buf.limit(oldlimit);\n         }\n         if (readResult \u003d\u003d -1) {\n           return nRead;\n         } else {\n           nRead +\u003d readResult;\n           buf.position(buf.position() + readResult);\n         }\n       }\n \n       // offsetFromChunkBoundary \u003e 0 \u003d\u003e unaligned read, use slow path to read\n       // until chunk boundary\n-      if ((buf.remaining() \u003e 0 \u0026\u0026 buf.remaining() \u003c bytesPerChecksum) || offsetFromChunkBoundary \u003e 0) {\n-        int toRead \u003d Math.min(buf.remaining(), bytesPerChecksum - offsetFromChunkBoundary);\n+      if ((buf.remaining() \u003e 0 \u0026\u0026 buf.remaining() \u003c bytesPerChecksum) ||\n+          offsetFromChunkBoundary \u003e 0) {\n+        int toRead \u003d Math.min(buf.remaining(),\n+            bytesPerChecksum - offsetFromChunkBoundary);\n         int readResult \u003d fillSlowReadBuffer(toRead);\n         if (readResult \u003d\u003d -1) {\n           return nRead;\n         } else {\n           int fromSlowReadBuff \u003d Math.min(readResult, buf.remaining());\n           writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n           nRead +\u003d fromSlowReadBuff;\n         }\n       }\n     } else {\n-      // Non-checksummed reads are much easier; we can just fill the buffer directly.\n+      // Non-checksummed reads are much easier; we can just fill the buffer\n+      // directly.\n       nRead \u003d doByteBufferRead(buf);\n       if (nRead \u003e 0) {\n         buf.position(buf.position() + nRead);\n       }\n     }\n     return nRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read(ByteBuffer buf) throws IOException {\n    int nRead \u003d 0;\n    if (verifyChecksum) {\n      // A \u0027direct\u0027 read actually has three phases. The first drains any\n      // remaining bytes from the slow read buffer. After this the read is\n      // guaranteed to be on a checksum chunk boundary. If there are still bytes\n      // to read, the fast direct path is used for as many remaining bytes as\n      // possible, up to a multiple of the checksum chunk size. Finally, any\n      // \u0027odd\u0027 bytes remaining at the end of the read cause another slow read to\n      // be issued, which involves an extra copy.\n\n      // Every \u0027slow\u0027 read tries to fill the slow read buffer in one go for\n      // efficiency\u0027s sake. As described above, all non-checksum-chunk-aligned\n      // reads will be served from the slower read path.\n\n      if (slowReadBuff.hasRemaining()) {\n        // There are remaining bytes from a small read available. This usually\n        // means this read is unaligned, which falls back to the slow path.\n        int fromSlowReadBuff \u003d Math.min(buf.remaining(),\n            slowReadBuff.remaining());\n        writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n        nRead +\u003d fromSlowReadBuff;\n      }\n\n      if (buf.remaining() \u003e\u003d bytesPerChecksum \u0026\u0026 offsetFromChunkBoundary \u003d\u003d 0) {\n        // Since we have drained the \u0027small read\u0027 buffer, we are guaranteed to\n        // be chunk-aligned\n        int len \u003d buf.remaining() - (buf.remaining() % bytesPerChecksum);\n\n        // There\u0027s only enough checksum buffer space available to checksum one\n        // entire slow read buffer. This saves keeping the number of checksum\n        // chunks around.\n        len \u003d Math.min(len, slowReadBuff.capacity());\n        int oldlimit \u003d buf.limit();\n        buf.limit(buf.position() + len);\n        int readResult \u003d 0;\n        try {\n          readResult \u003d doByteBufferRead(buf);\n        } finally {\n          buf.limit(oldlimit);\n        }\n        if (readResult \u003d\u003d -1) {\n          return nRead;\n        } else {\n          nRead +\u003d readResult;\n          buf.position(buf.position() + readResult);\n        }\n      }\n\n      // offsetFromChunkBoundary \u003e 0 \u003d\u003e unaligned read, use slow path to read\n      // until chunk boundary\n      if ((buf.remaining() \u003e 0 \u0026\u0026 buf.remaining() \u003c bytesPerChecksum) ||\n          offsetFromChunkBoundary \u003e 0) {\n        int toRead \u003d Math.min(buf.remaining(),\n            bytesPerChecksum - offsetFromChunkBoundary);\n        int readResult \u003d fillSlowReadBuffer(toRead);\n        if (readResult \u003d\u003d -1) {\n          return nRead;\n        } else {\n          int fromSlowReadBuff \u003d Math.min(readResult, buf.remaining());\n          writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n          nRead +\u003d fromSlowReadBuff;\n        }\n      }\n    } else {\n      // Non-checksummed reads are much easier; we can just fill the buffer\n      // directly.\n      nRead \u003d doByteBufferRead(buf);\n      if (nRead \u003e 0) {\n        buf.position(buf.position() + nRead);\n      }\n    }\n    return nRead;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
      "extendedDetails": {}
    },
    "e2c9b288b223b9fd82dc12018936e13128413492": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8925. Move BlockReaderLocal to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "28/08/15 2:38 PM",
      "commitName": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/08/15 2:21 PM",
      "commitNameOld": "b94b56806d3d6e04984e229b479f7ac15b62bbfa",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public synchronized int read(ByteBuffer buf) throws IOException {\n    int nRead \u003d 0;\n    if (verifyChecksum) {\n      // A \u0027direct\u0027 read actually has three phases. The first drains any\n      // remaining bytes from the slow read buffer. After this the read is\n      // guaranteed to be on a checksum chunk boundary. If there are still bytes\n      // to read, the fast direct path is used for as many remaining bytes as\n      // possible, up to a multiple of the checksum chunk size. Finally, any\n      // \u0027odd\u0027 bytes remaining at the end of the read cause another slow read to\n      // be issued, which involves an extra copy.\n\n      // Every \u0027slow\u0027 read tries to fill the slow read buffer in one go for\n      // efficiency\u0027s sake. As described above, all non-checksum-chunk-aligned\n      // reads will be served from the slower read path.\n\n      if (slowReadBuff.hasRemaining()) {\n        // There are remaining bytes from a small read available. This usually\n        // means this read is unaligned, which falls back to the slow path.\n        int fromSlowReadBuff \u003d Math.min(buf.remaining(), slowReadBuff.remaining());\n        writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n        nRead +\u003d fromSlowReadBuff;\n      }\n\n      if (buf.remaining() \u003e\u003d bytesPerChecksum \u0026\u0026 offsetFromChunkBoundary \u003d\u003d 0) {\n        // Since we have drained the \u0027small read\u0027 buffer, we are guaranteed to\n        // be chunk-aligned\n        int len \u003d buf.remaining() - (buf.remaining() % bytesPerChecksum);\n\n        // There\u0027s only enough checksum buffer space available to checksum one\n        // entire slow read buffer. This saves keeping the number of checksum\n        // chunks around.\n        len \u003d Math.min(len, slowReadBuff.capacity());\n        int oldlimit \u003d buf.limit();\n        buf.limit(buf.position() + len);\n        int readResult \u003d 0;\n        try {\n          readResult \u003d doByteBufferRead(buf);\n        } finally {\n          buf.limit(oldlimit);\n        }\n        if (readResult \u003d\u003d -1) {\n          return nRead;\n        } else {\n          nRead +\u003d readResult;\n          buf.position(buf.position() + readResult);\n        }\n      }\n\n      // offsetFromChunkBoundary \u003e 0 \u003d\u003e unaligned read, use slow path to read\n      // until chunk boundary\n      if ((buf.remaining() \u003e 0 \u0026\u0026 buf.remaining() \u003c bytesPerChecksum) || offsetFromChunkBoundary \u003e 0) {\n        int toRead \u003d Math.min(buf.remaining(), bytesPerChecksum - offsetFromChunkBoundary);\n        int readResult \u003d fillSlowReadBuffer(toRead);\n        if (readResult \u003d\u003d -1) {\n          return nRead;\n        } else {\n          int fromSlowReadBuff \u003d Math.min(readResult, buf.remaining());\n          writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n          nRead +\u003d fromSlowReadBuff;\n        }\n      }\n    } else {\n      // Non-checksummed reads are much easier; we can just fill the buffer directly.\n      nRead \u003d doByteBufferRead(buf);\n      if (nRead \u003e 0) {\n        buf.position(buf.position() + nRead);\n      }\n    }\n    return nRead;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java"
      }
    },
    "694a6721316aea14c1244447974231abc8dff0cb": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4538. Allow use of legacy blockreader. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1461818 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/03/13 12:28 PM",
      "commitName": "694a6721316aea14c1244447974231abc8dff0cb",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,70 @@\n+  public synchronized int read(ByteBuffer buf) throws IOException {\n+    int nRead \u003d 0;\n+    if (verifyChecksum) {\n+      // A \u0027direct\u0027 read actually has three phases. The first drains any\n+      // remaining bytes from the slow read buffer. After this the read is\n+      // guaranteed to be on a checksum chunk boundary. If there are still bytes\n+      // to read, the fast direct path is used for as many remaining bytes as\n+      // possible, up to a multiple of the checksum chunk size. Finally, any\n+      // \u0027odd\u0027 bytes remaining at the end of the read cause another slow read to\n+      // be issued, which involves an extra copy.\n+\n+      // Every \u0027slow\u0027 read tries to fill the slow read buffer in one go for\n+      // efficiency\u0027s sake. As described above, all non-checksum-chunk-aligned\n+      // reads will be served from the slower read path.\n+\n+      if (slowReadBuff.hasRemaining()) {\n+        // There are remaining bytes from a small read available. This usually\n+        // means this read is unaligned, which falls back to the slow path.\n+        int fromSlowReadBuff \u003d Math.min(buf.remaining(), slowReadBuff.remaining());\n+        writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n+        nRead +\u003d fromSlowReadBuff;\n+      }\n+\n+      if (buf.remaining() \u003e\u003d bytesPerChecksum \u0026\u0026 offsetFromChunkBoundary \u003d\u003d 0) {\n+        // Since we have drained the \u0027small read\u0027 buffer, we are guaranteed to\n+        // be chunk-aligned\n+        int len \u003d buf.remaining() - (buf.remaining() % bytesPerChecksum);\n+\n+        // There\u0027s only enough checksum buffer space available to checksum one\n+        // entire slow read buffer. This saves keeping the number of checksum\n+        // chunks around.\n+        len \u003d Math.min(len, slowReadBuff.capacity());\n+        int oldlimit \u003d buf.limit();\n+        buf.limit(buf.position() + len);\n+        int readResult \u003d 0;\n+        try {\n+          readResult \u003d doByteBufferRead(buf);\n+        } finally {\n+          buf.limit(oldlimit);\n+        }\n+        if (readResult \u003d\u003d -1) {\n+          return nRead;\n+        } else {\n+          nRead +\u003d readResult;\n+          buf.position(buf.position() + readResult);\n+        }\n+      }\n+\n+      // offsetFromChunkBoundary \u003e 0 \u003d\u003e unaligned read, use slow path to read\n+      // until chunk boundary\n+      if ((buf.remaining() \u003e 0 \u0026\u0026 buf.remaining() \u003c bytesPerChecksum) || offsetFromChunkBoundary \u003e 0) {\n+        int toRead \u003d Math.min(buf.remaining(), bytesPerChecksum - offsetFromChunkBoundary);\n+        int readResult \u003d fillSlowReadBuffer(toRead);\n+        if (readResult \u003d\u003d -1) {\n+          return nRead;\n+        } else {\n+          int fromSlowReadBuff \u003d Math.min(readResult, buf.remaining());\n+          writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n+          nRead +\u003d fromSlowReadBuff;\n+        }\n+      }\n+    } else {\n+      // Non-checksummed reads are much easier; we can just fill the buffer directly.\n+      nRead \u003d doByteBufferRead(buf);\n+      if (nRead \u003e 0) {\n+        buf.position(buf.position() + nRead);\n+      }\n+    }\n+    return nRead;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read(ByteBuffer buf) throws IOException {\n    int nRead \u003d 0;\n    if (verifyChecksum) {\n      // A \u0027direct\u0027 read actually has three phases. The first drains any\n      // remaining bytes from the slow read buffer. After this the read is\n      // guaranteed to be on a checksum chunk boundary. If there are still bytes\n      // to read, the fast direct path is used for as many remaining bytes as\n      // possible, up to a multiple of the checksum chunk size. Finally, any\n      // \u0027odd\u0027 bytes remaining at the end of the read cause another slow read to\n      // be issued, which involves an extra copy.\n\n      // Every \u0027slow\u0027 read tries to fill the slow read buffer in one go for\n      // efficiency\u0027s sake. As described above, all non-checksum-chunk-aligned\n      // reads will be served from the slower read path.\n\n      if (slowReadBuff.hasRemaining()) {\n        // There are remaining bytes from a small read available. This usually\n        // means this read is unaligned, which falls back to the slow path.\n        int fromSlowReadBuff \u003d Math.min(buf.remaining(), slowReadBuff.remaining());\n        writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n        nRead +\u003d fromSlowReadBuff;\n      }\n\n      if (buf.remaining() \u003e\u003d bytesPerChecksum \u0026\u0026 offsetFromChunkBoundary \u003d\u003d 0) {\n        // Since we have drained the \u0027small read\u0027 buffer, we are guaranteed to\n        // be chunk-aligned\n        int len \u003d buf.remaining() - (buf.remaining() % bytesPerChecksum);\n\n        // There\u0027s only enough checksum buffer space available to checksum one\n        // entire slow read buffer. This saves keeping the number of checksum\n        // chunks around.\n        len \u003d Math.min(len, slowReadBuff.capacity());\n        int oldlimit \u003d buf.limit();\n        buf.limit(buf.position() + len);\n        int readResult \u003d 0;\n        try {\n          readResult \u003d doByteBufferRead(buf);\n        } finally {\n          buf.limit(oldlimit);\n        }\n        if (readResult \u003d\u003d -1) {\n          return nRead;\n        } else {\n          nRead +\u003d readResult;\n          buf.position(buf.position() + readResult);\n        }\n      }\n\n      // offsetFromChunkBoundary \u003e 0 \u003d\u003e unaligned read, use slow path to read\n      // until chunk boundary\n      if ((buf.remaining() \u003e 0 \u0026\u0026 buf.remaining() \u003c bytesPerChecksum) || offsetFromChunkBoundary \u003e 0) {\n        int toRead \u003d Math.min(buf.remaining(), bytesPerChecksum - offsetFromChunkBoundary);\n        int readResult \u003d fillSlowReadBuffer(toRead);\n        if (readResult \u003d\u003d -1) {\n          return nRead;\n        } else {\n          int fromSlowReadBuff \u003d Math.min(readResult, buf.remaining());\n          writeSlice(slowReadBuff, buf, fromSlowReadBuff);\n          nRead +\u003d fromSlowReadBuff;\n        }\n      }\n    } else {\n      // Non-checksummed reads are much easier; we can just fill the buffer directly.\n      nRead \u003d doByteBufferRead(buf);\n      if (nRead \u003e 0) {\n        buf.position(buf.position() + nRead);\n      }\n    }\n    return nRead;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocalLegacy.java"
    }
  }
}