{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "TimelineUIDConverter.java",
  "functionName": "encodeUID",
  "functionId": "encodeUID___context-TimelineReaderContext",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/reader/TimelineUIDConverter.java",
  "functionStartLine": 30,
  "functionEndLine": 41,
  "numCommitsSeen": 5,
  "timeTaken": 885,
  "changeHistory": [
    "02a9710a099fc9572122d87dd3e90c78522f5836",
    "9d40d9d34ce3b88e868ae91fcc09377107c094c7"
  ],
  "changeHistoryShort": {
    "02a9710a099fc9572122d87dd3e90c78522f5836": "Ybodychange",
    "9d40d9d34ce3b88e868ae91fcc09377107c094c7": "Yintroduced"
  },
  "changeHistoryDetails": {
    "02a9710a099fc9572122d87dd3e90c78522f5836": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5585. [Atsv2] Reader side changes for entity prefix and support for pagination via additional filters (Rohith Sharma K S via Varun Saxena)\n",
      "commitDate": "29/08/17 10:59 PM",
      "commitName": "02a9710a099fc9572122d87dd3e90c78522f5836",
      "commitAuthor": "Varun Saxena",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "960af7d4717b8a8949d0b2e43949e7daab45aa88",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 415.59,
      "commitsBetweenForRepo": 2589,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,24 @@\n     String encodeUID(TimelineReaderContext context) {\n       if (context \u003d\u003d null) {\n         return null;\n       }\n       if (context.getClusterId() \u003d\u003d null || context.getAppId() \u003d\u003d null ||\n           context.getEntityType() \u003d\u003d null || context.getEntityId() \u003d\u003d null) {\n         return null;\n       }\n       if (context.getUserId() !\u003d null \u0026\u0026 context.getFlowName() !\u003d null \u0026\u0026\n           context.getFlowRunId() !\u003d null) {\n         // Flow information exists.\n         String[] entityTupleArr \u003d {context.getClusterId(), context.getUserId(),\n             context.getFlowName(), context.getFlowRunId().toString(),\n-            context.getAppId(), context.getEntityType(), context.getEntityId()};\n+            context.getAppId(), context.getEntityType(),\n+            context.getEntityIdPrefix().toString(), context.getEntityId() };\n         return joinAndEscapeUIDParts(entityTupleArr);\n       } else {\n         // Only entity and app information exists. Flow info does not exist.\n         String[] entityTupleArr \u003d {context.getClusterId(), context.getAppId(),\n-            context.getEntityType(), context.getEntityId()};\n+            context.getEntityType(), context.getEntityIdPrefix().toString(),\n+            context.getEntityId() };\n         return joinAndEscapeUIDParts(entityTupleArr);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    String encodeUID(TimelineReaderContext context) {\n      if (context \u003d\u003d null) {\n        return null;\n      }\n      if (context.getClusterId() \u003d\u003d null || context.getAppId() \u003d\u003d null ||\n          context.getEntityType() \u003d\u003d null || context.getEntityId() \u003d\u003d null) {\n        return null;\n      }\n      if (context.getUserId() !\u003d null \u0026\u0026 context.getFlowName() !\u003d null \u0026\u0026\n          context.getFlowRunId() !\u003d null) {\n        // Flow information exists.\n        String[] entityTupleArr \u003d {context.getClusterId(), context.getUserId(),\n            context.getFlowName(), context.getFlowRunId().toString(),\n            context.getAppId(), context.getEntityType(),\n            context.getEntityIdPrefix().toString(), context.getEntityId() };\n        return joinAndEscapeUIDParts(entityTupleArr);\n      } else {\n        // Only entity and app information exists. Flow info does not exist.\n        String[] entityTupleArr \u003d {context.getClusterId(), context.getAppId(),\n            context.getEntityType(), context.getEntityIdPrefix().toString(),\n            context.getEntityId() };\n        return joinAndEscapeUIDParts(entityTupleArr);\n      }\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/reader/TimelineUIDConverter.java",
      "extendedDetails": {}
    },
    "9d40d9d34ce3b88e868ae91fcc09377107c094c7": {
      "type": "Yintroduced",
      "commitMessage": "YARN-4224. Support fetching entities by UID and change the REST\ninterface to conform to current REST APIs\u0027 in YARN. (Varun Saxena via\ngtcarrera9)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "9d40d9d34ce3b88e868ae91fcc09377107c094c7",
      "commitAuthor": "Li Lu",
      "diff": "@@ -0,0 +1,22 @@\n+    String encodeUID(TimelineReaderContext context) {\n+      if (context \u003d\u003d null) {\n+        return null;\n+      }\n+      if (context.getClusterId() \u003d\u003d null || context.getAppId() \u003d\u003d null ||\n+          context.getEntityType() \u003d\u003d null || context.getEntityId() \u003d\u003d null) {\n+        return null;\n+      }\n+      if (context.getUserId() !\u003d null \u0026\u0026 context.getFlowName() !\u003d null \u0026\u0026\n+          context.getFlowRunId() !\u003d null) {\n+        // Flow information exists.\n+        String[] entityTupleArr \u003d {context.getClusterId(), context.getUserId(),\n+            context.getFlowName(), context.getFlowRunId().toString(),\n+            context.getAppId(), context.getEntityType(), context.getEntityId()};\n+        return joinAndEscapeUIDParts(entityTupleArr);\n+      } else {\n+        // Only entity and app information exists. Flow info does not exist.\n+        String[] entityTupleArr \u003d {context.getClusterId(), context.getAppId(),\n+            context.getEntityType(), context.getEntityId()};\n+        return joinAndEscapeUIDParts(entityTupleArr);\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    String encodeUID(TimelineReaderContext context) {\n      if (context \u003d\u003d null) {\n        return null;\n      }\n      if (context.getClusterId() \u003d\u003d null || context.getAppId() \u003d\u003d null ||\n          context.getEntityType() \u003d\u003d null || context.getEntityId() \u003d\u003d null) {\n        return null;\n      }\n      if (context.getUserId() !\u003d null \u0026\u0026 context.getFlowName() !\u003d null \u0026\u0026\n          context.getFlowRunId() !\u003d null) {\n        // Flow information exists.\n        String[] entityTupleArr \u003d {context.getClusterId(), context.getUserId(),\n            context.getFlowName(), context.getFlowRunId().toString(),\n            context.getAppId(), context.getEntityType(), context.getEntityId()};\n        return joinAndEscapeUIDParts(entityTupleArr);\n      } else {\n        // Only entity and app information exists. Flow info does not exist.\n        String[] entityTupleArr \u003d {context.getClusterId(), context.getAppId(),\n            context.getEntityType(), context.getEntityId()};\n        return joinAndEscapeUIDParts(entityTupleArr);\n      }\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/reader/TimelineUIDConverter.java"
    }
  }
}