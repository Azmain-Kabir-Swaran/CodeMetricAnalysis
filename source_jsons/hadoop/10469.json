{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataStorage.java",
  "functionName": "getTrashDirectoryForReplica",
  "functionId": "getTrashDirectoryForReplica___bpid-String__info-ReplicaInfo",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java",
  "functionStartLine": 209,
  "functionEndLine": 214,
  "numCommitsSeen": 129,
  "timeTaken": 3637,
  "changeHistory": [
    "86c9862bec0248d671e657aa56094a2919b8ac14",
    "3a61d25457606b93f7e99a48fe8f66984f4084b0",
    "5df82fa01d26c18685ad7617128dbc2913547cb3"
  ],
  "changeHistoryShort": {
    "86c9862bec0248d671e657aa56094a2919b8ac14": "Ymultichange(Yrename,Yparameterchange,Ybodychange)",
    "3a61d25457606b93f7e99a48fe8f66984f4084b0": "Ybodychange",
    "5df82fa01d26c18685ad7617128dbc2913547cb3": "Yintroduced"
  },
  "changeHistoryDetails": {
    "86c9862bec0248d671e657aa56094a2919b8ac14": {
      "type": "Ymultichange(Yrename,Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "13/09/16 12:54 PM",
      "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthor": "Lei Xu",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
          "commitDate": "13/09/16 12:54 PM",
          "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "18/05/16 9:38 AM",
          "commitNameOld": "cf552aa87b4c47f0c73f51f44f3bc1d267c524cf",
          "commitAuthorOld": "Lei Xu",
          "daysBetweenCommits": 118.14,
          "commitsBetweenForRepo": 897,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,6 @@\n-  public String getTrashDirectoryForBlockFile(String bpid, File blockFile) {\n+  public String getTrashDirectoryForReplica(String bpid, ReplicaInfo info) {\n     if (trashEnabledBpids.contains(bpid)) {\n-      return getBPStorage(bpid).getTrashDirectory(blockFile);\n+      return getBPStorage(bpid).getTrashDirectory(info);\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public String getTrashDirectoryForReplica(String bpid, ReplicaInfo info) {\n    if (trashEnabledBpids.contains(bpid)) {\n      return getBPStorage(bpid).getTrashDirectory(info);\n    }\n    return null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java",
          "extendedDetails": {
            "oldValue": "getTrashDirectoryForBlockFile",
            "newValue": "getTrashDirectoryForReplica"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
          "commitDate": "13/09/16 12:54 PM",
          "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "18/05/16 9:38 AM",
          "commitNameOld": "cf552aa87b4c47f0c73f51f44f3bc1d267c524cf",
          "commitAuthorOld": "Lei Xu",
          "daysBetweenCommits": 118.14,
          "commitsBetweenForRepo": 897,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,6 @@\n-  public String getTrashDirectoryForBlockFile(String bpid, File blockFile) {\n+  public String getTrashDirectoryForReplica(String bpid, ReplicaInfo info) {\n     if (trashEnabledBpids.contains(bpid)) {\n-      return getBPStorage(bpid).getTrashDirectory(blockFile);\n+      return getBPStorage(bpid).getTrashDirectory(info);\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public String getTrashDirectoryForReplica(String bpid, ReplicaInfo info) {\n    if (trashEnabledBpids.contains(bpid)) {\n      return getBPStorage(bpid).getTrashDirectory(info);\n    }\n    return null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java",
          "extendedDetails": {
            "oldValue": "[bpid-String, blockFile-File]",
            "newValue": "[bpid-String, info-ReplicaInfo]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
          "commitDate": "13/09/16 12:54 PM",
          "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "18/05/16 9:38 AM",
          "commitNameOld": "cf552aa87b4c47f0c73f51f44f3bc1d267c524cf",
          "commitAuthorOld": "Lei Xu",
          "daysBetweenCommits": 118.14,
          "commitsBetweenForRepo": 897,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,6 @@\n-  public String getTrashDirectoryForBlockFile(String bpid, File blockFile) {\n+  public String getTrashDirectoryForReplica(String bpid, ReplicaInfo info) {\n     if (trashEnabledBpids.contains(bpid)) {\n-      return getBPStorage(bpid).getTrashDirectory(blockFile);\n+      return getBPStorage(bpid).getTrashDirectory(info);\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public String getTrashDirectoryForReplica(String bpid, ReplicaInfo info) {\n    if (trashEnabledBpids.contains(bpid)) {\n      return getBPStorage(bpid).getTrashDirectory(info);\n    }\n    return null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java",
          "extendedDetails": {}
        }
      ]
    },
    "3a61d25457606b93f7e99a48fe8f66984f4084b0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6125. Cleanup unnecessary cast in HDFS code base. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1581242 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/03/14 10:51 PM",
      "commitName": "3a61d25457606b93f7e99a48fe8f66984f4084b0",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "24/03/14 4:32 PM",
      "commitNameOld": "c2ef7e239eb0e81cf8a3e971378e9e696202de67",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.26,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,6 @@\n   public String getTrashDirectoryForBlockFile(String bpid, File blockFile) {\n     if (trashEnabledBpids.contains(bpid)) {\n-      return ((BlockPoolSliceStorage) getBPStorage(bpid)).getTrashDirectory(blockFile);\n+      return getBPStorage(bpid).getTrashDirectory(blockFile);\n     }\n     return null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String getTrashDirectoryForBlockFile(String bpid, File blockFile) {\n    if (trashEnabledBpids.contains(bpid)) {\n      return getBPStorage(bpid).getTrashDirectory(blockFile);\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java",
      "extendedDetails": {}
    },
    "5df82fa01d26c18685ad7617128dbc2913547cb3": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5907. BlockPoolSliceStorage trash to handle block deletions during rolling upgrade. (Arpit Agarwal)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1568346 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/02/14 8:37 AM",
      "commitName": "5df82fa01d26c18685ad7617128dbc2913547cb3",
      "commitAuthor": "Arpit Agarwal",
      "diff": "@@ -0,0 +1,6 @@\n+  public String getTrashDirectoryForBlockFile(String bpid, File blockFile) {\n+    if (trashEnabledBpids.contains(bpid)) {\n+      return ((BlockPoolSliceStorage) getBPStorage(bpid)).getTrashDirectory(blockFile);\n+    }\n+    return null;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public String getTrashDirectoryForBlockFile(String bpid, File blockFile) {\n    if (trashEnabledBpids.contains(bpid)) {\n      return ((BlockPoolSliceStorage) getBPStorage(bpid)).getTrashDirectory(blockFile);\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java"
    }
  }
}