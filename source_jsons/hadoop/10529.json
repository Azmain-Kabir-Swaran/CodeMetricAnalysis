{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BPServiceActor.java",
  "functionName": "generateUniqueBlockReportId",
  "functionId": "generateUniqueBlockReportId",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java",
  "functionStartLine": 348,
  "functionEndLine": 357,
  "numCommitsSeen": 125,
  "timeTaken": 3165,
  "changeHistory": [
    "470c87dbc6c24dd3b370f1ad9e7ab1f6dabd2080",
    "b1e059089d6a5b2b7006d7d384c6df81ed268bd9",
    "50ee8f4e67a66aa77c5359182f61f3e951844db6"
  ],
  "changeHistoryShort": {
    "470c87dbc6c24dd3b370f1ad9e7ab1f6dabd2080": "Ybodychange",
    "b1e059089d6a5b2b7006d7d384c6df81ed268bd9": "Ybodychange",
    "50ee8f4e67a66aa77c5359182f61f3e951844db6": "Yintroduced"
  },
  "changeHistoryDetails": {
    "470c87dbc6c24dd3b370f1ad9e7ab1f6dabd2080": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11970. Replace uses of ThreadLocal\u003cRandom\u003e with JDK7 ThreadLocalRandom (Sean Busbey via Colin P. McCabe)\n",
      "commitDate": "19/05/15 10:50 AM",
      "commitName": "470c87dbc6c24dd3b370f1ad9e7ab1f6dabd2080",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "21/04/15 10:58 AM",
      "commitNameOld": "dfc1c4c303cf15afc6c3361ed9d3238562f73cbd",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 27.99,
      "commitsBetweenForRepo": 339,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,10 @@\n   private long generateUniqueBlockReportId() {\n     // Initialize the block report ID the first time through.\n     // Note that 0 is used on the NN to indicate \"uninitialized\", so we should\n     // not send a 0 value ourselves.\n     prevBlockReportId++;\n     while (prevBlockReportId \u003d\u003d 0) {\n-      prevBlockReportId \u003d DFSUtil.getRandom().nextLong();\n+      prevBlockReportId \u003d ThreadLocalRandom.current().nextLong();\n     }\n     return prevBlockReportId;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long generateUniqueBlockReportId() {\n    // Initialize the block report ID the first time through.\n    // Note that 0 is used on the NN to indicate \"uninitialized\", so we should\n    // not send a 0 value ourselves.\n    prevBlockReportId++;\n    while (prevBlockReportId \u003d\u003d 0) {\n      prevBlockReportId \u003d ThreadLocalRandom.current().nextLong();\n    }\n    return prevBlockReportId;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java",
      "extendedDetails": {}
    },
    "b1e059089d6a5b2b7006d7d384c6df81ed268bd9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7979. Initialize block report IDs with a random number.\n",
      "commitDate": "08/04/15 9:43 PM",
      "commitName": "b1e059089d6a5b2b7006d7d384c6df81ed268bd9",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "01/04/15 12:54 PM",
      "commitNameOld": "ed72daa5df97669906234e8ac9a406d78136b206",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 7.37,
      "commitsBetweenForRepo": 64,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,10 @@\n   private long generateUniqueBlockReportId() {\n-    long id \u003d System.nanoTime();\n-    if (id \u003c\u003d prevBlockReportId) {\n-      id \u003d prevBlockReportId + 1;\n+    // Initialize the block report ID the first time through.\n+    // Note that 0 is used on the NN to indicate \"uninitialized\", so we should\n+    // not send a 0 value ourselves.\n+    prevBlockReportId++;\n+    while (prevBlockReportId \u003d\u003d 0) {\n+      prevBlockReportId \u003d DFSUtil.getRandom().nextLong();\n     }\n-    prevBlockReportId \u003d id;\n-    return id;\n+    return prevBlockReportId;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private long generateUniqueBlockReportId() {\n    // Initialize the block report ID the first time through.\n    // Note that 0 is used on the NN to indicate \"uninitialized\", so we should\n    // not send a 0 value ourselves.\n    prevBlockReportId++;\n    while (prevBlockReportId \u003d\u003d 0) {\n      prevBlockReportId \u003d DFSUtil.getRandom().nextLong();\n    }\n    return prevBlockReportId;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java",
      "extendedDetails": {}
    },
    "50ee8f4e67a66aa77c5359182f61f3e951844db6": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7960. The full block report should prune zombie storages even if they\u0027re not empty. Contributed by Colin McCabe and Eddy Xu.\n",
      "commitDate": "23/03/15 10:00 PM",
      "commitName": "50ee8f4e67a66aa77c5359182f61f3e951844db6",
      "commitAuthor": "Andrew Wang",
      "diff": "@@ -0,0 +1,8 @@\n+  private long generateUniqueBlockReportId() {\n+    long id \u003d System.nanoTime();\n+    if (id \u003c\u003d prevBlockReportId) {\n+      id \u003d prevBlockReportId + 1;\n+    }\n+    prevBlockReportId \u003d id;\n+    return id;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private long generateUniqueBlockReportId() {\n    long id \u003d System.nanoTime();\n    if (id \u003c\u003d prevBlockReportId) {\n      id \u003d prevBlockReportId + 1;\n    }\n    prevBlockReportId \u003d id;\n    return id;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java"
    }
  }
}