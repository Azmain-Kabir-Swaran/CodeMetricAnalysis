{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PBHelperClient.java",
  "functionName": "convert",
  "functionId": "convert___info-DatanodeInfo",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
  "functionStartLine": 375,
  "functionEndLine": 402,
  "numCommitsSeen": 224,
  "timeTaken": 8939,
  "changeHistory": [
    "1d2640b6132e8308c07476badd2d1482be68a298",
    "9714fc1dd48edb1c40d96d69ae82ed3b0fab7748",
    "b5adc5c3011f111f86d232cb33ec522547f68a95",
    "5f23abfa30ea29a5474513c463b4d462c0e824ee",
    "3a9c7076e81c1cc47c0ecf30c60abd9a65d8a501",
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
    "75ead273bea8a7dad61c4f99c3a16cab2697c498",
    "b4eb963c3c3e0b123003d7b32cdf7c9202cfb441",
    "8bd825bb6f35fd6fef397e3ccae0898bf7bed201",
    "38a19bc293dec6221ae96e304fc6ab660d94e706",
    "7a59150bff64fc81f838de586eacd6d062172605",
    "0a713035f2fb1a222291cfdb2cbde906814c2fd9"
  ],
  "changeHistoryShort": {
    "1d2640b6132e8308c07476badd2d1482be68a298": "Ybodychange",
    "9714fc1dd48edb1c40d96d69ae82ed3b0fab7748": "Ybodychange",
    "b5adc5c3011f111f86d232cb33ec522547f68a95": "Ybodychange",
    "5f23abfa30ea29a5474513c463b4d462c0e824ee": "Ybodychange",
    "3a9c7076e81c1cc47c0ecf30c60abd9a65d8a501": "Ybodychange",
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": "Ymultichange(Ymovefromfile,Ybodychange)",
    "75ead273bea8a7dad61c4f99c3a16cab2697c498": "Ybodychange",
    "b4eb963c3c3e0b123003d7b32cdf7c9202cfb441": "Ybodychange",
    "8bd825bb6f35fd6fef397e3ccae0898bf7bed201": "Ybodychange",
    "38a19bc293dec6221ae96e304fc6ab660d94e706": "Ybodychange",
    "7a59150bff64fc81f838de586eacd6d062172605": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
    "0a713035f2fb1a222291cfdb2cbde906814c2fd9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1d2640b6132e8308c07476badd2d1482be68a298": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13601. Optimize ByteString conversions in PBHelper.\n",
      "commitDate": "22/05/18 11:55 PM",
      "commitName": "1d2640b6132e8308c07476badd2d1482be68a298",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "26/04/18 5:36 AM",
      "commitNameOld": "0ec88ea42be7178d5fbc832ac393ded6c2aca8c8",
      "commitAuthorOld": "Nanda kumar",
      "daysBetweenCommits": 26.76,
      "commitsBetweenForRepo": 232,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,28 @@\n   public static DatanodeInfoProto convert(DatanodeInfo info) {\n     DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n     if (info.getNetworkLocation() !\u003d null) {\n-      builder.setLocation(info.getNetworkLocation());\n+      builder.setLocationBytes(\n+          bytestringCache.getUnchecked(info.getNetworkLocation()));\n     }\n     if (info.getUpgradeDomain() !\u003d null) {\n       builder.setUpgradeDomain(info.getUpgradeDomain());\n     }\n     builder\n         .setId(convert((DatanodeID) info))\n         .setCapacity(info.getCapacity())\n         .setDfsUsed(info.getDfsUsed())\n         .setNonDfsUsed(info.getNonDfsUsed())\n         .setRemaining(info.getRemaining())\n         .setBlockPoolUsed(info.getBlockPoolUsed())\n         .setCacheCapacity(info.getCacheCapacity())\n         .setCacheUsed(info.getCacheUsed())\n         .setLastUpdate(info.getLastUpdate())\n         .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n         .setXceiverCount(info.getXceiverCount())\n         .setAdminState(convert(info.getAdminState()))\n         .setLastBlockReportTime(info.getLastBlockReportTime())\n         .setLastBlockReportMonotonic(info.getLastBlockReportMonotonic())\n         .setNumBlocks(info.getNumBlocks())\n         .build();\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static DatanodeInfoProto convert(DatanodeInfo info) {\n    DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n    if (info.getNetworkLocation() !\u003d null) {\n      builder.setLocationBytes(\n          bytestringCache.getUnchecked(info.getNetworkLocation()));\n    }\n    if (info.getUpgradeDomain() !\u003d null) {\n      builder.setUpgradeDomain(info.getUpgradeDomain());\n    }\n    builder\n        .setId(convert((DatanodeID) info))\n        .setCapacity(info.getCapacity())\n        .setDfsUsed(info.getDfsUsed())\n        .setNonDfsUsed(info.getNonDfsUsed())\n        .setRemaining(info.getRemaining())\n        .setBlockPoolUsed(info.getBlockPoolUsed())\n        .setCacheCapacity(info.getCacheCapacity())\n        .setCacheUsed(info.getCacheUsed())\n        .setLastUpdate(info.getLastUpdate())\n        .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n        .setXceiverCount(info.getXceiverCount())\n        .setAdminState(convert(info.getAdminState()))\n        .setLastBlockReportTime(info.getLastBlockReportTime())\n        .setLastBlockReportMonotonic(info.getLastBlockReportMonotonic())\n        .setNumBlocks(info.getNumBlocks())\n        .build();\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "9714fc1dd48edb1c40d96d69ae82ed3b0fab7748": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-336. dfsadmin -report should report number of blocks from datanode. Contributed by Bharat Viswanadham.\n",
      "commitDate": "13/03/18 4:39 PM",
      "commitName": "9714fc1dd48edb1c40d96d69ae82ed3b0fab7748",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "02/01/18 2:59 PM",
      "commitNameOld": "42a1c98597e6dba2e371510a6b2b6b1fb94e4090",
      "commitAuthorOld": "Manoj Govindassamy",
      "daysBetweenCommits": 70.03,
      "commitsBetweenForRepo": 452,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,27 @@\n   public static DatanodeInfoProto convert(DatanodeInfo info) {\n     DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n     if (info.getNetworkLocation() !\u003d null) {\n       builder.setLocation(info.getNetworkLocation());\n     }\n     if (info.getUpgradeDomain() !\u003d null) {\n       builder.setUpgradeDomain(info.getUpgradeDomain());\n     }\n     builder\n         .setId(convert((DatanodeID) info))\n         .setCapacity(info.getCapacity())\n         .setDfsUsed(info.getDfsUsed())\n         .setNonDfsUsed(info.getNonDfsUsed())\n         .setRemaining(info.getRemaining())\n         .setBlockPoolUsed(info.getBlockPoolUsed())\n         .setCacheCapacity(info.getCacheCapacity())\n         .setCacheUsed(info.getCacheUsed())\n         .setLastUpdate(info.getLastUpdate())\n         .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n         .setXceiverCount(info.getXceiverCount())\n         .setAdminState(convert(info.getAdminState()))\n         .setLastBlockReportTime(info.getLastBlockReportTime())\n         .setLastBlockReportMonotonic(info.getLastBlockReportMonotonic())\n+        .setNumBlocks(info.getNumBlocks())\n         .build();\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static DatanodeInfoProto convert(DatanodeInfo info) {\n    DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n    if (info.getNetworkLocation() !\u003d null) {\n      builder.setLocation(info.getNetworkLocation());\n    }\n    if (info.getUpgradeDomain() !\u003d null) {\n      builder.setUpgradeDomain(info.getUpgradeDomain());\n    }\n    builder\n        .setId(convert((DatanodeID) info))\n        .setCapacity(info.getCapacity())\n        .setDfsUsed(info.getDfsUsed())\n        .setNonDfsUsed(info.getNonDfsUsed())\n        .setRemaining(info.getRemaining())\n        .setBlockPoolUsed(info.getBlockPoolUsed())\n        .setCacheCapacity(info.getCacheCapacity())\n        .setCacheUsed(info.getCacheUsed())\n        .setLastUpdate(info.getLastUpdate())\n        .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n        .setXceiverCount(info.getXceiverCount())\n        .setAdminState(convert(info.getAdminState()))\n        .setLastBlockReportTime(info.getLastBlockReportTime())\n        .setLastBlockReportMonotonic(info.getLastBlockReportMonotonic())\n        .setNumBlocks(info.getNumBlocks())\n        .build();\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "b5adc5c3011f111f86d232cb33ec522547f68a95": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10838. Last full block report received time for each DN should be easily discoverable. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "06/03/17 4:39 PM",
      "commitName": "b5adc5c3011f111f86d232cb33ec522547f68a95",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "13/02/17 11:29 AM",
      "commitNameOld": "4ed33e9ca3d85568e3904753a3ef61a85f801838",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 21.22,
      "commitsBetweenForRepo": 133,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,26 @@\n   public static DatanodeInfoProto convert(DatanodeInfo info) {\n     DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n     if (info.getNetworkLocation() !\u003d null) {\n       builder.setLocation(info.getNetworkLocation());\n     }\n     if (info.getUpgradeDomain() !\u003d null) {\n       builder.setUpgradeDomain(info.getUpgradeDomain());\n     }\n     builder\n         .setId(convert((DatanodeID) info))\n         .setCapacity(info.getCapacity())\n         .setDfsUsed(info.getDfsUsed())\n         .setNonDfsUsed(info.getNonDfsUsed())\n         .setRemaining(info.getRemaining())\n         .setBlockPoolUsed(info.getBlockPoolUsed())\n         .setCacheCapacity(info.getCacheCapacity())\n         .setCacheUsed(info.getCacheUsed())\n         .setLastUpdate(info.getLastUpdate())\n         .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n         .setXceiverCount(info.getXceiverCount())\n         .setAdminState(convert(info.getAdminState()))\n+        .setLastBlockReportTime(info.getLastBlockReportTime())\n+        .setLastBlockReportMonotonic(info.getLastBlockReportMonotonic())\n         .build();\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static DatanodeInfoProto convert(DatanodeInfo info) {\n    DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n    if (info.getNetworkLocation() !\u003d null) {\n      builder.setLocation(info.getNetworkLocation());\n    }\n    if (info.getUpgradeDomain() !\u003d null) {\n      builder.setUpgradeDomain(info.getUpgradeDomain());\n    }\n    builder\n        .setId(convert((DatanodeID) info))\n        .setCapacity(info.getCapacity())\n        .setDfsUsed(info.getDfsUsed())\n        .setNonDfsUsed(info.getNonDfsUsed())\n        .setRemaining(info.getRemaining())\n        .setBlockPoolUsed(info.getBlockPoolUsed())\n        .setCacheCapacity(info.getCacheCapacity())\n        .setCacheUsed(info.getCacheUsed())\n        .setLastUpdate(info.getLastUpdate())\n        .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n        .setXceiverCount(info.getXceiverCount())\n        .setAdminState(convert(info.getAdminState()))\n        .setLastBlockReportTime(info.getLastBlockReportTime())\n        .setLastBlockReportMonotonic(info.getLastBlockReportMonotonic())\n        .build();\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "5f23abfa30ea29a5474513c463b4d462c0e824ee": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9038. DFS reserved space is erroneously counted towards non-DFS used. (Brahma Reddy Battula)\n",
      "commitDate": "06/09/16 1:37 PM",
      "commitName": "5f23abfa30ea29a5474513c463b4d462c0e824ee",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "23/08/16 4:14 AM",
      "commitNameOld": "f0efea490e5aa9dd629d2199aae9c5b1290a17ee",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 14.39,
      "commitsBetweenForRepo": 82,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,24 @@\n   public static DatanodeInfoProto convert(DatanodeInfo info) {\n     DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n     if (info.getNetworkLocation() !\u003d null) {\n       builder.setLocation(info.getNetworkLocation());\n     }\n     if (info.getUpgradeDomain() !\u003d null) {\n       builder.setUpgradeDomain(info.getUpgradeDomain());\n     }\n     builder\n         .setId(convert((DatanodeID) info))\n         .setCapacity(info.getCapacity())\n         .setDfsUsed(info.getDfsUsed())\n+        .setNonDfsUsed(info.getNonDfsUsed())\n         .setRemaining(info.getRemaining())\n         .setBlockPoolUsed(info.getBlockPoolUsed())\n         .setCacheCapacity(info.getCacheCapacity())\n         .setCacheUsed(info.getCacheUsed())\n         .setLastUpdate(info.getLastUpdate())\n         .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n         .setXceiverCount(info.getXceiverCount())\n         .setAdminState(convert(info.getAdminState()))\n         .build();\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static DatanodeInfoProto convert(DatanodeInfo info) {\n    DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n    if (info.getNetworkLocation() !\u003d null) {\n      builder.setLocation(info.getNetworkLocation());\n    }\n    if (info.getUpgradeDomain() !\u003d null) {\n      builder.setUpgradeDomain(info.getUpgradeDomain());\n    }\n    builder\n        .setId(convert((DatanodeID) info))\n        .setCapacity(info.getCapacity())\n        .setDfsUsed(info.getDfsUsed())\n        .setNonDfsUsed(info.getNonDfsUsed())\n        .setRemaining(info.getRemaining())\n        .setBlockPoolUsed(info.getBlockPoolUsed())\n        .setCacheCapacity(info.getCacheCapacity())\n        .setCacheUsed(info.getCacheUsed())\n        .setLastUpdate(info.getLastUpdate())\n        .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n        .setXceiverCount(info.getXceiverCount())\n        .setAdminState(convert(info.getAdminState()))\n        .build();\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "3a9c7076e81c1cc47c0ecf30c60abd9a65d8a501": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9004. Add upgrade domain to DatanodeInfo. Contributed by Ming Ma (via Lei (Eddy) Xu).\n\nChange-Id: I887c66578eebd61acc34b94f18da6e6851c609f4\n",
      "commitDate": "19/09/15 6:08 PM",
      "commitName": "3a9c7076e81c1cc47c0ecf30c60abd9a65d8a501",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "03/09/15 3:32 PM",
      "commitNameOld": "ed78b14ebc9a21bb57ccd088e8b49bfa457a396f",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 16.11,
      "commitsBetweenForRepo": 102,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,23 @@\n   public static DatanodeInfoProto convert(DatanodeInfo info) {\n     DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n     if (info.getNetworkLocation() !\u003d null) {\n       builder.setLocation(info.getNetworkLocation());\n     }\n+    if (info.getUpgradeDomain() !\u003d null) {\n+      builder.setUpgradeDomain(info.getUpgradeDomain());\n+    }\n     builder\n       .setId(convert((DatanodeID) info))\n       .setCapacity(info.getCapacity())\n       .setDfsUsed(info.getDfsUsed())\n       .setRemaining(info.getRemaining())\n       .setBlockPoolUsed(info.getBlockPoolUsed())\n       .setCacheCapacity(info.getCacheCapacity())\n       .setCacheUsed(info.getCacheUsed())\n       .setLastUpdate(info.getLastUpdate())\n       .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n       .setXceiverCount(info.getXceiverCount())\n       .setAdminState(convert(info.getAdminState()))\n       .build();\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static DatanodeInfoProto convert(DatanodeInfo info) {\n    DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n    if (info.getNetworkLocation() !\u003d null) {\n      builder.setLocation(info.getNetworkLocation());\n    }\n    if (info.getUpgradeDomain() !\u003d null) {\n      builder.setUpgradeDomain(info.getUpgradeDomain());\n    }\n    builder\n      .setId(convert((DatanodeID) info))\n      .setCapacity(info.getCapacity())\n      .setDfsUsed(info.getDfsUsed())\n      .setRemaining(info.getRemaining())\n      .setBlockPoolUsed(info.getBlockPoolUsed())\n      .setCacheCapacity(info.getCacheCapacity())\n      .setCacheUsed(info.getCacheUsed())\n      .setLastUpdate(info.getLastUpdate())\n      .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n      .setXceiverCount(info.getXceiverCount())\n      .setAdminState(convert(info.getAdminState()))\n      .build();\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
      "extendedDetails": {}
    },
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-8934. Move ShortCircuitShm to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "22/08/15 1:31 PM",
      "commitName": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-8934. Move ShortCircuitShm to hdfs-client. Contributed by Mingliang Liu.\n",
          "commitDate": "22/08/15 1:31 PM",
          "commitName": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "22/08/15 12:39 AM",
          "commitNameOld": "61bf9cae6f3882c6e9a9222f59457b9be91e3018",
          "commitAuthorOld": "Karthik Kambatla",
          "daysBetweenCommits": 0.54,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,20 @@\n   public static DatanodeInfoProto convert(DatanodeInfo info) {\n     DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n     if (info.getNetworkLocation() !\u003d null) {\n       builder.setLocation(info.getNetworkLocation());\n     }\n     builder\n-        .setId(PBHelper.convert((DatanodeID)info))\n-        .setCapacity(info.getCapacity())\n-        .setDfsUsed(info.getDfsUsed())\n-        .setRemaining(info.getRemaining())\n-        .setBlockPoolUsed(info.getBlockPoolUsed())\n-        .setCacheCapacity(info.getCacheCapacity())\n-        .setCacheUsed(info.getCacheUsed())\n-        .setLastUpdate(info.getLastUpdate())\n-        .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n-        .setXceiverCount(info.getXceiverCount())\n-        .setAdminState(PBHelper.convert(info.getAdminState()))\n-        .build();\n+      .setId(convert((DatanodeID) info))\n+      .setCapacity(info.getCapacity())\n+      .setDfsUsed(info.getDfsUsed())\n+      .setRemaining(info.getRemaining())\n+      .setBlockPoolUsed(info.getBlockPoolUsed())\n+      .setCacheCapacity(info.getCacheCapacity())\n+      .setCacheUsed(info.getCacheUsed())\n+      .setLastUpdate(info.getLastUpdate())\n+      .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n+      .setXceiverCount(info.getXceiverCount())\n+      .setAdminState(convert(info.getAdminState()))\n+      .build();\n     return builder.build();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static DatanodeInfoProto convert(DatanodeInfo info) {\n    DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n    if (info.getNetworkLocation() !\u003d null) {\n      builder.setLocation(info.getNetworkLocation());\n    }\n    builder\n      .setId(convert((DatanodeID) info))\n      .setCapacity(info.getCapacity())\n      .setDfsUsed(info.getDfsUsed())\n      .setRemaining(info.getRemaining())\n      .setBlockPoolUsed(info.getBlockPoolUsed())\n      .setCacheCapacity(info.getCacheCapacity())\n      .setCacheUsed(info.getCacheUsed())\n      .setLastUpdate(info.getLastUpdate())\n      .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n      .setXceiverCount(info.getXceiverCount())\n      .setAdminState(convert(info.getAdminState()))\n      .build();\n    return builder.build();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
            "oldMethodName": "convert",
            "newMethodName": "convert"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8934. Move ShortCircuitShm to hdfs-client. Contributed by Mingliang Liu.\n",
          "commitDate": "22/08/15 1:31 PM",
          "commitName": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "22/08/15 12:39 AM",
          "commitNameOld": "61bf9cae6f3882c6e9a9222f59457b9be91e3018",
          "commitAuthorOld": "Karthik Kambatla",
          "daysBetweenCommits": 0.54,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,20 @@\n   public static DatanodeInfoProto convert(DatanodeInfo info) {\n     DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n     if (info.getNetworkLocation() !\u003d null) {\n       builder.setLocation(info.getNetworkLocation());\n     }\n     builder\n-        .setId(PBHelper.convert((DatanodeID)info))\n-        .setCapacity(info.getCapacity())\n-        .setDfsUsed(info.getDfsUsed())\n-        .setRemaining(info.getRemaining())\n-        .setBlockPoolUsed(info.getBlockPoolUsed())\n-        .setCacheCapacity(info.getCacheCapacity())\n-        .setCacheUsed(info.getCacheUsed())\n-        .setLastUpdate(info.getLastUpdate())\n-        .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n-        .setXceiverCount(info.getXceiverCount())\n-        .setAdminState(PBHelper.convert(info.getAdminState()))\n-        .build();\n+      .setId(convert((DatanodeID) info))\n+      .setCapacity(info.getCapacity())\n+      .setDfsUsed(info.getDfsUsed())\n+      .setRemaining(info.getRemaining())\n+      .setBlockPoolUsed(info.getBlockPoolUsed())\n+      .setCacheCapacity(info.getCacheCapacity())\n+      .setCacheUsed(info.getCacheUsed())\n+      .setLastUpdate(info.getLastUpdate())\n+      .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n+      .setXceiverCount(info.getXceiverCount())\n+      .setAdminState(convert(info.getAdminState()))\n+      .build();\n     return builder.build();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static DatanodeInfoProto convert(DatanodeInfo info) {\n    DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n    if (info.getNetworkLocation() !\u003d null) {\n      builder.setLocation(info.getNetworkLocation());\n    }\n    builder\n      .setId(convert((DatanodeID) info))\n      .setCapacity(info.getCapacity())\n      .setDfsUsed(info.getDfsUsed())\n      .setRemaining(info.getRemaining())\n      .setBlockPoolUsed(info.getBlockPoolUsed())\n      .setCacheCapacity(info.getCacheCapacity())\n      .setCacheUsed(info.getCacheUsed())\n      .setLastUpdate(info.getLastUpdate())\n      .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n      .setXceiverCount(info.getXceiverCount())\n      .setAdminState(convert(info.getAdminState()))\n      .build();\n    return builder.build();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
          "extendedDetails": {}
        }
      ]
    },
    "75ead273bea8a7dad61c4f99c3a16cab2697c498": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6841. Use Time.monotonicNow() wherever applicable instead of Time.now(). Contributed by Vinayakumar B\n",
      "commitDate": "20/03/15 12:02 PM",
      "commitName": "75ead273bea8a7dad61c4f99c3a16cab2697c498",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "13/03/15 12:23 PM",
      "commitNameOld": "d324164a51a43d72c02567248bd9f0f12b244a40",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 6.99,
      "commitsBetweenForRepo": 79,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,20 @@\n   public static DatanodeInfoProto convert(DatanodeInfo info) {\n     DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n     if (info.getNetworkLocation() !\u003d null) {\n       builder.setLocation(info.getNetworkLocation());\n     }\n     builder\n         .setId(PBHelper.convert((DatanodeID)info))\n         .setCapacity(info.getCapacity())\n         .setDfsUsed(info.getDfsUsed())\n         .setRemaining(info.getRemaining())\n         .setBlockPoolUsed(info.getBlockPoolUsed())\n         .setCacheCapacity(info.getCacheCapacity())\n         .setCacheUsed(info.getCacheUsed())\n         .setLastUpdate(info.getLastUpdate())\n+        .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n         .setXceiverCount(info.getXceiverCount())\n         .setAdminState(PBHelper.convert(info.getAdminState()))\n         .build();\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static DatanodeInfoProto convert(DatanodeInfo info) {\n    DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n    if (info.getNetworkLocation() !\u003d null) {\n      builder.setLocation(info.getNetworkLocation());\n    }\n    builder\n        .setId(PBHelper.convert((DatanodeID)info))\n        .setCapacity(info.getCapacity())\n        .setDfsUsed(info.getDfsUsed())\n        .setRemaining(info.getRemaining())\n        .setBlockPoolUsed(info.getBlockPoolUsed())\n        .setCacheCapacity(info.getCacheCapacity())\n        .setCacheUsed(info.getCacheUsed())\n        .setLastUpdate(info.getLastUpdate())\n        .setLastUpdateMonotonic(info.getLastUpdateMonotonic())\n        .setXceiverCount(info.getXceiverCount())\n        .setAdminState(PBHelper.convert(info.getAdminState()))\n        .build();\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "b4eb963c3c3e0b123003d7b32cdf7c9202cfb441": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5659. dfsadmin -report doesn\u0027t output cache information properly. Contributed by Andrew Wang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1554893 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/01/14 12:11 PM",
      "commitName": "b4eb963c3c3e0b123003d7b32cdf7c9202cfb441",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "20/12/13 3:27 PM",
      "commitNameOld": "b9ae3087c0f83bfeeea47ded8e19932b46fd2350",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 12.86,
      "commitsBetweenForRepo": 28,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,19 @@\n   public static DatanodeInfoProto convert(DatanodeInfo info) {\n     DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n-    builder.setBlockPoolUsed(info.getBlockPoolUsed());\n-    builder.setAdminState(PBHelper.convert(info.getAdminState()));\n-    builder.setCapacity(info.getCapacity())\n-        .setDfsUsed(info.getDfsUsed())\n+    if (info.getNetworkLocation() !\u003d null) {\n+      builder.setLocation(info.getNetworkLocation());\n+    }\n+    builder\n         .setId(PBHelper.convert((DatanodeID)info))\n-        .setLastUpdate(info.getLastUpdate())\n-        .setLocation(info.getNetworkLocation())\n+        .setCapacity(info.getCapacity())\n+        .setDfsUsed(info.getDfsUsed())\n         .setRemaining(info.getRemaining())\n+        .setBlockPoolUsed(info.getBlockPoolUsed())\n+        .setCacheCapacity(info.getCacheCapacity())\n+        .setCacheUsed(info.getCacheUsed())\n+        .setLastUpdate(info.getLastUpdate())\n         .setXceiverCount(info.getXceiverCount())\n+        .setAdminState(PBHelper.convert(info.getAdminState()))\n         .build();\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static DatanodeInfoProto convert(DatanodeInfo info) {\n    DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n    if (info.getNetworkLocation() !\u003d null) {\n      builder.setLocation(info.getNetworkLocation());\n    }\n    builder\n        .setId(PBHelper.convert((DatanodeID)info))\n        .setCapacity(info.getCapacity())\n        .setDfsUsed(info.getDfsUsed())\n        .setRemaining(info.getRemaining())\n        .setBlockPoolUsed(info.getBlockPoolUsed())\n        .setCacheCapacity(info.getCacheCapacity())\n        .setCacheUsed(info.getCacheUsed())\n        .setLastUpdate(info.getLastUpdate())\n        .setXceiverCount(info.getXceiverCount())\n        .setAdminState(PBHelper.convert(info.getAdminState()))\n        .build();\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "8bd825bb6f35fd6fef397e3ccae0898bf7bed201": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3164. Move DatanodeInfo#hostName to DatanodeID. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1307890 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/03/12 12:58 PM",
      "commitName": "8bd825bb6f35fd6fef397e3ccae0898bf7bed201",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "17/02/12 5:27 PM",
      "commitNameOld": "ef5d7156dba5fb5f03b3d46e9ecfec5273eca66f",
      "commitAuthorOld": "",
      "daysBetweenCommits": 42.77,
      "commitsBetweenForRepo": 278,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,14 @@\n   public static DatanodeInfoProto convert(DatanodeInfo info) {\n     DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n     builder.setBlockPoolUsed(info.getBlockPoolUsed());\n     builder.setAdminState(PBHelper.convert(info.getAdminState()));\n     builder.setCapacity(info.getCapacity())\n         .setDfsUsed(info.getDfsUsed())\n-        .setHostName(info.getHostName())\n         .setId(PBHelper.convert((DatanodeID)info))\n         .setLastUpdate(info.getLastUpdate())\n         .setLocation(info.getNetworkLocation())\n         .setRemaining(info.getRemaining())\n         .setXceiverCount(info.getXceiverCount())\n         .build();\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static DatanodeInfoProto convert(DatanodeInfo info) {\n    DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n    builder.setBlockPoolUsed(info.getBlockPoolUsed());\n    builder.setAdminState(PBHelper.convert(info.getAdminState()));\n    builder.setCapacity(info.getCapacity())\n        .setDfsUsed(info.getDfsUsed())\n        .setId(PBHelper.convert((DatanodeID)info))\n        .setLastUpdate(info.getLastUpdate())\n        .setLocation(info.getNetworkLocation())\n        .setRemaining(info.getRemaining())\n        .setXceiverCount(info.getXceiverCount())\n        .build();\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "38a19bc293dec6221ae96e304fc6ab660d94e706": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2642. Protobuf translators for DatanodeProtocol.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1212606 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/12/11 12:02 PM",
      "commitName": "38a19bc293dec6221ae96e304fc6ab660d94e706",
      "commitAuthor": "Jitendra Nath Pandey",
      "commitDateOld": "06/12/11 5:05 PM",
      "commitNameOld": "c17bb83644b39f551796b8ab6a43023f70b1b89a",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 2.79,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,15 @@\n   public static DatanodeInfoProto convert(DatanodeInfo info) {\n-    return DatanodeInfoProto.newBuilder()\n-        .setAdminState(PBHelper.convert(info.getAdminState()))\n-        .setBlockPoolUsed(info.getBlockPoolUsed())\n-        .setCapacity(info.getCapacity())\n+    DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n+    builder.setBlockPoolUsed(info.getBlockPoolUsed());\n+    builder.setAdminState(PBHelper.convert(info.getAdminState()));\n+    builder.setCapacity(info.getCapacity())\n         .setDfsUsed(info.getDfsUsed())\n         .setHostName(info.getHostName())\n         .setId(PBHelper.convert((DatanodeID)info))\n         .setLastUpdate(info.getLastUpdate())\n         .setLocation(info.getNetworkLocation())\n         .setRemaining(info.getRemaining())\n         .setXceiverCount(info.getXceiverCount())\n         .build();\n+    return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static DatanodeInfoProto convert(DatanodeInfo info) {\n    DatanodeInfoProto.Builder builder \u003d DatanodeInfoProto.newBuilder();\n    builder.setBlockPoolUsed(info.getBlockPoolUsed());\n    builder.setAdminState(PBHelper.convert(info.getAdminState()));\n    builder.setCapacity(info.getCapacity())\n        .setDfsUsed(info.getDfsUsed())\n        .setHostName(info.getHostName())\n        .setId(PBHelper.convert((DatanodeID)info))\n        .setLastUpdate(info.getLastUpdate())\n        .setLocation(info.getNetworkLocation())\n        .setRemaining(info.getRemaining())\n        .setXceiverCount(info.getXceiverCount())\n        .build();\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
      "extendedDetails": {}
    },
    "7a59150bff64fc81f838de586eacd6d062172605": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-2629. Implement protobuf service for InterDatanodeProtocol. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1211206 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/12/11 2:19 PM",
      "commitName": "7a59150bff64fc81f838de586eacd6d062172605",
      "commitAuthor": "Suresh Srinivas",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2629. Implement protobuf service for InterDatanodeProtocol. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1211206 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/11 2:19 PM",
          "commitName": "7a59150bff64fc81f838de586eacd6d062172605",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "05/12/11 4:25 PM",
          "commitNameOld": "0a713035f2fb1a222291cfdb2cbde906814c2fd9",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 0.91,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,14 @@\n-  public static BlockWithLocations[] convert(List\u003cBlockWithLocationsProto\u003e b) {\n-    BlockWithLocations[] ret \u003d new BlockWithLocations[b.size()];\n-    int i \u003d 0;\n-    for (BlockWithLocationsProto entry : b) {\n-      ret[i++] \u003d convert(entry);\n-    }\n-    return ret;\n+  public static DatanodeInfoProto convert(DatanodeInfo info) {\n+    return DatanodeInfoProto.newBuilder()\n+        .setAdminState(PBHelper.convert(info.getAdminState()))\n+        .setBlockPoolUsed(info.getBlockPoolUsed())\n+        .setCapacity(info.getCapacity())\n+        .setDfsUsed(info.getDfsUsed())\n+        .setHostName(info.getHostName())\n+        .setId(PBHelper.convert((DatanodeID)info))\n+        .setLastUpdate(info.getLastUpdate())\n+        .setLocation(info.getNetworkLocation())\n+        .setRemaining(info.getRemaining())\n+        .setXceiverCount(info.getXceiverCount())\n+        .build();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static DatanodeInfoProto convert(DatanodeInfo info) {\n    return DatanodeInfoProto.newBuilder()\n        .setAdminState(PBHelper.convert(info.getAdminState()))\n        .setBlockPoolUsed(info.getBlockPoolUsed())\n        .setCapacity(info.getCapacity())\n        .setDfsUsed(info.getDfsUsed())\n        .setHostName(info.getHostName())\n        .setId(PBHelper.convert((DatanodeID)info))\n        .setLastUpdate(info.getLastUpdate())\n        .setLocation(info.getNetworkLocation())\n        .setRemaining(info.getRemaining())\n        .setXceiverCount(info.getXceiverCount())\n        .build();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
          "extendedDetails": {
            "oldValue": "[b-List\u003cBlockWithLocationsProto\u003e]",
            "newValue": "[info-DatanodeInfo]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-2629. Implement protobuf service for InterDatanodeProtocol. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1211206 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/11 2:19 PM",
          "commitName": "7a59150bff64fc81f838de586eacd6d062172605",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "05/12/11 4:25 PM",
          "commitNameOld": "0a713035f2fb1a222291cfdb2cbde906814c2fd9",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 0.91,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,14 @@\n-  public static BlockWithLocations[] convert(List\u003cBlockWithLocationsProto\u003e b) {\n-    BlockWithLocations[] ret \u003d new BlockWithLocations[b.size()];\n-    int i \u003d 0;\n-    for (BlockWithLocationsProto entry : b) {\n-      ret[i++] \u003d convert(entry);\n-    }\n-    return ret;\n+  public static DatanodeInfoProto convert(DatanodeInfo info) {\n+    return DatanodeInfoProto.newBuilder()\n+        .setAdminState(PBHelper.convert(info.getAdminState()))\n+        .setBlockPoolUsed(info.getBlockPoolUsed())\n+        .setCapacity(info.getCapacity())\n+        .setDfsUsed(info.getDfsUsed())\n+        .setHostName(info.getHostName())\n+        .setId(PBHelper.convert((DatanodeID)info))\n+        .setLastUpdate(info.getLastUpdate())\n+        .setLocation(info.getNetworkLocation())\n+        .setRemaining(info.getRemaining())\n+        .setXceiverCount(info.getXceiverCount())\n+        .build();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static DatanodeInfoProto convert(DatanodeInfo info) {\n    return DatanodeInfoProto.newBuilder()\n        .setAdminState(PBHelper.convert(info.getAdminState()))\n        .setBlockPoolUsed(info.getBlockPoolUsed())\n        .setCapacity(info.getCapacity())\n        .setDfsUsed(info.getDfsUsed())\n        .setHostName(info.getHostName())\n        .setId(PBHelper.convert((DatanodeID)info))\n        .setLastUpdate(info.getLastUpdate())\n        .setLocation(info.getNetworkLocation())\n        .setRemaining(info.getRemaining())\n        .setXceiverCount(info.getXceiverCount())\n        .build();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
          "extendedDetails": {
            "oldValue": "BlockWithLocations[]",
            "newValue": "DatanodeInfoProto"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2629. Implement protobuf service for InterDatanodeProtocol. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1211206 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/11 2:19 PM",
          "commitName": "7a59150bff64fc81f838de586eacd6d062172605",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "05/12/11 4:25 PM",
          "commitNameOld": "0a713035f2fb1a222291cfdb2cbde906814c2fd9",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 0.91,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,14 @@\n-  public static BlockWithLocations[] convert(List\u003cBlockWithLocationsProto\u003e b) {\n-    BlockWithLocations[] ret \u003d new BlockWithLocations[b.size()];\n-    int i \u003d 0;\n-    for (BlockWithLocationsProto entry : b) {\n-      ret[i++] \u003d convert(entry);\n-    }\n-    return ret;\n+  public static DatanodeInfoProto convert(DatanodeInfo info) {\n+    return DatanodeInfoProto.newBuilder()\n+        .setAdminState(PBHelper.convert(info.getAdminState()))\n+        .setBlockPoolUsed(info.getBlockPoolUsed())\n+        .setCapacity(info.getCapacity())\n+        .setDfsUsed(info.getDfsUsed())\n+        .setHostName(info.getHostName())\n+        .setId(PBHelper.convert((DatanodeID)info))\n+        .setLastUpdate(info.getLastUpdate())\n+        .setLocation(info.getNetworkLocation())\n+        .setRemaining(info.getRemaining())\n+        .setXceiverCount(info.getXceiverCount())\n+        .build();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static DatanodeInfoProto convert(DatanodeInfo info) {\n    return DatanodeInfoProto.newBuilder()\n        .setAdminState(PBHelper.convert(info.getAdminState()))\n        .setBlockPoolUsed(info.getBlockPoolUsed())\n        .setCapacity(info.getCapacity())\n        .setDfsUsed(info.getDfsUsed())\n        .setHostName(info.getHostName())\n        .setId(PBHelper.convert((DatanodeID)info))\n        .setLastUpdate(info.getLastUpdate())\n        .setLocation(info.getNetworkLocation())\n        .setRemaining(info.getRemaining())\n        .setXceiverCount(info.getXceiverCount())\n        .build();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java",
          "extendedDetails": {}
        }
      ]
    },
    "0a713035f2fb1a222291cfdb2cbde906814c2fd9": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2618. Implement protobuf service for NamenodeProtocol. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1210719 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/12/11 4:25 PM",
      "commitName": "0a713035f2fb1a222291cfdb2cbde906814c2fd9",
      "commitAuthor": "Suresh Srinivas",
      "diff": "@@ -0,0 +1,8 @@\n+  public static BlockWithLocations[] convert(List\u003cBlockWithLocationsProto\u003e b) {\n+    BlockWithLocations[] ret \u003d new BlockWithLocations[b.size()];\n+    int i \u003d 0;\n+    for (BlockWithLocationsProto entry : b) {\n+      ret[i++] \u003d convert(entry);\n+    }\n+    return ret;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static BlockWithLocations[] convert(List\u003cBlockWithLocationsProto\u003e b) {\n    BlockWithLocations[] ret \u003d new BlockWithLocations[b.size()];\n    int i \u003d 0;\n    for (BlockWithLocationsProto entry : b) {\n      ret[i++] \u003d convert(entry);\n    }\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java"
    }
  }
}