{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSEditLogOp.java",
  "functionName": "decodeOp",
  "functionId": "decodeOp",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
  "functionStartLine": 5147,
  "functionEndLine": 5165,
  "numCommitsSeen": 117,
  "timeTaken": 8754,
  "changeHistory": [
    "24f6a7c9563757234f53ca23e12f9c9208b53082",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
    "9dab514b22f49322738935cfd915c2b4eba50b88",
    "00067895a01c66d53715b50bbcb3605efd6425f2",
    "019d6a22b152feef796a46d538ef593c20741a31",
    "19dd66a3f616cd8a4527f2adeef911a7d4b3f349",
    "95710c15b7a724897bcde826e112df6d4b4fe56b",
    "706394d03992b394e9f907aff2155df493e4ea4e",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
    "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "24f6a7c9563757234f53ca23e12f9c9208b53082": "Ymultichange(Ymodifierchange,Ybodychange)",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": "Ybodychange",
    "9dab514b22f49322738935cfd915c2b4eba50b88": "Ybodychange",
    "00067895a01c66d53715b50bbcb3605efd6425f2": "Ybodychange",
    "019d6a22b152feef796a46d538ef593c20741a31": "Ybodychange",
    "19dd66a3f616cd8a4527f2adeef911a7d4b3f349": "Ybodychange",
    "95710c15b7a724897bcde826e112df6d4b4fe56b": "Ybodychange",
    "706394d03992b394e9f907aff2155df493e4ea4e": "Ymultichange(Yrename,Ymodifierchange,Ybodychange)",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": "Ybodychange",
    "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "24f6a7c9563757234f53ca23e12f9c9208b53082": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-8965. Harden edit log reading code against out of memory errors (cmccabe)\n",
      "commitDate": "31/08/15 6:06 PM",
      "commitName": "24f6a7c9563757234f53ca23e12f9c9208b53082",
      "commitAuthor": "Colin Patrick Mccabe",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-8965. Harden edit log reading code against out of memory errors (cmccabe)\n",
          "commitDate": "31/08/15 6:06 PM",
          "commitName": "24f6a7c9563757234f53ca23e12f9c9208b53082",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "08/07/15 10:37 AM",
          "commitNameOld": "fc6182d5ed92ac70de1f4633edd5265b7be1a8dc",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 54.31,
          "commitsBetweenForRepo": 294,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,28 @@\n-    private FSEditLogOp decodeOp() throws IOException {\n+    public FSEditLogOp decodeOp() throws IOException {\n       limiter.setLimit(maxOpSize);\n       in.mark(maxOpSize);\n-\n-      if (checksum !\u003d null) {\n-        checksum.reset();\n-      }\n-\n       byte opCodeByte;\n       try {\n         opCodeByte \u003d in.readByte();\n       } catch (EOFException eof) {\n         // EOF at an opcode boundary is expected.\n         return null;\n       }\n-\n       FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n       if (opCode \u003d\u003d OP_INVALID) {\n         verifyTerminator();\n         return null;\n       }\n-\n       FSEditLogOp op \u003d cache.get(opCode);\n       if (op \u003d\u003d null) {\n         throw new IOException(\"Read invalid opcode \" + opCode);\n       }\n-\n-      if (supportEditLogLength) {\n-        in.readInt();\n-      }\n-\n       if (NameNodeLayoutVersion.supports(\n-          LayoutVersion.Feature.STORED_TXIDS, logVersion)) {\n-        // Read the txid\n+            LayoutVersion.Feature.STORED_TXIDS, logVersion)) {\n         op.setTransactionId(in.readLong());\n       } else {\n         op.setTransactionId(HdfsServerConstants.INVALID_TXID);\n       }\n-\n       op.readFields(in, logVersion);\n-\n-      validateChecksum(in, checksum, op.txid);\n       return op;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    public FSEditLogOp decodeOp() throws IOException {\n      limiter.setLimit(maxOpSize);\n      in.mark(maxOpSize);\n      byte opCodeByte;\n      try {\n        opCodeByte \u003d in.readByte();\n      } catch (EOFException eof) {\n        // EOF at an opcode boundary is expected.\n        return null;\n      }\n      FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n      if (opCode \u003d\u003d OP_INVALID) {\n        verifyTerminator();\n        return null;\n      }\n      FSEditLogOp op \u003d cache.get(opCode);\n      if (op \u003d\u003d null) {\n        throw new IOException(\"Read invalid opcode \" + opCode);\n      }\n      if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.STORED_TXIDS, logVersion)) {\n        op.setTransactionId(in.readLong());\n      } else {\n        op.setTransactionId(HdfsServerConstants.INVALID_TXID);\n      }\n      op.readFields(in, logVersion);\n      return op;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8965. Harden edit log reading code against out of memory errors (cmccabe)\n",
          "commitDate": "31/08/15 6:06 PM",
          "commitName": "24f6a7c9563757234f53ca23e12f9c9208b53082",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "08/07/15 10:37 AM",
          "commitNameOld": "fc6182d5ed92ac70de1f4633edd5265b7be1a8dc",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 54.31,
          "commitsBetweenForRepo": 294,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,28 @@\n-    private FSEditLogOp decodeOp() throws IOException {\n+    public FSEditLogOp decodeOp() throws IOException {\n       limiter.setLimit(maxOpSize);\n       in.mark(maxOpSize);\n-\n-      if (checksum !\u003d null) {\n-        checksum.reset();\n-      }\n-\n       byte opCodeByte;\n       try {\n         opCodeByte \u003d in.readByte();\n       } catch (EOFException eof) {\n         // EOF at an opcode boundary is expected.\n         return null;\n       }\n-\n       FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n       if (opCode \u003d\u003d OP_INVALID) {\n         verifyTerminator();\n         return null;\n       }\n-\n       FSEditLogOp op \u003d cache.get(opCode);\n       if (op \u003d\u003d null) {\n         throw new IOException(\"Read invalid opcode \" + opCode);\n       }\n-\n-      if (supportEditLogLength) {\n-        in.readInt();\n-      }\n-\n       if (NameNodeLayoutVersion.supports(\n-          LayoutVersion.Feature.STORED_TXIDS, logVersion)) {\n-        // Read the txid\n+            LayoutVersion.Feature.STORED_TXIDS, logVersion)) {\n         op.setTransactionId(in.readLong());\n       } else {\n         op.setTransactionId(HdfsServerConstants.INVALID_TXID);\n       }\n-\n       op.readFields(in, logVersion);\n-\n-      validateChecksum(in, checksum, op.txid);\n       return op;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    public FSEditLogOp decodeOp() throws IOException {\n      limiter.setLimit(maxOpSize);\n      in.mark(maxOpSize);\n      byte opCodeByte;\n      try {\n        opCodeByte \u003d in.readByte();\n      } catch (EOFException eof) {\n        // EOF at an opcode boundary is expected.\n        return null;\n      }\n      FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n      if (opCode \u003d\u003d OP_INVALID) {\n        verifyTerminator();\n        return null;\n      }\n      FSEditLogOp op \u003d cache.get(opCode);\n      if (op \u003d\u003d null) {\n        throw new IOException(\"Read invalid opcode \" + opCode);\n      }\n      if (NameNodeLayoutVersion.supports(\n            LayoutVersion.Feature.STORED_TXIDS, logVersion)) {\n        op.setTransactionId(in.readLong());\n      } else {\n        op.setTransactionId(HdfsServerConstants.INVALID_TXID);\n      }\n      op.readFields(in, logVersion);\n      return op;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
          "extendedDetails": {}
        }
      ]
    },
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8249. Separate HdfsConstants into the client and the server side class. Contributed by Haohui Mai.\n",
      "commitDate": "02/05/15 10:03 AM",
      "commitName": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "20/04/15 12:36 AM",
      "commitNameOld": "5c97db07fb306842f49d73a67a90cecec19a7833",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 12.39,
      "commitsBetweenForRepo": 126,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n     private FSEditLogOp decodeOp() throws IOException {\n       limiter.setLimit(maxOpSize);\n       in.mark(maxOpSize);\n \n       if (checksum !\u003d null) {\n         checksum.reset();\n       }\n \n       byte opCodeByte;\n       try {\n         opCodeByte \u003d in.readByte();\n       } catch (EOFException eof) {\n         // EOF at an opcode boundary is expected.\n         return null;\n       }\n \n       FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n       if (opCode \u003d\u003d OP_INVALID) {\n         verifyTerminator();\n         return null;\n       }\n \n       FSEditLogOp op \u003d cache.get(opCode);\n       if (op \u003d\u003d null) {\n         throw new IOException(\"Read invalid opcode \" + opCode);\n       }\n \n       if (supportEditLogLength) {\n         in.readInt();\n       }\n \n       if (NameNodeLayoutVersion.supports(\n           LayoutVersion.Feature.STORED_TXIDS, logVersion)) {\n         // Read the txid\n         op.setTransactionId(in.readLong());\n       } else {\n-        op.setTransactionId(HdfsConstants.INVALID_TXID);\n+        op.setTransactionId(HdfsServerConstants.INVALID_TXID);\n       }\n \n       op.readFields(in, logVersion);\n \n       validateChecksum(in, checksum, op.txid);\n       return op;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private FSEditLogOp decodeOp() throws IOException {\n      limiter.setLimit(maxOpSize);\n      in.mark(maxOpSize);\n\n      if (checksum !\u003d null) {\n        checksum.reset();\n      }\n\n      byte opCodeByte;\n      try {\n        opCodeByte \u003d in.readByte();\n      } catch (EOFException eof) {\n        // EOF at an opcode boundary is expected.\n        return null;\n      }\n\n      FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n      if (opCode \u003d\u003d OP_INVALID) {\n        verifyTerminator();\n        return null;\n      }\n\n      FSEditLogOp op \u003d cache.get(opCode);\n      if (op \u003d\u003d null) {\n        throw new IOException(\"Read invalid opcode \" + opCode);\n      }\n\n      if (supportEditLogLength) {\n        in.readInt();\n      }\n\n      if (NameNodeLayoutVersion.supports(\n          LayoutVersion.Feature.STORED_TXIDS, logVersion)) {\n        // Read the txid\n        op.setTransactionId(in.readLong());\n      } else {\n        op.setTransactionId(HdfsServerConstants.INVALID_TXID);\n      }\n\n      op.readFields(in, logVersion);\n\n      validateChecksum(in, checksum, op.txid);\n      return op;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "9dab514b22f49322738935cfd915c2b4eba50b88": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6038. Allow JournalNode to handle editlog produced by new release with future layoutversion. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1579813 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/03/14 4:06 PM",
      "commitName": "9dab514b22f49322738935cfd915c2b4eba50b88",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "19/02/14 1:40 PM",
      "commitNameOld": "d69985d90b9349228ab30622073c388dba296698",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 29.06,
      "commitsBetweenForRepo": 269,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,44 @@\n     private FSEditLogOp decodeOp() throws IOException {\n       limiter.setLimit(maxOpSize);\n       in.mark(maxOpSize);\n \n       if (checksum !\u003d null) {\n         checksum.reset();\n       }\n \n       byte opCodeByte;\n       try {\n         opCodeByte \u003d in.readByte();\n       } catch (EOFException eof) {\n         // EOF at an opcode boundary is expected.\n         return null;\n       }\n \n       FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n       if (opCode \u003d\u003d OP_INVALID) {\n         verifyTerminator();\n         return null;\n       }\n \n       FSEditLogOp op \u003d cache.get(opCode);\n       if (op \u003d\u003d null) {\n         throw new IOException(\"Read invalid opcode \" + opCode);\n       }\n \n+      if (supportEditLogLength) {\n+        in.readInt();\n+      }\n+\n       if (NameNodeLayoutVersion.supports(\n           LayoutVersion.Feature.STORED_TXIDS, logVersion)) {\n         // Read the txid\n         op.setTransactionId(in.readLong());\n       } else {\n         op.setTransactionId(HdfsConstants.INVALID_TXID);\n       }\n \n       op.readFields(in, logVersion);\n \n       validateChecksum(in, checksum, op.txid);\n       return op;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private FSEditLogOp decodeOp() throws IOException {\n      limiter.setLimit(maxOpSize);\n      in.mark(maxOpSize);\n\n      if (checksum !\u003d null) {\n        checksum.reset();\n      }\n\n      byte opCodeByte;\n      try {\n        opCodeByte \u003d in.readByte();\n      } catch (EOFException eof) {\n        // EOF at an opcode boundary is expected.\n        return null;\n      }\n\n      FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n      if (opCode \u003d\u003d OP_INVALID) {\n        verifyTerminator();\n        return null;\n      }\n\n      FSEditLogOp op \u003d cache.get(opCode);\n      if (op \u003d\u003d null) {\n        throw new IOException(\"Read invalid opcode \" + opCode);\n      }\n\n      if (supportEditLogLength) {\n        in.readInt();\n      }\n\n      if (NameNodeLayoutVersion.supports(\n          LayoutVersion.Feature.STORED_TXIDS, logVersion)) {\n        // Read the txid\n        op.setTransactionId(in.readLong());\n      } else {\n        op.setTransactionId(HdfsConstants.INVALID_TXID);\n      }\n\n      op.readFields(in, logVersion);\n\n      validateChecksum(in, checksum, op.txid);\n      return op;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "00067895a01c66d53715b50bbcb3605efd6425f2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5754. Split LayoutVerion into NameNodeLayoutVersion and DataNodeLayoutVersion. Contributed by Brandon Li\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1563041 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/01/14 7:21 PM",
      "commitName": "00067895a01c66d53715b50bbcb3605efd6425f2",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "27/01/14 9:35 PM",
      "commitNameOld": "917502ef316447d282304f70d170a4686a4c7834",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 2.91,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,40 @@\n     private FSEditLogOp decodeOp() throws IOException {\n       limiter.setLimit(maxOpSize);\n       in.mark(maxOpSize);\n \n       if (checksum !\u003d null) {\n         checksum.reset();\n       }\n \n       byte opCodeByte;\n       try {\n         opCodeByte \u003d in.readByte();\n       } catch (EOFException eof) {\n         // EOF at an opcode boundary is expected.\n         return null;\n       }\n \n       FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n       if (opCode \u003d\u003d OP_INVALID) {\n         verifyTerminator();\n         return null;\n       }\n \n       FSEditLogOp op \u003d cache.get(opCode);\n       if (op \u003d\u003d null) {\n         throw new IOException(\"Read invalid opcode \" + opCode);\n       }\n \n-      if (LayoutVersion.supports(Feature.STORED_TXIDS, logVersion)) {\n+      if (NameNodeLayoutVersion.supports(\n+          LayoutVersion.Feature.STORED_TXIDS, logVersion)) {\n         // Read the txid\n         op.setTransactionId(in.readLong());\n       } else {\n         op.setTransactionId(HdfsConstants.INVALID_TXID);\n       }\n \n       op.readFields(in, logVersion);\n \n       validateChecksum(in, checksum, op.txid);\n       return op;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private FSEditLogOp decodeOp() throws IOException {\n      limiter.setLimit(maxOpSize);\n      in.mark(maxOpSize);\n\n      if (checksum !\u003d null) {\n        checksum.reset();\n      }\n\n      byte opCodeByte;\n      try {\n        opCodeByte \u003d in.readByte();\n      } catch (EOFException eof) {\n        // EOF at an opcode boundary is expected.\n        return null;\n      }\n\n      FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n      if (opCode \u003d\u003d OP_INVALID) {\n        verifyTerminator();\n        return null;\n      }\n\n      FSEditLogOp op \u003d cache.get(opCode);\n      if (op \u003d\u003d null) {\n        throw new IOException(\"Read invalid opcode \" + opCode);\n      }\n\n      if (NameNodeLayoutVersion.supports(\n          LayoutVersion.Feature.STORED_TXIDS, logVersion)) {\n        // Read the txid\n        op.setTransactionId(in.readLong());\n      } else {\n        op.setTransactionId(HdfsConstants.INVALID_TXID);\n      }\n\n      op.readFields(in, logVersion);\n\n      validateChecksum(in, checksum, op.txid);\n      return op;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "019d6a22b152feef796a46d538ef593c20741a31": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4304. Make FSEditLogOp.MAX_OP_SIZE configurable. Contributed by Colin Patrick McCabe.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1449218 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/02/13 1:21 PM",
      "commitName": "019d6a22b152feef796a46d538ef593c20741a31",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "24/08/12 6:03 PM",
      "commitNameOld": "deead78e35b0cb81af875b5a8032cbd06c9a2dae",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 181.85,
      "commitsBetweenForRepo": 892,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,39 @@\n     private FSEditLogOp decodeOp() throws IOException {\n-      limiter.setLimit(MAX_OP_SIZE);\n-      in.mark(MAX_OP_SIZE);\n+      limiter.setLimit(maxOpSize);\n+      in.mark(maxOpSize);\n \n       if (checksum !\u003d null) {\n         checksum.reset();\n       }\n \n       byte opCodeByte;\n       try {\n         opCodeByte \u003d in.readByte();\n       } catch (EOFException eof) {\n         // EOF at an opcode boundary is expected.\n         return null;\n       }\n \n       FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n       if (opCode \u003d\u003d OP_INVALID) {\n         verifyTerminator();\n         return null;\n       }\n \n       FSEditLogOp op \u003d cache.get(opCode);\n       if (op \u003d\u003d null) {\n         throw new IOException(\"Read invalid opcode \" + opCode);\n       }\n \n       if (LayoutVersion.supports(Feature.STORED_TXIDS, logVersion)) {\n         // Read the txid\n         op.setTransactionId(in.readLong());\n       } else {\n         op.setTransactionId(HdfsConstants.INVALID_TXID);\n       }\n \n       op.readFields(in, logVersion);\n \n       validateChecksum(in, checksum, op.txid);\n       return op;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private FSEditLogOp decodeOp() throws IOException {\n      limiter.setLimit(maxOpSize);\n      in.mark(maxOpSize);\n\n      if (checksum !\u003d null) {\n        checksum.reset();\n      }\n\n      byte opCodeByte;\n      try {\n        opCodeByte \u003d in.readByte();\n      } catch (EOFException eof) {\n        // EOF at an opcode boundary is expected.\n        return null;\n      }\n\n      FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n      if (opCode \u003d\u003d OP_INVALID) {\n        verifyTerminator();\n        return null;\n      }\n\n      FSEditLogOp op \u003d cache.get(opCode);\n      if (op \u003d\u003d null) {\n        throw new IOException(\"Read invalid opcode \" + opCode);\n      }\n\n      if (LayoutVersion.supports(Feature.STORED_TXIDS, logVersion)) {\n        // Read the txid\n        op.setTransactionId(in.readLong());\n      } else {\n        op.setTransactionId(HdfsConstants.INVALID_TXID);\n      }\n\n      op.readFields(in, logVersion);\n\n      validateChecksum(in, checksum, op.txid);\n      return op;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "19dd66a3f616cd8a4527f2adeef911a7d4b3f349": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3510.  Editlog pre-allocation is performed prior to writing edits to avoid partial edits case disk out of space. Contributed by Collin McCabe.\n        \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1355189 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/06/12 4:00 PM",
      "commitName": "19dd66a3f616cd8a4527f2adeef911a7d4b3f349",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "11/06/12 11:01 AM",
      "commitNameOld": "56d2ef6f5ed25055f19eb61e02c52fb9237a78b7",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 17.21,
      "commitsBetweenForRepo": 80,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,39 @@\n     private FSEditLogOp decodeOp() throws IOException {\n+      limiter.setLimit(MAX_OP_SIZE);\n+      in.mark(MAX_OP_SIZE);\n+\n       if (checksum !\u003d null) {\n         checksum.reset();\n       }\n \n       byte opCodeByte;\n       try {\n         opCodeByte \u003d in.readByte();\n       } catch (EOFException eof) {\n         // EOF at an opcode boundary is expected.\n         return null;\n       }\n \n       FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n       if (opCode \u003d\u003d OP_INVALID) {\n         verifyTerminator();\n         return null;\n       }\n \n       FSEditLogOp op \u003d cache.get(opCode);\n       if (op \u003d\u003d null) {\n         throw new IOException(\"Read invalid opcode \" + opCode);\n       }\n \n       if (LayoutVersion.supports(Feature.STORED_TXIDS, logVersion)) {\n         // Read the txid\n         op.setTransactionId(in.readLong());\n       } else {\n         op.setTransactionId(HdfsConstants.INVALID_TXID);\n       }\n \n       op.readFields(in, logVersion);\n \n       validateChecksum(in, checksum, op.txid);\n       return op;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private FSEditLogOp decodeOp() throws IOException {\n      limiter.setLimit(MAX_OP_SIZE);\n      in.mark(MAX_OP_SIZE);\n\n      if (checksum !\u003d null) {\n        checksum.reset();\n      }\n\n      byte opCodeByte;\n      try {\n        opCodeByte \u003d in.readByte();\n      } catch (EOFException eof) {\n        // EOF at an opcode boundary is expected.\n        return null;\n      }\n\n      FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n      if (opCode \u003d\u003d OP_INVALID) {\n        verifyTerminator();\n        return null;\n      }\n\n      FSEditLogOp op \u003d cache.get(opCode);\n      if (op \u003d\u003d null) {\n        throw new IOException(\"Read invalid opcode \" + opCode);\n      }\n\n      if (LayoutVersion.supports(Feature.STORED_TXIDS, logVersion)) {\n        // Read the txid\n        op.setTransactionId(in.readLong());\n      } else {\n        op.setTransactionId(HdfsConstants.INVALID_TXID);\n      }\n\n      op.readFields(in, logVersion);\n\n      validateChecksum(in, checksum, op.txid);\n      return op;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "95710c15b7a724897bcde826e112df6d4b4fe56b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3335. check for edit log corruption at the end of the log. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1338492 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/05/12 5:41 PM",
      "commitName": "95710c15b7a724897bcde826e112df6d4b4fe56b",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "10/05/12 4:13 PM",
      "commitNameOld": "98b00d7cc015555642068827e6c52eaed0740c94",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 4.06,
      "commitsBetweenForRepo": 24,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,36 @@\n     private FSEditLogOp decodeOp() throws IOException {\n       if (checksum !\u003d null) {\n         checksum.reset();\n       }\n \n       byte opCodeByte;\n       try {\n         opCodeByte \u003d in.readByte();\n       } catch (EOFException eof) {\n         // EOF at an opcode boundary is expected.\n         return null;\n       }\n \n       FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n-      if (opCode \u003d\u003d OP_INVALID)\n+      if (opCode \u003d\u003d OP_INVALID) {\n+        verifyTerminator();\n         return null;\n+      }\n \n       FSEditLogOp op \u003d cache.get(opCode);\n       if (op \u003d\u003d null) {\n         throw new IOException(\"Read invalid opcode \" + opCode);\n       }\n \n       if (LayoutVersion.supports(Feature.STORED_TXIDS, logVersion)) {\n         // Read the txid\n         op.setTransactionId(in.readLong());\n       } else {\n         op.setTransactionId(HdfsConstants.INVALID_TXID);\n       }\n \n       op.readFields(in, logVersion);\n \n       validateChecksum(in, checksum, op.txid);\n       return op;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private FSEditLogOp decodeOp() throws IOException {\n      if (checksum !\u003d null) {\n        checksum.reset();\n      }\n\n      byte opCodeByte;\n      try {\n        opCodeByte \u003d in.readByte();\n      } catch (EOFException eof) {\n        // EOF at an opcode boundary is expected.\n        return null;\n      }\n\n      FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n      if (opCode \u003d\u003d OP_INVALID) {\n        verifyTerminator();\n        return null;\n      }\n\n      FSEditLogOp op \u003d cache.get(opCode);\n      if (op \u003d\u003d null) {\n        throw new IOException(\"Read invalid opcode \" + opCode);\n      }\n\n      if (LayoutVersion.supports(Feature.STORED_TXIDS, logVersion)) {\n        // Read the txid\n        op.setTransactionId(in.readLong());\n      } else {\n        op.setTransactionId(HdfsConstants.INVALID_TXID);\n      }\n\n      op.readFields(in, logVersion);\n\n      validateChecksum(in, checksum, op.txid);\n      return op;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "706394d03992b394e9f907aff2155df493e4ea4e": {
      "type": "Ymultichange(Yrename,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-3004. Implement Recovery Mode. Contributed by Colin Patrick McCabe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311394 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/04/12 12:39 PM",
      "commitName": "706394d03992b394e9f907aff2155df493e4ea4e",
      "commitAuthor": "Eli Collins",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-3004. Implement Recovery Mode. Contributed by Colin Patrick McCabe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311394 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "09/04/12 12:39 PM",
          "commitName": "706394d03992b394e9f907aff2155df493e4ea4e",
          "commitAuthor": "Eli Collins",
          "commitDateOld": "04/04/12 5:02 PM",
          "commitNameOld": "4f6e0a5a659064e0af3bec315e7c25d5e43b47f5",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 4.82,
          "commitsBetweenForRepo": 36,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,36 +1,34 @@\n-    public FSEditLogOp readOp() throws IOException {\n+    private FSEditLogOp decodeOp() throws IOException {\n       if (checksum !\u003d null) {\n         checksum.reset();\n       }\n \n-      in.mark(1);\n-\n       byte opCodeByte;\n       try {\n         opCodeByte \u003d in.readByte();\n       } catch (EOFException eof) {\n         // EOF at an opcode boundary is expected.\n         return null;\n       }\n \n       FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n-      if (opCode \u003d\u003d OP_INVALID) {\n-        in.reset(); // reset back to end of file if somebody reads it again\n+      if (opCode \u003d\u003d OP_INVALID)\n         return null;\n-      }\n \n-      FSEditLogOp op \u003d opInstances.get().get(opCode);\n+      FSEditLogOp op \u003d cache.get(opCode);\n       if (op \u003d\u003d null) {\n         throw new IOException(\"Read invalid opcode \" + opCode);\n       }\n \n       if (LayoutVersion.supports(Feature.STORED_TXIDS, logVersion)) {\n         // Read the txid\n         op.setTransactionId(in.readLong());\n+      } else {\n+        op.setTransactionId(HdfsConstants.INVALID_TXID);\n       }\n \n       op.readFields(in, logVersion);\n \n       validateChecksum(in, checksum, op.txid);\n       return op;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private FSEditLogOp decodeOp() throws IOException {\n      if (checksum !\u003d null) {\n        checksum.reset();\n      }\n\n      byte opCodeByte;\n      try {\n        opCodeByte \u003d in.readByte();\n      } catch (EOFException eof) {\n        // EOF at an opcode boundary is expected.\n        return null;\n      }\n\n      FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n      if (opCode \u003d\u003d OP_INVALID)\n        return null;\n\n      FSEditLogOp op \u003d cache.get(opCode);\n      if (op \u003d\u003d null) {\n        throw new IOException(\"Read invalid opcode \" + opCode);\n      }\n\n      if (LayoutVersion.supports(Feature.STORED_TXIDS, logVersion)) {\n        // Read the txid\n        op.setTransactionId(in.readLong());\n      } else {\n        op.setTransactionId(HdfsConstants.INVALID_TXID);\n      }\n\n      op.readFields(in, logVersion);\n\n      validateChecksum(in, checksum, op.txid);\n      return op;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
          "extendedDetails": {
            "oldValue": "readOp",
            "newValue": "decodeOp"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-3004. Implement Recovery Mode. Contributed by Colin Patrick McCabe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311394 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "09/04/12 12:39 PM",
          "commitName": "706394d03992b394e9f907aff2155df493e4ea4e",
          "commitAuthor": "Eli Collins",
          "commitDateOld": "04/04/12 5:02 PM",
          "commitNameOld": "4f6e0a5a659064e0af3bec315e7c25d5e43b47f5",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 4.82,
          "commitsBetweenForRepo": 36,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,36 +1,34 @@\n-    public FSEditLogOp readOp() throws IOException {\n+    private FSEditLogOp decodeOp() throws IOException {\n       if (checksum !\u003d null) {\n         checksum.reset();\n       }\n \n-      in.mark(1);\n-\n       byte opCodeByte;\n       try {\n         opCodeByte \u003d in.readByte();\n       } catch (EOFException eof) {\n         // EOF at an opcode boundary is expected.\n         return null;\n       }\n \n       FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n-      if (opCode \u003d\u003d OP_INVALID) {\n-        in.reset(); // reset back to end of file if somebody reads it again\n+      if (opCode \u003d\u003d OP_INVALID)\n         return null;\n-      }\n \n-      FSEditLogOp op \u003d opInstances.get().get(opCode);\n+      FSEditLogOp op \u003d cache.get(opCode);\n       if (op \u003d\u003d null) {\n         throw new IOException(\"Read invalid opcode \" + opCode);\n       }\n \n       if (LayoutVersion.supports(Feature.STORED_TXIDS, logVersion)) {\n         // Read the txid\n         op.setTransactionId(in.readLong());\n+      } else {\n+        op.setTransactionId(HdfsConstants.INVALID_TXID);\n       }\n \n       op.readFields(in, logVersion);\n \n       validateChecksum(in, checksum, op.txid);\n       return op;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private FSEditLogOp decodeOp() throws IOException {\n      if (checksum !\u003d null) {\n        checksum.reset();\n      }\n\n      byte opCodeByte;\n      try {\n        opCodeByte \u003d in.readByte();\n      } catch (EOFException eof) {\n        // EOF at an opcode boundary is expected.\n        return null;\n      }\n\n      FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n      if (opCode \u003d\u003d OP_INVALID)\n        return null;\n\n      FSEditLogOp op \u003d cache.get(opCode);\n      if (op \u003d\u003d null) {\n        throw new IOException(\"Read invalid opcode \" + opCode);\n      }\n\n      if (LayoutVersion.supports(Feature.STORED_TXIDS, logVersion)) {\n        // Read the txid\n        op.setTransactionId(in.readLong());\n      } else {\n        op.setTransactionId(HdfsConstants.INVALID_TXID);\n      }\n\n      op.readFields(in, logVersion);\n\n      validateChecksum(in, checksum, op.txid);\n      return op;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3004. Implement Recovery Mode. Contributed by Colin Patrick McCabe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311394 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "09/04/12 12:39 PM",
          "commitName": "706394d03992b394e9f907aff2155df493e4ea4e",
          "commitAuthor": "Eli Collins",
          "commitDateOld": "04/04/12 5:02 PM",
          "commitNameOld": "4f6e0a5a659064e0af3bec315e7c25d5e43b47f5",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 4.82,
          "commitsBetweenForRepo": 36,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,36 +1,34 @@\n-    public FSEditLogOp readOp() throws IOException {\n+    private FSEditLogOp decodeOp() throws IOException {\n       if (checksum !\u003d null) {\n         checksum.reset();\n       }\n \n-      in.mark(1);\n-\n       byte opCodeByte;\n       try {\n         opCodeByte \u003d in.readByte();\n       } catch (EOFException eof) {\n         // EOF at an opcode boundary is expected.\n         return null;\n       }\n \n       FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n-      if (opCode \u003d\u003d OP_INVALID) {\n-        in.reset(); // reset back to end of file if somebody reads it again\n+      if (opCode \u003d\u003d OP_INVALID)\n         return null;\n-      }\n \n-      FSEditLogOp op \u003d opInstances.get().get(opCode);\n+      FSEditLogOp op \u003d cache.get(opCode);\n       if (op \u003d\u003d null) {\n         throw new IOException(\"Read invalid opcode \" + opCode);\n       }\n \n       if (LayoutVersion.supports(Feature.STORED_TXIDS, logVersion)) {\n         // Read the txid\n         op.setTransactionId(in.readLong());\n+      } else {\n+        op.setTransactionId(HdfsConstants.INVALID_TXID);\n       }\n \n       op.readFields(in, logVersion);\n \n       validateChecksum(in, checksum, op.txid);\n       return op;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private FSEditLogOp decodeOp() throws IOException {\n      if (checksum !\u003d null) {\n        checksum.reset();\n      }\n\n      byte opCodeByte;\n      try {\n        opCodeByte \u003d in.readByte();\n      } catch (EOFException eof) {\n        // EOF at an opcode boundary is expected.\n        return null;\n      }\n\n      FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n      if (opCode \u003d\u003d OP_INVALID)\n        return null;\n\n      FSEditLogOp op \u003d cache.get(opCode);\n      if (op \u003d\u003d null) {\n        throw new IOException(\"Read invalid opcode \" + opCode);\n      }\n\n      if (LayoutVersion.supports(Feature.STORED_TXIDS, logVersion)) {\n        // Read the txid\n        op.setTransactionId(in.readLong());\n      } else {\n        op.setTransactionId(HdfsConstants.INVALID_TXID);\n      }\n\n      op.readFields(in, logVersion);\n\n      validateChecksum(in, checksum, op.txid);\n      return op;\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public FSEditLogOp readOp() throws IOException {\n      if (checksum !\u003d null) {\n        checksum.reset();\n      }\n\n      in.mark(1);\n\n      byte opCodeByte;\n      try {\n        opCodeByte \u003d in.readByte();\n      } catch (EOFException eof) {\n        // EOF at an opcode boundary is expected.\n        return null;\n      }\n\n      FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n      if (opCode \u003d\u003d OP_INVALID) {\n        in.reset(); // reset back to end of file if somebody reads it again\n        return null;\n      }\n\n      FSEditLogOp op \u003d opInstances.get().get(opCode);\n      if (op \u003d\u003d null) {\n        throw new IOException(\"Read invalid opcode \" + opCode);\n      }\n\n      if (LayoutVersion.supports(Feature.STORED_TXIDS, logVersion)) {\n        // Read the txid\n        op.setTransactionId(in.readLong());\n      }\n\n      op.readFields(in, logVersion);\n\n      validateChecksum(in, checksum, op.txid);\n      return op;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public FSEditLogOp readOp() throws IOException {\n      if (checksum !\u003d null) {\n        checksum.reset();\n      }\n\n      in.mark(1);\n\n      byte opCodeByte;\n      try {\n        opCodeByte \u003d in.readByte();\n      } catch (EOFException eof) {\n        // EOF at an opcode boundary is expected.\n        return null;\n      }\n\n      FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n      if (opCode \u003d\u003d OP_INVALID) {\n        in.reset(); // reset back to end of file if somebody reads it again\n        return null;\n      }\n\n      FSEditLogOp op \u003d opInstances.get().get(opCode);\n      if (op \u003d\u003d null) {\n        throw new IOException(\"Read invalid opcode \" + opCode);\n      }\n\n      if (LayoutVersion.supports(Feature.STORED_TXIDS, logVersion)) {\n        // Read the txid\n        op.setTransactionId(in.readLong());\n      }\n\n      op.readFields(in, logVersion);\n\n      validateChecksum(in, checksum, op.txid);\n      return op;\n    }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java"
      }
    },
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/11 9:28 AM",
      "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "27/07/11 10:46 PM",
      "commitNameOld": "44320eed1732ea59bd9ec83009eb10e0e6f13023",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 1.45,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,36 @@\n     public FSEditLogOp readOp() throws IOException {\n       if (checksum !\u003d null) {\n         checksum.reset();\n       }\n \n       in.mark(1);\n \n       byte opCodeByte;\n       try {\n         opCodeByte \u003d in.readByte();\n       } catch (EOFException eof) {\n         // EOF at an opcode boundary is expected.\n         return null;\n       }\n \n       FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n       if (opCode \u003d\u003d OP_INVALID) {\n         in.reset(); // reset back to end of file if somebody reads it again\n         return null;\n       }\n \n       FSEditLogOp op \u003d opInstances.get().get(opCode);\n       if (op \u003d\u003d null) {\n         throw new IOException(\"Read invalid opcode \" + opCode);\n       }\n+\n+      if (LayoutVersion.supports(Feature.STORED_TXIDS, logVersion)) {\n+        // Read the txid\n+        op.setTransactionId(in.readLong());\n+      }\n+\n       op.readFields(in, logVersion);\n \n-      validateChecksum(in, checksum);\n+      validateChecksum(in, checksum, op.txid);\n       return op;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public FSEditLogOp readOp() throws IOException {\n      if (checksum !\u003d null) {\n        checksum.reset();\n      }\n\n      in.mark(1);\n\n      byte opCodeByte;\n      try {\n        opCodeByte \u003d in.readByte();\n      } catch (EOFException eof) {\n        // EOF at an opcode boundary is expected.\n        return null;\n      }\n\n      FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n      if (opCode \u003d\u003d OP_INVALID) {\n        in.reset(); // reset back to end of file if somebody reads it again\n        return null;\n      }\n\n      FSEditLogOp op \u003d opInstances.get().get(opCode);\n      if (op \u003d\u003d null) {\n        throw new IOException(\"Read invalid opcode \" + opCode);\n      }\n\n      if (LayoutVersion.supports(Feature.STORED_TXIDS, logVersion)) {\n        // Read the txid\n        op.setTransactionId(in.readLong());\n      }\n\n      op.readFields(in, logVersion);\n\n      validateChecksum(in, checksum, op.txid);\n      return op;\n    }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2149. Move EditLogOp serialization formats into FsEditLogOp implementations. Contributed by Ivan Kelly.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1151238 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/07/11 1:46 PM",
      "commitName": "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "28/06/11 6:31 PM",
      "commitNameOld": "09b6f98de431628c80bc8a6faf0070eeaf72ff2a",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 27.8,
      "commitsBetweenForRepo": 92,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,30 @@\n     public FSEditLogOp readOp() throws IOException {\n       if (checksum !\u003d null) {\n         checksum.reset();\n       }\n \n       in.mark(1);\n \n       byte opCodeByte;\n       try {\n         opCodeByte \u003d in.readByte();\n       } catch (EOFException eof) {\n         // EOF at an opcode boundary is expected.\n         return null;\n       }\n \n       FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n       if (opCode \u003d\u003d OP_INVALID) {\n         in.reset(); // reset back to end of file if somebody reads it again\n         return null;\n       }\n \n-      FSEditLogOp op \u003d opInstances.get(opCode);\n+      FSEditLogOp op \u003d opInstances.get().get(opCode);\n       if (op \u003d\u003d null) {\n         throw new IOException(\"Read invalid opcode \" + opCode);\n       }\n       op.readFields(in, logVersion);\n \n       validateChecksum(in, checksum);\n       return op;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public FSEditLogOp readOp() throws IOException {\n      if (checksum !\u003d null) {\n        checksum.reset();\n      }\n\n      in.mark(1);\n\n      byte opCodeByte;\n      try {\n        opCodeByte \u003d in.readByte();\n      } catch (EOFException eof) {\n        // EOF at an opcode boundary is expected.\n        return null;\n      }\n\n      FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n      if (opCode \u003d\u003d OP_INVALID) {\n        in.reset(); // reset back to end of file if somebody reads it again\n        return null;\n      }\n\n      FSEditLogOp op \u003d opInstances.get().get(opCode);\n      if (op \u003d\u003d null) {\n        throw new IOException(\"Read invalid opcode \" + opCode);\n      }\n      op.readFields(in, logVersion);\n\n      validateChecksum(in, checksum);\n      return op;\n    }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,30 @@\n+    public FSEditLogOp readOp() throws IOException {\n+      if (checksum !\u003d null) {\n+        checksum.reset();\n+      }\n+\n+      in.mark(1);\n+\n+      byte opCodeByte;\n+      try {\n+        opCodeByte \u003d in.readByte();\n+      } catch (EOFException eof) {\n+        // EOF at an opcode boundary is expected.\n+        return null;\n+      }\n+\n+      FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n+      if (opCode \u003d\u003d OP_INVALID) {\n+        in.reset(); // reset back to end of file if somebody reads it again\n+        return null;\n+      }\n+\n+      FSEditLogOp op \u003d opInstances.get(opCode);\n+      if (op \u003d\u003d null) {\n+        throw new IOException(\"Read invalid opcode \" + opCode);\n+      }\n+      op.readFields(in, logVersion);\n+\n+      validateChecksum(in, checksum);\n+      return op;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public FSEditLogOp readOp() throws IOException {\n      if (checksum !\u003d null) {\n        checksum.reset();\n      }\n\n      in.mark(1);\n\n      byte opCodeByte;\n      try {\n        opCodeByte \u003d in.readByte();\n      } catch (EOFException eof) {\n        // EOF at an opcode boundary is expected.\n        return null;\n      }\n\n      FSEditLogOpCodes opCode \u003d FSEditLogOpCodes.fromByte(opCodeByte);\n      if (opCode \u003d\u003d OP_INVALID) {\n        in.reset(); // reset back to end of file if somebody reads it again\n        return null;\n      }\n\n      FSEditLogOp op \u003d opInstances.get(opCode);\n      if (op \u003d\u003d null) {\n        throw new IOException(\"Read invalid opcode \" + opCode);\n      }\n      op.readFields(in, logVersion);\n\n      validateChecksum(in, checksum);\n      return op;\n    }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java"
    }
  }
}