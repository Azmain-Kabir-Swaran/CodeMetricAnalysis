{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSOutputStream.java",
  "functionName": "computePacketChunkSize",
  "functionId": "computePacketChunkSize___psize-int__csize-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
  "functionStartLine": 412,
  "functionEndLine": 420,
  "numCommitsSeen": 146,
  "timeTaken": 8160,
  "changeHistory": [
    "39285e6a1978ea5e53bdc1b0aef62421382124a8",
    "6ee0539ede78b640f01c5eac18ded161182a7835",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "9ed43f2189fb4674b7379e8e995d53d4970d5c3a",
    "a979f3b58fafebbd6118ec1f861cf3f62c59c9cb",
    "463aec11718e47d4aabb86a7a539cb973460aae6",
    "9ea7c06468d236452f03c38a31d1a45f7f09dc50",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": "Ybodychange",
    "6ee0539ede78b640f01c5eac18ded161182a7835": "Ybodychange",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": "Ybodychange",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "9ed43f2189fb4674b7379e8e995d53d4970d5c3a": "Ymodifierchange",
    "a979f3b58fafebbd6118ec1f861cf3f62c59c9cb": "Ybodychange",
    "463aec11718e47d4aabb86a7a539cb973460aae6": "Ybodychange",
    "9ea7c06468d236452f03c38a31d1a45f7f09dc50": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8971. Remove guards when calling LOG.debug() and LOG.trace() in client package. Contributed by Mingliang Liu.\n",
      "commitDate": "29/09/15 5:52 PM",
      "commitName": "39285e6a1978ea5e53bdc1b0aef62421382124a8",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:51 PM",
      "commitNameOld": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,9 @@\n   protected void computePacketChunkSize(int psize, int csize) {\n     final int bodySize \u003d psize - PacketHeader.PKT_MAX_HEADER_LEN;\n     final int chunkSize \u003d csize + getChecksumSize();\n     chunksPerPacket \u003d Math.max(bodySize/chunkSize, 1);\n     packetSize \u003d chunkSize*chunksPerPacket;\n-    if (DFSClient.LOG.isDebugEnabled()) {\n-      DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d\" + src +\n-                \", chunkSize\u003d\" + chunkSize +\n-                \", chunksPerPacket\u003d\" + chunksPerPacket +\n-                \", packetSize\u003d\" + packetSize);\n-    }\n+    DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d{}, chunkSize\u003d{}, \"\n+            + \"chunksPerPacket\u003d{}, packetSize\u003d{}\",\n+        src, chunkSize, chunksPerPacket, packetSize);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void computePacketChunkSize(int psize, int csize) {\n    final int bodySize \u003d psize - PacketHeader.PKT_MAX_HEADER_LEN;\n    final int chunkSize \u003d csize + getChecksumSize();\n    chunksPerPacket \u003d Math.max(bodySize/chunkSize, 1);\n    packetSize \u003d chunkSize*chunksPerPacket;\n    DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d{}, chunkSize\u003d{}, \"\n            + \"chunksPerPacket\u003d{}, packetSize\u003d{}\",\n        src, chunkSize, chunksPerPacket, packetSize);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "6ee0539ede78b640f01c5eac18ded161182a7835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\"\n\nThis reverts commit d5a9a3daa0224249221ffa7b8bd5751ab2feca56.\n",
      "commitDate": "29/09/15 5:51 PM",
      "commitName": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:48 PM",
      "commitNameOld": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,12 @@\n   protected void computePacketChunkSize(int psize, int csize) {\n     final int bodySize \u003d psize - PacketHeader.PKT_MAX_HEADER_LEN;\n     final int chunkSize \u003d csize + getChecksumSize();\n     chunksPerPacket \u003d Math.max(bodySize/chunkSize, 1);\n     packetSize \u003d chunkSize*chunksPerPacket;\n-    DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d{}, chunkSize\u003d{}, \"\n-            + \"chunksPerPacket\u003d{}, packetSize\u003d{}\",\n-        src, chunkSize, chunksPerPacket, packetSize);\n+    if (DFSClient.LOG.isDebugEnabled()) {\n+      DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d\" + src +\n+                \", chunkSize\u003d\" + chunkSize +\n+                \", chunksPerPacket\u003d\" + chunksPerPacket +\n+                \", packetSize\u003d\" + packetSize);\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void computePacketChunkSize(int psize, int csize) {\n    final int bodySize \u003d psize - PacketHeader.PKT_MAX_HEADER_LEN;\n    final int chunkSize \u003d csize + getChecksumSize();\n    chunksPerPacket \u003d Math.max(bodySize/chunkSize, 1);\n    packetSize \u003d chunkSize*chunksPerPacket;\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d\" + src +\n                \", chunkSize\u003d\" + chunkSize +\n                \", chunksPerPacket\u003d\" + chunksPerPacket +\n                \", packetSize\u003d\" + packetSize);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "29/09/15 5:48 PM",
      "commitName": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/09/15 7:42 AM",
      "commitNameOld": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 1.42,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,9 @@\n   protected void computePacketChunkSize(int psize, int csize) {\n     final int bodySize \u003d psize - PacketHeader.PKT_MAX_HEADER_LEN;\n     final int chunkSize \u003d csize + getChecksumSize();\n     chunksPerPacket \u003d Math.max(bodySize/chunkSize, 1);\n     packetSize \u003d chunkSize*chunksPerPacket;\n-    if (DFSClient.LOG.isDebugEnabled()) {\n-      DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d\" + src +\n-                \", chunkSize\u003d\" + chunkSize +\n-                \", chunksPerPacket\u003d\" + chunksPerPacket +\n-                \", packetSize\u003d\" + packetSize);\n-    }\n+    DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d{}, chunkSize\u003d{}, \"\n+            + \"chunksPerPacket\u003d{}, packetSize\u003d{}\",\n+        src, chunkSize, chunksPerPacket, packetSize);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void computePacketChunkSize(int psize, int csize) {\n    final int bodySize \u003d psize - PacketHeader.PKT_MAX_HEADER_LEN;\n    final int chunkSize \u003d csize + getChecksumSize();\n    chunksPerPacket \u003d Math.max(bodySize/chunkSize, 1);\n    packetSize \u003d chunkSize*chunksPerPacket;\n    DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d{}, chunkSize\u003d{}, \"\n            + \"chunksPerPacket\u003d{}, packetSize\u003d{}\",\n        src, chunkSize, chunksPerPacket, packetSize);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected void computePacketChunkSize(int psize, int csize) {\n    final int bodySize \u003d psize - PacketHeader.PKT_MAX_HEADER_LEN;\n    final int chunkSize \u003d csize + getChecksumSize();\n    chunksPerPacket \u003d Math.max(bodySize/chunkSize, 1);\n    packetSize \u003d chunkSize*chunksPerPacket;\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d\" + src +\n                \", chunkSize\u003d\" + chunkSize +\n                \", chunksPerPacket\u003d\" + chunksPerPacket +\n                \", packetSize\u003d\" + packetSize);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java"
      }
    },
    "9ed43f2189fb4674b7379e8e995d53d4970d5c3a": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-7888. Change DFSOutputStream and DataStreamer for convenience of subclassing. Contributed by Li Bo\n",
      "commitDate": "02/04/15 10:59 AM",
      "commitName": "9ed43f2189fb4674b7379e8e995d53d4970d5c3a",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "01/04/15 2:10 PM",
      "commitNameOld": "c94d594a57806dec515e2a2053a1221f8ce48cc4",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 0.87,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n-  private void computePacketChunkSize(int psize, int csize) {\n+  protected void computePacketChunkSize(int psize, int csize) {\n     final int bodySize \u003d psize - PacketHeader.PKT_MAX_HEADER_LEN;\n     final int chunkSize \u003d csize + getChecksumSize();\n     chunksPerPacket \u003d Math.max(bodySize/chunkSize, 1);\n     packetSize \u003d chunkSize*chunksPerPacket;\n     if (DFSClient.LOG.isDebugEnabled()) {\n       DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d\" + src +\n                 \", chunkSize\u003d\" + chunkSize +\n                 \", chunksPerPacket\u003d\" + chunksPerPacket +\n                 \", packetSize\u003d\" + packetSize);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void computePacketChunkSize(int psize, int csize) {\n    final int bodySize \u003d psize - PacketHeader.PKT_MAX_HEADER_LEN;\n    final int chunkSize \u003d csize + getChecksumSize();\n    chunksPerPacket \u003d Math.max(bodySize/chunkSize, 1);\n    packetSize \u003d chunkSize*chunksPerPacket;\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d\" + src +\n                \", chunkSize\u003d\" + chunkSize +\n                \", chunksPerPacket\u003d\" + chunksPerPacket +\n                \", packetSize\u003d\" + packetSize);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {
        "oldValue": "[private]",
        "newValue": "[protected]"
      }
    },
    "a979f3b58fafebbd6118ec1f861cf3f62c59c9cb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7308. Change the packet chunk size computation in DFSOutputStream in order to enforce packet size \u003c\u003d 64kB.  Contributed by Takuya Fukudome\n",
      "commitDate": "27/02/15 7:45 AM",
      "commitName": "a979f3b58fafebbd6118ec1f861cf3f62c59c9cb",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "21/02/15 3:38 PM",
      "commitNameOld": "8b465b4b8caed31ca9daeaae108f9a868a30a455",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 5.67,
      "commitsBetweenForRepo": 45,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,12 @@\n   private void computePacketChunkSize(int psize, int csize) {\n+    final int bodySize \u003d psize - PacketHeader.PKT_MAX_HEADER_LEN;\n     final int chunkSize \u003d csize + getChecksumSize();\n-    chunksPerPacket \u003d Math.max(psize/chunkSize, 1);\n+    chunksPerPacket \u003d Math.max(bodySize/chunkSize, 1);\n     packetSize \u003d chunkSize*chunksPerPacket;\n     if (DFSClient.LOG.isDebugEnabled()) {\n       DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d\" + src +\n                 \", chunkSize\u003d\" + chunkSize +\n                 \", chunksPerPacket\u003d\" + chunksPerPacket +\n                 \", packetSize\u003d\" + packetSize);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void computePacketChunkSize(int psize, int csize) {\n    final int bodySize \u003d psize - PacketHeader.PKT_MAX_HEADER_LEN;\n    final int chunkSize \u003d csize + getChecksumSize();\n    chunksPerPacket \u003d Math.max(bodySize/chunkSize, 1);\n    packetSize \u003d chunkSize*chunksPerPacket;\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d\" + src +\n                \", chunkSize\u003d\" + chunkSize +\n                \", chunksPerPacket\u003d\" + chunksPerPacket +\n                \", packetSize\u003d\" + packetSize);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "463aec11718e47d4aabb86a7a539cb973460aae6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6934. Move checksum computation off the hot path when writing to RAM disk. Contributed by Chris Nauroth.\n",
      "commitDate": "27/10/14 9:38 AM",
      "commitName": "463aec11718e47d4aabb86a7a539cb973460aae6",
      "commitAuthor": "cnauroth",
      "commitDateOld": "17/10/14 6:30 PM",
      "commitNameOld": "2e140523d3ccb27809cde4a55e95f7e0006c028f",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 9.63,
      "commitsBetweenForRepo": 71,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n   private void computePacketChunkSize(int psize, int csize) {\n-    int chunkSize \u003d csize + checksum.getChecksumSize();\n+    final int chunkSize \u003d csize + getChecksumSize();\n     chunksPerPacket \u003d Math.max(psize/chunkSize, 1);\n     packetSize \u003d chunkSize*chunksPerPacket;\n     if (DFSClient.LOG.isDebugEnabled()) {\n       DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d\" + src +\n                 \", chunkSize\u003d\" + chunkSize +\n                 \", chunksPerPacket\u003d\" + chunksPerPacket +\n                 \", packetSize\u003d\" + packetSize);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void computePacketChunkSize(int psize, int csize) {\n    final int chunkSize \u003d csize + getChecksumSize();\n    chunksPerPacket \u003d Math.max(psize/chunkSize, 1);\n    packetSize \u003d chunkSize*chunksPerPacket;\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d\" + src +\n                \", chunkSize\u003d\" + chunkSize +\n                \", chunksPerPacket\u003d\" + chunksPerPacket +\n                \", packetSize\u003d\" + packetSize);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "9ea7c06468d236452f03c38a31d1a45f7f09dc50": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3721. hsync support broke wire compatibility. Contributed by Todd Lipcon and Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1371495 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/08/12 2:31 PM",
      "commitName": "9ea7c06468d236452f03c38a31d1a45f7f09dc50",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "07/08/12 9:40 AM",
      "commitNameOld": "9b4a7900c7dfc0590316eedaa97144f938885651",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 2.2,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,11 @@\n   private void computePacketChunkSize(int psize, int csize) {\n     int chunkSize \u003d csize + checksum.getChecksumSize();\n-    int n \u003d PacketHeader.PKT_HEADER_LEN;\n-    chunksPerPacket \u003d Math.max((psize - n + chunkSize-1)/chunkSize, 1);\n-    packetSize \u003d n + chunkSize*chunksPerPacket;\n+    chunksPerPacket \u003d Math.max(psize/chunkSize, 1);\n+    packetSize \u003d chunkSize*chunksPerPacket;\n     if (DFSClient.LOG.isDebugEnabled()) {\n       DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d\" + src +\n                 \", chunkSize\u003d\" + chunkSize +\n                 \", chunksPerPacket\u003d\" + chunksPerPacket +\n                 \", packetSize\u003d\" + packetSize);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void computePacketChunkSize(int psize, int csize) {\n    int chunkSize \u003d csize + checksum.getChecksumSize();\n    chunksPerPacket \u003d Math.max(psize/chunkSize, 1);\n    packetSize \u003d chunkSize*chunksPerPacket;\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d\" + src +\n                \", chunkSize\u003d\" + chunkSize +\n                \", chunksPerPacket\u003d\" + chunksPerPacket +\n                \", packetSize\u003d\" + packetSize);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void computePacketChunkSize(int psize, int csize) {\n    int chunkSize \u003d csize + checksum.getChecksumSize();\n    int n \u003d PacketHeader.PKT_HEADER_LEN;\n    chunksPerPacket \u003d Math.max((psize - n + chunkSize-1)/chunkSize, 1);\n    packetSize \u003d n + chunkSize*chunksPerPacket;\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d\" + src +\n                \", chunkSize\u003d\" + chunkSize +\n                \", chunksPerPacket\u003d\" + chunksPerPacket +\n                \", packetSize\u003d\" + packetSize);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void computePacketChunkSize(int psize, int csize) {\n    int chunkSize \u003d csize + checksum.getChecksumSize();\n    int n \u003d PacketHeader.PKT_HEADER_LEN;\n    chunksPerPacket \u003d Math.max((psize - n + chunkSize-1)/chunkSize, 1);\n    packetSize \u003d n + chunkSize*chunksPerPacket;\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d\" + src +\n                \", chunkSize\u003d\" + chunkSize +\n                \", chunksPerPacket\u003d\" + chunksPerPacket +\n                \", packetSize\u003d\" + packetSize);\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,12 @@\n+  private void computePacketChunkSize(int psize, int csize) {\n+    int chunkSize \u003d csize + checksum.getChecksumSize();\n+    int n \u003d PacketHeader.PKT_HEADER_LEN;\n+    chunksPerPacket \u003d Math.max((psize - n + chunkSize-1)/chunkSize, 1);\n+    packetSize \u003d n + chunkSize*chunksPerPacket;\n+    if (DFSClient.LOG.isDebugEnabled()) {\n+      DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d\" + src +\n+                \", chunkSize\u003d\" + chunkSize +\n+                \", chunksPerPacket\u003d\" + chunksPerPacket +\n+                \", packetSize\u003d\" + packetSize);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void computePacketChunkSize(int psize, int csize) {\n    int chunkSize \u003d csize + checksum.getChecksumSize();\n    int n \u003d PacketHeader.PKT_HEADER_LEN;\n    chunksPerPacket \u003d Math.max((psize - n + chunkSize-1)/chunkSize, 1);\n    packetSize \u003d n + chunkSize*chunksPerPacket;\n    if (DFSClient.LOG.isDebugEnabled()) {\n      DFSClient.LOG.debug(\"computePacketChunkSize: src\u003d\" + src +\n                \", chunkSize\u003d\" + chunkSize +\n                \", chunksPerPacket\u003d\" + chunksPerPacket +\n                \", packetSize\u003d\" + packetSize);\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/DFSOutputStream.java"
    }
  }
}