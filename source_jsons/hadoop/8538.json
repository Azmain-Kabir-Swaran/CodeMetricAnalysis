{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImage.java",
  "functionName": "saveDigestAndRenameCheckpointImage",
  "functionId": "saveDigestAndRenameCheckpointImage___nnf-NameNodeFile__txid-long__digest-MD5Hash",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
  "functionStartLine": 1446,
  "functionEndLine": 1474,
  "numCommitsSeen": 195,
  "timeTaken": 5555,
  "changeHistory": [
    "4cfc8664362ed04b01872e854715a36dad9408a6",
    "e3d2e4c156851de7dac16154521a2e06ea83ec7b",
    "377424e36a25ab34bba9aaed5feaae9d293eb57f",
    "4f9bbaa301194e3d20972a10f51638c7f4d121f0",
    "807e08334eb51e3ef97caf00444e19b686164501",
    "4a5ba3b7bd2360fd9605863630b477d362874e1e",
    "1a75ec82885e45baf4d5cd56d6c738d8e68d8bc7",
    "a87328dfab96a335535e8952e548534b73c00b7c",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63"
  ],
  "changeHistoryShort": {
    "4cfc8664362ed04b01872e854715a36dad9408a6": "Ybodychange",
    "e3d2e4c156851de7dac16154521a2e06ea83ec7b": "Ymultichange(Yparameterchange,Ybodychange)",
    "377424e36a25ab34bba9aaed5feaae9d293eb57f": "Ybodychange",
    "4f9bbaa301194e3d20972a10f51638c7f4d121f0": "Ybodychange",
    "807e08334eb51e3ef97caf00444e19b686164501": "Ybodychange",
    "4a5ba3b7bd2360fd9605863630b477d362874e1e": "Ybodychange",
    "1a75ec82885e45baf4d5cd56d6c738d8e68d8bc7": "Ymodifierchange",
    "a87328dfab96a335535e8952e548534b73c00b7c": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4cfc8664362ed04b01872e854715a36dad9408a6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11714. Newly added NN storage directory won\u0027t get initialized and cause space exhaustion. Contributed by Kihwal Lee.\n",
      "commitDate": "01/05/17 3:29 PM",
      "commitName": "4cfc8664362ed04b01872e854715a36dad9408a6",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "17/01/17 2:33 PM",
      "commitNameOld": "b1fce2b8b14c4ce43f7098a269ac2b95304db0ce",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 104.0,
      "commitsBetweenForRepo": 578,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,29 @@\n   public synchronized void saveDigestAndRenameCheckpointImage(NameNodeFile nnf,\n       long txid, MD5Hash digest) throws IOException {\n     // Write and rename MD5 file\n     List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n     \n     for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n       File imageFile \u003d NNStorage.getImageFile(sd, nnf, txid);\n       try {\n         MD5FileUtils.saveMD5File(imageFile, digest);\n       } catch (IOException ioe) {\n         badSds.add(sd);\n       }\n     }\n     storage.reportErrorsOnDirectories(badSds);\n     \n     CheckpointFaultInjector.getInstance().afterMD5Rename();\n     \n     // Rename image from tmp file\n     renameCheckpoint(txid, NameNodeFile.IMAGE_NEW, nnf, false);\n     // So long as this is the newest image available,\n     // advertise it as such to other checkpointers\n     // from now on\n     if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n       storage.setMostRecentCheckpointInfo(txid, Time.now());\n     }\n+\n+    // Create a version file in any new storage directory.\n+    initNewDirs();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void saveDigestAndRenameCheckpointImage(NameNodeFile nnf,\n      long txid, MD5Hash digest) throws IOException {\n    // Write and rename MD5 file\n    List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n    \n    for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n      File imageFile \u003d NNStorage.getImageFile(sd, nnf, txid);\n      try {\n        MD5FileUtils.saveMD5File(imageFile, digest);\n      } catch (IOException ioe) {\n        badSds.add(sd);\n      }\n    }\n    storage.reportErrorsOnDirectories(badSds);\n    \n    CheckpointFaultInjector.getInstance().afterMD5Rename();\n    \n    // Rename image from tmp file\n    renameCheckpoint(txid, NameNodeFile.IMAGE_NEW, nnf, false);\n    // So long as this is the newest image available,\n    // advertise it as such to other checkpointers\n    // from now on\n    if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n      storage.setMostRecentCheckpointInfo(txid, Time.now());\n    }\n\n    // Create a version file in any new storage directory.\n    initNewDirs();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "e3d2e4c156851de7dac16154521a2e06ea83ec7b": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6000. Avoid saving namespace when starting rolling upgrade. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1571840 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/02/14 1:58 PM",
      "commitName": "e3d2e4c156851de7dac16154521a2e06ea83ec7b",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6000. Avoid saving namespace when starting rolling upgrade. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1571840 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "25/02/14 1:58 PM",
          "commitName": "e3d2e4c156851de7dac16154521a2e06ea83ec7b",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "23/02/14 1:35 PM",
          "commitNameOld": "8e7a2b8d5d9975690da20d3ff41d04f361171f0a",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 2.02,
          "commitsBetweenForRepo": 22,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,26 @@\n-  public synchronized void saveDigestAndRenameCheckpointImage(\n+  public synchronized void saveDigestAndRenameCheckpointImage(NameNodeFile nnf,\n       long txid, MD5Hash digest) throws IOException {\n     // Write and rename MD5 file\n     List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n     \n     for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n-      File imageFile \u003d NNStorage.getImageFile(sd, txid);\n+      File imageFile \u003d NNStorage.getImageFile(sd, nnf, txid);\n       try {\n         MD5FileUtils.saveMD5File(imageFile, digest);\n       } catch (IOException ioe) {\n         badSds.add(sd);\n       }\n     }\n     storage.reportErrorsOnDirectories(badSds);\n     \n     CheckpointFaultInjector.getInstance().afterMD5Rename();\n     \n     // Rename image from tmp file\n-    renameCheckpoint(txid, NameNodeFile.IMAGE_NEW, NameNodeFile.IMAGE, false);\n+    renameCheckpoint(txid, NameNodeFile.IMAGE_NEW, nnf, false);\n     // So long as this is the newest image available,\n     // advertise it as such to other checkpointers\n     // from now on\n     if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n       storage.setMostRecentCheckpointInfo(txid, Time.now());\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void saveDigestAndRenameCheckpointImage(NameNodeFile nnf,\n      long txid, MD5Hash digest) throws IOException {\n    // Write and rename MD5 file\n    List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n    \n    for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n      File imageFile \u003d NNStorage.getImageFile(sd, nnf, txid);\n      try {\n        MD5FileUtils.saveMD5File(imageFile, digest);\n      } catch (IOException ioe) {\n        badSds.add(sd);\n      }\n    }\n    storage.reportErrorsOnDirectories(badSds);\n    \n    CheckpointFaultInjector.getInstance().afterMD5Rename();\n    \n    // Rename image from tmp file\n    renameCheckpoint(txid, NameNodeFile.IMAGE_NEW, nnf, false);\n    // So long as this is the newest image available,\n    // advertise it as such to other checkpointers\n    // from now on\n    if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n      storage.setMostRecentCheckpointInfo(txid, Time.now());\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {
            "oldValue": "[txid-long, digest-MD5Hash]",
            "newValue": "[nnf-NameNodeFile, txid-long, digest-MD5Hash]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6000. Avoid saving namespace when starting rolling upgrade. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1571840 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "25/02/14 1:58 PM",
          "commitName": "e3d2e4c156851de7dac16154521a2e06ea83ec7b",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "23/02/14 1:35 PM",
          "commitNameOld": "8e7a2b8d5d9975690da20d3ff41d04f361171f0a",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 2.02,
          "commitsBetweenForRepo": 22,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,26 @@\n-  public synchronized void saveDigestAndRenameCheckpointImage(\n+  public synchronized void saveDigestAndRenameCheckpointImage(NameNodeFile nnf,\n       long txid, MD5Hash digest) throws IOException {\n     // Write and rename MD5 file\n     List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n     \n     for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n-      File imageFile \u003d NNStorage.getImageFile(sd, txid);\n+      File imageFile \u003d NNStorage.getImageFile(sd, nnf, txid);\n       try {\n         MD5FileUtils.saveMD5File(imageFile, digest);\n       } catch (IOException ioe) {\n         badSds.add(sd);\n       }\n     }\n     storage.reportErrorsOnDirectories(badSds);\n     \n     CheckpointFaultInjector.getInstance().afterMD5Rename();\n     \n     // Rename image from tmp file\n-    renameCheckpoint(txid, NameNodeFile.IMAGE_NEW, NameNodeFile.IMAGE, false);\n+    renameCheckpoint(txid, NameNodeFile.IMAGE_NEW, nnf, false);\n     // So long as this is the newest image available,\n     // advertise it as such to other checkpointers\n     // from now on\n     if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n       storage.setMostRecentCheckpointInfo(txid, Time.now());\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public synchronized void saveDigestAndRenameCheckpointImage(NameNodeFile nnf,\n      long txid, MD5Hash digest) throws IOException {\n    // Write and rename MD5 file\n    List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n    \n    for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n      File imageFile \u003d NNStorage.getImageFile(sd, nnf, txid);\n      try {\n        MD5FileUtils.saveMD5File(imageFile, digest);\n      } catch (IOException ioe) {\n        badSds.add(sd);\n      }\n    }\n    storage.reportErrorsOnDirectories(badSds);\n    \n    CheckpointFaultInjector.getInstance().afterMD5Rename();\n    \n    // Rename image from tmp file\n    renameCheckpoint(txid, NameNodeFile.IMAGE_NEW, nnf, false);\n    // So long as this is the newest image available,\n    // advertise it as such to other checkpointers\n    // from now on\n    if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n      storage.setMostRecentCheckpointInfo(txid, Time.now());\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
          "extendedDetails": {}
        }
      ]
    },
    "377424e36a25ab34bba9aaed5feaae9d293eb57f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5966. Fix rollback of rolling upgrade in NameNode HA setup.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1569885 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/02/14 11:41 AM",
      "commitName": "377424e36a25ab34bba9aaed5feaae9d293eb57f",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "18/02/14 12:12 PM",
      "commitNameOld": "bc962d6df470e3de18df3a4fd9f8a9853953bda1",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.98,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,26 @@\n   public synchronized void saveDigestAndRenameCheckpointImage(\n       long txid, MD5Hash digest) throws IOException {\n     // Write and rename MD5 file\n     List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n     \n     for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n       File imageFile \u003d NNStorage.getImageFile(sd, txid);\n       try {\n         MD5FileUtils.saveMD5File(imageFile, digest);\n       } catch (IOException ioe) {\n         badSds.add(sd);\n       }\n     }\n     storage.reportErrorsOnDirectories(badSds);\n     \n     CheckpointFaultInjector.getInstance().afterMD5Rename();\n     \n     // Rename image from tmp file\n-    renameCheckpoint(txid, NameNodeFile.IMAGE_NEW, NameNodeFile.IMAGE);\n+    renameCheckpoint(txid, NameNodeFile.IMAGE_NEW, NameNodeFile.IMAGE, false);\n     // So long as this is the newest image available,\n     // advertise it as such to other checkpointers\n     // from now on\n     if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n       storage.setMostRecentCheckpointInfo(txid, Time.now());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void saveDigestAndRenameCheckpointImage(\n      long txid, MD5Hash digest) throws IOException {\n    // Write and rename MD5 file\n    List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n    \n    for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n      File imageFile \u003d NNStorage.getImageFile(sd, txid);\n      try {\n        MD5FileUtils.saveMD5File(imageFile, digest);\n      } catch (IOException ioe) {\n        badSds.add(sd);\n      }\n    }\n    storage.reportErrorsOnDirectories(badSds);\n    \n    CheckpointFaultInjector.getInstance().afterMD5Rename();\n    \n    // Rename image from tmp file\n    renameCheckpoint(txid, NameNodeFile.IMAGE_NEW, NameNodeFile.IMAGE, false);\n    // So long as this is the newest image available,\n    // advertise it as such to other checkpointers\n    // from now on\n    if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n      storage.setMostRecentCheckpointInfo(txid, Time.now());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "4f9bbaa301194e3d20972a10f51638c7f4d121f0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5889. When starting rolling upgrade, create a fs image for rollback so that the standby namenode can create checkpoints during upgrade.  Contributed by szetszwo \u0026 jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1567861 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/02/14 12:04 AM",
      "commitName": "4f9bbaa301194e3d20972a10f51638c7f4d121f0",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "06/02/14 6:08 PM",
      "commitNameOld": "c780454413caffbc37a02c4252eb5ec7abe57f97",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 6.25,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,26 @@\n   public synchronized void saveDigestAndRenameCheckpointImage(\n       long txid, MD5Hash digest) throws IOException {\n     // Write and rename MD5 file\n     List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n     \n     for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n       File imageFile \u003d NNStorage.getImageFile(sd, txid);\n       try {\n         MD5FileUtils.saveMD5File(imageFile, digest);\n       } catch (IOException ioe) {\n         badSds.add(sd);\n       }\n     }\n     storage.reportErrorsOnDirectories(badSds);\n     \n     CheckpointFaultInjector.getInstance().afterMD5Rename();\n     \n     // Rename image from tmp file\n-    renameCheckpoint(txid);\n+    renameCheckpoint(txid, NameNodeFile.IMAGE_NEW, NameNodeFile.IMAGE);\n     // So long as this is the newest image available,\n     // advertise it as such to other checkpointers\n     // from now on\n     if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n       storage.setMostRecentCheckpointInfo(txid, Time.now());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void saveDigestAndRenameCheckpointImage(\n      long txid, MD5Hash digest) throws IOException {\n    // Write and rename MD5 file\n    List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n    \n    for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n      File imageFile \u003d NNStorage.getImageFile(sd, txid);\n      try {\n        MD5FileUtils.saveMD5File(imageFile, digest);\n      } catch (IOException ioe) {\n        badSds.add(sd);\n      }\n    }\n    storage.reportErrorsOnDirectories(badSds);\n    \n    CheckpointFaultInjector.getInstance().afterMD5Rename();\n    \n    // Rename image from tmp file\n    renameCheckpoint(txid, NameNodeFile.IMAGE_NEW, NameNodeFile.IMAGE);\n    // So long as this is the newest image available,\n    // advertise it as such to other checkpointers\n    // from now on\n    if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n      storage.setMostRecentCheckpointInfo(txid, Time.now());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "807e08334eb51e3ef97caf00444e19b686164501": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4596. Shutting down namenode during checkpointing can lead to md5sum error. Contributed by Andrew Wang.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1456630 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/03/13 1:01 PM",
      "commitName": "807e08334eb51e3ef97caf00444e19b686164501",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "14/03/13 11:04 AM",
      "commitNameOld": "bcabbcdf4cf7b4bcda62d74b06c9736bc55f6fc1",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,26 @@\n   public synchronized void saveDigestAndRenameCheckpointImage(\n       long txid, MD5Hash digest) throws IOException {\n-    renameCheckpoint(txid);\n+    // Write and rename MD5 file\n     List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n     \n     for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n       File imageFile \u003d NNStorage.getImageFile(sd, txid);\n       try {\n         MD5FileUtils.saveMD5File(imageFile, digest);\n       } catch (IOException ioe) {\n         badSds.add(sd);\n       }\n     }\n     storage.reportErrorsOnDirectories(badSds);\n     \n+    CheckpointFaultInjector.getInstance().afterMD5Rename();\n+    \n+    // Rename image from tmp file\n+    renameCheckpoint(txid);\n     // So long as this is the newest image available,\n     // advertise it as such to other checkpointers\n     // from now on\n     if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n       storage.setMostRecentCheckpointInfo(txid, Time.now());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void saveDigestAndRenameCheckpointImage(\n      long txid, MD5Hash digest) throws IOException {\n    // Write and rename MD5 file\n    List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n    \n    for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n      File imageFile \u003d NNStorage.getImageFile(sd, txid);\n      try {\n        MD5FileUtils.saveMD5File(imageFile, digest);\n      } catch (IOException ioe) {\n        badSds.add(sd);\n      }\n    }\n    storage.reportErrorsOnDirectories(badSds);\n    \n    CheckpointFaultInjector.getInstance().afterMD5Rename();\n    \n    // Rename image from tmp file\n    renameCheckpoint(txid);\n    // So long as this is the newest image available,\n    // advertise it as such to other checkpointers\n    // from now on\n    if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n      storage.setMostRecentCheckpointInfo(txid, Time.now());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "4a5ba3b7bd2360fd9605863630b477d362874e1e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3641. Move server Util time methods to common and use now instead of System#currentTimeMillis. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1360858 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/07/12 12:01 PM",
      "commitName": "4a5ba3b7bd2360fd9605863630b477d362874e1e",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "02/07/12 11:21 AM",
      "commitNameOld": "7accbabdee0b7619ff83514c173e815d290b33bf",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 10.03,
      "commitsBetweenForRepo": 67,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   public synchronized void saveDigestAndRenameCheckpointImage(\n       long txid, MD5Hash digest) throws IOException {\n     renameCheckpoint(txid);\n     List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n     \n     for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n       File imageFile \u003d NNStorage.getImageFile(sd, txid);\n       try {\n         MD5FileUtils.saveMD5File(imageFile, digest);\n       } catch (IOException ioe) {\n         badSds.add(sd);\n       }\n     }\n     storage.reportErrorsOnDirectories(badSds);\n     \n     // So long as this is the newest image available,\n     // advertise it as such to other checkpointers\n     // from now on\n     if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n-      storage.setMostRecentCheckpointInfo(txid, Util.now());\n+      storage.setMostRecentCheckpointInfo(txid, Time.now());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void saveDigestAndRenameCheckpointImage(\n      long txid, MD5Hash digest) throws IOException {\n    renameCheckpoint(txid);\n    List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n    \n    for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n      File imageFile \u003d NNStorage.getImageFile(sd, txid);\n      try {\n        MD5FileUtils.saveMD5File(imageFile, digest);\n      } catch (IOException ioe) {\n        badSds.add(sd);\n      }\n    }\n    storage.reportErrorsOnDirectories(badSds);\n    \n    // So long as this is the newest image available,\n    // advertise it as such to other checkpointers\n    // from now on\n    if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n      storage.setMostRecentCheckpointInfo(txid, Time.now());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "1a75ec82885e45baf4d5cd56d6c738d8e68d8bc7": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-2731. Add command to bootstrap the Standby Node\u0027s name directories from the Active NameNode. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1299807 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/03/12 12:41 PM",
      "commitName": "1a75ec82885e45baf4d5cd56d6c738d8e68d8bc7",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "28/02/12 5:09 PM",
      "commitNameOld": "978a8050e28b2afb193a3e00d82a8475fa4d2428",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 12.77,
      "commitsBetweenForRepo": 90,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n-  synchronized void saveDigestAndRenameCheckpointImage(\n+  public synchronized void saveDigestAndRenameCheckpointImage(\n       long txid, MD5Hash digest) throws IOException {\n     renameCheckpoint(txid);\n     List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n     \n     for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n       File imageFile \u003d NNStorage.getImageFile(sd, txid);\n       try {\n         MD5FileUtils.saveMD5File(imageFile, digest);\n       } catch (IOException ioe) {\n         badSds.add(sd);\n       }\n     }\n     storage.reportErrorsOnDirectories(badSds);\n     \n     // So long as this is the newest image available,\n     // advertise it as such to other checkpointers\n     // from now on\n     if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n       storage.setMostRecentCheckpointInfo(txid, Util.now());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void saveDigestAndRenameCheckpointImage(\n      long txid, MD5Hash digest) throws IOException {\n    renameCheckpoint(txid);\n    List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n    \n    for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n      File imageFile \u003d NNStorage.getImageFile(sd, txid);\n      try {\n        MD5FileUtils.saveMD5File(imageFile, digest);\n      } catch (IOException ioe) {\n        badSds.add(sd);\n      }\n    }\n    storage.reportErrorsOnDirectories(badSds);\n    \n    // So long as this is the newest image available,\n    // advertise it as such to other checkpointers\n    // from now on\n    if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n      storage.setMostRecentCheckpointInfo(txid, Util.now());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {
        "oldValue": "[synchronized]",
        "newValue": "[public, synchronized]"
      }
    },
    "a87328dfab96a335535e8952e548534b73c00b7c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2943. Expose last checkpoint time and transaction stats as JMX metrics. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1243822 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/02/12 12:27 AM",
      "commitName": "a87328dfab96a335535e8952e548534b73c00b7c",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "07/12/11 1:47 PM",
      "commitNameOld": "a27adf3de4ea88a80401fc7157c5e39747230c2a",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 68.44,
      "commitsBetweenForRepo": 392,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   synchronized void saveDigestAndRenameCheckpointImage(\n       long txid, MD5Hash digest) throws IOException {\n     renameCheckpoint(txid);\n     List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n     \n     for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n       File imageFile \u003d NNStorage.getImageFile(sd, txid);\n       try {\n         MD5FileUtils.saveMD5File(imageFile, digest);\n       } catch (IOException ioe) {\n         badSds.add(sd);\n       }\n     }\n     storage.reportErrorsOnDirectories(badSds);\n     \n     // So long as this is the newest image available,\n     // advertise it as such to other checkpointers\n     // from now on\n     if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n-      storage.setMostRecentCheckpointTxId(txid);\n+      storage.setMostRecentCheckpointInfo(txid, Util.now());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void saveDigestAndRenameCheckpointImage(\n      long txid, MD5Hash digest) throws IOException {\n    renameCheckpoint(txid);\n    List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n    \n    for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n      File imageFile \u003d NNStorage.getImageFile(sd, txid);\n      try {\n        MD5FileUtils.saveMD5File(imageFile, digest);\n      } catch (IOException ioe) {\n        badSds.add(sd);\n      }\n    }\n    storage.reportErrorsOnDirectories(badSds);\n    \n    // So long as this is the newest image available,\n    // advertise it as such to other checkpointers\n    // from now on\n    if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n      storage.setMostRecentCheckpointInfo(txid, Util.now());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  synchronized void saveDigestAndRenameCheckpointImage(\n      long txid, MD5Hash digest) throws IOException {\n    renameCheckpoint(txid);\n    List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n    \n    for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n      File imageFile \u003d NNStorage.getImageFile(sd, txid);\n      try {\n        MD5FileUtils.saveMD5File(imageFile, digest);\n      } catch (IOException ioe) {\n        badSds.add(sd);\n      }\n    }\n    storage.reportErrorsOnDirectories(badSds);\n    \n    // So long as this is the newest image available,\n    // advertise it as such to other checkpointers\n    // from now on\n    if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n      storage.setMostRecentCheckpointTxId(txid);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  synchronized void saveDigestAndRenameCheckpointImage(\n      long txid, MD5Hash digest) throws IOException {\n    renameCheckpoint(txid);\n    List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n    \n    for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n      File imageFile \u003d NNStorage.getImageFile(sd, txid);\n      try {\n        MD5FileUtils.saveMD5File(imageFile, digest);\n      } catch (IOException ioe) {\n        badSds.add(sd);\n      }\n    }\n    storage.reportErrorsOnDirectories(badSds);\n    \n    // So long as this is the newest image available,\n    // advertise it as such to other checkpointers\n    // from now on\n    if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n      storage.setMostRecentCheckpointTxId(txid);\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java"
      }
    },
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/11 9:28 AM",
      "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,22 @@\n+  synchronized void saveDigestAndRenameCheckpointImage(\n+      long txid, MD5Hash digest) throws IOException {\n+    renameCheckpoint(txid);\n+    List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n+    \n+    for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n+      File imageFile \u003d NNStorage.getImageFile(sd, txid);\n+      try {\n+        MD5FileUtils.saveMD5File(imageFile, digest);\n+      } catch (IOException ioe) {\n+        badSds.add(sd);\n+      }\n+    }\n+    storage.reportErrorsOnDirectories(badSds);\n+    \n+    // So long as this is the newest image available,\n+    // advertise it as such to other checkpointers\n+    // from now on\n+    if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n+      storage.setMostRecentCheckpointTxId(txid);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void saveDigestAndRenameCheckpointImage(\n      long txid, MD5Hash digest) throws IOException {\n    renameCheckpoint(txid);\n    List\u003cStorageDirectory\u003e badSds \u003d Lists.newArrayList();\n    \n    for (StorageDirectory sd : storage.dirIterable(NameNodeDirType.IMAGE)) {\n      File imageFile \u003d NNStorage.getImageFile(sd, txid);\n      try {\n        MD5FileUtils.saveMD5File(imageFile, digest);\n      } catch (IOException ioe) {\n        badSds.add(sd);\n      }\n    }\n    storage.reportErrorsOnDirectories(badSds);\n    \n    // So long as this is the newest image available,\n    // advertise it as such to other checkpointers\n    // from now on\n    if (txid \u003e storage.getMostRecentCheckpointTxId()) {\n      storage.setMostRecentCheckpointTxId(txid);\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java"
    }
  }
}