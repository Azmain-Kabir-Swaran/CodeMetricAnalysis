{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HttpFSFileSystem.java",
  "functionName": "initialize",
  "functionId": "initialize___name-URI__conf-Configuration",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/client/HttpFSFileSystem.java",
  "functionStartLine": 390,
  "functionEndLine": 413,
  "numCommitsSeen": 51,
  "timeTaken": 1792,
  "changeHistory": [
    "70b218748badf079c859c3af2b468a0b7b49c333",
    "be9c67930b57c516723d566625f9036a88a84055",
    "4d4560189adccb941a3dc5eee7add134adbf6519",
    "3334306512b5dc932814fded31a89ba1ee97cd9f"
  ],
  "changeHistoryShort": {
    "70b218748badf079c859c3af2b468a0b7b49c333": "Ybodychange",
    "be9c67930b57c516723d566625f9036a88a84055": "Ybodychange",
    "4d4560189adccb941a3dc5eee7add134adbf6519": "Ybodychange",
    "3334306512b5dc932814fded31a89ba1ee97cd9f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "70b218748badf079c859c3af2b468a0b7b49c333": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-11015. Http server/client utils to propagate and recreate Exceptions from server to client. (tucu)\n",
      "commitDate": "04/09/14 9:11 AM",
      "commitName": "70b218748badf079c859c3af2b468a0b7b49c333",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "07/08/14 9:58 PM",
      "commitNameOld": "be9c67930b57c516723d566625f9036a88a84055",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 27.47,
      "commitsBetweenForRepo": 206,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,24 @@\n   public void initialize(URI name, Configuration conf) throws IOException {\n     UserGroupInformation ugi \u003d UserGroupInformation.getCurrentUser();\n \n     //the real use is the one that has the Kerberos credentials needed for\n     //SPNEGO to work\n     realUser \u003d ugi.getRealUser();\n     if (realUser \u003d\u003d null) {\n       realUser \u003d UserGroupInformation.getLoginUser();\n     }\n-    doAs \u003d ugi.getShortUserName();\n     super.initialize(name, conf);\n     try {\n       uri \u003d new URI(name.getScheme() + \"://\" + name.getAuthority());\n     } catch (URISyntaxException ex) {\n       throw new IOException(ex);\n     }\n \n     Class\u003c? extends DelegationTokenAuthenticator\u003e klass \u003d\n         getConf().getClass(\"httpfs.authenticator.class\",\n             KerberosDelegationTokenAuthenticator.class,\n             DelegationTokenAuthenticator.class);\n     DelegationTokenAuthenticator authenticator \u003d\n         ReflectionUtils.newInstance(klass, getConf());\n     authURL \u003d new DelegationTokenAuthenticatedURL(authenticator);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(URI name, Configuration conf) throws IOException {\n    UserGroupInformation ugi \u003d UserGroupInformation.getCurrentUser();\n\n    //the real use is the one that has the Kerberos credentials needed for\n    //SPNEGO to work\n    realUser \u003d ugi.getRealUser();\n    if (realUser \u003d\u003d null) {\n      realUser \u003d UserGroupInformation.getLoginUser();\n    }\n    super.initialize(name, conf);\n    try {\n      uri \u003d new URI(name.getScheme() + \"://\" + name.getAuthority());\n    } catch (URISyntaxException ex) {\n      throw new IOException(ex);\n    }\n\n    Class\u003c? extends DelegationTokenAuthenticator\u003e klass \u003d\n        getConf().getClass(\"httpfs.authenticator.class\",\n            KerberosDelegationTokenAuthenticator.class,\n            DelegationTokenAuthenticator.class);\n    DelegationTokenAuthenticator authenticator \u003d\n        ReflectionUtils.newInstance(klass, getConf());\n    authURL \u003d new DelegationTokenAuthenticatedURL(authenticator);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/client/HttpFSFileSystem.java",
      "extendedDetails": {}
    },
    "be9c67930b57c516723d566625f9036a88a84055": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10771. Refactor HTTP delegation support out of httpfs to common, PART 2. (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616672 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/14 9:58 PM",
      "commitName": "be9c67930b57c516723d566625f9036a88a84055",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "24/06/14 8:59 AM",
      "commitNameOld": "46162a213f60f915df76c60b0412f45a021e1e7e",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 44.54,
      "commitsBetweenForRepo": 316,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,25 @@\n   public void initialize(URI name, Configuration conf) throws IOException {\n     UserGroupInformation ugi \u003d UserGroupInformation.getCurrentUser();\n \n     //the real use is the one that has the Kerberos credentials needed for\n     //SPNEGO to work\n     realUser \u003d ugi.getRealUser();\n     if (realUser \u003d\u003d null) {\n       realUser \u003d UserGroupInformation.getLoginUser();\n     }\n     doAs \u003d ugi.getShortUserName();\n     super.initialize(name, conf);\n     try {\n       uri \u003d new URI(name.getScheme() + \"://\" + name.getAuthority());\n-      httpFSAddr \u003d NetUtils.createSocketAddr(getCanonicalUri().toString());\n     } catch (URISyntaxException ex) {\n       throw new IOException(ex);\n     }\n+\n+    Class\u003c? extends DelegationTokenAuthenticator\u003e klass \u003d\n+        getConf().getClass(\"httpfs.authenticator.class\",\n+            KerberosDelegationTokenAuthenticator.class,\n+            DelegationTokenAuthenticator.class);\n+    DelegationTokenAuthenticator authenticator \u003d\n+        ReflectionUtils.newInstance(klass, getConf());\n+    authURL \u003d new DelegationTokenAuthenticatedURL(authenticator);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(URI name, Configuration conf) throws IOException {\n    UserGroupInformation ugi \u003d UserGroupInformation.getCurrentUser();\n\n    //the real use is the one that has the Kerberos credentials needed for\n    //SPNEGO to work\n    realUser \u003d ugi.getRealUser();\n    if (realUser \u003d\u003d null) {\n      realUser \u003d UserGroupInformation.getLoginUser();\n    }\n    doAs \u003d ugi.getShortUserName();\n    super.initialize(name, conf);\n    try {\n      uri \u003d new URI(name.getScheme() + \"://\" + name.getAuthority());\n    } catch (URISyntaxException ex) {\n      throw new IOException(ex);\n    }\n\n    Class\u003c? extends DelegationTokenAuthenticator\u003e klass \u003d\n        getConf().getClass(\"httpfs.authenticator.class\",\n            KerberosDelegationTokenAuthenticator.class,\n            DelegationTokenAuthenticator.class);\n    DelegationTokenAuthenticator authenticator \u003d\n        ReflectionUtils.newInstance(klass, getConf());\n    authURL \u003d new DelegationTokenAuthenticatedURL(authenticator);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/client/HttpFSFileSystem.java",
      "extendedDetails": {}
    },
    "4d4560189adccb941a3dc5eee7add134adbf6519": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3113. httpfs does not support delegation tokens. (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1365988 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/07/12 6:39 AM",
      "commitName": "4d4560189adccb941a3dc5eee7add134adbf6519",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "29/06/12 1:59 PM",
      "commitNameOld": "34605c9594770b204b28a809d8dbc0dae11ff0d1",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 26.69,
      "commitsBetweenForRepo": 161,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,18 @@\n   public void initialize(URI name, Configuration conf) throws IOException {\n     UserGroupInformation ugi \u003d UserGroupInformation.getCurrentUser();\n-    doAs \u003d ugi.getUserName();\n+\n+    //the real use is the one that has the Kerberos credentials needed for\n+    //SPNEGO to work\n+    realUser \u003d ugi.getRealUser();\n+    if (realUser \u003d\u003d null) {\n+      realUser \u003d UserGroupInformation.getLoginUser();\n+    }\n+    doAs \u003d ugi.getShortUserName();\n     super.initialize(name, conf);\n     try {\n-      uri \u003d new URI(name.getScheme() + \"://\" + name.getHost() + \":\" + name.getPort());\n+      uri \u003d new URI(name.getScheme() + \"://\" + name.getAuthority());\n+      httpFSAddr \u003d NetUtils.createSocketAddr(getCanonicalUri().toString());\n     } catch (URISyntaxException ex) {\n       throw new IOException(ex);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(URI name, Configuration conf) throws IOException {\n    UserGroupInformation ugi \u003d UserGroupInformation.getCurrentUser();\n\n    //the real use is the one that has the Kerberos credentials needed for\n    //SPNEGO to work\n    realUser \u003d ugi.getRealUser();\n    if (realUser \u003d\u003d null) {\n      realUser \u003d UserGroupInformation.getLoginUser();\n    }\n    doAs \u003d ugi.getShortUserName();\n    super.initialize(name, conf);\n    try {\n      uri \u003d new URI(name.getScheme() + \"://\" + name.getAuthority());\n      httpFSAddr \u003d NetUtils.createSocketAddr(getCanonicalUri().toString());\n    } catch (URISyntaxException ex) {\n      throw new IOException(ex);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/client/HttpFSFileSystem.java",
      "extendedDetails": {}
    },
    "3334306512b5dc932814fded31a89ba1ee97cd9f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2178. Contributing Hoop to HDFS, replacement for HDFS proxy with read/write capabilities. (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1212060 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/12/11 11:25 AM",
      "commitName": "3334306512b5dc932814fded31a89ba1ee97cd9f",
      "commitAuthor": "Alejandro Abdelnur",
      "diff": "@@ -0,0 +1,10 @@\n+  public void initialize(URI name, Configuration conf) throws IOException {\n+    UserGroupInformation ugi \u003d UserGroupInformation.getCurrentUser();\n+    doAs \u003d ugi.getUserName();\n+    super.initialize(name, conf);\n+    try {\n+      uri \u003d new URI(name.getScheme() + \"://\" + name.getHost() + \":\" + name.getPort());\n+    } catch (URISyntaxException ex) {\n+      throw new IOException(ex);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void initialize(URI name, Configuration conf) throws IOException {\n    UserGroupInformation ugi \u003d UserGroupInformation.getCurrentUser();\n    doAs \u003d ugi.getUserName();\n    super.initialize(name, conf);\n    try {\n      uri \u003d new URI(name.getScheme() + \"://\" + name.getHost() + \":\" + name.getPort());\n    } catch (URISyntaxException ex) {\n      throw new IOException(ex);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/client/HttpFSFileSystem.java"
    }
  }
}