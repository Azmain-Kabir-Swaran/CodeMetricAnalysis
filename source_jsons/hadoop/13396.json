{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ErasureCodingWork.java",
  "functionName": "chooseSource4SimpleReplication",
  "functionId": "chooseSource4SimpleReplication",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ErasureCodingWork.java",
  "functionStartLine": 106,
  "functionEndLine": 125,
  "numCommitsSeen": 13,
  "timeTaken": 954,
  "changeHistory": [
    "e54cc2931262bf49682a8323da9811976218c03b"
  ],
  "changeHistoryShort": {
    "e54cc2931262bf49682a8323da9811976218c03b": "Yintroduced"
  },
  "changeHistoryDetails": {
    "e54cc2931262bf49682a8323da9811976218c03b": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9818. Correctly handle EC reconstruction work caused by not enough racks. Contributed by Jing Zhao.\n",
      "commitDate": "19/02/16 7:02 PM",
      "commitName": "e54cc2931262bf49682a8323da9811976218c03b",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,20 @@\n+  private int chooseSource4SimpleReplication() {\n+    Map\u003cString, List\u003cInteger\u003e\u003e map \u003d new HashMap\u003c\u003e();\n+    for (int i \u003d 0; i \u003c getSrcNodes().length; i++) {\n+      final String rack \u003d getSrcNodes()[i].getNetworkLocation();\n+      List\u003cInteger\u003e dnList \u003d map.get(rack);\n+      if (dnList \u003d\u003d null) {\n+        dnList \u003d new ArrayList\u003c\u003e();\n+        map.put(rack, dnList);\n+      }\n+      dnList.add(i);\n+    }\n+    List\u003cInteger\u003e max \u003d null;\n+    for (Map.Entry\u003cString, List\u003cInteger\u003e\u003e entry : map.entrySet()) {\n+      if (max \u003d\u003d null || entry.getValue().size() \u003e max.size()) {\n+        max \u003d entry.getValue();\n+      }\n+    }\n+    assert max !\u003d null;\n+    return max.get(0);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private int chooseSource4SimpleReplication() {\n    Map\u003cString, List\u003cInteger\u003e\u003e map \u003d new HashMap\u003c\u003e();\n    for (int i \u003d 0; i \u003c getSrcNodes().length; i++) {\n      final String rack \u003d getSrcNodes()[i].getNetworkLocation();\n      List\u003cInteger\u003e dnList \u003d map.get(rack);\n      if (dnList \u003d\u003d null) {\n        dnList \u003d new ArrayList\u003c\u003e();\n        map.put(rack, dnList);\n      }\n      dnList.add(i);\n    }\n    List\u003cInteger\u003e max \u003d null;\n    for (Map.Entry\u003cString, List\u003cInteger\u003e\u003e entry : map.entrySet()) {\n      if (max \u003d\u003d null || entry.getValue().size() \u003e max.size()) {\n        max \u003d entry.getValue();\n      }\n    }\n    assert max !\u003d null;\n    return max.get(0);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ErasureCodingWork.java"
    }
  }
}