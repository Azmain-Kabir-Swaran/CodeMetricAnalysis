{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Client.java",
  "functionName": "writeConnectionContext",
  "functionId": "writeConnectionContext___remoteId-ConnectionId__authMethod-AuthMethod",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java",
  "functionStartLine": 1007,
  "functionEndLine": 1028,
  "numCommitsSeen": 193,
  "timeTaken": 4763,
  "changeHistory": [
    "d4d076876a8d0002bd3a73491d8459d11cb4896c",
    "23abb09c1f979d8c18ece81e32630a35ed569399",
    "8724ceb2359af66c800043e665c17a2a30981c7d",
    "a3a9d72e98a9cc0f94af7c832dd13c408856636d",
    "aa4fe26a01d2ca881cb458d49032ce419351bed1",
    "5605b54010b67785085192629d9a191e0c79bd90",
    "589c68ae09effd6c4f26505d61636f779c22e99f",
    "7ae04652a6adf0f9d04b8702a7fe3b9790afa8b9",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
    "940389afce6a1b9b9e1519aed528cbc444786756",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36"
  ],
  "changeHistoryShort": {
    "d4d076876a8d0002bd3a73491d8459d11cb4896c": "Ybodychange",
    "23abb09c1f979d8c18ece81e32630a35ed569399": "Ybodychange",
    "8724ceb2359af66c800043e665c17a2a30981c7d": "Ybodychange",
    "a3a9d72e98a9cc0f94af7c832dd13c408856636d": "Ybodychange",
    "aa4fe26a01d2ca881cb458d49032ce419351bed1": "Ybodychange",
    "5605b54010b67785085192629d9a191e0c79bd90": "Ymultichange(Yparameterchange,Ybodychange)",
    "589c68ae09effd6c4f26505d61636f779c22e99f": "Yrename",
    "7ae04652a6adf0f9d04b8702a7fe3b9790afa8b9": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yfilerename",
    "940389afce6a1b9b9e1519aed528cbc444786756": "Ybodychange",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d4d076876a8d0002bd3a73491d8459d11cb4896c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10940. RPC client does no bounds checking of responses. Contributed by Daryn Sharp.\n",
      "commitDate": "09/09/16 8:39 AM",
      "commitName": "d4d076876a8d0002bd3a73491d8459d11cb4896c",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "02/09/16 9:03 AM",
      "commitNameOld": "23abb09c1f979d8c18ece81e32630a35ed569399",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 6.98,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,22 @@\n     private void writeConnectionContext(ConnectionId remoteId,\n                                         AuthMethod authMethod)\n                                             throws IOException {\n       // Write out the ConnectionHeader\n       IpcConnectionContextProto message \u003d ProtoUtil.makeIpcConnectionContext(\n           RPC.getProtocolName(remoteId.getProtocol()),\n           remoteId.getTicket(),\n           authMethod);\n       RpcRequestHeaderProto connectionContextHeader \u003d ProtoUtil\n           .makeRpcRequestHeader(RpcKind.RPC_PROTOCOL_BUFFER,\n               OperationProto.RPC_FINAL_PACKET, CONNECTION_CONTEXT_CALL_ID,\n               RpcConstants.INVALID_RETRY_COUNT, clientId);\n+      // do not flush.  the context and first ipc call request must be sent\n+      // together to avoid possibility of broken pipes upon authz failure.\n+      // see writeConnectionHeader\n       final ResponseBuffer buf \u003d new ResponseBuffer();\n       connectionContextHeader.writeDelimitedTo(buf);\n       message.writeDelimitedTo(buf);\n-      buf.writeTo(out);\n+      synchronized (ipcStreams.out) {\n+        ipcStreams.sendRequest(buf.toByteArray());\n+      }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void writeConnectionContext(ConnectionId remoteId,\n                                        AuthMethod authMethod)\n                                            throws IOException {\n      // Write out the ConnectionHeader\n      IpcConnectionContextProto message \u003d ProtoUtil.makeIpcConnectionContext(\n          RPC.getProtocolName(remoteId.getProtocol()),\n          remoteId.getTicket(),\n          authMethod);\n      RpcRequestHeaderProto connectionContextHeader \u003d ProtoUtil\n          .makeRpcRequestHeader(RpcKind.RPC_PROTOCOL_BUFFER,\n              OperationProto.RPC_FINAL_PACKET, CONNECTION_CONTEXT_CALL_ID,\n              RpcConstants.INVALID_RETRY_COUNT, clientId);\n      // do not flush.  the context and first ipc call request must be sent\n      // together to avoid possibility of broken pipes upon authz failure.\n      // see writeConnectionHeader\n      final ResponseBuffer buf \u003d new ResponseBuffer();\n      connectionContextHeader.writeDelimitedTo(buf);\n      message.writeDelimitedTo(buf);\n      synchronized (ipcStreams.out) {\n        ipcStreams.sendRequest(buf.toByteArray());\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java",
      "extendedDetails": {}
    },
    "23abb09c1f979d8c18ece81e32630a35ed569399": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13547. Optimize IPC client protobuf decoding. Contributed by Daryn Sharp.\n",
      "commitDate": "02/09/16 9:03 AM",
      "commitName": "23abb09c1f979d8c18ece81e32630a35ed569399",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "25/06/16 12:45 AM",
      "commitNameOld": "d328e667067743f723e332d92154da8e84e65742",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 69.35,
      "commitsBetweenForRepo": 554,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,17 @@\n     private void writeConnectionContext(ConnectionId remoteId,\n                                         AuthMethod authMethod)\n                                             throws IOException {\n       // Write out the ConnectionHeader\n       IpcConnectionContextProto message \u003d ProtoUtil.makeIpcConnectionContext(\n           RPC.getProtocolName(remoteId.getProtocol()),\n           remoteId.getTicket(),\n           authMethod);\n       RpcRequestHeaderProto connectionContextHeader \u003d ProtoUtil\n           .makeRpcRequestHeader(RpcKind.RPC_PROTOCOL_BUFFER,\n               OperationProto.RPC_FINAL_PACKET, CONNECTION_CONTEXT_CALL_ID,\n               RpcConstants.INVALID_RETRY_COUNT, clientId);\n-      RpcRequestMessageWrapper request \u003d\n-          new RpcRequestMessageWrapper(connectionContextHeader, message);\n-      \n-      // Write out the packet length\n-      out.writeInt(request.getLength());\n-      request.write(out);\n+      final ResponseBuffer buf \u003d new ResponseBuffer();\n+      connectionContextHeader.writeDelimitedTo(buf);\n+      message.writeDelimitedTo(buf);\n+      buf.writeTo(out);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void writeConnectionContext(ConnectionId remoteId,\n                                        AuthMethod authMethod)\n                                            throws IOException {\n      // Write out the ConnectionHeader\n      IpcConnectionContextProto message \u003d ProtoUtil.makeIpcConnectionContext(\n          RPC.getProtocolName(remoteId.getProtocol()),\n          remoteId.getTicket(),\n          authMethod);\n      RpcRequestHeaderProto connectionContextHeader \u003d ProtoUtil\n          .makeRpcRequestHeader(RpcKind.RPC_PROTOCOL_BUFFER,\n              OperationProto.RPC_FINAL_PACKET, CONNECTION_CONTEXT_CALL_ID,\n              RpcConstants.INVALID_RETRY_COUNT, clientId);\n      final ResponseBuffer buf \u003d new ResponseBuffer();\n      connectionContextHeader.writeDelimitedTo(buf);\n      message.writeDelimitedTo(buf);\n      buf.writeTo(out);\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java",
      "extendedDetails": {}
    },
    "8724ceb2359af66c800043e665c17a2a30981c7d": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9717. Add retry attempt count to the RPC requests. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1504725 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/07/13 4:44 PM",
      "commitName": "8724ceb2359af66c800043e665c17a2a30981c7d",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "17/07/13 9:42 PM",
      "commitNameOld": "7ec67c5118e8d13e2cb0ab09d04f0609b645a676",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.79,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n     private void writeConnectionContext(ConnectionId remoteId,\n                                         AuthMethod authMethod)\n                                             throws IOException {\n       // Write out the ConnectionHeader\n       IpcConnectionContextProto message \u003d ProtoUtil.makeIpcConnectionContext(\n           RPC.getProtocolName(remoteId.getProtocol()),\n           remoteId.getTicket(),\n           authMethod);\n-      RpcRequestHeaderProto connectionContextHeader \u003d\n-          ProtoUtil.makeRpcRequestHeader(RpcKind.RPC_PROTOCOL_BUFFER,\n+      RpcRequestHeaderProto connectionContextHeader \u003d ProtoUtil\n+          .makeRpcRequestHeader(RpcKind.RPC_PROTOCOL_BUFFER,\n               OperationProto.RPC_FINAL_PACKET, CONNECTION_CONTEXT_CALL_ID,\n-              clientId);\n+              RpcConstants.INVALID_RETRY_COUNT, clientId);\n       RpcRequestMessageWrapper request \u003d\n           new RpcRequestMessageWrapper(connectionContextHeader, message);\n       \n       // Write out the packet length\n       out.writeInt(request.getLength());\n       request.write(out);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void writeConnectionContext(ConnectionId remoteId,\n                                        AuthMethod authMethod)\n                                            throws IOException {\n      // Write out the ConnectionHeader\n      IpcConnectionContextProto message \u003d ProtoUtil.makeIpcConnectionContext(\n          RPC.getProtocolName(remoteId.getProtocol()),\n          remoteId.getTicket(),\n          authMethod);\n      RpcRequestHeaderProto connectionContextHeader \u003d ProtoUtil\n          .makeRpcRequestHeader(RpcKind.RPC_PROTOCOL_BUFFER,\n              OperationProto.RPC_FINAL_PACKET, CONNECTION_CONTEXT_CALL_ID,\n              RpcConstants.INVALID_RETRY_COUNT, clientId);\n      RpcRequestMessageWrapper request \u003d\n          new RpcRequestMessageWrapper(connectionContextHeader, message);\n      \n      // Write out the packet length\n      out.writeInt(request.getLength());\n      request.write(out);\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java",
      "extendedDetails": {}
    },
    "a3a9d72e98a9cc0f94af7c832dd13c408856636d": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9683. [RPC v9] Wrap IpcConnectionContext in RPC headers (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1503811 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/07/13 10:59 AM",
      "commitName": "a3a9d72e98a9cc0f94af7c832dd13c408856636d",
      "commitAuthor": "Daryn Sharp",
      "commitDateOld": "12/07/13 2:36 PM",
      "commitNameOld": "a038ec6ceb3b02e5a82c99fb023ecf90865d5f69",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 3.85,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,19 @@\n     private void writeConnectionContext(ConnectionId remoteId,\n                                         AuthMethod authMethod)\n                                             throws IOException {\n       // Write out the ConnectionHeader\n-      DataOutputBuffer buf \u003d new DataOutputBuffer();\n-      ProtoUtil.makeIpcConnectionContext(\n+      IpcConnectionContextProto message \u003d ProtoUtil.makeIpcConnectionContext(\n           RPC.getProtocolName(remoteId.getProtocol()),\n           remoteId.getTicket(),\n-          authMethod).writeTo(buf);\n+          authMethod);\n+      RpcRequestHeaderProto connectionContextHeader \u003d\n+          ProtoUtil.makeRpcRequestHeader(RpcKind.RPC_PROTOCOL_BUFFER,\n+              OperationProto.RPC_FINAL_PACKET, CONNECTION_CONTEXT_CALL_ID,\n+              clientId);\n+      RpcRequestMessageWrapper request \u003d\n+          new RpcRequestMessageWrapper(connectionContextHeader, message);\n       \n       // Write out the packet length\n-      int bufLen \u003d buf.getLength();\n-\n-      out.writeInt(bufLen);\n-      out.write(buf.getData(), 0, bufLen);\n+      out.writeInt(request.getLength());\n+      request.write(out);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void writeConnectionContext(ConnectionId remoteId,\n                                        AuthMethod authMethod)\n                                            throws IOException {\n      // Write out the ConnectionHeader\n      IpcConnectionContextProto message \u003d ProtoUtil.makeIpcConnectionContext(\n          RPC.getProtocolName(remoteId.getProtocol()),\n          remoteId.getTicket(),\n          authMethod);\n      RpcRequestHeaderProto connectionContextHeader \u003d\n          ProtoUtil.makeRpcRequestHeader(RpcKind.RPC_PROTOCOL_BUFFER,\n              OperationProto.RPC_FINAL_PACKET, CONNECTION_CONTEXT_CALL_ID,\n              clientId);\n      RpcRequestMessageWrapper request \u003d\n          new RpcRequestMessageWrapper(connectionContextHeader, message);\n      \n      // Write out the packet length\n      out.writeInt(request.getLength());\n      request.write(out);\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java",
      "extendedDetails": {}
    },
    "aa4fe26a01d2ca881cb458d49032ce419351bed1": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9140 Cleanup rpc PB protos (sanjay Radia)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1423189 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/12/12 2:16 PM",
      "commitName": "aa4fe26a01d2ca881cb458d49032ce419351bed1",
      "commitAuthor": "Sanjay Radia",
      "commitDateOld": "10/12/12 1:25 PM",
      "commitNameOld": "7ba12a628ad8de8c3e00afb45228b3e9d82c129b",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 7.04,
      "commitsBetweenForRepo": 29,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n     private void writeConnectionContext(ConnectionId remoteId,\n                                         AuthMethod authMethod)\n                                             throws IOException {\n       // Write out the ConnectionHeader\n       DataOutputBuffer buf \u003d new DataOutputBuffer();\n       ProtoUtil.makeIpcConnectionContext(\n           RPC.getProtocolName(remoteId.getProtocol()),\n           remoteId.getTicket(),\n           authMethod).writeTo(buf);\n       \n-      // Write out the payload length\n+      // Write out the packet length\n       int bufLen \u003d buf.getLength();\n \n       out.writeInt(bufLen);\n       out.write(buf.getData(), 0, bufLen);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void writeConnectionContext(ConnectionId remoteId,\n                                        AuthMethod authMethod)\n                                            throws IOException {\n      // Write out the ConnectionHeader\n      DataOutputBuffer buf \u003d new DataOutputBuffer();\n      ProtoUtil.makeIpcConnectionContext(\n          RPC.getProtocolName(remoteId.getProtocol()),\n          remoteId.getTicket(),\n          authMethod).writeTo(buf);\n      \n      // Write out the packet length\n      int bufLen \u003d buf.getLength();\n\n      out.writeInt(bufLen);\n      out.write(buf.getData(), 0, bufLen);\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java",
      "extendedDetails": {}
    },
    "5605b54010b67785085192629d9a191e0c79bd90": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HADOOP-9012. IPC Client sends wrong connection context (daryn via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1406184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/11/12 7:37 AM",
      "commitName": "5605b54010b67785085192629d9a191e0c79bd90",
      "commitAuthor": "Robert Joseph Evans",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-9012. IPC Client sends wrong connection context (daryn via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1406184 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/11/12 7:37 AM",
          "commitName": "5605b54010b67785085192629d9a191e0c79bd90",
          "commitAuthor": "Robert Joseph Evans",
          "commitDateOld": "05/11/12 10:37 AM",
          "commitNameOld": "b1aa62a848646f78e019c74186d9696e9101afcf",
          "commitAuthorOld": "Robert Joseph Evans",
          "daysBetweenCommits": 0.87,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,16 @@\n-    private void writeConnectionContext() throws IOException {\n+    private void writeConnectionContext(ConnectionId remoteId,\n+                                        AuthMethod authMethod)\n+                                            throws IOException {\n       // Write out the ConnectionHeader\n       DataOutputBuffer buf \u003d new DataOutputBuffer();\n-      connectionContext.writeTo(buf);\n+      ProtoUtil.makeIpcConnectionContext(\n+          RPC.getProtocolName(remoteId.getProtocol()),\n+          remoteId.getTicket(),\n+          authMethod).writeTo(buf);\n       \n       // Write out the payload length\n       int bufLen \u003d buf.getLength();\n \n       out.writeInt(bufLen);\n       out.write(buf.getData(), 0, bufLen);\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void writeConnectionContext(ConnectionId remoteId,\n                                        AuthMethod authMethod)\n                                            throws IOException {\n      // Write out the ConnectionHeader\n      DataOutputBuffer buf \u003d new DataOutputBuffer();\n      ProtoUtil.makeIpcConnectionContext(\n          RPC.getProtocolName(remoteId.getProtocol()),\n          remoteId.getTicket(),\n          authMethod).writeTo(buf);\n      \n      // Write out the payload length\n      int bufLen \u003d buf.getLength();\n\n      out.writeInt(bufLen);\n      out.write(buf.getData(), 0, bufLen);\n    }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[remoteId-ConnectionId, authMethod-AuthMethod]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-9012. IPC Client sends wrong connection context (daryn via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1406184 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/11/12 7:37 AM",
          "commitName": "5605b54010b67785085192629d9a191e0c79bd90",
          "commitAuthor": "Robert Joseph Evans",
          "commitDateOld": "05/11/12 10:37 AM",
          "commitNameOld": "b1aa62a848646f78e019c74186d9696e9101afcf",
          "commitAuthorOld": "Robert Joseph Evans",
          "daysBetweenCommits": 0.87,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,16 @@\n-    private void writeConnectionContext() throws IOException {\n+    private void writeConnectionContext(ConnectionId remoteId,\n+                                        AuthMethod authMethod)\n+                                            throws IOException {\n       // Write out the ConnectionHeader\n       DataOutputBuffer buf \u003d new DataOutputBuffer();\n-      connectionContext.writeTo(buf);\n+      ProtoUtil.makeIpcConnectionContext(\n+          RPC.getProtocolName(remoteId.getProtocol()),\n+          remoteId.getTicket(),\n+          authMethod).writeTo(buf);\n       \n       // Write out the payload length\n       int bufLen \u003d buf.getLength();\n \n       out.writeInt(bufLen);\n       out.write(buf.getData(), 0, bufLen);\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void writeConnectionContext(ConnectionId remoteId,\n                                        AuthMethod authMethod)\n                                            throws IOException {\n      // Write out the ConnectionHeader\n      DataOutputBuffer buf \u003d new DataOutputBuffer();\n      ProtoUtil.makeIpcConnectionContext(\n          RPC.getProtocolName(remoteId.getProtocol()),\n          remoteId.getTicket(),\n          authMethod).writeTo(buf);\n      \n      // Write out the payload length\n      int bufLen \u003d buf.getLength();\n\n      out.writeInt(bufLen);\n      out.write(buf.getData(), 0, bufLen);\n    }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java",
          "extendedDetails": {}
        }
      ]
    },
    "589c68ae09effd6c4f26505d61636f779c22e99f": {
      "type": "Yrename",
      "commitMessage": "    HADOOP-8285 Use ProtoBuf for RpcPayLoadHeader (sanjay radia)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1329319 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/04/12 9:34 AM",
      "commitName": "589c68ae09effd6c4f26505d61636f779c22e99f",
      "commitAuthor": "Sanjay Radia",
      "commitDateOld": "12/04/12 1:43 PM",
      "commitNameOld": "047a7b276c497a4ebb896c93a24e2f0edf258a7b",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 10.83,
      "commitsBetweenForRepo": 64,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,11 @@\n-    private void writeHeader() throws IOException {\n+    private void writeConnectionContext() throws IOException {\n       // Write out the ConnectionHeader\n       DataOutputBuffer buf \u003d new DataOutputBuffer();\n       connectionContext.writeTo(buf);\n       \n       // Write out the payload length\n       int bufLen \u003d buf.getLength();\n+\n       out.writeInt(bufLen);\n       out.write(buf.getData(), 0, bufLen);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void writeConnectionContext() throws IOException {\n      // Write out the ConnectionHeader\n      DataOutputBuffer buf \u003d new DataOutputBuffer();\n      connectionContext.writeTo(buf);\n      \n      // Write out the payload length\n      int bufLen \u003d buf.getLength();\n\n      out.writeInt(bufLen);\n      out.write(buf.getData(), 0, bufLen);\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java",
      "extendedDetails": {
        "oldValue": "writeHeader",
        "newValue": "writeConnectionContext"
      }
    },
    "7ae04652a6adf0f9d04b8702a7fe3b9790afa8b9": {
      "type": "Ybodychange",
      "commitMessage": "    HADOOP-7557 Make IPC header be extensible (sanjay radia)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1295261 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/02/12 12:43 PM",
      "commitName": "7ae04652a6adf0f9d04b8702a7fe3b9790afa8b9",
      "commitAuthor": "Sanjay Radia",
      "commitDateOld": "14/02/12 11:47 AM",
      "commitNameOld": "f42e58c381a1a8d4feb9384de3b8d8c857830d33",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 15.04,
      "commitsBetweenForRepo": 98,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,10 @@\n     private void writeHeader() throws IOException {\n       // Write out the ConnectionHeader\n       DataOutputBuffer buf \u003d new DataOutputBuffer();\n-      header.write(buf);\n+      connectionContext.writeTo(buf);\n       \n       // Write out the payload length\n       int bufLen \u003d buf.getLength();\n       out.writeInt(bufLen);\n       out.write(buf.getData(), 0, bufLen);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void writeHeader() throws IOException {\n      // Write out the ConnectionHeader\n      DataOutputBuffer buf \u003d new DataOutputBuffer();\n      connectionContext.writeTo(buf);\n      \n      // Write out the payload length\n      int bufLen \u003d buf.getLength();\n      out.writeInt(bufLen);\n      out.write(buf.getData(), 0, bufLen);\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void writeHeader() throws IOException {\n      // Write out the ConnectionHeader\n      DataOutputBuffer buf \u003d new DataOutputBuffer();\n      header.write(buf);\n      \n      // Write out the payload length\n      int bufLen \u003d buf.getLength();\n      out.writeInt(bufLen);\n      out.write(buf.getData(), 0, bufLen);\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java",
      "extendedDetails": {
        "oldPath": "hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java"
      }
    },
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-6671. Use maven for hadoop common builds. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1153184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/08/11 9:37 AM",
      "commitName": "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
      "commitAuthor": "Thomas White",
      "commitDateOld": "01/08/11 3:53 PM",
      "commitNameOld": "9bac807cedbcff34e1a144fb475eff267e5ed86d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void writeHeader() throws IOException {\n      // Write out the ConnectionHeader\n      DataOutputBuffer buf \u003d new DataOutputBuffer();\n      header.write(buf);\n      \n      // Write out the payload length\n      int bufLen \u003d buf.getLength();\n      out.writeInt(bufLen);\n      out.write(buf.getData(), 0, bufLen);\n    }",
      "path": "hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java",
      "extendedDetails": {
        "oldPath": "common/src/java/org/apache/hadoop/ipc/Client.java",
        "newPath": "hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "11/06/11 9:13 PM",
      "commitNameOld": "a285fb5effe9ba3be4ec5f942afaf5ddd1186151",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void writeHeader() throws IOException {\n      // Write out the ConnectionHeader\n      DataOutputBuffer buf \u003d new DataOutputBuffer();\n      header.write(buf);\n      \n      // Write out the payload length\n      int bufLen \u003d buf.getLength();\n      out.writeInt(bufLen);\n      out.write(buf.getData(), 0, bufLen);\n    }",
      "path": "common/src/java/org/apache/hadoop/ipc/Client.java",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/hadoop/ipc/Client.java",
        "newPath": "common/src/java/org/apache/hadoop/ipc/Client.java"
      }
    },
    "940389afce6a1b9b9e1519aed528cbc444786756": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-6419. Adds SASL based authentication to RPC. Contributed by Kan Zhang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@905860 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/02/10 5:30 PM",
      "commitName": "940389afce6a1b9b9e1519aed528cbc444786756",
      "commitAuthor": "Devaraj Das",
      "commitDateOld": "26/01/10 2:55 PM",
      "commitNameOld": "34d1b39c7525898b43e44a7c5cbd86768714baf0",
      "commitAuthorOld": "Hairong Kuang",
      "daysBetweenCommits": 7.11,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,10 @@\n     private void writeHeader() throws IOException {\n-      // Write out the header and version\n-      out.write(Server.HEADER.array());\n-      out.write(Server.CURRENT_VERSION);\n-\n       // Write out the ConnectionHeader\n       DataOutputBuffer buf \u003d new DataOutputBuffer();\n       header.write(buf);\n       \n       // Write out the payload length\n       int bufLen \u003d buf.getLength();\n       out.writeInt(bufLen);\n       out.write(buf.getData(), 0, bufLen);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void writeHeader() throws IOException {\n      // Write out the ConnectionHeader\n      DataOutputBuffer buf \u003d new DataOutputBuffer();\n      header.write(buf);\n      \n      // Write out the payload length\n      int bufLen \u003d buf.getLength();\n      out.writeInt(bufLen);\n      out.write(buf.getData(), 0, bufLen);\n    }",
      "path": "src/java/org/apache/hadoop/ipc/Client.java",
      "extendedDetails": {}
    },
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-4687 Moving src directories on branch\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/core/branches/HADOOP-4687/core@776174 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/05/09 9:20 PM",
      "commitName": "5128a9a453d64bfe1ed978cf9ffed27985eeef36",
      "commitAuthor": "Owen O\u0027Malley",
      "diff": "@@ -0,0 +1,14 @@\n+    private void writeHeader() throws IOException {\n+      // Write out the header and version\n+      out.write(Server.HEADER.array());\n+      out.write(Server.CURRENT_VERSION);\n+\n+      // Write out the ConnectionHeader\n+      DataOutputBuffer buf \u003d new DataOutputBuffer();\n+      header.write(buf);\n+      \n+      // Write out the payload length\n+      int bufLen \u003d buf.getLength();\n+      out.writeInt(bufLen);\n+      out.write(buf.getData(), 0, bufLen);\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private void writeHeader() throws IOException {\n      // Write out the header and version\n      out.write(Server.HEADER.array());\n      out.write(Server.CURRENT_VERSION);\n\n      // Write out the ConnectionHeader\n      DataOutputBuffer buf \u003d new DataOutputBuffer();\n      header.write(buf);\n      \n      // Write out the payload length\n      int bufLen \u003d buf.getLength();\n      out.writeInt(bufLen);\n      out.write(buf.getData(), 0, bufLen);\n    }",
      "path": "src/java/org/apache/hadoop/ipc/Client.java"
    }
  }
}