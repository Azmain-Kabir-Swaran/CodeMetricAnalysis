{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPlacementPolicyWithNodeGroup.java",
  "functionName": "chooseLocalStorage",
  "functionId": "chooseLocalStorage___localMachine-Node__excludedNodes-Set__Node____blocksize-long__maxNodesPerRack-int__results-List__DatanodeStorageInfo____avoidStaleNodes-boolean__storageTypes-EnumMap__StorageType,Integer____fallbackToNodeGroupAndLocalRack-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
  "functionStartLine": 125,
  "functionEndLine": 151,
  "numCommitsSeen": 90,
  "timeTaken": 5454,
  "changeHistory": [
    "588baab160e7c328dca1c45cf3541e79218406e8",
    "80a29906bcd718bbba223fa099e523281d9f3369",
    "e08701ec71f7c10d8f15122d90c35f9f22e40837",
    "44d9bb26d640ca5c1de651563c7993b4ecd6b653",
    "abf09f090f77a7e54e331b7a07354e7926b60dc9",
    "f98c343c7f11c165bcc0f7cdbaa2a3998b12cfd2",
    "d01caeee77f4ea00173db7f20a945f6cbfd0c9f7",
    "2887bbb33cefaac0c548eb2450a1f8e3e60f5ea7",
    "4d0cab2729e2bdb1742b62dba69bd30ab69c868e"
  ],
  "changeHistoryShort": {
    "588baab160e7c328dca1c45cf3541e79218406e8": "Ymultichange(Yparameterchange,Ybodychange)",
    "80a29906bcd718bbba223fa099e523281d9f3369": "Ybodychange",
    "e08701ec71f7c10d8f15122d90c35f9f22e40837": "Ymultichange(Yparameterchange,Ybodychange)",
    "44d9bb26d640ca5c1de651563c7993b4ecd6b653": "Ymultichange(Yparameterchange,Ybodychange)",
    "abf09f090f77a7e54e331b7a07354e7926b60dc9": "Ymultichange(Yrename,Yparameterchange,Yreturntypechange,Ybodychange)",
    "f98c343c7f11c165bcc0f7cdbaa2a3998b12cfd2": "Ymultichange(Yparameterchange,Ybodychange)",
    "d01caeee77f4ea00173db7f20a945f6cbfd0c9f7": "Ymultichange(Yparameterchange,Ybodychange)",
    "2887bbb33cefaac0c548eb2450a1f8e3e60f5ea7": "Ymultichange(Yparameterchange,Ybodychange)",
    "4d0cab2729e2bdb1742b62dba69bd30ab69c868e": "Yintroduced"
  },
  "changeHistoryDetails": {
    "588baab160e7c328dca1c45cf3541e79218406e8": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-9044. Give Priority to FavouredNodes , before selecting nodes from FavouredNode\u0027s Node Group (Contributed by J.Andreina)\n",
      "commitDate": "28/10/15 11:14 PM",
      "commitName": "588baab160e7c328dca1c45cf3541e79218406e8",
      "commitAuthor": "Vinayakumar B",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9044. Give Priority to FavouredNodes , before selecting nodes from FavouredNode\u0027s Node Group (Contributed by J.Andreina)\n",
          "commitDate": "28/10/15 11:14 PM",
          "commitName": "588baab160e7c328dca1c45cf3541e79218406e8",
          "commitAuthor": "Vinayakumar B",
          "commitDateOld": "12/09/15 5:10 AM",
          "commitNameOld": "c7156503856e24faf844c5c647157b310d8b537f",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 46.75,
          "commitsBetweenForRepo": 389,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,27 +1,27 @@\n   protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n       Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n       List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n-      EnumMap\u003cStorageType, Integer\u003e storageTypes, boolean fallbackToLocalRack)\n+      EnumMap\u003cStorageType, Integer\u003e storageTypes,\n+      boolean fallbackToNodeGroupAndLocalRack)\n       throws NotEnoughReplicasException {\n     DatanodeStorageInfo localStorage \u003d chooseLocalStorage(localMachine,\n         excludedNodes, blocksize, maxNodesPerRack, results,\n         avoidStaleNodes, storageTypes);\n     if (localStorage !\u003d null) {\n       return localStorage;\n     }\n \n+    if (!fallbackToNodeGroupAndLocalRack) {\n+      return null;\n+    }\n     // try a node on local node group\n     DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n         (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n     if (chosenStorage !\u003d null) {\n       return chosenStorage;\n     }\n-\n-    if (!fallbackToLocalRack) {\n-      return null;\n-    }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n      EnumMap\u003cStorageType, Integer\u003e storageTypes,\n      boolean fallbackToNodeGroupAndLocalRack)\n      throws NotEnoughReplicasException {\n    DatanodeStorageInfo localStorage \u003d chooseLocalStorage(localMachine,\n        excludedNodes, blocksize, maxNodesPerRack, results,\n        avoidStaleNodes, storageTypes);\n    if (localStorage !\u003d null) {\n      return localStorage;\n    }\n\n    if (!fallbackToNodeGroupAndLocalRack) {\n      return null;\n    }\n    // try a node on local node group\n    DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    if (chosenStorage !\u003d null) {\n      return chosenStorage;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {
            "oldValue": "[localMachine-Node, excludedNodes-Set\u003cNode\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeStorageInfo\u003e, avoidStaleNodes-boolean, storageTypes-EnumMap\u003cStorageType,Integer\u003e, fallbackToLocalRack-boolean]",
            "newValue": "[localMachine-Node, excludedNodes-Set\u003cNode\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeStorageInfo\u003e, avoidStaleNodes-boolean, storageTypes-EnumMap\u003cStorageType,Integer\u003e, fallbackToNodeGroupAndLocalRack-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9044. Give Priority to FavouredNodes , before selecting nodes from FavouredNode\u0027s Node Group (Contributed by J.Andreina)\n",
          "commitDate": "28/10/15 11:14 PM",
          "commitName": "588baab160e7c328dca1c45cf3541e79218406e8",
          "commitAuthor": "Vinayakumar B",
          "commitDateOld": "12/09/15 5:10 AM",
          "commitNameOld": "c7156503856e24faf844c5c647157b310d8b537f",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 46.75,
          "commitsBetweenForRepo": 389,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,27 +1,27 @@\n   protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n       Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n       List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n-      EnumMap\u003cStorageType, Integer\u003e storageTypes, boolean fallbackToLocalRack)\n+      EnumMap\u003cStorageType, Integer\u003e storageTypes,\n+      boolean fallbackToNodeGroupAndLocalRack)\n       throws NotEnoughReplicasException {\n     DatanodeStorageInfo localStorage \u003d chooseLocalStorage(localMachine,\n         excludedNodes, blocksize, maxNodesPerRack, results,\n         avoidStaleNodes, storageTypes);\n     if (localStorage !\u003d null) {\n       return localStorage;\n     }\n \n+    if (!fallbackToNodeGroupAndLocalRack) {\n+      return null;\n+    }\n     // try a node on local node group\n     DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n         (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n     if (chosenStorage !\u003d null) {\n       return chosenStorage;\n     }\n-\n-    if (!fallbackToLocalRack) {\n-      return null;\n-    }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n      EnumMap\u003cStorageType, Integer\u003e storageTypes,\n      boolean fallbackToNodeGroupAndLocalRack)\n      throws NotEnoughReplicasException {\n    DatanodeStorageInfo localStorage \u003d chooseLocalStorage(localMachine,\n        excludedNodes, blocksize, maxNodesPerRack, results,\n        avoidStaleNodes, storageTypes);\n    if (localStorage !\u003d null) {\n      return localStorage;\n    }\n\n    if (!fallbackToNodeGroupAndLocalRack) {\n      return null;\n    }\n    // try a node on local node group\n    DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    if (chosenStorage !\u003d null) {\n      return chosenStorage;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {}
        }
      ]
    },
    "80a29906bcd718bbba223fa099e523281d9f3369": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8884. Fail-fast check in BlockPlacementPolicyDefault#chooseTarget. (yliu)\n",
      "commitDate": "20/08/15 5:07 AM",
      "commitName": "80a29906bcd718bbba223fa099e523281d9f3369",
      "commitAuthor": "yliu",
      "commitDateOld": "21/02/15 3:38 PM",
      "commitNameOld": "8b465b4b8caed31ca9daeaae108f9a868a30a455",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 179.52,
      "commitsBetweenForRepo": 1408,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,27 @@\n   protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n       Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n       List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n       EnumMap\u003cStorageType, Integer\u003e storageTypes, boolean fallbackToLocalRack)\n       throws NotEnoughReplicasException {\n-    // if no local machine, randomly choose one node\n-    if (localMachine \u003d\u003d null)\n-      return chooseRandom(NodeBase.ROOT, excludedNodes, \n-          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n-\n-    // otherwise try local machine first\n-    if (localMachine instanceof DatanodeDescriptor) {\n-      DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n-      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n-        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n-            .entrySet().iterator(); iter.hasNext(); ) {\n-          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n-          for (DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n-              localDataNode.getStorageInfos())) {\n-            StorageType type \u003d entry.getKey();\n-            if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n-                maxNodesPerRack, false, results, avoidStaleNodes, type) \u003e\u003d 0) {\n-              int num \u003d entry.getValue();\n-              if (num \u003d\u003d 1) {\n-                iter.remove();\n-              } else {\n-                entry.setValue(num - 1);\n-              }\n-              return localStorage;\n-            }\n-          }\n-        }\n-      }\n+    DatanodeStorageInfo localStorage \u003d chooseLocalStorage(localMachine,\n+        excludedNodes, blocksize, maxNodesPerRack, results,\n+        avoidStaleNodes, storageTypes);\n+    if (localStorage !\u003d null) {\n+      return localStorage;\n     }\n \n     // try a node on local node group\n     DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n         (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n     if (chosenStorage !\u003d null) {\n       return chosenStorage;\n     }\n \n     if (!fallbackToLocalRack) {\n       return null;\n     }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n      EnumMap\u003cStorageType, Integer\u003e storageTypes, boolean fallbackToLocalRack)\n      throws NotEnoughReplicasException {\n    DatanodeStorageInfo localStorage \u003d chooseLocalStorage(localMachine,\n        excludedNodes, blocksize, maxNodesPerRack, results,\n        avoidStaleNodes, storageTypes);\n    if (localStorage !\u003d null) {\n      return localStorage;\n    }\n\n    // try a node on local node group\n    DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    if (chosenStorage !\u003d null) {\n      return chosenStorage;\n    }\n\n    if (!fallbackToLocalRack) {\n      return null;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
      "extendedDetails": {}
    },
    "e08701ec71f7c10d8f15122d90c35f9f22e40837": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6961. Archival Storage: BlockPlacementPolicy#chooseTarget should check each valid storage type in each choosing round.\n",
      "commitDate": "04/09/14 2:19 PM",
      "commitName": "e08701ec71f7c10d8f15122d90c35f9f22e40837",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6961. Archival Storage: BlockPlacementPolicy#chooseTarget should check each valid storage type in each choosing round.\n",
          "commitDate": "04/09/14 2:19 PM",
          "commitName": "e08701ec71f7c10d8f15122d90c35f9f22e40837",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "21/07/14 4:21 PM",
          "commitNameOld": "44d9bb26d640ca5c1de651563c7993b4ecd6b653",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 44.92,
          "commitsBetweenForRepo": 367,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,39 +1,50 @@\n   protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n       Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n       List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n-      StorageType storageType, boolean fallbackToLocalRack\n-      ) throws NotEnoughReplicasException {\n+      EnumMap\u003cStorageType, Integer\u003e storageTypes, boolean fallbackToLocalRack)\n+      throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n     if (localMachine \u003d\u003d null)\n       return chooseRandom(NodeBase.ROOT, excludedNodes, \n-          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n+          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n \n     // otherwise try local machine first\n     if (localMachine instanceof DatanodeDescriptor) {\n       DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n       if (excludedNodes.add(localMachine)) { // was not in the excluded list\n-        for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n-            localDataNode.getStorageInfos())) {\n-          if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n-              maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n-            return localStorage;\n+        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n+            .entrySet().iterator(); iter.hasNext(); ) {\n+          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n+          for (DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n+              localDataNode.getStorageInfos())) {\n+            StorageType type \u003d entry.getKey();\n+            if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n+                maxNodesPerRack, false, results, avoidStaleNodes, type) \u003e\u003d 0) {\n+              int num \u003d entry.getValue();\n+              if (num \u003d\u003d 1) {\n+                iter.remove();\n+              } else {\n+                entry.setValue(num - 1);\n+              }\n+              return localStorage;\n+            }\n           }\n         }\n       }\n     }\n \n     // try a node on local node group\n     DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n         (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n-        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n+        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n     if (chosenStorage !\u003d null) {\n       return chosenStorage;\n     }\n \n     if (!fallbackToLocalRack) {\n       return null;\n     }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, \n-        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n+        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n      EnumMap\u003cStorageType, Integer\u003e storageTypes, boolean fallbackToLocalRack)\n      throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null)\n      return chooseRandom(NodeBase.ROOT, excludedNodes, \n          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n\n    // otherwise try local machine first\n    if (localMachine instanceof DatanodeDescriptor) {\n      DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n            .entrySet().iterator(); iter.hasNext(); ) {\n          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n          for (DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n              localDataNode.getStorageInfos())) {\n            StorageType type \u003d entry.getKey();\n            if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n                maxNodesPerRack, false, results, avoidStaleNodes, type) \u003e\u003d 0) {\n              int num \u003d entry.getValue();\n              if (num \u003d\u003d 1) {\n                iter.remove();\n              } else {\n                entry.setValue(num - 1);\n              }\n              return localStorage;\n            }\n          }\n        }\n      }\n    }\n\n    // try a node on local node group\n    DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    if (chosenStorage !\u003d null) {\n      return chosenStorage;\n    }\n\n    if (!fallbackToLocalRack) {\n      return null;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {
            "oldValue": "[localMachine-Node, excludedNodes-Set\u003cNode\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeStorageInfo\u003e, avoidStaleNodes-boolean, storageType-StorageType, fallbackToLocalRack-boolean]",
            "newValue": "[localMachine-Node, excludedNodes-Set\u003cNode\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeStorageInfo\u003e, avoidStaleNodes-boolean, storageTypes-EnumMap\u003cStorageType,Integer\u003e, fallbackToLocalRack-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6961. Archival Storage: BlockPlacementPolicy#chooseTarget should check each valid storage type in each choosing round.\n",
          "commitDate": "04/09/14 2:19 PM",
          "commitName": "e08701ec71f7c10d8f15122d90c35f9f22e40837",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "21/07/14 4:21 PM",
          "commitNameOld": "44d9bb26d640ca5c1de651563c7993b4ecd6b653",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 44.92,
          "commitsBetweenForRepo": 367,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,39 +1,50 @@\n   protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n       Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n       List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n-      StorageType storageType, boolean fallbackToLocalRack\n-      ) throws NotEnoughReplicasException {\n+      EnumMap\u003cStorageType, Integer\u003e storageTypes, boolean fallbackToLocalRack)\n+      throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n     if (localMachine \u003d\u003d null)\n       return chooseRandom(NodeBase.ROOT, excludedNodes, \n-          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n+          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n \n     // otherwise try local machine first\n     if (localMachine instanceof DatanodeDescriptor) {\n       DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n       if (excludedNodes.add(localMachine)) { // was not in the excluded list\n-        for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n-            localDataNode.getStorageInfos())) {\n-          if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n-              maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n-            return localStorage;\n+        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n+            .entrySet().iterator(); iter.hasNext(); ) {\n+          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n+          for (DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n+              localDataNode.getStorageInfos())) {\n+            StorageType type \u003d entry.getKey();\n+            if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n+                maxNodesPerRack, false, results, avoidStaleNodes, type) \u003e\u003d 0) {\n+              int num \u003d entry.getValue();\n+              if (num \u003d\u003d 1) {\n+                iter.remove();\n+              } else {\n+                entry.setValue(num - 1);\n+              }\n+              return localStorage;\n+            }\n           }\n         }\n       }\n     }\n \n     // try a node on local node group\n     DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n         (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n-        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n+        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n     if (chosenStorage !\u003d null) {\n       return chosenStorage;\n     }\n \n     if (!fallbackToLocalRack) {\n       return null;\n     }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, \n-        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n+        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n      EnumMap\u003cStorageType, Integer\u003e storageTypes, boolean fallbackToLocalRack)\n      throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null)\n      return chooseRandom(NodeBase.ROOT, excludedNodes, \n          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n\n    // otherwise try local machine first\n    if (localMachine instanceof DatanodeDescriptor) {\n      DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n            .entrySet().iterator(); iter.hasNext(); ) {\n          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n          for (DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n              localDataNode.getStorageInfos())) {\n            StorageType type \u003d entry.getKey();\n            if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n                maxNodesPerRack, false, results, avoidStaleNodes, type) \u003e\u003d 0) {\n              int num \u003d entry.getValue();\n              if (num \u003d\u003d 1) {\n                iter.remove();\n              } else {\n                entry.setValue(num - 1);\n              }\n              return localStorage;\n            }\n          }\n        }\n      }\n    }\n\n    // try a node on local node group\n    DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    if (chosenStorage !\u003d null) {\n      return chosenStorage;\n    }\n\n    if (!fallbackToLocalRack) {\n      return null;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {}
        }
      ]
    },
    "44d9bb26d640ca5c1de651563c7993b4ecd6b653": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6680. BlockPlacementPolicyDefault does not choose favored nodes correctly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1612427 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/07/14 4:21 PM",
      "commitName": "44d9bb26d640ca5c1de651563c7993b4ecd6b653",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6680. BlockPlacementPolicyDefault does not choose favored nodes correctly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1612427 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/07/14 4:21 PM",
          "commitName": "44d9bb26d640ca5c1de651563c7993b4ecd6b653",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "18/07/14 10:40 AM",
          "commitNameOld": "08466eaa0045658fa7919a634e48f2d0669f8414",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 3.24,
          "commitsBetweenForRepo": 15,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,34 +1,39 @@\n   protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n       Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n       List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n-      StorageType storageType) throws NotEnoughReplicasException {\n+      StorageType storageType, boolean fallbackToLocalRack\n+      ) throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n     if (localMachine \u003d\u003d null)\n       return chooseRandom(NodeBase.ROOT, excludedNodes, \n           blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n \n     // otherwise try local machine first\n     if (localMachine instanceof DatanodeDescriptor) {\n       DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n       if (excludedNodes.add(localMachine)) { // was not in the excluded list\n         for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n             localDataNode.getStorageInfos())) {\n           if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n               maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n             return localStorage;\n           }\n         }\n       }\n     }\n \n     // try a node on local node group\n     DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n         (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n     if (chosenStorage !\u003d null) {\n       return chosenStorage;\n     }\n+\n+    if (!fallbackToLocalRack) {\n+      return null;\n+    }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n      StorageType storageType, boolean fallbackToLocalRack\n      ) throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null)\n      return chooseRandom(NodeBase.ROOT, excludedNodes, \n          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n\n    // otherwise try local machine first\n    if (localMachine instanceof DatanodeDescriptor) {\n      DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n        for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n            localDataNode.getStorageInfos())) {\n          if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n              maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n            return localStorage;\n          }\n        }\n      }\n    }\n\n    // try a node on local node group\n    DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n    if (chosenStorage !\u003d null) {\n      return chosenStorage;\n    }\n\n    if (!fallbackToLocalRack) {\n      return null;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {
            "oldValue": "[localMachine-Node, excludedNodes-Set\u003cNode\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeStorageInfo\u003e, avoidStaleNodes-boolean, storageType-StorageType]",
            "newValue": "[localMachine-Node, excludedNodes-Set\u003cNode\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeStorageInfo\u003e, avoidStaleNodes-boolean, storageType-StorageType, fallbackToLocalRack-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6680. BlockPlacementPolicyDefault does not choose favored nodes correctly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1612427 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/07/14 4:21 PM",
          "commitName": "44d9bb26d640ca5c1de651563c7993b4ecd6b653",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "18/07/14 10:40 AM",
          "commitNameOld": "08466eaa0045658fa7919a634e48f2d0669f8414",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 3.24,
          "commitsBetweenForRepo": 15,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,34 +1,39 @@\n   protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n       Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n       List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n-      StorageType storageType) throws NotEnoughReplicasException {\n+      StorageType storageType, boolean fallbackToLocalRack\n+      ) throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n     if (localMachine \u003d\u003d null)\n       return chooseRandom(NodeBase.ROOT, excludedNodes, \n           blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n \n     // otherwise try local machine first\n     if (localMachine instanceof DatanodeDescriptor) {\n       DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n       if (excludedNodes.add(localMachine)) { // was not in the excluded list\n         for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n             localDataNode.getStorageInfos())) {\n           if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n               maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n             return localStorage;\n           }\n         }\n       }\n     }\n \n     // try a node on local node group\n     DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n         (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n     if (chosenStorage !\u003d null) {\n       return chosenStorage;\n     }\n+\n+    if (!fallbackToLocalRack) {\n+      return null;\n+    }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n      StorageType storageType, boolean fallbackToLocalRack\n      ) throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null)\n      return chooseRandom(NodeBase.ROOT, excludedNodes, \n          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n\n    // otherwise try local machine first\n    if (localMachine instanceof DatanodeDescriptor) {\n      DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n        for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n            localDataNode.getStorageInfos())) {\n          if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n              maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n            return localStorage;\n          }\n        }\n      }\n    }\n\n    // try a node on local node group\n    DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n    if (chosenStorage !\u003d null) {\n      return chosenStorage;\n    }\n\n    if (!fallbackToLocalRack) {\n      return null;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {}
        }
      ]
    },
    "abf09f090f77a7e54e331b7a07354e7926b60dc9": {
      "type": "Ymultichange(Yrename,Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-4990. Change BlockPlacementPolicy to choose storages instead of datanodes.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1524444 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/09/13 8:12 AM",
      "commitName": "abf09f090f77a7e54e331b7a07354e7926b60dc9",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-4990. Change BlockPlacementPolicy to choose storages instead of datanodes.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1524444 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/09/13 8:12 AM",
          "commitName": "abf09f090f77a7e54e331b7a07354e7926b60dc9",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "16/09/13 7:38 PM",
          "commitNameOld": "f98c343c7f11c165bcc0f7cdbaa2a3998b12cfd2",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 1.52,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,31 +1,34 @@\n-  protected DatanodeDescriptor chooseLocalNode(Node localMachine,\n+  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n       Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n-      List\u003cDatanodeDescriptor\u003e results, boolean avoidStaleNodes)\n-        throws NotEnoughReplicasException {\n+      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n+      StorageType storageType) throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n     if (localMachine \u003d\u003d null)\n       return chooseRandom(NodeBase.ROOT, excludedNodes, \n-          blocksize, maxNodesPerRack, results, avoidStaleNodes);\n+          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n \n+    // otherwise try local machine first\n     if (localMachine instanceof DatanodeDescriptor) {\n       DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n-      // otherwise try local machine first\n       if (excludedNodes.add(localMachine)) { // was not in the excluded list\n-        if (addIfIsGoodTarget(localDataNode, excludedNodes, blocksize,\n-            maxNodesPerRack, false, results, avoidStaleNodes) \u003e\u003d 0) {\n-          return localDataNode;\n+        for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n+            localDataNode.getStorageInfos())) {\n+          if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n+              maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n+            return localStorage;\n+          }\n         }\n       }\n     }\n \n     // try a node on local node group\n-    DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n+    DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n         (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n-        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n-    if (chosenNode !\u003d null) {\n-      return chosenNode;\n+        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n+    if (chosenStorage !\u003d null) {\n+      return chosenStorage;\n     }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, \n-        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n+        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n      StorageType storageType) throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null)\n      return chooseRandom(NodeBase.ROOT, excludedNodes, \n          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n\n    // otherwise try local machine first\n    if (localMachine instanceof DatanodeDescriptor) {\n      DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n        for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n            localDataNode.getStorageInfos())) {\n          if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n              maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n            return localStorage;\n          }\n        }\n      }\n    }\n\n    // try a node on local node group\n    DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n    if (chosenStorage !\u003d null) {\n      return chosenStorage;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {
            "oldValue": "chooseLocalNode",
            "newValue": "chooseLocalStorage"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4990. Change BlockPlacementPolicy to choose storages instead of datanodes.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1524444 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/09/13 8:12 AM",
          "commitName": "abf09f090f77a7e54e331b7a07354e7926b60dc9",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "16/09/13 7:38 PM",
          "commitNameOld": "f98c343c7f11c165bcc0f7cdbaa2a3998b12cfd2",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 1.52,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,31 +1,34 @@\n-  protected DatanodeDescriptor chooseLocalNode(Node localMachine,\n+  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n       Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n-      List\u003cDatanodeDescriptor\u003e results, boolean avoidStaleNodes)\n-        throws NotEnoughReplicasException {\n+      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n+      StorageType storageType) throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n     if (localMachine \u003d\u003d null)\n       return chooseRandom(NodeBase.ROOT, excludedNodes, \n-          blocksize, maxNodesPerRack, results, avoidStaleNodes);\n+          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n \n+    // otherwise try local machine first\n     if (localMachine instanceof DatanodeDescriptor) {\n       DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n-      // otherwise try local machine first\n       if (excludedNodes.add(localMachine)) { // was not in the excluded list\n-        if (addIfIsGoodTarget(localDataNode, excludedNodes, blocksize,\n-            maxNodesPerRack, false, results, avoidStaleNodes) \u003e\u003d 0) {\n-          return localDataNode;\n+        for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n+            localDataNode.getStorageInfos())) {\n+          if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n+              maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n+            return localStorage;\n+          }\n         }\n       }\n     }\n \n     // try a node on local node group\n-    DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n+    DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n         (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n-        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n-    if (chosenNode !\u003d null) {\n-      return chosenNode;\n+        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n+    if (chosenStorage !\u003d null) {\n+      return chosenStorage;\n     }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, \n-        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n+        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n      StorageType storageType) throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null)\n      return chooseRandom(NodeBase.ROOT, excludedNodes, \n          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n\n    // otherwise try local machine first\n    if (localMachine instanceof DatanodeDescriptor) {\n      DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n        for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n            localDataNode.getStorageInfos())) {\n          if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n              maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n            return localStorage;\n          }\n        }\n      }\n    }\n\n    // try a node on local node group\n    DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n    if (chosenStorage !\u003d null) {\n      return chosenStorage;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {
            "oldValue": "[localMachine-Node, excludedNodes-Set\u003cNode\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeDescriptor\u003e, avoidStaleNodes-boolean]",
            "newValue": "[localMachine-Node, excludedNodes-Set\u003cNode\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeStorageInfo\u003e, avoidStaleNodes-boolean, storageType-StorageType]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-4990. Change BlockPlacementPolicy to choose storages instead of datanodes.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1524444 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/09/13 8:12 AM",
          "commitName": "abf09f090f77a7e54e331b7a07354e7926b60dc9",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "16/09/13 7:38 PM",
          "commitNameOld": "f98c343c7f11c165bcc0f7cdbaa2a3998b12cfd2",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 1.52,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,31 +1,34 @@\n-  protected DatanodeDescriptor chooseLocalNode(Node localMachine,\n+  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n       Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n-      List\u003cDatanodeDescriptor\u003e results, boolean avoidStaleNodes)\n-        throws NotEnoughReplicasException {\n+      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n+      StorageType storageType) throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n     if (localMachine \u003d\u003d null)\n       return chooseRandom(NodeBase.ROOT, excludedNodes, \n-          blocksize, maxNodesPerRack, results, avoidStaleNodes);\n+          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n \n+    // otherwise try local machine first\n     if (localMachine instanceof DatanodeDescriptor) {\n       DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n-      // otherwise try local machine first\n       if (excludedNodes.add(localMachine)) { // was not in the excluded list\n-        if (addIfIsGoodTarget(localDataNode, excludedNodes, blocksize,\n-            maxNodesPerRack, false, results, avoidStaleNodes) \u003e\u003d 0) {\n-          return localDataNode;\n+        for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n+            localDataNode.getStorageInfos())) {\n+          if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n+              maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n+            return localStorage;\n+          }\n         }\n       }\n     }\n \n     // try a node on local node group\n-    DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n+    DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n         (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n-        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n-    if (chosenNode !\u003d null) {\n-      return chosenNode;\n+        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n+    if (chosenStorage !\u003d null) {\n+      return chosenStorage;\n     }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, \n-        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n+        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n      StorageType storageType) throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null)\n      return chooseRandom(NodeBase.ROOT, excludedNodes, \n          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n\n    // otherwise try local machine first\n    if (localMachine instanceof DatanodeDescriptor) {\n      DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n        for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n            localDataNode.getStorageInfos())) {\n          if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n              maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n            return localStorage;\n          }\n        }\n      }\n    }\n\n    // try a node on local node group\n    DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n    if (chosenStorage !\u003d null) {\n      return chosenStorage;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {
            "oldValue": "DatanodeDescriptor",
            "newValue": "DatanodeStorageInfo"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4990. Change BlockPlacementPolicy to choose storages instead of datanodes.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1524444 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/09/13 8:12 AM",
          "commitName": "abf09f090f77a7e54e331b7a07354e7926b60dc9",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "16/09/13 7:38 PM",
          "commitNameOld": "f98c343c7f11c165bcc0f7cdbaa2a3998b12cfd2",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 1.52,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,31 +1,34 @@\n-  protected DatanodeDescriptor chooseLocalNode(Node localMachine,\n+  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n       Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n-      List\u003cDatanodeDescriptor\u003e results, boolean avoidStaleNodes)\n-        throws NotEnoughReplicasException {\n+      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n+      StorageType storageType) throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n     if (localMachine \u003d\u003d null)\n       return chooseRandom(NodeBase.ROOT, excludedNodes, \n-          blocksize, maxNodesPerRack, results, avoidStaleNodes);\n+          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n \n+    // otherwise try local machine first\n     if (localMachine instanceof DatanodeDescriptor) {\n       DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n-      // otherwise try local machine first\n       if (excludedNodes.add(localMachine)) { // was not in the excluded list\n-        if (addIfIsGoodTarget(localDataNode, excludedNodes, blocksize,\n-            maxNodesPerRack, false, results, avoidStaleNodes) \u003e\u003d 0) {\n-          return localDataNode;\n+        for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n+            localDataNode.getStorageInfos())) {\n+          if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n+              maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n+            return localStorage;\n+          }\n         }\n       }\n     }\n \n     // try a node on local node group\n-    DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n+    DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n         (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n-        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n-    if (chosenNode !\u003d null) {\n-      return chosenNode;\n+        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n+    if (chosenStorage !\u003d null) {\n+      return chosenStorage;\n     }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, \n-        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n+        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n      StorageType storageType) throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null)\n      return chooseRandom(NodeBase.ROOT, excludedNodes, \n          blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n\n    // otherwise try local machine first\n    if (localMachine instanceof DatanodeDescriptor) {\n      DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n        for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n            localDataNode.getStorageInfos())) {\n          if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n              maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n            return localStorage;\n          }\n        }\n      }\n    }\n\n    // try a node on local node group\n    DatanodeStorageInfo chosenStorage \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n    if (chosenStorage !\u003d null) {\n      return chosenStorage;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes, storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {}
        }
      ]
    },
    "f98c343c7f11c165bcc0f7cdbaa2a3998b12cfd2": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5207. In BlockPlacementPolicy.chooseTarget(..), change the writer and the excludedNodes parameter types respectively to Node and Set.  Contributed by Junping Du\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1523875 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/09/13 7:38 PM",
      "commitName": "f98c343c7f11c165bcc0f7cdbaa2a3998b12cfd2",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5207. In BlockPlacementPolicy.chooseTarget(..), change the writer and the excludedNodes parameter types respectively to Node and Set.  Contributed by Junping Du\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1523875 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "16/09/13 7:38 PM",
          "commitName": "f98c343c7f11c165bcc0f7cdbaa2a3998b12cfd2",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "14/09/13 9:15 PM",
          "commitNameOld": "d01caeee77f4ea00173db7f20a945f6cbfd0c9f7",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 1.93,
          "commitsBetweenForRepo": 12,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,31 @@\n-  protected DatanodeDescriptor chooseLocalNode(DatanodeDescriptor localMachine,\n-      Map\u003cNode, Node\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n+  protected DatanodeDescriptor chooseLocalNode(Node localMachine,\n+      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n       List\u003cDatanodeDescriptor\u003e results, boolean avoidStaleNodes)\n         throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n     if (localMachine \u003d\u003d null)\n       return chooseRandom(NodeBase.ROOT, excludedNodes, \n           blocksize, maxNodesPerRack, results, avoidStaleNodes);\n \n-    // otherwise try local machine first\n-    Node oldNode \u003d excludedNodes.put(localMachine, localMachine);\n-    if (oldNode \u003d\u003d null) { // was not in the excluded list\n-      if (addIfIsGoodTarget(localMachine, excludedNodes, blocksize,\n-          maxNodesPerRack, false, results, avoidStaleNodes) \u003e\u003d 0) {\n-        return localMachine;\n+    if (localMachine instanceof DatanodeDescriptor) {\n+      DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n+      // otherwise try local machine first\n+      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n+        if (addIfIsGoodTarget(localDataNode, excludedNodes, blocksize,\n+            maxNodesPerRack, false, results, avoidStaleNodes) \u003e\u003d 0) {\n+          return localDataNode;\n+        }\n       }\n-    } \n+    }\n \n     // try a node on local node group\n     DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n         (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes);\n     if (chosenNode !\u003d null) {\n       return chosenNode;\n     }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeDescriptor chooseLocalNode(Node localMachine,\n      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeDescriptor\u003e results, boolean avoidStaleNodes)\n        throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null)\n      return chooseRandom(NodeBase.ROOT, excludedNodes, \n          blocksize, maxNodesPerRack, results, avoidStaleNodes);\n\n    if (localMachine instanceof DatanodeDescriptor) {\n      DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n      // otherwise try local machine first\n      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n        if (addIfIsGoodTarget(localDataNode, excludedNodes, blocksize,\n            maxNodesPerRack, false, results, avoidStaleNodes) \u003e\u003d 0) {\n          return localDataNode;\n        }\n      }\n    }\n\n    // try a node on local node group\n    DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n    if (chosenNode !\u003d null) {\n      return chosenNode;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {
            "oldValue": "[localMachine-DatanodeDescriptor, excludedNodes-Map\u003cNode,Node\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeDescriptor\u003e, avoidStaleNodes-boolean]",
            "newValue": "[localMachine-Node, excludedNodes-Set\u003cNode\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeDescriptor\u003e, avoidStaleNodes-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5207. In BlockPlacementPolicy.chooseTarget(..), change the writer and the excludedNodes parameter types respectively to Node and Set.  Contributed by Junping Du\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1523875 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "16/09/13 7:38 PM",
          "commitName": "f98c343c7f11c165bcc0f7cdbaa2a3998b12cfd2",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "14/09/13 9:15 PM",
          "commitNameOld": "d01caeee77f4ea00173db7f20a945f6cbfd0c9f7",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 1.93,
          "commitsBetweenForRepo": 12,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,31 @@\n-  protected DatanodeDescriptor chooseLocalNode(DatanodeDescriptor localMachine,\n-      Map\u003cNode, Node\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n+  protected DatanodeDescriptor chooseLocalNode(Node localMachine,\n+      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n       List\u003cDatanodeDescriptor\u003e results, boolean avoidStaleNodes)\n         throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n     if (localMachine \u003d\u003d null)\n       return chooseRandom(NodeBase.ROOT, excludedNodes, \n           blocksize, maxNodesPerRack, results, avoidStaleNodes);\n \n-    // otherwise try local machine first\n-    Node oldNode \u003d excludedNodes.put(localMachine, localMachine);\n-    if (oldNode \u003d\u003d null) { // was not in the excluded list\n-      if (addIfIsGoodTarget(localMachine, excludedNodes, blocksize,\n-          maxNodesPerRack, false, results, avoidStaleNodes) \u003e\u003d 0) {\n-        return localMachine;\n+    if (localMachine instanceof DatanodeDescriptor) {\n+      DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n+      // otherwise try local machine first\n+      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n+        if (addIfIsGoodTarget(localDataNode, excludedNodes, blocksize,\n+            maxNodesPerRack, false, results, avoidStaleNodes) \u003e\u003d 0) {\n+          return localDataNode;\n+        }\n       }\n-    } \n+    }\n \n     // try a node on local node group\n     DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n         (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes);\n     if (chosenNode !\u003d null) {\n       return chosenNode;\n     }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeDescriptor chooseLocalNode(Node localMachine,\n      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeDescriptor\u003e results, boolean avoidStaleNodes)\n        throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null)\n      return chooseRandom(NodeBase.ROOT, excludedNodes, \n          blocksize, maxNodesPerRack, results, avoidStaleNodes);\n\n    if (localMachine instanceof DatanodeDescriptor) {\n      DatanodeDescriptor localDataNode \u003d (DatanodeDescriptor)localMachine;\n      // otherwise try local machine first\n      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n        if (addIfIsGoodTarget(localDataNode, excludedNodes, blocksize,\n            maxNodesPerRack, false, results, avoidStaleNodes) \u003e\u003d 0) {\n          return localDataNode;\n        }\n      }\n    }\n\n    // try a node on local node group\n    DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n    if (chosenNode !\u003d null) {\n      return chosenNode;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {}
        }
      ]
    },
    "d01caeee77f4ea00173db7f20a945f6cbfd0c9f7": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5188. In BlockPlacementPolicy, reduce the number of chooseTarget(..) methods; replace HashMap with Map in parameter declarations and cleanup some related code.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1523400 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/09/13 9:15 PM",
      "commitName": "d01caeee77f4ea00173db7f20a945f6cbfd0c9f7",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5188. In BlockPlacementPolicy, reduce the number of chooseTarget(..) methods; replace HashMap with Map in parameter declarations and cleanup some related code.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1523400 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/09/13 9:15 PM",
          "commitName": "d01caeee77f4ea00173db7f20a945f6cbfd0c9f7",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "14/08/13 9:52 PM",
          "commitNameOld": "0182ea16d359b41c065bf9cbf740f8b23f6381e3",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 30.97,
          "commitsBetweenForRepo": 162,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,29 @@\n   protected DatanodeDescriptor chooseLocalNode(DatanodeDescriptor localMachine,\n-      HashMap\u003cNode, Node\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n+      Map\u003cNode, Node\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n       List\u003cDatanodeDescriptor\u003e results, boolean avoidStaleNodes)\n         throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n     if (localMachine \u003d\u003d null)\n       return chooseRandom(NodeBase.ROOT, excludedNodes, \n           blocksize, maxNodesPerRack, results, avoidStaleNodes);\n \n     // otherwise try local machine first\n     Node oldNode \u003d excludedNodes.put(localMachine, localMachine);\n     if (oldNode \u003d\u003d null) { // was not in the excluded list\n-      if (isGoodTarget(localMachine, blocksize,\n-          maxNodesPerRack, false, results, avoidStaleNodes)) {\n-        results.add(localMachine);\n-        // Nodes under same nodegroup should be excluded.\n-        addNodeGroupToExcludedNodes(excludedNodes,\n-            localMachine.getNetworkLocation());\n+      if (addIfIsGoodTarget(localMachine, excludedNodes, blocksize,\n+          maxNodesPerRack, false, results, avoidStaleNodes) \u003e\u003d 0) {\n         return localMachine;\n       }\n     } \n \n     // try a node on local node group\n     DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n         (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes);\n     if (chosenNode !\u003d null) {\n       return chosenNode;\n     }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeDescriptor chooseLocalNode(DatanodeDescriptor localMachine,\n      Map\u003cNode, Node\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeDescriptor\u003e results, boolean avoidStaleNodes)\n        throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null)\n      return chooseRandom(NodeBase.ROOT, excludedNodes, \n          blocksize, maxNodesPerRack, results, avoidStaleNodes);\n\n    // otherwise try local machine first\n    Node oldNode \u003d excludedNodes.put(localMachine, localMachine);\n    if (oldNode \u003d\u003d null) { // was not in the excluded list\n      if (addIfIsGoodTarget(localMachine, excludedNodes, blocksize,\n          maxNodesPerRack, false, results, avoidStaleNodes) \u003e\u003d 0) {\n        return localMachine;\n      }\n    } \n\n    // try a node on local node group\n    DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n    if (chosenNode !\u003d null) {\n      return chosenNode;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {
            "oldValue": "[localMachine-DatanodeDescriptor, excludedNodes-HashMap\u003cNode,Node\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeDescriptor\u003e, avoidStaleNodes-boolean]",
            "newValue": "[localMachine-DatanodeDescriptor, excludedNodes-Map\u003cNode,Node\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeDescriptor\u003e, avoidStaleNodes-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5188. In BlockPlacementPolicy, reduce the number of chooseTarget(..) methods; replace HashMap with Map in parameter declarations and cleanup some related code.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1523400 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/09/13 9:15 PM",
          "commitName": "d01caeee77f4ea00173db7f20a945f6cbfd0c9f7",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "14/08/13 9:52 PM",
          "commitNameOld": "0182ea16d359b41c065bf9cbf740f8b23f6381e3",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 30.97,
          "commitsBetweenForRepo": 162,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,29 @@\n   protected DatanodeDescriptor chooseLocalNode(DatanodeDescriptor localMachine,\n-      HashMap\u003cNode, Node\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n+      Map\u003cNode, Node\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n       List\u003cDatanodeDescriptor\u003e results, boolean avoidStaleNodes)\n         throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n     if (localMachine \u003d\u003d null)\n       return chooseRandom(NodeBase.ROOT, excludedNodes, \n           blocksize, maxNodesPerRack, results, avoidStaleNodes);\n \n     // otherwise try local machine first\n     Node oldNode \u003d excludedNodes.put(localMachine, localMachine);\n     if (oldNode \u003d\u003d null) { // was not in the excluded list\n-      if (isGoodTarget(localMachine, blocksize,\n-          maxNodesPerRack, false, results, avoidStaleNodes)) {\n-        results.add(localMachine);\n-        // Nodes under same nodegroup should be excluded.\n-        addNodeGroupToExcludedNodes(excludedNodes,\n-            localMachine.getNetworkLocation());\n+      if (addIfIsGoodTarget(localMachine, excludedNodes, blocksize,\n+          maxNodesPerRack, false, results, avoidStaleNodes) \u003e\u003d 0) {\n         return localMachine;\n       }\n     } \n \n     // try a node on local node group\n     DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n         (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes);\n     if (chosenNode !\u003d null) {\n       return chosenNode;\n     }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, \n         blocksize, maxNodesPerRack, results, avoidStaleNodes);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeDescriptor chooseLocalNode(DatanodeDescriptor localMachine,\n      Map\u003cNode, Node\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeDescriptor\u003e results, boolean avoidStaleNodes)\n        throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null)\n      return chooseRandom(NodeBase.ROOT, excludedNodes, \n          blocksize, maxNodesPerRack, results, avoidStaleNodes);\n\n    // otherwise try local machine first\n    Node oldNode \u003d excludedNodes.put(localMachine, localMachine);\n    if (oldNode \u003d\u003d null) { // was not in the excluded list\n      if (addIfIsGoodTarget(localMachine, excludedNodes, blocksize,\n          maxNodesPerRack, false, results, avoidStaleNodes) \u003e\u003d 0) {\n        return localMachine;\n      }\n    } \n\n    // try a node on local node group\n    DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n    if (chosenNode !\u003d null) {\n      return chosenNode;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {}
        }
      ]
    },
    "2887bbb33cefaac0c548eb2450a1f8e3e60f5ea7": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-3912. Detect and avoid stale datanodes for writes. Contributed by Jing Zhao\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1397211 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/10/12 11:08 AM",
      "commitName": "2887bbb33cefaac0c548eb2450a1f8e3e60f5ea7",
      "commitAuthor": "Suresh Srinivas",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-3912. Detect and avoid stale datanodes for writes. Contributed by Jing Zhao\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1397211 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "11/10/12 11:08 AM",
          "commitName": "2887bbb33cefaac0c548eb2450a1f8e3e60f5ea7",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "24/08/12 6:03 PM",
          "commitNameOld": "deead78e35b0cb81af875b5a8032cbd06c9a2dae",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 47.71,
          "commitsBetweenForRepo": 284,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,36 +1,33 @@\n-  protected DatanodeDescriptor chooseLocalNode(\n-      DatanodeDescriptor localMachine,\n-      HashMap\u003cNode, Node\u003e excludedNodes,\n-      long blocksize,\n-      int maxNodesPerRack,\n-      List\u003cDatanodeDescriptor\u003e results)\n+  protected DatanodeDescriptor chooseLocalNode(DatanodeDescriptor localMachine,\n+      HashMap\u003cNode, Node\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n+      List\u003cDatanodeDescriptor\u003e results, boolean avoidStaleNodes)\n         throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n     if (localMachine \u003d\u003d null)\n       return chooseRandom(NodeBase.ROOT, excludedNodes, \n-          blocksize, maxNodesPerRack, results);\n+          blocksize, maxNodesPerRack, results, avoidStaleNodes);\n \n     // otherwise try local machine first\n     Node oldNode \u003d excludedNodes.put(localMachine, localMachine);\n     if (oldNode \u003d\u003d null) { // was not in the excluded list\n       if (isGoodTarget(localMachine, blocksize,\n-          maxNodesPerRack, false, results)) {\n+          maxNodesPerRack, false, results, avoidStaleNodes)) {\n         results.add(localMachine);\n         // Nodes under same nodegroup should be excluded.\n         addNodeGroupToExcludedNodes(excludedNodes,\n             localMachine.getNetworkLocation());\n         return localMachine;\n       }\n     } \n \n     // try a node on local node group\n     DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n         (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n-        blocksize, maxNodesPerRack, results);\n+        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n     if (chosenNode !\u003d null) {\n       return chosenNode;\n     }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, \n-        blocksize, maxNodesPerRack, results);\n+        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeDescriptor chooseLocalNode(DatanodeDescriptor localMachine,\n      HashMap\u003cNode, Node\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeDescriptor\u003e results, boolean avoidStaleNodes)\n        throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null)\n      return chooseRandom(NodeBase.ROOT, excludedNodes, \n          blocksize, maxNodesPerRack, results, avoidStaleNodes);\n\n    // otherwise try local machine first\n    Node oldNode \u003d excludedNodes.put(localMachine, localMachine);\n    if (oldNode \u003d\u003d null) { // was not in the excluded list\n      if (isGoodTarget(localMachine, blocksize,\n          maxNodesPerRack, false, results, avoidStaleNodes)) {\n        results.add(localMachine);\n        // Nodes under same nodegroup should be excluded.\n        addNodeGroupToExcludedNodes(excludedNodes,\n            localMachine.getNetworkLocation());\n        return localMachine;\n      }\n    } \n\n    // try a node on local node group\n    DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n    if (chosenNode !\u003d null) {\n      return chosenNode;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {
            "oldValue": "[localMachine-DatanodeDescriptor, excludedNodes-HashMap\u003cNode,Node\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeDescriptor\u003e]",
            "newValue": "[localMachine-DatanodeDescriptor, excludedNodes-HashMap\u003cNode,Node\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeDescriptor\u003e, avoidStaleNodes-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3912. Detect and avoid stale datanodes for writes. Contributed by Jing Zhao\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1397211 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "11/10/12 11:08 AM",
          "commitName": "2887bbb33cefaac0c548eb2450a1f8e3e60f5ea7",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "24/08/12 6:03 PM",
          "commitNameOld": "deead78e35b0cb81af875b5a8032cbd06c9a2dae",
          "commitAuthorOld": "Suresh Srinivas",
          "daysBetweenCommits": 47.71,
          "commitsBetweenForRepo": 284,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,36 +1,33 @@\n-  protected DatanodeDescriptor chooseLocalNode(\n-      DatanodeDescriptor localMachine,\n-      HashMap\u003cNode, Node\u003e excludedNodes,\n-      long blocksize,\n-      int maxNodesPerRack,\n-      List\u003cDatanodeDescriptor\u003e results)\n+  protected DatanodeDescriptor chooseLocalNode(DatanodeDescriptor localMachine,\n+      HashMap\u003cNode, Node\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n+      List\u003cDatanodeDescriptor\u003e results, boolean avoidStaleNodes)\n         throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n     if (localMachine \u003d\u003d null)\n       return chooseRandom(NodeBase.ROOT, excludedNodes, \n-          blocksize, maxNodesPerRack, results);\n+          blocksize, maxNodesPerRack, results, avoidStaleNodes);\n \n     // otherwise try local machine first\n     Node oldNode \u003d excludedNodes.put(localMachine, localMachine);\n     if (oldNode \u003d\u003d null) { // was not in the excluded list\n       if (isGoodTarget(localMachine, blocksize,\n-          maxNodesPerRack, false, results)) {\n+          maxNodesPerRack, false, results, avoidStaleNodes)) {\n         results.add(localMachine);\n         // Nodes under same nodegroup should be excluded.\n         addNodeGroupToExcludedNodes(excludedNodes,\n             localMachine.getNetworkLocation());\n         return localMachine;\n       }\n     } \n \n     // try a node on local node group\n     DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n         (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n-        blocksize, maxNodesPerRack, results);\n+        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n     if (chosenNode !\u003d null) {\n       return chosenNode;\n     }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, \n-        blocksize, maxNodesPerRack, results);\n+        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeDescriptor chooseLocalNode(DatanodeDescriptor localMachine,\n      HashMap\u003cNode, Node\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeDescriptor\u003e results, boolean avoidStaleNodes)\n        throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null)\n      return chooseRandom(NodeBase.ROOT, excludedNodes, \n          blocksize, maxNodesPerRack, results, avoidStaleNodes);\n\n    // otherwise try local machine first\n    Node oldNode \u003d excludedNodes.put(localMachine, localMachine);\n    if (oldNode \u003d\u003d null) { // was not in the excluded list\n      if (isGoodTarget(localMachine, blocksize,\n          maxNodesPerRack, false, results, avoidStaleNodes)) {\n        results.add(localMachine);\n        // Nodes under same nodegroup should be excluded.\n        addNodeGroupToExcludedNodes(excludedNodes,\n            localMachine.getNetworkLocation());\n        return localMachine;\n      }\n    } \n\n    // try a node on local node group\n    DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n    if (chosenNode !\u003d null) {\n      return chosenNode;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results, avoidStaleNodes);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java",
          "extendedDetails": {}
        }
      ]
    },
    "4d0cab2729e2bdb1742b62dba69bd30ab69c868e": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3601. Add BlockPlacementPolicyWithNodeGroup to support block placement with 4-layer network topology.  Contributed by Junping Du\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1357442 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/07/12 6:31 PM",
      "commitName": "4d0cab2729e2bdb1742b62dba69bd30ab69c868e",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,36 @@\n+  protected DatanodeDescriptor chooseLocalNode(\n+      DatanodeDescriptor localMachine,\n+      HashMap\u003cNode, Node\u003e excludedNodes,\n+      long blocksize,\n+      int maxNodesPerRack,\n+      List\u003cDatanodeDescriptor\u003e results)\n+        throws NotEnoughReplicasException {\n+    // if no local machine, randomly choose one node\n+    if (localMachine \u003d\u003d null)\n+      return chooseRandom(NodeBase.ROOT, excludedNodes, \n+          blocksize, maxNodesPerRack, results);\n+\n+    // otherwise try local machine first\n+    Node oldNode \u003d excludedNodes.put(localMachine, localMachine);\n+    if (oldNode \u003d\u003d null) { // was not in the excluded list\n+      if (isGoodTarget(localMachine, blocksize,\n+          maxNodesPerRack, false, results)) {\n+        results.add(localMachine);\n+        // Nodes under same nodegroup should be excluded.\n+        addNodeGroupToExcludedNodes(excludedNodes,\n+            localMachine.getNetworkLocation());\n+        return localMachine;\n+      }\n+    } \n+\n+    // try a node on local node group\n+    DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n+        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n+        blocksize, maxNodesPerRack, results);\n+    if (chosenNode !\u003d null) {\n+      return chosenNode;\n+    }\n+    // try a node on local rack\n+    return chooseLocalRack(localMachine, excludedNodes, \n+        blocksize, maxNodesPerRack, results);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeDescriptor chooseLocalNode(\n      DatanodeDescriptor localMachine,\n      HashMap\u003cNode, Node\u003e excludedNodes,\n      long blocksize,\n      int maxNodesPerRack,\n      List\u003cDatanodeDescriptor\u003e results)\n        throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null)\n      return chooseRandom(NodeBase.ROOT, excludedNodes, \n          blocksize, maxNodesPerRack, results);\n\n    // otherwise try local machine first\n    Node oldNode \u003d excludedNodes.put(localMachine, localMachine);\n    if (oldNode \u003d\u003d null) { // was not in the excluded list\n      if (isGoodTarget(localMachine, blocksize,\n          maxNodesPerRack, false, results)) {\n        results.add(localMachine);\n        // Nodes under same nodegroup should be excluded.\n        addNodeGroupToExcludedNodes(excludedNodes,\n            localMachine.getNetworkLocation());\n        return localMachine;\n      }\n    } \n\n    // try a node on local node group\n    DatanodeDescriptor chosenNode \u003d chooseLocalNodeGroup(\n        (NetworkTopologyWithNodeGroup)clusterMap, localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results);\n    if (chosenNode !\u003d null) {\n      return chosenNode;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, \n        blocksize, maxNodesPerRack, results);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.java"
    }
  }
}