{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RpcProgramNfs3.java",
  "functionName": "readdirplus",
  "functionId": "readdirplus___xdr-XDR__securityHandler-SecurityHandler__remoteAddress-SocketAddress",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
  "functionStartLine": 1694,
  "functionEndLine": 1868,
  "numCommitsSeen": 105,
  "timeTaken": 6909,
  "changeHistory": [
    "05145404d54c6c3cc65833d317977ba12599514d",
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
    "d6602b5f39833611b4afa4581552f6c4c37e23a8",
    "645a8f2a4d09acb5a21820f52ee78784d9e4cc8a",
    "c6f20007ebda509b39a7e4098b99e9b43d73d5b2",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f",
    "5e5e35b1856293503124b77d5d4998a4d8e83082",
    "195f31a8ef6b15e1962ab945b2f83af98e0058c6",
    "27f106e2261d0dfdb04e3d08dfd84ca4fdfad244",
    "d71d40a63d198991077d5babd70be5e9787a53f1",
    "cd9182d8b5f60428f6c91b0eb0b2e61d52a07020",
    "7b28f363b1b3f12cecc92d0bba8eb3021b67b48e",
    "c9aa74743773c61be938cc1a6ea811ae1404bca2",
    "9ff3836a367737d6dfcb12f50c8bd2f1b2233e37",
    "2ecab65e3e290a1ee192b39ec70868863853543a",
    "3bfd18c6b0483ae27eff6d53bda934e67dda5464",
    "05f35518f19d48890770128727289582cca3457b",
    "a9befa6f0a8a27b49b1e6483e749661f493f06cf",
    "613979c8fdacf25fd563395ecc399c4de94d3ee7",
    "15632cd76f12c2f7df50d0df4865fbe3d8261597",
    "37f587563a943a827fbff865f5302bac6d202415"
  ],
  "changeHistoryShort": {
    "05145404d54c6c3cc65833d317977ba12599514d": "Ybodychange",
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": "Ybodychange",
    "d6602b5f39833611b4afa4581552f6c4c37e23a8": "Ybodychange",
    "645a8f2a4d09acb5a21820f52ee78784d9e4cc8a": "Ybodychange",
    "c6f20007ebda509b39a7e4098b99e9b43d73d5b2": "Ybodychange",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": "Ybodychange",
    "5e5e35b1856293503124b77d5d4998a4d8e83082": "Ybodychange",
    "195f31a8ef6b15e1962ab945b2f83af98e0058c6": "Ybodychange",
    "27f106e2261d0dfdb04e3d08dfd84ca4fdfad244": "Ybodychange",
    "d71d40a63d198991077d5babd70be5e9787a53f1": "Ybodychange",
    "cd9182d8b5f60428f6c91b0eb0b2e61d52a07020": "Ybodychange",
    "7b28f363b1b3f12cecc92d0bba8eb3021b67b48e": "Ybodychange",
    "c9aa74743773c61be938cc1a6ea811ae1404bca2": "Ybodychange",
    "9ff3836a367737d6dfcb12f50c8bd2f1b2233e37": "Ybodychange",
    "2ecab65e3e290a1ee192b39ec70868863853543a": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
    "3bfd18c6b0483ae27eff6d53bda934e67dda5464": "Ybodychange",
    "05f35518f19d48890770128727289582cca3457b": "Ybodychange",
    "a9befa6f0a8a27b49b1e6483e749661f493f06cf": "Ybodychange",
    "613979c8fdacf25fd563395ecc399c4de94d3ee7": "Ymultichange(Yparameterchange,Ybodychange)",
    "15632cd76f12c2f7df50d0df4865fbe3d8261597": "Ymultichange(Yparameterchange,Ybodychange)",
    "37f587563a943a827fbff865f5302bac6d202415": "Yintroduced"
  },
  "changeHistoryDetails": {
    "05145404d54c6c3cc65833d317977ba12599514d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14339. Inconsistent log level practices in RpcProgramNfs3.java. Contributed by Anuhan Torgonshar.\n",
      "commitDate": "24/06/19 8:30 AM",
      "commitName": "05145404d54c6c3cc65833d317977ba12599514d",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "17/06/19 10:45 PM",
      "commitNameOld": "098c325a78dce2697ec94a22a4a3981fa5a3849e",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 6.41,
      "commitsBetweenForRepo": 42,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,175 +1,175 @@\n   READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n \n \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d READDIRPLUS3Request.deserialize(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     int namenodeId \u003d handle.getNamenodeId();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negative cookie: {}\",\n           cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request: {}\",\n           dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request: {}\",\n           maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileHandle: {} cookie: {} dirCount: {} \" +\n               \"maxCount: {} client: {}\",\n           handle.dumpFileHandle(), cookie, dirCount, maxCount, remoteAddress);\n     }\n     DFSClient dfsClient \u003d\n         clientCache.getDfsClient(securityHandler.getUser(), namenodeId);\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting;\n     Nfs3FileAttributes postOpDirAttr;\n     long dotdotFileId \u003d 0;\n     HdfsFileStatus dotdotStatus \u003d null;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId: {}\", handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDirectory()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId: {}\",\n             handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         if (aixCompatMode) {\n           // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n           // the same cookieverf value even across VFS-level readdir calls,\n           // instead of getting a new cookieverf for every VFS-level readdir\n           // call. This means that whenever a readdir call is made by an AIX NFS\n           // client for a given directory, and that directory is subsequently\n           // modified, thus changing its mtime, no later readdir calls will\n           // succeed for that directory from AIX until the FS is\n           // unmounted/remounted. See HDFS-6549 for more info.\n           LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n               \"mismatches.\");\n         } else {\n           LOG.error(\"cookieverf mismatch. request cookieverf: {} \" +\n                   \"dir cookieverf: {}\",\n               cookieVerf, dirStatus.getModificationTime());\n           return new READDIRPLUS3Response(\n               Nfs3Status.NFS3ERR_BAD_COOKIE,\n               Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug),\n               0, null);\n         }\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path: \"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes(Charset.forName(\"UTF-8\"));\n       }\n \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId: {}\", handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception\", e);\n       int status \u003d mapErrorStatus(e);\n       return new READDIRPLUS3Response(status);\n     }\n \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileId(), namenodeId));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n               iug), new FileHandle(dotdotFileId, namenodeId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId, namenodeId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n-          LOG.error(\"Can\u0027t get file attributes for fileId: {}\", fileId, e);\n+          LOG.info(\"Can\u0027t get file attributes for fileId: {}\", fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId, namenodeId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n-          LOG.error(\"Can\u0027t get file attributes for fileId: {}\", fileId, e);\n+          LOG.info(\"Can\u0027t get file attributes for fileId: {}\", fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n\n\n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d READDIRPLUS3Request.deserialize(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    int namenodeId \u003d handle.getNamenodeId();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negative cookie: {}\",\n          cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request: {}\",\n          dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request: {}\",\n          maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileHandle: {} cookie: {} dirCount: {} \" +\n              \"maxCount: {} client: {}\",\n          handle.dumpFileHandle(), cookie, dirCount, maxCount, remoteAddress);\n    }\n    DFSClient dfsClient \u003d\n        clientCache.getDfsClient(securityHandler.getUser(), namenodeId);\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting;\n    Nfs3FileAttributes postOpDirAttr;\n    long dotdotFileId \u003d 0;\n    HdfsFileStatus dotdotStatus \u003d null;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId: {}\", handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDirectory()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId: {}\",\n            handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        if (aixCompatMode) {\n          // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n          // the same cookieverf value even across VFS-level readdir calls,\n          // instead of getting a new cookieverf for every VFS-level readdir\n          // call. This means that whenever a readdir call is made by an AIX NFS\n          // client for a given directory, and that directory is subsequently\n          // modified, thus changing its mtime, no later readdir calls will\n          // succeed for that directory from AIX until the FS is\n          // unmounted/remounted. See HDFS-6549 for more info.\n          LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n              \"mismatches.\");\n        } else {\n          LOG.error(\"cookieverf mismatch. request cookieverf: {} \" +\n                  \"dir cookieverf: {}\",\n              cookieVerf, dirStatus.getModificationTime());\n          return new READDIRPLUS3Response(\n              Nfs3Status.NFS3ERR_BAD_COOKIE,\n              Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug),\n              0, null);\n        }\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path: \"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes(Charset.forName(\"UTF-8\"));\n      }\n\n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId: {}\", handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception\", e);\n      int status \u003d mapErrorStatus(e);\n      return new READDIRPLUS3Response(status);\n    }\n\n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n\n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n\n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId(), namenodeId));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n              iug), new FileHandle(dotdotFileId, namenodeId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId, namenodeId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.info(\"Can\u0027t get file attributes for fileId: {}\", fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId, namenodeId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.info(\"Can\u0027t get file attributes for fileId: {}\", fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10571. Use Log.*(Object, Throwable) overload to log exceptions.\nContributed by Andras Bokor.\n",
      "commitDate": "14/02/18 8:20 AM",
      "commitName": "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "10/10/17 10:38 AM",
      "commitNameOld": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
      "commitAuthorOld": "Jitendra Pandey",
      "daysBetweenCommits": 126.95,
      "commitsBetweenForRepo": 833,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,172 +1,175 @@\n   READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n \n \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d READDIRPLUS3Request.deserialize(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     int namenodeId \u003d handle.getNamenodeId();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n-      LOG.error(\"Invalid READDIRPLUS request, with negative cookie: \" + cookie);\n+      LOG.error(\"Invalid READDIRPLUS request, with negative cookie: {}\",\n+          cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n-      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request: \" + dirCount);\n+      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request: {}\",\n+          dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n-      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request: \" + maxCount);\n+      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request: {}\",\n+          maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"NFS READDIRPLUS fileHandle: \" + handle.dumpFileHandle()\n-          + \" cookie: \" + cookie + \" dirCount: \" + dirCount + \" maxCount: \"\n-          + maxCount + \" client: \" + remoteAddress);\n+      LOG.debug(\"NFS READDIRPLUS fileHandle: {} cookie: {} dirCount: {} \" +\n+              \"maxCount: {} client: {}\",\n+          handle.dumpFileHandle(), cookie, dirCount, maxCount, remoteAddress);\n     }\n-\n     DFSClient dfsClient \u003d\n         clientCache.getDfsClient(securityHandler.getUser(), namenodeId);\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting;\n     Nfs3FileAttributes postOpDirAttr;\n     long dotdotFileId \u003d 0;\n     HdfsFileStatus dotdotStatus \u003d null;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n-        LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n+        LOG.info(\"Can\u0027t get path for fileId: {}\", handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDirectory()) {\n-        LOG.error(\"Can\u0027t readdirplus for regular file, fileId: \"\n-            + handle.getFileId());\n+        LOG.error(\"Can\u0027t readdirplus for regular file, fileId: {}\",\n+            handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         if (aixCompatMode) {\n           // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n           // the same cookieverf value even across VFS-level readdir calls,\n           // instead of getting a new cookieverf for every VFS-level readdir\n           // call. This means that whenever a readdir call is made by an AIX NFS\n           // client for a given directory, and that directory is subsequently\n           // modified, thus changing its mtime, no later readdir calls will\n           // succeed for that directory from AIX until the FS is\n           // unmounted/remounted. See HDFS-6549 for more info.\n           LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n               \"mismatches.\");\n         } else {\n-          LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n-              + \" dir cookieverf: \" + dirStatus.getModificationTime());\n+          LOG.error(\"cookieverf mismatch. request cookieverf: {} \" +\n+                  \"dir cookieverf: {}\",\n+              cookieVerf, dirStatus.getModificationTime());\n           return new READDIRPLUS3Response(\n               Nfs3Status.NFS3ERR_BAD_COOKIE,\n               Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug),\n               0, null);\n         }\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path: \"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes(Charset.forName(\"UTF-8\"));\n       }\n \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n-        LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n+        LOG.info(\"Can\u0027t get path for fileId: {}\", handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n-      LOG.warn(\"Exception \", e);\n+      LOG.warn(\"Exception\", e);\n       int status \u003d mapErrorStatus(e);\n       return new READDIRPLUS3Response(status);\n     }\n \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileId(), namenodeId));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n               iug), new FileHandle(dotdotFileId, namenodeId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId, namenodeId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n-          LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n+          LOG.error(\"Can\u0027t get file attributes for fileId: {}\", fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId, namenodeId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n-          LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n+          LOG.error(\"Can\u0027t get file attributes for fileId: {}\", fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n\n\n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d READDIRPLUS3Request.deserialize(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    int namenodeId \u003d handle.getNamenodeId();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negative cookie: {}\",\n          cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request: {}\",\n          dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request: {}\",\n          maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileHandle: {} cookie: {} dirCount: {} \" +\n              \"maxCount: {} client: {}\",\n          handle.dumpFileHandle(), cookie, dirCount, maxCount, remoteAddress);\n    }\n    DFSClient dfsClient \u003d\n        clientCache.getDfsClient(securityHandler.getUser(), namenodeId);\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting;\n    Nfs3FileAttributes postOpDirAttr;\n    long dotdotFileId \u003d 0;\n    HdfsFileStatus dotdotStatus \u003d null;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId: {}\", handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDirectory()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId: {}\",\n            handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        if (aixCompatMode) {\n          // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n          // the same cookieverf value even across VFS-level readdir calls,\n          // instead of getting a new cookieverf for every VFS-level readdir\n          // call. This means that whenever a readdir call is made by an AIX NFS\n          // client for a given directory, and that directory is subsequently\n          // modified, thus changing its mtime, no later readdir calls will\n          // succeed for that directory from AIX until the FS is\n          // unmounted/remounted. See HDFS-6549 for more info.\n          LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n              \"mismatches.\");\n        } else {\n          LOG.error(\"cookieverf mismatch. request cookieverf: {} \" +\n                  \"dir cookieverf: {}\",\n              cookieVerf, dirStatus.getModificationTime());\n          return new READDIRPLUS3Response(\n              Nfs3Status.NFS3ERR_BAD_COOKIE,\n              Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug),\n              0, null);\n        }\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path: \"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes(Charset.forName(\"UTF-8\"));\n      }\n\n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId: {}\", handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception\", e);\n      int status \u003d mapErrorStatus(e);\n      return new READDIRPLUS3Response(status);\n    }\n\n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n\n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n\n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId(), namenodeId));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n              iug), new FileHandle(dotdotFileId, namenodeId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId, namenodeId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId: {}\", fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId, namenodeId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId: {}\", fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "d6602b5f39833611b4afa4581552f6c4c37e23a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11575. Supporting HDFS NFS gateway with Federated HDFS. Contributed by Mukul Kumar Singh.\n",
      "commitDate": "10/10/17 10:38 AM",
      "commitName": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
      "commitAuthor": "Jitendra Pandey",
      "commitDateOld": "14/08/17 9:57 PM",
      "commitNameOld": "645a8f2a4d09acb5a21820f52ee78784d9e4cc8a",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 56.53,
      "commitsBetweenForRepo": 520,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,169 +1,172 @@\n   READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n \n-    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n-    if (dfsClient \u003d\u003d null) {\n-      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n-    }\n \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d READDIRPLUS3Request.deserialize(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n+    int namenodeId \u003d handle.getNamenodeId();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negative cookie: \" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request: \" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request: \" + maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n-          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount\n-          + \" client: \" + remoteAddress);\n+      LOG.debug(\"NFS READDIRPLUS fileHandle: \" + handle.dumpFileHandle()\n+          + \" cookie: \" + cookie + \" dirCount: \" + dirCount + \" maxCount: \"\n+          + maxCount + \" client: \" + remoteAddress);\n+    }\n+\n+    DFSClient dfsClient \u003d\n+        clientCache.getDfsClient(securityHandler.getUser(), namenodeId);\n+    if (dfsClient \u003d\u003d null) {\n+      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting;\n     Nfs3FileAttributes postOpDirAttr;\n     long dotdotFileId \u003d 0;\n     HdfsFileStatus dotdotStatus \u003d null;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDirectory()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId: \"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         if (aixCompatMode) {\n           // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n           // the same cookieverf value even across VFS-level readdir calls,\n           // instead of getting a new cookieverf for every VFS-level readdir\n           // call. This means that whenever a readdir call is made by an AIX NFS\n           // client for a given directory, and that directory is subsequently\n           // modified, thus changing its mtime, no later readdir calls will\n           // succeed for that directory from AIX until the FS is\n           // unmounted/remounted. See HDFS-6549 for more info.\n           LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n               \"mismatches.\");\n         } else {\n           LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n               + \" dir cookieverf: \" + dirStatus.getModificationTime());\n           return new READDIRPLUS3Response(\n               Nfs3Status.NFS3ERR_BAD_COOKIE,\n               Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug),\n               0, null);\n         }\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path: \"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes(Charset.forName(\"UTF-8\"));\n       }\n \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       int status \u003d mapErrorStatus(e);\n       return new READDIRPLUS3Response(status);\n     }\n \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n-              postOpDirAttr.getFileId()));\n+              postOpDirAttr.getFileId(), namenodeId));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n-              iug), new FileHandle(dotdotFileId));\n+              iug), new FileHandle(dotdotFileId, namenodeId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n-        FileHandle childHandle \u003d new FileHandle(fileId);\n+        FileHandle childHandle \u003d new FileHandle(fileId, namenodeId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n-        FileHandle childHandle \u003d new FileHandle(fileId);\n+        FileHandle childHandle \u003d new FileHandle(fileId, namenodeId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n\n\n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d READDIRPLUS3Request.deserialize(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    int namenodeId \u003d handle.getNamenodeId();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negative cookie: \" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request: \" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request: \" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileHandle: \" + handle.dumpFileHandle()\n          + \" cookie: \" + cookie + \" dirCount: \" + dirCount + \" maxCount: \"\n          + maxCount + \" client: \" + remoteAddress);\n    }\n\n    DFSClient dfsClient \u003d\n        clientCache.getDfsClient(securityHandler.getUser(), namenodeId);\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting;\n    Nfs3FileAttributes postOpDirAttr;\n    long dotdotFileId \u003d 0;\n    HdfsFileStatus dotdotStatus \u003d null;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDirectory()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId: \"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        if (aixCompatMode) {\n          // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n          // the same cookieverf value even across VFS-level readdir calls,\n          // instead of getting a new cookieverf for every VFS-level readdir\n          // call. This means that whenever a readdir call is made by an AIX NFS\n          // client for a given directory, and that directory is subsequently\n          // modified, thus changing its mtime, no later readdir calls will\n          // succeed for that directory from AIX until the FS is\n          // unmounted/remounted. See HDFS-6549 for more info.\n          LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n              \"mismatches.\");\n        } else {\n          LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n              + \" dir cookieverf: \" + dirStatus.getModificationTime());\n          return new READDIRPLUS3Response(\n              Nfs3Status.NFS3ERR_BAD_COOKIE,\n              Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug),\n              0, null);\n        }\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path: \"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes(Charset.forName(\"UTF-8\"));\n      }\n\n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new READDIRPLUS3Response(status);\n    }\n\n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n\n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n\n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId(), namenodeId));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n              iug), new FileHandle(dotdotFileId, namenodeId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId, namenodeId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId, namenodeId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "645a8f2a4d09acb5a21820f52ee78784d9e4cc8a": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14726. Mark FileStatus::isDir as final\n",
      "commitDate": "14/08/17 9:57 PM",
      "commitName": "645a8f2a4d09acb5a21820f52ee78784d9e4cc8a",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "16/01/17 2:53 PM",
      "commitNameOld": "d1d0b3e1fd593d590aaf2e3db8f730a296b20aa1",
      "commitAuthorOld": "Jitendra Pandey",
      "daysBetweenCommits": 210.25,
      "commitsBetweenForRepo": 1196,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,169 +1,169 @@\n   READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d READDIRPLUS3Request.deserialize(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negative cookie: \" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request: \" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request: \" + maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount\n           + \" client: \" + remoteAddress);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting;\n     Nfs3FileAttributes postOpDirAttr;\n     long dotdotFileId \u003d 0;\n     HdfsFileStatus dotdotStatus \u003d null;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n-      if (!dirStatus.isDir()) {\n+      if (!dirStatus.isDirectory()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId: \"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         if (aixCompatMode) {\n           // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n           // the same cookieverf value even across VFS-level readdir calls,\n           // instead of getting a new cookieverf for every VFS-level readdir\n           // call. This means that whenever a readdir call is made by an AIX NFS\n           // client for a given directory, and that directory is subsequently\n           // modified, thus changing its mtime, no later readdir calls will\n           // succeed for that directory from AIX until the FS is\n           // unmounted/remounted. See HDFS-6549 for more info.\n           LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n               \"mismatches.\");\n         } else {\n           LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n               + \" dir cookieverf: \" + dirStatus.getModificationTime());\n           return new READDIRPLUS3Response(\n               Nfs3Status.NFS3ERR_BAD_COOKIE,\n               Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug),\n               0, null);\n         }\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path: \"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes(Charset.forName(\"UTF-8\"));\n       }\n \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       int status \u003d mapErrorStatus(e);\n       return new READDIRPLUS3Response(status);\n     }\n \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileId()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n               iug), new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n\n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d READDIRPLUS3Request.deserialize(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negative cookie: \" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request: \" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request: \" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount\n          + \" client: \" + remoteAddress);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting;\n    Nfs3FileAttributes postOpDirAttr;\n    long dotdotFileId \u003d 0;\n    HdfsFileStatus dotdotStatus \u003d null;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDirectory()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId: \"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        if (aixCompatMode) {\n          // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n          // the same cookieverf value even across VFS-level readdir calls,\n          // instead of getting a new cookieverf for every VFS-level readdir\n          // call. This means that whenever a readdir call is made by an AIX NFS\n          // client for a given directory, and that directory is subsequently\n          // modified, thus changing its mtime, no later readdir calls will\n          // succeed for that directory from AIX until the FS is\n          // unmounted/remounted. See HDFS-6549 for more info.\n          LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n              \"mismatches.\");\n        } else {\n          LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n              + \" dir cookieverf: \" + dirStatus.getModificationTime());\n          return new READDIRPLUS3Response(\n              Nfs3Status.NFS3ERR_BAD_COOKIE,\n              Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug),\n              0, null);\n        }\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path: \"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes(Charset.forName(\"UTF-8\"));\n      }\n\n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new READDIRPLUS3Response(status);\n    }\n\n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n\n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n\n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n              iug), new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "c6f20007ebda509b39a7e4098b99e9b43d73d5b2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7733. NFS: readdir/readdirplus return null directory attribute on failure. (Contributed by Arpit Agarwal)\n",
      "commitDate": "04/02/15 4:25 PM",
      "commitName": "c6f20007ebda509b39a7e4098b99e9b43d73d5b2",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "28/01/15 12:56 PM",
      "commitNameOld": "f37849188b05a6251584de1aed5e66d5dfa7da4f",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 7.15,
      "commitsBetweenForRepo": 57,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,166 +1,169 @@\n   READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d READDIRPLUS3Request.deserialize(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negative cookie: \" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request: \" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request: \" + maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount\n           + \" client: \" + remoteAddress);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting;\n     Nfs3FileAttributes postOpDirAttr;\n     long dotdotFileId \u003d 0;\n     HdfsFileStatus dotdotStatus \u003d null;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId: \"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         if (aixCompatMode) {\n           // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n           // the same cookieverf value even across VFS-level readdir calls,\n           // instead of getting a new cookieverf for every VFS-level readdir\n           // call. This means that whenever a readdir call is made by an AIX NFS\n           // client for a given directory, and that directory is subsequently\n           // modified, thus changing its mtime, no later readdir calls will\n           // succeed for that directory from AIX until the FS is\n           // unmounted/remounted. See HDFS-6549 for more info.\n           LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n               \"mismatches.\");\n         } else {\n           LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n               + \" dir cookieverf: \" + dirStatus.getModificationTime());\n-          return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n+          return new READDIRPLUS3Response(\n+              Nfs3Status.NFS3ERR_BAD_COOKIE,\n+              Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug),\n+              0, null);\n         }\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path: \"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes(Charset.forName(\"UTF-8\"));\n       }\n \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       int status \u003d mapErrorStatus(e);\n       return new READDIRPLUS3Response(status);\n     }\n \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileId()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n               iug), new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n\n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d READDIRPLUS3Request.deserialize(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negative cookie: \" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request: \" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request: \" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount\n          + \" client: \" + remoteAddress);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting;\n    Nfs3FileAttributes postOpDirAttr;\n    long dotdotFileId \u003d 0;\n    HdfsFileStatus dotdotStatus \u003d null;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId: \"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        if (aixCompatMode) {\n          // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n          // the same cookieverf value even across VFS-level readdir calls,\n          // instead of getting a new cookieverf for every VFS-level readdir\n          // call. This means that whenever a readdir call is made by an AIX NFS\n          // client for a given directory, and that directory is subsequently\n          // modified, thus changing its mtime, no later readdir calls will\n          // succeed for that directory from AIX until the FS is\n          // unmounted/remounted. See HDFS-6549 for more info.\n          LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n              \"mismatches.\");\n        } else {\n          LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n              + \" dir cookieverf: \" + dirStatus.getModificationTime());\n          return new READDIRPLUS3Response(\n              Nfs3Status.NFS3ERR_BAD_COOKIE,\n              Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug),\n              0, null);\n        }\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path: \"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes(Charset.forName(\"UTF-8\"));\n      }\n\n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new READDIRPLUS3Response(status);\n    }\n\n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n\n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n\n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n              iug), new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7423. various typos and message formatting fixes in nfs daemon and doc. (Charles Lamb via yliu)\n",
      "commitDate": "28/01/15 12:56 PM",
      "commitName": "f37849188b05a6251584de1aed5e66d5dfa7da4f",
      "commitAuthor": "yliu",
      "commitDateOld": "19/01/15 5:29 PM",
      "commitNameOld": "5e5e35b1856293503124b77d5d4998a4d8e83082",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 8.81,
      "commitsBetweenForRepo": 76,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,166 +1,166 @@\n   READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d READDIRPLUS3Request.deserialize(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n-      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n+      LOG.error(\"Invalid READDIRPLUS request, with negative cookie: \" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n-      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n+      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request: \" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n-      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n+      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request: \" + maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount\n-          + \" client:\" + remoteAddress);\n+          + \" client: \" + remoteAddress);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting;\n     Nfs3FileAttributes postOpDirAttr;\n     long dotdotFileId \u003d 0;\n     HdfsFileStatus dotdotStatus \u003d null;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n-        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n+        LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n-        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n+        LOG.error(\"Can\u0027t readdirplus for regular file, fileId: \"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         if (aixCompatMode) {\n           // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n           // the same cookieverf value even across VFS-level readdir calls,\n           // instead of getting a new cookieverf for every VFS-level readdir\n           // call. This means that whenever a readdir call is made by an AIX NFS\n           // client for a given directory, and that directory is subsequently\n           // modified, thus changing its mtime, no later readdir calls will\n           // succeed for that directory from AIX until the FS is\n           // unmounted/remounted. See HDFS-6549 for more info.\n           LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n               \"mismatches.\");\n         } else {\n           LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n               + \" dir cookieverf: \" + dirStatus.getModificationTime());\n           return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n         }\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n-          throw new IOException(\"Can\u0027t get path for handle path:\"\n+          throw new IOException(\"Can\u0027t get path for handle path: \"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes(Charset.forName(\"UTF-8\"));\n       }\n \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n-        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n+        LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       int status \u003d mapErrorStatus(e);\n       return new READDIRPLUS3Response(status);\n     }\n \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileId()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n               iug), new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n-          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n+          LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n-          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n+          LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n\n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d READDIRPLUS3Request.deserialize(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negative cookie: \" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request: \" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request: \" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount\n          + \" client: \" + remoteAddress);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting;\n    Nfs3FileAttributes postOpDirAttr;\n    long dotdotFileId \u003d 0;\n    HdfsFileStatus dotdotStatus \u003d null;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId: \"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        if (aixCompatMode) {\n          // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n          // the same cookieverf value even across VFS-level readdir calls,\n          // instead of getting a new cookieverf for every VFS-level readdir\n          // call. This means that whenever a readdir call is made by an AIX NFS\n          // client for a given directory, and that directory is subsequently\n          // modified, thus changing its mtime, no later readdir calls will\n          // succeed for that directory from AIX until the FS is\n          // unmounted/remounted. See HDFS-6549 for more info.\n          LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n              \"mismatches.\");\n        } else {\n          LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n              + \" dir cookieverf: \" + dirStatus.getModificationTime());\n          return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n        }\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path: \"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes(Charset.forName(\"UTF-8\"));\n      }\n\n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId: \" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new READDIRPLUS3Response(status);\n    }\n\n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n\n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n\n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n              iug), new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId: \" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "5e5e35b1856293503124b77d5d4998a4d8e83082": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7640. print NFS Client in the NFS log. Contributed by Brandon Li.\n",
      "commitDate": "19/01/15 5:29 PM",
      "commitName": "5e5e35b1856293503124b77d5d4998a4d8e83082",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "11/12/14 3:40 PM",
      "commitNameOld": "f6f2a3f1c73266bfedd802eacde60d8b19b81015",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 39.08,
      "commitsBetweenForRepo": 202,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,165 +1,166 @@\n   READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d READDIRPLUS3Request.deserialize(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n-          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n+          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount\n+          + \" client:\" + remoteAddress);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting;\n     Nfs3FileAttributes postOpDirAttr;\n     long dotdotFileId \u003d 0;\n     HdfsFileStatus dotdotStatus \u003d null;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         if (aixCompatMode) {\n           // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n           // the same cookieverf value even across VFS-level readdir calls,\n           // instead of getting a new cookieverf for every VFS-level readdir\n           // call. This means that whenever a readdir call is made by an AIX NFS\n           // client for a given directory, and that directory is subsequently\n           // modified, thus changing its mtime, no later readdir calls will\n           // succeed for that directory from AIX until the FS is\n           // unmounted/remounted. See HDFS-6549 for more info.\n           LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n               \"mismatches.\");\n         } else {\n           LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n               + \" dir cookieverf: \" + dirStatus.getModificationTime());\n           return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n         }\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes(Charset.forName(\"UTF-8\"));\n       }\n \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       int status \u003d mapErrorStatus(e);\n       return new READDIRPLUS3Response(status);\n     }\n \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileId()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n               iug), new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n\n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d READDIRPLUS3Request.deserialize(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount\n          + \" client:\" + remoteAddress);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting;\n    Nfs3FileAttributes postOpDirAttr;\n    long dotdotFileId \u003d 0;\n    HdfsFileStatus dotdotStatus \u003d null;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        if (aixCompatMode) {\n          // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n          // the same cookieverf value even across VFS-level readdir calls,\n          // instead of getting a new cookieverf for every VFS-level readdir\n          // call. This means that whenever a readdir call is made by an AIX NFS\n          // client for a given directory, and that directory is subsequently\n          // modified, thus changing its mtime, no later readdir calls will\n          // succeed for that directory from AIX until the FS is\n          // unmounted/remounted. See HDFS-6549 for more info.\n          LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n              \"mismatches.\");\n        } else {\n          LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n              + \" dir cookieverf: \" + dirStatus.getModificationTime());\n          return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n        }\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes(Charset.forName(\"UTF-8\"));\n      }\n\n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new READDIRPLUS3Response(status);\n    }\n\n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n\n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n\n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n              iug), new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "195f31a8ef6b15e1962ab945b2f83af98e0058c6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7502. Fix findbugs warning in hdfs-nfs project. Contributed by Brandon Li.\n",
      "commitDate": "09/12/14 8:42 PM",
      "commitName": "195f31a8ef6b15e1962ab945b2f83af98e0058c6",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "04/12/14 10:46 AM",
      "commitNameOld": "1bbcc3d0320b9435317bfeaa078af22d4de8d00c",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 5.41,
      "commitsBetweenForRepo": 46,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,165 +1,165 @@\n   READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d READDIRPLUS3Request.deserialize(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting;\n     Nfs3FileAttributes postOpDirAttr;\n     long dotdotFileId \u003d 0;\n     HdfsFileStatus dotdotStatus \u003d null;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         if (aixCompatMode) {\n           // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n           // the same cookieverf value even across VFS-level readdir calls,\n           // instead of getting a new cookieverf for every VFS-level readdir\n           // call. This means that whenever a readdir call is made by an AIX NFS\n           // client for a given directory, and that directory is subsequently\n           // modified, thus changing its mtime, no later readdir calls will\n           // succeed for that directory from AIX until the FS is\n           // unmounted/remounted. See HDFS-6549 for more info.\n           LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n               \"mismatches.\");\n         } else {\n           LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n               + \" dir cookieverf: \" + dirStatus.getModificationTime());\n           return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n         }\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n-        startAfter \u003d inodeIdPath.getBytes();\n+        startAfter \u003d inodeIdPath.getBytes(Charset.forName(\"UTF-8\"));\n       }\n \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       int status \u003d mapErrorStatus(e);\n       return new READDIRPLUS3Response(status);\n     }\n \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileId()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n               iug), new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n\n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d READDIRPLUS3Request.deserialize(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting;\n    Nfs3FileAttributes postOpDirAttr;\n    long dotdotFileId \u003d 0;\n    HdfsFileStatus dotdotStatus \u003d null;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        if (aixCompatMode) {\n          // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n          // the same cookieverf value even across VFS-level readdir calls,\n          // instead of getting a new cookieverf for every VFS-level readdir\n          // call. This means that whenever a readdir call is made by an AIX NFS\n          // client for a given directory, and that directory is subsequently\n          // modified, thus changing its mtime, no later readdir calls will\n          // succeed for that directory from AIX until the FS is\n          // unmounted/remounted. See HDFS-6549 for more info.\n          LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n              \"mismatches.\");\n        } else {\n          LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n              + \" dir cookieverf: \" + dirStatus.getModificationTime());\n          return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n        }\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes(Charset.forName(\"UTF-8\"));\n      }\n\n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new READDIRPLUS3Response(status);\n    }\n\n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n\n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n\n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n              iug), new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "27f106e2261d0dfdb04e3d08dfd84ca4fdfad244": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7356. Use DirectoryListing.hasMore() directly in nfs. Contributed by Li Lu.\n",
      "commitDate": "04/11/14 3:04 PM",
      "commitName": "27f106e2261d0dfdb04e3d08dfd84ca4fdfad244",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "29/10/14 5:54 PM",
      "commitNameOld": "05b66ca0749bdb03d1df3b95199eb4f331409f7d",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 5.92,
      "commitsBetweenForRepo": 52,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,166 +1,165 @@\n   READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d READDIRPLUS3Request.deserialize(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting;\n     Nfs3FileAttributes postOpDirAttr;\n     long dotdotFileId \u003d 0;\n     HdfsFileStatus dotdotStatus \u003d null;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         if (aixCompatMode) {\n           // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n           // the same cookieverf value even across VFS-level readdir calls,\n           // instead of getting a new cookieverf for every VFS-level readdir\n           // call. This means that whenever a readdir call is made by an AIX NFS\n           // client for a given directory, and that directory is subsequently\n           // modified, thus changing its mtime, no later readdir calls will\n           // succeed for that directory from AIX until the FS is\n           // unmounted/remounted. See HDFS-6549 for more info.\n           LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n               \"mismatches.\");\n         } else {\n           LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n               + \" dir cookieverf: \" + dirStatus.getModificationTime());\n           return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n         }\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       int status \u003d mapErrorStatus(e);\n       return new READDIRPLUS3Response(status);\n     }\n \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n-    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n-        .getRemainingEntries() \u003d\u003d 0);\n+    boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileId()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n               iug), new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n\n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d READDIRPLUS3Request.deserialize(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting;\n    Nfs3FileAttributes postOpDirAttr;\n    long dotdotFileId \u003d 0;\n    HdfsFileStatus dotdotStatus \u003d null;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        if (aixCompatMode) {\n          // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n          // the same cookieverf value even across VFS-level readdir calls,\n          // instead of getting a new cookieverf for every VFS-level readdir\n          // call. This means that whenever a readdir call is made by an AIX NFS\n          // client for a given directory, and that directory is subsequently\n          // modified, thus changing its mtime, no later readdir calls will\n          // succeed for that directory from AIX until the FS is\n          // unmounted/remounted. See HDFS-6549 for more info.\n          LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n              \"mismatches.\");\n        } else {\n          LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n              + \" dir cookieverf: \" + dirStatus.getModificationTime());\n          return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n        }\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n\n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new READDIRPLUS3Response(status);\n    }\n\n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003e\u003d fstatus.length) \u0026\u0026 !dlisting.hasMore();\n\n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n\n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n              iug), new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "d71d40a63d198991077d5babd70be5e9787a53f1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7180. NFSv3 gateway frequently gets stuck due to GC. Contributed by Brandon Li\n",
      "commitDate": "22/10/14 9:27 PM",
      "commitName": "d71d40a63d198991077d5babd70be5e9787a53f1",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "21/10/14 11:49 AM",
      "commitNameOld": "4e134a02a4b6f30704b99dfb166dc361daf426ea",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 1.4,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,166 +1,166 @@\n   READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d READDIRPLUS3Request.deserialize(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n     }\n \n     HdfsFileStatus dirStatus;\n-    DirectoryListing dlisting \u003d null;\n-    Nfs3FileAttributes postOpDirAttr \u003d null;\n+    DirectoryListing dlisting;\n+    Nfs3FileAttributes postOpDirAttr;\n     long dotdotFileId \u003d 0;\n     HdfsFileStatus dotdotStatus \u003d null;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         if (aixCompatMode) {\n           // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n           // the same cookieverf value even across VFS-level readdir calls,\n           // instead of getting a new cookieverf for every VFS-level readdir\n           // call. This means that whenever a readdir call is made by an AIX NFS\n           // client for a given directory, and that directory is subsequently\n           // modified, thus changing its mtime, no later readdir calls will\n           // succeed for that directory from AIX until the FS is\n           // unmounted/remounted. See HDFS-6549 for more info.\n           LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n               \"mismatches.\");\n         } else {\n           LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n               + \" dir cookieverf: \" + dirStatus.getModificationTime());\n           return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n         }\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       int status \u003d mapErrorStatus(e);\n       return new READDIRPLUS3Response(status);\n     }\n \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileId()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n               iug), new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n\n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d READDIRPLUS3Request.deserialize(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting;\n    Nfs3FileAttributes postOpDirAttr;\n    long dotdotFileId \u003d 0;\n    HdfsFileStatus dotdotStatus \u003d null;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        if (aixCompatMode) {\n          // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n          // the same cookieverf value even across VFS-level readdir calls,\n          // instead of getting a new cookieverf for every VFS-level readdir\n          // call. This means that whenever a readdir call is made by an AIX NFS\n          // client for a given directory, and that directory is subsequently\n          // modified, thus changing its mtime, no later readdir calls will\n          // succeed for that directory from AIX until the FS is\n          // unmounted/remounted. See HDFS-6549 for more info.\n          LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n              \"mismatches.\");\n        } else {\n          LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n              + \" dir cookieverf: \" + dirStatus.getModificationTime());\n          return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n        }\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n\n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new READDIRPLUS3Response(status);\n    }\n\n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n\n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n\n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n              iug), new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "cd9182d8b5f60428f6c91b0eb0b2e61d52a07020": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6892. Add XDR packaging method for each NFS request. Contributed by Brandon Li\n",
      "commitDate": "27/08/14 11:06 AM",
      "commitName": "cd9182d8b5f60428f6c91b0eb0b2e61d52a07020",
      "commitAuthor": "brandonli",
      "commitDateOld": "21/08/14 10:53 AM",
      "commitNameOld": "7b28f363b1b3f12cecc92d0bba8eb3021b67b48e",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 6.01,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,166 +1,166 @@\n   READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n \n     READDIRPLUS3Request request \u003d null;\n     try {\n-      request \u003d new READDIRPLUS3Request(xdr);\n+      request \u003d READDIRPLUS3Request.deserialize(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpDirAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     HdfsFileStatus dotdotStatus \u003d null;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         if (aixCompatMode) {\n           // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n           // the same cookieverf value even across VFS-level readdir calls,\n           // instead of getting a new cookieverf for every VFS-level readdir\n           // call. This means that whenever a readdir call is made by an AIX NFS\n           // client for a given directory, and that directory is subsequently\n           // modified, thus changing its mtime, no later readdir calls will\n           // succeed for that directory from AIX until the FS is\n           // unmounted/remounted. See HDFS-6549 for more info.\n           LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n               \"mismatches.\");\n         } else {\n           LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n               + \" dir cookieverf: \" + dirStatus.getModificationTime());\n           return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n         }\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       int status \u003d mapErrorStatus(e);\n       return new READDIRPLUS3Response(status);\n     }\n \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileId()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n               iug), new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n\n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d READDIRPLUS3Request.deserialize(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpDirAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    HdfsFileStatus dotdotStatus \u003d null;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        if (aixCompatMode) {\n          // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n          // the same cookieverf value even across VFS-level readdir calls,\n          // instead of getting a new cookieverf for every VFS-level readdir\n          // call. This means that whenever a readdir call is made by an AIX NFS\n          // client for a given directory, and that directory is subsequently\n          // modified, thus changing its mtime, no later readdir calls will\n          // succeed for that directory from AIX until the FS is\n          // unmounted/remounted. See HDFS-6549 for more info.\n          LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n              \"mismatches.\");\n        } else {\n          LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n              + \" dir cookieverf: \" + dirStatus.getModificationTime());\n          return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n        }\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n\n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new READDIRPLUS3Response(status);\n    }\n\n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n\n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n\n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n              iug), new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "7b28f363b1b3f12cecc92d0bba8eb3021b67b48e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6890. NFS readdirplus doesn\u0027t return dotdot attributes. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1619500 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/08/14 10:53 AM",
      "commitName": "7b28f363b1b3f12cecc92d0bba8eb3021b67b48e",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "11/08/14 2:34 PM",
      "commitNameOld": "b760f20af122b3e403bf3f5c7fd6320d1e82242f",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 9.85,
      "commitsBetweenForRepo": 96,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,164 +1,166 @@\n   READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d new READDIRPLUS3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpDirAttr \u003d null;\n     long dotdotFileId \u003d 0;\n+    HdfsFileStatus dotdotStatus \u003d null;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         if (aixCompatMode) {\n           // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n           // the same cookieverf value even across VFS-level readdir calls,\n           // instead of getting a new cookieverf for every VFS-level readdir\n           // call. This means that whenever a readdir call is made by an AIX NFS\n           // client for a given directory, and that directory is subsequently\n           // modified, thus changing its mtime, no later readdir calls will\n           // succeed for that directory from AIX until the FS is\n           // unmounted/remounted. See HDFS-6549 for more info.\n           LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n               \"mismatches.\");\n         } else {\n           LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n               + \" dir cookieverf: \" + dirStatus.getModificationTime());\n           return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n         }\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n-        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n+        dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       int status \u003d mapErrorStatus(e);\n       return new READDIRPLUS3Response(status);\n     }\n \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileId()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n-          dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n+          dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n+              iug), new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n\n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d new READDIRPLUS3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpDirAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    HdfsFileStatus dotdotStatus \u003d null;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        if (aixCompatMode) {\n          // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n          // the same cookieverf value even across VFS-level readdir calls,\n          // instead of getting a new cookieverf for every VFS-level readdir\n          // call. This means that whenever a readdir call is made by an AIX NFS\n          // client for a given directory, and that directory is subsequently\n          // modified, thus changing its mtime, no later readdir calls will\n          // succeed for that directory from AIX until the FS is\n          // unmounted/remounted. See HDFS-6549 for more info.\n          LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n              \"mismatches.\");\n        } else {\n          LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n              + \" dir cookieverf: \" + dirStatus.getModificationTime());\n          return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n        }\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n\n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new READDIRPLUS3Response(status);\n    }\n\n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n\n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n\n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, Nfs3Utils.getNfs3FileAttrFromFileStatus(dotdotStatus,\n              iug), new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "c9aa74743773c61be938cc1a6ea811ae1404bca2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6451. NFS should not return NFS3ERR_IO for AccessControlException. Contributed by Abhiraj Butala\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1615702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/08/14 10:40 AM",
      "commitName": "c9aa74743773c61be938cc1a6ea811ae1404bca2",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "23/07/14 2:22 PM",
      "commitNameOld": "2a5f1029a5221c42ab61b22f99d79251ed069ca4",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 11.85,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,163 +1,164 @@\n   READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n-    \n+\n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n-    \n+\n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d new READDIRPLUS3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n-    \n+\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpDirAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         if (aixCompatMode) {\n           // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n           // the same cookieverf value even across VFS-level readdir calls,\n           // instead of getting a new cookieverf for every VFS-level readdir\n           // call. This means that whenever a readdir call is made by an AIX NFS\n           // client for a given directory, and that directory is subsequently\n           // modified, thus changing its mtime, no later readdir calls will\n           // succeed for that directory from AIX until the FS is\n           // unmounted/remounted. See HDFS-6549 for more info.\n           LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n               \"mismatches.\");\n         } else {\n           LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n               + \" dir cookieverf: \" + dirStatus.getModificationTime());\n           return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n         }\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n-      \n+\n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n-      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n+      int status \u003d mapErrorStatus(e);\n+      return new READDIRPLUS3Response(status);\n     }\n-    \n+\n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n-    \n+\n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n-      \n+\n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileId()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n\n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n\n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d new READDIRPLUS3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpDirAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        if (aixCompatMode) {\n          // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n          // the same cookieverf value even across VFS-level readdir calls,\n          // instead of getting a new cookieverf for every VFS-level readdir\n          // call. This means that whenever a readdir call is made by an AIX NFS\n          // client for a given directory, and that directory is subsequently\n          // modified, thus changing its mtime, no later readdir calls will\n          // succeed for that directory from AIX until the FS is\n          // unmounted/remounted. See HDFS-6549 for more info.\n          LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n              \"mismatches.\");\n        } else {\n          LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n              + \" dir cookieverf: \" + dirStatus.getModificationTime());\n          return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n        }\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n\n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      int status \u003d mapErrorStatus(e);\n      return new READDIRPLUS3Response(status);\n    }\n\n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n\n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n\n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "9ff3836a367737d6dfcb12f50c8bd2f1b2233e37": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6549. Add support for accessing the NFS gateway from the AIX NFS client. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1604022 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/06/14 12:39 PM",
      "commitName": "9ff3836a367737d6dfcb12f50c8bd2f1b2233e37",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "18/06/14 1:45 PM",
      "commitNameOld": "2ecab65e3e290a1ee192b39ec70868863853543a",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 0.95,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,150 +1,163 @@\n   READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n       SocketAddress remoteAddress) {\n     if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n     \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n     \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d new READDIRPLUS3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpDirAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n-        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n-            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n-        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n+        if (aixCompatMode) {\n+          // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n+          // the same cookieverf value even across VFS-level readdir calls,\n+          // instead of getting a new cookieverf for every VFS-level readdir\n+          // call. This means that whenever a readdir call is made by an AIX NFS\n+          // client for a given directory, and that directory is subsequently\n+          // modified, thus changing its mtime, no later readdir calls will\n+          // succeed for that directory from AIX until the FS is\n+          // unmounted/remounted. See HDFS-6549 for more info.\n+          LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n+              \"mismatches.\");\n+        } else {\n+          LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n+              + \" dir cookieverf: \" + dirStatus.getModificationTime());\n+          return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n+        }\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n       \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n     }\n     \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n     \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n       \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileId()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n    \n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n    \n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d new READDIRPLUS3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpDirAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        if (aixCompatMode) {\n          // The AIX NFS client misinterprets RFC-1813 and will repeatedly send\n          // the same cookieverf value even across VFS-level readdir calls,\n          // instead of getting a new cookieverf for every VFS-level readdir\n          // call. This means that whenever a readdir call is made by an AIX NFS\n          // client for a given directory, and that directory is subsequently\n          // modified, thus changing its mtime, no later readdir calls will\n          // succeed for that directory from AIX until the FS is\n          // unmounted/remounted. See HDFS-6549 for more info.\n          LOG.warn(\"AIX compatibility mode enabled, ignoring cookieverf \" +\n              \"mismatches.\");\n        } else {\n          LOG.error(\"cookieverf mismatch. request cookieverf: \" + cookieVerf\n              + \" dir cookieverf: \" + dirStatus.getModificationTime());\n          return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n        }\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      \n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n    }\n    \n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n      \n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "2ecab65e3e290a1ee192b39ec70868863853543a": {
      "type": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-6439. NFS should not reject NFS requests to the NULL procedure whether port monitoring is enabled or not. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603622 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/06/14 1:45 PM",
      "commitName": "2ecab65e3e290a1ee192b39ec70868863853543a",
      "commitAuthor": "Brandon Li",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6439. NFS should not reject NFS requests to the NULL procedure whether port monitoring is enabled or not. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603622 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/06/14 1:45 PM",
          "commitName": "2ecab65e3e290a1ee192b39ec70868863853543a",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "30/05/14 4:53 PM",
          "commitNameOld": "42391d260da400593812396c1ffd45d1a371d3cb",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 18.87,
          "commitsBetweenForRepo": 106,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,150 +1,150 @@\n-  public READDIRPLUS3Response readdirplus(XDR xdr,\n-      SecurityHandler securityHandler, InetAddress client) {\n-    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n+  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n+      SocketAddress remoteAddress) {\n+    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n     \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n     \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d new READDIRPLUS3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpDirAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n             + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n       \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n     }\n     \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n     \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n       \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileId()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n    \n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n    \n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d new READDIRPLUS3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpDirAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      \n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n    }\n    \n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n      \n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {
            "oldValue": "[xdr-XDR, securityHandler-SecurityHandler, client-InetAddress]",
            "newValue": "[xdr-XDR, securityHandler-SecurityHandler, remoteAddress-SocketAddress]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-6439. NFS should not reject NFS requests to the NULL procedure whether port monitoring is enabled or not. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603622 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/06/14 1:45 PM",
          "commitName": "2ecab65e3e290a1ee192b39ec70868863853543a",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "30/05/14 4:53 PM",
          "commitNameOld": "42391d260da400593812396c1ffd45d1a371d3cb",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 18.87,
          "commitsBetweenForRepo": 106,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,150 +1,150 @@\n-  public READDIRPLUS3Response readdirplus(XDR xdr,\n-      SecurityHandler securityHandler, InetAddress client) {\n-    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n+  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n+      SocketAddress remoteAddress) {\n+    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n     \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n     \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d new READDIRPLUS3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpDirAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n             + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n       \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n     }\n     \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n     \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n       \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileId()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n    \n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n    \n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d new READDIRPLUS3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpDirAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      \n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n    }\n    \n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n      \n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6439. NFS should not reject NFS requests to the NULL procedure whether port monitoring is enabled or not. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1603622 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/06/14 1:45 PM",
          "commitName": "2ecab65e3e290a1ee192b39ec70868863853543a",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "30/05/14 4:53 PM",
          "commitNameOld": "42391d260da400593812396c1ffd45d1a371d3cb",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 18.87,
          "commitsBetweenForRepo": 106,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,150 +1,150 @@\n-  public READDIRPLUS3Response readdirplus(XDR xdr,\n-      SecurityHandler securityHandler, InetAddress client) {\n-    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n+  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n+      SocketAddress remoteAddress) {\n+    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n     \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n     \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d new READDIRPLUS3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpDirAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n             + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n       \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n     }\n     \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n     \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n       \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileId()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  READDIRPLUS3Response readdirplus(XDR xdr, SecurityHandler securityHandler,\n      SocketAddress remoteAddress) {\n    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n    \n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n    \n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d new READDIRPLUS3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpDirAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      \n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n    }\n    \n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n      \n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {}
        }
      ]
    },
    "3bfd18c6b0483ae27eff6d53bda934e67dda5464": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6050. NFS does not handle exceptions correctly in a few places. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1581055 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/03/14 1:49 PM",
      "commitName": "3bfd18c6b0483ae27eff6d53bda934e67dda5464",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "13/03/14 2:03 PM",
      "commitNameOld": "842aa2bc9432cc137bda0a5aec9c9eef12b000ce",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 10.99,
      "commitsBetweenForRepo": 79,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,152 +1,150 @@\n   public READDIRPLUS3Response readdirplus(XDR xdr,\n       SecurityHandler securityHandler, InetAddress client) {\n     if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n     \n     DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n     \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d new READDIRPLUS3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpDirAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n             + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n       \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n     }\n     \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n     \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n       \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n-              postOpDirAttr.getFileid()));\n+              postOpDirAttr.getFileId()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n-          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n-              + \" error:\" + e);\n+          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n-          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n-              + \" error:\" + e);\n+          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public READDIRPLUS3Response readdirplus(XDR xdr,\n      SecurityHandler securityHandler, InetAddress client) {\n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n    \n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n    \n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d new READDIRPLUS3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpDirAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      \n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n    }\n    \n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n      \n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileId()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId, e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "05f35518f19d48890770128727289582cca3457b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5171. NFS should create input stream for a file and try to share it with multiple read requests. Contributed by Haohui Mai\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1535586 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/10/13 4:40 PM",
      "commitName": "05f35518f19d48890770128727289582cca3457b",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "15/10/13 2:23 PM",
      "commitNameOld": "a9befa6f0a8a27b49b1e6483e749661f493f06cf",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 9.1,
      "commitsBetweenForRepo": 50,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,152 +1,152 @@\n   public READDIRPLUS3Response readdirplus(XDR xdr,\n       SecurityHandler securityHandler, InetAddress client) {\n     if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n     \n-    DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n+    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n     \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d new READDIRPLUS3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n     if (maxCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpDirAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n             + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n       \n       dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n     }\n     \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n     \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n       \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileid()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n               + \" error:\" + e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n               + \" error:\" + e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public READDIRPLUS3Response readdirplus(XDR xdr,\n      SecurityHandler securityHandler, InetAddress client) {\n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n    \n    DFSClient dfsClient \u003d clientCache.getDfsClient(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n    \n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d new READDIRPLUS3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpDirAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      \n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n    }\n    \n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n      \n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileid()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n              + \" error:\" + e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n              + \" error:\" + e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "a9befa6f0a8a27b49b1e6483e749661f493f06cf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5330. fix readdir and readdirplus for large directories. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1532539 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/10/13 2:23 PM",
      "commitName": "a9befa6f0a8a27b49b1e6483e749661f493f06cf",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "08/10/13 4:40 PM",
      "commitNameOld": "5c02d2f6225144772dcb975d3144b057b71d6476",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 6.9,
      "commitsBetweenForRepo": 49,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,148 +1,152 @@\n   public READDIRPLUS3Response readdirplus(XDR xdr,\n       SecurityHandler securityHandler, InetAddress client) {\n     if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n     \n     DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n     \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d new READDIRPLUS3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n-      LOG.info(\"Nonpositive count in invalid READDIRPLUS request:\" + dirCount);\n-      return new READDIRPLUS3Response(Nfs3Status.NFS3_OK);\n+      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n+      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     int maxCount \u003d request.getMaxCount();\n-\n+    if (maxCount \u003c\u003d 0) {\n+      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n+      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n+    }\n+    \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpDirAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n             + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n-      dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n-\n+      \n+      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n     }\n     \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n     \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n       \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileid()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n               + \" error:\" + e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n               + \" error:\" + e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public READDIRPLUS3Response readdirplus(XDR xdr,\n      SecurityHandler securityHandler, InetAddress client) {\n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n    \n    DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n    \n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d new READDIRPLUS3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive dircount in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    int maxCount \u003d request.getMaxCount();\n    if (maxCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive maxcount in invalid READDIRPLUS request:\" + maxCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpDirAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      \n      dlisting \u003d listPaths(dfsClient, dirFileIdPath, startAfter);\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n    }\n    \n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n      \n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileid()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n              + \" error:\" + e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n              + \" error:\" + e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
      "extendedDetails": {}
    },
    "613979c8fdacf25fd563395ecc399c4de94d3ee7": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-5085. Refactor o.a.h.nfs to support different types of authentications. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1521601 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/09/13 12:29 PM",
      "commitName": "613979c8fdacf25fd563395ecc399c4de94d3ee7",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5085. Refactor o.a.h.nfs to support different types of authentications. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1521601 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/09/13 12:29 PM",
          "commitName": "613979c8fdacf25fd563395ecc399c4de94d3ee7",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "31/08/13 2:12 PM",
          "commitNameOld": "cbca1668317f3f2d295eea53d7bd020bda4a810f",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 9.93,
          "commitsBetweenForRepo": 38,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,149 +1,148 @@\n-  public READDIRPLUS3Response readdirplus(XDR xdr, RpcAuthSys authSys,\n-      InetAddress client) {\n+  public READDIRPLUS3Response readdirplus(XDR xdr,\n+      SecurityHandler securityHandler, InetAddress client) {\n     if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n     \n-    String uname \u003d authSysCheck(authSys);\n-    DFSClient dfsClient \u003d clientCache.get(uname);\n+    DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n     \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d new READDIRPLUS3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive count in invalid READDIRPLUS request:\" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3_OK);\n     }\n     int maxCount \u003d request.getMaxCount();\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpDirAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n             + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n       dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n \n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n     }\n     \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n     \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n       \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileid()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n               + \" error:\" + e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n               + \" error:\" + e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public READDIRPLUS3Response readdirplus(XDR xdr,\n      SecurityHandler securityHandler, InetAddress client) {\n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n    \n    DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n    \n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d new READDIRPLUS3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive count in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3_OK);\n    }\n    int maxCount \u003d request.getMaxCount();\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpDirAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n    }\n    \n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n      \n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileid()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n              + \" error:\" + e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n              + \" error:\" + e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {
            "oldValue": "[xdr-XDR, authSys-RpcAuthSys, client-InetAddress]",
            "newValue": "[xdr-XDR, securityHandler-SecurityHandler, client-InetAddress]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5085. Refactor o.a.h.nfs to support different types of authentications. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1521601 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/09/13 12:29 PM",
          "commitName": "613979c8fdacf25fd563395ecc399c4de94d3ee7",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "31/08/13 2:12 PM",
          "commitNameOld": "cbca1668317f3f2d295eea53d7bd020bda4a810f",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 9.93,
          "commitsBetweenForRepo": 38,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,149 +1,148 @@\n-  public READDIRPLUS3Response readdirplus(XDR xdr, RpcAuthSys authSys,\n-      InetAddress client) {\n+  public READDIRPLUS3Response readdirplus(XDR xdr,\n+      SecurityHandler securityHandler, InetAddress client) {\n     if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n     }\n     \n-    String uname \u003d authSysCheck(authSys);\n-    DFSClient dfsClient \u003d clientCache.get(uname);\n+    DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n     \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d new READDIRPLUS3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive count in invalid READDIRPLUS request:\" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3_OK);\n     }\n     int maxCount \u003d request.getMaxCount();\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpDirAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n             + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n       dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n \n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n     }\n     \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n     \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n       \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileid()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n               + \" error:\" + e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n               + \" error:\" + e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public READDIRPLUS3Response readdirplus(XDR xdr,\n      SecurityHandler securityHandler, InetAddress client) {\n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n    \n    DFSClient dfsClient \u003d clientCache.get(securityHandler.getUser());\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n    \n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d new READDIRPLUS3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive count in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3_OK);\n    }\n    int maxCount \u003d request.getMaxCount();\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpDirAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n    }\n    \n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n      \n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileid()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n              + \" error:\" + e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n              + \" error:\" + e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {}
        }
      ]
    },
    "15632cd76f12c2f7df50d0df4865fbe3d8261597": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-4947 Add NFS server export table to control export by hostname or IP range. Contributed by Jing Zhao\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1517040 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/08/13 2:14 PM",
      "commitName": "15632cd76f12c2f7df50d0df4865fbe3d8261597",
      "commitAuthor": "Brandon Li",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4947 Add NFS server export table to control export by hostname or IP range. Contributed by Jing Zhao\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1517040 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/08/13 2:14 PM",
          "commitName": "15632cd76f12c2f7df50d0df4865fbe3d8261597",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "19/08/13 2:54 PM",
          "commitNameOld": "c9b89de0eacf15f21faa3a7ba30d4773f571c9a4",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 3.97,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,144 +1,149 @@\n-  public READDIRPLUS3Response readdirplus(XDR xdr, RpcAuthSys authSys) {   \n+  public READDIRPLUS3Response readdirplus(XDR xdr, RpcAuthSys authSys,\n+      InetAddress client) {\n+    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n+      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n+    }\n+    \n     String uname \u003d authSysCheck(authSys);\n     DFSClient dfsClient \u003d clientCache.get(uname);\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n     \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d new READDIRPLUS3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive count in invalid READDIRPLUS request:\" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3_OK);\n     }\n     int maxCount \u003d request.getMaxCount();\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpDirAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n             + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n       dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n \n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n     }\n     \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n     \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n       \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileid()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n               + \" error:\" + e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n               + \" error:\" + e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public READDIRPLUS3Response readdirplus(XDR xdr, RpcAuthSys authSys,\n      InetAddress client) {\n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n    \n    String uname \u003d authSysCheck(authSys);\n    DFSClient dfsClient \u003d clientCache.get(uname);\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n    \n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d new READDIRPLUS3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive count in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3_OK);\n    }\n    int maxCount \u003d request.getMaxCount();\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpDirAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n    }\n    \n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n      \n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileid()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n              + \" error:\" + e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n              + \" error:\" + e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {
            "oldValue": "[xdr-XDR, authSys-RpcAuthSys]",
            "newValue": "[xdr-XDR, authSys-RpcAuthSys, client-InetAddress]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4947 Add NFS server export table to control export by hostname or IP range. Contributed by Jing Zhao\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1517040 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/08/13 2:14 PM",
          "commitName": "15632cd76f12c2f7df50d0df4865fbe3d8261597",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "19/08/13 2:54 PM",
          "commitNameOld": "c9b89de0eacf15f21faa3a7ba30d4773f571c9a4",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 3.97,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,144 +1,149 @@\n-  public READDIRPLUS3Response readdirplus(XDR xdr, RpcAuthSys authSys) {   \n+  public READDIRPLUS3Response readdirplus(XDR xdr, RpcAuthSys authSys,\n+      InetAddress client) {\n+    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n+      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n+    }\n+    \n     String uname \u003d authSysCheck(authSys);\n     DFSClient dfsClient \u003d clientCache.get(uname);\n     if (dfsClient \u003d\u003d null) {\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n     }\n     \n     READDIRPLUS3Request request \u003d null;\n     try {\n       request \u003d new READDIRPLUS3Request(xdr);\n     } catch (IOException e) {\n       LOG.error(\"Invalid READDIRPLUS request\");\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n \n     FileHandle handle \u003d request.getHandle();\n     long cookie \u003d request.getCookie();\n     if (cookie \u003c 0) {\n       LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n     }\n     long dirCount \u003d request.getDirCount();\n     if (dirCount \u003c\u003d 0) {\n       LOG.info(\"Nonpositive count in invalid READDIRPLUS request:\" + dirCount);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3_OK);\n     }\n     int maxCount \u003d request.getMaxCount();\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n           + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n     }\n \n     HdfsFileStatus dirStatus;\n     DirectoryListing dlisting \u003d null;\n     Nfs3FileAttributes postOpDirAttr \u003d null;\n     long dotdotFileId \u003d 0;\n     try {\n       String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n       dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n       if (dirStatus \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n       if (!dirStatus.isDir()) {\n         LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n             + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n       }\n       long cookieVerf \u003d request.getCookieVerf();\n       if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n         LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n             + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n       }\n \n       if (cookie \u003d\u003d 0) {\n         // Get dotdot fileId\n         String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n         HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n \n         if (dotdotStatus \u003d\u003d null) {\n           // This should not happen\n           throw new IOException(\"Can\u0027t get path for handle path:\"\n               + dotdotFileIdPath);\n         }\n         dotdotFileId \u003d dotdotStatus.getFileId();\n       }\n \n       // Get the list from the resume point\n       byte[] startAfter;\n       if (cookie \u003d\u003d 0) {\n         startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n       } else {\n         String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n         startAfter \u003d inodeIdPath.getBytes();\n       }\n       dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n \n       postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n       if (postOpDirAttr \u003d\u003d null) {\n         LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n         return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Exception \", e);\n       return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n     }\n     \n     // Set up the dirents in the response\n     HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n     int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n     boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n         .getRemainingEntries() \u003d\u003d 0);\n     \n     READDIRPLUS3Response.EntryPlus3[] entries;\n     if (cookie \u003d\u003d 0) {\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n       \n       entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n           postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n               postOpDirAttr.getFileid()));\n       entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n           dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n \n       for (int i \u003d 2; i \u003c n + 2; i++) {\n         long fileId \u003d fstatus[i - 2].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n               + \" error:\" + e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n       }\n     } else {\n       // Resume from last readdirplus. If the cookie is \"..\", the result\n       // list is up the directory content since HDFS uses name as resume point.\n       entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n       for (int i \u003d 0; i \u003c n; i++) {\n         long fileId \u003d fstatus[i].getFileId();\n         FileHandle childHandle \u003d new FileHandle(fileId);\n         Nfs3FileAttributes attr;\n         try {\n           attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n         } catch (IOException e) {\n           LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n               + \" error:\" + e);\n           continue;\n         }\n         entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n             fstatus[i].getLocalName(), fileId, attr, childHandle);\n       }\n     }\n \n     DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n         eof);\n     return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n         dirStatus.getModificationTime(), dirListPlus);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public READDIRPLUS3Response readdirplus(XDR xdr, RpcAuthSys authSys,\n      InetAddress client) {\n    if (!checkAccessPrivilege(client, AccessPrivilege.READ_ONLY)) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_ACCES);\n    }\n    \n    String uname \u003d authSysCheck(authSys);\n    DFSClient dfsClient \u003d clientCache.get(uname);\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n    \n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d new READDIRPLUS3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive count in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3_OK);\n    }\n    int maxCount \u003d request.getMaxCount();\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpDirAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n    }\n    \n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n      \n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileid()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n              + \" error:\" + e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n              + \" error:\" + e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java",
          "extendedDetails": {}
        }
      ]
    },
    "37f587563a943a827fbff865f5302bac6d202415": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4762 Provide HDFS based NFSv3 and Mountd implementation. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1499029 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/07/13 10:31 AM",
      "commitName": "37f587563a943a827fbff865f5302bac6d202415",
      "commitAuthor": "Brandon Li",
      "diff": "@@ -0,0 +1,144 @@\n+  public READDIRPLUS3Response readdirplus(XDR xdr, RpcAuthSys authSys) {   \n+    String uname \u003d authSysCheck(authSys);\n+    DFSClient dfsClient \u003d clientCache.get(uname);\n+    if (dfsClient \u003d\u003d null) {\n+      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n+    }\n+    \n+    READDIRPLUS3Request request \u003d null;\n+    try {\n+      request \u003d new READDIRPLUS3Request(xdr);\n+    } catch (IOException e) {\n+      LOG.error(\"Invalid READDIRPLUS request\");\n+      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n+    }\n+\n+    FileHandle handle \u003d request.getHandle();\n+    long cookie \u003d request.getCookie();\n+    if (cookie \u003c 0) {\n+      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n+      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n+    }\n+    long dirCount \u003d request.getDirCount();\n+    if (dirCount \u003c\u003d 0) {\n+      LOG.info(\"Nonpositive count in invalid READDIRPLUS request:\" + dirCount);\n+      return new READDIRPLUS3Response(Nfs3Status.NFS3_OK);\n+    }\n+    int maxCount \u003d request.getMaxCount();\n+\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n+          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n+    }\n+\n+    HdfsFileStatus dirStatus;\n+    DirectoryListing dlisting \u003d null;\n+    Nfs3FileAttributes postOpDirAttr \u003d null;\n+    long dotdotFileId \u003d 0;\n+    try {\n+      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n+      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n+      if (dirStatus \u003d\u003d null) {\n+        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n+        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n+      }\n+      if (!dirStatus.isDir()) {\n+        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n+            + handle.getFileId());\n+        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n+      }\n+      long cookieVerf \u003d request.getCookieVerf();\n+      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n+        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n+            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n+        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n+      }\n+\n+      if (cookie \u003d\u003d 0) {\n+        // Get dotdot fileId\n+        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n+        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n+\n+        if (dotdotStatus \u003d\u003d null) {\n+          // This should not happen\n+          throw new IOException(\"Can\u0027t get path for handle path:\"\n+              + dotdotFileIdPath);\n+        }\n+        dotdotFileId \u003d dotdotStatus.getFileId();\n+      }\n+\n+      // Get the list from the resume point\n+      byte[] startAfter;\n+      if (cookie \u003d\u003d 0) {\n+        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n+      } else {\n+        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n+        startAfter \u003d inodeIdPath.getBytes();\n+      }\n+      dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n+\n+      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n+      if (postOpDirAttr \u003d\u003d null) {\n+        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n+        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n+      }\n+    } catch (IOException e) {\n+      LOG.warn(\"Exception \", e);\n+      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n+    }\n+    \n+    // Set up the dirents in the response\n+    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n+    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n+    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n+        .getRemainingEntries() \u003d\u003d 0);\n+    \n+    READDIRPLUS3Response.EntryPlus3[] entries;\n+    if (cookie \u003d\u003d 0) {\n+      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n+      \n+      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n+          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n+              postOpDirAttr.getFileid()));\n+      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n+          dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n+\n+      for (int i \u003d 2; i \u003c n + 2; i++) {\n+        long fileId \u003d fstatus[i - 2].getFileId();\n+        FileHandle childHandle \u003d new FileHandle(fileId);\n+        Nfs3FileAttributes attr;\n+        try {\n+          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n+        } catch (IOException e) {\n+          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n+              + \" error:\" + e);\n+          continue;\n+        }\n+        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n+            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n+      }\n+    } else {\n+      // Resume from last readdirplus. If the cookie is \"..\", the result\n+      // list is up the directory content since HDFS uses name as resume point.\n+      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n+      for (int i \u003d 0; i \u003c n; i++) {\n+        long fileId \u003d fstatus[i].getFileId();\n+        FileHandle childHandle \u003d new FileHandle(fileId);\n+        Nfs3FileAttributes attr;\n+        try {\n+          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n+        } catch (IOException e) {\n+          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n+              + \" error:\" + e);\n+          continue;\n+        }\n+        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n+            fstatus[i].getLocalName(), fileId, attr, childHandle);\n+      }\n+    }\n+\n+    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n+        eof);\n+    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n+        dirStatus.getModificationTime(), dirListPlus);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public READDIRPLUS3Response readdirplus(XDR xdr, RpcAuthSys authSys) {   \n    String uname \u003d authSysCheck(authSys);\n    DFSClient dfsClient \u003d clientCache.get(uname);\n    if (dfsClient \u003d\u003d null) {\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_SERVERFAULT);\n    }\n    \n    READDIRPLUS3Request request \u003d null;\n    try {\n      request \u003d new READDIRPLUS3Request(xdr);\n    } catch (IOException e) {\n      LOG.error(\"Invalid READDIRPLUS request\");\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n\n    FileHandle handle \u003d request.getHandle();\n    long cookie \u003d request.getCookie();\n    if (cookie \u003c 0) {\n      LOG.error(\"Invalid READDIRPLUS request, with negitve cookie:\" + cookie);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_INVAL);\n    }\n    long dirCount \u003d request.getDirCount();\n    if (dirCount \u003c\u003d 0) {\n      LOG.info(\"Nonpositive count in invalid READDIRPLUS request:\" + dirCount);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3_OK);\n    }\n    int maxCount \u003d request.getMaxCount();\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"NFS READDIRPLUS fileId: \" + handle.getFileId() + \" cookie: \"\n          + cookie + \" dirCount: \" + dirCount + \" maxCount: \" + maxCount);\n    }\n\n    HdfsFileStatus dirStatus;\n    DirectoryListing dlisting \u003d null;\n    Nfs3FileAttributes postOpDirAttr \u003d null;\n    long dotdotFileId \u003d 0;\n    try {\n      String dirFileIdPath \u003d Nfs3Utils.getFileIdPath(handle);\n      dirStatus \u003d dfsClient.getFileInfo(dirFileIdPath);\n      if (dirStatus \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n      if (!dirStatus.isDir()) {\n        LOG.error(\"Can\u0027t readdirplus for regular file, fileId:\"\n            + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_NOTDIR);\n      }\n      long cookieVerf \u003d request.getCookieVerf();\n      if ((cookieVerf !\u003d 0) \u0026\u0026 (cookieVerf !\u003d dirStatus.getModificationTime())) {\n        LOG.error(\"CookierVerf mismatch. request cookierVerf:\" + cookieVerf\n            + \" dir cookieVerf:\" + dirStatus.getModificationTime());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_BAD_COOKIE);\n      }\n\n      if (cookie \u003d\u003d 0) {\n        // Get dotdot fileId\n        String dotdotFileIdPath \u003d dirFileIdPath + \"/..\";\n        HdfsFileStatus dotdotStatus \u003d dfsClient.getFileInfo(dotdotFileIdPath);\n\n        if (dotdotStatus \u003d\u003d null) {\n          // This should not happen\n          throw new IOException(\"Can\u0027t get path for handle path:\"\n              + dotdotFileIdPath);\n        }\n        dotdotFileId \u003d dotdotStatus.getFileId();\n      }\n\n      // Get the list from the resume point\n      byte[] startAfter;\n      if (cookie \u003d\u003d 0) {\n        startAfter \u003d HdfsFileStatus.EMPTY_NAME;\n      } else {\n        String inodeIdPath \u003d Nfs3Utils.getFileIdPath(cookie);\n        startAfter \u003d inodeIdPath.getBytes();\n      }\n      dlisting \u003d dfsClient.listPaths(dirFileIdPath, startAfter);\n\n      postOpDirAttr \u003d Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);\n      if (postOpDirAttr \u003d\u003d null) {\n        LOG.info(\"Can\u0027t get path for fileId:\" + handle.getFileId());\n        return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_STALE);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception \", e);\n      return new READDIRPLUS3Response(Nfs3Status.NFS3ERR_IO);\n    }\n    \n    // Set up the dirents in the response\n    HdfsFileStatus[] fstatus \u003d dlisting.getPartialListing();\n    int n \u003d (int) Math.min(fstatus.length, dirCount-2);\n    boolean eof \u003d (n \u003c fstatus.length) ? false : (dlisting\n        .getRemainingEntries() \u003d\u003d 0);\n    \n    READDIRPLUS3Response.EntryPlus3[] entries;\n    if (cookie \u003d\u003d 0) {\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n+2];\n      \n      entries[0] \u003d new READDIRPLUS3Response.EntryPlus3(\n          postOpDirAttr.getFileId(), \".\", 0, postOpDirAttr, new FileHandle(\n              postOpDirAttr.getFileid()));\n      entries[1] \u003d new READDIRPLUS3Response.EntryPlus3(dotdotFileId, \"..\",\n          dotdotFileId, postOpDirAttr, new FileHandle(dotdotFileId));\n\n      for (int i \u003d 2; i \u003c n + 2; i++) {\n        long fileId \u003d fstatus[i - 2].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n              + \" error:\" + e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i - 2].getLocalName(), fileId, attr, childHandle);\n      }\n    } else {\n      // Resume from last readdirplus. If the cookie is \"..\", the result\n      // list is up the directory content since HDFS uses name as resume point.\n      entries \u003d new READDIRPLUS3Response.EntryPlus3[n]; \n      for (int i \u003d 0; i \u003c n; i++) {\n        long fileId \u003d fstatus[i].getFileId();\n        FileHandle childHandle \u003d new FileHandle(fileId);\n        Nfs3FileAttributes attr;\n        try {\n          attr \u003d writeManager.getFileAttr(dfsClient, childHandle, iug);\n        } catch (IOException e) {\n          LOG.error(\"Can\u0027t get file attributes for fileId:\" + fileId\n              + \" error:\" + e);\n          continue;\n        }\n        entries[i] \u003d new READDIRPLUS3Response.EntryPlus3(fileId,\n            fstatus[i].getLocalName(), fileId, attr, childHandle);\n      }\n    }\n\n    DirListPlus3 dirListPlus \u003d new READDIRPLUS3Response.DirListPlus3(entries,\n        eof);\n    return new READDIRPLUS3Response(Nfs3Status.NFS3_OK, postOpDirAttr,\n        dirStatus.getModificationTime(), dirListPlus);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java"
    }
  }
}