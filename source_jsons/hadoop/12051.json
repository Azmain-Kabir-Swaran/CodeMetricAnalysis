{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FsDatasetImpl.java",
  "functionName": "evictBlocks",
  "functionId": "evictBlocks___bytesNeeded-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
  "functionStartLine": 3268,
  "functionEndLine": 3316,
  "numCommitsSeen": 297,
  "timeTaken": 9417,
  "changeHistory": [
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8",
    "e98adb00b7da8fa913b86ecf2049444b1d8617d4",
    "96b12662ea76e3ded4ef13944fc8df206cfb4613",
    "86c9862bec0248d671e657aa56094a2919b8ac14",
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c",
    "c7d022b66f0c5baafbb7000a435c1d6e39906efe",
    "058af60c56207907f2bedf76df4284e86d923e0c",
    "463aec11718e47d4aabb86a7a539cb973460aae6",
    "1efd9c98258fbb973d2058dcf0850042e53bd02f",
    "5e8b6973527e5f714652641ed95e8a4509e18cfa",
    "b2d5ed36bcb80e2581191dcdc3976e825c959142"
  ],
  "changeHistoryShort": {
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8": "Ybodychange",
    "e98adb00b7da8fa913b86ecf2049444b1d8617d4": "Ybodychange",
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": "Ybodychange",
    "86c9862bec0248d671e657aa56094a2919b8ac14": "Ybodychange",
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c": "Ybodychange",
    "c7d022b66f0c5baafbb7000a435c1d6e39906efe": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
    "058af60c56207907f2bedf76df4284e86d923e0c": "Ybodychange",
    "463aec11718e47d4aabb86a7a539cb973460aae6": "Ybodychange",
    "1efd9c98258fbb973d2058dcf0850042e53bd02f": "Ybodychange",
    "5e8b6973527e5f714652641ed95e8a4509e18cfa": "Ybodychange",
    "b2d5ed36bcb80e2581191dcdc3976e825c959142": "Ybodychange"
  },
  "changeHistoryDetails": {
    "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15150. Introduce read write lock to Datanode. Contributed Stephen O\u0027Donnell.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "11/02/20 8:00 AM",
      "commitName": "d7c136b9ed6d99e1b03f5b89723b3a20df359ba8",
      "commitAuthor": "Stephen O\u0027Donnell",
      "commitDateOld": "28/01/20 10:10 AM",
      "commitNameOld": "1839c467f60cbb8592d446694ec3d7710cda5142",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 13.91,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,49 @@\n     public void evictBlocks(long bytesNeeded) throws IOException {\n       int iterations \u003d 0;\n \n       final long cacheCapacity \u003d cacheManager.getMemCacheCapacity();\n \n       while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n              (cacheCapacity - cacheManager.getMemCacheUsed()) \u003c bytesNeeded) {\n         RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n \n         if (replicaState \u003d\u003d null) {\n           break;\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Evicting block \" + replicaState);\n         }\n \n         ReplicaInfo replicaInfo, newReplicaInfo;\n         final String bpid \u003d replicaState.getBlockPoolId();\n \n-        try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n+        try (AutoCloseableLock lock \u003d datasetWriteLock.acquire()) {\n           replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(),\n                                        replicaState.getBlockId());\n           Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n           ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n               replicaState.getBlockId(), false);\n \n           // Move the replica from lazyPersist/ to finalized/ on\n           // the target volume\n           newReplicaInfo \u003d\n               replicaState.getLazyPersistVolume().activateSavedReplica(bpid,\n                   replicaInfo, replicaState);\n           // Update the volumeMap entry.\n           volumeMap.add(bpid, newReplicaInfo);\n \n           // Update metrics\n           datanode.getMetrics().incrRamDiskBlocksEvicted();\n           datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n               Time.monotonicNow() - replicaState.getCreationTime());\n           if (replicaState.getNumReads() \u003d\u003d 0) {\n             datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n           }\n \n           // Delete the block+meta files from RAM disk and release locked\n           // memory.\n           removeOldReplica(replicaInfo, newReplicaInfo, bpid);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void evictBlocks(long bytesNeeded) throws IOException {\n      int iterations \u003d 0;\n\n      final long cacheCapacity \u003d cacheManager.getMemCacheCapacity();\n\n      while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n             (cacheCapacity - cacheManager.getMemCacheUsed()) \u003c bytesNeeded) {\n        RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n\n        if (replicaState \u003d\u003d null) {\n          break;\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Evicting block \" + replicaState);\n        }\n\n        ReplicaInfo replicaInfo, newReplicaInfo;\n        final String bpid \u003d replicaState.getBlockPoolId();\n\n        try (AutoCloseableLock lock \u003d datasetWriteLock.acquire()) {\n          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(),\n                                       replicaState.getBlockId());\n          Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n          ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n              replicaState.getBlockId(), false);\n\n          // Move the replica from lazyPersist/ to finalized/ on\n          // the target volume\n          newReplicaInfo \u003d\n              replicaState.getLazyPersistVolume().activateSavedReplica(bpid,\n                  replicaInfo, replicaState);\n          // Update the volumeMap entry.\n          volumeMap.add(bpid, newReplicaInfo);\n\n          // Update metrics\n          datanode.getMetrics().incrRamDiskBlocksEvicted();\n          datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n              Time.monotonicNow() - replicaState.getCreationTime());\n          if (replicaState.getNumReads() \u003d\u003d 0) {\n            datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n          }\n\n          // Delete the block+meta files from RAM disk and release locked\n          // memory.\n          removeOldReplica(replicaInfo, newReplicaInfo, bpid);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "e98adb00b7da8fa913b86ecf2049444b1d8617d4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14458. Report pmem stats to namenode. Contributed by Feilong He.\n",
      "commitDate": "15/07/19 12:32 AM",
      "commitName": "e98adb00b7da8fa913b86ecf2049444b1d8617d4",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "06/06/19 11:59 AM",
      "commitNameOld": "e1dfc060f8f0247f97127c75c9284a068fc93907",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 38.52,
      "commitsBetweenForRepo": 308,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,49 @@\n     public void evictBlocks(long bytesNeeded) throws IOException {\n       int iterations \u003d 0;\n \n-      final long cacheCapacity \u003d cacheManager.getCacheCapacity();\n+      final long cacheCapacity \u003d cacheManager.getMemCacheCapacity();\n \n       while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n-             (cacheCapacity - cacheManager.getCacheUsed()) \u003c bytesNeeded) {\n+             (cacheCapacity - cacheManager.getMemCacheUsed()) \u003c bytesNeeded) {\n         RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n \n         if (replicaState \u003d\u003d null) {\n           break;\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Evicting block \" + replicaState);\n         }\n \n         ReplicaInfo replicaInfo, newReplicaInfo;\n         final String bpid \u003d replicaState.getBlockPoolId();\n \n         try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n           replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(),\n                                        replicaState.getBlockId());\n           Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n           ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n               replicaState.getBlockId(), false);\n \n           // Move the replica from lazyPersist/ to finalized/ on\n           // the target volume\n           newReplicaInfo \u003d\n               replicaState.getLazyPersistVolume().activateSavedReplica(bpid,\n                   replicaInfo, replicaState);\n           // Update the volumeMap entry.\n           volumeMap.add(bpid, newReplicaInfo);\n \n           // Update metrics\n           datanode.getMetrics().incrRamDiskBlocksEvicted();\n           datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n               Time.monotonicNow() - replicaState.getCreationTime());\n           if (replicaState.getNumReads() \u003d\u003d 0) {\n             datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n           }\n \n           // Delete the block+meta files from RAM disk and release locked\n           // memory.\n           removeOldReplica(replicaInfo, newReplicaInfo, bpid);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void evictBlocks(long bytesNeeded) throws IOException {\n      int iterations \u003d 0;\n\n      final long cacheCapacity \u003d cacheManager.getMemCacheCapacity();\n\n      while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n             (cacheCapacity - cacheManager.getMemCacheUsed()) \u003c bytesNeeded) {\n        RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n\n        if (replicaState \u003d\u003d null) {\n          break;\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Evicting block \" + replicaState);\n        }\n\n        ReplicaInfo replicaInfo, newReplicaInfo;\n        final String bpid \u003d replicaState.getBlockPoolId();\n\n        try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(),\n                                       replicaState.getBlockId());\n          Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n          ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n              replicaState.getBlockId(), false);\n\n          // Move the replica from lazyPersist/ to finalized/ on\n          // the target volume\n          newReplicaInfo \u003d\n              replicaState.getLazyPersistVolume().activateSavedReplica(bpid,\n                  replicaInfo, replicaState);\n          // Update the volumeMap entry.\n          volumeMap.add(bpid, newReplicaInfo);\n\n          // Update metrics\n          datanode.getMetrics().incrRamDiskBlocksEvicted();\n          datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n              Time.monotonicNow() - replicaState.getCreationTime());\n          if (replicaState.getNumReads() \u003d\u003d 0) {\n            datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n          }\n\n          // Delete the block+meta files from RAM disk and release locked\n          // memory.\n          removeOldReplica(replicaInfo, newReplicaInfo, bpid);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10637. Modifications to remove the assumption that FsVolumes are backed by java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "10/10/16 3:30 PM",
      "commitName": "96b12662ea76e3ded4ef13944fc8df206cfb4613",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "30/09/16 11:11 PM",
      "commitNameOld": "fe9ebe20ab113567f0777c11cb48ce0d3ce587a8",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 9.68,
      "commitsBetweenForRepo": 64,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,52 +1,50 @@\n     public void evictBlocks(long bytesNeeded) throws IOException {\n       int iterations \u003d 0;\n \n       final long cacheCapacity \u003d cacheManager.getCacheCapacity();\n \n       while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n              (cacheCapacity - cacheManager.getCacheUsed()) \u003c bytesNeeded) {\n         RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n \n         if (replicaState \u003d\u003d null) {\n           break;\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Evicting block \" + replicaState);\n         }\n \n         ReplicaInfo replicaInfo, newReplicaInfo;\n         final String bpid \u003d replicaState.getBlockPoolId();\n \n         try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n           replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(),\n                                        replicaState.getBlockId());\n           Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n           ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n               replicaState.getBlockId(), false);\n \n           // Move the replica from lazyPersist/ to finalized/ on\n           // the target volume\n-          BlockPoolSlice bpSlice \u003d\n-              replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n-\n           newReplicaInfo \u003d\n-              bpSlice.activateSavedReplica(replicaInfo, replicaState);\n+              replicaState.getLazyPersistVolume().activateSavedReplica(bpid,\n+                  replicaInfo, replicaState);\n \n           // Update the volumeMap entry.\n           volumeMap.add(bpid, newReplicaInfo);\n \n           // Update metrics\n           datanode.getMetrics().incrRamDiskBlocksEvicted();\n           datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n               Time.monotonicNow() - replicaState.getCreationTime());\n           if (replicaState.getNumReads() \u003d\u003d 0) {\n             datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n           }\n \n           // Delete the block+meta files from RAM disk and release locked\n           // memory.\n           removeOldReplica(replicaInfo, newReplicaInfo, bpid);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void evictBlocks(long bytesNeeded) throws IOException {\n      int iterations \u003d 0;\n\n      final long cacheCapacity \u003d cacheManager.getCacheCapacity();\n\n      while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n             (cacheCapacity - cacheManager.getCacheUsed()) \u003c bytesNeeded) {\n        RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n\n        if (replicaState \u003d\u003d null) {\n          break;\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Evicting block \" + replicaState);\n        }\n\n        ReplicaInfo replicaInfo, newReplicaInfo;\n        final String bpid \u003d replicaState.getBlockPoolId();\n\n        try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(),\n                                       replicaState.getBlockId());\n          Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n          ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n              replicaState.getBlockId(), false);\n\n          // Move the replica from lazyPersist/ to finalized/ on\n          // the target volume\n          newReplicaInfo \u003d\n              replicaState.getLazyPersistVolume().activateSavedReplica(bpid,\n                  replicaInfo, replicaState);\n\n          // Update the volumeMap entry.\n          volumeMap.add(bpid, newReplicaInfo);\n\n          // Update metrics\n          datanode.getMetrics().incrRamDiskBlocksEvicted();\n          datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n              Time.monotonicNow() - replicaState.getCreationTime());\n          if (replicaState.getNumReads() \u003d\u003d 0) {\n            datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n          }\n\n          // Delete the block+meta files from RAM disk and release locked\n          // memory.\n          removeOldReplica(replicaInfo, newReplicaInfo, bpid);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "86c9862bec0248d671e657aa56094a2919b8ac14": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "13/09/16 12:54 PM",
      "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "10/09/16 6:22 PM",
      "commitNameOld": "a99bf26a0899bcc4307c3a242c8414eaef555aa7",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 2.77,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,52 @@\n     public void evictBlocks(long bytesNeeded) throws IOException {\n       int iterations \u003d 0;\n \n       final long cacheCapacity \u003d cacheManager.getCacheCapacity();\n \n       while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n              (cacheCapacity - cacheManager.getCacheUsed()) \u003c bytesNeeded) {\n         RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n \n         if (replicaState \u003d\u003d null) {\n           break;\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Evicting block \" + replicaState);\n         }\n \n         ReplicaInfo replicaInfo, newReplicaInfo;\n-        File blockFile, metaFile;\n-        long blockFileUsed, metaFileUsed;\n         final String bpid \u003d replicaState.getBlockPoolId();\n \n         try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n           replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(),\n                                        replicaState.getBlockId());\n           Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n-          blockFile \u003d replicaInfo.getBlockFile();\n-          metaFile \u003d replicaInfo.getMetaFile();\n-          blockFileUsed \u003d blockFile.length();\n-          metaFileUsed \u003d metaFile.length();\n           ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n               replicaState.getBlockId(), false);\n \n           // Move the replica from lazyPersist/ to finalized/ on\n           // the target volume\n           BlockPoolSlice bpSlice \u003d\n               replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n-          File newBlockFile \u003d bpSlice.activateSavedReplica(\n-              replicaInfo, replicaState.getSavedMetaFile(),\n-              replicaState.getSavedBlockFile());\n \n           newReplicaInfo \u003d\n-              new FinalizedReplica(replicaInfo.getBlockId(),\n-                                   replicaInfo.getBytesOnDisk(),\n-                                   replicaInfo.getGenerationStamp(),\n-                                   replicaState.getLazyPersistVolume(),\n-                                   newBlockFile.getParentFile());\n+              bpSlice.activateSavedReplica(replicaInfo, replicaState);\n \n           // Update the volumeMap entry.\n           volumeMap.add(bpid, newReplicaInfo);\n \n           // Update metrics\n           datanode.getMetrics().incrRamDiskBlocksEvicted();\n           datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n               Time.monotonicNow() - replicaState.getCreationTime());\n           if (replicaState.getNumReads() \u003d\u003d 0) {\n             datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n           }\n \n           // Delete the block+meta files from RAM disk and release locked\n           // memory.\n-          removeOldReplica(replicaInfo, newReplicaInfo, blockFile, metaFile,\n-              blockFileUsed, metaFileUsed, bpid);\n+          removeOldReplica(replicaInfo, newReplicaInfo, bpid);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void evictBlocks(long bytesNeeded) throws IOException {\n      int iterations \u003d 0;\n\n      final long cacheCapacity \u003d cacheManager.getCacheCapacity();\n\n      while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n             (cacheCapacity - cacheManager.getCacheUsed()) \u003c bytesNeeded) {\n        RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n\n        if (replicaState \u003d\u003d null) {\n          break;\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Evicting block \" + replicaState);\n        }\n\n        ReplicaInfo replicaInfo, newReplicaInfo;\n        final String bpid \u003d replicaState.getBlockPoolId();\n\n        try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(),\n                                       replicaState.getBlockId());\n          Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n          ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n              replicaState.getBlockId(), false);\n\n          // Move the replica from lazyPersist/ to finalized/ on\n          // the target volume\n          BlockPoolSlice bpSlice \u003d\n              replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n\n          newReplicaInfo \u003d\n              bpSlice.activateSavedReplica(replicaInfo, replicaState);\n\n          // Update the volumeMap entry.\n          volumeMap.add(bpid, newReplicaInfo);\n\n          // Update metrics\n          datanode.getMetrics().incrRamDiskBlocksEvicted();\n          datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n              Time.monotonicNow() - replicaState.getCreationTime());\n          if (replicaState.getNumReads() \u003d\u003d 0) {\n            datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n          }\n\n          // Delete the block+meta files from RAM disk and release locked\n          // memory.\n          removeOldReplica(replicaInfo, newReplicaInfo, bpid);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10682. Replace FsDatasetImpl object lock with a separate lock object. (Chen Liang)\n",
      "commitDate": "08/08/16 12:02 PM",
      "commitName": "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "08/07/16 7:40 PM",
      "commitNameOld": "da6f1b88dd47e22b24d44f6fc8bbee73e85746f7",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 30.68,
      "commitsBetweenForRepo": 320,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,66 @@\n     public void evictBlocks(long bytesNeeded) throws IOException {\n       int iterations \u003d 0;\n \n       final long cacheCapacity \u003d cacheManager.getCacheCapacity();\n \n       while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n              (cacheCapacity - cacheManager.getCacheUsed()) \u003c bytesNeeded) {\n         RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n \n         if (replicaState \u003d\u003d null) {\n           break;\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Evicting block \" + replicaState);\n         }\n \n         ReplicaInfo replicaInfo, newReplicaInfo;\n         File blockFile, metaFile;\n         long blockFileUsed, metaFileUsed;\n         final String bpid \u003d replicaState.getBlockPoolId();\n \n-        synchronized (FsDatasetImpl.this) {\n+        try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n           replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(),\n                                        replicaState.getBlockId());\n           Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n           blockFile \u003d replicaInfo.getBlockFile();\n           metaFile \u003d replicaInfo.getMetaFile();\n           blockFileUsed \u003d blockFile.length();\n           metaFileUsed \u003d metaFile.length();\n           ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n               replicaState.getBlockId(), false);\n \n           // Move the replica from lazyPersist/ to finalized/ on\n           // the target volume\n           BlockPoolSlice bpSlice \u003d\n               replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n           File newBlockFile \u003d bpSlice.activateSavedReplica(\n               replicaInfo, replicaState.getSavedMetaFile(),\n               replicaState.getSavedBlockFile());\n \n           newReplicaInfo \u003d\n               new FinalizedReplica(replicaInfo.getBlockId(),\n                                    replicaInfo.getBytesOnDisk(),\n                                    replicaInfo.getGenerationStamp(),\n                                    replicaState.getLazyPersistVolume(),\n                                    newBlockFile.getParentFile());\n \n           // Update the volumeMap entry.\n           volumeMap.add(bpid, newReplicaInfo);\n \n           // Update metrics\n           datanode.getMetrics().incrRamDiskBlocksEvicted();\n           datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n               Time.monotonicNow() - replicaState.getCreationTime());\n           if (replicaState.getNumReads() \u003d\u003d 0) {\n             datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n           }\n \n           // Delete the block+meta files from RAM disk and release locked\n           // memory.\n           removeOldReplica(replicaInfo, newReplicaInfo, blockFile, metaFile,\n               blockFileUsed, metaFileUsed, bpid);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void evictBlocks(long bytesNeeded) throws IOException {\n      int iterations \u003d 0;\n\n      final long cacheCapacity \u003d cacheManager.getCacheCapacity();\n\n      while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n             (cacheCapacity - cacheManager.getCacheUsed()) \u003c bytesNeeded) {\n        RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n\n        if (replicaState \u003d\u003d null) {\n          break;\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Evicting block \" + replicaState);\n        }\n\n        ReplicaInfo replicaInfo, newReplicaInfo;\n        File blockFile, metaFile;\n        long blockFileUsed, metaFileUsed;\n        final String bpid \u003d replicaState.getBlockPoolId();\n\n        try (AutoCloseableLock lock \u003d datasetLock.acquire()) {\n          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(),\n                                       replicaState.getBlockId());\n          Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n          blockFile \u003d replicaInfo.getBlockFile();\n          metaFile \u003d replicaInfo.getMetaFile();\n          blockFileUsed \u003d blockFile.length();\n          metaFileUsed \u003d metaFile.length();\n          ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n              replicaState.getBlockId(), false);\n\n          // Move the replica from lazyPersist/ to finalized/ on\n          // the target volume\n          BlockPoolSlice bpSlice \u003d\n              replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n          File newBlockFile \u003d bpSlice.activateSavedReplica(\n              replicaInfo, replicaState.getSavedMetaFile(),\n              replicaState.getSavedBlockFile());\n\n          newReplicaInfo \u003d\n              new FinalizedReplica(replicaInfo.getBlockId(),\n                                   replicaInfo.getBytesOnDisk(),\n                                   replicaInfo.getGenerationStamp(),\n                                   replicaState.getLazyPersistVolume(),\n                                   newBlockFile.getParentFile());\n\n          // Update the volumeMap entry.\n          volumeMap.add(bpid, newReplicaInfo);\n\n          // Update metrics\n          datanode.getMetrics().incrRamDiskBlocksEvicted();\n          datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n              Time.monotonicNow() - replicaState.getCreationTime());\n          if (replicaState.getNumReads() \u003d\u003d 0) {\n            datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n          }\n\n          // Delete the block+meta files from RAM disk and release locked\n          // memory.\n          removeOldReplica(replicaInfo, newReplicaInfo, blockFile, metaFile,\n              blockFileUsed, metaFileUsed, bpid);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "c7d022b66f0c5baafbb7000a435c1d6e39906efe": {
      "type": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-8192. Eviction should key off used locked memory instead of ram disk free space. (Contributed by Arpit Agarwal)\n",
      "commitDate": "20/06/15 1:27 PM",
      "commitName": "c7d022b66f0c5baafbb7000a435c1d6e39906efe",
      "commitAuthor": "Arpit Agarwal",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-8192. Eviction should key off used locked memory instead of ram disk free space. (Contributed by Arpit Agarwal)\n",
          "commitDate": "20/06/15 1:27 PM",
          "commitName": "c7d022b66f0c5baafbb7000a435c1d6e39906efe",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "16/05/15 9:05 AM",
          "commitNameOld": "e453989a5722e653bd97e3e54f9bbdffc9454fba",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 35.18,
          "commitsBetweenForRepo": 253,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,60 +1,66 @@\n-    private void evictBlocks() throws IOException {\n+    public void evictBlocks(long bytesNeeded) throws IOException {\n       int iterations \u003d 0;\n \n+      final long cacheCapacity \u003d cacheManager.getCacheCapacity();\n+\n       while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n-             transientFreeSpaceBelowThreshold()) {\n+             (cacheCapacity - cacheManager.getCacheUsed()) \u003c bytesNeeded) {\n         RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n \n         if (replicaState \u003d\u003d null) {\n           break;\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Evicting block \" + replicaState);\n         }\n \n         ReplicaInfo replicaInfo, newReplicaInfo;\n         File blockFile, metaFile;\n         long blockFileUsed, metaFileUsed;\n         final String bpid \u003d replicaState.getBlockPoolId();\n \n         synchronized (FsDatasetImpl.this) {\n-          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(), replicaState.getBlockId());\n+          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(),\n+                                       replicaState.getBlockId());\n           Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n           blockFile \u003d replicaInfo.getBlockFile();\n           metaFile \u003d replicaInfo.getMetaFile();\n           blockFileUsed \u003d blockFile.length();\n           metaFileUsed \u003d metaFile.length();\n           ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n               replicaState.getBlockId(), false);\n \n-          // Move the replica from lazyPersist/ to finalized/ on target volume\n+          // Move the replica from lazyPersist/ to finalized/ on\n+          // the target volume\n           BlockPoolSlice bpSlice \u003d\n               replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n           File newBlockFile \u003d bpSlice.activateSavedReplica(\n               replicaInfo, replicaState.getSavedMetaFile(),\n               replicaState.getSavedBlockFile());\n \n           newReplicaInfo \u003d\n               new FinalizedReplica(replicaInfo.getBlockId(),\n                                    replicaInfo.getBytesOnDisk(),\n                                    replicaInfo.getGenerationStamp(),\n                                    replicaState.getLazyPersistVolume(),\n                                    newBlockFile.getParentFile());\n \n           // Update the volumeMap entry.\n           volumeMap.add(bpid, newReplicaInfo);\n \n           // Update metrics\n           datanode.getMetrics().incrRamDiskBlocksEvicted();\n           datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n               Time.monotonicNow() - replicaState.getCreationTime());\n           if (replicaState.getNumReads() \u003d\u003d 0) {\n             datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n           }\n-        }\n \n-        removeOldReplica(replicaInfo, newReplicaInfo, blockFile, metaFile,\n-            blockFileUsed, metaFileUsed, bpid);\n+          // Delete the block+meta files from RAM disk and release locked\n+          // memory.\n+          removeOldReplica(replicaInfo, newReplicaInfo, blockFile, metaFile,\n+              blockFileUsed, metaFileUsed, bpid);\n+        }\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    public void evictBlocks(long bytesNeeded) throws IOException {\n      int iterations \u003d 0;\n\n      final long cacheCapacity \u003d cacheManager.getCacheCapacity();\n\n      while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n             (cacheCapacity - cacheManager.getCacheUsed()) \u003c bytesNeeded) {\n        RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n\n        if (replicaState \u003d\u003d null) {\n          break;\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Evicting block \" + replicaState);\n        }\n\n        ReplicaInfo replicaInfo, newReplicaInfo;\n        File blockFile, metaFile;\n        long blockFileUsed, metaFileUsed;\n        final String bpid \u003d replicaState.getBlockPoolId();\n\n        synchronized (FsDatasetImpl.this) {\n          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(),\n                                       replicaState.getBlockId());\n          Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n          blockFile \u003d replicaInfo.getBlockFile();\n          metaFile \u003d replicaInfo.getMetaFile();\n          blockFileUsed \u003d blockFile.length();\n          metaFileUsed \u003d metaFile.length();\n          ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n              replicaState.getBlockId(), false);\n\n          // Move the replica from lazyPersist/ to finalized/ on\n          // the target volume\n          BlockPoolSlice bpSlice \u003d\n              replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n          File newBlockFile \u003d bpSlice.activateSavedReplica(\n              replicaInfo, replicaState.getSavedMetaFile(),\n              replicaState.getSavedBlockFile());\n\n          newReplicaInfo \u003d\n              new FinalizedReplica(replicaInfo.getBlockId(),\n                                   replicaInfo.getBytesOnDisk(),\n                                   replicaInfo.getGenerationStamp(),\n                                   replicaState.getLazyPersistVolume(),\n                                   newBlockFile.getParentFile());\n\n          // Update the volumeMap entry.\n          volumeMap.add(bpid, newReplicaInfo);\n\n          // Update metrics\n          datanode.getMetrics().incrRamDiskBlocksEvicted();\n          datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n              Time.monotonicNow() - replicaState.getCreationTime());\n          if (replicaState.getNumReads() \u003d\u003d 0) {\n            datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n          }\n\n          // Delete the block+meta files from RAM disk and release locked\n          // memory.\n          removeOldReplica(replicaInfo, newReplicaInfo, blockFile, metaFile,\n              blockFileUsed, metaFileUsed, bpid);\n        }\n      }\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[bytesNeeded-long]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-8192. Eviction should key off used locked memory instead of ram disk free space. (Contributed by Arpit Agarwal)\n",
          "commitDate": "20/06/15 1:27 PM",
          "commitName": "c7d022b66f0c5baafbb7000a435c1d6e39906efe",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "16/05/15 9:05 AM",
          "commitNameOld": "e453989a5722e653bd97e3e54f9bbdffc9454fba",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 35.18,
          "commitsBetweenForRepo": 253,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,60 +1,66 @@\n-    private void evictBlocks() throws IOException {\n+    public void evictBlocks(long bytesNeeded) throws IOException {\n       int iterations \u003d 0;\n \n+      final long cacheCapacity \u003d cacheManager.getCacheCapacity();\n+\n       while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n-             transientFreeSpaceBelowThreshold()) {\n+             (cacheCapacity - cacheManager.getCacheUsed()) \u003c bytesNeeded) {\n         RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n \n         if (replicaState \u003d\u003d null) {\n           break;\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Evicting block \" + replicaState);\n         }\n \n         ReplicaInfo replicaInfo, newReplicaInfo;\n         File blockFile, metaFile;\n         long blockFileUsed, metaFileUsed;\n         final String bpid \u003d replicaState.getBlockPoolId();\n \n         synchronized (FsDatasetImpl.this) {\n-          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(), replicaState.getBlockId());\n+          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(),\n+                                       replicaState.getBlockId());\n           Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n           blockFile \u003d replicaInfo.getBlockFile();\n           metaFile \u003d replicaInfo.getMetaFile();\n           blockFileUsed \u003d blockFile.length();\n           metaFileUsed \u003d metaFile.length();\n           ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n               replicaState.getBlockId(), false);\n \n-          // Move the replica from lazyPersist/ to finalized/ on target volume\n+          // Move the replica from lazyPersist/ to finalized/ on\n+          // the target volume\n           BlockPoolSlice bpSlice \u003d\n               replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n           File newBlockFile \u003d bpSlice.activateSavedReplica(\n               replicaInfo, replicaState.getSavedMetaFile(),\n               replicaState.getSavedBlockFile());\n \n           newReplicaInfo \u003d\n               new FinalizedReplica(replicaInfo.getBlockId(),\n                                    replicaInfo.getBytesOnDisk(),\n                                    replicaInfo.getGenerationStamp(),\n                                    replicaState.getLazyPersistVolume(),\n                                    newBlockFile.getParentFile());\n \n           // Update the volumeMap entry.\n           volumeMap.add(bpid, newReplicaInfo);\n \n           // Update metrics\n           datanode.getMetrics().incrRamDiskBlocksEvicted();\n           datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n               Time.monotonicNow() - replicaState.getCreationTime());\n           if (replicaState.getNumReads() \u003d\u003d 0) {\n             datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n           }\n-        }\n \n-        removeOldReplica(replicaInfo, newReplicaInfo, blockFile, metaFile,\n-            blockFileUsed, metaFileUsed, bpid);\n+          // Delete the block+meta files from RAM disk and release locked\n+          // memory.\n+          removeOldReplica(replicaInfo, newReplicaInfo, blockFile, metaFile,\n+              blockFileUsed, metaFileUsed, bpid);\n+        }\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    public void evictBlocks(long bytesNeeded) throws IOException {\n      int iterations \u003d 0;\n\n      final long cacheCapacity \u003d cacheManager.getCacheCapacity();\n\n      while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n             (cacheCapacity - cacheManager.getCacheUsed()) \u003c bytesNeeded) {\n        RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n\n        if (replicaState \u003d\u003d null) {\n          break;\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Evicting block \" + replicaState);\n        }\n\n        ReplicaInfo replicaInfo, newReplicaInfo;\n        File blockFile, metaFile;\n        long blockFileUsed, metaFileUsed;\n        final String bpid \u003d replicaState.getBlockPoolId();\n\n        synchronized (FsDatasetImpl.this) {\n          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(),\n                                       replicaState.getBlockId());\n          Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n          blockFile \u003d replicaInfo.getBlockFile();\n          metaFile \u003d replicaInfo.getMetaFile();\n          blockFileUsed \u003d blockFile.length();\n          metaFileUsed \u003d metaFile.length();\n          ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n              replicaState.getBlockId(), false);\n\n          // Move the replica from lazyPersist/ to finalized/ on\n          // the target volume\n          BlockPoolSlice bpSlice \u003d\n              replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n          File newBlockFile \u003d bpSlice.activateSavedReplica(\n              replicaInfo, replicaState.getSavedMetaFile(),\n              replicaState.getSavedBlockFile());\n\n          newReplicaInfo \u003d\n              new FinalizedReplica(replicaInfo.getBlockId(),\n                                   replicaInfo.getBytesOnDisk(),\n                                   replicaInfo.getGenerationStamp(),\n                                   replicaState.getLazyPersistVolume(),\n                                   newBlockFile.getParentFile());\n\n          // Update the volumeMap entry.\n          volumeMap.add(bpid, newReplicaInfo);\n\n          // Update metrics\n          datanode.getMetrics().incrRamDiskBlocksEvicted();\n          datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n              Time.monotonicNow() - replicaState.getCreationTime());\n          if (replicaState.getNumReads() \u003d\u003d 0) {\n            datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n          }\n\n          // Delete the block+meta files from RAM disk and release locked\n          // memory.\n          removeOldReplica(replicaInfo, newReplicaInfo, blockFile, metaFile,\n              blockFileUsed, metaFileUsed, bpid);\n        }\n      }\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8192. Eviction should key off used locked memory instead of ram disk free space. (Contributed by Arpit Agarwal)\n",
          "commitDate": "20/06/15 1:27 PM",
          "commitName": "c7d022b66f0c5baafbb7000a435c1d6e39906efe",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "16/05/15 9:05 AM",
          "commitNameOld": "e453989a5722e653bd97e3e54f9bbdffc9454fba",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 35.18,
          "commitsBetweenForRepo": 253,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,60 +1,66 @@\n-    private void evictBlocks() throws IOException {\n+    public void evictBlocks(long bytesNeeded) throws IOException {\n       int iterations \u003d 0;\n \n+      final long cacheCapacity \u003d cacheManager.getCacheCapacity();\n+\n       while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n-             transientFreeSpaceBelowThreshold()) {\n+             (cacheCapacity - cacheManager.getCacheUsed()) \u003c bytesNeeded) {\n         RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n \n         if (replicaState \u003d\u003d null) {\n           break;\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Evicting block \" + replicaState);\n         }\n \n         ReplicaInfo replicaInfo, newReplicaInfo;\n         File blockFile, metaFile;\n         long blockFileUsed, metaFileUsed;\n         final String bpid \u003d replicaState.getBlockPoolId();\n \n         synchronized (FsDatasetImpl.this) {\n-          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(), replicaState.getBlockId());\n+          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(),\n+                                       replicaState.getBlockId());\n           Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n           blockFile \u003d replicaInfo.getBlockFile();\n           metaFile \u003d replicaInfo.getMetaFile();\n           blockFileUsed \u003d blockFile.length();\n           metaFileUsed \u003d metaFile.length();\n           ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n               replicaState.getBlockId(), false);\n \n-          // Move the replica from lazyPersist/ to finalized/ on target volume\n+          // Move the replica from lazyPersist/ to finalized/ on\n+          // the target volume\n           BlockPoolSlice bpSlice \u003d\n               replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n           File newBlockFile \u003d bpSlice.activateSavedReplica(\n               replicaInfo, replicaState.getSavedMetaFile(),\n               replicaState.getSavedBlockFile());\n \n           newReplicaInfo \u003d\n               new FinalizedReplica(replicaInfo.getBlockId(),\n                                    replicaInfo.getBytesOnDisk(),\n                                    replicaInfo.getGenerationStamp(),\n                                    replicaState.getLazyPersistVolume(),\n                                    newBlockFile.getParentFile());\n \n           // Update the volumeMap entry.\n           volumeMap.add(bpid, newReplicaInfo);\n \n           // Update metrics\n           datanode.getMetrics().incrRamDiskBlocksEvicted();\n           datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n               Time.monotonicNow() - replicaState.getCreationTime());\n           if (replicaState.getNumReads() \u003d\u003d 0) {\n             datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n           }\n-        }\n \n-        removeOldReplica(replicaInfo, newReplicaInfo, blockFile, metaFile,\n-            blockFileUsed, metaFileUsed, bpid);\n+          // Delete the block+meta files from RAM disk and release locked\n+          // memory.\n+          removeOldReplica(replicaInfo, newReplicaInfo, blockFile, metaFile,\n+              blockFileUsed, metaFileUsed, bpid);\n+        }\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    public void evictBlocks(long bytesNeeded) throws IOException {\n      int iterations \u003d 0;\n\n      final long cacheCapacity \u003d cacheManager.getCacheCapacity();\n\n      while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n             (cacheCapacity - cacheManager.getCacheUsed()) \u003c bytesNeeded) {\n        RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n\n        if (replicaState \u003d\u003d null) {\n          break;\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Evicting block \" + replicaState);\n        }\n\n        ReplicaInfo replicaInfo, newReplicaInfo;\n        File blockFile, metaFile;\n        long blockFileUsed, metaFileUsed;\n        final String bpid \u003d replicaState.getBlockPoolId();\n\n        synchronized (FsDatasetImpl.this) {\n          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(),\n                                       replicaState.getBlockId());\n          Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n          blockFile \u003d replicaInfo.getBlockFile();\n          metaFile \u003d replicaInfo.getMetaFile();\n          blockFileUsed \u003d blockFile.length();\n          metaFileUsed \u003d metaFile.length();\n          ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n              replicaState.getBlockId(), false);\n\n          // Move the replica from lazyPersist/ to finalized/ on\n          // the target volume\n          BlockPoolSlice bpSlice \u003d\n              replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n          File newBlockFile \u003d bpSlice.activateSavedReplica(\n              replicaInfo, replicaState.getSavedMetaFile(),\n              replicaState.getSavedBlockFile());\n\n          newReplicaInfo \u003d\n              new FinalizedReplica(replicaInfo.getBlockId(),\n                                   replicaInfo.getBytesOnDisk(),\n                                   replicaInfo.getGenerationStamp(),\n                                   replicaState.getLazyPersistVolume(),\n                                   newBlockFile.getParentFile());\n\n          // Update the volumeMap entry.\n          volumeMap.add(bpid, newReplicaInfo);\n\n          // Update metrics\n          datanode.getMetrics().incrRamDiskBlocksEvicted();\n          datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n              Time.monotonicNow() - replicaState.getCreationTime());\n          if (replicaState.getNumReads() \u003d\u003d 0) {\n            datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n          }\n\n          // Delete the block+meta files from RAM disk and release locked\n          // memory.\n          removeOldReplica(replicaInfo, newReplicaInfo, blockFile, metaFile,\n              blockFileUsed, metaFileUsed, bpid);\n        }\n      }\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "058af60c56207907f2bedf76df4284e86d923e0c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7310. Mover can give first priority to local DN if it has target storage type available in local DN. (Vinayakumar B via umamahesh)\n",
      "commitDate": "26/11/14 9:57 AM",
      "commitName": "058af60c56207907f2bedf76df4284e86d923e0c",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "30/10/14 5:31 PM",
      "commitNameOld": "a9331fe9b071fdcdae0c6c747d7b6b306142e671",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 26.73,
      "commitsBetweenForRepo": 232,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,82 +1,60 @@\n     private void evictBlocks() throws IOException {\n       int iterations \u003d 0;\n \n       while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n              transientFreeSpaceBelowThreshold()) {\n         RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n \n         if (replicaState \u003d\u003d null) {\n           break;\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Evicting block \" + replicaState);\n         }\n \n         ReplicaInfo replicaInfo, newReplicaInfo;\n         File blockFile, metaFile;\n         long blockFileUsed, metaFileUsed;\n         final String bpid \u003d replicaState.getBlockPoolId();\n \n         synchronized (FsDatasetImpl.this) {\n           replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(), replicaState.getBlockId());\n           Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n           blockFile \u003d replicaInfo.getBlockFile();\n           metaFile \u003d replicaInfo.getMetaFile();\n           blockFileUsed \u003d blockFile.length();\n           metaFileUsed \u003d metaFile.length();\n           ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n               replicaState.getBlockId(), false);\n \n           // Move the replica from lazyPersist/ to finalized/ on target volume\n           BlockPoolSlice bpSlice \u003d\n               replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n           File newBlockFile \u003d bpSlice.activateSavedReplica(\n               replicaInfo, replicaState.getSavedMetaFile(),\n               replicaState.getSavedBlockFile());\n \n           newReplicaInfo \u003d\n               new FinalizedReplica(replicaInfo.getBlockId(),\n                                    replicaInfo.getBytesOnDisk(),\n                                    replicaInfo.getGenerationStamp(),\n                                    replicaState.getLazyPersistVolume(),\n                                    newBlockFile.getParentFile());\n \n           // Update the volumeMap entry.\n           volumeMap.add(bpid, newReplicaInfo);\n \n           // Update metrics\n           datanode.getMetrics().incrRamDiskBlocksEvicted();\n           datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n               Time.monotonicNow() - replicaState.getCreationTime());\n           if (replicaState.getNumReads() \u003d\u003d 0) {\n             datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n           }\n         }\n \n-        // Before deleting the files from transient storage we must notify the\n-        // NN that the files are on the new storage. Else a blockReport from\n-        // the transient storage might cause the NN to think the blocks are lost.\n-        // Replicas must be evicted from client short-circuit caches, because the\n-        // storage will no longer be transient, and thus will require validating\n-        // checksum.  This also stops a client from holding file descriptors,\n-        // which would prevent the OS from reclaiming the memory.\n-        ExtendedBlock extendedBlock \u003d\n-            new ExtendedBlock(bpid, newReplicaInfo);\n-        datanode.getShortCircuitRegistry().processBlockInvalidation(\n-            ExtendedBlockId.fromExtendedBlock(extendedBlock));\n-        datanode.notifyNamenodeReceivedBlock(\n-            extendedBlock, null, newReplicaInfo.getStorageUuid());\n-\n-        // Remove the old replicas from transient storage.\n-        if (blockFile.delete() || !blockFile.exists()) {\n-          ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, blockFileUsed);\n-          if (metaFile.delete() || !metaFile.exists()) {\n-            ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, metaFileUsed);\n-          }\n-        }\n-\n-        // If deletion failed then the directory scanner will cleanup the blocks\n-        // eventually.\n+        removeOldReplica(replicaInfo, newReplicaInfo, blockFile, metaFile,\n+            blockFileUsed, metaFileUsed, bpid);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void evictBlocks() throws IOException {\n      int iterations \u003d 0;\n\n      while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n             transientFreeSpaceBelowThreshold()) {\n        RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n\n        if (replicaState \u003d\u003d null) {\n          break;\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Evicting block \" + replicaState);\n        }\n\n        ReplicaInfo replicaInfo, newReplicaInfo;\n        File blockFile, metaFile;\n        long blockFileUsed, metaFileUsed;\n        final String bpid \u003d replicaState.getBlockPoolId();\n\n        synchronized (FsDatasetImpl.this) {\n          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(), replicaState.getBlockId());\n          Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n          blockFile \u003d replicaInfo.getBlockFile();\n          metaFile \u003d replicaInfo.getMetaFile();\n          blockFileUsed \u003d blockFile.length();\n          metaFileUsed \u003d metaFile.length();\n          ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n              replicaState.getBlockId(), false);\n\n          // Move the replica from lazyPersist/ to finalized/ on target volume\n          BlockPoolSlice bpSlice \u003d\n              replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n          File newBlockFile \u003d bpSlice.activateSavedReplica(\n              replicaInfo, replicaState.getSavedMetaFile(),\n              replicaState.getSavedBlockFile());\n\n          newReplicaInfo \u003d\n              new FinalizedReplica(replicaInfo.getBlockId(),\n                                   replicaInfo.getBytesOnDisk(),\n                                   replicaInfo.getGenerationStamp(),\n                                   replicaState.getLazyPersistVolume(),\n                                   newBlockFile.getParentFile());\n\n          // Update the volumeMap entry.\n          volumeMap.add(bpid, newReplicaInfo);\n\n          // Update metrics\n          datanode.getMetrics().incrRamDiskBlocksEvicted();\n          datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n              Time.monotonicNow() - replicaState.getCreationTime());\n          if (replicaState.getNumReads() \u003d\u003d 0) {\n            datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n          }\n        }\n\n        removeOldReplica(replicaInfo, newReplicaInfo, blockFile, metaFile,\n            blockFileUsed, metaFileUsed, bpid);\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "463aec11718e47d4aabb86a7a539cb973460aae6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6934. Move checksum computation off the hot path when writing to RAM disk. Contributed by Chris Nauroth.\n",
      "commitDate": "27/10/14 9:38 AM",
      "commitName": "463aec11718e47d4aabb86a7a539cb973460aae6",
      "commitAuthor": "cnauroth",
      "commitDateOld": "24/10/14 1:08 PM",
      "commitNameOld": "a52eb4bc5fb21574859f779001ea9d95bf5207fe",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 2.85,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,82 @@\n     private void evictBlocks() throws IOException {\n       int iterations \u003d 0;\n \n       while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n              transientFreeSpaceBelowThreshold()) {\n         RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n \n         if (replicaState \u003d\u003d null) {\n           break;\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Evicting block \" + replicaState);\n         }\n \n         ReplicaInfo replicaInfo, newReplicaInfo;\n         File blockFile, metaFile;\n         long blockFileUsed, metaFileUsed;\n         final String bpid \u003d replicaState.getBlockPoolId();\n \n         synchronized (FsDatasetImpl.this) {\n           replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(), replicaState.getBlockId());\n           Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n           blockFile \u003d replicaInfo.getBlockFile();\n           metaFile \u003d replicaInfo.getMetaFile();\n           blockFileUsed \u003d blockFile.length();\n           metaFileUsed \u003d metaFile.length();\n           ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n               replicaState.getBlockId(), false);\n \n           // Move the replica from lazyPersist/ to finalized/ on target volume\n           BlockPoolSlice bpSlice \u003d\n               replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n           File newBlockFile \u003d bpSlice.activateSavedReplica(\n               replicaInfo, replicaState.getSavedMetaFile(),\n               replicaState.getSavedBlockFile());\n \n           newReplicaInfo \u003d\n               new FinalizedReplica(replicaInfo.getBlockId(),\n                                    replicaInfo.getBytesOnDisk(),\n                                    replicaInfo.getGenerationStamp(),\n                                    replicaState.getLazyPersistVolume(),\n                                    newBlockFile.getParentFile());\n \n           // Update the volumeMap entry.\n           volumeMap.add(bpid, newReplicaInfo);\n \n           // Update metrics\n           datanode.getMetrics().incrRamDiskBlocksEvicted();\n           datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n               Time.monotonicNow() - replicaState.getCreationTime());\n           if (replicaState.getNumReads() \u003d\u003d 0) {\n             datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n           }\n         }\n \n         // Before deleting the files from transient storage we must notify the\n         // NN that the files are on the new storage. Else a blockReport from\n         // the transient storage might cause the NN to think the blocks are lost.\n+        // Replicas must be evicted from client short-circuit caches, because the\n+        // storage will no longer be transient, and thus will require validating\n+        // checksum.  This also stops a client from holding file descriptors,\n+        // which would prevent the OS from reclaiming the memory.\n         ExtendedBlock extendedBlock \u003d\n             new ExtendedBlock(bpid, newReplicaInfo);\n+        datanode.getShortCircuitRegistry().processBlockInvalidation(\n+            ExtendedBlockId.fromExtendedBlock(extendedBlock));\n         datanode.notifyNamenodeReceivedBlock(\n             extendedBlock, null, newReplicaInfo.getStorageUuid());\n \n         // Remove the old replicas from transient storage.\n         if (blockFile.delete() || !blockFile.exists()) {\n           ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, blockFileUsed);\n           if (metaFile.delete() || !metaFile.exists()) {\n             ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, metaFileUsed);\n           }\n         }\n \n         // If deletion failed then the directory scanner will cleanup the blocks\n         // eventually.\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void evictBlocks() throws IOException {\n      int iterations \u003d 0;\n\n      while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n             transientFreeSpaceBelowThreshold()) {\n        RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n\n        if (replicaState \u003d\u003d null) {\n          break;\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Evicting block \" + replicaState);\n        }\n\n        ReplicaInfo replicaInfo, newReplicaInfo;\n        File blockFile, metaFile;\n        long blockFileUsed, metaFileUsed;\n        final String bpid \u003d replicaState.getBlockPoolId();\n\n        synchronized (FsDatasetImpl.this) {\n          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(), replicaState.getBlockId());\n          Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n          blockFile \u003d replicaInfo.getBlockFile();\n          metaFile \u003d replicaInfo.getMetaFile();\n          blockFileUsed \u003d blockFile.length();\n          metaFileUsed \u003d metaFile.length();\n          ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n              replicaState.getBlockId(), false);\n\n          // Move the replica from lazyPersist/ to finalized/ on target volume\n          BlockPoolSlice bpSlice \u003d\n              replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n          File newBlockFile \u003d bpSlice.activateSavedReplica(\n              replicaInfo, replicaState.getSavedMetaFile(),\n              replicaState.getSavedBlockFile());\n\n          newReplicaInfo \u003d\n              new FinalizedReplica(replicaInfo.getBlockId(),\n                                   replicaInfo.getBytesOnDisk(),\n                                   replicaInfo.getGenerationStamp(),\n                                   replicaState.getLazyPersistVolume(),\n                                   newBlockFile.getParentFile());\n\n          // Update the volumeMap entry.\n          volumeMap.add(bpid, newReplicaInfo);\n\n          // Update metrics\n          datanode.getMetrics().incrRamDiskBlocksEvicted();\n          datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n              Time.monotonicNow() - replicaState.getCreationTime());\n          if (replicaState.getNumReads() \u003d\u003d 0) {\n            datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n          }\n        }\n\n        // Before deleting the files from transient storage we must notify the\n        // NN that the files are on the new storage. Else a blockReport from\n        // the transient storage might cause the NN to think the blocks are lost.\n        // Replicas must be evicted from client short-circuit caches, because the\n        // storage will no longer be transient, and thus will require validating\n        // checksum.  This also stops a client from holding file descriptors,\n        // which would prevent the OS from reclaiming the memory.\n        ExtendedBlock extendedBlock \u003d\n            new ExtendedBlock(bpid, newReplicaInfo);\n        datanode.getShortCircuitRegistry().processBlockInvalidation(\n            ExtendedBlockId.fromExtendedBlock(extendedBlock));\n        datanode.notifyNamenodeReceivedBlock(\n            extendedBlock, null, newReplicaInfo.getStorageUuid());\n\n        // Remove the old replicas from transient storage.\n        if (blockFile.delete() || !blockFile.exists()) {\n          ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, blockFileUsed);\n          if (metaFile.delete() || !metaFile.exists()) {\n            ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, metaFileUsed);\n          }\n        }\n\n        // If deletion failed then the directory scanner will cleanup the blocks\n        // eventually.\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "1efd9c98258fbb973d2058dcf0850042e53bd02f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7112. LazyWriter should use either async IO or one thread per physical disk. Contributed by Xiaoyu Yao.\n",
      "commitDate": "07/10/14 8:25 PM",
      "commitName": "1efd9c98258fbb973d2058dcf0850042e53bd02f",
      "commitAuthor": "cnauroth",
      "commitDateOld": "30/09/14 12:53 AM",
      "commitNameOld": "5e8b6973527e5f714652641ed95e8a4509e18cfa",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 7.81,
      "commitsBetweenForRepo": 80,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,75 +1,76 @@\n     private void evictBlocks() throws IOException {\n       int iterations \u003d 0;\n \n       while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n              transientFreeSpaceBelowThreshold()) {\n         RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n \n         if (replicaState \u003d\u003d null) {\n           break;\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Evicting block \" + replicaState);\n         }\n \n         ReplicaInfo replicaInfo, newReplicaInfo;\n         File blockFile, metaFile;\n         long blockFileUsed, metaFileUsed;\n         final String bpid \u003d replicaState.getBlockPoolId();\n \n         synchronized (FsDatasetImpl.this) {\n           replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(), replicaState.getBlockId());\n           Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n           blockFile \u003d replicaInfo.getBlockFile();\n           metaFile \u003d replicaInfo.getMetaFile();\n           blockFileUsed \u003d blockFile.length();\n           metaFileUsed \u003d metaFile.length();\n-          discardRamDiskReplica(replicaState, false);\n+          ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n+              replicaState.getBlockId(), false);\n \n           // Move the replica from lazyPersist/ to finalized/ on target volume\n           BlockPoolSlice bpSlice \u003d\n               replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n           File newBlockFile \u003d bpSlice.activateSavedReplica(\n               replicaInfo, replicaState.getSavedMetaFile(),\n               replicaState.getSavedBlockFile());\n \n           newReplicaInfo \u003d\n               new FinalizedReplica(replicaInfo.getBlockId(),\n                                    replicaInfo.getBytesOnDisk(),\n                                    replicaInfo.getGenerationStamp(),\n                                    replicaState.getLazyPersistVolume(),\n                                    newBlockFile.getParentFile());\n \n           // Update the volumeMap entry.\n           volumeMap.add(bpid, newReplicaInfo);\n \n           // Update metrics\n           datanode.getMetrics().incrRamDiskBlocksEvicted();\n           datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n               Time.monotonicNow() - replicaState.getCreationTime());\n           if (replicaState.getNumReads() \u003d\u003d 0) {\n             datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n           }\n         }\n \n         // Before deleting the files from transient storage we must notify the\n         // NN that the files are on the new storage. Else a blockReport from\n         // the transient storage might cause the NN to think the blocks are lost.\n         ExtendedBlock extendedBlock \u003d\n             new ExtendedBlock(bpid, newReplicaInfo);\n         datanode.notifyNamenodeReceivedBlock(\n             extendedBlock, null, newReplicaInfo.getStorageUuid());\n \n         // Remove the old replicas from transient storage.\n         if (blockFile.delete() || !blockFile.exists()) {\n           ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, blockFileUsed);\n           if (metaFile.delete() || !metaFile.exists()) {\n             ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, metaFileUsed);\n           }\n         }\n \n         // If deletion failed then the directory scanner will cleanup the blocks\n         // eventually.\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void evictBlocks() throws IOException {\n      int iterations \u003d 0;\n\n      while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n             transientFreeSpaceBelowThreshold()) {\n        RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n\n        if (replicaState \u003d\u003d null) {\n          break;\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Evicting block \" + replicaState);\n        }\n\n        ReplicaInfo replicaInfo, newReplicaInfo;\n        File blockFile, metaFile;\n        long blockFileUsed, metaFileUsed;\n        final String bpid \u003d replicaState.getBlockPoolId();\n\n        synchronized (FsDatasetImpl.this) {\n          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(), replicaState.getBlockId());\n          Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n          blockFile \u003d replicaInfo.getBlockFile();\n          metaFile \u003d replicaInfo.getMetaFile();\n          blockFileUsed \u003d blockFile.length();\n          metaFileUsed \u003d metaFile.length();\n          ramDiskReplicaTracker.discardReplica(replicaState.getBlockPoolId(),\n              replicaState.getBlockId(), false);\n\n          // Move the replica from lazyPersist/ to finalized/ on target volume\n          BlockPoolSlice bpSlice \u003d\n              replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n          File newBlockFile \u003d bpSlice.activateSavedReplica(\n              replicaInfo, replicaState.getSavedMetaFile(),\n              replicaState.getSavedBlockFile());\n\n          newReplicaInfo \u003d\n              new FinalizedReplica(replicaInfo.getBlockId(),\n                                   replicaInfo.getBytesOnDisk(),\n                                   replicaInfo.getGenerationStamp(),\n                                   replicaState.getLazyPersistVolume(),\n                                   newBlockFile.getParentFile());\n\n          // Update the volumeMap entry.\n          volumeMap.add(bpid, newReplicaInfo);\n\n          // Update metrics\n          datanode.getMetrics().incrRamDiskBlocksEvicted();\n          datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n              Time.monotonicNow() - replicaState.getCreationTime());\n          if (replicaState.getNumReads() \u003d\u003d 0) {\n            datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n          }\n        }\n\n        // Before deleting the files from transient storage we must notify the\n        // NN that the files are on the new storage. Else a blockReport from\n        // the transient storage might cause the NN to think the blocks are lost.\n        ExtendedBlock extendedBlock \u003d\n            new ExtendedBlock(bpid, newReplicaInfo);\n        datanode.notifyNamenodeReceivedBlock(\n            extendedBlock, null, newReplicaInfo.getStorageUuid());\n\n        // Remove the old replicas from transient storage.\n        if (blockFile.delete() || !blockFile.exists()) {\n          ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, blockFileUsed);\n          if (metaFile.delete() || !metaFile.exists()) {\n            ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, metaFileUsed);\n          }\n        }\n\n        // If deletion failed then the directory scanner will cleanup the blocks\n        // eventually.\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "5e8b6973527e5f714652641ed95e8a4509e18cfa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7129. Metrics to track usage of memory for writes. (Contributed by Xiaoyu Yao)\n",
      "commitDate": "30/09/14 12:53 AM",
      "commitName": "5e8b6973527e5f714652641ed95e8a4509e18cfa",
      "commitAuthor": "arp",
      "commitDateOld": "29/09/14 10:27 PM",
      "commitNameOld": "bb84f1fccb18c6c7373851e05d2451d55e908242",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,75 @@\n     private void evictBlocks() throws IOException {\n       int iterations \u003d 0;\n \n       while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n              transientFreeSpaceBelowThreshold()) {\n         RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n \n         if (replicaState \u003d\u003d null) {\n           break;\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Evicting block \" + replicaState);\n         }\n \n         ReplicaInfo replicaInfo, newReplicaInfo;\n         File blockFile, metaFile;\n         long blockFileUsed, metaFileUsed;\n         final String bpid \u003d replicaState.getBlockPoolId();\n \n         synchronized (FsDatasetImpl.this) {\n           replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(), replicaState.getBlockId());\n           Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n           blockFile \u003d replicaInfo.getBlockFile();\n           metaFile \u003d replicaInfo.getMetaFile();\n           blockFileUsed \u003d blockFile.length();\n           metaFileUsed \u003d metaFile.length();\n-          ramDiskReplicaTracker.discardReplica(replicaState, false);\n+          discardRamDiskReplica(replicaState, false);\n \n           // Move the replica from lazyPersist/ to finalized/ on target volume\n           BlockPoolSlice bpSlice \u003d\n               replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n           File newBlockFile \u003d bpSlice.activateSavedReplica(\n               replicaInfo, replicaState.getSavedMetaFile(),\n               replicaState.getSavedBlockFile());\n \n           newReplicaInfo \u003d\n               new FinalizedReplica(replicaInfo.getBlockId(),\n                                    replicaInfo.getBytesOnDisk(),\n                                    replicaInfo.getGenerationStamp(),\n                                    replicaState.getLazyPersistVolume(),\n                                    newBlockFile.getParentFile());\n \n           // Update the volumeMap entry.\n           volumeMap.add(bpid, newReplicaInfo);\n+\n+          // Update metrics\n+          datanode.getMetrics().incrRamDiskBlocksEvicted();\n+          datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n+              Time.monotonicNow() - replicaState.getCreationTime());\n+          if (replicaState.getNumReads() \u003d\u003d 0) {\n+            datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n+          }\n         }\n \n         // Before deleting the files from transient storage we must notify the\n         // NN that the files are on the new storage. Else a blockReport from\n         // the transient storage might cause the NN to think the blocks are lost.\n         ExtendedBlock extendedBlock \u003d\n             new ExtendedBlock(bpid, newReplicaInfo);\n         datanode.notifyNamenodeReceivedBlock(\n             extendedBlock, null, newReplicaInfo.getStorageUuid());\n \n         // Remove the old replicas from transient storage.\n         if (blockFile.delete() || !blockFile.exists()) {\n           ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, blockFileUsed);\n           if (metaFile.delete() || !metaFile.exists()) {\n             ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, metaFileUsed);\n           }\n         }\n \n         // If deletion failed then the directory scanner will cleanup the blocks\n         // eventually.\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void evictBlocks() throws IOException {\n      int iterations \u003d 0;\n\n      while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n             transientFreeSpaceBelowThreshold()) {\n        RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n\n        if (replicaState \u003d\u003d null) {\n          break;\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Evicting block \" + replicaState);\n        }\n\n        ReplicaInfo replicaInfo, newReplicaInfo;\n        File blockFile, metaFile;\n        long blockFileUsed, metaFileUsed;\n        final String bpid \u003d replicaState.getBlockPoolId();\n\n        synchronized (FsDatasetImpl.this) {\n          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(), replicaState.getBlockId());\n          Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n          blockFile \u003d replicaInfo.getBlockFile();\n          metaFile \u003d replicaInfo.getMetaFile();\n          blockFileUsed \u003d blockFile.length();\n          metaFileUsed \u003d metaFile.length();\n          discardRamDiskReplica(replicaState, false);\n\n          // Move the replica from lazyPersist/ to finalized/ on target volume\n          BlockPoolSlice bpSlice \u003d\n              replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n          File newBlockFile \u003d bpSlice.activateSavedReplica(\n              replicaInfo, replicaState.getSavedMetaFile(),\n              replicaState.getSavedBlockFile());\n\n          newReplicaInfo \u003d\n              new FinalizedReplica(replicaInfo.getBlockId(),\n                                   replicaInfo.getBytesOnDisk(),\n                                   replicaInfo.getGenerationStamp(),\n                                   replicaState.getLazyPersistVolume(),\n                                   newBlockFile.getParentFile());\n\n          // Update the volumeMap entry.\n          volumeMap.add(bpid, newReplicaInfo);\n\n          // Update metrics\n          datanode.getMetrics().incrRamDiskBlocksEvicted();\n          datanode.getMetrics().addRamDiskBlocksEvictionWindowMs(\n              Time.monotonicNow() - replicaState.getCreationTime());\n          if (replicaState.getNumReads() \u003d\u003d 0) {\n            datanode.getMetrics().incrRamDiskBlocksEvictedWithoutRead();\n          }\n        }\n\n        // Before deleting the files from transient storage we must notify the\n        // NN that the files are on the new storage. Else a blockReport from\n        // the transient storage might cause the NN to think the blocks are lost.\n        ExtendedBlock extendedBlock \u003d\n            new ExtendedBlock(bpid, newReplicaInfo);\n        datanode.notifyNamenodeReceivedBlock(\n            extendedBlock, null, newReplicaInfo.getStorageUuid());\n\n        // Remove the old replicas from transient storage.\n        if (blockFile.delete() || !blockFile.exists()) {\n          ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, blockFileUsed);\n          if (metaFile.delete() || !metaFile.exists()) {\n            ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, metaFileUsed);\n          }\n        }\n\n        // If deletion failed then the directory scanner will cleanup the blocks\n        // eventually.\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    },
    "b2d5ed36bcb80e2581191dcdc3976e825c959142": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7100. Make eviction scheme pluggable. (Arpit Agarwal)\n",
      "commitDate": "20/09/14 1:25 PM",
      "commitName": "b2d5ed36bcb80e2581191dcdc3976e825c959142",
      "commitAuthor": "arp",
      "commitDateOld": "19/09/14 10:02 AM",
      "commitNameOld": "222bf0fe6706ee43964fd39b8315c1a339fbc84a",
      "commitAuthorOld": "",
      "daysBetweenCommits": 1.14,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,67 @@\n     private void evictBlocks() throws IOException {\n       int iterations \u003d 0;\n \n       while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n              transientFreeSpaceBelowThreshold()) {\n-        LazyWriteReplicaTracker.ReplicaState replicaState \u003d\n-            lazyWriteReplicaTracker.getNextCandidateForEviction();\n+        RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n \n         if (replicaState \u003d\u003d null) {\n           break;\n         }\n \n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Evicting block \" + replicaState);\n         }\n \n         ReplicaInfo replicaInfo, newReplicaInfo;\n         File blockFile, metaFile;\n         long blockFileUsed, metaFileUsed;\n+        final String bpid \u003d replicaState.getBlockPoolId();\n \n         synchronized (FsDatasetImpl.this) {\n-          replicaInfo \u003d getReplicaInfo(replicaState.bpid, replicaState.blockId);\n+          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(), replicaState.getBlockId());\n           Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n           blockFile \u003d replicaInfo.getBlockFile();\n           metaFile \u003d replicaInfo.getMetaFile();\n           blockFileUsed \u003d blockFile.length();\n           metaFileUsed \u003d metaFile.length();\n-          lazyWriteReplicaTracker.discardReplica(replicaState, false);\n+          ramDiskReplicaTracker.discardReplica(replicaState, false);\n \n           // Move the replica from lazyPersist/ to finalized/ on target volume\n           BlockPoolSlice bpSlice \u003d\n-              replicaState.lazyPersistVolume.getBlockPoolSlice(replicaState.bpid);\n+              replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n           File newBlockFile \u003d bpSlice.activateSavedReplica(\n-              replicaInfo, replicaState.savedBlockFile);\n+              replicaInfo, replicaState.getSavedMetaFile(),\n+              replicaState.getSavedBlockFile());\n \n           newReplicaInfo \u003d\n               new FinalizedReplica(replicaInfo.getBlockId(),\n                                    replicaInfo.getBytesOnDisk(),\n                                    replicaInfo.getGenerationStamp(),\n-                                   replicaState.lazyPersistVolume,\n+                                   replicaState.getLazyPersistVolume(),\n                                    newBlockFile.getParentFile());\n \n           // Update the volumeMap entry.\n-          volumeMap.add(replicaState.bpid, newReplicaInfo);\n+          volumeMap.add(bpid, newReplicaInfo);\n         }\n \n         // Before deleting the files from transient storage we must notify the\n         // NN that the files are on the new storage. Else a blockReport from\n         // the transient storage might cause the NN to think the blocks are lost.\n         ExtendedBlock extendedBlock \u003d\n-            new ExtendedBlock(replicaState.bpid, newReplicaInfo);\n+            new ExtendedBlock(bpid, newReplicaInfo);\n         datanode.notifyNamenodeReceivedBlock(\n             extendedBlock, null, newReplicaInfo.getStorageUuid());\n \n         // Remove the old replicas from transient storage.\n         if (blockFile.delete() || !blockFile.exists()) {\n-          ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(replicaState.bpid, blockFileUsed);\n+          ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, blockFileUsed);\n           if (metaFile.delete() || !metaFile.exists()) {\n-            ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(replicaState.bpid, metaFileUsed);\n+            ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, metaFileUsed);\n           }\n         }\n \n         // If deletion failed then the directory scanner will cleanup the blocks\n         // eventually.\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void evictBlocks() throws IOException {\n      int iterations \u003d 0;\n\n      while (iterations++ \u003c MAX_BLOCK_EVICTIONS_PER_ITERATION \u0026\u0026\n             transientFreeSpaceBelowThreshold()) {\n        RamDiskReplica replicaState \u003d ramDiskReplicaTracker.getNextCandidateForEviction();\n\n        if (replicaState \u003d\u003d null) {\n          break;\n        }\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Evicting block \" + replicaState);\n        }\n\n        ReplicaInfo replicaInfo, newReplicaInfo;\n        File blockFile, metaFile;\n        long blockFileUsed, metaFileUsed;\n        final String bpid \u003d replicaState.getBlockPoolId();\n\n        synchronized (FsDatasetImpl.this) {\n          replicaInfo \u003d getReplicaInfo(replicaState.getBlockPoolId(), replicaState.getBlockId());\n          Preconditions.checkState(replicaInfo.getVolume().isTransientStorage());\n          blockFile \u003d replicaInfo.getBlockFile();\n          metaFile \u003d replicaInfo.getMetaFile();\n          blockFileUsed \u003d blockFile.length();\n          metaFileUsed \u003d metaFile.length();\n          ramDiskReplicaTracker.discardReplica(replicaState, false);\n\n          // Move the replica from lazyPersist/ to finalized/ on target volume\n          BlockPoolSlice bpSlice \u003d\n              replicaState.getLazyPersistVolume().getBlockPoolSlice(bpid);\n          File newBlockFile \u003d bpSlice.activateSavedReplica(\n              replicaInfo, replicaState.getSavedMetaFile(),\n              replicaState.getSavedBlockFile());\n\n          newReplicaInfo \u003d\n              new FinalizedReplica(replicaInfo.getBlockId(),\n                                   replicaInfo.getBytesOnDisk(),\n                                   replicaInfo.getGenerationStamp(),\n                                   replicaState.getLazyPersistVolume(),\n                                   newBlockFile.getParentFile());\n\n          // Update the volumeMap entry.\n          volumeMap.add(bpid, newReplicaInfo);\n        }\n\n        // Before deleting the files from transient storage we must notify the\n        // NN that the files are on the new storage. Else a blockReport from\n        // the transient storage might cause the NN to think the blocks are lost.\n        ExtendedBlock extendedBlock \u003d\n            new ExtendedBlock(bpid, newReplicaInfo);\n        datanode.notifyNamenodeReceivedBlock(\n            extendedBlock, null, newReplicaInfo.getStorageUuid());\n\n        // Remove the old replicas from transient storage.\n        if (blockFile.delete() || !blockFile.exists()) {\n          ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, blockFileUsed);\n          if (metaFile.delete() || !metaFile.exists()) {\n            ((FsVolumeImpl) replicaInfo.getVolume()).decDfsUsed(bpid, metaFileUsed);\n          }\n        }\n\n        // If deletion failed then the directory scanner will cleanup the blocks\n        // eventually.\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java",
      "extendedDetails": {}
    }
  }
}