{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FsVolumeImpl.java",
  "functionName": "incDfsUsed",
  "functionId": "incDfsUsed___bpid-String__value-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeImpl.java",
  "functionStartLine": 384,
  "functionEndLine": 389,
  "numCommitsSeen": 71,
  "timeTaken": 2760,
  "changeHistory": [
    "bb8a6eea52cb1e2c3d0b7f8b49a1bab9e4255acd",
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c",
    "1efd9c98258fbb973d2058dcf0850042e53bd02f"
  ],
  "changeHistoryShort": {
    "bb8a6eea52cb1e2c3d0b7f8b49a1bab9e4255acd": "Ybodychange",
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c": "Ybodychange",
    "1efd9c98258fbb973d2058dcf0850042e53bd02f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "bb8a6eea52cb1e2c3d0b7f8b49a1bab9e4255acd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7060. Avoid taking locks when sending heartbeats from the DataNode. Contributed by Jiandan Yang.\n",
      "commitDate": "07/11/17 6:22 PM",
      "commitName": "bb8a6eea52cb1e2c3d0b7f8b49a1bab9e4255acd",
      "commitAuthor": "Weiwei Yang",
      "commitDateOld": "03/04/17 8:13 PM",
      "commitNameOld": "6eba79232f36b36e0196163adc8fe4219a6b6bf9",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 217.96,
      "commitsBetweenForRepo": 1557,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,6 @@\n   void incDfsUsed(String bpid, long value) {\n-    try(AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n-      BlockPoolSlice bp \u003d bpSlices.get(bpid);\n-      if (bp !\u003d null) {\n-        bp.incDfsUsed(value);\n-      }\n+    BlockPoolSlice bp \u003d bpSlices.get(bpid);\n+    if (bp !\u003d null) {\n+      bp.incDfsUsed(value);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void incDfsUsed(String bpid, long value) {\n    BlockPoolSlice bp \u003d bpSlices.get(bpid);\n    if (bp !\u003d null) {\n      bp.incDfsUsed(value);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeImpl.java",
      "extendedDetails": {}
    },
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10682. Replace FsDatasetImpl object lock with a separate lock object. (Chen Liang)\n",
      "commitDate": "08/08/16 12:02 PM",
      "commitName": "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "23/06/16 6:20 PM",
      "commitNameOld": "7820737cfa178d9de1bcbb1e99b9677d70901914",
      "commitAuthorOld": "Anu Engineer",
      "daysBetweenCommits": 45.74,
      "commitsBetweenForRepo": 409,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,8 @@\n   void incDfsUsed(String bpid, long value) {\n-    synchronized(dataset) {\n+    try(AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n       BlockPoolSlice bp \u003d bpSlices.get(bpid);\n       if (bp !\u003d null) {\n         bp.incDfsUsed(value);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void incDfsUsed(String bpid, long value) {\n    try(AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n      BlockPoolSlice bp \u003d bpSlices.get(bpid);\n      if (bp !\u003d null) {\n        bp.incDfsUsed(value);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeImpl.java",
      "extendedDetails": {}
    },
    "1efd9c98258fbb973d2058dcf0850042e53bd02f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7112. LazyWriter should use either async IO or one thread per physical disk. Contributed by Xiaoyu Yao.\n",
      "commitDate": "07/10/14 8:25 PM",
      "commitName": "1efd9c98258fbb973d2058dcf0850042e53bd02f",
      "commitAuthor": "cnauroth",
      "diff": "@@ -0,0 +1,8 @@\n+  void incDfsUsed(String bpid, long value) {\n+    synchronized(dataset) {\n+      BlockPoolSlice bp \u003d bpSlices.get(bpid);\n+      if (bp !\u003d null) {\n+        bp.incDfsUsed(value);\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void incDfsUsed(String bpid, long value) {\n    synchronized(dataset) {\n      BlockPoolSlice bp \u003d bpSlices.get(bpid);\n      if (bp !\u003d null) {\n        bp.incDfsUsed(value);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeImpl.java"
    }
  }
}