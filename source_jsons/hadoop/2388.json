{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PBHelperClient.java",
  "functionName": "convertBlockIndices",
  "functionId": "convertBlockIndices___blockIndices-List__Integer__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java",
  "functionStartLine": 1061,
  "functionEndLine": 1067,
  "numCommitsSeen": 80,
  "timeTaken": 2666,
  "changeHistory": [
    "d749cf65e1ab0e0daf5be86931507183f189e855"
  ],
  "changeHistoryShort": {
    "d749cf65e1ab0e0daf5be86931507183f189e855": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d749cf65e1ab0e0daf5be86931507183f189e855": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9833. Erasure coding: recomputing block checksum on the fly by reconstructing the missed/corrupt block data. Contributed by Rakesh R.\n",
      "commitDate": "01/06/16 9:56 PM",
      "commitName": "d749cf65e1ab0e0daf5be86931507183f189e855",
      "commitAuthor": "Kai Zheng",
      "diff": "@@ -0,0 +1,7 @@\n+  public static byte[] convertBlockIndices(List\u003cInteger\u003e blockIndices) {\n+    byte[] blkIndices \u003d new byte[blockIndices.size()];\n+    for (int i \u003d 0; i \u003c blockIndices.size(); i++) {\n+      blkIndices[i] \u003d (byte) blockIndices.get(i).intValue();\n+    }\n+    return blkIndices;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static byte[] convertBlockIndices(List\u003cInteger\u003e blockIndices) {\n    byte[] blkIndices \u003d new byte[blockIndices.size()];\n    for (int i \u003d 0; i \u003c blockIndices.size(); i++) {\n      blkIndices[i] \u003d (byte) blockIndices.get(i).intValue();\n    }\n    return blkIndices;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java"
    }
  }
}