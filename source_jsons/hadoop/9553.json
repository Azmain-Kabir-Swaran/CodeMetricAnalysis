{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ReportCommand.java",
  "functionName": "recordNodeReport",
  "functionId": "recordNodeReport___result-TextStringBuilder__dbdn-DiskBalancerDataNode__nodeFormat-String(modifiers-final)__volumeFormat-String(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/ReportCommand.java",
  "functionStartLine": 178,
  "functionEndLine": 215,
  "numCommitsSeen": 23,
  "timeTaken": 1120,
  "changeHistory": [
    "88625f5cd90766136a9ebd76a8d84b45a37e6c99",
    "8a93f45a80932a1ef62a6c20551e8cab95888fee"
  ],
  "changeHistoryShort": {
    "88625f5cd90766136a9ebd76a8d84b45a37e6c99": "Yparameterchange",
    "8a93f45a80932a1ef62a6c20551e8cab95888fee": "Yintroduced"
  },
  "changeHistoryDetails": {
    "88625f5cd90766136a9ebd76a8d84b45a37e6c99": {
      "type": "Yparameterchange",
      "commitMessage": "HADOOP-15531. Use commons-text instead of commons-lang in some classes to fix deprecation warnings. Contributed by Takanobu Asanuma.\n",
      "commitDate": "13/07/18 8:42 AM",
      "commitName": "88625f5cd90766136a9ebd76a8d84b45a37e6c99",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "18/06/18 10:17 AM",
      "commitNameOld": "fba9d7cd746cd7b659d2fd9d2bfa23266be9009b",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 24.93,
      "commitsBetweenForRepo": 148,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,38 @@\n-  private void recordNodeReport(StrBuilder result, DiskBalancerDataNode dbdn,\n+  private void recordNodeReport(TextStringBuilder result, DiskBalancerDataNode dbdn,\n       final String nodeFormat, final String volumeFormat) throws Exception {\n     final String trueStr \u003d \"True\";\n     final String falseStr \u003d \"False\";\n \n     // get storage path of datanode\n     populatePathNames(dbdn);\n     result.appendln(String.format(nodeFormat,\n         dbdn.getDataNodeName(),\n         dbdn.getDataNodeIP(),\n         dbdn.getDataNodePort(),\n         dbdn.getDataNodeUUID(),\n         dbdn.getVolumeCount(),\n         dbdn.getNodeDataDensity()));\n \n     List\u003cString\u003e volumeList \u003d Lists.newArrayList();\n     for (DiskBalancerVolumeSet vset : dbdn.getVolumeSets().values()) {\n       for (DiskBalancerVolume vol : vset.getVolumes()) {\n         volumeList.add(String.format(volumeFormat,\n             vol.getStorageType(),\n             vol.getPath(),\n             vol.getUsedRatio(),\n             vol.getUsed(),\n             vol.getCapacity(),\n             vol.getFreeRatio(),\n             vol.getFreeSpace(),\n             vol.getCapacity(),\n             vol.isFailed() ? trueStr : falseStr,\n             vol.isReadOnly() ? trueStr: falseStr,\n             vol.isSkip() ? trueStr : falseStr,\n             vol.isTransient() ? trueStr : falseStr));\n       }\n     }\n \n     Collections.sort(volumeList);\n     result.appendln(\n         StringUtils.join(volumeList.toArray(), System.lineSeparator()));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void recordNodeReport(TextStringBuilder result, DiskBalancerDataNode dbdn,\n      final String nodeFormat, final String volumeFormat) throws Exception {\n    final String trueStr \u003d \"True\";\n    final String falseStr \u003d \"False\";\n\n    // get storage path of datanode\n    populatePathNames(dbdn);\n    result.appendln(String.format(nodeFormat,\n        dbdn.getDataNodeName(),\n        dbdn.getDataNodeIP(),\n        dbdn.getDataNodePort(),\n        dbdn.getDataNodeUUID(),\n        dbdn.getVolumeCount(),\n        dbdn.getNodeDataDensity()));\n\n    List\u003cString\u003e volumeList \u003d Lists.newArrayList();\n    for (DiskBalancerVolumeSet vset : dbdn.getVolumeSets().values()) {\n      for (DiskBalancerVolume vol : vset.getVolumes()) {\n        volumeList.add(String.format(volumeFormat,\n            vol.getStorageType(),\n            vol.getPath(),\n            vol.getUsedRatio(),\n            vol.getUsed(),\n            vol.getCapacity(),\n            vol.getFreeRatio(),\n            vol.getFreeSpace(),\n            vol.getCapacity(),\n            vol.isFailed() ? trueStr : falseStr,\n            vol.isReadOnly() ? trueStr: falseStr,\n            vol.isSkip() ? trueStr : falseStr,\n            vol.isTransient() ? trueStr : falseStr));\n      }\n    }\n\n    Collections.sort(volumeList);\n    result.appendln(\n        StringUtils.join(volumeList.toArray(), System.lineSeparator()));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/ReportCommand.java",
      "extendedDetails": {
        "oldValue": "[result-StrBuilder, dbdn-DiskBalancerDataNode, nodeFormat-String(modifiers-final), volumeFormat-String(modifiers-final)]",
        "newValue": "[result-TextStringBuilder, dbdn-DiskBalancerDataNode, nodeFormat-String(modifiers-final), volumeFormat-String(modifiers-final)]"
      }
    },
    "8a93f45a80932a1ef62a6c20551e8cab95888fee": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-10821. DiskBalancer: Report command support with multiple nodes. Contributed by Yiqun Lin.\n",
      "commitDate": "12/09/16 3:45 PM",
      "commitName": "8a93f45a80932a1ef62a6c20551e8cab95888fee",
      "commitAuthor": "Anu Engineer",
      "diff": "@@ -0,0 +1,38 @@\n+  private void recordNodeReport(StrBuilder result, DiskBalancerDataNode dbdn,\n+      final String nodeFormat, final String volumeFormat) throws Exception {\n+    final String trueStr \u003d \"True\";\n+    final String falseStr \u003d \"False\";\n+\n+    // get storage path of datanode\n+    populatePathNames(dbdn);\n+    result.appendln(String.format(nodeFormat,\n+        dbdn.getDataNodeName(),\n+        dbdn.getDataNodeIP(),\n+        dbdn.getDataNodePort(),\n+        dbdn.getDataNodeUUID(),\n+        dbdn.getVolumeCount(),\n+        dbdn.getNodeDataDensity()));\n+\n+    List\u003cString\u003e volumeList \u003d Lists.newArrayList();\n+    for (DiskBalancerVolumeSet vset : dbdn.getVolumeSets().values()) {\n+      for (DiskBalancerVolume vol : vset.getVolumes()) {\n+        volumeList.add(String.format(volumeFormat,\n+            vol.getStorageType(),\n+            vol.getPath(),\n+            vol.getUsedRatio(),\n+            vol.getUsed(),\n+            vol.getCapacity(),\n+            vol.getFreeRatio(),\n+            vol.getFreeSpace(),\n+            vol.getCapacity(),\n+            vol.isFailed() ? trueStr : falseStr,\n+            vol.isReadOnly() ? trueStr: falseStr,\n+            vol.isSkip() ? trueStr : falseStr,\n+            vol.isTransient() ? trueStr : falseStr));\n+      }\n+    }\n+\n+    Collections.sort(volumeList);\n+    result.appendln(\n+        StringUtils.join(volumeList.toArray(), System.lineSeparator()));\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void recordNodeReport(StrBuilder result, DiskBalancerDataNode dbdn,\n      final String nodeFormat, final String volumeFormat) throws Exception {\n    final String trueStr \u003d \"True\";\n    final String falseStr \u003d \"False\";\n\n    // get storage path of datanode\n    populatePathNames(dbdn);\n    result.appendln(String.format(nodeFormat,\n        dbdn.getDataNodeName(),\n        dbdn.getDataNodeIP(),\n        dbdn.getDataNodePort(),\n        dbdn.getDataNodeUUID(),\n        dbdn.getVolumeCount(),\n        dbdn.getNodeDataDensity()));\n\n    List\u003cString\u003e volumeList \u003d Lists.newArrayList();\n    for (DiskBalancerVolumeSet vset : dbdn.getVolumeSets().values()) {\n      for (DiskBalancerVolume vol : vset.getVolumes()) {\n        volumeList.add(String.format(volumeFormat,\n            vol.getStorageType(),\n            vol.getPath(),\n            vol.getUsedRatio(),\n            vol.getUsed(),\n            vol.getCapacity(),\n            vol.getFreeRatio(),\n            vol.getFreeSpace(),\n            vol.getCapacity(),\n            vol.isFailed() ? trueStr : falseStr,\n            vol.isReadOnly() ? trueStr: falseStr,\n            vol.isSkip() ? trueStr : falseStr,\n            vol.isTransient() ? trueStr : falseStr));\n      }\n    }\n\n    Collections.sort(volumeList);\n    result.appendln(\n        StringUtils.join(volumeList.toArray(), System.lineSeparator()));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/ReportCommand.java"
    }
  }
}