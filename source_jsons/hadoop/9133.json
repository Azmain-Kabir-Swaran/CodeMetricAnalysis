{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSNamesystem.java",
  "functionName": "getDatanodeStorageReport",
  "functionId": "getDatanodeStorageReport___type-DatanodeReportType(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
  "functionStartLine": 4828,
  "functionEndLine": 4844,
  "numCommitsSeen": 873,
  "timeTaken": 31154,
  "changeHistory": [
    "1824aee9da4056de0fb638906b2172e486bbebe7",
    "f600fbb6c4987c69292faea6b5abf022bb213ffd",
    "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
    "9d3e4cccf9cd0ffb60ee0e7c65cea5ae3c8015c2",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893",
    "ed0bebabaaf27cd730f7f8eb002d92c9c7db327d"
  ],
  "changeHistoryShort": {
    "1824aee9da4056de0fb638906b2172e486bbebe7": "Ybodychange",
    "f600fbb6c4987c69292faea6b5abf022bb213ffd": "Ybodychange",
    "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d": "Ybodychange",
    "9d3e4cccf9cd0ffb60ee0e7c65cea5ae3c8015c2": "Ymultichange(Yexceptionschange,Ybodychange)",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": "Ybodychange",
    "ed0bebabaaf27cd730f7f8eb002d92c9c7db327d": "Ybodychange"
  },
  "changeHistoryDetails": {
    "1824aee9da4056de0fb638906b2172e486bbebe7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15217 Add more information to longest write/read lock held log\n\n",
      "commitDate": "18/04/20 1:52 PM",
      "commitName": "1824aee9da4056de0fb638906b2172e486bbebe7",
      "commitAuthor": "Toshihiro Suzuki",
      "commitDateOld": "25/03/20 10:28 AM",
      "commitNameOld": "a700803a18fb957d2799001a2ce1dcb70f75c080",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 24.14,
      "commitsBetweenForRepo": 78,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   DatanodeStorageReport[] getDatanodeStorageReport(final DatanodeReportType type\n       ) throws IOException {\n     String operationName \u003d \"getDatanodeStorageReport\";\n     DatanodeStorageReport[] reports;\n     checkSuperuserPrivilege(operationName);\n     checkOperation(OperationCategory.UNCHECKED);\n     readLock();\n     try {\n       checkOperation(OperationCategory.UNCHECKED);\n       final DatanodeManager dm \u003d getBlockManager().getDatanodeManager();      \n       reports \u003d dm.getDatanodeStorageReport(type);\n     } finally {\n-      readUnlock(operationName);\n+      readUnlock(operationName, getLockReportInfoSupplier(null));\n     }\n     logAuditEvent(true, operationName, null);\n     return reports;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  DatanodeStorageReport[] getDatanodeStorageReport(final DatanodeReportType type\n      ) throws IOException {\n    String operationName \u003d \"getDatanodeStorageReport\";\n    DatanodeStorageReport[] reports;\n    checkSuperuserPrivilege(operationName);\n    checkOperation(OperationCategory.UNCHECKED);\n    readLock();\n    try {\n      checkOperation(OperationCategory.UNCHECKED);\n      final DatanodeManager dm \u003d getBlockManager().getDatanodeManager();      \n      reports \u003d dm.getDatanodeStorageReport(type);\n    } finally {\n      readUnlock(operationName, getLockReportInfoSupplier(null));\n    }\n    logAuditEvent(true, operationName, null);\n    return reports;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "f600fbb6c4987c69292faea6b5abf022bb213ffd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11246. FSNameSystem#logAuditEvent should be called outside the read or write locks. Contributed by He Xiaoqiao, Kuhu Shukla.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\nCo-authored-by: Kuhu Shukla \u003ckshukla@apache.org\u003e\n",
      "commitDate": "29/08/19 10:10 AM",
      "commitName": "f600fbb6c4987c69292faea6b5abf022bb213ffd",
      "commitAuthor": "He Xiaoqiao",
      "commitDateOld": "27/08/19 3:26 PM",
      "commitNameOld": "dde9399b37bffb77da17c025f0b9b673d7088bc6",
      "commitAuthorOld": "He Xiaoqiao",
      "daysBetweenCommits": 1.78,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   DatanodeStorageReport[] getDatanodeStorageReport(final DatanodeReportType type\n       ) throws IOException {\n     String operationName \u003d \"getDatanodeStorageReport\";\n     DatanodeStorageReport[] reports;\n     checkSuperuserPrivilege(operationName);\n     checkOperation(OperationCategory.UNCHECKED);\n     readLock();\n     try {\n       checkOperation(OperationCategory.UNCHECKED);\n       final DatanodeManager dm \u003d getBlockManager().getDatanodeManager();      \n       reports \u003d dm.getDatanodeStorageReport(type);\n     } finally {\n-      readUnlock(\"getDatanodeStorageReport\");\n+      readUnlock(operationName);\n     }\n     logAuditEvent(true, operationName, null);\n     return reports;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  DatanodeStorageReport[] getDatanodeStorageReport(final DatanodeReportType type\n      ) throws IOException {\n    String operationName \u003d \"getDatanodeStorageReport\";\n    DatanodeStorageReport[] reports;\n    checkSuperuserPrivilege(operationName);\n    checkOperation(OperationCategory.UNCHECKED);\n    readLock();\n    try {\n      checkOperation(OperationCategory.UNCHECKED);\n      final DatanodeManager dm \u003d getBlockManager().getDatanodeManager();      \n      reports \u003d dm.getDatanodeStorageReport(type);\n    } finally {\n      readUnlock(operationName);\n    }\n    logAuditEvent(true, operationName, null);\n    return reports;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12982 : [SPS]: Reduce the locking and cleanup the Namesystem access. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "78420719eb1f138c6f10558befb7bc8ebcc28a54",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,17 @@\n   DatanodeStorageReport[] getDatanodeStorageReport(final DatanodeReportType type\n       ) throws IOException {\n     String operationName \u003d \"getDatanodeStorageReport\";\n     DatanodeStorageReport[] reports;\n     checkSuperuserPrivilege(operationName);\n     checkOperation(OperationCategory.UNCHECKED);\n     readLock();\n     try {\n       checkOperation(OperationCategory.UNCHECKED);\n       final DatanodeManager dm \u003d getBlockManager().getDatanodeManager();      \n-      final List\u003cDatanodeDescriptor\u003e datanodes \u003d dm.getDatanodeListForReport(type);\n-\n-      reports \u003d new DatanodeStorageReport[datanodes.size()];\n-      for (int i \u003d 0; i \u003c reports.length; i++) {\n-        final DatanodeDescriptor d \u003d datanodes.get(i);\n-        reports[i] \u003d new DatanodeStorageReport(\n-            new DatanodeInfoBuilder().setFrom(d).build(),\n-            d.getStorageReports());\n-      }\n+      reports \u003d dm.getDatanodeStorageReport(type);\n     } finally {\n       readUnlock(\"getDatanodeStorageReport\");\n     }\n     logAuditEvent(true, operationName, null);\n     return reports;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  DatanodeStorageReport[] getDatanodeStorageReport(final DatanodeReportType type\n      ) throws IOException {\n    String operationName \u003d \"getDatanodeStorageReport\";\n    DatanodeStorageReport[] reports;\n    checkSuperuserPrivilege(operationName);\n    checkOperation(OperationCategory.UNCHECKED);\n    readLock();\n    try {\n      checkOperation(OperationCategory.UNCHECKED);\n      final DatanodeManager dm \u003d getBlockManager().getDatanodeManager();      \n      reports \u003d dm.getDatanodeStorageReport(type);\n    } finally {\n      readUnlock(\"getDatanodeStorageReport\");\n    }\n    logAuditEvent(true, operationName, null);\n    return reports;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "9d3e4cccf9cd0ffb60ee0e7c65cea5ae3c8015c2": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-5040.Audit log for admin commands/ logging output of all DFS admin commands. Contributed by Kuhu Shukla.\n",
      "commitDate": "26/09/17 9:29 AM",
      "commitName": "9d3e4cccf9cd0ffb60ee0e7c65cea5ae3c8015c2",
      "commitAuthor": "Brahma Reddy Battula",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-5040.Audit log for admin commands/ logging output of all DFS admin commands. Contributed by Kuhu Shukla.\n",
          "commitDate": "26/09/17 9:29 AM",
          "commitName": "9d3e4cccf9cd0ffb60ee0e7c65cea5ae3c8015c2",
          "commitAuthor": "Brahma Reddy Battula",
          "commitDateOld": "24/09/17 9:03 PM",
          "commitNameOld": "d0b2c5850b523a3888b2fadcfcdf6edbed33f221",
          "commitAuthorOld": "Anu Engineer",
          "daysBetweenCommits": 1.52,
          "commitsBetweenForRepo": 15,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,25 @@\n   DatanodeStorageReport[] getDatanodeStorageReport(final DatanodeReportType type\n-      ) throws AccessControlException, StandbyException {\n-    checkSuperuserPrivilege();\n+      ) throws IOException {\n+    String operationName \u003d \"getDatanodeStorageReport\";\n+    DatanodeStorageReport[] reports;\n+    checkSuperuserPrivilege(operationName);\n     checkOperation(OperationCategory.UNCHECKED);\n     readLock();\n     try {\n       checkOperation(OperationCategory.UNCHECKED);\n       final DatanodeManager dm \u003d getBlockManager().getDatanodeManager();      \n       final List\u003cDatanodeDescriptor\u003e datanodes \u003d dm.getDatanodeListForReport(type);\n \n-      DatanodeStorageReport[] reports \u003d new DatanodeStorageReport[datanodes.size()];\n+      reports \u003d new DatanodeStorageReport[datanodes.size()];\n       for (int i \u003d 0; i \u003c reports.length; i++) {\n         final DatanodeDescriptor d \u003d datanodes.get(i);\n         reports[i] \u003d new DatanodeStorageReport(\n             new DatanodeInfoBuilder().setFrom(d).build(),\n             d.getStorageReports());\n       }\n-      return reports;\n     } finally {\n       readUnlock(\"getDatanodeStorageReport\");\n     }\n+    logAuditEvent(true, operationName, null);\n+    return reports;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  DatanodeStorageReport[] getDatanodeStorageReport(final DatanodeReportType type\n      ) throws IOException {\n    String operationName \u003d \"getDatanodeStorageReport\";\n    DatanodeStorageReport[] reports;\n    checkSuperuserPrivilege(operationName);\n    checkOperation(OperationCategory.UNCHECKED);\n    readLock();\n    try {\n      checkOperation(OperationCategory.UNCHECKED);\n      final DatanodeManager dm \u003d getBlockManager().getDatanodeManager();      \n      final List\u003cDatanodeDescriptor\u003e datanodes \u003d dm.getDatanodeListForReport(type);\n\n      reports \u003d new DatanodeStorageReport[datanodes.size()];\n      for (int i \u003d 0; i \u003c reports.length; i++) {\n        final DatanodeDescriptor d \u003d datanodes.get(i);\n        reports[i] \u003d new DatanodeStorageReport(\n            new DatanodeInfoBuilder().setFrom(d).build(),\n            d.getStorageReports());\n      }\n    } finally {\n      readUnlock(\"getDatanodeStorageReport\");\n    }\n    logAuditEvent(true, operationName, null);\n    return reports;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[AccessControlException, StandbyException]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5040.Audit log for admin commands/ logging output of all DFS admin commands. Contributed by Kuhu Shukla.\n",
          "commitDate": "26/09/17 9:29 AM",
          "commitName": "9d3e4cccf9cd0ffb60ee0e7c65cea5ae3c8015c2",
          "commitAuthor": "Brahma Reddy Battula",
          "commitDateOld": "24/09/17 9:03 PM",
          "commitNameOld": "d0b2c5850b523a3888b2fadcfcdf6edbed33f221",
          "commitAuthorOld": "Anu Engineer",
          "daysBetweenCommits": 1.52,
          "commitsBetweenForRepo": 15,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,25 @@\n   DatanodeStorageReport[] getDatanodeStorageReport(final DatanodeReportType type\n-      ) throws AccessControlException, StandbyException {\n-    checkSuperuserPrivilege();\n+      ) throws IOException {\n+    String operationName \u003d \"getDatanodeStorageReport\";\n+    DatanodeStorageReport[] reports;\n+    checkSuperuserPrivilege(operationName);\n     checkOperation(OperationCategory.UNCHECKED);\n     readLock();\n     try {\n       checkOperation(OperationCategory.UNCHECKED);\n       final DatanodeManager dm \u003d getBlockManager().getDatanodeManager();      \n       final List\u003cDatanodeDescriptor\u003e datanodes \u003d dm.getDatanodeListForReport(type);\n \n-      DatanodeStorageReport[] reports \u003d new DatanodeStorageReport[datanodes.size()];\n+      reports \u003d new DatanodeStorageReport[datanodes.size()];\n       for (int i \u003d 0; i \u003c reports.length; i++) {\n         final DatanodeDescriptor d \u003d datanodes.get(i);\n         reports[i] \u003d new DatanodeStorageReport(\n             new DatanodeInfoBuilder().setFrom(d).build(),\n             d.getStorageReports());\n       }\n-      return reports;\n     } finally {\n       readUnlock(\"getDatanodeStorageReport\");\n     }\n+    logAuditEvent(true, operationName, null);\n+    return reports;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  DatanodeStorageReport[] getDatanodeStorageReport(final DatanodeReportType type\n      ) throws IOException {\n    String operationName \u003d \"getDatanodeStorageReport\";\n    DatanodeStorageReport[] reports;\n    checkSuperuserPrivilege(operationName);\n    checkOperation(OperationCategory.UNCHECKED);\n    readLock();\n    try {\n      checkOperation(OperationCategory.UNCHECKED);\n      final DatanodeManager dm \u003d getBlockManager().getDatanodeManager();      \n      final List\u003cDatanodeDescriptor\u003e datanodes \u003d dm.getDatanodeListForReport(type);\n\n      reports \u003d new DatanodeStorageReport[datanodes.size()];\n      for (int i \u003d 0; i \u003c reports.length; i++) {\n        final DatanodeDescriptor d \u003d datanodes.get(i);\n        reports[i] \u003d new DatanodeStorageReport(\n            new DatanodeInfoBuilder().setFrom(d).build(),\n            d.getStorageReports());\n      }\n    } finally {\n      readUnlock(\"getDatanodeStorageReport\");\n    }\n    logAuditEvent(true, operationName, null);\n    return reports;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10872. Add MutableRate metrics for FSNamesystemLock operations. Contributed by Erik Krogen.\n",
      "commitDate": "14/11/16 11:05 AM",
      "commitName": "ff0b99eafeda035ebe0dc82cfe689808047a8893",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "08/11/16 6:17 PM",
      "commitNameOld": "ed0bebabaaf27cd730f7f8eb002d92c9c7db327d",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 5.7,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   DatanodeStorageReport[] getDatanodeStorageReport(final DatanodeReportType type\n       ) throws AccessControlException, StandbyException {\n     checkSuperuserPrivilege();\n     checkOperation(OperationCategory.UNCHECKED);\n     readLock();\n     try {\n       checkOperation(OperationCategory.UNCHECKED);\n       final DatanodeManager dm \u003d getBlockManager().getDatanodeManager();      \n       final List\u003cDatanodeDescriptor\u003e datanodes \u003d dm.getDatanodeListForReport(type);\n \n       DatanodeStorageReport[] reports \u003d new DatanodeStorageReport[datanodes.size()];\n       for (int i \u003d 0; i \u003c reports.length; i++) {\n         final DatanodeDescriptor d \u003d datanodes.get(i);\n         reports[i] \u003d new DatanodeStorageReport(\n             new DatanodeInfoBuilder().setFrom(d).build(),\n             d.getStorageReports());\n       }\n       return reports;\n     } finally {\n-      readUnlock();\n+      readUnlock(\"getDatanodeStorageReport\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  DatanodeStorageReport[] getDatanodeStorageReport(final DatanodeReportType type\n      ) throws AccessControlException, StandbyException {\n    checkSuperuserPrivilege();\n    checkOperation(OperationCategory.UNCHECKED);\n    readLock();\n    try {\n      checkOperation(OperationCategory.UNCHECKED);\n      final DatanodeManager dm \u003d getBlockManager().getDatanodeManager();      \n      final List\u003cDatanodeDescriptor\u003e datanodes \u003d dm.getDatanodeListForReport(type);\n\n      DatanodeStorageReport[] reports \u003d new DatanodeStorageReport[datanodes.size()];\n      for (int i \u003d 0; i \u003c reports.length; i++) {\n        final DatanodeDescriptor d \u003d datanodes.get(i);\n        reports[i] \u003d new DatanodeStorageReport(\n            new DatanodeInfoBuilder().setFrom(d).build(),\n            d.getStorageReports());\n      }\n      return reports;\n    } finally {\n      readUnlock(\"getDatanodeStorageReport\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "ed0bebabaaf27cd730f7f8eb002d92c9c7db327d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9482. Replace DatanodeInfo constructors with a builder pattern. Contributed by Brahma Reddy Battula.\n",
      "commitDate": "08/11/16 6:17 PM",
      "commitName": "ed0bebabaaf27cd730f7f8eb002d92c9c7db327d",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "28/10/16 10:53 AM",
      "commitNameOld": "8a9388e5f6d622152798aaaa256064919e4fec37",
      "commitAuthorOld": "Mingliang Liu",
      "daysBetweenCommits": 11.35,
      "commitsBetweenForRepo": 111,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,22 @@\n   DatanodeStorageReport[] getDatanodeStorageReport(final DatanodeReportType type\n       ) throws AccessControlException, StandbyException {\n     checkSuperuserPrivilege();\n     checkOperation(OperationCategory.UNCHECKED);\n     readLock();\n     try {\n       checkOperation(OperationCategory.UNCHECKED);\n       final DatanodeManager dm \u003d getBlockManager().getDatanodeManager();      \n       final List\u003cDatanodeDescriptor\u003e datanodes \u003d dm.getDatanodeListForReport(type);\n \n       DatanodeStorageReport[] reports \u003d new DatanodeStorageReport[datanodes.size()];\n       for (int i \u003d 0; i \u003c reports.length; i++) {\n         final DatanodeDescriptor d \u003d datanodes.get(i);\n-        reports[i] \u003d new DatanodeStorageReport(new DatanodeInfo(d),\n+        reports[i] \u003d new DatanodeStorageReport(\n+            new DatanodeInfoBuilder().setFrom(d).build(),\n             d.getStorageReports());\n       }\n       return reports;\n     } finally {\n       readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  DatanodeStorageReport[] getDatanodeStorageReport(final DatanodeReportType type\n      ) throws AccessControlException, StandbyException {\n    checkSuperuserPrivilege();\n    checkOperation(OperationCategory.UNCHECKED);\n    readLock();\n    try {\n      checkOperation(OperationCategory.UNCHECKED);\n      final DatanodeManager dm \u003d getBlockManager().getDatanodeManager();      \n      final List\u003cDatanodeDescriptor\u003e datanodes \u003d dm.getDatanodeListForReport(type);\n\n      DatanodeStorageReport[] reports \u003d new DatanodeStorageReport[datanodes.size()];\n      for (int i \u003d 0; i \u003c reports.length; i++) {\n        final DatanodeDescriptor d \u003d datanodes.get(i);\n        reports[i] \u003d new DatanodeStorageReport(\n            new DatanodeInfoBuilder().setFrom(d).build(),\n            d.getStorageReports());\n      }\n      return reports;\n    } finally {\n      readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    }
  }
}