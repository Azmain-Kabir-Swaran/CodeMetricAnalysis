{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PBImageTextWriter.java",
  "functionName": "visit",
  "functionId": "visit___file-RandomAccessFile",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageTextWriter.java",
  "functionStartLine": 563,
  "functionEndLine": 625,
  "numCommitsSeen": 9,
  "timeTaken": 1731,
  "changeHistory": [
    "177131793a88960b734038f6e646476d568c3626",
    "9d494f0c0eaa05417f3a3e88487d878d1731da36",
    "caf7298e49f646a40023af999f62d61846fde5e2"
  ],
  "changeHistoryShort": {
    "177131793a88960b734038f6e646476d568c3626": "Ybodychange",
    "9d494f0c0eaa05417f3a3e88487d878d1731da36": "Ybodychange",
    "caf7298e49f646a40023af999f62d61846fde5e2": "Yintroduced"
  },
  "changeHistoryDetails": {
    "177131793a88960b734038f6e646476d568c3626": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14172. Avoid NPE when SectionName#fromString returns null. Contributed by Xiang Li.\n",
      "commitDate": "08/02/19 4:51 AM",
      "commitName": "177131793a88960b734038f6e646476d568c3626",
      "commitAuthor": "Yiqun Lin",
      "commitDateOld": "03/12/18 10:34 AM",
      "commitNameOld": "fb10803dfa67394650072bdea327296f8ad2a744",
      "commitAuthorOld": "Adam Antal",
      "daysBetweenCommits": 66.76,
      "commitsBetweenForRepo": 438,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,59 +1,63 @@\n   public void visit(RandomAccessFile file) throws IOException {\n     Configuration conf \u003d new Configuration();\n     if (!FSImageUtil.checkFileFormat(file)) {\n       throw new IOException(\"Unrecognized FSImage\");\n     }\n \n     FileSummary summary \u003d FSImageUtil.loadSummary(file);\n \n     try (FileInputStream fin \u003d new FileInputStream(file.getFD())) {\n       InputStream is;\n       ArrayList\u003cFileSummary.Section\u003e sections \u003d\n           Lists.newArrayList(summary.getSectionsList());\n       Collections.sort(sections,\n           new Comparator\u003cFileSummary.Section\u003e() {\n             @Override\n             public int compare(FsImageProto.FileSummary.Section s1,\n                 FsImageProto.FileSummary.Section s2) {\n               FSImageFormatProtobuf.SectionName n1 \u003d\n                   FSImageFormatProtobuf.SectionName.fromString(s1.getName());\n               FSImageFormatProtobuf.SectionName n2 \u003d\n                   FSImageFormatProtobuf.SectionName.fromString(s2.getName());\n               if (n1 \u003d\u003d null) {\n                 return n2 \u003d\u003d null ? 0 : -1;\n               } else if (n2 \u003d\u003d null) {\n                 return -1;\n               } else {\n                 return n1.ordinal() - n2.ordinal();\n               }\n             }\n           });\n \n       ImmutableList\u003cLong\u003e refIdList \u003d null;\n       for (FileSummary.Section section : sections) {\n         fin.getChannel().position(section.getOffset());\n         is \u003d FSImageUtil.wrapInputStreamForCompression(conf,\n             summary.getCodec(), new BufferedInputStream(new LimitInputStream(\n                 fin, section.getLength())));\n-        switch (SectionName.fromString(section.getName())) {\n+        SectionName sectionName \u003d SectionName.fromString(section.getName());\n+        if (sectionName \u003d\u003d null) {\n+          throw new IOException(\"Unrecognized section \" + section.getName());\n+        }\n+        switch (sectionName) {\n         case STRING_TABLE:\n           LOG.info(\"Loading string table\");\n           stringTable \u003d FSImageLoader.loadStringTable(is);\n           break;\n         case INODE_REFERENCE:\n           // Load INodeReference so that all INodes can be processed.\n           // Snapshots are not handled and will just be ignored for now.\n           LOG.info(\"Loading inode references\");\n           refIdList \u003d FSImageLoader.loadINodeReferenceSection(is);\n           break;\n         default:\n           break;\n         }\n       }\n \n       loadDirectories(fin, sections, summary, conf);\n       loadINodeDirSection(fin, sections, summary, conf, refIdList);\n       metadataMap.sync();\n       output(conf, summary, fin, sections);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void visit(RandomAccessFile file) throws IOException {\n    Configuration conf \u003d new Configuration();\n    if (!FSImageUtil.checkFileFormat(file)) {\n      throw new IOException(\"Unrecognized FSImage\");\n    }\n\n    FileSummary summary \u003d FSImageUtil.loadSummary(file);\n\n    try (FileInputStream fin \u003d new FileInputStream(file.getFD())) {\n      InputStream is;\n      ArrayList\u003cFileSummary.Section\u003e sections \u003d\n          Lists.newArrayList(summary.getSectionsList());\n      Collections.sort(sections,\n          new Comparator\u003cFileSummary.Section\u003e() {\n            @Override\n            public int compare(FsImageProto.FileSummary.Section s1,\n                FsImageProto.FileSummary.Section s2) {\n              FSImageFormatProtobuf.SectionName n1 \u003d\n                  FSImageFormatProtobuf.SectionName.fromString(s1.getName());\n              FSImageFormatProtobuf.SectionName n2 \u003d\n                  FSImageFormatProtobuf.SectionName.fromString(s2.getName());\n              if (n1 \u003d\u003d null) {\n                return n2 \u003d\u003d null ? 0 : -1;\n              } else if (n2 \u003d\u003d null) {\n                return -1;\n              } else {\n                return n1.ordinal() - n2.ordinal();\n              }\n            }\n          });\n\n      ImmutableList\u003cLong\u003e refIdList \u003d null;\n      for (FileSummary.Section section : sections) {\n        fin.getChannel().position(section.getOffset());\n        is \u003d FSImageUtil.wrapInputStreamForCompression(conf,\n            summary.getCodec(), new BufferedInputStream(new LimitInputStream(\n                fin, section.getLength())));\n        SectionName sectionName \u003d SectionName.fromString(section.getName());\n        if (sectionName \u003d\u003d null) {\n          throw new IOException(\"Unrecognized section \" + section.getName());\n        }\n        switch (sectionName) {\n        case STRING_TABLE:\n          LOG.info(\"Loading string table\");\n          stringTable \u003d FSImageLoader.loadStringTable(is);\n          break;\n        case INODE_REFERENCE:\n          // Load INodeReference so that all INodes can be processed.\n          // Snapshots are not handled and will just be ignored for now.\n          LOG.info(\"Loading inode references\");\n          refIdList \u003d FSImageLoader.loadINodeReferenceSection(is);\n          break;\n        default:\n          break;\n        }\n      }\n\n      loadDirectories(fin, sections, summary, conf);\n      loadINodeDirSection(fin, sections, summary, conf, refIdList);\n      metadataMap.sync();\n      output(conf, summary, fin, sections);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageTextWriter.java",
      "extendedDetails": {}
    },
    "9d494f0c0eaa05417f3a3e88487d878d1731da36": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9721. Allow Delimited PB OIV tool to run upon fsimage that contains INodeReference. (Xiao Chen via lei)\n",
      "commitDate": "02/02/16 10:42 AM",
      "commitName": "9d494f0c0eaa05417f3a3e88487d878d1731da36",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "07/04/15 2:23 PM",
      "commitNameOld": "1e72d98c69bef3526cf0eb617de69e0b6d2fc13c",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 300.89,
      "commitsBetweenForRepo": 2355,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,59 @@\n   public void visit(RandomAccessFile file) throws IOException {\n     Configuration conf \u003d new Configuration();\n     if (!FSImageUtil.checkFileFormat(file)) {\n       throw new IOException(\"Unrecognized FSImage\");\n     }\n \n     FileSummary summary \u003d FSImageUtil.loadSummary(file);\n \n     try (FileInputStream fin \u003d new FileInputStream(file.getFD())) {\n       InputStream is;\n       ArrayList\u003cFileSummary.Section\u003e sections \u003d\n           Lists.newArrayList(summary.getSectionsList());\n       Collections.sort(sections,\n           new Comparator\u003cFileSummary.Section\u003e() {\n             @Override\n             public int compare(FsImageProto.FileSummary.Section s1,\n                 FsImageProto.FileSummary.Section s2) {\n               FSImageFormatProtobuf.SectionName n1 \u003d\n                   FSImageFormatProtobuf.SectionName.fromString(s1.getName());\n               FSImageFormatProtobuf.SectionName n2 \u003d\n                   FSImageFormatProtobuf.SectionName.fromString(s2.getName());\n               if (n1 \u003d\u003d null) {\n                 return n2 \u003d\u003d null ? 0 : -1;\n               } else if (n2 \u003d\u003d null) {\n                 return -1;\n               } else {\n                 return n1.ordinal() - n2.ordinal();\n               }\n             }\n           });\n \n+      ImmutableList\u003cLong\u003e refIdList \u003d null;\n       for (FileSummary.Section section : sections) {\n         fin.getChannel().position(section.getOffset());\n         is \u003d FSImageUtil.wrapInputStreamForCompression(conf,\n             summary.getCodec(), new BufferedInputStream(new LimitInputStream(\n                 fin, section.getLength())));\n         switch (SectionName.fromString(section.getName())) {\n         case STRING_TABLE:\n+          LOG.info(\"Loading string table\");\n           stringTable \u003d FSImageLoader.loadStringTable(is);\n           break;\n+        case INODE_REFERENCE:\n+          // Load INodeReference so that all INodes can be processed.\n+          // Snapshots are not handled and will just be ignored for now.\n+          LOG.info(\"Loading inode references\");\n+          refIdList \u003d FSImageLoader.loadINodeReferenceSection(is);\n+          break;\n         default:\n           break;\n         }\n       }\n \n       loadDirectories(fin, sections, summary, conf);\n-      loadINodeDirSection(fin, sections, summary, conf);\n+      loadINodeDirSection(fin, sections, summary, conf, refIdList);\n       metadataMap.sync();\n       output(conf, summary, fin, sections);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void visit(RandomAccessFile file) throws IOException {\n    Configuration conf \u003d new Configuration();\n    if (!FSImageUtil.checkFileFormat(file)) {\n      throw new IOException(\"Unrecognized FSImage\");\n    }\n\n    FileSummary summary \u003d FSImageUtil.loadSummary(file);\n\n    try (FileInputStream fin \u003d new FileInputStream(file.getFD())) {\n      InputStream is;\n      ArrayList\u003cFileSummary.Section\u003e sections \u003d\n          Lists.newArrayList(summary.getSectionsList());\n      Collections.sort(sections,\n          new Comparator\u003cFileSummary.Section\u003e() {\n            @Override\n            public int compare(FsImageProto.FileSummary.Section s1,\n                FsImageProto.FileSummary.Section s2) {\n              FSImageFormatProtobuf.SectionName n1 \u003d\n                  FSImageFormatProtobuf.SectionName.fromString(s1.getName());\n              FSImageFormatProtobuf.SectionName n2 \u003d\n                  FSImageFormatProtobuf.SectionName.fromString(s2.getName());\n              if (n1 \u003d\u003d null) {\n                return n2 \u003d\u003d null ? 0 : -1;\n              } else if (n2 \u003d\u003d null) {\n                return -1;\n              } else {\n                return n1.ordinal() - n2.ordinal();\n              }\n            }\n          });\n\n      ImmutableList\u003cLong\u003e refIdList \u003d null;\n      for (FileSummary.Section section : sections) {\n        fin.getChannel().position(section.getOffset());\n        is \u003d FSImageUtil.wrapInputStreamForCompression(conf,\n            summary.getCodec(), new BufferedInputStream(new LimitInputStream(\n                fin, section.getLength())));\n        switch (SectionName.fromString(section.getName())) {\n        case STRING_TABLE:\n          LOG.info(\"Loading string table\");\n          stringTable \u003d FSImageLoader.loadStringTable(is);\n          break;\n        case INODE_REFERENCE:\n          // Load INodeReference so that all INodes can be processed.\n          // Snapshots are not handled and will just be ignored for now.\n          LOG.info(\"Loading inode references\");\n          refIdList \u003d FSImageLoader.loadINodeReferenceSection(is);\n          break;\n        default:\n          break;\n        }\n      }\n\n      loadDirectories(fin, sections, summary, conf);\n      loadINodeDirSection(fin, sections, summary, conf, refIdList);\n      metadataMap.sync();\n      output(conf, summary, fin, sections);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageTextWriter.java",
      "extendedDetails": {}
    },
    "caf7298e49f646a40023af999f62d61846fde5e2": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6673. Add delimited format support to PB OIV tool. Contributed by Eddy Xu.\n",
      "commitDate": "28/01/15 12:36 PM",
      "commitName": "caf7298e49f646a40023af999f62d61846fde5e2",
      "commitAuthor": "Andrew Wang",
      "diff": "@@ -0,0 +1,51 @@\n+  public void visit(RandomAccessFile file) throws IOException {\n+    Configuration conf \u003d new Configuration();\n+    if (!FSImageUtil.checkFileFormat(file)) {\n+      throw new IOException(\"Unrecognized FSImage\");\n+    }\n+\n+    FileSummary summary \u003d FSImageUtil.loadSummary(file);\n+\n+    try (FileInputStream fin \u003d new FileInputStream(file.getFD())) {\n+      InputStream is;\n+      ArrayList\u003cFileSummary.Section\u003e sections \u003d\n+          Lists.newArrayList(summary.getSectionsList());\n+      Collections.sort(sections,\n+          new Comparator\u003cFileSummary.Section\u003e() {\n+            @Override\n+            public int compare(FsImageProto.FileSummary.Section s1,\n+                FsImageProto.FileSummary.Section s2) {\n+              FSImageFormatProtobuf.SectionName n1 \u003d\n+                  FSImageFormatProtobuf.SectionName.fromString(s1.getName());\n+              FSImageFormatProtobuf.SectionName n2 \u003d\n+                  FSImageFormatProtobuf.SectionName.fromString(s2.getName());\n+              if (n1 \u003d\u003d null) {\n+                return n2 \u003d\u003d null ? 0 : -1;\n+              } else if (n2 \u003d\u003d null) {\n+                return -1;\n+              } else {\n+                return n1.ordinal() - n2.ordinal();\n+              }\n+            }\n+          });\n+\n+      for (FileSummary.Section section : sections) {\n+        fin.getChannel().position(section.getOffset());\n+        is \u003d FSImageUtil.wrapInputStreamForCompression(conf,\n+            summary.getCodec(), new BufferedInputStream(new LimitInputStream(\n+                fin, section.getLength())));\n+        switch (SectionName.fromString(section.getName())) {\n+        case STRING_TABLE:\n+          stringTable \u003d FSImageLoader.loadStringTable(is);\n+          break;\n+        default:\n+          break;\n+        }\n+      }\n+\n+      loadDirectories(fin, sections, summary, conf);\n+      loadINodeDirSection(fin, sections, summary, conf);\n+      metadataMap.sync();\n+      output(conf, summary, fin, sections);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void visit(RandomAccessFile file) throws IOException {\n    Configuration conf \u003d new Configuration();\n    if (!FSImageUtil.checkFileFormat(file)) {\n      throw new IOException(\"Unrecognized FSImage\");\n    }\n\n    FileSummary summary \u003d FSImageUtil.loadSummary(file);\n\n    try (FileInputStream fin \u003d new FileInputStream(file.getFD())) {\n      InputStream is;\n      ArrayList\u003cFileSummary.Section\u003e sections \u003d\n          Lists.newArrayList(summary.getSectionsList());\n      Collections.sort(sections,\n          new Comparator\u003cFileSummary.Section\u003e() {\n            @Override\n            public int compare(FsImageProto.FileSummary.Section s1,\n                FsImageProto.FileSummary.Section s2) {\n              FSImageFormatProtobuf.SectionName n1 \u003d\n                  FSImageFormatProtobuf.SectionName.fromString(s1.getName());\n              FSImageFormatProtobuf.SectionName n2 \u003d\n                  FSImageFormatProtobuf.SectionName.fromString(s2.getName());\n              if (n1 \u003d\u003d null) {\n                return n2 \u003d\u003d null ? 0 : -1;\n              } else if (n2 \u003d\u003d null) {\n                return -1;\n              } else {\n                return n1.ordinal() - n2.ordinal();\n              }\n            }\n          });\n\n      for (FileSummary.Section section : sections) {\n        fin.getChannel().position(section.getOffset());\n        is \u003d FSImageUtil.wrapInputStreamForCompression(conf,\n            summary.getCodec(), new BufferedInputStream(new LimitInputStream(\n                fin, section.getLength())));\n        switch (SectionName.fromString(section.getName())) {\n        case STRING_TABLE:\n          stringTable \u003d FSImageLoader.loadStringTable(is);\n          break;\n        default:\n          break;\n        }\n      }\n\n      loadDirectories(fin, sections, summary, conf);\n      loadINodeDirSection(fin, sections, summary, conf);\n      metadataMap.sync();\n      output(conf, summary, fin, sections);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageTextWriter.java"
    }
  }
}