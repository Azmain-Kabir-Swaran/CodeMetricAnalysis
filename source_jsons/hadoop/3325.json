{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JsonUtilClient.java",
  "functionName": "toFileStatus",
  "functionId": "toFileStatus___json-Map__?,?__(modifiers-final)__includesType-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
  "functionStartLine": 118,
  "functionEndLine": 199,
  "numCommitsSeen": 99,
  "timeTaken": 10327,
  "changeHistory": [
    "074050ca595a81927c867951e48cef132a0284be",
    "a1de8cbac5fb9af403db2a02814575f0940d5f39",
    "8aa6c4f079fd38a3230bc070c2ce837fefbc5301",
    "26c2a97c566969f50eb8e8432009724c51152a98",
    "0fc988e6a3dc6b435cbeea680549c06ef6147e3f",
    "d55a84951abe87a31c17bd4b84cd309ed202e540",
    "12e44e7bdaf53d3720a89d32f0cc2717241bd6b2",
    "52b00600df921763725396ed92194d3338167655",
    "1d37a8812160bb030244a1e6b1c753f962d8d2ed",
    "91c81fdc24709b3caf1f6281c8879ffee08db956",
    "9da927540f0ea6698388a4e79ef32c4dc51495ea",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
    "5c97db07fb306842f49d73a67a90cecec19a7833",
    "76e7264e8d6407f527bd877009aca11f7bb63bd7",
    "ab04ff9efe632b4eca6faca7407ac35e00e6a379",
    "e2262d3d18c6d5c2aa20f96920104dc07271b869",
    "bb84f1fccb18c6c7373851e05d2451d55e908242",
    "073bbd805c6680f47bbfcc6e8efd708ad729bca4",
    "e3803d002c660f18a5c2ecf32344fd6f3f491a5b",
    "a7bcc9535860214380e235641d1d5d2dd15aee58",
    "9b250d74f029f8ccf3a613f9fb74f59838a66ec1",
    "2efea952139b30dd1c881eed0b443ffa72be6dce",
    "bdee397e95e98ece071345822e2e4d3f690f09c3",
    "65158e478f135ec051c1939bd5f371818365dffd",
    "4f68aa060090319b8de5c30f41d193632503ed17",
    "c6eaa8b37fe7749402d9da91bde23f90cd95b44a",
    "6ecf78a99b4b10d4c569cc2b335060ab988b8001",
    "567ab4335f8ded3c03bdb0ada59fef4da6a36289",
    "4525c4a25ba90163c9543116e2bd54239e0dd097",
    "94c631af1fc49f5ae5881fcd5f0e80b17308d15d",
    "6afe3e0d22caa2b0752d52ddf7794c25a66cc9c8",
    "676f488efffd50eb47e75cd750f9bc948b9e12fb",
    "1b1016beeb716bef8dad93bb2c7c4631a14b3d57",
    "4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de",
    "61d0b7530c8978c095ab6f62d9d38e168bd829c6"
  ],
  "changeHistoryShort": {
    "074050ca595a81927c867951e48cef132a0284be": "Ymultichange(Ymodifierchange,Ybodychange)",
    "a1de8cbac5fb9af403db2a02814575f0940d5f39": "Ybodychange",
    "8aa6c4f079fd38a3230bc070c2ce837fefbc5301": "Ybodychange",
    "26c2a97c566969f50eb8e8432009724c51152a98": "Ybodychange",
    "0fc988e6a3dc6b435cbeea680549c06ef6147e3f": "Ybodychange",
    "d55a84951abe87a31c17bd4b84cd309ed202e540": "Ybodychange",
    "12e44e7bdaf53d3720a89d32f0cc2717241bd6b2": "Ybodychange",
    "52b00600df921763725396ed92194d3338167655": "Ybodychange",
    "1d37a8812160bb030244a1e6b1c753f962d8d2ed": "Ybodychange",
    "91c81fdc24709b3caf1f6281c8879ffee08db956": "Ybodychange",
    "9da927540f0ea6698388a4e79ef32c4dc51495ea": "Ybodychange",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": "Ybodychange",
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": "Ymultichange(Yfilerename,Ybodychange)",
    "5c97db07fb306842f49d73a67a90cecec19a7833": "Ybodychange",
    "76e7264e8d6407f527bd877009aca11f7bb63bd7": "Ybodychange",
    "ab04ff9efe632b4eca6faca7407ac35e00e6a379": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange)",
    "e2262d3d18c6d5c2aa20f96920104dc07271b869": "Ybodychange",
    "bb84f1fccb18c6c7373851e05d2451d55e908242": "Ybodychange",
    "073bbd805c6680f47bbfcc6e8efd708ad729bca4": "Ybodychange",
    "e3803d002c660f18a5c2ecf32344fd6f3f491a5b": "Ybodychange",
    "a7bcc9535860214380e235641d1d5d2dd15aee58": "Ybodychange",
    "9b250d74f029f8ccf3a613f9fb74f59838a66ec1": "Ybodychange",
    "2efea952139b30dd1c881eed0b443ffa72be6dce": "Ybodychange",
    "bdee397e95e98ece071345822e2e4d3f690f09c3": "Ybodychange",
    "65158e478f135ec051c1939bd5f371818365dffd": "Ybodychange",
    "4f68aa060090319b8de5c30f41d193632503ed17": "Ybodychange",
    "c6eaa8b37fe7749402d9da91bde23f90cd95b44a": "Ybodychange",
    "6ecf78a99b4b10d4c569cc2b335060ab988b8001": "Ybodychange",
    "567ab4335f8ded3c03bdb0ada59fef4da6a36289": "Ybodychange",
    "4525c4a25ba90163c9543116e2bd54239e0dd097": "Ybodychange",
    "94c631af1fc49f5ae5881fcd5f0e80b17308d15d": "Ybodychange",
    "6afe3e0d22caa2b0752d52ddf7794c25a66cc9c8": "Ybodychange",
    "676f488efffd50eb47e75cd750f9bc948b9e12fb": "Ymultichange(Yparameterchange,Ybodychange)",
    "1b1016beeb716bef8dad93bb2c7c4631a14b3d57": "Ymultichange(Yparameterchange,Ybodychange)",
    "4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de": "Ybodychange",
    "61d0b7530c8978c095ab6f62d9d38e168bd829c6": "Yintroduced"
  },
  "changeHistoryDetails": {
    "074050ca595a81927c867951e48cef132a0284be": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-15063. HttpFS: getFileStatus doesn\u0027t return ecPolicy. Contributed by hemanthboyina.\n",
      "commitDate": "31/12/19 6:26 PM",
      "commitName": "074050ca595a81927c867951e48cef132a0284be",
      "commitAuthor": "Takanobu Asanuma",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-15063. HttpFS: getFileStatus doesn\u0027t return ecPolicy. Contributed by hemanthboyina.\n",
          "commitDate": "31/12/19 6:26 PM",
          "commitName": "074050ca595a81927c867951e48cef132a0284be",
          "commitAuthor": "Takanobu Asanuma",
          "commitDateOld": "01/08/19 5:15 PM",
          "commitNameOld": "17e8cf501b384af93726e4f2e6f5e28c6e3a8f65",
          "commitAuthorOld": "Siyao Meng",
          "daysBetweenCommits": 152.09,
          "commitsBetweenForRepo": 928,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,81 +1,82 @@\n-  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n+  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n       boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final WebHdfsConstants.PathType type \u003d\n         WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n         : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String)m.get(\"permission\"));\n \n     Boolean aclBit \u003d (Boolean) m.get(\"aclBit\");\n     Boolean encBit \u003d (Boolean) m.get(\"encBit\");\n     Boolean erasureBit  \u003d (Boolean) m.get(\"ecBit\");\n     Boolean snapshotEnabledBit  \u003d (Boolean) m.get(\"snapshotEnabled\");\n     EnumSet\u003cHdfsFileStatus.Flags\u003e f \u003d\n         EnumSet.noneOf(HdfsFileStatus.Flags.class);\n     if (aclBit !\u003d null \u0026\u0026 aclBit) {\n       f.add(HdfsFileStatus.Flags.HAS_ACL);\n     }\n     if (encBit !\u003d null \u0026\u0026 encBit) {\n       f.add(HdfsFileStatus.Flags.HAS_CRYPT);\n     }\n     if (erasureBit !\u003d null \u0026\u0026 erasureBit) {\n       f.add(HdfsFileStatus.Flags.HAS_EC);\n     }\n     if (snapshotEnabledBit !\u003d null \u0026\u0026 snapshotEnabledBit) {\n       f.add(HdfsFileStatus.Flags.SNAPSHOT_ENABLED);\n     }\n \n     Map\u003cString, Object\u003e ecPolicyObj \u003d (Map) m.get(\"ecPolicyObj\");\n     ErasureCodingPolicy ecPolicy \u003d null;\n     if (ecPolicyObj !\u003d null) {\n       Map\u003cString, String\u003e extraOptions \u003d (Map) ecPolicyObj.get(\"extraOptions\");\n       ECSchema ecSchema \u003d new ECSchema((String) ecPolicyObj.get(\"codecName\"),\n-          (int) ecPolicyObj.get(\"numDataUnits\"),\n-          (int) ecPolicyObj.get(\"numParityUnits\"), extraOptions);\n+          (int) ((Number) ecPolicyObj.get(\"numDataUnits\")).longValue(),\n+          (int) ((Number) ecPolicyObj.get(\"numParityUnits\")).longValue(),\n+          extraOptions);\n       ecPolicy \u003d new ErasureCodingPolicy((String) ecPolicyObj.get(\"name\"),\n-          ecSchema, (int) ecPolicyObj.get(\"cellSize\"),\n-          (byte) (int) ecPolicyObj.get(\"id\"));\n+          ecSchema, (int) ((Number) ecPolicyObj.get(\"cellSize\")).longValue(),\n+          (byte) (int) ((Number) ecPolicyObj.get(\"id\")).longValue());\n \n     }\n \n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() :\n         HdfsConstants.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n     return new HdfsFileStatus.Builder()\n       .length(len)\n       .isdir(type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY)\n       .replication(replication)\n       .blocksize(blockSize)\n       .mtime(mTime)\n       .atime(aTime)\n       .perm(permission)\n       .flags(f)\n       .owner(owner)\n       .group(group)\n       .symlink(symlink)\n       .path(DFSUtilClient.string2Bytes(localName))\n       .fileId(fileId)\n       .children(childrenNum)\n       .storagePolicy(storagePolicy)\n       .ecPolicy(ecPolicy)\n       .build();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n      boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d\n        WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String)m.get(\"permission\"));\n\n    Boolean aclBit \u003d (Boolean) m.get(\"aclBit\");\n    Boolean encBit \u003d (Boolean) m.get(\"encBit\");\n    Boolean erasureBit  \u003d (Boolean) m.get(\"ecBit\");\n    Boolean snapshotEnabledBit  \u003d (Boolean) m.get(\"snapshotEnabled\");\n    EnumSet\u003cHdfsFileStatus.Flags\u003e f \u003d\n        EnumSet.noneOf(HdfsFileStatus.Flags.class);\n    if (aclBit !\u003d null \u0026\u0026 aclBit) {\n      f.add(HdfsFileStatus.Flags.HAS_ACL);\n    }\n    if (encBit !\u003d null \u0026\u0026 encBit) {\n      f.add(HdfsFileStatus.Flags.HAS_CRYPT);\n    }\n    if (erasureBit !\u003d null \u0026\u0026 erasureBit) {\n      f.add(HdfsFileStatus.Flags.HAS_EC);\n    }\n    if (snapshotEnabledBit !\u003d null \u0026\u0026 snapshotEnabledBit) {\n      f.add(HdfsFileStatus.Flags.SNAPSHOT_ENABLED);\n    }\n\n    Map\u003cString, Object\u003e ecPolicyObj \u003d (Map) m.get(\"ecPolicyObj\");\n    ErasureCodingPolicy ecPolicy \u003d null;\n    if (ecPolicyObj !\u003d null) {\n      Map\u003cString, String\u003e extraOptions \u003d (Map) ecPolicyObj.get(\"extraOptions\");\n      ECSchema ecSchema \u003d new ECSchema((String) ecPolicyObj.get(\"codecName\"),\n          (int) ((Number) ecPolicyObj.get(\"numDataUnits\")).longValue(),\n          (int) ((Number) ecPolicyObj.get(\"numParityUnits\")).longValue(),\n          extraOptions);\n      ecPolicy \u003d new ErasureCodingPolicy((String) ecPolicyObj.get(\"name\"),\n          ecSchema, (int) ((Number) ecPolicyObj.get(\"cellSize\")).longValue(),\n          (byte) (int) ((Number) ecPolicyObj.get(\"id\")).longValue());\n\n    }\n\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() :\n        HdfsConstants.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n    return new HdfsFileStatus.Builder()\n      .length(len)\n      .isdir(type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY)\n      .replication(replication)\n      .blocksize(blockSize)\n      .mtime(mTime)\n      .atime(aTime)\n      .perm(permission)\n      .flags(f)\n      .owner(owner)\n      .group(group)\n      .symlink(symlink)\n      .path(DFSUtilClient.string2Bytes(localName))\n      .fileId(fileId)\n      .children(childrenNum)\n      .storagePolicy(storagePolicy)\n      .ecPolicy(ecPolicy)\n      .build();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
          "extendedDetails": {
            "oldValue": "[static]",
            "newValue": "[public, static]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-15063. HttpFS: getFileStatus doesn\u0027t return ecPolicy. Contributed by hemanthboyina.\n",
          "commitDate": "31/12/19 6:26 PM",
          "commitName": "074050ca595a81927c867951e48cef132a0284be",
          "commitAuthor": "Takanobu Asanuma",
          "commitDateOld": "01/08/19 5:15 PM",
          "commitNameOld": "17e8cf501b384af93726e4f2e6f5e28c6e3a8f65",
          "commitAuthorOld": "Siyao Meng",
          "daysBetweenCommits": 152.09,
          "commitsBetweenForRepo": 928,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,81 +1,82 @@\n-  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n+  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n       boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final WebHdfsConstants.PathType type \u003d\n         WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n         : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String)m.get(\"permission\"));\n \n     Boolean aclBit \u003d (Boolean) m.get(\"aclBit\");\n     Boolean encBit \u003d (Boolean) m.get(\"encBit\");\n     Boolean erasureBit  \u003d (Boolean) m.get(\"ecBit\");\n     Boolean snapshotEnabledBit  \u003d (Boolean) m.get(\"snapshotEnabled\");\n     EnumSet\u003cHdfsFileStatus.Flags\u003e f \u003d\n         EnumSet.noneOf(HdfsFileStatus.Flags.class);\n     if (aclBit !\u003d null \u0026\u0026 aclBit) {\n       f.add(HdfsFileStatus.Flags.HAS_ACL);\n     }\n     if (encBit !\u003d null \u0026\u0026 encBit) {\n       f.add(HdfsFileStatus.Flags.HAS_CRYPT);\n     }\n     if (erasureBit !\u003d null \u0026\u0026 erasureBit) {\n       f.add(HdfsFileStatus.Flags.HAS_EC);\n     }\n     if (snapshotEnabledBit !\u003d null \u0026\u0026 snapshotEnabledBit) {\n       f.add(HdfsFileStatus.Flags.SNAPSHOT_ENABLED);\n     }\n \n     Map\u003cString, Object\u003e ecPolicyObj \u003d (Map) m.get(\"ecPolicyObj\");\n     ErasureCodingPolicy ecPolicy \u003d null;\n     if (ecPolicyObj !\u003d null) {\n       Map\u003cString, String\u003e extraOptions \u003d (Map) ecPolicyObj.get(\"extraOptions\");\n       ECSchema ecSchema \u003d new ECSchema((String) ecPolicyObj.get(\"codecName\"),\n-          (int) ecPolicyObj.get(\"numDataUnits\"),\n-          (int) ecPolicyObj.get(\"numParityUnits\"), extraOptions);\n+          (int) ((Number) ecPolicyObj.get(\"numDataUnits\")).longValue(),\n+          (int) ((Number) ecPolicyObj.get(\"numParityUnits\")).longValue(),\n+          extraOptions);\n       ecPolicy \u003d new ErasureCodingPolicy((String) ecPolicyObj.get(\"name\"),\n-          ecSchema, (int) ecPolicyObj.get(\"cellSize\"),\n-          (byte) (int) ecPolicyObj.get(\"id\"));\n+          ecSchema, (int) ((Number) ecPolicyObj.get(\"cellSize\")).longValue(),\n+          (byte) (int) ((Number) ecPolicyObj.get(\"id\")).longValue());\n \n     }\n \n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() :\n         HdfsConstants.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n     return new HdfsFileStatus.Builder()\n       .length(len)\n       .isdir(type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY)\n       .replication(replication)\n       .blocksize(blockSize)\n       .mtime(mTime)\n       .atime(aTime)\n       .perm(permission)\n       .flags(f)\n       .owner(owner)\n       .group(group)\n       .symlink(symlink)\n       .path(DFSUtilClient.string2Bytes(localName))\n       .fileId(fileId)\n       .children(childrenNum)\n       .storagePolicy(storagePolicy)\n       .ecPolicy(ecPolicy)\n       .build();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n      boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d\n        WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String)m.get(\"permission\"));\n\n    Boolean aclBit \u003d (Boolean) m.get(\"aclBit\");\n    Boolean encBit \u003d (Boolean) m.get(\"encBit\");\n    Boolean erasureBit  \u003d (Boolean) m.get(\"ecBit\");\n    Boolean snapshotEnabledBit  \u003d (Boolean) m.get(\"snapshotEnabled\");\n    EnumSet\u003cHdfsFileStatus.Flags\u003e f \u003d\n        EnumSet.noneOf(HdfsFileStatus.Flags.class);\n    if (aclBit !\u003d null \u0026\u0026 aclBit) {\n      f.add(HdfsFileStatus.Flags.HAS_ACL);\n    }\n    if (encBit !\u003d null \u0026\u0026 encBit) {\n      f.add(HdfsFileStatus.Flags.HAS_CRYPT);\n    }\n    if (erasureBit !\u003d null \u0026\u0026 erasureBit) {\n      f.add(HdfsFileStatus.Flags.HAS_EC);\n    }\n    if (snapshotEnabledBit !\u003d null \u0026\u0026 snapshotEnabledBit) {\n      f.add(HdfsFileStatus.Flags.SNAPSHOT_ENABLED);\n    }\n\n    Map\u003cString, Object\u003e ecPolicyObj \u003d (Map) m.get(\"ecPolicyObj\");\n    ErasureCodingPolicy ecPolicy \u003d null;\n    if (ecPolicyObj !\u003d null) {\n      Map\u003cString, String\u003e extraOptions \u003d (Map) ecPolicyObj.get(\"extraOptions\");\n      ECSchema ecSchema \u003d new ECSchema((String) ecPolicyObj.get(\"codecName\"),\n          (int) ((Number) ecPolicyObj.get(\"numDataUnits\")).longValue(),\n          (int) ((Number) ecPolicyObj.get(\"numParityUnits\")).longValue(),\n          extraOptions);\n      ecPolicy \u003d new ErasureCodingPolicy((String) ecPolicyObj.get(\"name\"),\n          ecSchema, (int) ((Number) ecPolicyObj.get(\"cellSize\")).longValue(),\n          (byte) (int) ((Number) ecPolicyObj.get(\"id\")).longValue());\n\n    }\n\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() :\n        HdfsConstants.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n    return new HdfsFileStatus.Builder()\n      .length(len)\n      .isdir(type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY)\n      .replication(replication)\n      .blocksize(blockSize)\n      .mtime(mTime)\n      .atime(aTime)\n      .perm(permission)\n      .flags(f)\n      .owner(owner)\n      .group(group)\n      .symlink(symlink)\n      .path(DFSUtilClient.string2Bytes(localName))\n      .fileId(fileId)\n      .children(childrenNum)\n      .storagePolicy(storagePolicy)\n      .ecPolicy(ecPolicy)\n      .build();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
          "extendedDetails": {}
        }
      ]
    },
    "a1de8cbac5fb9af403db2a02814575f0940d5f39": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13838. WebHdfsFileSystem.getFileStatus() won\u0027t return correct \"snapshot enabled\" status. Contributed by Siyao Meng.\n",
      "commitDate": "13/09/18 2:22 PM",
      "commitName": "a1de8cbac5fb9af403db2a02814575f0940d5f39",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "30/08/18 11:44 AM",
      "commitNameOld": "8aa6c4f079fd38a3230bc070c2ce837fefbc5301",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 14.11,
      "commitsBetweenForRepo": 126,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,81 @@\n   static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n       boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final WebHdfsConstants.PathType type \u003d\n         WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n         : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String)m.get(\"permission\"));\n \n     Boolean aclBit \u003d (Boolean) m.get(\"aclBit\");\n     Boolean encBit \u003d (Boolean) m.get(\"encBit\");\n     Boolean erasureBit  \u003d (Boolean) m.get(\"ecBit\");\n+    Boolean snapshotEnabledBit  \u003d (Boolean) m.get(\"snapshotEnabled\");\n     EnumSet\u003cHdfsFileStatus.Flags\u003e f \u003d\n         EnumSet.noneOf(HdfsFileStatus.Flags.class);\n     if (aclBit !\u003d null \u0026\u0026 aclBit) {\n       f.add(HdfsFileStatus.Flags.HAS_ACL);\n     }\n     if (encBit !\u003d null \u0026\u0026 encBit) {\n       f.add(HdfsFileStatus.Flags.HAS_CRYPT);\n     }\n     if (erasureBit !\u003d null \u0026\u0026 erasureBit) {\n       f.add(HdfsFileStatus.Flags.HAS_EC);\n     }\n+    if (snapshotEnabledBit !\u003d null \u0026\u0026 snapshotEnabledBit) {\n+      f.add(HdfsFileStatus.Flags.SNAPSHOT_ENABLED);\n+    }\n \n     Map\u003cString, Object\u003e ecPolicyObj \u003d (Map) m.get(\"ecPolicyObj\");\n     ErasureCodingPolicy ecPolicy \u003d null;\n     if (ecPolicyObj !\u003d null) {\n       Map\u003cString, String\u003e extraOptions \u003d (Map) ecPolicyObj.get(\"extraOptions\");\n       ECSchema ecSchema \u003d new ECSchema((String) ecPolicyObj.get(\"codecName\"),\n           (int) ecPolicyObj.get(\"numDataUnits\"),\n           (int) ecPolicyObj.get(\"numParityUnits\"), extraOptions);\n       ecPolicy \u003d new ErasureCodingPolicy((String) ecPolicyObj.get(\"name\"),\n           ecSchema, (int) ecPolicyObj.get(\"cellSize\"),\n           (byte) (int) ecPolicyObj.get(\"id\"));\n \n     }\n \n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() :\n         HdfsConstants.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n     return new HdfsFileStatus.Builder()\n       .length(len)\n       .isdir(type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY)\n       .replication(replication)\n       .blocksize(blockSize)\n       .mtime(mTime)\n       .atime(aTime)\n       .perm(permission)\n       .flags(f)\n       .owner(owner)\n       .group(group)\n       .symlink(symlink)\n       .path(DFSUtilClient.string2Bytes(localName))\n       .fileId(fileId)\n       .children(childrenNum)\n       .storagePolicy(storagePolicy)\n       .ecPolicy(ecPolicy)\n       .build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n      boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d\n        WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String)m.get(\"permission\"));\n\n    Boolean aclBit \u003d (Boolean) m.get(\"aclBit\");\n    Boolean encBit \u003d (Boolean) m.get(\"encBit\");\n    Boolean erasureBit  \u003d (Boolean) m.get(\"ecBit\");\n    Boolean snapshotEnabledBit  \u003d (Boolean) m.get(\"snapshotEnabled\");\n    EnumSet\u003cHdfsFileStatus.Flags\u003e f \u003d\n        EnumSet.noneOf(HdfsFileStatus.Flags.class);\n    if (aclBit !\u003d null \u0026\u0026 aclBit) {\n      f.add(HdfsFileStatus.Flags.HAS_ACL);\n    }\n    if (encBit !\u003d null \u0026\u0026 encBit) {\n      f.add(HdfsFileStatus.Flags.HAS_CRYPT);\n    }\n    if (erasureBit !\u003d null \u0026\u0026 erasureBit) {\n      f.add(HdfsFileStatus.Flags.HAS_EC);\n    }\n    if (snapshotEnabledBit !\u003d null \u0026\u0026 snapshotEnabledBit) {\n      f.add(HdfsFileStatus.Flags.SNAPSHOT_ENABLED);\n    }\n\n    Map\u003cString, Object\u003e ecPolicyObj \u003d (Map) m.get(\"ecPolicyObj\");\n    ErasureCodingPolicy ecPolicy \u003d null;\n    if (ecPolicyObj !\u003d null) {\n      Map\u003cString, String\u003e extraOptions \u003d (Map) ecPolicyObj.get(\"extraOptions\");\n      ECSchema ecSchema \u003d new ECSchema((String) ecPolicyObj.get(\"codecName\"),\n          (int) ecPolicyObj.get(\"numDataUnits\"),\n          (int) ecPolicyObj.get(\"numParityUnits\"), extraOptions);\n      ecPolicy \u003d new ErasureCodingPolicy((String) ecPolicyObj.get(\"name\"),\n          ecSchema, (int) ecPolicyObj.get(\"cellSize\"),\n          (byte) (int) ecPolicyObj.get(\"id\"));\n\n    }\n\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() :\n        HdfsConstants.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n    return new HdfsFileStatus.Builder()\n      .length(len)\n      .isdir(type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY)\n      .replication(replication)\n      .blocksize(blockSize)\n      .mtime(mTime)\n      .atime(aTime)\n      .perm(permission)\n      .flags(f)\n      .owner(owner)\n      .group(group)\n      .symlink(symlink)\n      .path(DFSUtilClient.string2Bytes(localName))\n      .fileId(fileId)\n      .children(childrenNum)\n      .storagePolicy(storagePolicy)\n      .ecPolicy(ecPolicy)\n      .build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
      "extendedDetails": {}
    },
    "8aa6c4f079fd38a3230bc070c2ce837fefbc5301": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-13838. WebHdfsFileSystem.getFileStatus() won\u0027t return correct \"snapshot enabled\" status. Contributed by Siyao Meng.\"\n\nThis reverts commit 26c2a97c566969f50eb8e8432009724c51152a98.\n",
      "commitDate": "30/08/18 11:44 AM",
      "commitName": "8aa6c4f079fd38a3230bc070c2ce837fefbc5301",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "27/08/18 4:02 PM",
      "commitNameOld": "26c2a97c566969f50eb8e8432009724c51152a98",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 2.82,
      "commitsBetweenForRepo": 28,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,81 +1,77 @@\n   static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n       boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final WebHdfsConstants.PathType type \u003d\n         WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n         : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String)m.get(\"permission\"));\n \n     Boolean aclBit \u003d (Boolean) m.get(\"aclBit\");\n     Boolean encBit \u003d (Boolean) m.get(\"encBit\");\n     Boolean erasureBit  \u003d (Boolean) m.get(\"ecBit\");\n-    Boolean snapshotEnabledBit  \u003d (Boolean) m.get(\"snapshotEnabled\");\n     EnumSet\u003cHdfsFileStatus.Flags\u003e f \u003d\n         EnumSet.noneOf(HdfsFileStatus.Flags.class);\n     if (aclBit !\u003d null \u0026\u0026 aclBit) {\n       f.add(HdfsFileStatus.Flags.HAS_ACL);\n     }\n     if (encBit !\u003d null \u0026\u0026 encBit) {\n       f.add(HdfsFileStatus.Flags.HAS_CRYPT);\n     }\n     if (erasureBit !\u003d null \u0026\u0026 erasureBit) {\n       f.add(HdfsFileStatus.Flags.HAS_EC);\n     }\n-    if (snapshotEnabledBit !\u003d null \u0026\u0026 snapshotEnabledBit) {\n-      f.add(HdfsFileStatus.Flags.SNAPSHOT_ENABLED);\n-    }\n \n     Map\u003cString, Object\u003e ecPolicyObj \u003d (Map) m.get(\"ecPolicyObj\");\n     ErasureCodingPolicy ecPolicy \u003d null;\n     if (ecPolicyObj !\u003d null) {\n       Map\u003cString, String\u003e extraOptions \u003d (Map) ecPolicyObj.get(\"extraOptions\");\n       ECSchema ecSchema \u003d new ECSchema((String) ecPolicyObj.get(\"codecName\"),\n           (int) ecPolicyObj.get(\"numDataUnits\"),\n           (int) ecPolicyObj.get(\"numParityUnits\"), extraOptions);\n       ecPolicy \u003d new ErasureCodingPolicy((String) ecPolicyObj.get(\"name\"),\n           ecSchema, (int) ecPolicyObj.get(\"cellSize\"),\n           (byte) (int) ecPolicyObj.get(\"id\"));\n \n     }\n \n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() :\n         HdfsConstants.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n     return new HdfsFileStatus.Builder()\n       .length(len)\n       .isdir(type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY)\n       .replication(replication)\n       .blocksize(blockSize)\n       .mtime(mTime)\n       .atime(aTime)\n       .perm(permission)\n       .flags(f)\n       .owner(owner)\n       .group(group)\n       .symlink(symlink)\n       .path(DFSUtilClient.string2Bytes(localName))\n       .fileId(fileId)\n       .children(childrenNum)\n       .storagePolicy(storagePolicy)\n       .ecPolicy(ecPolicy)\n       .build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n      boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d\n        WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String)m.get(\"permission\"));\n\n    Boolean aclBit \u003d (Boolean) m.get(\"aclBit\");\n    Boolean encBit \u003d (Boolean) m.get(\"encBit\");\n    Boolean erasureBit  \u003d (Boolean) m.get(\"ecBit\");\n    EnumSet\u003cHdfsFileStatus.Flags\u003e f \u003d\n        EnumSet.noneOf(HdfsFileStatus.Flags.class);\n    if (aclBit !\u003d null \u0026\u0026 aclBit) {\n      f.add(HdfsFileStatus.Flags.HAS_ACL);\n    }\n    if (encBit !\u003d null \u0026\u0026 encBit) {\n      f.add(HdfsFileStatus.Flags.HAS_CRYPT);\n    }\n    if (erasureBit !\u003d null \u0026\u0026 erasureBit) {\n      f.add(HdfsFileStatus.Flags.HAS_EC);\n    }\n\n    Map\u003cString, Object\u003e ecPolicyObj \u003d (Map) m.get(\"ecPolicyObj\");\n    ErasureCodingPolicy ecPolicy \u003d null;\n    if (ecPolicyObj !\u003d null) {\n      Map\u003cString, String\u003e extraOptions \u003d (Map) ecPolicyObj.get(\"extraOptions\");\n      ECSchema ecSchema \u003d new ECSchema((String) ecPolicyObj.get(\"codecName\"),\n          (int) ecPolicyObj.get(\"numDataUnits\"),\n          (int) ecPolicyObj.get(\"numParityUnits\"), extraOptions);\n      ecPolicy \u003d new ErasureCodingPolicy((String) ecPolicyObj.get(\"name\"),\n          ecSchema, (int) ecPolicyObj.get(\"cellSize\"),\n          (byte) (int) ecPolicyObj.get(\"id\"));\n\n    }\n\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() :\n        HdfsConstants.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n    return new HdfsFileStatus.Builder()\n      .length(len)\n      .isdir(type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY)\n      .replication(replication)\n      .blocksize(blockSize)\n      .mtime(mTime)\n      .atime(aTime)\n      .perm(permission)\n      .flags(f)\n      .owner(owner)\n      .group(group)\n      .symlink(symlink)\n      .path(DFSUtilClient.string2Bytes(localName))\n      .fileId(fileId)\n      .children(childrenNum)\n      .storagePolicy(storagePolicy)\n      .ecPolicy(ecPolicy)\n      .build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
      "extendedDetails": {}
    },
    "26c2a97c566969f50eb8e8432009724c51152a98": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13838. WebHdfsFileSystem.getFileStatus() won\u0027t return correct \"snapshot enabled\" status. Contributed by Siyao Meng.\n",
      "commitDate": "27/08/18 4:02 PM",
      "commitName": "26c2a97c566969f50eb8e8432009724c51152a98",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "16/05/18 11:28 AM",
      "commitNameOld": "0fc988e6a3dc6b435cbeea680549c06ef6147e3f",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 103.19,
      "commitsBetweenForRepo": 759,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,81 @@\n   static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n       boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final WebHdfsConstants.PathType type \u003d\n         WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n         : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String)m.get(\"permission\"));\n \n     Boolean aclBit \u003d (Boolean) m.get(\"aclBit\");\n     Boolean encBit \u003d (Boolean) m.get(\"encBit\");\n     Boolean erasureBit  \u003d (Boolean) m.get(\"ecBit\");\n+    Boolean snapshotEnabledBit  \u003d (Boolean) m.get(\"snapshotEnabled\");\n     EnumSet\u003cHdfsFileStatus.Flags\u003e f \u003d\n         EnumSet.noneOf(HdfsFileStatus.Flags.class);\n     if (aclBit !\u003d null \u0026\u0026 aclBit) {\n       f.add(HdfsFileStatus.Flags.HAS_ACL);\n     }\n     if (encBit !\u003d null \u0026\u0026 encBit) {\n       f.add(HdfsFileStatus.Flags.HAS_CRYPT);\n     }\n     if (erasureBit !\u003d null \u0026\u0026 erasureBit) {\n       f.add(HdfsFileStatus.Flags.HAS_EC);\n     }\n+    if (snapshotEnabledBit !\u003d null \u0026\u0026 snapshotEnabledBit) {\n+      f.add(HdfsFileStatus.Flags.SNAPSHOT_ENABLED);\n+    }\n \n     Map\u003cString, Object\u003e ecPolicyObj \u003d (Map) m.get(\"ecPolicyObj\");\n     ErasureCodingPolicy ecPolicy \u003d null;\n     if (ecPolicyObj !\u003d null) {\n       Map\u003cString, String\u003e extraOptions \u003d (Map) ecPolicyObj.get(\"extraOptions\");\n       ECSchema ecSchema \u003d new ECSchema((String) ecPolicyObj.get(\"codecName\"),\n           (int) ecPolicyObj.get(\"numDataUnits\"),\n           (int) ecPolicyObj.get(\"numParityUnits\"), extraOptions);\n       ecPolicy \u003d new ErasureCodingPolicy((String) ecPolicyObj.get(\"name\"),\n           ecSchema, (int) ecPolicyObj.get(\"cellSize\"),\n           (byte) (int) ecPolicyObj.get(\"id\"));\n \n     }\n \n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() :\n         HdfsConstants.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n     return new HdfsFileStatus.Builder()\n       .length(len)\n       .isdir(type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY)\n       .replication(replication)\n       .blocksize(blockSize)\n       .mtime(mTime)\n       .atime(aTime)\n       .perm(permission)\n       .flags(f)\n       .owner(owner)\n       .group(group)\n       .symlink(symlink)\n       .path(DFSUtilClient.string2Bytes(localName))\n       .fileId(fileId)\n       .children(childrenNum)\n       .storagePolicy(storagePolicy)\n       .ecPolicy(ecPolicy)\n       .build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n      boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d\n        WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String)m.get(\"permission\"));\n\n    Boolean aclBit \u003d (Boolean) m.get(\"aclBit\");\n    Boolean encBit \u003d (Boolean) m.get(\"encBit\");\n    Boolean erasureBit  \u003d (Boolean) m.get(\"ecBit\");\n    Boolean snapshotEnabledBit  \u003d (Boolean) m.get(\"snapshotEnabled\");\n    EnumSet\u003cHdfsFileStatus.Flags\u003e f \u003d\n        EnumSet.noneOf(HdfsFileStatus.Flags.class);\n    if (aclBit !\u003d null \u0026\u0026 aclBit) {\n      f.add(HdfsFileStatus.Flags.HAS_ACL);\n    }\n    if (encBit !\u003d null \u0026\u0026 encBit) {\n      f.add(HdfsFileStatus.Flags.HAS_CRYPT);\n    }\n    if (erasureBit !\u003d null \u0026\u0026 erasureBit) {\n      f.add(HdfsFileStatus.Flags.HAS_EC);\n    }\n    if (snapshotEnabledBit !\u003d null \u0026\u0026 snapshotEnabledBit) {\n      f.add(HdfsFileStatus.Flags.SNAPSHOT_ENABLED);\n    }\n\n    Map\u003cString, Object\u003e ecPolicyObj \u003d (Map) m.get(\"ecPolicyObj\");\n    ErasureCodingPolicy ecPolicy \u003d null;\n    if (ecPolicyObj !\u003d null) {\n      Map\u003cString, String\u003e extraOptions \u003d (Map) ecPolicyObj.get(\"extraOptions\");\n      ECSchema ecSchema \u003d new ECSchema((String) ecPolicyObj.get(\"codecName\"),\n          (int) ecPolicyObj.get(\"numDataUnits\"),\n          (int) ecPolicyObj.get(\"numParityUnits\"), extraOptions);\n      ecPolicy \u003d new ErasureCodingPolicy((String) ecPolicyObj.get(\"name\"),\n          ecSchema, (int) ecPolicyObj.get(\"cellSize\"),\n          (byte) (int) ecPolicyObj.get(\"id\"));\n\n    }\n\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() :\n        HdfsConstants.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n    return new HdfsFileStatus.Builder()\n      .length(len)\n      .isdir(type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY)\n      .replication(replication)\n      .blocksize(blockSize)\n      .mtime(mTime)\n      .atime(aTime)\n      .perm(permission)\n      .flags(f)\n      .owner(owner)\n      .group(group)\n      .symlink(symlink)\n      .path(DFSUtilClient.string2Bytes(localName))\n      .fileId(fileId)\n      .children(childrenNum)\n      .storagePolicy(storagePolicy)\n      .ecPolicy(ecPolicy)\n      .build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
      "extendedDetails": {}
    },
    "0fc988e6a3dc6b435cbeea680549c06ef6147e3f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13512. WebHdfs getFileStatus doesn\u0027t return ecPolicy. Contributed by Ajay Kumar.\n",
      "commitDate": "16/05/18 11:28 AM",
      "commitName": "0fc988e6a3dc6b435cbeea680549c06ef6147e3f",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "13/03/18 9:43 AM",
      "commitNameOld": "b2b9ce585984a1791a8af3e2287c75c75b95586f",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 64.07,
      "commitsBetweenForRepo": 1078,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,63 +1,77 @@\n   static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n       boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final WebHdfsConstants.PathType type \u003d\n         WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n         : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String)m.get(\"permission\"));\n \n     Boolean aclBit \u003d (Boolean) m.get(\"aclBit\");\n     Boolean encBit \u003d (Boolean) m.get(\"encBit\");\n     Boolean erasureBit  \u003d (Boolean) m.get(\"ecBit\");\n     EnumSet\u003cHdfsFileStatus.Flags\u003e f \u003d\n         EnumSet.noneOf(HdfsFileStatus.Flags.class);\n     if (aclBit !\u003d null \u0026\u0026 aclBit) {\n       f.add(HdfsFileStatus.Flags.HAS_ACL);\n     }\n     if (encBit !\u003d null \u0026\u0026 encBit) {\n       f.add(HdfsFileStatus.Flags.HAS_CRYPT);\n     }\n     if (erasureBit !\u003d null \u0026\u0026 erasureBit) {\n       f.add(HdfsFileStatus.Flags.HAS_EC);\n     }\n \n+    Map\u003cString, Object\u003e ecPolicyObj \u003d (Map) m.get(\"ecPolicyObj\");\n+    ErasureCodingPolicy ecPolicy \u003d null;\n+    if (ecPolicyObj !\u003d null) {\n+      Map\u003cString, String\u003e extraOptions \u003d (Map) ecPolicyObj.get(\"extraOptions\");\n+      ECSchema ecSchema \u003d new ECSchema((String) ecPolicyObj.get(\"codecName\"),\n+          (int) ecPolicyObj.get(\"numDataUnits\"),\n+          (int) ecPolicyObj.get(\"numParityUnits\"), extraOptions);\n+      ecPolicy \u003d new ErasureCodingPolicy((String) ecPolicyObj.get(\"name\"),\n+          ecSchema, (int) ecPolicyObj.get(\"cellSize\"),\n+          (byte) (int) ecPolicyObj.get(\"id\"));\n+\n+    }\n+\n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() :\n         HdfsConstants.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n     return new HdfsFileStatus.Builder()\n       .length(len)\n       .isdir(type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY)\n       .replication(replication)\n       .blocksize(blockSize)\n       .mtime(mTime)\n       .atime(aTime)\n       .perm(permission)\n       .flags(f)\n       .owner(owner)\n       .group(group)\n       .symlink(symlink)\n       .path(DFSUtilClient.string2Bytes(localName))\n       .fileId(fileId)\n       .children(childrenNum)\n       .storagePolicy(storagePolicy)\n+      .ecPolicy(ecPolicy)\n       .build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n      boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d\n        WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String)m.get(\"permission\"));\n\n    Boolean aclBit \u003d (Boolean) m.get(\"aclBit\");\n    Boolean encBit \u003d (Boolean) m.get(\"encBit\");\n    Boolean erasureBit  \u003d (Boolean) m.get(\"ecBit\");\n    EnumSet\u003cHdfsFileStatus.Flags\u003e f \u003d\n        EnumSet.noneOf(HdfsFileStatus.Flags.class);\n    if (aclBit !\u003d null \u0026\u0026 aclBit) {\n      f.add(HdfsFileStatus.Flags.HAS_ACL);\n    }\n    if (encBit !\u003d null \u0026\u0026 encBit) {\n      f.add(HdfsFileStatus.Flags.HAS_CRYPT);\n    }\n    if (erasureBit !\u003d null \u0026\u0026 erasureBit) {\n      f.add(HdfsFileStatus.Flags.HAS_EC);\n    }\n\n    Map\u003cString, Object\u003e ecPolicyObj \u003d (Map) m.get(\"ecPolicyObj\");\n    ErasureCodingPolicy ecPolicy \u003d null;\n    if (ecPolicyObj !\u003d null) {\n      Map\u003cString, String\u003e extraOptions \u003d (Map) ecPolicyObj.get(\"extraOptions\");\n      ECSchema ecSchema \u003d new ECSchema((String) ecPolicyObj.get(\"codecName\"),\n          (int) ecPolicyObj.get(\"numDataUnits\"),\n          (int) ecPolicyObj.get(\"numParityUnits\"), extraOptions);\n      ecPolicy \u003d new ErasureCodingPolicy((String) ecPolicyObj.get(\"name\"),\n          ecSchema, (int) ecPolicyObj.get(\"cellSize\"),\n          (byte) (int) ecPolicyObj.get(\"id\"));\n\n    }\n\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() :\n        HdfsConstants.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n    return new HdfsFileStatus.Builder()\n      .length(len)\n      .isdir(type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY)\n      .replication(replication)\n      .blocksize(blockSize)\n      .mtime(mTime)\n      .atime(aTime)\n      .perm(permission)\n      .flags(f)\n      .owner(owner)\n      .group(group)\n      .symlink(symlink)\n      .path(DFSUtilClient.string2Bytes(localName))\n      .fileId(fileId)\n      .children(childrenNum)\n      .storagePolicy(storagePolicy)\n      .ecPolicy(ecPolicy)\n      .build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
      "extendedDetails": {}
    },
    "d55a84951abe87a31c17bd4b84cd309ed202e540": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12582. Replace HdfsFileStatus constructor with a builder pattern. Contributed by Bharat Viswanadham\n",
      "commitDate": "27/10/17 3:36 PM",
      "commitName": "d55a84951abe87a31c17bd4b84cd309ed202e540",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "26/09/17 1:15 PM",
      "commitNameOld": "0da29cbeea40cb7839abcd72566b997962829329",
      "commitAuthorOld": "Daryn Sharp",
      "daysBetweenCommits": 31.1,
      "commitsBetweenForRepo": 222,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,63 @@\n   static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n       boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final WebHdfsConstants.PathType type \u003d\n         WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n         : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String)m.get(\"permission\"));\n \n     Boolean aclBit \u003d (Boolean) m.get(\"aclBit\");\n     Boolean encBit \u003d (Boolean) m.get(\"encBit\");\n     Boolean erasureBit  \u003d (Boolean) m.get(\"ecBit\");\n     EnumSet\u003cHdfsFileStatus.Flags\u003e f \u003d\n         EnumSet.noneOf(HdfsFileStatus.Flags.class);\n     if (aclBit !\u003d null \u0026\u0026 aclBit) {\n       f.add(HdfsFileStatus.Flags.HAS_ACL);\n     }\n     if (encBit !\u003d null \u0026\u0026 encBit) {\n       f.add(HdfsFileStatus.Flags.HAS_CRYPT);\n     }\n     if (erasureBit !\u003d null \u0026\u0026 erasureBit) {\n       f.add(HdfsFileStatus.Flags.HAS_EC);\n     }\n \n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() :\n         HdfsConstants.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n-    return new HdfsFileStatus(len,\n-        type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication, blockSize,\n-        mTime, aTime, permission, f, owner, group, symlink,\n-        DFSUtilClient.string2Bytes(localName), fileId, childrenNum,\n-        null, storagePolicy, null);\n+    return new HdfsFileStatus.Builder()\n+      .length(len)\n+      .isdir(type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY)\n+      .replication(replication)\n+      .blocksize(blockSize)\n+      .mtime(mTime)\n+      .atime(aTime)\n+      .perm(permission)\n+      .flags(f)\n+      .owner(owner)\n+      .group(group)\n+      .symlink(symlink)\n+      .path(DFSUtilClient.string2Bytes(localName))\n+      .fileId(fileId)\n+      .children(childrenNum)\n+      .storagePolicy(storagePolicy)\n+      .build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n      boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d\n        WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String)m.get(\"permission\"));\n\n    Boolean aclBit \u003d (Boolean) m.get(\"aclBit\");\n    Boolean encBit \u003d (Boolean) m.get(\"encBit\");\n    Boolean erasureBit  \u003d (Boolean) m.get(\"ecBit\");\n    EnumSet\u003cHdfsFileStatus.Flags\u003e f \u003d\n        EnumSet.noneOf(HdfsFileStatus.Flags.class);\n    if (aclBit !\u003d null \u0026\u0026 aclBit) {\n      f.add(HdfsFileStatus.Flags.HAS_ACL);\n    }\n    if (encBit !\u003d null \u0026\u0026 encBit) {\n      f.add(HdfsFileStatus.Flags.HAS_CRYPT);\n    }\n    if (erasureBit !\u003d null \u0026\u0026 erasureBit) {\n      f.add(HdfsFileStatus.Flags.HAS_EC);\n    }\n\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() :\n        HdfsConstants.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n    return new HdfsFileStatus.Builder()\n      .length(len)\n      .isdir(type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY)\n      .replication(replication)\n      .blocksize(blockSize)\n      .mtime(mTime)\n      .atime(aTime)\n      .perm(permission)\n      .flags(f)\n      .owner(owner)\n      .group(group)\n      .symlink(symlink)\n      .path(DFSUtilClient.string2Bytes(localName))\n      .fileId(fileId)\n      .children(childrenNum)\n      .storagePolicy(storagePolicy)\n      .build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
      "extendedDetails": {}
    },
    "12e44e7bdaf53d3720a89d32f0cc2717241bd6b2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6984. Serialize FileStatus via protobuf.\n",
      "commitDate": "02/08/17 12:12 PM",
      "commitName": "12e44e7bdaf53d3720a89d32f0cc2717241bd6b2",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "24/03/17 11:44 AM",
      "commitNameOld": "52b00600df921763725396ed92194d3338167655",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 131.02,
      "commitsBetweenForRepo": 741,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,51 @@\n   static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n       boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final WebHdfsConstants.PathType type \u003d\n         WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n         : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n-    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n-        (Boolean) m.get(\"aclBit\"),\n-        (Boolean) m.get(\"encBit\"),\n-        (Boolean) m.get(\"ecBit\"));\n+    final FsPermission permission \u003d toFsPermission((String)m.get(\"permission\"));\n+\n+    Boolean aclBit \u003d (Boolean) m.get(\"aclBit\");\n+    Boolean encBit \u003d (Boolean) m.get(\"encBit\");\n+    Boolean erasureBit  \u003d (Boolean) m.get(\"ecBit\");\n+    EnumSet\u003cHdfsFileStatus.Flags\u003e f \u003d\n+        EnumSet.noneOf(HdfsFileStatus.Flags.class);\n+    if (aclBit !\u003d null \u0026\u0026 aclBit) {\n+      f.add(HdfsFileStatus.Flags.HAS_ACL);\n+    }\n+    if (encBit !\u003d null \u0026\u0026 encBit) {\n+      f.add(HdfsFileStatus.Flags.HAS_CRYPT);\n+    }\n+    if (erasureBit !\u003d null \u0026\u0026 erasureBit) {\n+      f.add(HdfsFileStatus.Flags.HAS_EC);\n+    }\n+\n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() :\n         HdfsConstants.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n-    return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY,\n-        replication, blockSize, mTime, aTime, permission, owner, group,\n-        symlink, DFSUtilClient.string2Bytes(localName),\n-        fileId, childrenNum, null,\n-        storagePolicy, null);\n+    return new HdfsFileStatus(len,\n+        type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication, blockSize,\n+        mTime, aTime, permission, f, owner, group, symlink,\n+        DFSUtilClient.string2Bytes(localName), fileId, childrenNum,\n+        null, storagePolicy, null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n      boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d\n        WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String)m.get(\"permission\"));\n\n    Boolean aclBit \u003d (Boolean) m.get(\"aclBit\");\n    Boolean encBit \u003d (Boolean) m.get(\"encBit\");\n    Boolean erasureBit  \u003d (Boolean) m.get(\"ecBit\");\n    EnumSet\u003cHdfsFileStatus.Flags\u003e f \u003d\n        EnumSet.noneOf(HdfsFileStatus.Flags.class);\n    if (aclBit !\u003d null \u0026\u0026 aclBit) {\n      f.add(HdfsFileStatus.Flags.HAS_ACL);\n    }\n    if (encBit !\u003d null \u0026\u0026 encBit) {\n      f.add(HdfsFileStatus.Flags.HAS_CRYPT);\n    }\n    if (erasureBit !\u003d null \u0026\u0026 erasureBit) {\n      f.add(HdfsFileStatus.Flags.HAS_EC);\n    }\n\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() :\n        HdfsConstants.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n    return new HdfsFileStatus(len,\n        type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication, blockSize,\n        mTime, aTime, permission, f, owner, group, symlink,\n        DFSUtilClient.string2Bytes(localName), fileId, childrenNum,\n        null, storagePolicy, null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
      "extendedDetails": {}
    },
    "52b00600df921763725396ed92194d3338167655": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13715. Add isErasureCoded() API to FileStatus class. Contributed by Manoj Govindassamy.\n",
      "commitDate": "24/03/17 11:44 AM",
      "commitName": "52b00600df921763725396ed92194d3338167655",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "06/03/17 4:39 PM",
      "commitNameOld": "b5adc5c3011f111f86d232cb33ec522547f68a95",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 17.75,
      "commitsBetweenForRepo": 107,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,38 @@\n   static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n       boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final WebHdfsConstants.PathType type \u003d\n         WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n         : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n         (Boolean) m.get(\"aclBit\"),\n-        (Boolean) m.get(\"encBit\"));\n+        (Boolean) m.get(\"encBit\"),\n+        (Boolean) m.get(\"ecBit\"));\n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() :\n         HdfsConstants.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n     return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY,\n         replication, blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtilClient.string2Bytes(localName),\n         fileId, childrenNum, null,\n         storagePolicy, null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json,\n      boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d\n        WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n        (Boolean) m.get(\"aclBit\"),\n        (Boolean) m.get(\"encBit\"),\n        (Boolean) m.get(\"ecBit\"));\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() :\n        HdfsConstants.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n    return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY,\n        replication, blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtilClient.string2Bytes(localName),\n        fileId, childrenNum, null,\n        storagePolicy, null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
      "extendedDetails": {}
    },
    "1d37a8812160bb030244a1e6b1c753f962d8d2ed": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8854. Erasure coding: add ECPolicy to replace schema+cellSize in hadoop-hdfs. Contributed by Walter Su.\n",
      "commitDate": "13/08/15 10:04 AM",
      "commitName": "1d37a8812160bb030244a1e6b1c753f962d8d2ed",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "29/06/15 10:32 PM",
      "commitNameOld": "0b7af27b9a369d6abdb1fb6c216f50692267f3f4",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 44.48,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n   static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n         : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                    (Boolean) m.get(\"aclBit\"),\n                                                    (Boolean) m.get(\"encBit\"));\n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() : HdfsConstants.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n     return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtilClient.string2Bytes(localName),\n         fileId, childrenNum, null,\n-        storagePolicy, null, 0);\n+        storagePolicy, null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                   (Boolean) m.get(\"aclBit\"),\n                                                   (Boolean) m.get(\"encBit\"));\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() : HdfsConstants.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n    return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtilClient.string2Bytes(localName),\n        fileId, childrenNum, null,\n        storagePolicy, null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
      "extendedDetails": {}
    },
    "91c81fdc24709b3caf1f6281c8879ffee08db956": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8375. Add cellSize as an XAttr to ECZone. Contributed by Vinayakumar B.\n",
      "commitDate": "26/05/15 12:02 PM",
      "commitName": "91c81fdc24709b3caf1f6281c8879ffee08db956",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "26/05/15 12:01 PM",
      "commitNameOld": "9da927540f0ea6698388a4e79ef32c4dc51495ea",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n   static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n         : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                    (Boolean) m.get(\"aclBit\"),\n                                                    (Boolean) m.get(\"encBit\"));\n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() : HdfsConstants.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n     return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtilClient.string2Bytes(localName),\n         fileId, childrenNum, null,\n-        storagePolicy, null);\n+        storagePolicy, null, 0);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                   (Boolean) m.get(\"aclBit\"),\n                                                   (Boolean) m.get(\"encBit\"));\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() : HdfsConstants.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n    return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtilClient.string2Bytes(localName),\n        fileId, childrenNum, null,\n        storagePolicy, null, 0);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
      "extendedDetails": {}
    },
    "9da927540f0ea6698388a4e79ef32c4dc51495ea": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8289. Erasure Coding: add ECSchema to HdfsFileStatus. Contributed by Yong Zhang.\n",
      "commitDate": "26/05/15 12:01 PM",
      "commitName": "9da927540f0ea6698388a4e79ef32c4dc51495ea",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "02/05/15 10:03 AM",
      "commitNameOld": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 24.08,
      "commitsBetweenForRepo": 367,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n   static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n         : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                    (Boolean) m.get(\"aclBit\"),\n                                                    (Boolean) m.get(\"encBit\"));\n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() : HdfsConstants.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n     return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtilClient.string2Bytes(localName),\n         fileId, childrenNum, null,\n-        storagePolicy);\n+        storagePolicy, null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                   (Boolean) m.get(\"aclBit\"),\n                                                   (Boolean) m.get(\"encBit\"));\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() : HdfsConstants.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n    return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtilClient.string2Bytes(localName),\n        fileId, childrenNum, null,\n        storagePolicy, null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
      "extendedDetails": {}
    },
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8249. Separate HdfsConstants into the client and the server side class. Contributed by Haohui Mai.\n",
      "commitDate": "02/05/15 10:03 AM",
      "commitName": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "23/04/15 5:33 PM",
      "commitNameOld": "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 8.69,
      "commitsBetweenForRepo": 78,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n   static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n         : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                    (Boolean) m.get(\"aclBit\"),\n                                                    (Boolean) m.get(\"encBit\"));\n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n-        ((Number) m.get(\"fileId\")).longValue() : HdfsConstantsClient.GRANDFATHER_INODE_ID;\n+        ((Number) m.get(\"fileId\")).longValue() : HdfsConstants.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n-        HdfsConstantsClient.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n+        HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n     return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtilClient.string2Bytes(localName),\n         fileId, childrenNum, null,\n         storagePolicy);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                   (Boolean) m.get(\"aclBit\"),\n                                                   (Boolean) m.get(\"encBit\"));\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() : HdfsConstants.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n    return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtilClient.string2Bytes(localName),\n        fileId, childrenNum, null,\n        storagePolicy);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
      "extendedDetails": {}
    },
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "HDFS-8052. Move WebHdfsFileSystem into hadoop-hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "23/04/15 5:33 PM",
      "commitName": "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "HDFS-8052. Move WebHdfsFileSystem into hadoop-hdfs-client. Contributed by Haohui Mai.\n",
          "commitDate": "23/04/15 5:33 PM",
          "commitName": "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "23/04/15 4:40 PM",
          "commitNameOld": "0b3f8957a87ada1a275c9904b211fdbdcefafb02",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,34 @@\n   static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n-        : DFSUtil.string2Bytes((String) m.get(\"symlink\"));\n+        : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                    (Boolean) m.get(\"aclBit\"),\n                                                    (Boolean) m.get(\"encBit\"));\n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() : HdfsConstantsClient.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         HdfsConstantsClient.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n     return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n-        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null,\n+        symlink, DFSUtilClient.string2Bytes(localName),\n+        fileId, childrenNum, null,\n         storagePolicy);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                   (Boolean) m.get(\"aclBit\"),\n                                                   (Boolean) m.get(\"encBit\"));\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() : HdfsConstantsClient.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        HdfsConstantsClient.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n    return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtilClient.string2Bytes(localName),\n        fileId, childrenNum, null,\n        storagePolicy);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8052. Move WebHdfsFileSystem into hadoop-hdfs-client. Contributed by Haohui Mai.\n",
          "commitDate": "23/04/15 5:33 PM",
          "commitName": "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "23/04/15 4:40 PM",
          "commitNameOld": "0b3f8957a87ada1a275c9904b211fdbdcefafb02",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,34 @@\n   static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n-        : DFSUtil.string2Bytes((String) m.get(\"symlink\"));\n+        : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                    (Boolean) m.get(\"aclBit\"),\n                                                    (Boolean) m.get(\"encBit\"));\n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() : HdfsConstantsClient.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         HdfsConstantsClient.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n     return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n-        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null,\n+        symlink, DFSUtilClient.string2Bytes(localName),\n+        fileId, childrenNum, null,\n         storagePolicy);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtilClient.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                   (Boolean) m.get(\"aclBit\"),\n                                                   (Boolean) m.get(\"encBit\"));\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() : HdfsConstantsClient.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        HdfsConstantsClient.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n    return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtilClient.string2Bytes(localName),\n        fileId, childrenNum, null,\n        storagePolicy);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
          "extendedDetails": {}
        }
      ]
    },
    "5c97db07fb306842f49d73a67a90cecec19a7833": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8169. Move LocatedBlocks and related classes to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "20/04/15 12:36 AM",
      "commitName": "5c97db07fb306842f49d73a67a90cecec19a7833",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "16/04/15 10:49 PM",
      "commitNameOld": "76e7264e8d6407f527bd877009aca11f7bb63bd7",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 3.07,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,33 @@\n   static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n         : DFSUtil.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                    (Boolean) m.get(\"aclBit\"),\n                                                    (Boolean) m.get(\"encBit\"));\n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() : HdfsConstantsClient.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n-        BlockStoragePolicySuite.ID_UNSPECIFIED;\n+        HdfsConstantsClient.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n     return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null,\n         storagePolicy);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                   (Boolean) m.get(\"aclBit\"),\n                                                   (Boolean) m.get(\"encBit\"));\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() : HdfsConstantsClient.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        HdfsConstantsClient.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED;\n    return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null,\n        storagePolicy);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
      "extendedDetails": {}
    },
    "76e7264e8d6407f527bd877009aca11f7bb63bd7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8165. Move GRANDFATHER_GENERATION_STAMP and GRANDFATER_INODE_ID to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "16/04/15 10:49 PM",
      "commitName": "76e7264e8d6407f527bd877009aca11f7bb63bd7",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "07/04/15 9:30 PM",
      "commitNameOld": "ab04ff9efe632b4eca6faca7407ac35e00e6a379",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 9.05,
      "commitsBetweenForRepo": 81,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,33 @@\n   static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n         : DFSUtil.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                    (Boolean) m.get(\"aclBit\"),\n                                                    (Boolean) m.get(\"encBit\"));\n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n-        ((Number) m.get(\"fileId\")).longValue() : INodeId.GRANDFATHER_INODE_ID;\n+        ((Number) m.get(\"fileId\")).longValue() : HdfsConstantsClient.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         BlockStoragePolicySuite.ID_UNSPECIFIED;\n     return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null,\n         storagePolicy);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                   (Boolean) m.get(\"aclBit\"),\n                                                   (Boolean) m.get(\"encBit\"));\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() : HdfsConstantsClient.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        BlockStoragePolicySuite.ID_UNSPECIFIED;\n    return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null,\n        storagePolicy);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
      "extendedDetails": {}
    },
    "ab04ff9efe632b4eca6faca7407ac35e00e6a379": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-8080. Separate JSON related routines used by WebHdfsFileSystem to a package local class. Contributed by Haohui Mai.\n",
      "commitDate": "07/04/15 9:30 PM",
      "commitName": "ab04ff9efe632b4eca6faca7407ac35e00e6a379",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-8080. Separate JSON related routines used by WebHdfsFileSystem to a package local class. Contributed by Haohui Mai.\n",
          "commitDate": "07/04/15 9:30 PM",
          "commitName": "ab04ff9efe632b4eca6faca7407ac35e00e6a379",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "07/04/15 9:26 PM",
          "commitNameOld": "d505c8acd30d6f40d0632fe9c93c886a4499a9fc",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,34 +1,33 @@\n-  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n+  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n-    final Map\u003c?, ?\u003e m \u003d includesType ? \n+    final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n-    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n-    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n-        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n+    final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n+    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n+        : DFSUtil.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n-      (Boolean)m.get(\"aclBit\"), (Boolean)m.get(\"encBit\"));\n+                                                   (Boolean) m.get(\"aclBit\"),\n+                                                   (Boolean) m.get(\"encBit\"));\n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n-    final boolean isLazyPersist \u003d m.containsKey(\"lazyPersist\")\n-        ? (Boolean) m.get(\"lazyPersist\") : false;\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() : INodeId.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         BlockStoragePolicySuite.ID_UNSPECIFIED;\n-    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n+    return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null,\n         storagePolicy);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                   (Boolean) m.get(\"aclBit\"),\n                                                   (Boolean) m.get(\"encBit\"));\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() : INodeId.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        BlockStoragePolicySuite.ID_UNSPECIFIED;\n    return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null,\n        storagePolicy);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
            "oldMethodName": "toFileStatus",
            "newMethodName": "toFileStatus"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-8080. Separate JSON related routines used by WebHdfsFileSystem to a package local class. Contributed by Haohui Mai.\n",
          "commitDate": "07/04/15 9:30 PM",
          "commitName": "ab04ff9efe632b4eca6faca7407ac35e00e6a379",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "07/04/15 9:26 PM",
          "commitNameOld": "d505c8acd30d6f40d0632fe9c93c886a4499a9fc",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,34 +1,33 @@\n-  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n+  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n-    final Map\u003c?, ?\u003e m \u003d includesType ? \n+    final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n-    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n-    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n-        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n+    final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n+    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n+        : DFSUtil.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n-      (Boolean)m.get(\"aclBit\"), (Boolean)m.get(\"encBit\"));\n+                                                   (Boolean) m.get(\"aclBit\"),\n+                                                   (Boolean) m.get(\"encBit\"));\n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n-    final boolean isLazyPersist \u003d m.containsKey(\"lazyPersist\")\n-        ? (Boolean) m.get(\"lazyPersist\") : false;\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() : INodeId.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         BlockStoragePolicySuite.ID_UNSPECIFIED;\n-    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n+    return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null,\n         storagePolicy);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                   (Boolean) m.get(\"aclBit\"),\n                                                   (Boolean) m.get(\"encBit\"));\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() : INodeId.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        BlockStoragePolicySuite.ID_UNSPECIFIED;\n    return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null,\n        storagePolicy);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
          "extendedDetails": {
            "oldValue": "[public, static]",
            "newValue": "[static]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8080. Separate JSON related routines used by WebHdfsFileSystem to a package local class. Contributed by Haohui Mai.\n",
          "commitDate": "07/04/15 9:30 PM",
          "commitName": "ab04ff9efe632b4eca6faca7407ac35e00e6a379",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "07/04/15 9:26 PM",
          "commitNameOld": "d505c8acd30d6f40d0632fe9c93c886a4499a9fc",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,34 +1,33 @@\n-  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n+  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n-    final Map\u003c?, ?\u003e m \u003d includesType ? \n+    final Map\u003c?, ?\u003e m \u003d includesType ?\n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n-    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n-    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n-        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n+    final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n+    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n+        : DFSUtil.string2Bytes((String) m.get(\"symlink\"));\n \n     final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n-      (Boolean)m.get(\"aclBit\"), (Boolean)m.get(\"encBit\"));\n+                                                   (Boolean) m.get(\"aclBit\"),\n+                                                   (Boolean) m.get(\"encBit\"));\n     final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n     final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n     final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n-    final boolean isLazyPersist \u003d m.containsKey(\"lazyPersist\")\n-        ? (Boolean) m.get(\"lazyPersist\") : false;\n     final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n     final long fileId \u003d m.containsKey(\"fileId\") ?\n         ((Number) m.get(\"fileId\")).longValue() : INodeId.GRANDFATHER_INODE_ID;\n     final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n         BlockStoragePolicySuite.ID_UNSPECIFIED;\n-    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n+    return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null,\n         storagePolicy);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ?\n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final WebHdfsConstants.PathType type \u003d WebHdfsConstants.PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d WebHdfsConstants.PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String) m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n                                                   (Boolean) m.get(\"aclBit\"),\n                                                   (Boolean) m.get(\"encBit\"));\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() : INodeId.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        BlockStoragePolicySuite.ID_UNSPECIFIED;\n    return new HdfsFileStatus(len, type \u003d\u003d WebHdfsConstants.PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null,\n        storagePolicy);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
          "extendedDetails": {}
        }
      ]
    },
    "e2262d3d18c6d5c2aa20f96920104dc07271b869": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6565. Use jackson instead jetty json in hdfs-client. Contributed by Akira AJISAKA.\n",
      "commitDate": "03/03/15 5:54 PM",
      "commitName": "e2262d3d18c6d5c2aa20f96920104dc07271b869",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "08/12/14 10:23 AM",
      "commitNameOld": "ffe942b82c1208bc7b22899da3a233944cb5ab52",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 85.31,
      "commitsBetweenForRepo": 663,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,34 @@\n   public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ? \n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n         : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n \n-    final long len \u003d (Long) m.get(\"length\");\n+    final long len \u003d ((Number) m.get(\"length\")).longValue();\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n       (Boolean)m.get(\"aclBit\"), (Boolean)m.get(\"encBit\"));\n-    final long aTime \u003d (Long) m.get(\"accessTime\");\n-    final long mTime \u003d (Long) m.get(\"modificationTime\");\n-    final long blockSize \u003d (Long) m.get(\"blockSize\");\n+    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n+    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n+    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n     final boolean isLazyPersist \u003d m.containsKey(\"lazyPersist\")\n         ? (Boolean) m.get(\"lazyPersist\") : false;\n-    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n-    final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n-        : INodeId.GRANDFATHER_INODE_ID;\n-    Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n-    final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n-            : childrenNumLong.intValue();\n+    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n+    final long fileId \u003d m.containsKey(\"fileId\") ?\n+        ((Number) m.get(\"fileId\")).longValue() : INodeId.GRANDFATHER_INODE_ID;\n+    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n-        (byte) (long) (Long) m.get(\"storagePolicy\") :\n-          BlockStoragePolicySuite.ID_UNSPECIFIED;\n+        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n+        BlockStoragePolicySuite.ID_UNSPECIFIED;\n     return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null,\n         storagePolicy);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n\n    final long len \u003d ((Number) m.get(\"length\")).longValue();\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n      (Boolean)m.get(\"aclBit\"), (Boolean)m.get(\"encBit\"));\n    final long aTime \u003d ((Number) m.get(\"accessTime\")).longValue();\n    final long mTime \u003d ((Number) m.get(\"modificationTime\")).longValue();\n    final long blockSize \u003d ((Number) m.get(\"blockSize\")).longValue();\n    final boolean isLazyPersist \u003d m.containsKey(\"lazyPersist\")\n        ? (Boolean) m.get(\"lazyPersist\") : false;\n    final short replication \u003d ((Number) m.get(\"replication\")).shortValue();\n    final long fileId \u003d m.containsKey(\"fileId\") ?\n        ((Number) m.get(\"fileId\")).longValue() : INodeId.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d getInt(m, \"childrenNum\", -1);\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) ((Number) m.get(\"storagePolicy\")).longValue() :\n        BlockStoragePolicySuite.ID_UNSPECIFIED;\n    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null,\n        storagePolicy);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "bb84f1fccb18c6c7373851e05d2451d55e908242": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7159. Use block storage policy to set lazy persist preference. (Arpit Agarwal)\n",
      "commitDate": "29/09/14 10:27 PM",
      "commitName": "bb84f1fccb18c6c7373851e05d2451d55e908242",
      "commitAuthor": "arp",
      "commitDateOld": "24/09/14 8:08 PM",
      "commitNameOld": "b1000fbba43786a8d1da129bc7c7a1bf253a9e7e",
      "commitAuthorOld": "",
      "daysBetweenCommits": 5.1,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,36 @@\n   public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ? \n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n         : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n \n     final long len \u003d (Long) m.get(\"length\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n       (Boolean)m.get(\"aclBit\"), (Boolean)m.get(\"encBit\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final boolean isLazyPersist \u003d m.containsKey(\"lazyPersist\")\n         ? (Boolean) m.get(\"lazyPersist\") : false;\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n     final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n         : INodeId.GRANDFATHER_INODE_ID;\n     Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n     final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n             : childrenNumLong.intValue();\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) (long) (Long) m.get(\"storagePolicy\") :\n           BlockStoragePolicySuite.ID_UNSPECIFIED;\n     return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n-        blockSize, isLazyPersist, mTime, aTime, permission, owner, group,\n+        blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null,\n         storagePolicy);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n\n    final long len \u003d (Long) m.get(\"length\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n      (Boolean)m.get(\"aclBit\"), (Boolean)m.get(\"encBit\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final boolean isLazyPersist \u003d m.containsKey(\"lazyPersist\")\n        ? (Boolean) m.get(\"lazyPersist\") : false;\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n        : INodeId.GRANDFATHER_INODE_ID;\n    Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n    final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n            : childrenNumLong.intValue();\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) (long) (Long) m.get(\"storagePolicy\") :\n          BlockStoragePolicySuite.ID_UNSPECIFIED;\n    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null,\n        storagePolicy);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "073bbd805c6680f47bbfcc6e8efd708ad729bca4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7081. Add new DistributedFileSystem API for getting all the existing storage policies. Contributed by Jing Zhao.\n",
      "commitDate": "24/09/14 10:05 AM",
      "commitName": "073bbd805c6680f47bbfcc6e8efd708ad729bca4",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "17/09/14 10:00 PM",
      "commitNameOld": "2d2b0009e662db75cf22e2ce8d618ed0a8e61c2f",
      "commitAuthorOld": "",
      "daysBetweenCommits": 6.5,
      "commitsBetweenForRepo": 67,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,33 @@\n   public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ? \n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n         : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n \n     final long len \u003d (Long) m.get(\"length\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n       (Boolean)m.get(\"aclBit\"), (Boolean)m.get(\"encBit\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n     final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n         : INodeId.GRANDFATHER_INODE_ID;\n     Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n     final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n             : childrenNumLong.intValue();\n     final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n         (byte) (long) (Long) m.get(\"storagePolicy\") :\n-          BlockStoragePolicy.ID_UNSPECIFIED;\n+          BlockStoragePolicySuite.ID_UNSPECIFIED;\n     return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group, symlink,\n         DFSUtil.string2Bytes(localName), fileId, childrenNum, null, storagePolicy);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n\n    final long len \u003d (Long) m.get(\"length\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n      (Boolean)m.get(\"aclBit\"), (Boolean)m.get(\"encBit\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n        : INodeId.GRANDFATHER_INODE_ID;\n    Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n    final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n            : childrenNumLong.intValue();\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) (long) (Long) m.get(\"storagePolicy\") :\n          BlockStoragePolicySuite.ID_UNSPECIFIED;\n    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group, symlink,\n        DFSUtil.string2Bytes(localName), fileId, childrenNum, null, storagePolicy);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "e3803d002c660f18a5c2ecf32344fd6f3f491a5b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6843. Create FileStatus isEncrypted() method (clamb via cmccabe)\n",
      "commitDate": "17/09/14 12:55 PM",
      "commitName": "e3803d002c660f18a5c2ecf32344fd6f3f491a5b",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "27/06/14 1:43 PM",
      "commitNameOld": "2efea952139b30dd1c881eed0b443ffa72be6dce",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 81.97,
      "commitsBetweenForRepo": 683,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n   public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ? \n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n         : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n \n     final long len \u003d (Long) m.get(\"length\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n-      (Boolean)m.get(\"aclBit\"));\n+      (Boolean)m.get(\"aclBit\"), (Boolean)m.get(\"encBit\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n     final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n         : INodeId.GRANDFATHER_INODE_ID;\n     Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n     final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n             : childrenNumLong.intValue();\n     return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum,\n         null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n\n    final long len \u003d (Long) m.get(\"length\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n      (Boolean)m.get(\"aclBit\"), (Boolean)m.get(\"encBit\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n        : INodeId.GRANDFATHER_INODE_ID;\n    Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n    final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n            : childrenNumLong.intValue();\n    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum,\n        null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "a7bcc9535860214380e235641d1d5d2dd15aee58": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6921. Add LazyPersist flag to FileStatus. (Arpit Agarwal)\n",
      "commitDate": "27/08/14 9:47 PM",
      "commitName": "a7bcc9535860214380e235641d1d5d2dd15aee58",
      "commitAuthor": "arp",
      "commitDateOld": "27/06/14 1:43 PM",
      "commitNameOld": "2efea952139b30dd1c881eed0b443ffa72be6dce",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 61.34,
      "commitsBetweenForRepo": 486,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,32 @@\n   public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ? \n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n         : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n \n     final long len \u003d (Long) m.get(\"length\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n       (Boolean)m.get(\"aclBit\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n+    final boolean isLazyPersist \u003d m.containsKey(\"lazyPersist\")\n+        ? (Boolean) m.get(\"lazyPersist\") : false;\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n     final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n         : INodeId.GRANDFATHER_INODE_ID;\n     Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n     final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n             : childrenNumLong.intValue();\n     return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n-        blockSize, mTime, aTime, permission, owner, group,\n-        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum,\n-        null);\n+        blockSize, isLazyPersist, mTime, aTime, permission, owner, group,\n+        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n\n    final long len \u003d (Long) m.get(\"length\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n      (Boolean)m.get(\"aclBit\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final boolean isLazyPersist \u003d m.containsKey(\"lazyPersist\")\n        ? (Boolean) m.get(\"lazyPersist\") : false;\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n        : INodeId.GRANDFATHER_INODE_ID;\n    Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n    final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n            : childrenNumLong.intValue();\n    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n        blockSize, isLazyPersist, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum, null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "9b250d74f029f8ccf3a613f9fb74f59838a66ec1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6847. Support storage policy on directories and include storage policy in HdfsFileStatus.  Contributed by Jing Zhao\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-6584@1618416 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/08/14 1:58 PM",
      "commitName": "9b250d74f029f8ccf3a613f9fb74f59838a66ec1",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "05/06/14 8:48 PM",
      "commitNameOld": "6a4f6d6b3e41e660c214b77c9ed43d4c65200b6a",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 71.72,
      "commitsBetweenForRepo": 480,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,33 @@\n   public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ? \n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n         : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n \n     final long len \u003d (Long) m.get(\"length\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n       (Boolean)m.get(\"aclBit\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n     final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n         : INodeId.GRANDFATHER_INODE_ID;\n     Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n     final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n             : childrenNumLong.intValue();\n+    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n+        (byte) (long) (Long) m.get(\"storagePolicy\") :\n+          BlockStoragePolicy.ID_UNSPECIFIED;\n     return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n-        blockSize, mTime, aTime, permission, owner, group,\n-        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum);\n+        blockSize, mTime, aTime, permission, owner, group, symlink,\n+        DFSUtil.string2Bytes(localName), fileId, childrenNum, storagePolicy);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n\n    final long len \u003d (Long) m.get(\"length\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n      (Boolean)m.get(\"aclBit\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n        : INodeId.GRANDFATHER_INODE_ID;\n    Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n    final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n            : childrenNumLong.intValue();\n    final byte storagePolicy \u003d m.containsKey(\"storagePolicy\") ?\n        (byte) (long) (Long) m.get(\"storagePolicy\") :\n          BlockStoragePolicy.ID_UNSPECIFIED;\n    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group, symlink,\n        DFSUtil.string2Bytes(localName), fileId, childrenNum, storagePolicy);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "2efea952139b30dd1c881eed0b443ffa72be6dce": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6391. Get the Key/IV from the NameNode for encrypted files in DFSClient. Contributed by Charles Lamb and Andrew Wang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/fs-encryption@1606220 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/06/14 1:43 PM",
      "commitName": "2efea952139b30dd1c881eed0b443ffa72be6dce",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "16/06/14 11:13 AM",
      "commitNameOld": "c5b7236d9c3240f6cefc1782bc7926a678d104f4",
      "commitAuthorOld": "",
      "daysBetweenCommits": 11.1,
      "commitsBetweenForRepo": 39,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n   public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ? \n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n         : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n \n     final long len \u003d (Long) m.get(\"length\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n       (Boolean)m.get(\"aclBit\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n     final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n         : INodeId.GRANDFATHER_INODE_ID;\n     Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n     final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n             : childrenNumLong.intValue();\n     return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum,\n-        null /* key */, null /* IV */);\n+        null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n\n    final long len \u003d (Long) m.get(\"length\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n      (Boolean)m.get(\"aclBit\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n        : INodeId.GRANDFATHER_INODE_ID;\n    Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n    final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n            : childrenNumLong.intValue();\n    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum,\n        null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "bdee397e95e98ece071345822e2e4d3f690f09c3": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-6392. Wire crypto streams for encrypted files in DFSClient. (clamb and yliu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/fs-encryption@1600582 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/06/14 3:10 AM",
      "commitName": "bdee397e95e98ece071345822e2e4d3f690f09c3",
      "commitAuthor": "Charles Lamb",
      "commitDateOld": "21/05/14 6:57 AM",
      "commitNameOld": "ac23a55547716df29b3e25c98a113399e184d9d1",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 14.84,
      "commitsBetweenForRepo": 63,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,31 @@\n   public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ? \n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n         : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n \n     final long len \u003d (Long) m.get(\"length\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n       (Boolean)m.get(\"aclBit\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n     final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n         : INodeId.GRANDFATHER_INODE_ID;\n     Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n     final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n             : childrenNumLong.intValue();\n     return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n-        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum);\n+        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum,\n+        null /* key */, null /* IV */);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n\n    final long len \u003d (Long) m.get(\"length\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n      (Boolean)m.get(\"aclBit\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n        : INodeId.GRANDFATHER_INODE_ID;\n    Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n    final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n            : childrenNumLong.intValue();\n    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum,\n        null /* key */, null /* IV */);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "65158e478f135ec051c1939bd5f371818365dffd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6326. WebHdfs ACL compatibility is broken. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594743 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/05/14 3:35 PM",
      "commitName": "65158e478f135ec051c1939bd5f371818365dffd",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "24/03/14 10:51 PM",
      "commitNameOld": "3a61d25457606b93f7e99a48fe8f66984f4084b0",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 50.7,
      "commitsBetweenForRepo": 307,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,30 @@\n   public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ? \n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n         : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n \n     final long len \u003d (Long) m.get(\"length\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n-    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n+    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n+      (Boolean)m.get(\"aclBit\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n     final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n         : INodeId.GRANDFATHER_INODE_ID;\n     Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n     final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n             : childrenNumLong.intValue();\n     return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n\n    final long len \u003d (Long) m.get(\"length\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"),\n      (Boolean)m.get(\"aclBit\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n        : INodeId.GRANDFATHER_INODE_ID;\n    Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n    final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n            : childrenNumLong.intValue();\n    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "4f68aa060090319b8de5c30f41d193632503ed17": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5043. For HdfsFileStatus, set default value of childrenNum to -1 instead of 0 to avoid confusing applications. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1508694 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/07/13 5:49 PM",
      "commitName": "4f68aa060090319b8de5c30f41d193632503ed17",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "10/07/13 10:32 AM",
      "commitNameOld": "c6eaa8b37fe7749402d9da91bde23f90cd95b44a",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 20.3,
      "commitsBetweenForRepo": 140,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,29 @@\n   public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ? \n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n         : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n \n     final long len \u003d (Long) m.get(\"length\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n     final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n         : INodeId.GRANDFATHER_INODE_ID;\n     Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n-    final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? 0\n+    final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n             : childrenNumLong.intValue();\n     return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n\n    final long len \u003d (Long) m.get(\"length\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n        : INodeId.GRANDFATHER_INODE_ID;\n    Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n    final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? -1\n            : childrenNumLong.intValue();\n    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "c6eaa8b37fe7749402d9da91bde23f90cd95b44a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4969. WebhdfsFileSystem expects non-standard WEBHDFS Json element. (rkanter via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1501868 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/07/13 10:32 AM",
      "commitName": "c6eaa8b37fe7749402d9da91bde23f90cd95b44a",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "20/06/13 5:32 PM",
      "commitNameOld": "6ecf78a99b4b10d4c569cc2b335060ab988b8001",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 19.71,
      "commitsBetweenForRepo": 72,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,29 @@\n   public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ? \n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n         : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n \n     final long len \u003d (Long) m.get(\"length\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n     final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n         : INodeId.GRANDFATHER_INODE_ID;\n-    final int childrenNum \u003d (int) (long) (Long) m.get(\"childrenNum\");\n+    Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n+    final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? 0\n+            : childrenNumLong.intValue();\n     return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n\n    final long len \u003d (Long) m.get(\"length\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n        : INodeId.GRANDFATHER_INODE_ID;\n    Long childrenNumLong \u003d (Long) m.get(\"childrenNum\");\n    final int childrenNum \u003d (childrenNumLong \u003d\u003d null) ? 0\n            : childrenNumLong.intValue();\n    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "6ecf78a99b4b10d4c569cc2b335060ab988b8001": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4772. Add number of children in HdfsFileStatus. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1495253 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/06/13 5:32 PM",
      "commitName": "6ecf78a99b4b10d4c569cc2b335060ab988b8001",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "20/02/13 7:19 PM",
      "commitNameOld": "567ab4335f8ded3c03bdb0ada59fef4da6a36289",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 119.88,
      "commitsBetweenForRepo": 774,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,27 @@\n   public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ? \n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n         : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n \n     final long len \u003d (Long) m.get(\"length\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n     final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n         : INodeId.GRANDFATHER_INODE_ID;\n+    final int childrenNum \u003d (int) (long) (Long) m.get(\"childrenNum\");\n     return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n-        symlink, DFSUtil.string2Bytes(localName), fileId);\n+        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n\n    final long len \u003d (Long) m.get(\"length\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n        : INodeId.GRANDFATHER_INODE_ID;\n    final int childrenNum \u003d (int) (long) (Long) m.get(\"childrenNum\");\n    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName), fileId, childrenNum);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "567ab4335f8ded3c03bdb0ada59fef4da6a36289": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4502. JsonUtil.toFileStatus(..) should check if the fileId property exists.  Contributed by Brandon Li\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1448502 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/02/13 7:19 PM",
      "commitName": "567ab4335f8ded3c03bdb0ada59fef4da6a36289",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "06/02/13 11:52 AM",
      "commitNameOld": "4525c4a25ba90163c9543116e2bd54239e0dd097",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 14.31,
      "commitsBetweenForRepo": 38,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,26 @@\n   public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ? \n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n         : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n \n     final long len \u003d (Long) m.get(\"length\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n-    final long fileId \u003d (Long) m.get(\"fileId\");\n+    final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n+        : INodeId.GRANDFATHER_INODE_ID;\n     return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName), fileId);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n\n    final long len \u003d (Long) m.get(\"length\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    final long fileId \u003d m.containsKey(\"fileId\") ? (Long) m.get(\"fileId\")\n        : INodeId.GRANDFATHER_INODE_ID;\n    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName), fileId);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "4525c4a25ba90163c9543116e2bd54239e0dd097": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4340. Update addBlock() to inculde inode id as additional argument. Contributed Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1443169 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/02/13 11:52 AM",
      "commitName": "4525c4a25ba90163c9543116e2bd54239e0dd097",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "21/08/12 2:44 AM",
      "commitNameOld": "f2dd818201402d0ca8a7049ba7abf77188443a64",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 169.42,
      "commitsBetweenForRepo": 885,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,25 @@\n   public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ? \n         (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"pathSuffix\");\n     final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n         : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n \n     final long len \u003d (Long) m.get(\"length\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n+    final long fileId \u003d (Long) m.get(\"fileId\");\n     return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n-        symlink, DFSUtil.string2Bytes(localName));\n+        symlink, DFSUtil.string2Bytes(localName), fileId);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n\n    final long len \u003d (Long) m.get(\"length\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    final long fileId \u003d (Long) m.get(\"fileId\");\n    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName), fileId);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "94c631af1fc49f5ae5881fcd5f0e80b17308d15d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2540. Webhdfs: change \"Expect: 100-continue\" to two-step write; change \"HdfsFileStatus\" and \"localName\" respectively to \"FileStatus\" and \"pathSuffix\" in JSON response.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1199396 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/11/11 11:25 AM",
      "commitName": "94c631af1fc49f5ae5881fcd5f0e80b17308d15d",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "03/11/11 3:34 PM",
      "commitNameOld": "6afe3e0d22caa2b0752d52ddf7794c25a66cc9c8",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 4.87,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ? \n-        (Map\u003c?, ?\u003e)json.get(HdfsFileStatus.class.getSimpleName()) : json;\n-    final String localName \u003d (String) m.get(\"localName\");\n+        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n+    final String localName \u003d (String) m.get(\"pathSuffix\");\n     final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n     final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n         : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n \n     final long len \u003d (Long) m.get(\"length\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n     return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n         blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(FileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"pathSuffix\");\n    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n\n    final long len \u003d (Long) m.get(\"length\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "6afe3e0d22caa2b0752d52ddf7794c25a66cc9c8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2527. WebHdfs: remove the use of \"Range\" header in Open; use ugi username if renewer parameter is null in GetDelegationToken; response OK when setting replication for non-files; rename GETFILEBLOCKLOCATIONS to GET_BLOCK_LOCATIONS and state that it is a private unstable API; replace isDirectory and isSymlink with enum {FILE, DIRECTORY, SYMLINK} in HdfsFileStatus JSON object. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1197329 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/11/11 3:34 PM",
      "commitName": "6afe3e0d22caa2b0752d52ddf7794c25a66cc9c8",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "27/10/11 4:13 PM",
      "commitNameOld": "8cb0d4b380e0fd4437310c1dd6ef8b8995cc383d",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 6.97,
      "commitsBetweenForRepo": 91,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,24 @@\n   public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n     final Map\u003c?, ?\u003e m \u003d includesType ? \n         (Map\u003c?, ?\u003e)json.get(HdfsFileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"localName\");\n-    final boolean isDir \u003d (Boolean) m.get(\"isDir\");\n-    final boolean isSymlink \u003d (Boolean) m.get(\"isSymlink\");\n-    final byte[] symlink \u003d isSymlink?\n-        DFSUtil.string2Bytes((String)m.get(\"symlink\")): null;\n+    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n+    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n+        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n \n-    final long len \u003d (Long) m.get(\"len\");\n+    final long len \u003d (Long) m.get(\"length\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n-    return new HdfsFileStatus(len, isDir, replication, blockSize, mTime, aTime,\n-        permission, owner, group,\n+    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n+        blockSize, mTime, aTime, permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(HdfsFileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"localName\");\n    final PathType type \u003d PathType.valueOf((String) m.get(\"type\"));\n    final byte[] symlink \u003d type !\u003d PathType.SYMLINK? null\n        : DFSUtil.string2Bytes((String)m.get(\"symlink\"));\n\n    final long len \u003d (Long) m.get(\"length\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    return new HdfsFileStatus(len, type \u003d\u003d PathType.DIRECTORY, replication,\n        blockSize, mTime, aTime, permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "676f488efffd50eb47e75cd750f9bc948b9e12fb": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-2404. webhdfs liststatus json response is not correct. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1180757 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/10/11 6:49 PM",
      "commitName": "676f488efffd50eb47e75cd750f9bc948b9e12fb",
      "commitAuthor": "Suresh Srinivas",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2404. webhdfs liststatus json response is not correct. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1180757 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "09/10/11 6:49 PM",
          "commitName": "676f488efffd50eb47e75cd750f9bc948b9e12fb",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "05/10/11 4:29 AM",
          "commitNameOld": "1b1016beeb716bef8dad93bb2c7c4631a14b3d57",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 4.6,
          "commitsBetweenForRepo": 35,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,25 @@\n-  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json) {\n+  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n-    final Map\u003c?, ?\u003e m \u003d (Map\u003c?, ?\u003e)json.get(HdfsFileStatus.class.getSimpleName());\n+    final Map\u003c?, ?\u003e m \u003d includesType ? \n+        (Map\u003c?, ?\u003e)json.get(HdfsFileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"localName\");\n     final boolean isDir \u003d (Boolean) m.get(\"isDir\");\n     final boolean isSymlink \u003d (Boolean) m.get(\"isSymlink\");\n     final byte[] symlink \u003d isSymlink?\n         DFSUtil.string2Bytes((String)m.get(\"symlink\")): null;\n \n     final long len \u003d (Long) m.get(\"len\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n     return new HdfsFileStatus(len, isDir, replication, blockSize, mTime, aTime,\n         permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(HdfsFileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"localName\");\n    final boolean isDir \u003d (Boolean) m.get(\"isDir\");\n    final boolean isSymlink \u003d (Boolean) m.get(\"isSymlink\");\n    final byte[] symlink \u003d isSymlink?\n        DFSUtil.string2Bytes((String)m.get(\"symlink\")): null;\n\n    final long len \u003d (Long) m.get(\"len\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    return new HdfsFileStatus(len, isDir, replication, blockSize, mTime, aTime,\n        permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
          "extendedDetails": {
            "oldValue": "[json-Map\u003c?,?\u003e(modifiers-final)]",
            "newValue": "[json-Map\u003c?,?\u003e(modifiers-final), includesType-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2404. webhdfs liststatus json response is not correct. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1180757 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "09/10/11 6:49 PM",
          "commitName": "676f488efffd50eb47e75cd750f9bc948b9e12fb",
          "commitAuthor": "Suresh Srinivas",
          "commitDateOld": "05/10/11 4:29 AM",
          "commitNameOld": "1b1016beeb716bef8dad93bb2c7c4631a14b3d57",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 4.6,
          "commitsBetweenForRepo": 35,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,25 @@\n-  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json) {\n+  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n     if (json \u003d\u003d null) {\n       return null;\n     }\n \n-    final Map\u003c?, ?\u003e m \u003d (Map\u003c?, ?\u003e)json.get(HdfsFileStatus.class.getSimpleName());\n+    final Map\u003c?, ?\u003e m \u003d includesType ? \n+        (Map\u003c?, ?\u003e)json.get(HdfsFileStatus.class.getSimpleName()) : json;\n     final String localName \u003d (String) m.get(\"localName\");\n     final boolean isDir \u003d (Boolean) m.get(\"isDir\");\n     final boolean isSymlink \u003d (Boolean) m.get(\"isSymlink\");\n     final byte[] symlink \u003d isSymlink?\n         DFSUtil.string2Bytes((String)m.get(\"symlink\")): null;\n \n     final long len \u003d (Long) m.get(\"len\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n     return new HdfsFileStatus(len, isDir, replication, blockSize, mTime, aTime,\n         permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json, boolean includesType) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d includesType ? \n        (Map\u003c?, ?\u003e)json.get(HdfsFileStatus.class.getSimpleName()) : json;\n    final String localName \u003d (String) m.get(\"localName\");\n    final boolean isDir \u003d (Boolean) m.get(\"isDir\");\n    final boolean isSymlink \u003d (Boolean) m.get(\"isSymlink\");\n    final byte[] symlink \u003d isSymlink?\n        DFSUtil.string2Bytes((String)m.get(\"symlink\")): null;\n\n    final long len \u003d (Long) m.get(\"len\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    return new HdfsFileStatus(len, isDir, replication, blockSize, mTime, aTime,\n        permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
          "extendedDetails": {}
        }
      ]
    },
    "1b1016beeb716bef8dad93bb2c7c4631a14b3d57": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-2395. Add a root element in the JSON responses of webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1179169 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/10/11 4:29 AM",
      "commitName": "1b1016beeb716bef8dad93bb2c7c4631a14b3d57",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2395. Add a root element in the JSON responses of webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1179169 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "05/10/11 4:29 AM",
          "commitName": "1b1016beeb716bef8dad93bb2c7c4631a14b3d57",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "30/09/11 9:49 PM",
          "commitNameOld": "dc8464f943b61b795df0cc8baec171bf07355763",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 4.28,
          "commitsBetweenForRepo": 25,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,24 @@\n-  public static HdfsFileStatus toFileStatus(final Map\u003cString, Object\u003e m) {\n-    if (m \u003d\u003d null) {\n+  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json) {\n+    if (json \u003d\u003d null) {\n       return null;\n     }\n \n+    final Map\u003c?, ?\u003e m \u003d (Map\u003c?, ?\u003e)json.get(HdfsFileStatus.class.getSimpleName());\n     final String localName \u003d (String) m.get(\"localName\");\n     final boolean isDir \u003d (Boolean) m.get(\"isDir\");\n     final boolean isSymlink \u003d (Boolean) m.get(\"isSymlink\");\n     final byte[] symlink \u003d isSymlink?\n         DFSUtil.string2Bytes((String)m.get(\"symlink\")): null;\n \n     final long len \u003d (Long) m.get(\"len\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n     return new HdfsFileStatus(len, isDir, replication, blockSize, mTime, aTime,\n         permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d (Map\u003c?, ?\u003e)json.get(HdfsFileStatus.class.getSimpleName());\n    final String localName \u003d (String) m.get(\"localName\");\n    final boolean isDir \u003d (Boolean) m.get(\"isDir\");\n    final boolean isSymlink \u003d (Boolean) m.get(\"isSymlink\");\n    final byte[] symlink \u003d isSymlink?\n        DFSUtil.string2Bytes((String)m.get(\"symlink\")): null;\n\n    final long len \u003d (Long) m.get(\"len\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    return new HdfsFileStatus(len, isDir, replication, blockSize, mTime, aTime,\n        permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
          "extendedDetails": {
            "oldValue": "[m-Map\u003cString,Object\u003e(modifiers-final)]",
            "newValue": "[json-Map\u003c?,?\u003e(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2395. Add a root element in the JSON responses of webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1179169 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "05/10/11 4:29 AM",
          "commitName": "1b1016beeb716bef8dad93bb2c7c4631a14b3d57",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "30/09/11 9:49 PM",
          "commitNameOld": "dc8464f943b61b795df0cc8baec171bf07355763",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 4.28,
          "commitsBetweenForRepo": 25,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,24 @@\n-  public static HdfsFileStatus toFileStatus(final Map\u003cString, Object\u003e m) {\n-    if (m \u003d\u003d null) {\n+  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json) {\n+    if (json \u003d\u003d null) {\n       return null;\n     }\n \n+    final Map\u003c?, ?\u003e m \u003d (Map\u003c?, ?\u003e)json.get(HdfsFileStatus.class.getSimpleName());\n     final String localName \u003d (String) m.get(\"localName\");\n     final boolean isDir \u003d (Boolean) m.get(\"isDir\");\n     final boolean isSymlink \u003d (Boolean) m.get(\"isSymlink\");\n     final byte[] symlink \u003d isSymlink?\n         DFSUtil.string2Bytes((String)m.get(\"symlink\")): null;\n \n     final long len \u003d (Long) m.get(\"len\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n     return new HdfsFileStatus(len, isDir, replication, blockSize, mTime, aTime,\n         permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003c?, ?\u003e json) {\n    if (json \u003d\u003d null) {\n      return null;\n    }\n\n    final Map\u003c?, ?\u003e m \u003d (Map\u003c?, ?\u003e)json.get(HdfsFileStatus.class.getSimpleName());\n    final String localName \u003d (String) m.get(\"localName\");\n    final boolean isDir \u003d (Boolean) m.get(\"isDir\");\n    final boolean isSymlink \u003d (Boolean) m.get(\"isSymlink\");\n    final byte[] symlink \u003d isSymlink?\n        DFSUtil.string2Bytes((String)m.get(\"symlink\")): null;\n\n    final long len \u003d (Long) m.get(\"len\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    return new HdfsFileStatus(len, isDir, replication, blockSize, mTime, aTime,\n        permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
          "extendedDetails": {}
        }
      ]
    },
    "4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2340. Support getFileBlockLocations and getDelegationToken in webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1173468 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/09/11 7:56 PM",
      "commitName": "4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "10/09/11 6:41 PM",
      "commitNameOld": "61d0b7530c8978c095ab6f62d9d38e168bd829c6",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 10.05,
      "commitsBetweenForRepo": 65,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,23 @@\n   public static HdfsFileStatus toFileStatus(final Map\u003cString, Object\u003e m) {\n-    if ((Boolean)m.get(\"isNull\")) {\n+    if (m \u003d\u003d null) {\n       return null;\n     }\n \n     final String localName \u003d (String) m.get(\"localName\");\n     final boolean isDir \u003d (Boolean) m.get(\"isDir\");\n     final boolean isSymlink \u003d (Boolean) m.get(\"isSymlink\");\n     final byte[] symlink \u003d isSymlink?\n         DFSUtil.string2Bytes((String)m.get(\"symlink\")): null;\n \n     final long len \u003d (Long) m.get(\"len\");\n     final String owner \u003d (String) m.get(\"owner\");\n     final String group \u003d (String) m.get(\"group\");\n     final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n     final long aTime \u003d (Long) m.get(\"accessTime\");\n     final long mTime \u003d (Long) m.get(\"modificationTime\");\n     final long blockSize \u003d (Long) m.get(\"blockSize\");\n     final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n     return new HdfsFileStatus(len, isDir, replication, blockSize, mTime, aTime,\n         permission, owner, group,\n         symlink, DFSUtil.string2Bytes(localName));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003cString, Object\u003e m) {\n    if (m \u003d\u003d null) {\n      return null;\n    }\n\n    final String localName \u003d (String) m.get(\"localName\");\n    final boolean isDir \u003d (Boolean) m.get(\"isDir\");\n    final boolean isSymlink \u003d (Boolean) m.get(\"isSymlink\");\n    final byte[] symlink \u003d isSymlink?\n        DFSUtil.string2Bytes((String)m.get(\"symlink\")): null;\n\n    final long len \u003d (Long) m.get(\"len\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    return new HdfsFileStatus(len, isDir, replication, blockSize, mTime, aTime,\n        permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {}
    },
    "61d0b7530c8978c095ab6f62d9d38e168bd829c6": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2284. Add a new FileSystem, webhdfs://, for supporting write Http access to HDFS.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1167662 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/09/11 6:41 PM",
      "commitName": "61d0b7530c8978c095ab6f62d9d38e168bd829c6",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,23 @@\n+  public static HdfsFileStatus toFileStatus(final Map\u003cString, Object\u003e m) {\n+    if ((Boolean)m.get(\"isNull\")) {\n+      return null;\n+    }\n+\n+    final String localName \u003d (String) m.get(\"localName\");\n+    final boolean isDir \u003d (Boolean) m.get(\"isDir\");\n+    final boolean isSymlink \u003d (Boolean) m.get(\"isSymlink\");\n+    final byte[] symlink \u003d isSymlink?\n+        DFSUtil.string2Bytes((String)m.get(\"symlink\")): null;\n+\n+    final long len \u003d (Long) m.get(\"len\");\n+    final String owner \u003d (String) m.get(\"owner\");\n+    final String group \u003d (String) m.get(\"group\");\n+    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n+    final long aTime \u003d (Long) m.get(\"accessTime\");\n+    final long mTime \u003d (Long) m.get(\"modificationTime\");\n+    final long blockSize \u003d (Long) m.get(\"blockSize\");\n+    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n+    return new HdfsFileStatus(len, isDir, replication, blockSize, mTime, aTime,\n+        permission, owner, group,\n+        symlink, DFSUtil.string2Bytes(localName));\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static HdfsFileStatus toFileStatus(final Map\u003cString, Object\u003e m) {\n    if ((Boolean)m.get(\"isNull\")) {\n      return null;\n    }\n\n    final String localName \u003d (String) m.get(\"localName\");\n    final boolean isDir \u003d (Boolean) m.get(\"isDir\");\n    final boolean isSymlink \u003d (Boolean) m.get(\"isSymlink\");\n    final byte[] symlink \u003d isSymlink?\n        DFSUtil.string2Bytes((String)m.get(\"symlink\")): null;\n\n    final long len \u003d (Long) m.get(\"len\");\n    final String owner \u003d (String) m.get(\"owner\");\n    final String group \u003d (String) m.get(\"group\");\n    final FsPermission permission \u003d toFsPermission((String) m.get(\"permission\"));\n    final long aTime \u003d (Long) m.get(\"accessTime\");\n    final long mTime \u003d (Long) m.get(\"modificationTime\");\n    final long blockSize \u003d (Long) m.get(\"blockSize\");\n    final short replication \u003d (short) (long) (Long) m.get(\"replication\");\n    return new HdfsFileStatus(len, isDir, replication, blockSize, mTime, aTime,\n        permission, owner, group,\n        symlink, DFSUtil.string2Bytes(localName));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java"
    }
  }
}