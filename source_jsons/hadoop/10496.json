{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataStorage.java",
  "functionName": "doFinalize",
  "functionId": "doFinalize___sd-StorageDirectory",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java",
  "functionStartLine": 966,
  "functionEndLine": 1000,
  "numCommitsSeen": 79,
  "timeTaken": 6105,
  "changeHistory": [
    "b3ae11d59790bb08b81848e9f944db7d3afbbd8a",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
    "a11042365f93cf235ecc6f8b1a615cf3edd3e75a",
    "0e8e499ff482c165d21c8e4f5ff9c33f306ca0d9",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "b3ae11d59790bb08b81848e9f944db7d3afbbd8a": "Ybodychange",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": "Ybodychange",
    "a11042365f93cf235ecc6f8b1a615cf3edd3e75a": "Ybodychange",
    "0e8e499ff482c165d21c8e4f5ff9c33f306ca0d9": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b3ae11d59790bb08b81848e9f944db7d3afbbd8a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12997. Move logging to slf4j in BlockPoolSliceStorage and Storage. Contributed by Ajay Kumar.\n",
      "commitDate": "01/02/18 10:45 AM",
      "commitName": "b3ae11d59790bb08b81848e9f944db7d3afbbd8a",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "8239e3afb31d3c4485817d4b8b8b195b554acbe7",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 47.7,
      "commitsBetweenForRepo": 240,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,35 @@\n   void doFinalize(StorageDirectory sd) throws IOException {\n     File prevDir \u003d sd.getPreviousDir();\n     if (!prevDir.exists())\n       return; // already discarded\n     \n     final String dataDirPath \u003d sd.getRoot().getCanonicalPath();\n-    LOG.info(\"Finalizing upgrade for storage directory \" \n-             + dataDirPath \n-             + \".\\n   cur LV \u003d \" + this.getLayoutVersion()\n-             + \"; cur CTime \u003d \" + this.getCTime());\n+    LOG.info(\"Finalizing upgrade for storage directory {}.\\n   cur LV \u003d {}; \"\n+        + \"cur CTime \u003d {}\", dataDirPath, this.getLayoutVersion(), this\n+        .getCTime());\n     assert sd.getCurrentDir().exists() : \"Current directory must exist.\";\n     final File tmpDir \u003d sd.getFinalizedTmp();//finalized.tmp directory\n     final File bbwDir \u003d new File(sd.getRoot(), Storage.STORAGE_1_BBW);\n     // 1. rename previous to finalized.tmp\n     rename(prevDir, tmpDir);\n \n     // 2. delete finalized.tmp dir in a separate thread\n     // Also delete the blocksBeingWritten from HDFS 1.x and earlier, if\n     // it exists.\n     new Daemon(new Runnable() {\n         @Override\n         public void run() {\n           try {\n             deleteDir(tmpDir);\n             if (bbwDir.exists()) {\n               deleteDir(bbwDir);\n             }\n           } catch(IOException ex) {\n             LOG.error(\"Finalize upgrade for \" + dataDirPath + \" failed\", ex);\n           }\n           LOG.info(\"Finalize upgrade for \" + dataDirPath + \" is complete\");\n         }\n         @Override\n         public String toString() { return \"Finalize \" + dataDirPath; }\n       }).start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void doFinalize(StorageDirectory sd) throws IOException {\n    File prevDir \u003d sd.getPreviousDir();\n    if (!prevDir.exists())\n      return; // already discarded\n    \n    final String dataDirPath \u003d sd.getRoot().getCanonicalPath();\n    LOG.info(\"Finalizing upgrade for storage directory {}.\\n   cur LV \u003d {}; \"\n        + \"cur CTime \u003d {}\", dataDirPath, this.getLayoutVersion(), this\n        .getCTime());\n    assert sd.getCurrentDir().exists() : \"Current directory must exist.\";\n    final File tmpDir \u003d sd.getFinalizedTmp();//finalized.tmp directory\n    final File bbwDir \u003d new File(sd.getRoot(), Storage.STORAGE_1_BBW);\n    // 1. rename previous to finalized.tmp\n    rename(prevDir, tmpDir);\n\n    // 2. delete finalized.tmp dir in a separate thread\n    // Also delete the blocksBeingWritten from HDFS 1.x and earlier, if\n    // it exists.\n    new Daemon(new Runnable() {\n        @Override\n        public void run() {\n          try {\n            deleteDir(tmpDir);\n            if (bbwDir.exists()) {\n              deleteDir(bbwDir);\n            }\n          } catch(IOException ex) {\n            LOG.error(\"Finalize upgrade for \" + dataDirPath + \" failed\", ex);\n          }\n          LOG.info(\"Finalize upgrade for \" + dataDirPath + \" is complete\");\n        }\n        @Override\n        public String toString() { return \"Finalize \" + dataDirPath; }\n      }).start();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java",
      "extendedDetails": {}
    },
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4122. Cleanup HDFS logs and reduce the size of logged messages. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1403120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/10/12 4:10 PM",
      "commitName": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "24/08/12 3:10 PM",
      "commitNameOld": "a11042365f93cf235ecc6f8b1a615cf3edd3e75a",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 65.04,
      "commitsBetweenForRepo": 386,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,36 @@\n   void doFinalize(StorageDirectory sd) throws IOException {\n     File prevDir \u003d sd.getPreviousDir();\n     if (!prevDir.exists())\n       return; // already discarded\n     \n     final String dataDirPath \u003d sd.getRoot().getCanonicalPath();\n     LOG.info(\"Finalizing upgrade for storage directory \" \n              + dataDirPath \n              + \".\\n   cur LV \u003d \" + this.getLayoutVersion()\n              + \"; cur CTime \u003d \" + this.getCTime());\n     assert sd.getCurrentDir().exists() : \"Current directory must exist.\";\n     final File tmpDir \u003d sd.getFinalizedTmp();//finalized.tmp directory\n     final File bbwDir \u003d new File(sd.getRoot(), Storage.STORAGE_1_BBW);\n     // 1. rename previous to finalized.tmp\n     rename(prevDir, tmpDir);\n \n     // 2. delete finalized.tmp dir in a separate thread\n     // Also delete the blocksBeingWritten from HDFS 1.x and earlier, if\n     // it exists.\n     new Daemon(new Runnable() {\n         @Override\n         public void run() {\n           try {\n             deleteDir(tmpDir);\n             if (bbwDir.exists()) {\n               deleteDir(bbwDir);\n             }\n           } catch(IOException ex) {\n-            LOG.error(\"Finalize upgrade for \" + dataDirPath + \" failed.\", ex);\n+            LOG.error(\"Finalize upgrade for \" + dataDirPath + \" failed\", ex);\n           }\n-          LOG.info(\"Finalize upgrade for \" + dataDirPath + \" is complete.\");\n+          LOG.info(\"Finalize upgrade for \" + dataDirPath + \" is complete\");\n         }\n         @Override\n         public String toString() { return \"Finalize \" + dataDirPath; }\n       }).start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void doFinalize(StorageDirectory sd) throws IOException {\n    File prevDir \u003d sd.getPreviousDir();\n    if (!prevDir.exists())\n      return; // already discarded\n    \n    final String dataDirPath \u003d sd.getRoot().getCanonicalPath();\n    LOG.info(\"Finalizing upgrade for storage directory \" \n             + dataDirPath \n             + \".\\n   cur LV \u003d \" + this.getLayoutVersion()\n             + \"; cur CTime \u003d \" + this.getCTime());\n    assert sd.getCurrentDir().exists() : \"Current directory must exist.\";\n    final File tmpDir \u003d sd.getFinalizedTmp();//finalized.tmp directory\n    final File bbwDir \u003d new File(sd.getRoot(), Storage.STORAGE_1_BBW);\n    // 1. rename previous to finalized.tmp\n    rename(prevDir, tmpDir);\n\n    // 2. delete finalized.tmp dir in a separate thread\n    // Also delete the blocksBeingWritten from HDFS 1.x and earlier, if\n    // it exists.\n    new Daemon(new Runnable() {\n        @Override\n        public void run() {\n          try {\n            deleteDir(tmpDir);\n            if (bbwDir.exists()) {\n              deleteDir(bbwDir);\n            }\n          } catch(IOException ex) {\n            LOG.error(\"Finalize upgrade for \" + dataDirPath + \" failed\", ex);\n          }\n          LOG.info(\"Finalize upgrade for \" + dataDirPath + \" is complete\");\n        }\n        @Override\n        public String toString() { return \"Finalize \" + dataDirPath; }\n      }).start();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java",
      "extendedDetails": {}
    },
    "a11042365f93cf235ecc6f8b1a615cf3edd3e75a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3731. 2.0 release upgrade must handle blocks being written from 1.0. Contributed by Colin Patrick McCabe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1377137 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/12 3:10 PM",
      "commitName": "a11042365f93cf235ecc6f8b1a615cf3edd3e75a",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "21/08/12 2:18 PM",
      "commitNameOld": "6c0ccb5989c2053f5a1ebab0dd9fdb7b4019fda8",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 3.04,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,36 @@\n   void doFinalize(StorageDirectory sd) throws IOException {\n     File prevDir \u003d sd.getPreviousDir();\n     if (!prevDir.exists())\n       return; // already discarded\n     \n     final String dataDirPath \u003d sd.getRoot().getCanonicalPath();\n     LOG.info(\"Finalizing upgrade for storage directory \" \n              + dataDirPath \n              + \".\\n   cur LV \u003d \" + this.getLayoutVersion()\n              + \"; cur CTime \u003d \" + this.getCTime());\n     assert sd.getCurrentDir().exists() : \"Current directory must exist.\";\n     final File tmpDir \u003d sd.getFinalizedTmp();//finalized.tmp directory\n+    final File bbwDir \u003d new File(sd.getRoot(), Storage.STORAGE_1_BBW);\n     // 1. rename previous to finalized.tmp\n     rename(prevDir, tmpDir);\n \n     // 2. delete finalized.tmp dir in a separate thread\n+    // Also delete the blocksBeingWritten from HDFS 1.x and earlier, if\n+    // it exists.\n     new Daemon(new Runnable() {\n         @Override\n         public void run() {\n           try {\n             deleteDir(tmpDir);\n+            if (bbwDir.exists()) {\n+              deleteDir(bbwDir);\n+            }\n           } catch(IOException ex) {\n             LOG.error(\"Finalize upgrade for \" + dataDirPath + \" failed.\", ex);\n           }\n           LOG.info(\"Finalize upgrade for \" + dataDirPath + \" is complete.\");\n         }\n         @Override\n         public String toString() { return \"Finalize \" + dataDirPath; }\n       }).start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void doFinalize(StorageDirectory sd) throws IOException {\n    File prevDir \u003d sd.getPreviousDir();\n    if (!prevDir.exists())\n      return; // already discarded\n    \n    final String dataDirPath \u003d sd.getRoot().getCanonicalPath();\n    LOG.info(\"Finalizing upgrade for storage directory \" \n             + dataDirPath \n             + \".\\n   cur LV \u003d \" + this.getLayoutVersion()\n             + \"; cur CTime \u003d \" + this.getCTime());\n    assert sd.getCurrentDir().exists() : \"Current directory must exist.\";\n    final File tmpDir \u003d sd.getFinalizedTmp();//finalized.tmp directory\n    final File bbwDir \u003d new File(sd.getRoot(), Storage.STORAGE_1_BBW);\n    // 1. rename previous to finalized.tmp\n    rename(prevDir, tmpDir);\n\n    // 2. delete finalized.tmp dir in a separate thread\n    // Also delete the blocksBeingWritten from HDFS 1.x and earlier, if\n    // it exists.\n    new Daemon(new Runnable() {\n        @Override\n        public void run() {\n          try {\n            deleteDir(tmpDir);\n            if (bbwDir.exists()) {\n              deleteDir(bbwDir);\n            }\n          } catch(IOException ex) {\n            LOG.error(\"Finalize upgrade for \" + dataDirPath + \" failed.\", ex);\n          }\n          LOG.info(\"Finalize upgrade for \" + dataDirPath + \" is complete.\");\n        }\n        @Override\n        public String toString() { return \"Finalize \" + dataDirPath; }\n      }).start();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java",
      "extendedDetails": {}
    },
    "0e8e499ff482c165d21c8e4f5ff9c33f306ca0d9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3659. Add missing @Override to methods across the hadoop-hdfs project. Contributed by Brandon Li. (harsh)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1361894 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/07/12 7:58 PM",
      "commitName": "0e8e499ff482c165d21c8e4f5ff9c33f306ca0d9",
      "commitAuthor": "Harsh J",
      "commitDateOld": "02/04/12 10:38 AM",
      "commitNameOld": "bc13dfb1426944ce45293cb8f444239a7406762c",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 104.39,
      "commitsBetweenForRepo": 651,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,30 @@\n   void doFinalize(StorageDirectory sd) throws IOException {\n     File prevDir \u003d sd.getPreviousDir();\n     if (!prevDir.exists())\n       return; // already discarded\n     \n     final String dataDirPath \u003d sd.getRoot().getCanonicalPath();\n     LOG.info(\"Finalizing upgrade for storage directory \" \n              + dataDirPath \n              + \".\\n   cur LV \u003d \" + this.getLayoutVersion()\n              + \"; cur CTime \u003d \" + this.getCTime());\n     assert sd.getCurrentDir().exists() : \"Current directory must exist.\";\n     final File tmpDir \u003d sd.getFinalizedTmp();//finalized.tmp directory\n     // 1. rename previous to finalized.tmp\n     rename(prevDir, tmpDir);\n \n     // 2. delete finalized.tmp dir in a separate thread\n     new Daemon(new Runnable() {\n+        @Override\n         public void run() {\n           try {\n             deleteDir(tmpDir);\n           } catch(IOException ex) {\n             LOG.error(\"Finalize upgrade for \" + dataDirPath + \" failed.\", ex);\n           }\n           LOG.info(\"Finalize upgrade for \" + dataDirPath + \" is complete.\");\n         }\n+        @Override\n         public String toString() { return \"Finalize \" + dataDirPath; }\n       }).start();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void doFinalize(StorageDirectory sd) throws IOException {\n    File prevDir \u003d sd.getPreviousDir();\n    if (!prevDir.exists())\n      return; // already discarded\n    \n    final String dataDirPath \u003d sd.getRoot().getCanonicalPath();\n    LOG.info(\"Finalizing upgrade for storage directory \" \n             + dataDirPath \n             + \".\\n   cur LV \u003d \" + this.getLayoutVersion()\n             + \"; cur CTime \u003d \" + this.getCTime());\n    assert sd.getCurrentDir().exists() : \"Current directory must exist.\";\n    final File tmpDir \u003d sd.getFinalizedTmp();//finalized.tmp directory\n    // 1. rename previous to finalized.tmp\n    rename(prevDir, tmpDir);\n\n    // 2. delete finalized.tmp dir in a separate thread\n    new Daemon(new Runnable() {\n        @Override\n        public void run() {\n          try {\n            deleteDir(tmpDir);\n          } catch(IOException ex) {\n            LOG.error(\"Finalize upgrade for \" + dataDirPath + \" failed.\", ex);\n          }\n          LOG.info(\"Finalize upgrade for \" + dataDirPath + \" is complete.\");\n        }\n        @Override\n        public String toString() { return \"Finalize \" + dataDirPath; }\n      }).start();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  void doFinalize(StorageDirectory sd) throws IOException {\n    File prevDir \u003d sd.getPreviousDir();\n    if (!prevDir.exists())\n      return; // already discarded\n    \n    final String dataDirPath \u003d sd.getRoot().getCanonicalPath();\n    LOG.info(\"Finalizing upgrade for storage directory \" \n             + dataDirPath \n             + \".\\n   cur LV \u003d \" + this.getLayoutVersion()\n             + \"; cur CTime \u003d \" + this.getCTime());\n    assert sd.getCurrentDir().exists() : \"Current directory must exist.\";\n    final File tmpDir \u003d sd.getFinalizedTmp();//finalized.tmp directory\n    // 1. rename previous to finalized.tmp\n    rename(prevDir, tmpDir);\n\n    // 2. delete finalized.tmp dir in a separate thread\n    new Daemon(new Runnable() {\n        public void run() {\n          try {\n            deleteDir(tmpDir);\n          } catch(IOException ex) {\n            LOG.error(\"Finalize upgrade for \" + dataDirPath + \" failed.\", ex);\n          }\n          LOG.info(\"Finalize upgrade for \" + dataDirPath + \" is complete.\");\n        }\n        public String toString() { return \"Finalize \" + dataDirPath; }\n      }).start();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  void doFinalize(StorageDirectory sd) throws IOException {\n    File prevDir \u003d sd.getPreviousDir();\n    if (!prevDir.exists())\n      return; // already discarded\n    \n    final String dataDirPath \u003d sd.getRoot().getCanonicalPath();\n    LOG.info(\"Finalizing upgrade for storage directory \" \n             + dataDirPath \n             + \".\\n   cur LV \u003d \" + this.getLayoutVersion()\n             + \"; cur CTime \u003d \" + this.getCTime());\n    assert sd.getCurrentDir().exists() : \"Current directory must exist.\";\n    final File tmpDir \u003d sd.getFinalizedTmp();//finalized.tmp directory\n    // 1. rename previous to finalized.tmp\n    rename(prevDir, tmpDir);\n\n    // 2. delete finalized.tmp dir in a separate thread\n    new Daemon(new Runnable() {\n        public void run() {\n          try {\n            deleteDir(tmpDir);\n          } catch(IOException ex) {\n            LOG.error(\"Finalize upgrade for \" + dataDirPath + \" failed.\", ex);\n          }\n          LOG.info(\"Finalize upgrade for \" + dataDirPath + \" is complete.\");\n        }\n        public String toString() { return \"Finalize \" + dataDirPath; }\n      }).start();\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,28 @@\n+  void doFinalize(StorageDirectory sd) throws IOException {\n+    File prevDir \u003d sd.getPreviousDir();\n+    if (!prevDir.exists())\n+      return; // already discarded\n+    \n+    final String dataDirPath \u003d sd.getRoot().getCanonicalPath();\n+    LOG.info(\"Finalizing upgrade for storage directory \" \n+             + dataDirPath \n+             + \".\\n   cur LV \u003d \" + this.getLayoutVersion()\n+             + \"; cur CTime \u003d \" + this.getCTime());\n+    assert sd.getCurrentDir().exists() : \"Current directory must exist.\";\n+    final File tmpDir \u003d sd.getFinalizedTmp();//finalized.tmp directory\n+    // 1. rename previous to finalized.tmp\n+    rename(prevDir, tmpDir);\n+\n+    // 2. delete finalized.tmp dir in a separate thread\n+    new Daemon(new Runnable() {\n+        public void run() {\n+          try {\n+            deleteDir(tmpDir);\n+          } catch(IOException ex) {\n+            LOG.error(\"Finalize upgrade for \" + dataDirPath + \" failed.\", ex);\n+          }\n+          LOG.info(\"Finalize upgrade for \" + dataDirPath + \" is complete.\");\n+        }\n+        public String toString() { return \"Finalize \" + dataDirPath; }\n+      }).start();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void doFinalize(StorageDirectory sd) throws IOException {\n    File prevDir \u003d sd.getPreviousDir();\n    if (!prevDir.exists())\n      return; // already discarded\n    \n    final String dataDirPath \u003d sd.getRoot().getCanonicalPath();\n    LOG.info(\"Finalizing upgrade for storage directory \" \n             + dataDirPath \n             + \".\\n   cur LV \u003d \" + this.getLayoutVersion()\n             + \"; cur CTime \u003d \" + this.getCTime());\n    assert sd.getCurrentDir().exists() : \"Current directory must exist.\";\n    final File tmpDir \u003d sd.getFinalizedTmp();//finalized.tmp directory\n    // 1. rename previous to finalized.tmp\n    rename(prevDir, tmpDir);\n\n    // 2. delete finalized.tmp dir in a separate thread\n    new Daemon(new Runnable() {\n        public void run() {\n          try {\n            deleteDir(tmpDir);\n          } catch(IOException ex) {\n            LOG.error(\"Finalize upgrade for \" + dataDirPath + \" failed.\", ex);\n          }\n          LOG.info(\"Finalize upgrade for \" + dataDirPath + \" is complete.\");\n        }\n        public String toString() { return \"Finalize \" + dataDirPath; }\n      }).start();\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java"
    }
  }
}