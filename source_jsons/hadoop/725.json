{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataStreamer.java",
  "functionName": "run",
  "functionId": "run",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
  "functionStartLine": 1078,
  "functionEndLine": 1207,
  "numCommitsSeen": 156,
  "timeTaken": 14260,
  "changeHistory": [
    "d9c4f1129c0814ab61fce6ea8baf4b272f84c252",
    "d6b7609c9674c3d0175868d7190293f1925d779b",
    "685cb83e4c3f433c5147e35217ce79ea520a0da5",
    "49b02d4a9bf9beac19f716488348ea4e30563ff4",
    "29b7df960fc3d0a7d1416225c3106c7d4222f0ca",
    "4a5819dae2b0ca8f8b6d94ef464882d079d86593",
    "193d27de0a5d23a61cabd41162ebc3292d8526d1",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8",
    "6ee0539ede78b640f01c5eac18ded161182a7835",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
    "892ade689f9bcce76daae8f66fc00a49bee8548e",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "8f378733423a5244461df79a92c00239514b8b93",
    "7947e5b53b9ac9524b535b0384c1c355b74723ff",
    "2cc9514ad643ae49d30524743420ee9744e571bd",
    "6ccf4fbf8a8374c289370f67b26ac05abad30ebc",
    "b80457158daf0dc712fbe5695625cc17d70d4bb4",
    "a16bfff71bd7f00e06e1f59bfe5445a154bb8c66",
    "75ead273bea8a7dad61c4f99c3a16cab2697c498",
    "8234fd0e1087e0e49aa1d6f286f292b7f70b368e",
    "952640fa4cbdc23fe8781e5627c2e8eab565c535",
    "c4980a2f343778544ca20ebea1338651793ea0d9",
    "b9f6d0c956f0278c8b9b83e05b523a442a730ebb",
    "36ccf097a95eae0761de7b657752e4808a86c094",
    "1228f8f6fb16de4f0283dd1c7939e6fc3dfb7aae",
    "57b28693ee295746c6d168d37dd05eaf7b601b87",
    "ceea91c9cd8b2a18be13217894ccf1c17198de18",
    "631ccbdd2031a8387d4c2b743a4fc64c990391ce",
    "be7dd8333a7e56e732171db0781786987de03195",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "d9c4f1129c0814ab61fce6ea8baf4b272f84c252": "Ybodychange",
    "d6b7609c9674c3d0175868d7190293f1925d779b": "Ybodychange",
    "685cb83e4c3f433c5147e35217ce79ea520a0da5": "Ybodychange",
    "49b02d4a9bf9beac19f716488348ea4e30563ff4": "Ybodychange",
    "29b7df960fc3d0a7d1416225c3106c7d4222f0ca": "Ybodychange",
    "4a5819dae2b0ca8f8b6d94ef464882d079d86593": "Ybodychange",
    "193d27de0a5d23a61cabd41162ebc3292d8526d1": "Ybodychange",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": "Ybodychange",
    "6ee0539ede78b640f01c5eac18ded161182a7835": "Ybodychange",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": "Ybodychange",
    "892ade689f9bcce76daae8f66fc00a49bee8548e": "Ybodychange",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "8f378733423a5244461df79a92c00239514b8b93": "Ybodychange",
    "7947e5b53b9ac9524b535b0384c1c355b74723ff": "Ybodychange",
    "2cc9514ad643ae49d30524743420ee9744e571bd": "Ybodychange",
    "6ccf4fbf8a8374c289370f67b26ac05abad30ebc": "Ybodychange",
    "b80457158daf0dc712fbe5695625cc17d70d4bb4": "Ybodychange",
    "a16bfff71bd7f00e06e1f59bfe5445a154bb8c66": "Ymultichange(Ymovefromfile,Ybodychange)",
    "75ead273bea8a7dad61c4f99c3a16cab2697c498": "Ybodychange",
    "8234fd0e1087e0e49aa1d6f286f292b7f70b368e": "Ybodychange",
    "952640fa4cbdc23fe8781e5627c2e8eab565c535": "Ybodychange",
    "c4980a2f343778544ca20ebea1338651793ea0d9": "Ybodychange",
    "b9f6d0c956f0278c8b9b83e05b523a442a730ebb": "Ybodychange",
    "36ccf097a95eae0761de7b657752e4808a86c094": "Ybodychange",
    "1228f8f6fb16de4f0283dd1c7939e6fc3dfb7aae": "Ybodychange",
    "57b28693ee295746c6d168d37dd05eaf7b601b87": "Ybodychange",
    "ceea91c9cd8b2a18be13217894ccf1c17198de18": "Ybodychange",
    "631ccbdd2031a8387d4c2b743a4fc64c990391ce": "Ybodychange",
    "be7dd8333a7e56e732171db0781786987de03195": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d9c4f1129c0814ab61fce6ea8baf4b272f84c252": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15219. DFS Client will stuck when ResponseProcessor.run throw Error (#1902). Contributed by  zhengchenyu.\n\n",
      "commitDate": "24/03/20 10:47 AM",
      "commitName": "d9c4f1129c0814ab61fce6ea8baf4b272f84c252",
      "commitAuthor": "Isa Hekmatizadeh",
      "commitDateOld": "10/12/19 7:22 PM",
      "commitNameOld": "c2e9783d5f236015f2ad826fcbad061e2118e454",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 104.6,
      "commitsBetweenForRepo": 337,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,130 +1,130 @@\n     public void run() {\n \n       setName(\"ResponseProcessor for block \" + block);\n       PipelineAck ack \u003d new PipelineAck();\n \n       TraceScope scope \u003d null;\n       while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n         // process responses from datanodes.\n         try {\n           // read an ack from the pipeline\n           ack.readFields(blockReplyStream);\n           if (ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n             Long begin \u003d packetSendTime.get(ack.getSeqno());\n             if (begin !\u003d null) {\n               long duration \u003d Time.monotonicNow() - begin;\n               if (duration \u003e dfsclientSlowLogThresholdMs) {\n                 LOG.info(\"Slow ReadProcessor read fields for block \" + block\n                     + \" took \" + duration + \"ms (threshold\u003d\"\n                     + dfsclientSlowLogThresholdMs + \"ms); ack: \" + ack\n                     + \", targets: \" + Arrays.asList(targets));\n               }\n             }\n           }\n \n           LOG.debug(\"DFSClient {}\", ack);\n \n           long seqno \u003d ack.getSeqno();\n           // processes response status from datanodes.\n           ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n           for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n             final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getHeaderFlag(i));\n             if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                 PipelineAck.ECN.CONGESTED) {\n               congestedNodesFromAck.add(targets[i]);\n             }\n             // Restart will not be treated differently unless it is\n             // the local node or the only one in the pipeline.\n             if (PipelineAck.isRestartOOBStatus(reply)) {\n               final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                   + targets[i];\n               errorState.initRestartingNode(i, message,\n                   shouldWaitForRestart(i));\n               throw new IOException(message);\n             }\n             // node error\n             if (reply !\u003d SUCCESS) {\n               errorState.setBadNodeIndex(i); // mark bad datanode\n               throw new IOException(\"Bad response \" + reply +\n                   \" for \" + block + \" from datanode \" + targets[i]);\n             }\n           }\n \n           if (!congestedNodesFromAck.isEmpty()) {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               congestedNodes.addAll(congestedNodesFromAck);\n             }\n           } else {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               lastCongestionBackoffTime \u003d 0;\n             }\n           }\n \n           assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n           if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n             continue;\n           }\n \n           // a success ack for a data packet\n           DFSPacket one;\n           synchronized (dataQueue) {\n             one \u003d ackQueue.getFirst();\n           }\n           if (one.getSeqno() !\u003d seqno) {\n             throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                 one.getSeqno() + \" for block \" + block +\n                 \" but received \" + seqno);\n           }\n           isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n           // Fail the packet write for testing in order to force a\n           // pipeline recovery.\n           if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n               isLastPacketInBlock) {\n             failPacket \u003d true;\n             throw new IOException(\n                 \"Failing the last packet for testing.\");\n           }\n \n           // update bytesAcked\n           block.setNumBytes(one.getLastByteOffsetBlock());\n \n           synchronized (dataQueue) {\n             scope \u003d one.getTraceScope();\n             if (scope !\u003d null) {\n               scope.reattach();\n               one.setTraceScope(null);\n             }\n             lastAckedSeqno \u003d seqno;\n             pipelineRecoveryCount \u003d 0;\n             ackQueue.removeFirst();\n             packetSendTime.remove(seqno);\n             dataQueue.notifyAll();\n \n             one.releaseBuffer(byteArrayManager);\n           }\n-        } catch (Exception e) {\n+        } catch (Throwable e) {\n           if (!responderClosed) {\n             lastException.set(e);\n             errorState.setInternalError();\n             errorState.markFirstNodeIfNotMarked();\n             synchronized (dataQueue) {\n               dataQueue.notifyAll();\n             }\n             if (!errorState.isRestartingNode()) {\n               LOG.warn(\"Exception for \" + block, e);\n             }\n             responderClosed \u003d true;\n           }\n         } finally {\n           if (scope !\u003d null) {\n             scope.close();\n           }\n           scope \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d null;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          ack.readFields(blockReplyStream);\n          if (ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            Long begin \u003d packetSendTime.get(ack.getSeqno());\n            if (begin !\u003d null) {\n              long duration \u003d Time.monotonicNow() - begin;\n              if (duration \u003e dfsclientSlowLogThresholdMs) {\n                LOG.info(\"Slow ReadProcessor read fields for block \" + block\n                    + \" took \" + duration + \"ms (threshold\u003d\"\n                    + dfsclientSlowLogThresholdMs + \"ms); ack: \" + ack\n                    + \", targets: \" + Arrays.asList(targets));\n              }\n            }\n          }\n\n          LOG.debug(\"DFSClient {}\", ack);\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getHeaderFlag(i));\n            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                PipelineAck.ECN.CONGESTED) {\n              congestedNodesFromAck.add(targets[i]);\n            }\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply)) {\n              final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                  + targets[i];\n              errorState.initRestartingNode(i, message,\n                  shouldWaitForRestart(i));\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              errorState.setBadNodeIndex(i); // mark bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for \" + block + \" from datanode \" + targets[i]);\n            }\n          }\n\n          if (!congestedNodesFromAck.isEmpty()) {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              congestedNodes.addAll(congestedNodesFromAck);\n            }\n          } else {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              lastCongestionBackoffTime \u003d 0;\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                one.getSeqno() + \" for block \" + block +\n                \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d one.getTraceScope();\n            if (scope !\u003d null) {\n              scope.reattach();\n              one.setTraceScope(null);\n            }\n            lastAckedSeqno \u003d seqno;\n            pipelineRecoveryCount \u003d 0;\n            ackQueue.removeFirst();\n            packetSendTime.remove(seqno);\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Throwable e) {\n          if (!responderClosed) {\n            lastException.set(e);\n            errorState.setInternalError();\n            errorState.markFirstNodeIfNotMarked();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (!errorState.isRestartingNode()) {\n              LOG.warn(\"Exception for \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n          if (scope !\u003d null) {\n            scope.close();\n          }\n          scope \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {}
    },
    "d6b7609c9674c3d0175868d7190293f1925d779b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14453. Improve Bad Sequence Number Error Message. Contributed by Shweta.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "02/05/19 2:25 PM",
      "commitName": "d6b7609c9674c3d0175868d7190293f1925d779b",
      "commitAuthor": "Shweta",
      "commitDateOld": "17/04/19 10:38 AM",
      "commitNameOld": "685cb83e4c3f433c5147e35217ce79ea520a0da5",
      "commitAuthorOld": "lys0716",
      "daysBetweenCommits": 15.16,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,130 +1,130 @@\n     public void run() {\n \n       setName(\"ResponseProcessor for block \" + block);\n       PipelineAck ack \u003d new PipelineAck();\n \n       TraceScope scope \u003d null;\n       while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n         // process responses from datanodes.\n         try {\n           // read an ack from the pipeline\n           ack.readFields(blockReplyStream);\n           if (ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n             Long begin \u003d packetSendTime.get(ack.getSeqno());\n             if (begin !\u003d null) {\n               long duration \u003d Time.monotonicNow() - begin;\n               if (duration \u003e dfsclientSlowLogThresholdMs) {\n                 LOG.info(\"Slow ReadProcessor read fields for block \" + block\n                     + \" took \" + duration + \"ms (threshold\u003d\"\n                     + dfsclientSlowLogThresholdMs + \"ms); ack: \" + ack\n                     + \", targets: \" + Arrays.asList(targets));\n               }\n             }\n           }\n \n           LOG.debug(\"DFSClient {}\", ack);\n \n           long seqno \u003d ack.getSeqno();\n           // processes response status from datanodes.\n           ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n           for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n             final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getHeaderFlag(i));\n             if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                 PipelineAck.ECN.CONGESTED) {\n               congestedNodesFromAck.add(targets[i]);\n             }\n             // Restart will not be treated differently unless it is\n             // the local node or the only one in the pipeline.\n             if (PipelineAck.isRestartOOBStatus(reply)) {\n               final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                   + targets[i];\n               errorState.initRestartingNode(i, message,\n                   shouldWaitForRestart(i));\n               throw new IOException(message);\n             }\n             // node error\n             if (reply !\u003d SUCCESS) {\n               errorState.setBadNodeIndex(i); // mark bad datanode\n               throw new IOException(\"Bad response \" + reply +\n                   \" for \" + block + \" from datanode \" + targets[i]);\n             }\n           }\n \n           if (!congestedNodesFromAck.isEmpty()) {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               congestedNodes.addAll(congestedNodesFromAck);\n             }\n           } else {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               lastCongestionBackoffTime \u003d 0;\n             }\n           }\n \n           assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n           if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n             continue;\n           }\n \n           // a success ack for a data packet\n           DFSPacket one;\n           synchronized (dataQueue) {\n             one \u003d ackQueue.getFirst();\n           }\n           if (one.getSeqno() !\u003d seqno) {\n-            throw new IOException(\"ResponseProcessor: Expecting seqno\" +\n-                \" for block \" + block +\n-                one.getSeqno() + \" but received \" + seqno);\n+            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n+                one.getSeqno() + \" for block \" + block +\n+                \" but received \" + seqno);\n           }\n           isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n           // Fail the packet write for testing in order to force a\n           // pipeline recovery.\n           if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n               isLastPacketInBlock) {\n             failPacket \u003d true;\n             throw new IOException(\n                 \"Failing the last packet for testing.\");\n           }\n \n           // update bytesAcked\n           block.setNumBytes(one.getLastByteOffsetBlock());\n \n           synchronized (dataQueue) {\n             scope \u003d one.getTraceScope();\n             if (scope !\u003d null) {\n               scope.reattach();\n               one.setTraceScope(null);\n             }\n             lastAckedSeqno \u003d seqno;\n             pipelineRecoveryCount \u003d 0;\n             ackQueue.removeFirst();\n             packetSendTime.remove(seqno);\n             dataQueue.notifyAll();\n \n             one.releaseBuffer(byteArrayManager);\n           }\n         } catch (Exception e) {\n           if (!responderClosed) {\n             lastException.set(e);\n             errorState.setInternalError();\n             errorState.markFirstNodeIfNotMarked();\n             synchronized (dataQueue) {\n               dataQueue.notifyAll();\n             }\n             if (!errorState.isRestartingNode()) {\n               LOG.warn(\"Exception for \" + block, e);\n             }\n             responderClosed \u003d true;\n           }\n         } finally {\n           if (scope !\u003d null) {\n             scope.close();\n           }\n           scope \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d null;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          ack.readFields(blockReplyStream);\n          if (ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            Long begin \u003d packetSendTime.get(ack.getSeqno());\n            if (begin !\u003d null) {\n              long duration \u003d Time.monotonicNow() - begin;\n              if (duration \u003e dfsclientSlowLogThresholdMs) {\n                LOG.info(\"Slow ReadProcessor read fields for block \" + block\n                    + \" took \" + duration + \"ms (threshold\u003d\"\n                    + dfsclientSlowLogThresholdMs + \"ms); ack: \" + ack\n                    + \", targets: \" + Arrays.asList(targets));\n              }\n            }\n          }\n\n          LOG.debug(\"DFSClient {}\", ack);\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getHeaderFlag(i));\n            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                PipelineAck.ECN.CONGESTED) {\n              congestedNodesFromAck.add(targets[i]);\n            }\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply)) {\n              final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                  + targets[i];\n              errorState.initRestartingNode(i, message,\n                  shouldWaitForRestart(i));\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              errorState.setBadNodeIndex(i); // mark bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for \" + block + \" from datanode \" + targets[i]);\n            }\n          }\n\n          if (!congestedNodesFromAck.isEmpty()) {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              congestedNodes.addAll(congestedNodesFromAck);\n            }\n          } else {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              lastCongestionBackoffTime \u003d 0;\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                one.getSeqno() + \" for block \" + block +\n                \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d one.getTraceScope();\n            if (scope !\u003d null) {\n              scope.reattach();\n              one.setTraceScope(null);\n            }\n            lastAckedSeqno \u003d seqno;\n            pipelineRecoveryCount \u003d 0;\n            ackQueue.removeFirst();\n            packetSendTime.remove(seqno);\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            lastException.set(e);\n            errorState.setInternalError();\n            errorState.markFirstNodeIfNotMarked();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (!errorState.isRestartingNode()) {\n              LOG.warn(\"Exception for \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n          if (scope !\u003d null) {\n            scope.close();\n          }\n          scope \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {}
    },
    "685cb83e4c3f433c5147e35217ce79ea520a0da5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14433. Remove the extra empty space in the DataStreamer logging. Contributed by Yishuang Lu. (#747)\n\n",
      "commitDate": "17/04/19 10:38 AM",
      "commitName": "685cb83e4c3f433c5147e35217ce79ea520a0da5",
      "commitAuthor": "lys0716",
      "commitDateOld": "28/03/19 11:16 AM",
      "commitNameOld": "49b02d4a9bf9beac19f716488348ea4e30563ff4",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 19.97,
      "commitsBetweenForRepo": 157,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,130 +1,130 @@\n     public void run() {\n \n       setName(\"ResponseProcessor for block \" + block);\n       PipelineAck ack \u003d new PipelineAck();\n \n       TraceScope scope \u003d null;\n       while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n         // process responses from datanodes.\n         try {\n           // read an ack from the pipeline\n           ack.readFields(blockReplyStream);\n           if (ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n             Long begin \u003d packetSendTime.get(ack.getSeqno());\n             if (begin !\u003d null) {\n               long duration \u003d Time.monotonicNow() - begin;\n               if (duration \u003e dfsclientSlowLogThresholdMs) {\n                 LOG.info(\"Slow ReadProcessor read fields for block \" + block\n                     + \" took \" + duration + \"ms (threshold\u003d\"\n                     + dfsclientSlowLogThresholdMs + \"ms); ack: \" + ack\n                     + \", targets: \" + Arrays.asList(targets));\n               }\n             }\n           }\n \n           LOG.debug(\"DFSClient {}\", ack);\n \n           long seqno \u003d ack.getSeqno();\n           // processes response status from datanodes.\n           ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n           for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n             final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getHeaderFlag(i));\n             if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                 PipelineAck.ECN.CONGESTED) {\n               congestedNodesFromAck.add(targets[i]);\n             }\n             // Restart will not be treated differently unless it is\n             // the local node or the only one in the pipeline.\n             if (PipelineAck.isRestartOOBStatus(reply)) {\n               final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                   + targets[i];\n               errorState.initRestartingNode(i, message,\n                   shouldWaitForRestart(i));\n               throw new IOException(message);\n             }\n             // node error\n             if (reply !\u003d SUCCESS) {\n               errorState.setBadNodeIndex(i); // mark bad datanode\n               throw new IOException(\"Bad response \" + reply +\n                   \" for \" + block + \" from datanode \" + targets[i]);\n             }\n           }\n \n           if (!congestedNodesFromAck.isEmpty()) {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               congestedNodes.addAll(congestedNodesFromAck);\n             }\n           } else {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               lastCongestionBackoffTime \u003d 0;\n             }\n           }\n \n           assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n           if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n             continue;\n           }\n \n           // a success ack for a data packet\n           DFSPacket one;\n           synchronized (dataQueue) {\n             one \u003d ackQueue.getFirst();\n           }\n           if (one.getSeqno() !\u003d seqno) {\n-            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n+            throw new IOException(\"ResponseProcessor: Expecting seqno\" +\n                 \" for block \" + block +\n                 one.getSeqno() + \" but received \" + seqno);\n           }\n           isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n           // Fail the packet write for testing in order to force a\n           // pipeline recovery.\n           if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n               isLastPacketInBlock) {\n             failPacket \u003d true;\n             throw new IOException(\n                 \"Failing the last packet for testing.\");\n           }\n \n           // update bytesAcked\n           block.setNumBytes(one.getLastByteOffsetBlock());\n \n           synchronized (dataQueue) {\n             scope \u003d one.getTraceScope();\n             if (scope !\u003d null) {\n               scope.reattach();\n               one.setTraceScope(null);\n             }\n             lastAckedSeqno \u003d seqno;\n             pipelineRecoveryCount \u003d 0;\n             ackQueue.removeFirst();\n             packetSendTime.remove(seqno);\n             dataQueue.notifyAll();\n \n             one.releaseBuffer(byteArrayManager);\n           }\n         } catch (Exception e) {\n           if (!responderClosed) {\n             lastException.set(e);\n             errorState.setInternalError();\n             errorState.markFirstNodeIfNotMarked();\n             synchronized (dataQueue) {\n               dataQueue.notifyAll();\n             }\n             if (!errorState.isRestartingNode()) {\n               LOG.warn(\"Exception for \" + block, e);\n             }\n             responderClosed \u003d true;\n           }\n         } finally {\n           if (scope !\u003d null) {\n             scope.close();\n           }\n           scope \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d null;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          ack.readFields(blockReplyStream);\n          if (ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            Long begin \u003d packetSendTime.get(ack.getSeqno());\n            if (begin !\u003d null) {\n              long duration \u003d Time.monotonicNow() - begin;\n              if (duration \u003e dfsclientSlowLogThresholdMs) {\n                LOG.info(\"Slow ReadProcessor read fields for block \" + block\n                    + \" took \" + duration + \"ms (threshold\u003d\"\n                    + dfsclientSlowLogThresholdMs + \"ms); ack: \" + ack\n                    + \", targets: \" + Arrays.asList(targets));\n              }\n            }\n          }\n\n          LOG.debug(\"DFSClient {}\", ack);\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getHeaderFlag(i));\n            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                PipelineAck.ECN.CONGESTED) {\n              congestedNodesFromAck.add(targets[i]);\n            }\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply)) {\n              final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                  + targets[i];\n              errorState.initRestartingNode(i, message,\n                  shouldWaitForRestart(i));\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              errorState.setBadNodeIndex(i); // mark bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for \" + block + \" from datanode \" + targets[i]);\n            }\n          }\n\n          if (!congestedNodesFromAck.isEmpty()) {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              congestedNodes.addAll(congestedNodesFromAck);\n            }\n          } else {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              lastCongestionBackoffTime \u003d 0;\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno\" +\n                \" for block \" + block +\n                one.getSeqno() + \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d one.getTraceScope();\n            if (scope !\u003d null) {\n              scope.reattach();\n              one.setTraceScope(null);\n            }\n            lastAckedSeqno \u003d seqno;\n            pipelineRecoveryCount \u003d 0;\n            ackQueue.removeFirst();\n            packetSendTime.remove(seqno);\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            lastException.set(e);\n            errorState.setInternalError();\n            errorState.markFirstNodeIfNotMarked();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (!errorState.isRestartingNode()) {\n              LOG.warn(\"Exception for \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n          if (scope !\u003d null) {\n            scope.close();\n          }\n          scope \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {}
    },
    "49b02d4a9bf9beac19f716488348ea4e30563ff4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14395. Remove WARN Logging From Interrupts. Contributed by David Mollitor.\n",
      "commitDate": "28/03/19 11:16 AM",
      "commitName": "49b02d4a9bf9beac19f716488348ea4e30563ff4",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "06/11/18 11:18 AM",
      "commitNameOld": "887244de4adebe27693ed4ad3296a6f700cfa8c1",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 141.96,
      "commitsBetweenForRepo": 1021,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,132 +1,130 @@\n     public void run() {\n \n       setName(\"ResponseProcessor for block \" + block);\n       PipelineAck ack \u003d new PipelineAck();\n \n       TraceScope scope \u003d null;\n       while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n         // process responses from datanodes.\n         try {\n           // read an ack from the pipeline\n           ack.readFields(blockReplyStream);\n           if (ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n             Long begin \u003d packetSendTime.get(ack.getSeqno());\n             if (begin !\u003d null) {\n               long duration \u003d Time.monotonicNow() - begin;\n               if (duration \u003e dfsclientSlowLogThresholdMs) {\n                 LOG.info(\"Slow ReadProcessor read fields for block \" + block\n                     + \" took \" + duration + \"ms (threshold\u003d\"\n                     + dfsclientSlowLogThresholdMs + \"ms); ack: \" + ack\n                     + \", targets: \" + Arrays.asList(targets));\n               }\n             }\n           }\n \n-          if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"DFSClient {}\", ack);\n-          }\n+          LOG.debug(\"DFSClient {}\", ack);\n \n           long seqno \u003d ack.getSeqno();\n           // processes response status from datanodes.\n           ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n           for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n             final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getHeaderFlag(i));\n             if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                 PipelineAck.ECN.CONGESTED) {\n               congestedNodesFromAck.add(targets[i]);\n             }\n             // Restart will not be treated differently unless it is\n             // the local node or the only one in the pipeline.\n             if (PipelineAck.isRestartOOBStatus(reply)) {\n               final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                   + targets[i];\n               errorState.initRestartingNode(i, message,\n                   shouldWaitForRestart(i));\n               throw new IOException(message);\n             }\n             // node error\n             if (reply !\u003d SUCCESS) {\n               errorState.setBadNodeIndex(i); // mark bad datanode\n               throw new IOException(\"Bad response \" + reply +\n                   \" for \" + block + \" from datanode \" + targets[i]);\n             }\n           }\n \n           if (!congestedNodesFromAck.isEmpty()) {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               congestedNodes.addAll(congestedNodesFromAck);\n             }\n           } else {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               lastCongestionBackoffTime \u003d 0;\n             }\n           }\n \n           assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n           if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n             continue;\n           }\n \n           // a success ack for a data packet\n           DFSPacket one;\n           synchronized (dataQueue) {\n             one \u003d ackQueue.getFirst();\n           }\n           if (one.getSeqno() !\u003d seqno) {\n             throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                 \" for block \" + block +\n                 one.getSeqno() + \" but received \" + seqno);\n           }\n           isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n           // Fail the packet write for testing in order to force a\n           // pipeline recovery.\n           if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n               isLastPacketInBlock) {\n             failPacket \u003d true;\n             throw new IOException(\n                 \"Failing the last packet for testing.\");\n           }\n \n           // update bytesAcked\n           block.setNumBytes(one.getLastByteOffsetBlock());\n \n           synchronized (dataQueue) {\n             scope \u003d one.getTraceScope();\n             if (scope !\u003d null) {\n               scope.reattach();\n               one.setTraceScope(null);\n             }\n             lastAckedSeqno \u003d seqno;\n             pipelineRecoveryCount \u003d 0;\n             ackQueue.removeFirst();\n             packetSendTime.remove(seqno);\n             dataQueue.notifyAll();\n \n             one.releaseBuffer(byteArrayManager);\n           }\n         } catch (Exception e) {\n           if (!responderClosed) {\n             lastException.set(e);\n             errorState.setInternalError();\n             errorState.markFirstNodeIfNotMarked();\n             synchronized (dataQueue) {\n               dataQueue.notifyAll();\n             }\n             if (!errorState.isRestartingNode()) {\n               LOG.warn(\"Exception for \" + block, e);\n             }\n             responderClosed \u003d true;\n           }\n         } finally {\n           if (scope !\u003d null) {\n             scope.close();\n           }\n           scope \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d null;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          ack.readFields(blockReplyStream);\n          if (ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            Long begin \u003d packetSendTime.get(ack.getSeqno());\n            if (begin !\u003d null) {\n              long duration \u003d Time.monotonicNow() - begin;\n              if (duration \u003e dfsclientSlowLogThresholdMs) {\n                LOG.info(\"Slow ReadProcessor read fields for block \" + block\n                    + \" took \" + duration + \"ms (threshold\u003d\"\n                    + dfsclientSlowLogThresholdMs + \"ms); ack: \" + ack\n                    + \", targets: \" + Arrays.asList(targets));\n              }\n            }\n          }\n\n          LOG.debug(\"DFSClient {}\", ack);\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getHeaderFlag(i));\n            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                PipelineAck.ECN.CONGESTED) {\n              congestedNodesFromAck.add(targets[i]);\n            }\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply)) {\n              final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                  + targets[i];\n              errorState.initRestartingNode(i, message,\n                  shouldWaitForRestart(i));\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              errorState.setBadNodeIndex(i); // mark bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for \" + block + \" from datanode \" + targets[i]);\n            }\n          }\n\n          if (!congestedNodesFromAck.isEmpty()) {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              congestedNodes.addAll(congestedNodesFromAck);\n            }\n          } else {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              lastCongestionBackoffTime \u003d 0;\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                \" for block \" + block +\n                one.getSeqno() + \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d one.getTraceScope();\n            if (scope !\u003d null) {\n              scope.reattach();\n              one.setTraceScope(null);\n            }\n            lastAckedSeqno \u003d seqno;\n            pipelineRecoveryCount \u003d 0;\n            ackQueue.removeFirst();\n            packetSendTime.remove(seqno);\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            lastException.set(e);\n            errorState.setInternalError();\n            errorState.markFirstNodeIfNotMarked();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (!errorState.isRestartingNode()) {\n              LOG.warn(\"Exception for \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n          if (scope !\u003d null) {\n            scope.close();\n          }\n          scope \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {}
    },
    "29b7df960fc3d0a7d1416225c3106c7d4222f0ca": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11856. Ability to re-add Upgrading Nodes to pipeline for future pipeline updates. Contributed by Vinayakumar B.\n",
      "commitDate": "25/05/17 11:05 AM",
      "commitName": "29b7df960fc3d0a7d1416225c3106c7d4222f0ca",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "05/05/17 12:01 PM",
      "commitNameOld": "a3954ccab148bddc290cb96528e63ff19799bcc9",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 19.96,
      "commitsBetweenForRepo": 106,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,132 +1,132 @@\n     public void run() {\n \n       setName(\"ResponseProcessor for block \" + block);\n       PipelineAck ack \u003d new PipelineAck();\n \n       TraceScope scope \u003d null;\n       while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n         // process responses from datanodes.\n         try {\n           // read an ack from the pipeline\n           ack.readFields(blockReplyStream);\n           if (ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n             Long begin \u003d packetSendTime.get(ack.getSeqno());\n             if (begin !\u003d null) {\n               long duration \u003d Time.monotonicNow() - begin;\n               if (duration \u003e dfsclientSlowLogThresholdMs) {\n                 LOG.info(\"Slow ReadProcessor read fields for block \" + block\n                     + \" took \" + duration + \"ms (threshold\u003d\"\n                     + dfsclientSlowLogThresholdMs + \"ms); ack: \" + ack\n                     + \", targets: \" + Arrays.asList(targets));\n               }\n             }\n           }\n \n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\"DFSClient {}\", ack);\n           }\n \n           long seqno \u003d ack.getSeqno();\n           // processes response status from datanodes.\n           ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n           for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n             final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getHeaderFlag(i));\n             if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                 PipelineAck.ECN.CONGESTED) {\n               congestedNodesFromAck.add(targets[i]);\n             }\n             // Restart will not be treated differently unless it is\n             // the local node or the only one in the pipeline.\n-            if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n-                shouldWaitForRestart(i)) {\n+            if (PipelineAck.isRestartOOBStatus(reply)) {\n               final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                   + targets[i];\n-              errorState.initRestartingNode(i, message);\n+              errorState.initRestartingNode(i, message,\n+                  shouldWaitForRestart(i));\n               throw new IOException(message);\n             }\n             // node error\n             if (reply !\u003d SUCCESS) {\n               errorState.setBadNodeIndex(i); // mark bad datanode\n               throw new IOException(\"Bad response \" + reply +\n                   \" for \" + block + \" from datanode \" + targets[i]);\n             }\n           }\n \n           if (!congestedNodesFromAck.isEmpty()) {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               congestedNodes.addAll(congestedNodesFromAck);\n             }\n           } else {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               lastCongestionBackoffTime \u003d 0;\n             }\n           }\n \n           assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n           if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n             continue;\n           }\n \n           // a success ack for a data packet\n           DFSPacket one;\n           synchronized (dataQueue) {\n             one \u003d ackQueue.getFirst();\n           }\n           if (one.getSeqno() !\u003d seqno) {\n             throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                 \" for block \" + block +\n                 one.getSeqno() + \" but received \" + seqno);\n           }\n           isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n           // Fail the packet write for testing in order to force a\n           // pipeline recovery.\n           if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n               isLastPacketInBlock) {\n             failPacket \u003d true;\n             throw new IOException(\n                 \"Failing the last packet for testing.\");\n           }\n \n           // update bytesAcked\n           block.setNumBytes(one.getLastByteOffsetBlock());\n \n           synchronized (dataQueue) {\n             scope \u003d one.getTraceScope();\n             if (scope !\u003d null) {\n               scope.reattach();\n               one.setTraceScope(null);\n             }\n             lastAckedSeqno \u003d seqno;\n             pipelineRecoveryCount \u003d 0;\n             ackQueue.removeFirst();\n             packetSendTime.remove(seqno);\n             dataQueue.notifyAll();\n \n             one.releaseBuffer(byteArrayManager);\n           }\n         } catch (Exception e) {\n           if (!responderClosed) {\n             lastException.set(e);\n             errorState.setInternalError();\n             errorState.markFirstNodeIfNotMarked();\n             synchronized (dataQueue) {\n               dataQueue.notifyAll();\n             }\n             if (!errorState.isRestartingNode()) {\n               LOG.warn(\"Exception for \" + block, e);\n             }\n             responderClosed \u003d true;\n           }\n         } finally {\n           if (scope !\u003d null) {\n             scope.close();\n           }\n           scope \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d null;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          ack.readFields(blockReplyStream);\n          if (ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            Long begin \u003d packetSendTime.get(ack.getSeqno());\n            if (begin !\u003d null) {\n              long duration \u003d Time.monotonicNow() - begin;\n              if (duration \u003e dfsclientSlowLogThresholdMs) {\n                LOG.info(\"Slow ReadProcessor read fields for block \" + block\n                    + \" took \" + duration + \"ms (threshold\u003d\"\n                    + dfsclientSlowLogThresholdMs + \"ms); ack: \" + ack\n                    + \", targets: \" + Arrays.asList(targets));\n              }\n            }\n          }\n\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"DFSClient {}\", ack);\n          }\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getHeaderFlag(i));\n            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                PipelineAck.ECN.CONGESTED) {\n              congestedNodesFromAck.add(targets[i]);\n            }\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply)) {\n              final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                  + targets[i];\n              errorState.initRestartingNode(i, message,\n                  shouldWaitForRestart(i));\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              errorState.setBadNodeIndex(i); // mark bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for \" + block + \" from datanode \" + targets[i]);\n            }\n          }\n\n          if (!congestedNodesFromAck.isEmpty()) {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              congestedNodes.addAll(congestedNodesFromAck);\n            }\n          } else {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              lastCongestionBackoffTime \u003d 0;\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                \" for block \" + block +\n                one.getSeqno() + \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d one.getTraceScope();\n            if (scope !\u003d null) {\n              scope.reattach();\n              one.setTraceScope(null);\n            }\n            lastAckedSeqno \u003d seqno;\n            pipelineRecoveryCount \u003d 0;\n            ackQueue.removeFirst();\n            packetSendTime.remove(seqno);\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            lastException.set(e);\n            errorState.setInternalError();\n            errorState.markFirstNodeIfNotMarked();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (!errorState.isRestartingNode()) {\n              LOG.warn(\"Exception for \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n          if (scope !\u003d null) {\n            scope.close();\n          }\n          scope \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {}
    },
    "4a5819dae2b0ca8f8b6d94ef464882d079d86593": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10303. DataStreamer#ResponseProcessor calculates packet ack latency incorrectly. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "17/05/16 6:53 AM",
      "commitName": "4a5819dae2b0ca8f8b6d94ef464882d079d86593",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "27/04/16 2:22 PM",
      "commitNameOld": "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 19.69,
      "commitsBetweenForRepo": 119,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,125 +1,132 @@\n     public void run() {\n \n       setName(\"ResponseProcessor for block \" + block);\n       PipelineAck ack \u003d new PipelineAck();\n \n       TraceScope scope \u003d null;\n       while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n         // process responses from datanodes.\n         try {\n           // read an ack from the pipeline\n-          long begin \u003d Time.monotonicNow();\n           ack.readFields(blockReplyStream);\n-          long duration \u003d Time.monotonicNow() - begin;\n-          if (duration \u003e dfsclientSlowLogThresholdMs\n-              \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n-            LOG.warn(\"Slow ReadProcessor read fields took \" + duration\n-                + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n-                + ack + \", targets: \" + Arrays.asList(targets));\n-          } else {\n+          if (ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n+            Long begin \u003d packetSendTime.get(ack.getSeqno());\n+            if (begin !\u003d null) {\n+              long duration \u003d Time.monotonicNow() - begin;\n+              if (duration \u003e dfsclientSlowLogThresholdMs) {\n+                LOG.info(\"Slow ReadProcessor read fields for block \" + block\n+                    + \" took \" + duration + \"ms (threshold\u003d\"\n+                    + dfsclientSlowLogThresholdMs + \"ms); ack: \" + ack\n+                    + \", targets: \" + Arrays.asList(targets));\n+              }\n+            }\n+          }\n+\n+          if (LOG.isDebugEnabled()) {\n             LOG.debug(\"DFSClient {}\", ack);\n           }\n \n           long seqno \u003d ack.getSeqno();\n           // processes response status from datanodes.\n           ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n           for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n             final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getHeaderFlag(i));\n             if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                 PipelineAck.ECN.CONGESTED) {\n               congestedNodesFromAck.add(targets[i]);\n             }\n             // Restart will not be treated differently unless it is\n             // the local node or the only one in the pipeline.\n             if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                 shouldWaitForRestart(i)) {\n               final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                   + targets[i];\n               errorState.initRestartingNode(i, message);\n               throw new IOException(message);\n             }\n             // node error\n             if (reply !\u003d SUCCESS) {\n               errorState.setBadNodeIndex(i); // mark bad datanode\n               throw new IOException(\"Bad response \" + reply +\n                   \" for \" + block + \" from datanode \" + targets[i]);\n             }\n           }\n \n           if (!congestedNodesFromAck.isEmpty()) {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               congestedNodes.addAll(congestedNodesFromAck);\n             }\n           } else {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               lastCongestionBackoffTime \u003d 0;\n             }\n           }\n \n           assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n           if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n             continue;\n           }\n \n           // a success ack for a data packet\n           DFSPacket one;\n           synchronized (dataQueue) {\n             one \u003d ackQueue.getFirst();\n           }\n           if (one.getSeqno() !\u003d seqno) {\n             throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                 \" for block \" + block +\n                 one.getSeqno() + \" but received \" + seqno);\n           }\n           isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n           // Fail the packet write for testing in order to force a\n           // pipeline recovery.\n           if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n               isLastPacketInBlock) {\n             failPacket \u003d true;\n             throw new IOException(\n                 \"Failing the last packet for testing.\");\n           }\n \n           // update bytesAcked\n           block.setNumBytes(one.getLastByteOffsetBlock());\n \n           synchronized (dataQueue) {\n             scope \u003d one.getTraceScope();\n             if (scope !\u003d null) {\n               scope.reattach();\n               one.setTraceScope(null);\n             }\n             lastAckedSeqno \u003d seqno;\n             pipelineRecoveryCount \u003d 0;\n             ackQueue.removeFirst();\n+            packetSendTime.remove(seqno);\n             dataQueue.notifyAll();\n \n             one.releaseBuffer(byteArrayManager);\n           }\n         } catch (Exception e) {\n           if (!responderClosed) {\n             lastException.set(e);\n             errorState.setInternalError();\n             errorState.markFirstNodeIfNotMarked();\n             synchronized (dataQueue) {\n               dataQueue.notifyAll();\n             }\n             if (!errorState.isRestartingNode()) {\n               LOG.warn(\"Exception for \" + block, e);\n             }\n             responderClosed \u003d true;\n           }\n         } finally {\n           if (scope !\u003d null) {\n             scope.close();\n           }\n           scope \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d null;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          ack.readFields(blockReplyStream);\n          if (ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            Long begin \u003d packetSendTime.get(ack.getSeqno());\n            if (begin !\u003d null) {\n              long duration \u003d Time.monotonicNow() - begin;\n              if (duration \u003e dfsclientSlowLogThresholdMs) {\n                LOG.info(\"Slow ReadProcessor read fields for block \" + block\n                    + \" took \" + duration + \"ms (threshold\u003d\"\n                    + dfsclientSlowLogThresholdMs + \"ms); ack: \" + ack\n                    + \", targets: \" + Arrays.asList(targets));\n              }\n            }\n          }\n\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"DFSClient {}\", ack);\n          }\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getHeaderFlag(i));\n            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                PipelineAck.ECN.CONGESTED) {\n              congestedNodesFromAck.add(targets[i]);\n            }\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                shouldWaitForRestart(i)) {\n              final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                  + targets[i];\n              errorState.initRestartingNode(i, message);\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              errorState.setBadNodeIndex(i); // mark bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for \" + block + \" from datanode \" + targets[i]);\n            }\n          }\n\n          if (!congestedNodesFromAck.isEmpty()) {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              congestedNodes.addAll(congestedNodesFromAck);\n            }\n          } else {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              lastCongestionBackoffTime \u003d 0;\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                \" for block \" + block +\n                one.getSeqno() + \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d one.getTraceScope();\n            if (scope !\u003d null) {\n              scope.reattach();\n              one.setTraceScope(null);\n            }\n            lastAckedSeqno \u003d seqno;\n            pipelineRecoveryCount \u003d 0;\n            ackQueue.removeFirst();\n            packetSendTime.remove(seqno);\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            lastException.set(e);\n            errorState.setInternalError();\n            errorState.markFirstNodeIfNotMarked();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (!errorState.isRestartingNode()) {\n              LOG.warn(\"Exception for \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n          if (scope !\u003d null) {\n            scope.close();\n          }\n          scope \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {}
    },
    "193d27de0a5d23a61cabd41162ebc3292d8526d1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9752. Permanent write failures may happen to slow writers during datanode rolling upgrades. Contributed by Walter Su.\n",
      "commitDate": "08/02/16 10:16 AM",
      "commitName": "193d27de0a5d23a61cabd41162ebc3292d8526d1",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "25/01/16 6:32 PM",
      "commitNameOld": "bd909ed9f2d853f614f04a50e2230a7932732776",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 13.66,
      "commitsBetweenForRepo": 92,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,124 +1,125 @@\n     public void run() {\n \n       setName(\"ResponseProcessor for block \" + block);\n       PipelineAck ack \u003d new PipelineAck();\n \n       TraceScope scope \u003d null;\n       while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n         // process responses from datanodes.\n         try {\n           // read an ack from the pipeline\n           long begin \u003d Time.monotonicNow();\n           ack.readFields(blockReplyStream);\n           long duration \u003d Time.monotonicNow() - begin;\n           if (duration \u003e dfsclientSlowLogThresholdMs\n               \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n             LOG.warn(\"Slow ReadProcessor read fields took \" + duration\n                 + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                 + ack + \", targets: \" + Arrays.asList(targets));\n           } else {\n             LOG.debug(\"DFSClient {}\", ack);\n           }\n \n           long seqno \u003d ack.getSeqno();\n           // processes response status from datanodes.\n           ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n           for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n             final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getHeaderFlag(i));\n             if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                 PipelineAck.ECN.CONGESTED) {\n               congestedNodesFromAck.add(targets[i]);\n             }\n             // Restart will not be treated differently unless it is\n             // the local node or the only one in the pipeline.\n             if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                 shouldWaitForRestart(i)) {\n               final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                   + targets[i];\n               errorState.initRestartingNode(i, message);\n               throw new IOException(message);\n             }\n             // node error\n             if (reply !\u003d SUCCESS) {\n               errorState.setBadNodeIndex(i); // mark bad datanode\n               throw new IOException(\"Bad response \" + reply +\n                   \" for \" + block + \" from datanode \" + targets[i]);\n             }\n           }\n \n           if (!congestedNodesFromAck.isEmpty()) {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               congestedNodes.addAll(congestedNodesFromAck);\n             }\n           } else {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               lastCongestionBackoffTime \u003d 0;\n             }\n           }\n \n           assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n           if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n             continue;\n           }\n \n           // a success ack for a data packet\n           DFSPacket one;\n           synchronized (dataQueue) {\n             one \u003d ackQueue.getFirst();\n           }\n           if (one.getSeqno() !\u003d seqno) {\n             throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                 \" for block \" + block +\n                 one.getSeqno() + \" but received \" + seqno);\n           }\n           isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n           // Fail the packet write for testing in order to force a\n           // pipeline recovery.\n           if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n               isLastPacketInBlock) {\n             failPacket \u003d true;\n             throw new IOException(\n                 \"Failing the last packet for testing.\");\n           }\n \n           // update bytesAcked\n           block.setNumBytes(one.getLastByteOffsetBlock());\n \n           synchronized (dataQueue) {\n             scope \u003d one.getTraceScope();\n             if (scope !\u003d null) {\n               scope.reattach();\n               one.setTraceScope(null);\n             }\n             lastAckedSeqno \u003d seqno;\n+            pipelineRecoveryCount \u003d 0;\n             ackQueue.removeFirst();\n             dataQueue.notifyAll();\n \n             one.releaseBuffer(byteArrayManager);\n           }\n         } catch (Exception e) {\n           if (!responderClosed) {\n             lastException.set(e);\n             errorState.setInternalError();\n             errorState.markFirstNodeIfNotMarked();\n             synchronized (dataQueue) {\n               dataQueue.notifyAll();\n             }\n             if (!errorState.isRestartingNode()) {\n               LOG.warn(\"Exception for \" + block, e);\n             }\n             responderClosed \u003d true;\n           }\n         } finally {\n           if (scope !\u003d null) {\n             scope.close();\n           }\n           scope \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d null;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          long begin \u003d Time.monotonicNow();\n          ack.readFields(blockReplyStream);\n          long duration \u003d Time.monotonicNow() - begin;\n          if (duration \u003e dfsclientSlowLogThresholdMs\n              \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            LOG.warn(\"Slow ReadProcessor read fields took \" + duration\n                + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                + ack + \", targets: \" + Arrays.asList(targets));\n          } else {\n            LOG.debug(\"DFSClient {}\", ack);\n          }\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getHeaderFlag(i));\n            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                PipelineAck.ECN.CONGESTED) {\n              congestedNodesFromAck.add(targets[i]);\n            }\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                shouldWaitForRestart(i)) {\n              final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                  + targets[i];\n              errorState.initRestartingNode(i, message);\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              errorState.setBadNodeIndex(i); // mark bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for \" + block + \" from datanode \" + targets[i]);\n            }\n          }\n\n          if (!congestedNodesFromAck.isEmpty()) {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              congestedNodes.addAll(congestedNodesFromAck);\n            }\n          } else {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              lastCongestionBackoffTime \u003d 0;\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                \" for block \" + block +\n                one.getSeqno() + \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d one.getTraceScope();\n            if (scope !\u003d null) {\n              scope.reattach();\n              one.setTraceScope(null);\n            }\n            lastAckedSeqno \u003d seqno;\n            pipelineRecoveryCount \u003d 0;\n            ackQueue.removeFirst();\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            lastException.set(e);\n            errorState.setInternalError();\n            errorState.markFirstNodeIfNotMarked();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (!errorState.isRestartingNode()) {\n              LOG.warn(\"Exception for \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n          if (scope !\u003d null) {\n            scope.close();\n          }\n          scope \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {}
    },
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8971. Remove guards when calling LOG.debug() and LOG.trace() in client package. Contributed by Mingliang Liu.\n",
      "commitDate": "29/09/15 5:52 PM",
      "commitName": "39285e6a1978ea5e53bdc1b0aef62421382124a8",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:51 PM",
      "commitNameOld": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,124 +1,124 @@\n     public void run() {\n \n       setName(\"ResponseProcessor for block \" + block);\n       PipelineAck ack \u003d new PipelineAck();\n \n       TraceScope scope \u003d null;\n       while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n         // process responses from datanodes.\n         try {\n           // read an ack from the pipeline\n           long begin \u003d Time.monotonicNow();\n           ack.readFields(blockReplyStream);\n           long duration \u003d Time.monotonicNow() - begin;\n           if (duration \u003e dfsclientSlowLogThresholdMs\n               \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n             LOG.warn(\"Slow ReadProcessor read fields took \" + duration\n                 + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                 + ack + \", targets: \" + Arrays.asList(targets));\n-          } else if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"DFSClient \" + ack);\n+          } else {\n+            LOG.debug(\"DFSClient {}\", ack);\n           }\n \n           long seqno \u003d ack.getSeqno();\n           // processes response status from datanodes.\n           ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n           for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n             final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getHeaderFlag(i));\n             if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                 PipelineAck.ECN.CONGESTED) {\n               congestedNodesFromAck.add(targets[i]);\n             }\n             // Restart will not be treated differently unless it is\n             // the local node or the only one in the pipeline.\n             if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                 shouldWaitForRestart(i)) {\n               final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                   + targets[i];\n               errorState.initRestartingNode(i, message);\n               throw new IOException(message);\n             }\n             // node error\n             if (reply !\u003d SUCCESS) {\n               errorState.setBadNodeIndex(i); // mark bad datanode\n               throw new IOException(\"Bad response \" + reply +\n                   \" for \" + block + \" from datanode \" + targets[i]);\n             }\n           }\n \n           if (!congestedNodesFromAck.isEmpty()) {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               congestedNodes.addAll(congestedNodesFromAck);\n             }\n           } else {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               lastCongestionBackoffTime \u003d 0;\n             }\n           }\n \n           assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n           if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n             continue;\n           }\n \n           // a success ack for a data packet\n           DFSPacket one;\n           synchronized (dataQueue) {\n             one \u003d ackQueue.getFirst();\n           }\n           if (one.getSeqno() !\u003d seqno) {\n             throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                 \" for block \" + block +\n                 one.getSeqno() + \" but received \" + seqno);\n           }\n           isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n           // Fail the packet write for testing in order to force a\n           // pipeline recovery.\n           if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n               isLastPacketInBlock) {\n             failPacket \u003d true;\n             throw new IOException(\n                 \"Failing the last packet for testing.\");\n           }\n \n           // update bytesAcked\n           block.setNumBytes(one.getLastByteOffsetBlock());\n \n           synchronized (dataQueue) {\n             scope \u003d one.getTraceScope();\n             if (scope !\u003d null) {\n               scope.reattach();\n               one.setTraceScope(null);\n             }\n             lastAckedSeqno \u003d seqno;\n             ackQueue.removeFirst();\n             dataQueue.notifyAll();\n \n             one.releaseBuffer(byteArrayManager);\n           }\n         } catch (Exception e) {\n           if (!responderClosed) {\n             lastException.set(e);\n             errorState.setError(true);\n             errorState.markFirstNodeIfNotMarked();\n             synchronized (dataQueue) {\n               dataQueue.notifyAll();\n             }\n             if (!errorState.isRestartingNode()) {\n               LOG.warn(\"Exception for \" + block, e);\n             }\n             responderClosed \u003d true;\n           }\n         } finally {\n           if (scope !\u003d null) {\n             scope.close();\n           }\n           scope \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d null;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          long begin \u003d Time.monotonicNow();\n          ack.readFields(blockReplyStream);\n          long duration \u003d Time.monotonicNow() - begin;\n          if (duration \u003e dfsclientSlowLogThresholdMs\n              \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            LOG.warn(\"Slow ReadProcessor read fields took \" + duration\n                + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                + ack + \", targets: \" + Arrays.asList(targets));\n          } else {\n            LOG.debug(\"DFSClient {}\", ack);\n          }\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getHeaderFlag(i));\n            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                PipelineAck.ECN.CONGESTED) {\n              congestedNodesFromAck.add(targets[i]);\n            }\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                shouldWaitForRestart(i)) {\n              final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                  + targets[i];\n              errorState.initRestartingNode(i, message);\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              errorState.setBadNodeIndex(i); // mark bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for \" + block + \" from datanode \" + targets[i]);\n            }\n          }\n\n          if (!congestedNodesFromAck.isEmpty()) {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              congestedNodes.addAll(congestedNodesFromAck);\n            }\n          } else {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              lastCongestionBackoffTime \u003d 0;\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                \" for block \" + block +\n                one.getSeqno() + \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d one.getTraceScope();\n            if (scope !\u003d null) {\n              scope.reattach();\n              one.setTraceScope(null);\n            }\n            lastAckedSeqno \u003d seqno;\n            ackQueue.removeFirst();\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            lastException.set(e);\n            errorState.setError(true);\n            errorState.markFirstNodeIfNotMarked();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (!errorState.isRestartingNode()) {\n              LOG.warn(\"Exception for \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n          if (scope !\u003d null) {\n            scope.close();\n          }\n          scope \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {}
    },
    "6ee0539ede78b640f01c5eac18ded161182a7835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\"\n\nThis reverts commit d5a9a3daa0224249221ffa7b8bd5751ab2feca56.\n",
      "commitDate": "29/09/15 5:51 PM",
      "commitName": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:48 PM",
      "commitNameOld": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,124 +1,124 @@\n     public void run() {\n \n       setName(\"ResponseProcessor for block \" + block);\n       PipelineAck ack \u003d new PipelineAck();\n \n       TraceScope scope \u003d null;\n       while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n         // process responses from datanodes.\n         try {\n           // read an ack from the pipeline\n           long begin \u003d Time.monotonicNow();\n           ack.readFields(blockReplyStream);\n           long duration \u003d Time.monotonicNow() - begin;\n           if (duration \u003e dfsclientSlowLogThresholdMs\n               \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n             LOG.warn(\"Slow ReadProcessor read fields took \" + duration\n                 + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                 + ack + \", targets: \" + Arrays.asList(targets));\n-          } else {\n-            LOG.debug(\"DFSClient {}\", ack);\n+          } else if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"DFSClient \" + ack);\n           }\n \n           long seqno \u003d ack.getSeqno();\n           // processes response status from datanodes.\n           ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n           for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n             final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getHeaderFlag(i));\n             if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                 PipelineAck.ECN.CONGESTED) {\n               congestedNodesFromAck.add(targets[i]);\n             }\n             // Restart will not be treated differently unless it is\n             // the local node or the only one in the pipeline.\n             if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                 shouldWaitForRestart(i)) {\n               final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                   + targets[i];\n               errorState.initRestartingNode(i, message);\n               throw new IOException(message);\n             }\n             // node error\n             if (reply !\u003d SUCCESS) {\n               errorState.setBadNodeIndex(i); // mark bad datanode\n               throw new IOException(\"Bad response \" + reply +\n                   \" for \" + block + \" from datanode \" + targets[i]);\n             }\n           }\n \n           if (!congestedNodesFromAck.isEmpty()) {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               congestedNodes.addAll(congestedNodesFromAck);\n             }\n           } else {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               lastCongestionBackoffTime \u003d 0;\n             }\n           }\n \n           assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n           if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n             continue;\n           }\n \n           // a success ack for a data packet\n           DFSPacket one;\n           synchronized (dataQueue) {\n             one \u003d ackQueue.getFirst();\n           }\n           if (one.getSeqno() !\u003d seqno) {\n             throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                 \" for block \" + block +\n                 one.getSeqno() + \" but received \" + seqno);\n           }\n           isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n           // Fail the packet write for testing in order to force a\n           // pipeline recovery.\n           if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n               isLastPacketInBlock) {\n             failPacket \u003d true;\n             throw new IOException(\n                 \"Failing the last packet for testing.\");\n           }\n \n           // update bytesAcked\n           block.setNumBytes(one.getLastByteOffsetBlock());\n \n           synchronized (dataQueue) {\n             scope \u003d one.getTraceScope();\n             if (scope !\u003d null) {\n               scope.reattach();\n               one.setTraceScope(null);\n             }\n             lastAckedSeqno \u003d seqno;\n             ackQueue.removeFirst();\n             dataQueue.notifyAll();\n \n             one.releaseBuffer(byteArrayManager);\n           }\n         } catch (Exception e) {\n           if (!responderClosed) {\n             lastException.set(e);\n             errorState.setError(true);\n             errorState.markFirstNodeIfNotMarked();\n             synchronized (dataQueue) {\n               dataQueue.notifyAll();\n             }\n             if (!errorState.isRestartingNode()) {\n               LOG.warn(\"Exception for \" + block, e);\n             }\n             responderClosed \u003d true;\n           }\n         } finally {\n           if (scope !\u003d null) {\n             scope.close();\n           }\n           scope \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d null;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          long begin \u003d Time.monotonicNow();\n          ack.readFields(blockReplyStream);\n          long duration \u003d Time.monotonicNow() - begin;\n          if (duration \u003e dfsclientSlowLogThresholdMs\n              \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            LOG.warn(\"Slow ReadProcessor read fields took \" + duration\n                + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                + ack + \", targets: \" + Arrays.asList(targets));\n          } else if (LOG.isDebugEnabled()) {\n            LOG.debug(\"DFSClient \" + ack);\n          }\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getHeaderFlag(i));\n            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                PipelineAck.ECN.CONGESTED) {\n              congestedNodesFromAck.add(targets[i]);\n            }\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                shouldWaitForRestart(i)) {\n              final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                  + targets[i];\n              errorState.initRestartingNode(i, message);\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              errorState.setBadNodeIndex(i); // mark bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for \" + block + \" from datanode \" + targets[i]);\n            }\n          }\n\n          if (!congestedNodesFromAck.isEmpty()) {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              congestedNodes.addAll(congestedNodesFromAck);\n            }\n          } else {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              lastCongestionBackoffTime \u003d 0;\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                \" for block \" + block +\n                one.getSeqno() + \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d one.getTraceScope();\n            if (scope !\u003d null) {\n              scope.reattach();\n              one.setTraceScope(null);\n            }\n            lastAckedSeqno \u003d seqno;\n            ackQueue.removeFirst();\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            lastException.set(e);\n            errorState.setError(true);\n            errorState.markFirstNodeIfNotMarked();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (!errorState.isRestartingNode()) {\n              LOG.warn(\"Exception for \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n          if (scope !\u003d null) {\n            scope.close();\n          }\n          scope \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {}
    },
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "29/09/15 5:48 PM",
      "commitName": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/09/15 11:29 AM",
      "commitNameOld": "4c9497cbf02ecc82532a4e79e18912d8e0eb4731",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 1.26,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,124 +1,124 @@\n     public void run() {\n \n       setName(\"ResponseProcessor for block \" + block);\n       PipelineAck ack \u003d new PipelineAck();\n \n       TraceScope scope \u003d null;\n       while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n         // process responses from datanodes.\n         try {\n           // read an ack from the pipeline\n           long begin \u003d Time.monotonicNow();\n           ack.readFields(blockReplyStream);\n           long duration \u003d Time.monotonicNow() - begin;\n           if (duration \u003e dfsclientSlowLogThresholdMs\n               \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n             LOG.warn(\"Slow ReadProcessor read fields took \" + duration\n                 + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                 + ack + \", targets: \" + Arrays.asList(targets));\n-          } else if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"DFSClient \" + ack);\n+          } else {\n+            LOG.debug(\"DFSClient {}\", ack);\n           }\n \n           long seqno \u003d ack.getSeqno();\n           // processes response status from datanodes.\n           ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n           for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n             final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getHeaderFlag(i));\n             if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                 PipelineAck.ECN.CONGESTED) {\n               congestedNodesFromAck.add(targets[i]);\n             }\n             // Restart will not be treated differently unless it is\n             // the local node or the only one in the pipeline.\n             if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                 shouldWaitForRestart(i)) {\n               final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                   + targets[i];\n               errorState.initRestartingNode(i, message);\n               throw new IOException(message);\n             }\n             // node error\n             if (reply !\u003d SUCCESS) {\n               errorState.setBadNodeIndex(i); // mark bad datanode\n               throw new IOException(\"Bad response \" + reply +\n                   \" for \" + block + \" from datanode \" + targets[i]);\n             }\n           }\n \n           if (!congestedNodesFromAck.isEmpty()) {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               congestedNodes.addAll(congestedNodesFromAck);\n             }\n           } else {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               lastCongestionBackoffTime \u003d 0;\n             }\n           }\n \n           assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n           if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n             continue;\n           }\n \n           // a success ack for a data packet\n           DFSPacket one;\n           synchronized (dataQueue) {\n             one \u003d ackQueue.getFirst();\n           }\n           if (one.getSeqno() !\u003d seqno) {\n             throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                 \" for block \" + block +\n                 one.getSeqno() + \" but received \" + seqno);\n           }\n           isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n           // Fail the packet write for testing in order to force a\n           // pipeline recovery.\n           if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n               isLastPacketInBlock) {\n             failPacket \u003d true;\n             throw new IOException(\n                 \"Failing the last packet for testing.\");\n           }\n \n           // update bytesAcked\n           block.setNumBytes(one.getLastByteOffsetBlock());\n \n           synchronized (dataQueue) {\n             scope \u003d one.getTraceScope();\n             if (scope !\u003d null) {\n               scope.reattach();\n               one.setTraceScope(null);\n             }\n             lastAckedSeqno \u003d seqno;\n             ackQueue.removeFirst();\n             dataQueue.notifyAll();\n \n             one.releaseBuffer(byteArrayManager);\n           }\n         } catch (Exception e) {\n           if (!responderClosed) {\n             lastException.set(e);\n             errorState.setError(true);\n             errorState.markFirstNodeIfNotMarked();\n             synchronized (dataQueue) {\n               dataQueue.notifyAll();\n             }\n             if (!errorState.isRestartingNode()) {\n               LOG.warn(\"Exception for \" + block, e);\n             }\n             responderClosed \u003d true;\n           }\n         } finally {\n           if (scope !\u003d null) {\n             scope.close();\n           }\n           scope \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d null;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          long begin \u003d Time.monotonicNow();\n          ack.readFields(blockReplyStream);\n          long duration \u003d Time.monotonicNow() - begin;\n          if (duration \u003e dfsclientSlowLogThresholdMs\n              \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            LOG.warn(\"Slow ReadProcessor read fields took \" + duration\n                + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                + ack + \", targets: \" + Arrays.asList(targets));\n          } else {\n            LOG.debug(\"DFSClient {}\", ack);\n          }\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getHeaderFlag(i));\n            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                PipelineAck.ECN.CONGESTED) {\n              congestedNodesFromAck.add(targets[i]);\n            }\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                shouldWaitForRestart(i)) {\n              final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                  + targets[i];\n              errorState.initRestartingNode(i, message);\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              errorState.setBadNodeIndex(i); // mark bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for \" + block + \" from datanode \" + targets[i]);\n            }\n          }\n\n          if (!congestedNodesFromAck.isEmpty()) {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              congestedNodes.addAll(congestedNodesFromAck);\n            }\n          } else {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              lastCongestionBackoffTime \u003d 0;\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                \" for block \" + block +\n                one.getSeqno() + \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d one.getTraceScope();\n            if (scope !\u003d null) {\n              scope.reattach();\n              one.setTraceScope(null);\n            }\n            lastAckedSeqno \u003d seqno;\n            ackQueue.removeFirst();\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            lastException.set(e);\n            errorState.setError(true);\n            errorState.markFirstNodeIfNotMarked();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (!errorState.isRestartingNode()) {\n              LOG.warn(\"Exception for \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n          if (scope !\u003d null) {\n            scope.close();\n          }\n          scope \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {}
    },
    "892ade689f9bcce76daae8f66fc00a49bee8548e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9080. Update htrace version to 4.0.1 (cmccabe)\n",
      "commitDate": "28/09/15 7:42 AM",
      "commitName": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "26/09/15 11:08 AM",
      "commitNameOld": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 1.86,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,118 +1,124 @@\n     public void run() {\n \n       setName(\"ResponseProcessor for block \" + block);\n       PipelineAck ack \u003d new PipelineAck();\n \n-      TraceScope scope \u003d NullScope.INSTANCE;\n+      TraceScope scope \u003d null;\n       while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n         // process responses from datanodes.\n         try {\n           // read an ack from the pipeline\n           long begin \u003d Time.monotonicNow();\n           ack.readFields(blockReplyStream);\n           long duration \u003d Time.monotonicNow() - begin;\n           if (duration \u003e dfsclientSlowLogThresholdMs\n               \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n             LOG.warn(\"Slow ReadProcessor read fields took \" + duration\n                 + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                 + ack + \", targets: \" + Arrays.asList(targets));\n           } else if (LOG.isDebugEnabled()) {\n             LOG.debug(\"DFSClient \" + ack);\n           }\n \n           long seqno \u003d ack.getSeqno();\n           // processes response status from datanodes.\n           ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n           for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n             final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getHeaderFlag(i));\n             if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                 PipelineAck.ECN.CONGESTED) {\n               congestedNodesFromAck.add(targets[i]);\n             }\n             // Restart will not be treated differently unless it is\n             // the local node or the only one in the pipeline.\n             if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                 shouldWaitForRestart(i)) {\n               final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                   + targets[i];\n               errorState.initRestartingNode(i, message);\n               throw new IOException(message);\n             }\n             // node error\n             if (reply !\u003d SUCCESS) {\n               errorState.setBadNodeIndex(i); // mark bad datanode\n               throw new IOException(\"Bad response \" + reply +\n                   \" for \" + block + \" from datanode \" + targets[i]);\n             }\n           }\n \n           if (!congestedNodesFromAck.isEmpty()) {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               congestedNodes.addAll(congestedNodesFromAck);\n             }\n           } else {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               lastCongestionBackoffTime \u003d 0;\n             }\n           }\n \n           assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n           if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n             continue;\n           }\n \n           // a success ack for a data packet\n           DFSPacket one;\n           synchronized (dataQueue) {\n             one \u003d ackQueue.getFirst();\n           }\n           if (one.getSeqno() !\u003d seqno) {\n             throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                 \" for block \" + block +\n                 one.getSeqno() + \" but received \" + seqno);\n           }\n           isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n           // Fail the packet write for testing in order to force a\n           // pipeline recovery.\n           if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n               isLastPacketInBlock) {\n             failPacket \u003d true;\n             throw new IOException(\n                 \"Failing the last packet for testing.\");\n           }\n \n           // update bytesAcked\n           block.setNumBytes(one.getLastByteOffsetBlock());\n \n           synchronized (dataQueue) {\n-            scope \u003d Trace.continueSpan(one.getTraceSpan());\n-            one.setTraceSpan(null);\n+            scope \u003d one.getTraceScope();\n+            if (scope !\u003d null) {\n+              scope.reattach();\n+              one.setTraceScope(null);\n+            }\n             lastAckedSeqno \u003d seqno;\n             ackQueue.removeFirst();\n             dataQueue.notifyAll();\n \n             one.releaseBuffer(byteArrayManager);\n           }\n         } catch (Exception e) {\n           if (!responderClosed) {\n             lastException.set(e);\n             errorState.setError(true);\n             errorState.markFirstNodeIfNotMarked();\n             synchronized (dataQueue) {\n               dataQueue.notifyAll();\n             }\n             if (!errorState.isRestartingNode()) {\n               LOG.warn(\"Exception for \" + block, e);\n             }\n             responderClosed \u003d true;\n           }\n         } finally {\n+          if (scope !\u003d null) {\n             scope.close();\n+          }\n+          scope \u003d null;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d null;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          long begin \u003d Time.monotonicNow();\n          ack.readFields(blockReplyStream);\n          long duration \u003d Time.monotonicNow() - begin;\n          if (duration \u003e dfsclientSlowLogThresholdMs\n              \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            LOG.warn(\"Slow ReadProcessor read fields took \" + duration\n                + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                + ack + \", targets: \" + Arrays.asList(targets));\n          } else if (LOG.isDebugEnabled()) {\n            LOG.debug(\"DFSClient \" + ack);\n          }\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getHeaderFlag(i));\n            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                PipelineAck.ECN.CONGESTED) {\n              congestedNodesFromAck.add(targets[i]);\n            }\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                shouldWaitForRestart(i)) {\n              final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                  + targets[i];\n              errorState.initRestartingNode(i, message);\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              errorState.setBadNodeIndex(i); // mark bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for \" + block + \" from datanode \" + targets[i]);\n            }\n          }\n\n          if (!congestedNodesFromAck.isEmpty()) {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              congestedNodes.addAll(congestedNodesFromAck);\n            }\n          } else {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              lastCongestionBackoffTime \u003d 0;\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                \" for block \" + block +\n                one.getSeqno() + \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d one.getTraceScope();\n            if (scope !\u003d null) {\n              scope.reattach();\n              one.setTraceScope(null);\n            }\n            lastAckedSeqno \u003d seqno;\n            ackQueue.removeFirst();\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            lastException.set(e);\n            errorState.setError(true);\n            errorState.markFirstNodeIfNotMarked();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (!errorState.isRestartingNode()) {\n              LOG.warn(\"Exception for \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n          if (scope !\u003d null) {\n            scope.close();\n          }\n          scope \u003d null;\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {}
    },
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d NullScope.INSTANCE;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          long begin \u003d Time.monotonicNow();\n          ack.readFields(blockReplyStream);\n          long duration \u003d Time.monotonicNow() - begin;\n          if (duration \u003e dfsclientSlowLogThresholdMs\n              \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            LOG.warn(\"Slow ReadProcessor read fields took \" + duration\n                + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                + ack + \", targets: \" + Arrays.asList(targets));\n          } else if (LOG.isDebugEnabled()) {\n            LOG.debug(\"DFSClient \" + ack);\n          }\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getHeaderFlag(i));\n            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                PipelineAck.ECN.CONGESTED) {\n              congestedNodesFromAck.add(targets[i]);\n            }\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                shouldWaitForRestart(i)) {\n              final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                  + targets[i];\n              errorState.initRestartingNode(i, message);\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              errorState.setBadNodeIndex(i); // mark bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for \" + block + \" from datanode \" + targets[i]);\n            }\n          }\n\n          if (!congestedNodesFromAck.isEmpty()) {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              congestedNodes.addAll(congestedNodesFromAck);\n            }\n          } else {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              lastCongestionBackoffTime \u003d 0;\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                \" for block \" + block +\n                one.getSeqno() + \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d Trace.continueSpan(one.getTraceSpan());\n            one.setTraceSpan(null);\n            lastAckedSeqno \u003d seqno;\n            ackQueue.removeFirst();\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            lastException.set(e);\n            errorState.setError(true);\n            errorState.markFirstNodeIfNotMarked();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (!errorState.isRestartingNode()) {\n              LOG.warn(\"Exception for \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n            scope.close();\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java"
      }
    },
    "8f378733423a5244461df79a92c00239514b8b93": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8397. Refactor the error handling code in DataStreamer. Contributed by Tsz Wo Nicholas Sze.\n",
      "commitDate": "15/05/15 4:14 PM",
      "commitName": "8f378733423a5244461df79a92c00239514b8b93",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "08/05/15 12:11 AM",
      "commitNameOld": "730f9930a48259f34e48404aee51e8d641cc3d36",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 7.67,
      "commitsBetweenForRepo": 95,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,124 +1,118 @@\n     public void run() {\n \n       setName(\"ResponseProcessor for block \" + block);\n       PipelineAck ack \u003d new PipelineAck();\n \n       TraceScope scope \u003d NullScope.INSTANCE;\n       while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n         // process responses from datanodes.\n         try {\n           // read an ack from the pipeline\n           long begin \u003d Time.monotonicNow();\n           ack.readFields(blockReplyStream);\n           long duration \u003d Time.monotonicNow() - begin;\n           if (duration \u003e dfsclientSlowLogThresholdMs\n               \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n             LOG.warn(\"Slow ReadProcessor read fields took \" + duration\n                 + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                 + ack + \", targets: \" + Arrays.asList(targets));\n           } else if (LOG.isDebugEnabled()) {\n             LOG.debug(\"DFSClient \" + ack);\n           }\n \n           long seqno \u003d ack.getSeqno();\n           // processes response status from datanodes.\n           ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n           for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n             final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getHeaderFlag(i));\n             if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                 PipelineAck.ECN.CONGESTED) {\n               congestedNodesFromAck.add(targets[i]);\n             }\n             // Restart will not be treated differently unless it is\n             // the local node or the only one in the pipeline.\n             if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                 shouldWaitForRestart(i)) {\n-              restartDeadline \u003d dfsClient.getConf().getDatanodeRestartTimeout()\n-                  + Time.monotonicNow();\n-              setRestartingNodeIndex(i);\n-              String message \u003d \"A datanode is restarting: \" + targets[i];\n-              LOG.info(message);\n+              final String message \u003d \"Datanode \" + i + \" is restarting: \"\n+                  + targets[i];\n+              errorState.initRestartingNode(i, message);\n               throw new IOException(message);\n             }\n             // node error\n             if (reply !\u003d SUCCESS) {\n-              setErrorIndex(i); // first bad datanode\n+              errorState.setBadNodeIndex(i); // mark bad datanode\n               throw new IOException(\"Bad response \" + reply +\n-                  \" for block \" + block +\n-                  \" from datanode \" +\n-                  targets[i]);\n+                  \" for \" + block + \" from datanode \" + targets[i]);\n             }\n           }\n \n           if (!congestedNodesFromAck.isEmpty()) {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               congestedNodes.addAll(congestedNodesFromAck);\n             }\n           } else {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               lastCongestionBackoffTime \u003d 0;\n             }\n           }\n \n           assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n           if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n             continue;\n           }\n \n           // a success ack for a data packet\n           DFSPacket one;\n           synchronized (dataQueue) {\n             one \u003d ackQueue.getFirst();\n           }\n           if (one.getSeqno() !\u003d seqno) {\n             throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                 \" for block \" + block +\n                 one.getSeqno() + \" but received \" + seqno);\n           }\n           isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n           // Fail the packet write for testing in order to force a\n           // pipeline recovery.\n           if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n               isLastPacketInBlock) {\n             failPacket \u003d true;\n             throw new IOException(\n                 \"Failing the last packet for testing.\");\n           }\n \n           // update bytesAcked\n           block.setNumBytes(one.getLastByteOffsetBlock());\n \n           synchronized (dataQueue) {\n             scope \u003d Trace.continueSpan(one.getTraceSpan());\n             one.setTraceSpan(null);\n             lastAckedSeqno \u003d seqno;\n             ackQueue.removeFirst();\n             dataQueue.notifyAll();\n \n             one.releaseBuffer(byteArrayManager);\n           }\n         } catch (Exception e) {\n           if (!responderClosed) {\n             lastException.set(e);\n-            hasError \u003d true;\n-            // If no explicit error report was received, mark the primary\n-            // node as failed.\n-            tryMarkPrimaryDatanodeFailed();\n+            errorState.setError(true);\n+            errorState.markFirstNodeIfNotMarked();\n             synchronized (dataQueue) {\n               dataQueue.notifyAll();\n             }\n-            if (restartingNodeIndex.get() \u003d\u003d -1) {\n+            if (!errorState.isRestartingNode()) {\n               LOG.warn(\"Exception for \" + block, e);\n             }\n             responderClosed \u003d true;\n           }\n         } finally {\n             scope.close();\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d NullScope.INSTANCE;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          long begin \u003d Time.monotonicNow();\n          ack.readFields(blockReplyStream);\n          long duration \u003d Time.monotonicNow() - begin;\n          if (duration \u003e dfsclientSlowLogThresholdMs\n              \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            LOG.warn(\"Slow ReadProcessor read fields took \" + duration\n                + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                + ack + \", targets: \" + Arrays.asList(targets));\n          } else if (LOG.isDebugEnabled()) {\n            LOG.debug(\"DFSClient \" + ack);\n          }\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getHeaderFlag(i));\n            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                PipelineAck.ECN.CONGESTED) {\n              congestedNodesFromAck.add(targets[i]);\n            }\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                shouldWaitForRestart(i)) {\n              final String message \u003d \"Datanode \" + i + \" is restarting: \"\n                  + targets[i];\n              errorState.initRestartingNode(i, message);\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              errorState.setBadNodeIndex(i); // mark bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for \" + block + \" from datanode \" + targets[i]);\n            }\n          }\n\n          if (!congestedNodesFromAck.isEmpty()) {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              congestedNodes.addAll(congestedNodesFromAck);\n            }\n          } else {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              lastCongestionBackoffTime \u003d 0;\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                \" for block \" + block +\n                one.getSeqno() + \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d Trace.continueSpan(one.getTraceSpan());\n            one.setTraceSpan(null);\n            lastAckedSeqno \u003d seqno;\n            ackQueue.removeFirst();\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            lastException.set(e);\n            errorState.setError(true);\n            errorState.markFirstNodeIfNotMarked();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (!errorState.isRestartingNode()) {\n              LOG.warn(\"Exception for \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n            scope.close();\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {}
    },
    "7947e5b53b9ac9524b535b0384c1c355b74723ff": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8283. DataStreamer cleanup and some minor improvement. Contributed by Tsz Wo Nicholas Sze.\n",
      "commitDate": "29/04/15 10:41 AM",
      "commitName": "7947e5b53b9ac9524b535b0384c1c355b74723ff",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "24/04/15 12:21 AM",
      "commitNameOld": "c8d72907ff5a4cb9ce1effca8ad9b69689d11d1d",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 5.43,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,128 +1,124 @@\n     public void run() {\n \n       setName(\"ResponseProcessor for block \" + block);\n       PipelineAck ack \u003d new PipelineAck();\n \n       TraceScope scope \u003d NullScope.INSTANCE;\n       while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n         // process responses from datanodes.\n         try {\n           // read an ack from the pipeline\n           long begin \u003d Time.monotonicNow();\n           ack.readFields(blockReplyStream);\n           long duration \u003d Time.monotonicNow() - begin;\n           if (duration \u003e dfsclientSlowLogThresholdMs\n               \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n-            DFSClient.LOG\n-                .warn(\"Slow ReadProcessor read fields took \" + duration\n-                    + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n-                    + ack + \", targets: \" + Arrays.asList(targets));\n-          } else if (DFSClient.LOG.isDebugEnabled()) {\n-            DFSClient.LOG.debug(\"DFSClient \" + ack);\n+            LOG.warn(\"Slow ReadProcessor read fields took \" + duration\n+                + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n+                + ack + \", targets: \" + Arrays.asList(targets));\n+          } else if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"DFSClient \" + ack);\n           }\n \n           long seqno \u003d ack.getSeqno();\n           // processes response status from datanodes.\n           ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n           for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n             final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getHeaderFlag(i));\n             if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                 PipelineAck.ECN.CONGESTED) {\n               congestedNodesFromAck.add(targets[i]);\n             }\n             // Restart will not be treated differently unless it is\n             // the local node or the only one in the pipeline.\n             if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                 shouldWaitForRestart(i)) {\n               restartDeadline \u003d dfsClient.getConf().getDatanodeRestartTimeout()\n                   + Time.monotonicNow();\n               setRestartingNodeIndex(i);\n               String message \u003d \"A datanode is restarting: \" + targets[i];\n-              DFSClient.LOG.info(message);\n+              LOG.info(message);\n               throw new IOException(message);\n             }\n             // node error\n             if (reply !\u003d SUCCESS) {\n               setErrorIndex(i); // first bad datanode\n               throw new IOException(\"Bad response \" + reply +\n                   \" for block \" + block +\n                   \" from datanode \" +\n                   targets[i]);\n             }\n           }\n \n           if (!congestedNodesFromAck.isEmpty()) {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               congestedNodes.addAll(congestedNodesFromAck);\n             }\n           } else {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               lastCongestionBackoffTime \u003d 0;\n             }\n           }\n \n           assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n           if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n             continue;\n           }\n \n           // a success ack for a data packet\n           DFSPacket one;\n           synchronized (dataQueue) {\n             one \u003d ackQueue.getFirst();\n           }\n           if (one.getSeqno() !\u003d seqno) {\n             throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                 \" for block \" + block +\n                 one.getSeqno() + \" but received \" + seqno);\n           }\n           isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n           // Fail the packet write for testing in order to force a\n           // pipeline recovery.\n           if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n               isLastPacketInBlock) {\n             failPacket \u003d true;\n             throw new IOException(\n                 \"Failing the last packet for testing.\");\n           }\n \n           // update bytesAcked\n           block.setNumBytes(one.getLastByteOffsetBlock());\n \n           synchronized (dataQueue) {\n             scope \u003d Trace.continueSpan(one.getTraceSpan());\n             one.setTraceSpan(null);\n             lastAckedSeqno \u003d seqno;\n             ackQueue.removeFirst();\n             dataQueue.notifyAll();\n \n             one.releaseBuffer(byteArrayManager);\n           }\n         } catch (Exception e) {\n           if (!responderClosed) {\n-            if (e instanceof IOException) {\n-              setLastException((IOException)e);\n-            }\n+            lastException.set(e);\n             hasError \u003d true;\n             // If no explicit error report was received, mark the primary\n             // node as failed.\n             tryMarkPrimaryDatanodeFailed();\n             synchronized (dataQueue) {\n               dataQueue.notifyAll();\n             }\n             if (restartingNodeIndex.get() \u003d\u003d -1) {\n-              DFSClient.LOG.warn(\"DataStreamer ResponseProcessor exception \"\n-                  + \" for block \" + block, e);\n+              LOG.warn(\"Exception for \" + block, e);\n             }\n             responderClosed \u003d true;\n           }\n         } finally {\n             scope.close();\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d NullScope.INSTANCE;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          long begin \u003d Time.monotonicNow();\n          ack.readFields(blockReplyStream);\n          long duration \u003d Time.monotonicNow() - begin;\n          if (duration \u003e dfsclientSlowLogThresholdMs\n              \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            LOG.warn(\"Slow ReadProcessor read fields took \" + duration\n                + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                + ack + \", targets: \" + Arrays.asList(targets));\n          } else if (LOG.isDebugEnabled()) {\n            LOG.debug(\"DFSClient \" + ack);\n          }\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getHeaderFlag(i));\n            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                PipelineAck.ECN.CONGESTED) {\n              congestedNodesFromAck.add(targets[i]);\n            }\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                shouldWaitForRestart(i)) {\n              restartDeadline \u003d dfsClient.getConf().getDatanodeRestartTimeout()\n                  + Time.monotonicNow();\n              setRestartingNodeIndex(i);\n              String message \u003d \"A datanode is restarting: \" + targets[i];\n              LOG.info(message);\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              setErrorIndex(i); // first bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for block \" + block +\n                  \" from datanode \" +\n                  targets[i]);\n            }\n          }\n\n          if (!congestedNodesFromAck.isEmpty()) {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              congestedNodes.addAll(congestedNodesFromAck);\n            }\n          } else {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              lastCongestionBackoffTime \u003d 0;\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                \" for block \" + block +\n                one.getSeqno() + \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d Trace.continueSpan(one.getTraceSpan());\n            one.setTraceSpan(null);\n            lastAckedSeqno \u003d seqno;\n            ackQueue.removeFirst();\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            lastException.set(e);\n            hasError \u003d true;\n            // If no explicit error report was received, mark the primary\n            // node as failed.\n            tryMarkPrimaryDatanodeFailed();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (restartingNodeIndex.get() \u003d\u003d -1) {\n              LOG.warn(\"Exception for \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n            scope.close();\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {}
    },
    "2cc9514ad643ae49d30524743420ee9744e571bd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8100. Refactor DFSClient.Conf to a standalone class and separates short-circuit related conf to ShortCircuitConf.\n",
      "commitDate": "10/04/15 2:48 PM",
      "commitName": "2cc9514ad643ae49d30524743420ee9744e571bd",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "07/04/15 1:59 PM",
      "commitNameOld": "571a1ce9d037d99e7c9042bcb77ae7a2c4daf6d3",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 3.03,
      "commitsBetweenForRepo": 48,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,128 +1,128 @@\n     public void run() {\n \n       setName(\"ResponseProcessor for block \" + block);\n       PipelineAck ack \u003d new PipelineAck();\n \n       TraceScope scope \u003d NullScope.INSTANCE;\n       while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n         // process responses from datanodes.\n         try {\n           // read an ack from the pipeline\n           long begin \u003d Time.monotonicNow();\n           ack.readFields(blockReplyStream);\n           long duration \u003d Time.monotonicNow() - begin;\n           if (duration \u003e dfsclientSlowLogThresholdMs\n               \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n             DFSClient.LOG\n                 .warn(\"Slow ReadProcessor read fields took \" + duration\n                     + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                     + ack + \", targets: \" + Arrays.asList(targets));\n           } else if (DFSClient.LOG.isDebugEnabled()) {\n             DFSClient.LOG.debug(\"DFSClient \" + ack);\n           }\n \n           long seqno \u003d ack.getSeqno();\n           // processes response status from datanodes.\n           ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n           for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n             final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getHeaderFlag(i));\n             if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                 PipelineAck.ECN.CONGESTED) {\n               congestedNodesFromAck.add(targets[i]);\n             }\n             // Restart will not be treated differently unless it is\n             // the local node or the only one in the pipeline.\n             if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                 shouldWaitForRestart(i)) {\n-              restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout\n+              restartDeadline \u003d dfsClient.getConf().getDatanodeRestartTimeout()\n                   + Time.monotonicNow();\n               setRestartingNodeIndex(i);\n               String message \u003d \"A datanode is restarting: \" + targets[i];\n               DFSClient.LOG.info(message);\n               throw new IOException(message);\n             }\n             // node error\n             if (reply !\u003d SUCCESS) {\n               setErrorIndex(i); // first bad datanode\n               throw new IOException(\"Bad response \" + reply +\n                   \" for block \" + block +\n                   \" from datanode \" +\n                   targets[i]);\n             }\n           }\n \n           if (!congestedNodesFromAck.isEmpty()) {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               congestedNodes.addAll(congestedNodesFromAck);\n             }\n           } else {\n             synchronized (congestedNodes) {\n               congestedNodes.clear();\n               lastCongestionBackoffTime \u003d 0;\n             }\n           }\n \n           assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n           if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n             continue;\n           }\n \n           // a success ack for a data packet\n           DFSPacket one;\n           synchronized (dataQueue) {\n             one \u003d ackQueue.getFirst();\n           }\n           if (one.getSeqno() !\u003d seqno) {\n             throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                 \" for block \" + block +\n                 one.getSeqno() + \" but received \" + seqno);\n           }\n           isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n           // Fail the packet write for testing in order to force a\n           // pipeline recovery.\n           if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n               isLastPacketInBlock) {\n             failPacket \u003d true;\n             throw new IOException(\n                 \"Failing the last packet for testing.\");\n           }\n \n           // update bytesAcked\n           block.setNumBytes(one.getLastByteOffsetBlock());\n \n           synchronized (dataQueue) {\n             scope \u003d Trace.continueSpan(one.getTraceSpan());\n             one.setTraceSpan(null);\n             lastAckedSeqno \u003d seqno;\n             ackQueue.removeFirst();\n             dataQueue.notifyAll();\n \n             one.releaseBuffer(byteArrayManager);\n           }\n         } catch (Exception e) {\n           if (!responderClosed) {\n             if (e instanceof IOException) {\n               setLastException((IOException)e);\n             }\n             hasError \u003d true;\n             // If no explicit error report was received, mark the primary\n             // node as failed.\n             tryMarkPrimaryDatanodeFailed();\n             synchronized (dataQueue) {\n               dataQueue.notifyAll();\n             }\n             if (restartingNodeIndex.get() \u003d\u003d -1) {\n               DFSClient.LOG.warn(\"DataStreamer ResponseProcessor exception \"\n                   + \" for block \" + block, e);\n             }\n             responderClosed \u003d true;\n           }\n         } finally {\n             scope.close();\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d NullScope.INSTANCE;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          long begin \u003d Time.monotonicNow();\n          ack.readFields(blockReplyStream);\n          long duration \u003d Time.monotonicNow() - begin;\n          if (duration \u003e dfsclientSlowLogThresholdMs\n              \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            DFSClient.LOG\n                .warn(\"Slow ReadProcessor read fields took \" + duration\n                    + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                    + ack + \", targets: \" + Arrays.asList(targets));\n          } else if (DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"DFSClient \" + ack);\n          }\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getHeaderFlag(i));\n            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                PipelineAck.ECN.CONGESTED) {\n              congestedNodesFromAck.add(targets[i]);\n            }\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                shouldWaitForRestart(i)) {\n              restartDeadline \u003d dfsClient.getConf().getDatanodeRestartTimeout()\n                  + Time.monotonicNow();\n              setRestartingNodeIndex(i);\n              String message \u003d \"A datanode is restarting: \" + targets[i];\n              DFSClient.LOG.info(message);\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              setErrorIndex(i); // first bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for block \" + block +\n                  \" from datanode \" +\n                  targets[i]);\n            }\n          }\n\n          if (!congestedNodesFromAck.isEmpty()) {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              congestedNodes.addAll(congestedNodesFromAck);\n            }\n          } else {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              lastCongestionBackoffTime \u003d 0;\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                \" for block \" + block +\n                one.getSeqno() + \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d Trace.continueSpan(one.getTraceSpan());\n            one.setTraceSpan(null);\n            lastAckedSeqno \u003d seqno;\n            ackQueue.removeFirst();\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            if (e instanceof IOException) {\n              setLastException((IOException)e);\n            }\n            hasError \u003d true;\n            // If no explicit error report was received, mark the primary\n            // node as failed.\n            tryMarkPrimaryDatanodeFailed();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (restartingNodeIndex.get() \u003d\u003d -1) {\n              DFSClient.LOG.warn(\"DataStreamer ResponseProcessor exception \"\n                  + \" for block \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n            scope.close();\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {}
    },
    "6ccf4fbf8a8374c289370f67b26ac05abad30ebc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8008. Support client-side back off when the datanodes are congested. Contributed by Haohui Mai.\n",
      "commitDate": "01/04/15 4:54 PM",
      "commitName": "6ccf4fbf8a8374c289370f67b26ac05abad30ebc",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "30/03/15 11:59 AM",
      "commitNameOld": "b80457158daf0dc712fbe5695625cc17d70d4bb4",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 2.21,
      "commitsBetweenForRepo": 28,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,111 +1,128 @@\n     public void run() {\n \n       setName(\"ResponseProcessor for block \" + block);\n       PipelineAck ack \u003d new PipelineAck();\n \n       TraceScope scope \u003d NullScope.INSTANCE;\n       while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n         // process responses from datanodes.\n         try {\n           // read an ack from the pipeline\n           long begin \u003d Time.monotonicNow();\n           ack.readFields(blockReplyStream);\n           long duration \u003d Time.monotonicNow() - begin;\n           if (duration \u003e dfsclientSlowLogThresholdMs\n               \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n             DFSClient.LOG\n                 .warn(\"Slow ReadProcessor read fields took \" + duration\n                     + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                     + ack + \", targets: \" + Arrays.asList(targets));\n           } else if (DFSClient.LOG.isDebugEnabled()) {\n             DFSClient.LOG.debug(\"DFSClient \" + ack);\n           }\n \n           long seqno \u003d ack.getSeqno();\n           // processes response status from datanodes.\n+          ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n           for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n             final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getHeaderFlag(i));\n+            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n+                PipelineAck.ECN.CONGESTED) {\n+              congestedNodesFromAck.add(targets[i]);\n+            }\n             // Restart will not be treated differently unless it is\n             // the local node or the only one in the pipeline.\n             if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                 shouldWaitForRestart(i)) {\n               restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout\n                   + Time.monotonicNow();\n               setRestartingNodeIndex(i);\n               String message \u003d \"A datanode is restarting: \" + targets[i];\n               DFSClient.LOG.info(message);\n               throw new IOException(message);\n             }\n             // node error\n             if (reply !\u003d SUCCESS) {\n               setErrorIndex(i); // first bad datanode\n               throw new IOException(\"Bad response \" + reply +\n                   \" for block \" + block +\n                   \" from datanode \" +\n                   targets[i]);\n             }\n           }\n \n+          if (!congestedNodesFromAck.isEmpty()) {\n+            synchronized (congestedNodes) {\n+              congestedNodes.clear();\n+              congestedNodes.addAll(congestedNodesFromAck);\n+            }\n+          } else {\n+            synchronized (congestedNodes) {\n+              congestedNodes.clear();\n+              lastCongestionBackoffTime \u003d 0;\n+            }\n+          }\n+\n           assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n           if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n             continue;\n           }\n \n           // a success ack for a data packet\n           DFSPacket one;\n           synchronized (dataQueue) {\n             one \u003d ackQueue.getFirst();\n           }\n           if (one.getSeqno() !\u003d seqno) {\n             throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                 \" for block \" + block +\n                 one.getSeqno() + \" but received \" + seqno);\n           }\n           isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n           // Fail the packet write for testing in order to force a\n           // pipeline recovery.\n           if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n               isLastPacketInBlock) {\n             failPacket \u003d true;\n             throw new IOException(\n                 \"Failing the last packet for testing.\");\n           }\n \n           // update bytesAcked\n           block.setNumBytes(one.getLastByteOffsetBlock());\n \n           synchronized (dataQueue) {\n             scope \u003d Trace.continueSpan(one.getTraceSpan());\n             one.setTraceSpan(null);\n             lastAckedSeqno \u003d seqno;\n             ackQueue.removeFirst();\n             dataQueue.notifyAll();\n \n             one.releaseBuffer(byteArrayManager);\n           }\n         } catch (Exception e) {\n           if (!responderClosed) {\n             if (e instanceof IOException) {\n               setLastException((IOException)e);\n             }\n             hasError \u003d true;\n             // If no explicit error report was received, mark the primary\n             // node as failed.\n             tryMarkPrimaryDatanodeFailed();\n             synchronized (dataQueue) {\n               dataQueue.notifyAll();\n             }\n             if (restartingNodeIndex.get() \u003d\u003d -1) {\n               DFSClient.LOG.warn(\"DataStreamer ResponseProcessor exception \"\n                   + \" for block \" + block, e);\n             }\n             responderClosed \u003d true;\n           }\n         } finally {\n             scope.close();\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d NullScope.INSTANCE;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          long begin \u003d Time.monotonicNow();\n          ack.readFields(blockReplyStream);\n          long duration \u003d Time.monotonicNow() - begin;\n          if (duration \u003e dfsclientSlowLogThresholdMs\n              \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            DFSClient.LOG\n                .warn(\"Slow ReadProcessor read fields took \" + duration\n                    + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                    + ack + \", targets: \" + Arrays.asList(targets));\n          } else if (DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"DFSClient \" + ack);\n          }\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          ArrayList\u003cDatanodeInfo\u003e congestedNodesFromAck \u003d new ArrayList\u003c\u003e();\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getHeaderFlag(i));\n            if (PipelineAck.getECNFromHeader(ack.getHeaderFlag(i)) \u003d\u003d\n                PipelineAck.ECN.CONGESTED) {\n              congestedNodesFromAck.add(targets[i]);\n            }\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                shouldWaitForRestart(i)) {\n              restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout\n                  + Time.monotonicNow();\n              setRestartingNodeIndex(i);\n              String message \u003d \"A datanode is restarting: \" + targets[i];\n              DFSClient.LOG.info(message);\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              setErrorIndex(i); // first bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for block \" + block +\n                  \" from datanode \" +\n                  targets[i]);\n            }\n          }\n\n          if (!congestedNodesFromAck.isEmpty()) {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              congestedNodes.addAll(congestedNodesFromAck);\n            }\n          } else {\n            synchronized (congestedNodes) {\n              congestedNodes.clear();\n              lastCongestionBackoffTime \u003d 0;\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                \" for block \" + block +\n                one.getSeqno() + \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d Trace.continueSpan(one.getTraceSpan());\n            one.setTraceSpan(null);\n            lastAckedSeqno \u003d seqno;\n            ackQueue.removeFirst();\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            if (e instanceof IOException) {\n              setLastException((IOException)e);\n            }\n            hasError \u003d true;\n            // If no explicit error report was received, mark the primary\n            // node as failed.\n            tryMarkPrimaryDatanodeFailed();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (restartingNodeIndex.get() \u003d\u003d -1) {\n              DFSClient.LOG.warn(\"DataStreamer ResponseProcessor exception \"\n                  + \" for block \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n            scope.close();\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {}
    },
    "b80457158daf0dc712fbe5695625cc17d70d4bb4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7748. Separate ECN flags from the Status in the DataTransferPipelineAck. Contributed by Anu Engineer and Haohui Mai.\n",
      "commitDate": "30/03/15 11:59 AM",
      "commitName": "b80457158daf0dc712fbe5695625cc17d70d4bb4",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "24/03/15 11:06 AM",
      "commitNameOld": "a16bfff71bd7f00e06e1f59bfe5445a154bb8c66",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 6.04,
      "commitsBetweenForRepo": 47,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,111 +1,111 @@\n     public void run() {\n \n       setName(\"ResponseProcessor for block \" + block);\n       PipelineAck ack \u003d new PipelineAck();\n \n       TraceScope scope \u003d NullScope.INSTANCE;\n       while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n         // process responses from datanodes.\n         try {\n           // read an ack from the pipeline\n           long begin \u003d Time.monotonicNow();\n           ack.readFields(blockReplyStream);\n           long duration \u003d Time.monotonicNow() - begin;\n           if (duration \u003e dfsclientSlowLogThresholdMs\n               \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n             DFSClient.LOG\n                 .warn(\"Slow ReadProcessor read fields took \" + duration\n                     + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                     + ack + \", targets: \" + Arrays.asList(targets));\n           } else if (DFSClient.LOG.isDebugEnabled()) {\n             DFSClient.LOG.debug(\"DFSClient \" + ack);\n           }\n \n           long seqno \u003d ack.getSeqno();\n           // processes response status from datanodes.\n           for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n             final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n-                .getReply(i));\n+                .getHeaderFlag(i));\n             // Restart will not be treated differently unless it is\n             // the local node or the only one in the pipeline.\n             if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                 shouldWaitForRestart(i)) {\n               restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout\n                   + Time.monotonicNow();\n               setRestartingNodeIndex(i);\n               String message \u003d \"A datanode is restarting: \" + targets[i];\n               DFSClient.LOG.info(message);\n               throw new IOException(message);\n             }\n             // node error\n             if (reply !\u003d SUCCESS) {\n               setErrorIndex(i); // first bad datanode\n               throw new IOException(\"Bad response \" + reply +\n                   \" for block \" + block +\n                   \" from datanode \" +\n                   targets[i]);\n             }\n           }\n \n           assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n           if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n             continue;\n           }\n \n           // a success ack for a data packet\n           DFSPacket one;\n           synchronized (dataQueue) {\n             one \u003d ackQueue.getFirst();\n           }\n           if (one.getSeqno() !\u003d seqno) {\n             throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                 \" for block \" + block +\n                 one.getSeqno() + \" but received \" + seqno);\n           }\n           isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n           // Fail the packet write for testing in order to force a\n           // pipeline recovery.\n           if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n               isLastPacketInBlock) {\n             failPacket \u003d true;\n             throw new IOException(\n                 \"Failing the last packet for testing.\");\n           }\n \n           // update bytesAcked\n           block.setNumBytes(one.getLastByteOffsetBlock());\n \n           synchronized (dataQueue) {\n             scope \u003d Trace.continueSpan(one.getTraceSpan());\n             one.setTraceSpan(null);\n             lastAckedSeqno \u003d seqno;\n             ackQueue.removeFirst();\n             dataQueue.notifyAll();\n \n             one.releaseBuffer(byteArrayManager);\n           }\n         } catch (Exception e) {\n           if (!responderClosed) {\n             if (e instanceof IOException) {\n               setLastException((IOException)e);\n             }\n             hasError \u003d true;\n             // If no explicit error report was received, mark the primary\n             // node as failed.\n             tryMarkPrimaryDatanodeFailed();\n             synchronized (dataQueue) {\n               dataQueue.notifyAll();\n             }\n             if (restartingNodeIndex.get() \u003d\u003d -1) {\n               DFSClient.LOG.warn(\"DataStreamer ResponseProcessor exception \"\n                   + \" for block \" + block, e);\n             }\n             responderClosed \u003d true;\n           }\n         } finally {\n             scope.close();\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d NullScope.INSTANCE;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          long begin \u003d Time.monotonicNow();\n          ack.readFields(blockReplyStream);\n          long duration \u003d Time.monotonicNow() - begin;\n          if (duration \u003e dfsclientSlowLogThresholdMs\n              \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            DFSClient.LOG\n                .warn(\"Slow ReadProcessor read fields took \" + duration\n                    + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                    + ack + \", targets: \" + Arrays.asList(targets));\n          } else if (DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"DFSClient \" + ack);\n          }\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getHeaderFlag(i));\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                shouldWaitForRestart(i)) {\n              restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout\n                  + Time.monotonicNow();\n              setRestartingNodeIndex(i);\n              String message \u003d \"A datanode is restarting: \" + targets[i];\n              DFSClient.LOG.info(message);\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              setErrorIndex(i); // first bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for block \" + block +\n                  \" from datanode \" +\n                  targets[i]);\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                \" for block \" + block +\n                one.getSeqno() + \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d Trace.continueSpan(one.getTraceSpan());\n            one.setTraceSpan(null);\n            lastAckedSeqno \u003d seqno;\n            ackQueue.removeFirst();\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            if (e instanceof IOException) {\n              setLastException((IOException)e);\n            }\n            hasError \u003d true;\n            // If no explicit error report was received, mark the primary\n            // node as failed.\n            tryMarkPrimaryDatanodeFailed();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (restartingNodeIndex.get() \u003d\u003d -1) {\n              DFSClient.LOG.warn(\"DataStreamer ResponseProcessor exception \"\n                  + \" for block \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n            scope.close();\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
      "extendedDetails": {}
    },
    "a16bfff71bd7f00e06e1f59bfe5445a154bb8c66": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-7854. Separate class DataStreamer out of DFSOutputStream. Contributed by Li Bo.\n",
      "commitDate": "24/03/15 11:06 AM",
      "commitName": "a16bfff71bd7f00e06e1f59bfe5445a154bb8c66",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-7854. Separate class DataStreamer out of DFSOutputStream. Contributed by Li Bo.\n",
          "commitDate": "24/03/15 11:06 AM",
          "commitName": "a16bfff71bd7f00e06e1f59bfe5445a154bb8c66",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "24/03/15 10:49 AM",
          "commitNameOld": "570a83ae80faf2076966acf30588733803327844",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,111 +1,111 @@\n-      public void run() {\n+    public void run() {\n \n-        setName(\"ResponseProcessor for block \" + block);\n-        PipelineAck ack \u003d new PipelineAck();\n+      setName(\"ResponseProcessor for block \" + block);\n+      PipelineAck ack \u003d new PipelineAck();\n \n-        TraceScope scope \u003d NullScope.INSTANCE;\n-        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n-          // process responses from datanodes.\n-          try {\n-            // read an ack from the pipeline\n-            long begin \u003d Time.monotonicNow();\n-            ack.readFields(blockReplyStream);\n-            long duration \u003d Time.monotonicNow() - begin;\n-            if (duration \u003e dfsclientSlowLogThresholdMs\n-                \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n-              DFSClient.LOG\n-                  .warn(\"Slow ReadProcessor read fields took \" + duration\n-                      + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n-                      + ack + \", targets: \" + Arrays.asList(targets));\n-            } else if (DFSClient.LOG.isDebugEnabled()) {\n-              DFSClient.LOG.debug(\"DFSClient \" + ack);\n-            }\n-\n-            long seqno \u003d ack.getSeqno();\n-            // processes response status from datanodes.\n-            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n-              final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n-                .getReply(i));\n-              // Restart will not be treated differently unless it is\n-              // the local node or the only one in the pipeline.\n-              if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n-                  shouldWaitForRestart(i)) {\n-                restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout\n-                    + Time.monotonicNow();\n-                setRestartingNodeIndex(i);\n-                String message \u003d \"A datanode is restarting: \" + targets[i];\n-                DFSClient.LOG.info(message);\n-               throw new IOException(message);\n-              }\n-              // node error\n-              if (reply !\u003d SUCCESS) {\n-                setErrorIndex(i); // first bad datanode\n-                throw new IOException(\"Bad response \" + reply +\n-                    \" for block \" + block +\n-                    \" from datanode \" + \n-                    targets[i]);\n-              }\n-            }\n-            \n-            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n-              \"Ack for unknown seqno should be a failed ack: \" + ack;\n-            if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n-              continue;\n-            }\n-\n-            // a success ack for a data packet\n-            DFSPacket one;\n-            synchronized (dataQueue) {\n-              one \u003d ackQueue.getFirst();\n-            }\n-            if (one.getSeqno() !\u003d seqno) {\n-              throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n-                                    \" for block \" + block +\n-                                    one.getSeqno() + \" but received \" + seqno);\n-            }\n-            isLastPacketInBlock \u003d one.isLastPacketInBlock();\n-\n-            // Fail the packet write for testing in order to force a\n-            // pipeline recovery.\n-            if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n-                isLastPacketInBlock) {\n-              failPacket \u003d true;\n-              throw new IOException(\n-                    \"Failing the last packet for testing.\");\n-            }\n-              \n-            // update bytesAcked\n-            block.setNumBytes(one.getLastByteOffsetBlock());\n-\n-            synchronized (dataQueue) {\n-              scope \u003d Trace.continueSpan(one.getTraceSpan());\n-              one.setTraceSpan(null);\n-              lastAckedSeqno \u003d seqno;\n-              ackQueue.removeFirst();\n-              dataQueue.notifyAll();\n-\n-              one.releaseBuffer(byteArrayManager);\n-            }\n-          } catch (Exception e) {\n-            if (!responderClosed) {\n-              if (e instanceof IOException) {\n-                setLastException((IOException)e);\n-              }\n-              hasError \u003d true;\n-              // If no explicit error report was received, mark the primary\n-              // node as failed.\n-              tryMarkPrimaryDatanodeFailed();\n-              synchronized (dataQueue) {\n-                dataQueue.notifyAll();\n-              }\n-              if (restartingNodeIndex.get() \u003d\u003d -1) {\n-                DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n-                     + \" for block \" + block, e);\n-              }\n-              responderClosed \u003d true;\n-            }\n-          } finally {\n-            scope.close();\n+      TraceScope scope \u003d NullScope.INSTANCE;\n+      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n+        // process responses from datanodes.\n+        try {\n+          // read an ack from the pipeline\n+          long begin \u003d Time.monotonicNow();\n+          ack.readFields(blockReplyStream);\n+          long duration \u003d Time.monotonicNow() - begin;\n+          if (duration \u003e dfsclientSlowLogThresholdMs\n+              \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n+            DFSClient.LOG\n+                .warn(\"Slow ReadProcessor read fields took \" + duration\n+                    + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n+                    + ack + \", targets: \" + Arrays.asList(targets));\n+          } else if (DFSClient.LOG.isDebugEnabled()) {\n+            DFSClient.LOG.debug(\"DFSClient \" + ack);\n           }\n+\n+          long seqno \u003d ack.getSeqno();\n+          // processes response status from datanodes.\n+          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n+            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n+                .getReply(i));\n+            // Restart will not be treated differently unless it is\n+            // the local node or the only one in the pipeline.\n+            if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n+                shouldWaitForRestart(i)) {\n+              restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout\n+                  + Time.monotonicNow();\n+              setRestartingNodeIndex(i);\n+              String message \u003d \"A datanode is restarting: \" + targets[i];\n+              DFSClient.LOG.info(message);\n+              throw new IOException(message);\n+            }\n+            // node error\n+            if (reply !\u003d SUCCESS) {\n+              setErrorIndex(i); // first bad datanode\n+              throw new IOException(\"Bad response \" + reply +\n+                  \" for block \" + block +\n+                  \" from datanode \" +\n+                  targets[i]);\n+            }\n+          }\n+\n+          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n+              \"Ack for unknown seqno should be a failed ack: \" + ack;\n+          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n+            continue;\n+          }\n+\n+          // a success ack for a data packet\n+          DFSPacket one;\n+          synchronized (dataQueue) {\n+            one \u003d ackQueue.getFirst();\n+          }\n+          if (one.getSeqno() !\u003d seqno) {\n+            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n+                \" for block \" + block +\n+                one.getSeqno() + \" but received \" + seqno);\n+          }\n+          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n+\n+          // Fail the packet write for testing in order to force a\n+          // pipeline recovery.\n+          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n+              isLastPacketInBlock) {\n+            failPacket \u003d true;\n+            throw new IOException(\n+                \"Failing the last packet for testing.\");\n+          }\n+\n+          // update bytesAcked\n+          block.setNumBytes(one.getLastByteOffsetBlock());\n+\n+          synchronized (dataQueue) {\n+            scope \u003d Trace.continueSpan(one.getTraceSpan());\n+            one.setTraceSpan(null);\n+            lastAckedSeqno \u003d seqno;\n+            ackQueue.removeFirst();\n+            dataQueue.notifyAll();\n+\n+            one.releaseBuffer(byteArrayManager);\n+          }\n+        } catch (Exception e) {\n+          if (!responderClosed) {\n+            if (e instanceof IOException) {\n+              setLastException((IOException)e);\n+            }\n+            hasError \u003d true;\n+            // If no explicit error report was received, mark the primary\n+            // node as failed.\n+            tryMarkPrimaryDatanodeFailed();\n+            synchronized (dataQueue) {\n+              dataQueue.notifyAll();\n+            }\n+            if (restartingNodeIndex.get() \u003d\u003d -1) {\n+              DFSClient.LOG.warn(\"DataStreamer ResponseProcessor exception \"\n+                  + \" for block \" + block, e);\n+            }\n+            responderClosed \u003d true;\n+          }\n+        } finally {\n+            scope.close();\n         }\n-      }\n\\ No newline at end of file\n+      }\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d NullScope.INSTANCE;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          long begin \u003d Time.monotonicNow();\n          ack.readFields(blockReplyStream);\n          long duration \u003d Time.monotonicNow() - begin;\n          if (duration \u003e dfsclientSlowLogThresholdMs\n              \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            DFSClient.LOG\n                .warn(\"Slow ReadProcessor read fields took \" + duration\n                    + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                    + ack + \", targets: \" + Arrays.asList(targets));\n          } else if (DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"DFSClient \" + ack);\n          }\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getReply(i));\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                shouldWaitForRestart(i)) {\n              restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout\n                  + Time.monotonicNow();\n              setRestartingNodeIndex(i);\n              String message \u003d \"A datanode is restarting: \" + targets[i];\n              DFSClient.LOG.info(message);\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              setErrorIndex(i); // first bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for block \" + block +\n                  \" from datanode \" +\n                  targets[i]);\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                \" for block \" + block +\n                one.getSeqno() + \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d Trace.continueSpan(one.getTraceSpan());\n            one.setTraceSpan(null);\n            lastAckedSeqno \u003d seqno;\n            ackQueue.removeFirst();\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            if (e instanceof IOException) {\n              setLastException((IOException)e);\n            }\n            hasError \u003d true;\n            // If no explicit error report was received, mark the primary\n            // node as failed.\n            tryMarkPrimaryDatanodeFailed();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (restartingNodeIndex.get() \u003d\u003d -1) {\n              DFSClient.LOG.warn(\"DataStreamer ResponseProcessor exception \"\n                  + \" for block \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n            scope.close();\n        }\n      }\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
            "oldMethodName": "run",
            "newMethodName": "run"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7854. Separate class DataStreamer out of DFSOutputStream. Contributed by Li Bo.\n",
          "commitDate": "24/03/15 11:06 AM",
          "commitName": "a16bfff71bd7f00e06e1f59bfe5445a154bb8c66",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "24/03/15 10:49 AM",
          "commitNameOld": "570a83ae80faf2076966acf30588733803327844",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,111 +1,111 @@\n-      public void run() {\n+    public void run() {\n \n-        setName(\"ResponseProcessor for block \" + block);\n-        PipelineAck ack \u003d new PipelineAck();\n+      setName(\"ResponseProcessor for block \" + block);\n+      PipelineAck ack \u003d new PipelineAck();\n \n-        TraceScope scope \u003d NullScope.INSTANCE;\n-        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n-          // process responses from datanodes.\n-          try {\n-            // read an ack from the pipeline\n-            long begin \u003d Time.monotonicNow();\n-            ack.readFields(blockReplyStream);\n-            long duration \u003d Time.monotonicNow() - begin;\n-            if (duration \u003e dfsclientSlowLogThresholdMs\n-                \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n-              DFSClient.LOG\n-                  .warn(\"Slow ReadProcessor read fields took \" + duration\n-                      + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n-                      + ack + \", targets: \" + Arrays.asList(targets));\n-            } else if (DFSClient.LOG.isDebugEnabled()) {\n-              DFSClient.LOG.debug(\"DFSClient \" + ack);\n-            }\n-\n-            long seqno \u003d ack.getSeqno();\n-            // processes response status from datanodes.\n-            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n-              final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n-                .getReply(i));\n-              // Restart will not be treated differently unless it is\n-              // the local node or the only one in the pipeline.\n-              if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n-                  shouldWaitForRestart(i)) {\n-                restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout\n-                    + Time.monotonicNow();\n-                setRestartingNodeIndex(i);\n-                String message \u003d \"A datanode is restarting: \" + targets[i];\n-                DFSClient.LOG.info(message);\n-               throw new IOException(message);\n-              }\n-              // node error\n-              if (reply !\u003d SUCCESS) {\n-                setErrorIndex(i); // first bad datanode\n-                throw new IOException(\"Bad response \" + reply +\n-                    \" for block \" + block +\n-                    \" from datanode \" + \n-                    targets[i]);\n-              }\n-            }\n-            \n-            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n-              \"Ack for unknown seqno should be a failed ack: \" + ack;\n-            if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n-              continue;\n-            }\n-\n-            // a success ack for a data packet\n-            DFSPacket one;\n-            synchronized (dataQueue) {\n-              one \u003d ackQueue.getFirst();\n-            }\n-            if (one.getSeqno() !\u003d seqno) {\n-              throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n-                                    \" for block \" + block +\n-                                    one.getSeqno() + \" but received \" + seqno);\n-            }\n-            isLastPacketInBlock \u003d one.isLastPacketInBlock();\n-\n-            // Fail the packet write for testing in order to force a\n-            // pipeline recovery.\n-            if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n-                isLastPacketInBlock) {\n-              failPacket \u003d true;\n-              throw new IOException(\n-                    \"Failing the last packet for testing.\");\n-            }\n-              \n-            // update bytesAcked\n-            block.setNumBytes(one.getLastByteOffsetBlock());\n-\n-            synchronized (dataQueue) {\n-              scope \u003d Trace.continueSpan(one.getTraceSpan());\n-              one.setTraceSpan(null);\n-              lastAckedSeqno \u003d seqno;\n-              ackQueue.removeFirst();\n-              dataQueue.notifyAll();\n-\n-              one.releaseBuffer(byteArrayManager);\n-            }\n-          } catch (Exception e) {\n-            if (!responderClosed) {\n-              if (e instanceof IOException) {\n-                setLastException((IOException)e);\n-              }\n-              hasError \u003d true;\n-              // If no explicit error report was received, mark the primary\n-              // node as failed.\n-              tryMarkPrimaryDatanodeFailed();\n-              synchronized (dataQueue) {\n-                dataQueue.notifyAll();\n-              }\n-              if (restartingNodeIndex.get() \u003d\u003d -1) {\n-                DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n-                     + \" for block \" + block, e);\n-              }\n-              responderClosed \u003d true;\n-            }\n-          } finally {\n-            scope.close();\n+      TraceScope scope \u003d NullScope.INSTANCE;\n+      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n+        // process responses from datanodes.\n+        try {\n+          // read an ack from the pipeline\n+          long begin \u003d Time.monotonicNow();\n+          ack.readFields(blockReplyStream);\n+          long duration \u003d Time.monotonicNow() - begin;\n+          if (duration \u003e dfsclientSlowLogThresholdMs\n+              \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n+            DFSClient.LOG\n+                .warn(\"Slow ReadProcessor read fields took \" + duration\n+                    + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n+                    + ack + \", targets: \" + Arrays.asList(targets));\n+          } else if (DFSClient.LOG.isDebugEnabled()) {\n+            DFSClient.LOG.debug(\"DFSClient \" + ack);\n           }\n+\n+          long seqno \u003d ack.getSeqno();\n+          // processes response status from datanodes.\n+          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n+            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n+                .getReply(i));\n+            // Restart will not be treated differently unless it is\n+            // the local node or the only one in the pipeline.\n+            if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n+                shouldWaitForRestart(i)) {\n+              restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout\n+                  + Time.monotonicNow();\n+              setRestartingNodeIndex(i);\n+              String message \u003d \"A datanode is restarting: \" + targets[i];\n+              DFSClient.LOG.info(message);\n+              throw new IOException(message);\n+            }\n+            // node error\n+            if (reply !\u003d SUCCESS) {\n+              setErrorIndex(i); // first bad datanode\n+              throw new IOException(\"Bad response \" + reply +\n+                  \" for block \" + block +\n+                  \" from datanode \" +\n+                  targets[i]);\n+            }\n+          }\n+\n+          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n+              \"Ack for unknown seqno should be a failed ack: \" + ack;\n+          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n+            continue;\n+          }\n+\n+          // a success ack for a data packet\n+          DFSPacket one;\n+          synchronized (dataQueue) {\n+            one \u003d ackQueue.getFirst();\n+          }\n+          if (one.getSeqno() !\u003d seqno) {\n+            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n+                \" for block \" + block +\n+                one.getSeqno() + \" but received \" + seqno);\n+          }\n+          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n+\n+          // Fail the packet write for testing in order to force a\n+          // pipeline recovery.\n+          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n+              isLastPacketInBlock) {\n+            failPacket \u003d true;\n+            throw new IOException(\n+                \"Failing the last packet for testing.\");\n+          }\n+\n+          // update bytesAcked\n+          block.setNumBytes(one.getLastByteOffsetBlock());\n+\n+          synchronized (dataQueue) {\n+            scope \u003d Trace.continueSpan(one.getTraceSpan());\n+            one.setTraceSpan(null);\n+            lastAckedSeqno \u003d seqno;\n+            ackQueue.removeFirst();\n+            dataQueue.notifyAll();\n+\n+            one.releaseBuffer(byteArrayManager);\n+          }\n+        } catch (Exception e) {\n+          if (!responderClosed) {\n+            if (e instanceof IOException) {\n+              setLastException((IOException)e);\n+            }\n+            hasError \u003d true;\n+            // If no explicit error report was received, mark the primary\n+            // node as failed.\n+            tryMarkPrimaryDatanodeFailed();\n+            synchronized (dataQueue) {\n+              dataQueue.notifyAll();\n+            }\n+            if (restartingNodeIndex.get() \u003d\u003d -1) {\n+              DFSClient.LOG.warn(\"DataStreamer ResponseProcessor exception \"\n+                  + \" for block \" + block, e);\n+            }\n+            responderClosed \u003d true;\n+          }\n+        } finally {\n+            scope.close();\n         }\n-      }\n\\ No newline at end of file\n+      }\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    public void run() {\n\n      setName(\"ResponseProcessor for block \" + block);\n      PipelineAck ack \u003d new PipelineAck();\n\n      TraceScope scope \u003d NullScope.INSTANCE;\n      while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n        // process responses from datanodes.\n        try {\n          // read an ack from the pipeline\n          long begin \u003d Time.monotonicNow();\n          ack.readFields(blockReplyStream);\n          long duration \u003d Time.monotonicNow() - begin;\n          if (duration \u003e dfsclientSlowLogThresholdMs\n              \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n            DFSClient.LOG\n                .warn(\"Slow ReadProcessor read fields took \" + duration\n                    + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                    + ack + \", targets: \" + Arrays.asList(targets));\n          } else if (DFSClient.LOG.isDebugEnabled()) {\n            DFSClient.LOG.debug(\"DFSClient \" + ack);\n          }\n\n          long seqno \u003d ack.getSeqno();\n          // processes response status from datanodes.\n          for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n            final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getReply(i));\n            // Restart will not be treated differently unless it is\n            // the local node or the only one in the pipeline.\n            if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                shouldWaitForRestart(i)) {\n              restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout\n                  + Time.monotonicNow();\n              setRestartingNodeIndex(i);\n              String message \u003d \"A datanode is restarting: \" + targets[i];\n              DFSClient.LOG.info(message);\n              throw new IOException(message);\n            }\n            // node error\n            if (reply !\u003d SUCCESS) {\n              setErrorIndex(i); // first bad datanode\n              throw new IOException(\"Bad response \" + reply +\n                  \" for block \" + block +\n                  \" from datanode \" +\n                  targets[i]);\n            }\n          }\n\n          assert seqno !\u003d PipelineAck.UNKOWN_SEQNO :\n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n          if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n            continue;\n          }\n\n          // a success ack for a data packet\n          DFSPacket one;\n          synchronized (dataQueue) {\n            one \u003d ackQueue.getFirst();\n          }\n          if (one.getSeqno() !\u003d seqno) {\n            throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                \" for block \" + block +\n                one.getSeqno() + \" but received \" + seqno);\n          }\n          isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n          // Fail the packet write for testing in order to force a\n          // pipeline recovery.\n          if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n              isLastPacketInBlock) {\n            failPacket \u003d true;\n            throw new IOException(\n                \"Failing the last packet for testing.\");\n          }\n\n          // update bytesAcked\n          block.setNumBytes(one.getLastByteOffsetBlock());\n\n          synchronized (dataQueue) {\n            scope \u003d Trace.continueSpan(one.getTraceSpan());\n            one.setTraceSpan(null);\n            lastAckedSeqno \u003d seqno;\n            ackQueue.removeFirst();\n            dataQueue.notifyAll();\n\n            one.releaseBuffer(byteArrayManager);\n          }\n        } catch (Exception e) {\n          if (!responderClosed) {\n            if (e instanceof IOException) {\n              setLastException((IOException)e);\n            }\n            hasError \u003d true;\n            // If no explicit error report was received, mark the primary\n            // node as failed.\n            tryMarkPrimaryDatanodeFailed();\n            synchronized (dataQueue) {\n              dataQueue.notifyAll();\n            }\n            if (restartingNodeIndex.get() \u003d\u003d -1) {\n              DFSClient.LOG.warn(\"DataStreamer ResponseProcessor exception \"\n                  + \" for block \" + block, e);\n            }\n            responderClosed \u003d true;\n          }\n        } finally {\n            scope.close();\n        }\n      }\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",
          "extendedDetails": {}
        }
      ]
    },
    "75ead273bea8a7dad61c4f99c3a16cab2697c498": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6841. Use Time.monotonicNow() wherever applicable instead of Time.now(). Contributed by Vinayakumar B\n",
      "commitDate": "20/03/15 12:02 PM",
      "commitName": "75ead273bea8a7dad61c4f99c3a16cab2697c498",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "20/03/15 9:12 AM",
      "commitNameOld": "15612313f578a5115f8d03885e9b0c8c376ed56e",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 0.12,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,111 +1,111 @@\n       public void run() {\n \n         setName(\"ResponseProcessor for block \" + block);\n         PipelineAck ack \u003d new PipelineAck();\n \n         TraceScope scope \u003d NullScope.INSTANCE;\n         while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n           // process responses from datanodes.\n           try {\n             // read an ack from the pipeline\n             long begin \u003d Time.monotonicNow();\n             ack.readFields(blockReplyStream);\n             long duration \u003d Time.monotonicNow() - begin;\n             if (duration \u003e dfsclientSlowLogThresholdMs\n                 \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n               DFSClient.LOG\n                   .warn(\"Slow ReadProcessor read fields took \" + duration\n                       + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                       + ack + \", targets: \" + Arrays.asList(targets));\n             } else if (DFSClient.LOG.isDebugEnabled()) {\n               DFSClient.LOG.debug(\"DFSClient \" + ack);\n             }\n \n             long seqno \u003d ack.getSeqno();\n             // processes response status from datanodes.\n             for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n               final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getReply(i));\n               // Restart will not be treated differently unless it is\n               // the local node or the only one in the pipeline.\n               if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                   shouldWaitForRestart(i)) {\n-                restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout +\n-                    Time.now();\n+                restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout\n+                    + Time.monotonicNow();\n                 setRestartingNodeIndex(i);\n                 String message \u003d \"A datanode is restarting: \" + targets[i];\n                 DFSClient.LOG.info(message);\n                throw new IOException(message);\n               }\n               // node error\n               if (reply !\u003d SUCCESS) {\n                 setErrorIndex(i); // first bad datanode\n                 throw new IOException(\"Bad response \" + reply +\n                     \" for block \" + block +\n                     \" from datanode \" + \n                     targets[i]);\n               }\n             }\n             \n             assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n             if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n               continue;\n             }\n \n             // a success ack for a data packet\n             DFSPacket one;\n             synchronized (dataQueue) {\n               one \u003d ackQueue.getFirst();\n             }\n             if (one.getSeqno() !\u003d seqno) {\n               throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                     \" for block \" + block +\n                                     one.getSeqno() + \" but received \" + seqno);\n             }\n             isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n             // Fail the packet write for testing in order to force a\n             // pipeline recovery.\n             if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n                 isLastPacketInBlock) {\n               failPacket \u003d true;\n               throw new IOException(\n                     \"Failing the last packet for testing.\");\n             }\n               \n             // update bytesAcked\n             block.setNumBytes(one.getLastByteOffsetBlock());\n \n             synchronized (dataQueue) {\n               scope \u003d Trace.continueSpan(one.getTraceSpan());\n               one.setTraceSpan(null);\n               lastAckedSeqno \u003d seqno;\n               ackQueue.removeFirst();\n               dataQueue.notifyAll();\n \n               one.releaseBuffer(byteArrayManager);\n             }\n           } catch (Exception e) {\n             if (!responderClosed) {\n               if (e instanceof IOException) {\n                 setLastException((IOException)e);\n               }\n               hasError \u003d true;\n               // If no explicit error report was received, mark the primary\n               // node as failed.\n               tryMarkPrimaryDatanodeFailed();\n               synchronized (dataQueue) {\n                 dataQueue.notifyAll();\n               }\n               if (restartingNodeIndex.get() \u003d\u003d -1) {\n                 DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                      + \" for block \" + block, e);\n               }\n               responderClosed \u003d true;\n             }\n           } finally {\n             scope.close();\n           }\n         }\n       }\n\\ No newline at end of file\n",
      "actualSource": "      public void run() {\n\n        setName(\"ResponseProcessor for block \" + block);\n        PipelineAck ack \u003d new PipelineAck();\n\n        TraceScope scope \u003d NullScope.INSTANCE;\n        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n          // process responses from datanodes.\n          try {\n            // read an ack from the pipeline\n            long begin \u003d Time.monotonicNow();\n            ack.readFields(blockReplyStream);\n            long duration \u003d Time.monotonicNow() - begin;\n            if (duration \u003e dfsclientSlowLogThresholdMs\n                \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n              DFSClient.LOG\n                  .warn(\"Slow ReadProcessor read fields took \" + duration\n                      + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                      + ack + \", targets: \" + Arrays.asList(targets));\n            } else if (DFSClient.LOG.isDebugEnabled()) {\n              DFSClient.LOG.debug(\"DFSClient \" + ack);\n            }\n\n            long seqno \u003d ack.getSeqno();\n            // processes response status from datanodes.\n            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n              final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getReply(i));\n              // Restart will not be treated differently unless it is\n              // the local node or the only one in the pipeline.\n              if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                  shouldWaitForRestart(i)) {\n                restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout\n                    + Time.monotonicNow();\n                setRestartingNodeIndex(i);\n                String message \u003d \"A datanode is restarting: \" + targets[i];\n                DFSClient.LOG.info(message);\n               throw new IOException(message);\n              }\n              // node error\n              if (reply !\u003d SUCCESS) {\n                setErrorIndex(i); // first bad datanode\n                throw new IOException(\"Bad response \" + reply +\n                    \" for block \" + block +\n                    \" from datanode \" + \n                    targets[i]);\n              }\n            }\n            \n            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n            if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n              continue;\n            }\n\n            // a success ack for a data packet\n            DFSPacket one;\n            synchronized (dataQueue) {\n              one \u003d ackQueue.getFirst();\n            }\n            if (one.getSeqno() !\u003d seqno) {\n              throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                    \" for block \" + block +\n                                    one.getSeqno() + \" but received \" + seqno);\n            }\n            isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n            // Fail the packet write for testing in order to force a\n            // pipeline recovery.\n            if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n                isLastPacketInBlock) {\n              failPacket \u003d true;\n              throw new IOException(\n                    \"Failing the last packet for testing.\");\n            }\n              \n            // update bytesAcked\n            block.setNumBytes(one.getLastByteOffsetBlock());\n\n            synchronized (dataQueue) {\n              scope \u003d Trace.continueSpan(one.getTraceSpan());\n              one.setTraceSpan(null);\n              lastAckedSeqno \u003d seqno;\n              ackQueue.removeFirst();\n              dataQueue.notifyAll();\n\n              one.releaseBuffer(byteArrayManager);\n            }\n          } catch (Exception e) {\n            if (!responderClosed) {\n              if (e instanceof IOException) {\n                setLastException((IOException)e);\n              }\n              hasError \u003d true;\n              // If no explicit error report was received, mark the primary\n              // node as failed.\n              tryMarkPrimaryDatanodeFailed();\n              synchronized (dataQueue) {\n                dataQueue.notifyAll();\n              }\n              if (restartingNodeIndex.get() \u003d\u003d -1) {\n                DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                     + \" for block \" + block, e);\n              }\n              responderClosed \u003d true;\n            }\n          } finally {\n            scope.close();\n          }\n        }\n      }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "8234fd0e1087e0e49aa1d6f286f292b7f70b368e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7054. Make DFSOutputStream tracing more fine-grained (cmccabe)\n",
      "commitDate": "18/03/15 6:14 PM",
      "commitName": "8234fd0e1087e0e49aa1d6f286f292b7f70b368e",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "16/03/15 9:58 PM",
      "commitNameOld": "046521cd6511b7fc6d9478cb2bed90d8e75fca20",
      "commitAuthorOld": "Harsh J",
      "daysBetweenCommits": 1.84,
      "commitsBetweenForRepo": 25,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,111 @@\n       public void run() {\n \n         setName(\"ResponseProcessor for block \" + block);\n         PipelineAck ack \u003d new PipelineAck();\n \n+        TraceScope scope \u003d NullScope.INSTANCE;\n         while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n           // process responses from datanodes.\n           try {\n             // read an ack from the pipeline\n             long begin \u003d Time.monotonicNow();\n             ack.readFields(blockReplyStream);\n             long duration \u003d Time.monotonicNow() - begin;\n             if (duration \u003e dfsclientSlowLogThresholdMs\n                 \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n               DFSClient.LOG\n                   .warn(\"Slow ReadProcessor read fields took \" + duration\n                       + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                       + ack + \", targets: \" + Arrays.asList(targets));\n             } else if (DFSClient.LOG.isDebugEnabled()) {\n               DFSClient.LOG.debug(\"DFSClient \" + ack);\n             }\n \n             long seqno \u003d ack.getSeqno();\n             // processes response status from datanodes.\n             for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n               final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getReply(i));\n               // Restart will not be treated differently unless it is\n               // the local node or the only one in the pipeline.\n               if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                   shouldWaitForRestart(i)) {\n                 restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout +\n                     Time.now();\n                 setRestartingNodeIndex(i);\n                 String message \u003d \"A datanode is restarting: \" + targets[i];\n                 DFSClient.LOG.info(message);\n                throw new IOException(message);\n               }\n               // node error\n               if (reply !\u003d SUCCESS) {\n                 setErrorIndex(i); // first bad datanode\n                 throw new IOException(\"Bad response \" + reply +\n                     \" for block \" + block +\n                     \" from datanode \" + \n                     targets[i]);\n               }\n             }\n             \n             assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n             if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n               continue;\n             }\n \n             // a success ack for a data packet\n             DFSPacket one;\n             synchronized (dataQueue) {\n               one \u003d ackQueue.getFirst();\n             }\n             if (one.getSeqno() !\u003d seqno) {\n               throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                     \" for block \" + block +\n                                     one.getSeqno() + \" but received \" + seqno);\n             }\n             isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n             // Fail the packet write for testing in order to force a\n             // pipeline recovery.\n             if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n                 isLastPacketInBlock) {\n               failPacket \u003d true;\n               throw new IOException(\n                     \"Failing the last packet for testing.\");\n             }\n               \n             // update bytesAcked\n             block.setNumBytes(one.getLastByteOffsetBlock());\n \n             synchronized (dataQueue) {\n+              scope \u003d Trace.continueSpan(one.getTraceSpan());\n+              one.setTraceSpan(null);\n               lastAckedSeqno \u003d seqno;\n               ackQueue.removeFirst();\n               dataQueue.notifyAll();\n \n               one.releaseBuffer(byteArrayManager);\n             }\n           } catch (Exception e) {\n             if (!responderClosed) {\n               if (e instanceof IOException) {\n                 setLastException((IOException)e);\n               }\n               hasError \u003d true;\n               // If no explicit error report was received, mark the primary\n               // node as failed.\n               tryMarkPrimaryDatanodeFailed();\n               synchronized (dataQueue) {\n                 dataQueue.notifyAll();\n               }\n               if (restartingNodeIndex.get() \u003d\u003d -1) {\n                 DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                      + \" for block \" + block, e);\n               }\n               responderClosed \u003d true;\n             }\n+          } finally {\n+            scope.close();\n           }\n         }\n       }\n\\ No newline at end of file\n",
      "actualSource": "      public void run() {\n\n        setName(\"ResponseProcessor for block \" + block);\n        PipelineAck ack \u003d new PipelineAck();\n\n        TraceScope scope \u003d NullScope.INSTANCE;\n        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n          // process responses from datanodes.\n          try {\n            // read an ack from the pipeline\n            long begin \u003d Time.monotonicNow();\n            ack.readFields(blockReplyStream);\n            long duration \u003d Time.monotonicNow() - begin;\n            if (duration \u003e dfsclientSlowLogThresholdMs\n                \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n              DFSClient.LOG\n                  .warn(\"Slow ReadProcessor read fields took \" + duration\n                      + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                      + ack + \", targets: \" + Arrays.asList(targets));\n            } else if (DFSClient.LOG.isDebugEnabled()) {\n              DFSClient.LOG.debug(\"DFSClient \" + ack);\n            }\n\n            long seqno \u003d ack.getSeqno();\n            // processes response status from datanodes.\n            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n              final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getReply(i));\n              // Restart will not be treated differently unless it is\n              // the local node or the only one in the pipeline.\n              if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                  shouldWaitForRestart(i)) {\n                restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout +\n                    Time.now();\n                setRestartingNodeIndex(i);\n                String message \u003d \"A datanode is restarting: \" + targets[i];\n                DFSClient.LOG.info(message);\n               throw new IOException(message);\n              }\n              // node error\n              if (reply !\u003d SUCCESS) {\n                setErrorIndex(i); // first bad datanode\n                throw new IOException(\"Bad response \" + reply +\n                    \" for block \" + block +\n                    \" from datanode \" + \n                    targets[i]);\n              }\n            }\n            \n            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n            if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n              continue;\n            }\n\n            // a success ack for a data packet\n            DFSPacket one;\n            synchronized (dataQueue) {\n              one \u003d ackQueue.getFirst();\n            }\n            if (one.getSeqno() !\u003d seqno) {\n              throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                    \" for block \" + block +\n                                    one.getSeqno() + \" but received \" + seqno);\n            }\n            isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n            // Fail the packet write for testing in order to force a\n            // pipeline recovery.\n            if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n                isLastPacketInBlock) {\n              failPacket \u003d true;\n              throw new IOException(\n                    \"Failing the last packet for testing.\");\n            }\n              \n            // update bytesAcked\n            block.setNumBytes(one.getLastByteOffsetBlock());\n\n            synchronized (dataQueue) {\n              scope \u003d Trace.continueSpan(one.getTraceSpan());\n              one.setTraceSpan(null);\n              lastAckedSeqno \u003d seqno;\n              ackQueue.removeFirst();\n              dataQueue.notifyAll();\n\n              one.releaseBuffer(byteArrayManager);\n            }\n          } catch (Exception e) {\n            if (!responderClosed) {\n              if (e instanceof IOException) {\n                setLastException((IOException)e);\n              }\n              hasError \u003d true;\n              // If no explicit error report was received, mark the primary\n              // node as failed.\n              tryMarkPrimaryDatanodeFailed();\n              synchronized (dataQueue) {\n                dataQueue.notifyAll();\n              }\n              if (restartingNodeIndex.get() \u003d\u003d -1) {\n                DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                     + \" for block \" + block, e);\n              }\n              responderClosed \u003d true;\n            }\n          } finally {\n            scope.close();\n          }\n        }\n      }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "952640fa4cbdc23fe8781e5627c2e8eab565c535": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7855. Separate class Packet from DFSOutputStream. Contributed by Li Bo.\n",
      "commitDate": "05/03/15 10:58 AM",
      "commitName": "952640fa4cbdc23fe8781e5627c2e8eab565c535",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "01/03/15 11:03 PM",
      "commitNameOld": "67ed59348d638d56e6752ba2c71fdcd69567546d",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 3.5,
      "commitsBetweenForRepo": 39,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,106 @@\n       public void run() {\n \n         setName(\"ResponseProcessor for block \" + block);\n         PipelineAck ack \u003d new PipelineAck();\n \n         while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n           // process responses from datanodes.\n           try {\n             // read an ack from the pipeline\n             long begin \u003d Time.monotonicNow();\n             ack.readFields(blockReplyStream);\n             long duration \u003d Time.monotonicNow() - begin;\n             if (duration \u003e dfsclientSlowLogThresholdMs\n-                \u0026\u0026 ack.getSeqno() !\u003d Packet.HEART_BEAT_SEQNO) {\n+                \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n               DFSClient.LOG\n                   .warn(\"Slow ReadProcessor read fields took \" + duration\n                       + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                       + ack + \", targets: \" + Arrays.asList(targets));\n             } else if (DFSClient.LOG.isDebugEnabled()) {\n               DFSClient.LOG.debug(\"DFSClient \" + ack);\n             }\n \n             long seqno \u003d ack.getSeqno();\n             // processes response status from datanodes.\n             for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n               final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                 .getReply(i));\n               // Restart will not be treated differently unless it is\n               // the local node or the only one in the pipeline.\n               if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                   shouldWaitForRestart(i)) {\n                 restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout +\n                     Time.now();\n                 setRestartingNodeIndex(i);\n                 String message \u003d \"A datanode is restarting: \" + targets[i];\n                 DFSClient.LOG.info(message);\n                throw new IOException(message);\n               }\n               // node error\n               if (reply !\u003d SUCCESS) {\n                 setErrorIndex(i); // first bad datanode\n                 throw new IOException(\"Bad response \" + reply +\n                     \" for block \" + block +\n                     \" from datanode \" + \n                     targets[i]);\n               }\n             }\n             \n             assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n-            if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n+            if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n               continue;\n             }\n \n             // a success ack for a data packet\n-            Packet one;\n+            DFSPacket one;\n             synchronized (dataQueue) {\n               one \u003d ackQueue.getFirst();\n             }\n-            if (one.seqno !\u003d seqno) {\n+            if (one.getSeqno() !\u003d seqno) {\n               throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                     \" for block \" + block +\n-                                    one.seqno + \" but received \" + seqno);\n+                                    one.getSeqno() + \" but received \" + seqno);\n             }\n-            isLastPacketInBlock \u003d one.lastPacketInBlock;\n+            isLastPacketInBlock \u003d one.isLastPacketInBlock();\n \n             // Fail the packet write for testing in order to force a\n             // pipeline recovery.\n             if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n                 isLastPacketInBlock) {\n               failPacket \u003d true;\n               throw new IOException(\n                     \"Failing the last packet for testing.\");\n             }\n               \n             // update bytesAcked\n             block.setNumBytes(one.getLastByteOffsetBlock());\n \n             synchronized (dataQueue) {\n               lastAckedSeqno \u003d seqno;\n               ackQueue.removeFirst();\n               dataQueue.notifyAll();\n \n               one.releaseBuffer(byteArrayManager);\n             }\n           } catch (Exception e) {\n             if (!responderClosed) {\n               if (e instanceof IOException) {\n                 setLastException((IOException)e);\n               }\n               hasError \u003d true;\n               // If no explicit error report was received, mark the primary\n               // node as failed.\n               tryMarkPrimaryDatanodeFailed();\n               synchronized (dataQueue) {\n                 dataQueue.notifyAll();\n               }\n               if (restartingNodeIndex.get() \u003d\u003d -1) {\n                 DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                      + \" for block \" + block, e);\n               }\n               responderClosed \u003d true;\n             }\n           }\n         }\n       }\n\\ No newline at end of file\n",
      "actualSource": "      public void run() {\n\n        setName(\"ResponseProcessor for block \" + block);\n        PipelineAck ack \u003d new PipelineAck();\n\n        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n          // process responses from datanodes.\n          try {\n            // read an ack from the pipeline\n            long begin \u003d Time.monotonicNow();\n            ack.readFields(blockReplyStream);\n            long duration \u003d Time.monotonicNow() - begin;\n            if (duration \u003e dfsclientSlowLogThresholdMs\n                \u0026\u0026 ack.getSeqno() !\u003d DFSPacket.HEART_BEAT_SEQNO) {\n              DFSClient.LOG\n                  .warn(\"Slow ReadProcessor read fields took \" + duration\n                      + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                      + ack + \", targets: \" + Arrays.asList(targets));\n            } else if (DFSClient.LOG.isDebugEnabled()) {\n              DFSClient.LOG.debug(\"DFSClient \" + ack);\n            }\n\n            long seqno \u003d ack.getSeqno();\n            // processes response status from datanodes.\n            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n              final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getReply(i));\n              // Restart will not be treated differently unless it is\n              // the local node or the only one in the pipeline.\n              if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                  shouldWaitForRestart(i)) {\n                restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout +\n                    Time.now();\n                setRestartingNodeIndex(i);\n                String message \u003d \"A datanode is restarting: \" + targets[i];\n                DFSClient.LOG.info(message);\n               throw new IOException(message);\n              }\n              // node error\n              if (reply !\u003d SUCCESS) {\n                setErrorIndex(i); // first bad datanode\n                throw new IOException(\"Bad response \" + reply +\n                    \" for block \" + block +\n                    \" from datanode \" + \n                    targets[i]);\n              }\n            }\n            \n            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n            if (seqno \u003d\u003d DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack\n              continue;\n            }\n\n            // a success ack for a data packet\n            DFSPacket one;\n            synchronized (dataQueue) {\n              one \u003d ackQueue.getFirst();\n            }\n            if (one.getSeqno() !\u003d seqno) {\n              throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                    \" for block \" + block +\n                                    one.getSeqno() + \" but received \" + seqno);\n            }\n            isLastPacketInBlock \u003d one.isLastPacketInBlock();\n\n            // Fail the packet write for testing in order to force a\n            // pipeline recovery.\n            if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n                isLastPacketInBlock) {\n              failPacket \u003d true;\n              throw new IOException(\n                    \"Failing the last packet for testing.\");\n            }\n              \n            // update bytesAcked\n            block.setNumBytes(one.getLastByteOffsetBlock());\n\n            synchronized (dataQueue) {\n              lastAckedSeqno \u003d seqno;\n              ackQueue.removeFirst();\n              dataQueue.notifyAll();\n\n              one.releaseBuffer(byteArrayManager);\n            }\n          } catch (Exception e) {\n            if (!responderClosed) {\n              if (e instanceof IOException) {\n                setLastException((IOException)e);\n              }\n              hasError \u003d true;\n              // If no explicit error report was received, mark the primary\n              // node as failed.\n              tryMarkPrimaryDatanodeFailed();\n              synchronized (dataQueue) {\n                dataQueue.notifyAll();\n              }\n              if (restartingNodeIndex.get() \u003d\u003d -1) {\n                DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                     + \" for block \" + block, e);\n              }\n              responderClosed \u003d true;\n            }\n          }\n        }\n      }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "c4980a2f343778544ca20ebea1338651793ea0d9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7270. Add congestion signaling capability to DataNode write protocol. Contributed by Haohui Mai.\n",
      "commitDate": "05/02/15 10:58 AM",
      "commitName": "c4980a2f343778544ca20ebea1338651793ea0d9",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "30/01/15 4:01 PM",
      "commitNameOld": "09ad9a868a89922e9b55b3e7c5b9f41fa54d3770",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 5.79,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,105 +1,106 @@\n       public void run() {\n \n         setName(\"ResponseProcessor for block \" + block);\n         PipelineAck ack \u003d new PipelineAck();\n \n         while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n           // process responses from datanodes.\n           try {\n             // read an ack from the pipeline\n             long begin \u003d Time.monotonicNow();\n             ack.readFields(blockReplyStream);\n             long duration \u003d Time.monotonicNow() - begin;\n             if (duration \u003e dfsclientSlowLogThresholdMs\n                 \u0026\u0026 ack.getSeqno() !\u003d Packet.HEART_BEAT_SEQNO) {\n               DFSClient.LOG\n                   .warn(\"Slow ReadProcessor read fields took \" + duration\n                       + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                       + ack + \", targets: \" + Arrays.asList(targets));\n             } else if (DFSClient.LOG.isDebugEnabled()) {\n               DFSClient.LOG.debug(\"DFSClient \" + ack);\n             }\n \n             long seqno \u003d ack.getSeqno();\n             // processes response status from datanodes.\n             for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n-              final Status reply \u003d ack.getReply(i);\n+              final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n+                .getReply(i));\n               // Restart will not be treated differently unless it is\n               // the local node or the only one in the pipeline.\n               if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                   shouldWaitForRestart(i)) {\n                 restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout +\n                     Time.now();\n                 setRestartingNodeIndex(i);\n                 String message \u003d \"A datanode is restarting: \" + targets[i];\n                 DFSClient.LOG.info(message);\n                throw new IOException(message);\n               }\n               // node error\n               if (reply !\u003d SUCCESS) {\n                 setErrorIndex(i); // first bad datanode\n                 throw new IOException(\"Bad response \" + reply +\n                     \" for block \" + block +\n                     \" from datanode \" + \n                     targets[i]);\n               }\n             }\n             \n             assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n             if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n               continue;\n             }\n \n             // a success ack for a data packet\n             Packet one;\n             synchronized (dataQueue) {\n               one \u003d ackQueue.getFirst();\n             }\n             if (one.seqno !\u003d seqno) {\n               throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                     \" for block \" + block +\n                                     one.seqno + \" but received \" + seqno);\n             }\n             isLastPacketInBlock \u003d one.lastPacketInBlock;\n \n             // Fail the packet write for testing in order to force a\n             // pipeline recovery.\n             if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n                 isLastPacketInBlock) {\n               failPacket \u003d true;\n               throw new IOException(\n                     \"Failing the last packet for testing.\");\n             }\n               \n             // update bytesAcked\n             block.setNumBytes(one.getLastByteOffsetBlock());\n \n             synchronized (dataQueue) {\n               lastAckedSeqno \u003d seqno;\n               ackQueue.removeFirst();\n               dataQueue.notifyAll();\n \n               one.releaseBuffer(byteArrayManager);\n             }\n           } catch (Exception e) {\n             if (!responderClosed) {\n               if (e instanceof IOException) {\n                 setLastException((IOException)e);\n               }\n               hasError \u003d true;\n               // If no explicit error report was received, mark the primary\n               // node as failed.\n               tryMarkPrimaryDatanodeFailed();\n               synchronized (dataQueue) {\n                 dataQueue.notifyAll();\n               }\n               if (restartingNodeIndex.get() \u003d\u003d -1) {\n                 DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                      + \" for block \" + block, e);\n               }\n               responderClosed \u003d true;\n             }\n           }\n         }\n       }\n\\ No newline at end of file\n",
      "actualSource": "      public void run() {\n\n        setName(\"ResponseProcessor for block \" + block);\n        PipelineAck ack \u003d new PipelineAck();\n\n        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n          // process responses from datanodes.\n          try {\n            // read an ack from the pipeline\n            long begin \u003d Time.monotonicNow();\n            ack.readFields(blockReplyStream);\n            long duration \u003d Time.monotonicNow() - begin;\n            if (duration \u003e dfsclientSlowLogThresholdMs\n                \u0026\u0026 ack.getSeqno() !\u003d Packet.HEART_BEAT_SEQNO) {\n              DFSClient.LOG\n                  .warn(\"Slow ReadProcessor read fields took \" + duration\n                      + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                      + ack + \", targets: \" + Arrays.asList(targets));\n            } else if (DFSClient.LOG.isDebugEnabled()) {\n              DFSClient.LOG.debug(\"DFSClient \" + ack);\n            }\n\n            long seqno \u003d ack.getSeqno();\n            // processes response status from datanodes.\n            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n              final Status reply \u003d PipelineAck.getStatusFromHeader(ack\n                .getReply(i));\n              // Restart will not be treated differently unless it is\n              // the local node or the only one in the pipeline.\n              if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                  shouldWaitForRestart(i)) {\n                restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout +\n                    Time.now();\n                setRestartingNodeIndex(i);\n                String message \u003d \"A datanode is restarting: \" + targets[i];\n                DFSClient.LOG.info(message);\n               throw new IOException(message);\n              }\n              // node error\n              if (reply !\u003d SUCCESS) {\n                setErrorIndex(i); // first bad datanode\n                throw new IOException(\"Bad response \" + reply +\n                    \" for block \" + block +\n                    \" from datanode \" + \n                    targets[i]);\n              }\n            }\n            \n            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n            if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n              continue;\n            }\n\n            // a success ack for a data packet\n            Packet one;\n            synchronized (dataQueue) {\n              one \u003d ackQueue.getFirst();\n            }\n            if (one.seqno !\u003d seqno) {\n              throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                    \" for block \" + block +\n                                    one.seqno + \" but received \" + seqno);\n            }\n            isLastPacketInBlock \u003d one.lastPacketInBlock;\n\n            // Fail the packet write for testing in order to force a\n            // pipeline recovery.\n            if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n                isLastPacketInBlock) {\n              failPacket \u003d true;\n              throw new IOException(\n                    \"Failing the last packet for testing.\");\n            }\n              \n            // update bytesAcked\n            block.setNumBytes(one.getLastByteOffsetBlock());\n\n            synchronized (dataQueue) {\n              lastAckedSeqno \u003d seqno;\n              ackQueue.removeFirst();\n              dataQueue.notifyAll();\n\n              one.releaseBuffer(byteArrayManager);\n            }\n          } catch (Exception e) {\n            if (!responderClosed) {\n              if (e instanceof IOException) {\n                setLastException((IOException)e);\n              }\n              hasError \u003d true;\n              // If no explicit error report was received, mark the primary\n              // node as failed.\n              tryMarkPrimaryDatanodeFailed();\n              synchronized (dataQueue) {\n                dataQueue.notifyAll();\n              }\n              if (restartingNodeIndex.get() \u003d\u003d -1) {\n                DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                     + \" for block \" + block, e);\n              }\n              responderClosed \u003d true;\n            }\n          }\n        }\n      }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "b9f6d0c956f0278c8b9b83e05b523a442a730ebb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7515. Fix new findbugs warnings in hadoop-hdfs. Contributed by Haohui Mai.\n",
      "commitDate": "11/12/14 12:36 PM",
      "commitName": "b9f6d0c956f0278c8b9b83e05b523a442a730ebb",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "17/11/14 6:49 AM",
      "commitNameOld": "6783d17fcf5b25165767888f756a6b7802ab1371",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 24.24,
      "commitsBetweenForRepo": 165,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,105 +1,105 @@\n       public void run() {\n \n         setName(\"ResponseProcessor for block \" + block);\n         PipelineAck ack \u003d new PipelineAck();\n \n         while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n           // process responses from datanodes.\n           try {\n             // read an ack from the pipeline\n             long begin \u003d Time.monotonicNow();\n             ack.readFields(blockReplyStream);\n             long duration \u003d Time.monotonicNow() - begin;\n             if (duration \u003e dfsclientSlowLogThresholdMs\n                 \u0026\u0026 ack.getSeqno() !\u003d Packet.HEART_BEAT_SEQNO) {\n               DFSClient.LOG\n                   .warn(\"Slow ReadProcessor read fields took \" + duration\n                       + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                       + ack + \", targets: \" + Arrays.asList(targets));\n             } else if (DFSClient.LOG.isDebugEnabled()) {\n               DFSClient.LOG.debug(\"DFSClient \" + ack);\n             }\n \n             long seqno \u003d ack.getSeqno();\n             // processes response status from datanodes.\n             for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n               final Status reply \u003d ack.getReply(i);\n               // Restart will not be treated differently unless it is\n               // the local node or the only one in the pipeline.\n               if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                   shouldWaitForRestart(i)) {\n                 restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout +\n                     Time.now();\n                 setRestartingNodeIndex(i);\n                 String message \u003d \"A datanode is restarting: \" + targets[i];\n                 DFSClient.LOG.info(message);\n                throw new IOException(message);\n               }\n               // node error\n               if (reply !\u003d SUCCESS) {\n                 setErrorIndex(i); // first bad datanode\n                 throw new IOException(\"Bad response \" + reply +\n                     \" for block \" + block +\n                     \" from datanode \" + \n                     targets[i]);\n               }\n             }\n             \n             assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n             if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n               continue;\n             }\n \n             // a success ack for a data packet\n             Packet one;\n             synchronized (dataQueue) {\n               one \u003d ackQueue.getFirst();\n             }\n             if (one.seqno !\u003d seqno) {\n               throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                     \" for block \" + block +\n                                     one.seqno + \" but received \" + seqno);\n             }\n             isLastPacketInBlock \u003d one.lastPacketInBlock;\n \n             // Fail the packet write for testing in order to force a\n             // pipeline recovery.\n             if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n                 isLastPacketInBlock) {\n               failPacket \u003d true;\n               throw new IOException(\n                     \"Failing the last packet for testing.\");\n             }\n               \n             // update bytesAcked\n             block.setNumBytes(one.getLastByteOffsetBlock());\n \n             synchronized (dataQueue) {\n               lastAckedSeqno \u003d seqno;\n               ackQueue.removeFirst();\n               dataQueue.notifyAll();\n \n               one.releaseBuffer(byteArrayManager);\n             }\n           } catch (Exception e) {\n             if (!responderClosed) {\n               if (e instanceof IOException) {\n                 setLastException((IOException)e);\n               }\n               hasError \u003d true;\n               // If no explicit error report was received, mark the primary\n               // node as failed.\n               tryMarkPrimaryDatanodeFailed();\n               synchronized (dataQueue) {\n                 dataQueue.notifyAll();\n               }\n-              if (restartingNodeIndex \u003d\u003d -1) {\n+              if (restartingNodeIndex.get() \u003d\u003d -1) {\n                 DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                      + \" for block \" + block, e);\n               }\n               responderClosed \u003d true;\n             }\n           }\n         }\n       }\n\\ No newline at end of file\n",
      "actualSource": "      public void run() {\n\n        setName(\"ResponseProcessor for block \" + block);\n        PipelineAck ack \u003d new PipelineAck();\n\n        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n          // process responses from datanodes.\n          try {\n            // read an ack from the pipeline\n            long begin \u003d Time.monotonicNow();\n            ack.readFields(blockReplyStream);\n            long duration \u003d Time.monotonicNow() - begin;\n            if (duration \u003e dfsclientSlowLogThresholdMs\n                \u0026\u0026 ack.getSeqno() !\u003d Packet.HEART_BEAT_SEQNO) {\n              DFSClient.LOG\n                  .warn(\"Slow ReadProcessor read fields took \" + duration\n                      + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                      + ack + \", targets: \" + Arrays.asList(targets));\n            } else if (DFSClient.LOG.isDebugEnabled()) {\n              DFSClient.LOG.debug(\"DFSClient \" + ack);\n            }\n\n            long seqno \u003d ack.getSeqno();\n            // processes response status from datanodes.\n            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n              final Status reply \u003d ack.getReply(i);\n              // Restart will not be treated differently unless it is\n              // the local node or the only one in the pipeline.\n              if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                  shouldWaitForRestart(i)) {\n                restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout +\n                    Time.now();\n                setRestartingNodeIndex(i);\n                String message \u003d \"A datanode is restarting: \" + targets[i];\n                DFSClient.LOG.info(message);\n               throw new IOException(message);\n              }\n              // node error\n              if (reply !\u003d SUCCESS) {\n                setErrorIndex(i); // first bad datanode\n                throw new IOException(\"Bad response \" + reply +\n                    \" for block \" + block +\n                    \" from datanode \" + \n                    targets[i]);\n              }\n            }\n            \n            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n            if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n              continue;\n            }\n\n            // a success ack for a data packet\n            Packet one;\n            synchronized (dataQueue) {\n              one \u003d ackQueue.getFirst();\n            }\n            if (one.seqno !\u003d seqno) {\n              throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                    \" for block \" + block +\n                                    one.seqno + \" but received \" + seqno);\n            }\n            isLastPacketInBlock \u003d one.lastPacketInBlock;\n\n            // Fail the packet write for testing in order to force a\n            // pipeline recovery.\n            if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n                isLastPacketInBlock) {\n              failPacket \u003d true;\n              throw new IOException(\n                    \"Failing the last packet for testing.\");\n            }\n              \n            // update bytesAcked\n            block.setNumBytes(one.getLastByteOffsetBlock());\n\n            synchronized (dataQueue) {\n              lastAckedSeqno \u003d seqno;\n              ackQueue.removeFirst();\n              dataQueue.notifyAll();\n\n              one.releaseBuffer(byteArrayManager);\n            }\n          } catch (Exception e) {\n            if (!responderClosed) {\n              if (e instanceof IOException) {\n                setLastException((IOException)e);\n              }\n              hasError \u003d true;\n              // If no explicit error report was received, mark the primary\n              // node as failed.\n              tryMarkPrimaryDatanodeFailed();\n              synchronized (dataQueue) {\n                dataQueue.notifyAll();\n              }\n              if (restartingNodeIndex.get() \u003d\u003d -1) {\n                DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                     + \" for block \" + block, e);\n              }\n              responderClosed \u003d true;\n            }\n          }\n        }\n      }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "36ccf097a95eae0761de7b657752e4808a86c094": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7276. Limit the number of byte arrays used by DFSOutputStream and provide a mechanism for recycling arrays.\n",
      "commitDate": "01/11/14 11:22 AM",
      "commitName": "36ccf097a95eae0761de7b657752e4808a86c094",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "27/10/14 9:38 AM",
      "commitNameOld": "463aec11718e47d4aabb86a7a539cb973460aae6",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 5.07,
      "commitsBetweenForRepo": 75,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,103 +1,105 @@\n       public void run() {\n \n         setName(\"ResponseProcessor for block \" + block);\n         PipelineAck ack \u003d new PipelineAck();\n \n         while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n           // process responses from datanodes.\n           try {\n             // read an ack from the pipeline\n             long begin \u003d Time.monotonicNow();\n             ack.readFields(blockReplyStream);\n             long duration \u003d Time.monotonicNow() - begin;\n             if (duration \u003e dfsclientSlowLogThresholdMs\n                 \u0026\u0026 ack.getSeqno() !\u003d Packet.HEART_BEAT_SEQNO) {\n               DFSClient.LOG\n                   .warn(\"Slow ReadProcessor read fields took \" + duration\n                       + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                       + ack + \", targets: \" + Arrays.asList(targets));\n             } else if (DFSClient.LOG.isDebugEnabled()) {\n               DFSClient.LOG.debug(\"DFSClient \" + ack);\n             }\n \n             long seqno \u003d ack.getSeqno();\n             // processes response status from datanodes.\n             for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n               final Status reply \u003d ack.getReply(i);\n               // Restart will not be treated differently unless it is\n               // the local node or the only one in the pipeline.\n               if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                   shouldWaitForRestart(i)) {\n                 restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout +\n                     Time.now();\n                 setRestartingNodeIndex(i);\n                 String message \u003d \"A datanode is restarting: \" + targets[i];\n                 DFSClient.LOG.info(message);\n                throw new IOException(message);\n               }\n               // node error\n               if (reply !\u003d SUCCESS) {\n                 setErrorIndex(i); // first bad datanode\n                 throw new IOException(\"Bad response \" + reply +\n                     \" for block \" + block +\n                     \" from datanode \" + \n                     targets[i]);\n               }\n             }\n             \n             assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n             if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n               continue;\n             }\n \n             // a success ack for a data packet\n             Packet one;\n             synchronized (dataQueue) {\n               one \u003d ackQueue.getFirst();\n             }\n             if (one.seqno !\u003d seqno) {\n               throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                     \" for block \" + block +\n                                     one.seqno + \" but received \" + seqno);\n             }\n             isLastPacketInBlock \u003d one.lastPacketInBlock;\n \n             // Fail the packet write for testing in order to force a\n             // pipeline recovery.\n             if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n                 isLastPacketInBlock) {\n               failPacket \u003d true;\n               throw new IOException(\n                     \"Failing the last packet for testing.\");\n             }\n               \n             // update bytesAcked\n             block.setNumBytes(one.getLastByteOffsetBlock());\n \n             synchronized (dataQueue) {\n               lastAckedSeqno \u003d seqno;\n               ackQueue.removeFirst();\n               dataQueue.notifyAll();\n+\n+              one.releaseBuffer(byteArrayManager);\n             }\n           } catch (Exception e) {\n             if (!responderClosed) {\n               if (e instanceof IOException) {\n                 setLastException((IOException)e);\n               }\n               hasError \u003d true;\n               // If no explicit error report was received, mark the primary\n               // node as failed.\n               tryMarkPrimaryDatanodeFailed();\n               synchronized (dataQueue) {\n                 dataQueue.notifyAll();\n               }\n               if (restartingNodeIndex \u003d\u003d -1) {\n                 DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                      + \" for block \" + block, e);\n               }\n               responderClosed \u003d true;\n             }\n           }\n         }\n       }\n\\ No newline at end of file\n",
      "actualSource": "      public void run() {\n\n        setName(\"ResponseProcessor for block \" + block);\n        PipelineAck ack \u003d new PipelineAck();\n\n        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n          // process responses from datanodes.\n          try {\n            // read an ack from the pipeline\n            long begin \u003d Time.monotonicNow();\n            ack.readFields(blockReplyStream);\n            long duration \u003d Time.monotonicNow() - begin;\n            if (duration \u003e dfsclientSlowLogThresholdMs\n                \u0026\u0026 ack.getSeqno() !\u003d Packet.HEART_BEAT_SEQNO) {\n              DFSClient.LOG\n                  .warn(\"Slow ReadProcessor read fields took \" + duration\n                      + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                      + ack + \", targets: \" + Arrays.asList(targets));\n            } else if (DFSClient.LOG.isDebugEnabled()) {\n              DFSClient.LOG.debug(\"DFSClient \" + ack);\n            }\n\n            long seqno \u003d ack.getSeqno();\n            // processes response status from datanodes.\n            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n              final Status reply \u003d ack.getReply(i);\n              // Restart will not be treated differently unless it is\n              // the local node or the only one in the pipeline.\n              if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                  shouldWaitForRestart(i)) {\n                restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout +\n                    Time.now();\n                setRestartingNodeIndex(i);\n                String message \u003d \"A datanode is restarting: \" + targets[i];\n                DFSClient.LOG.info(message);\n               throw new IOException(message);\n              }\n              // node error\n              if (reply !\u003d SUCCESS) {\n                setErrorIndex(i); // first bad datanode\n                throw new IOException(\"Bad response \" + reply +\n                    \" for block \" + block +\n                    \" from datanode \" + \n                    targets[i]);\n              }\n            }\n            \n            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n            if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n              continue;\n            }\n\n            // a success ack for a data packet\n            Packet one;\n            synchronized (dataQueue) {\n              one \u003d ackQueue.getFirst();\n            }\n            if (one.seqno !\u003d seqno) {\n              throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                    \" for block \" + block +\n                                    one.seqno + \" but received \" + seqno);\n            }\n            isLastPacketInBlock \u003d one.lastPacketInBlock;\n\n            // Fail the packet write for testing in order to force a\n            // pipeline recovery.\n            if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n                isLastPacketInBlock) {\n              failPacket \u003d true;\n              throw new IOException(\n                    \"Failing the last packet for testing.\");\n            }\n              \n            // update bytesAcked\n            block.setNumBytes(one.getLastByteOffsetBlock());\n\n            synchronized (dataQueue) {\n              lastAckedSeqno \u003d seqno;\n              ackQueue.removeFirst();\n              dataQueue.notifyAll();\n\n              one.releaseBuffer(byteArrayManager);\n            }\n          } catch (Exception e) {\n            if (!responderClosed) {\n              if (e instanceof IOException) {\n                setLastException((IOException)e);\n              }\n              hasError \u003d true;\n              // If no explicit error report was received, mark the primary\n              // node as failed.\n              tryMarkPrimaryDatanodeFailed();\n              synchronized (dataQueue) {\n                dataQueue.notifyAll();\n              }\n              if (restartingNodeIndex \u003d\u003d -1) {\n                DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                     + \" for block \" + block, e);\n              }\n              responderClosed \u003d true;\n            }\n          }\n        }\n      }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "1228f8f6fb16de4f0283dd1c7939e6fc3dfb7aae": {
      "type": "Ybodychange",
      "commitMessage": "HBASE-6110 adding more slow action log in critical write path (Liang Xie via stack)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1597633 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/05/14 12:38 PM",
      "commitName": "1228f8f6fb16de4f0283dd1c7939e6fc3dfb7aae",
      "commitAuthor": "Michael Stack",
      "commitDateOld": "09/05/14 3:36 PM",
      "commitNameOld": "f131dba8a3d603a5d15c4f035ed3da75b4daf0dc",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 16.88,
      "commitsBetweenForRepo": 97,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,95 +1,103 @@\n       public void run() {\n \n         setName(\"ResponseProcessor for block \" + block);\n         PipelineAck ack \u003d new PipelineAck();\n \n         while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n           // process responses from datanodes.\n           try {\n             // read an ack from the pipeline\n+            long begin \u003d Time.monotonicNow();\n             ack.readFields(blockReplyStream);\n-            if (DFSClient.LOG.isDebugEnabled()) {\n+            long duration \u003d Time.monotonicNow() - begin;\n+            if (duration \u003e dfsclientSlowLogThresholdMs\n+                \u0026\u0026 ack.getSeqno() !\u003d Packet.HEART_BEAT_SEQNO) {\n+              DFSClient.LOG\n+                  .warn(\"Slow ReadProcessor read fields took \" + duration\n+                      + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n+                      + ack + \", targets: \" + Arrays.asList(targets));\n+            } else if (DFSClient.LOG.isDebugEnabled()) {\n               DFSClient.LOG.debug(\"DFSClient \" + ack);\n             }\n-            \n+\n             long seqno \u003d ack.getSeqno();\n             // processes response status from datanodes.\n             for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n               final Status reply \u003d ack.getReply(i);\n               // Restart will not be treated differently unless it is\n               // the local node or the only one in the pipeline.\n               if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                   shouldWaitForRestart(i)) {\n                 restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout +\n                     Time.now();\n                 setRestartingNodeIndex(i);\n                 String message \u003d \"A datanode is restarting: \" + targets[i];\n                 DFSClient.LOG.info(message);\n                throw new IOException(message);\n               }\n               // node error\n               if (reply !\u003d SUCCESS) {\n                 setErrorIndex(i); // first bad datanode\n                 throw new IOException(\"Bad response \" + reply +\n                     \" for block \" + block +\n                     \" from datanode \" + \n                     targets[i]);\n               }\n             }\n             \n             assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n             if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n               continue;\n             }\n \n             // a success ack for a data packet\n             Packet one;\n             synchronized (dataQueue) {\n               one \u003d ackQueue.getFirst();\n             }\n             if (one.seqno !\u003d seqno) {\n               throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                     \" for block \" + block +\n                                     one.seqno + \" but received \" + seqno);\n             }\n             isLastPacketInBlock \u003d one.lastPacketInBlock;\n \n             // Fail the packet write for testing in order to force a\n             // pipeline recovery.\n             if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n                 isLastPacketInBlock) {\n               failPacket \u003d true;\n               throw new IOException(\n                     \"Failing the last packet for testing.\");\n             }\n               \n             // update bytesAcked\n             block.setNumBytes(one.getLastByteOffsetBlock());\n \n             synchronized (dataQueue) {\n               lastAckedSeqno \u003d seqno;\n               ackQueue.removeFirst();\n               dataQueue.notifyAll();\n             }\n           } catch (Exception e) {\n             if (!responderClosed) {\n               if (e instanceof IOException) {\n                 setLastException((IOException)e);\n               }\n               hasError \u003d true;\n               // If no explicit error report was received, mark the primary\n               // node as failed.\n               tryMarkPrimaryDatanodeFailed();\n               synchronized (dataQueue) {\n                 dataQueue.notifyAll();\n               }\n               if (restartingNodeIndex \u003d\u003d -1) {\n                 DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                      + \" for block \" + block, e);\n               }\n               responderClosed \u003d true;\n             }\n           }\n         }\n       }\n\\ No newline at end of file\n",
      "actualSource": "      public void run() {\n\n        setName(\"ResponseProcessor for block \" + block);\n        PipelineAck ack \u003d new PipelineAck();\n\n        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n          // process responses from datanodes.\n          try {\n            // read an ack from the pipeline\n            long begin \u003d Time.monotonicNow();\n            ack.readFields(blockReplyStream);\n            long duration \u003d Time.monotonicNow() - begin;\n            if (duration \u003e dfsclientSlowLogThresholdMs\n                \u0026\u0026 ack.getSeqno() !\u003d Packet.HEART_BEAT_SEQNO) {\n              DFSClient.LOG\n                  .warn(\"Slow ReadProcessor read fields took \" + duration\n                      + \"ms (threshold\u003d\" + dfsclientSlowLogThresholdMs + \"ms); ack: \"\n                      + ack + \", targets: \" + Arrays.asList(targets));\n            } else if (DFSClient.LOG.isDebugEnabled()) {\n              DFSClient.LOG.debug(\"DFSClient \" + ack);\n            }\n\n            long seqno \u003d ack.getSeqno();\n            // processes response status from datanodes.\n            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n              final Status reply \u003d ack.getReply(i);\n              // Restart will not be treated differently unless it is\n              // the local node or the only one in the pipeline.\n              if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                  shouldWaitForRestart(i)) {\n                restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout +\n                    Time.now();\n                setRestartingNodeIndex(i);\n                String message \u003d \"A datanode is restarting: \" + targets[i];\n                DFSClient.LOG.info(message);\n               throw new IOException(message);\n              }\n              // node error\n              if (reply !\u003d SUCCESS) {\n                setErrorIndex(i); // first bad datanode\n                throw new IOException(\"Bad response \" + reply +\n                    \" for block \" + block +\n                    \" from datanode \" + \n                    targets[i]);\n              }\n            }\n            \n            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n            if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n              continue;\n            }\n\n            // a success ack for a data packet\n            Packet one;\n            synchronized (dataQueue) {\n              one \u003d ackQueue.getFirst();\n            }\n            if (one.seqno !\u003d seqno) {\n              throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                    \" for block \" + block +\n                                    one.seqno + \" but received \" + seqno);\n            }\n            isLastPacketInBlock \u003d one.lastPacketInBlock;\n\n            // Fail the packet write for testing in order to force a\n            // pipeline recovery.\n            if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n                isLastPacketInBlock) {\n              failPacket \u003d true;\n              throw new IOException(\n                    \"Failing the last packet for testing.\");\n            }\n              \n            // update bytesAcked\n            block.setNumBytes(one.getLastByteOffsetBlock());\n\n            synchronized (dataQueue) {\n              lastAckedSeqno \u003d seqno;\n              ackQueue.removeFirst();\n              dataQueue.notifyAll();\n            }\n          } catch (Exception e) {\n            if (!responderClosed) {\n              if (e instanceof IOException) {\n                setLastException((IOException)e);\n              }\n              hasError \u003d true;\n              // If no explicit error report was received, mark the primary\n              // node as failed.\n              tryMarkPrimaryDatanodeFailed();\n              synchronized (dataQueue) {\n                dataQueue.notifyAll();\n              }\n              if (restartingNodeIndex \u003d\u003d -1) {\n                DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                     + \" for block \" + block, e);\n              }\n              responderClosed \u003d true;\n            }\n          }\n        }\n      }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "57b28693ee295746c6d168d37dd05eaf7b601b87": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5924. Utilize OOB upgrade message processing for writes. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1571792 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/02/14 11:24 AM",
      "commitName": "57b28693ee295746c6d168d37dd05eaf7b601b87",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "24/02/14 6:16 PM",
      "commitNameOld": "440c3cd1050f2a871a73d44406c0013b6ff73f2e",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.71,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,79 +1,95 @@\n       public void run() {\n \n         setName(\"ResponseProcessor for block \" + block);\n         PipelineAck ack \u003d new PipelineAck();\n \n         while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n           // process responses from datanodes.\n           try {\n             // read an ack from the pipeline\n             ack.readFields(blockReplyStream);\n             if (DFSClient.LOG.isDebugEnabled()) {\n               DFSClient.LOG.debug(\"DFSClient \" + ack);\n             }\n             \n             long seqno \u003d ack.getSeqno();\n             // processes response status from datanodes.\n             for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n               final Status reply \u003d ack.getReply(i);\n+              // Restart will not be treated differently unless it is\n+              // the local node or the only one in the pipeline.\n+              if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n+                  shouldWaitForRestart(i)) {\n+                restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout +\n+                    Time.now();\n+                setRestartingNodeIndex(i);\n+                String message \u003d \"A datanode is restarting: \" + targets[i];\n+                DFSClient.LOG.info(message);\n+               throw new IOException(message);\n+              }\n+              // node error\n               if (reply !\u003d SUCCESS) {\n-                errorIndex \u003d i; // first bad datanode\n+                setErrorIndex(i); // first bad datanode\n                 throw new IOException(\"Bad response \" + reply +\n                     \" for block \" + block +\n                     \" from datanode \" + \n                     targets[i]);\n               }\n             }\n             \n             assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n             if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n               continue;\n             }\n \n             // a success ack for a data packet\n             Packet one;\n             synchronized (dataQueue) {\n               one \u003d ackQueue.getFirst();\n             }\n             if (one.seqno !\u003d seqno) {\n               throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                     \" for block \" + block +\n                                     one.seqno + \" but received \" + seqno);\n             }\n             isLastPacketInBlock \u003d one.lastPacketInBlock;\n \n             // Fail the packet write for testing in order to force a\n             // pipeline recovery.\n             if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n                 isLastPacketInBlock) {\n               failPacket \u003d true;\n               throw new IOException(\n                     \"Failing the last packet for testing.\");\n             }\n               \n             // update bytesAcked\n             block.setNumBytes(one.getLastByteOffsetBlock());\n \n             synchronized (dataQueue) {\n               lastAckedSeqno \u003d seqno;\n               ackQueue.removeFirst();\n               dataQueue.notifyAll();\n             }\n           } catch (Exception e) {\n             if (!responderClosed) {\n               if (e instanceof IOException) {\n                 setLastException((IOException)e);\n               }\n               hasError \u003d true;\n-              errorIndex \u003d errorIndex\u003d\u003d-1 ? 0 : errorIndex;\n+              // If no explicit error report was received, mark the primary\n+              // node as failed.\n+              tryMarkPrimaryDatanodeFailed();\n               synchronized (dataQueue) {\n                 dataQueue.notifyAll();\n               }\n-              DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n-                  + \" for block \" + block, e);\n+              if (restartingNodeIndex \u003d\u003d -1) {\n+                DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n+                     + \" for block \" + block, e);\n+              }\n               responderClosed \u003d true;\n             }\n           }\n         }\n       }\n\\ No newline at end of file\n",
      "actualSource": "      public void run() {\n\n        setName(\"ResponseProcessor for block \" + block);\n        PipelineAck ack \u003d new PipelineAck();\n\n        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n          // process responses from datanodes.\n          try {\n            // read an ack from the pipeline\n            ack.readFields(blockReplyStream);\n            if (DFSClient.LOG.isDebugEnabled()) {\n              DFSClient.LOG.debug(\"DFSClient \" + ack);\n            }\n            \n            long seqno \u003d ack.getSeqno();\n            // processes response status from datanodes.\n            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n              final Status reply \u003d ack.getReply(i);\n              // Restart will not be treated differently unless it is\n              // the local node or the only one in the pipeline.\n              if (PipelineAck.isRestartOOBStatus(reply) \u0026\u0026\n                  shouldWaitForRestart(i)) {\n                restartDeadline \u003d dfsClient.getConf().datanodeRestartTimeout +\n                    Time.now();\n                setRestartingNodeIndex(i);\n                String message \u003d \"A datanode is restarting: \" + targets[i];\n                DFSClient.LOG.info(message);\n               throw new IOException(message);\n              }\n              // node error\n              if (reply !\u003d SUCCESS) {\n                setErrorIndex(i); // first bad datanode\n                throw new IOException(\"Bad response \" + reply +\n                    \" for block \" + block +\n                    \" from datanode \" + \n                    targets[i]);\n              }\n            }\n            \n            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n            if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n              continue;\n            }\n\n            // a success ack for a data packet\n            Packet one;\n            synchronized (dataQueue) {\n              one \u003d ackQueue.getFirst();\n            }\n            if (one.seqno !\u003d seqno) {\n              throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                    \" for block \" + block +\n                                    one.seqno + \" but received \" + seqno);\n            }\n            isLastPacketInBlock \u003d one.lastPacketInBlock;\n\n            // Fail the packet write for testing in order to force a\n            // pipeline recovery.\n            if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n                isLastPacketInBlock) {\n              failPacket \u003d true;\n              throw new IOException(\n                    \"Failing the last packet for testing.\");\n            }\n              \n            // update bytesAcked\n            block.setNumBytes(one.getLastByteOffsetBlock());\n\n            synchronized (dataQueue) {\n              lastAckedSeqno \u003d seqno;\n              ackQueue.removeFirst();\n              dataQueue.notifyAll();\n            }\n          } catch (Exception e) {\n            if (!responderClosed) {\n              if (e instanceof IOException) {\n                setLastException((IOException)e);\n              }\n              hasError \u003d true;\n              // If no explicit error report was received, mark the primary\n              // node as failed.\n              tryMarkPrimaryDatanodeFailed();\n              synchronized (dataQueue) {\n                dataQueue.notifyAll();\n              }\n              if (restartingNodeIndex \u003d\u003d -1) {\n                DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                     + \" for block \" + block, e);\n              }\n              responderClosed \u003d true;\n            }\n          }\n        }\n      }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "ceea91c9cd8b2a18be13217894ccf1c17198de18": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5438. Flaws in block report processing can cause data loss. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1542054 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/11/13 12:11 PM",
      "commitName": "ceea91c9cd8b2a18be13217894ccf1c17198de18",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "25/10/13 11:43 AM",
      "commitNameOld": "5829029154b8e8e02bc6aeb45435046ca080bbe9",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 20.06,
      "commitsBetweenForRepo": 102,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,79 @@\n       public void run() {\n \n         setName(\"ResponseProcessor for block \" + block);\n         PipelineAck ack \u003d new PipelineAck();\n \n         while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n           // process responses from datanodes.\n           try {\n             // read an ack from the pipeline\n             ack.readFields(blockReplyStream);\n             if (DFSClient.LOG.isDebugEnabled()) {\n               DFSClient.LOG.debug(\"DFSClient \" + ack);\n             }\n             \n             long seqno \u003d ack.getSeqno();\n             // processes response status from datanodes.\n             for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n               final Status reply \u003d ack.getReply(i);\n               if (reply !\u003d SUCCESS) {\n                 errorIndex \u003d i; // first bad datanode\n                 throw new IOException(\"Bad response \" + reply +\n                     \" for block \" + block +\n                     \" from datanode \" + \n                     targets[i]);\n               }\n             }\n             \n             assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n               \"Ack for unknown seqno should be a failed ack: \" + ack;\n             if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n               continue;\n             }\n \n             // a success ack for a data packet\n             Packet one;\n             synchronized (dataQueue) {\n               one \u003d ackQueue.getFirst();\n             }\n             if (one.seqno !\u003d seqno) {\n               throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                     \" for block \" + block +\n                                     one.seqno + \" but received \" + seqno);\n             }\n             isLastPacketInBlock \u003d one.lastPacketInBlock;\n+\n+            // Fail the packet write for testing in order to force a\n+            // pipeline recovery.\n+            if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n+                isLastPacketInBlock) {\n+              failPacket \u003d true;\n+              throw new IOException(\n+                    \"Failing the last packet for testing.\");\n+            }\n+              \n             // update bytesAcked\n             block.setNumBytes(one.getLastByteOffsetBlock());\n \n             synchronized (dataQueue) {\n               lastAckedSeqno \u003d seqno;\n               ackQueue.removeFirst();\n               dataQueue.notifyAll();\n             }\n           } catch (Exception e) {\n             if (!responderClosed) {\n               if (e instanceof IOException) {\n                 setLastException((IOException)e);\n               }\n               hasError \u003d true;\n               errorIndex \u003d errorIndex\u003d\u003d-1 ? 0 : errorIndex;\n               synchronized (dataQueue) {\n                 dataQueue.notifyAll();\n               }\n               DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                   + \" for block \" + block, e);\n               responderClosed \u003d true;\n             }\n           }\n         }\n       }\n\\ No newline at end of file\n",
      "actualSource": "      public void run() {\n\n        setName(\"ResponseProcessor for block \" + block);\n        PipelineAck ack \u003d new PipelineAck();\n\n        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n          // process responses from datanodes.\n          try {\n            // read an ack from the pipeline\n            ack.readFields(blockReplyStream);\n            if (DFSClient.LOG.isDebugEnabled()) {\n              DFSClient.LOG.debug(\"DFSClient \" + ack);\n            }\n            \n            long seqno \u003d ack.getSeqno();\n            // processes response status from datanodes.\n            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n              final Status reply \u003d ack.getReply(i);\n              if (reply !\u003d SUCCESS) {\n                errorIndex \u003d i; // first bad datanode\n                throw new IOException(\"Bad response \" + reply +\n                    \" for block \" + block +\n                    \" from datanode \" + \n                    targets[i]);\n              }\n            }\n            \n            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n            if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n              continue;\n            }\n\n            // a success ack for a data packet\n            Packet one;\n            synchronized (dataQueue) {\n              one \u003d ackQueue.getFirst();\n            }\n            if (one.seqno !\u003d seqno) {\n              throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                    \" for block \" + block +\n                                    one.seqno + \" but received \" + seqno);\n            }\n            isLastPacketInBlock \u003d one.lastPacketInBlock;\n\n            // Fail the packet write for testing in order to force a\n            // pipeline recovery.\n            if (DFSClientFaultInjector.get().failPacket() \u0026\u0026\n                isLastPacketInBlock) {\n              failPacket \u003d true;\n              throw new IOException(\n                    \"Failing the last packet for testing.\");\n            }\n              \n            // update bytesAcked\n            block.setNumBytes(one.getLastByteOffsetBlock());\n\n            synchronized (dataQueue) {\n              lastAckedSeqno \u003d seqno;\n              ackQueue.removeFirst();\n              dataQueue.notifyAll();\n            }\n          } catch (Exception e) {\n            if (!responderClosed) {\n              if (e instanceof IOException) {\n                setLastException((IOException)e);\n              }\n              hasError \u003d true;\n              errorIndex \u003d errorIndex\u003d\u003d-1 ? 0 : errorIndex;\n              synchronized (dataQueue) {\n                dataQueue.notifyAll();\n              }\n              DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                  + \" for block \" + block, e);\n              responderClosed \u003d true;\n            }\n          }\n        }\n      }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "631ccbdd2031a8387d4c2b743a4fc64c990391ce": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5374. Remove deadcode in DFSOutputStream. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1533258 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/10/13 1:47 PM",
      "commitName": "631ccbdd2031a8387d4c2b743a4fc64c990391ce",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "10/10/13 4:58 PM",
      "commitNameOld": "f2f5cdb5554d294a29ebf465101c5607fd56e244",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 6.87,
      "commitsBetweenForRepo": 49,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,69 @@\n       public void run() {\n \n         setName(\"ResponseProcessor for block \" + block);\n         PipelineAck ack \u003d new PipelineAck();\n \n         while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n           // process responses from datanodes.\n           try {\n             // read an ack from the pipeline\n             ack.readFields(blockReplyStream);\n             if (DFSClient.LOG.isDebugEnabled()) {\n               DFSClient.LOG.debug(\"DFSClient \" + ack);\n             }\n             \n             long seqno \u003d ack.getSeqno();\n             // processes response status from datanodes.\n             for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n               final Status reply \u003d ack.getReply(i);\n               if (reply !\u003d SUCCESS) {\n                 errorIndex \u003d i; // first bad datanode\n                 throw new IOException(\"Bad response \" + reply +\n                     \" for block \" + block +\n                     \" from datanode \" + \n                     targets[i]);\n               }\n             }\n             \n             assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n-              \"Ack for unkown seqno should be a failed ack: \" + ack;\n+              \"Ack for unknown seqno should be a failed ack: \" + ack;\n             if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n               continue;\n             }\n \n             // a success ack for a data packet\n-            Packet one \u003d null;\n+            Packet one;\n             synchronized (dataQueue) {\n               one \u003d ackQueue.getFirst();\n             }\n             if (one.seqno !\u003d seqno) {\n-              throw new IOException(\"Responseprocessor: Expecting seqno \" +\n+              throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                     \" for block \" + block +\n                                     one.seqno + \" but received \" + seqno);\n             }\n             isLastPacketInBlock \u003d one.lastPacketInBlock;\n             // update bytesAcked\n             block.setNumBytes(one.getLastByteOffsetBlock());\n \n             synchronized (dataQueue) {\n               lastAckedSeqno \u003d seqno;\n               ackQueue.removeFirst();\n               dataQueue.notifyAll();\n             }\n           } catch (Exception e) {\n             if (!responderClosed) {\n               if (e instanceof IOException) {\n                 setLastException((IOException)e);\n               }\n               hasError \u003d true;\n               errorIndex \u003d errorIndex\u003d\u003d-1 ? 0 : errorIndex;\n               synchronized (dataQueue) {\n                 dataQueue.notifyAll();\n               }\n               DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                   + \" for block \" + block, e);\n               responderClosed \u003d true;\n             }\n           }\n         }\n       }\n\\ No newline at end of file\n",
      "actualSource": "      public void run() {\n\n        setName(\"ResponseProcessor for block \" + block);\n        PipelineAck ack \u003d new PipelineAck();\n\n        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n          // process responses from datanodes.\n          try {\n            // read an ack from the pipeline\n            ack.readFields(blockReplyStream);\n            if (DFSClient.LOG.isDebugEnabled()) {\n              DFSClient.LOG.debug(\"DFSClient \" + ack);\n            }\n            \n            long seqno \u003d ack.getSeqno();\n            // processes response status from datanodes.\n            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n              final Status reply \u003d ack.getReply(i);\n              if (reply !\u003d SUCCESS) {\n                errorIndex \u003d i; // first bad datanode\n                throw new IOException(\"Bad response \" + reply +\n                    \" for block \" + block +\n                    \" from datanode \" + \n                    targets[i]);\n              }\n            }\n            \n            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n              \"Ack for unknown seqno should be a failed ack: \" + ack;\n            if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n              continue;\n            }\n\n            // a success ack for a data packet\n            Packet one;\n            synchronized (dataQueue) {\n              one \u003d ackQueue.getFirst();\n            }\n            if (one.seqno !\u003d seqno) {\n              throw new IOException(\"ResponseProcessor: Expecting seqno \" +\n                                    \" for block \" + block +\n                                    one.seqno + \" but received \" + seqno);\n            }\n            isLastPacketInBlock \u003d one.lastPacketInBlock;\n            // update bytesAcked\n            block.setNumBytes(one.getLastByteOffsetBlock());\n\n            synchronized (dataQueue) {\n              lastAckedSeqno \u003d seqno;\n              ackQueue.removeFirst();\n              dataQueue.notifyAll();\n            }\n          } catch (Exception e) {\n            if (!responderClosed) {\n              if (e instanceof IOException) {\n                setLastException((IOException)e);\n              }\n              hasError \u003d true;\n              errorIndex \u003d errorIndex\u003d\u003d-1 ? 0 : errorIndex;\n              synchronized (dataQueue) {\n                dataQueue.notifyAll();\n              }\n              DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                  + \" for block \" + block, e);\n              responderClosed \u003d true;\n            }\n          }\n        }\n      }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "be7dd8333a7e56e732171db0781786987de03195": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3144. Refactor DatanodeID#getName by use. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308205 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/04/12 3:12 PM",
      "commitName": "be7dd8333a7e56e732171db0781786987de03195",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "01/03/12 3:51 PM",
      "commitNameOld": "b2f67b47044a5cbb0c3aaac83299afba541aa771",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 30.93,
      "commitsBetweenForRepo": 182,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,69 @@\n       public void run() {\n \n         setName(\"ResponseProcessor for block \" + block);\n         PipelineAck ack \u003d new PipelineAck();\n \n         while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n           // process responses from datanodes.\n           try {\n             // read an ack from the pipeline\n             ack.readFields(blockReplyStream);\n             if (DFSClient.LOG.isDebugEnabled()) {\n               DFSClient.LOG.debug(\"DFSClient \" + ack);\n             }\n             \n             long seqno \u003d ack.getSeqno();\n             // processes response status from datanodes.\n             for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n               final Status reply \u003d ack.getReply(i);\n               if (reply !\u003d SUCCESS) {\n                 errorIndex \u003d i; // first bad datanode\n                 throw new IOException(\"Bad response \" + reply +\n                     \" for block \" + block +\n                     \" from datanode \" + \n-                    targets[i].getName());\n+                    targets[i]);\n               }\n             }\n             \n             assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n               \"Ack for unkown seqno should be a failed ack: \" + ack;\n             if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n               continue;\n             }\n \n             // a success ack for a data packet\n             Packet one \u003d null;\n             synchronized (dataQueue) {\n               one \u003d ackQueue.getFirst();\n             }\n             if (one.seqno !\u003d seqno) {\n               throw new IOException(\"Responseprocessor: Expecting seqno \" +\n                                     \" for block \" + block +\n                                     one.seqno + \" but received \" + seqno);\n             }\n             isLastPacketInBlock \u003d one.lastPacketInBlock;\n             // update bytesAcked\n             block.setNumBytes(one.getLastByteOffsetBlock());\n \n             synchronized (dataQueue) {\n               lastAckedSeqno \u003d seqno;\n               ackQueue.removeFirst();\n               dataQueue.notifyAll();\n             }\n           } catch (Exception e) {\n             if (!responderClosed) {\n               if (e instanceof IOException) {\n                 setLastException((IOException)e);\n               }\n               hasError \u003d true;\n               errorIndex \u003d errorIndex\u003d\u003d-1 ? 0 : errorIndex;\n               synchronized (dataQueue) {\n                 dataQueue.notifyAll();\n               }\n               DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                   + \" for block \" + block, e);\n               responderClosed \u003d true;\n             }\n           }\n         }\n       }\n\\ No newline at end of file\n",
      "actualSource": "      public void run() {\n\n        setName(\"ResponseProcessor for block \" + block);\n        PipelineAck ack \u003d new PipelineAck();\n\n        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n          // process responses from datanodes.\n          try {\n            // read an ack from the pipeline\n            ack.readFields(blockReplyStream);\n            if (DFSClient.LOG.isDebugEnabled()) {\n              DFSClient.LOG.debug(\"DFSClient \" + ack);\n            }\n            \n            long seqno \u003d ack.getSeqno();\n            // processes response status from datanodes.\n            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n              final Status reply \u003d ack.getReply(i);\n              if (reply !\u003d SUCCESS) {\n                errorIndex \u003d i; // first bad datanode\n                throw new IOException(\"Bad response \" + reply +\n                    \" for block \" + block +\n                    \" from datanode \" + \n                    targets[i]);\n              }\n            }\n            \n            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n              \"Ack for unkown seqno should be a failed ack: \" + ack;\n            if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n              continue;\n            }\n\n            // a success ack for a data packet\n            Packet one \u003d null;\n            synchronized (dataQueue) {\n              one \u003d ackQueue.getFirst();\n            }\n            if (one.seqno !\u003d seqno) {\n              throw new IOException(\"Responseprocessor: Expecting seqno \" +\n                                    \" for block \" + block +\n                                    one.seqno + \" but received \" + seqno);\n            }\n            isLastPacketInBlock \u003d one.lastPacketInBlock;\n            // update bytesAcked\n            block.setNumBytes(one.getLastByteOffsetBlock());\n\n            synchronized (dataQueue) {\n              lastAckedSeqno \u003d seqno;\n              ackQueue.removeFirst();\n              dataQueue.notifyAll();\n            }\n          } catch (Exception e) {\n            if (!responderClosed) {\n              if (e instanceof IOException) {\n                setLastException((IOException)e);\n              }\n              hasError \u003d true;\n              errorIndex \u003d errorIndex\u003d\u003d-1 ? 0 : errorIndex;\n              synchronized (dataQueue) {\n                dataQueue.notifyAll();\n              }\n              DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                  + \" for block \" + block, e);\n              responderClosed \u003d true;\n            }\n          }\n        }\n      }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "      public void run() {\n\n        setName(\"ResponseProcessor for block \" + block);\n        PipelineAck ack \u003d new PipelineAck();\n\n        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n          // process responses from datanodes.\n          try {\n            // read an ack from the pipeline\n            ack.readFields(blockReplyStream);\n            if (DFSClient.LOG.isDebugEnabled()) {\n              DFSClient.LOG.debug(\"DFSClient \" + ack);\n            }\n            \n            long seqno \u003d ack.getSeqno();\n            // processes response status from datanodes.\n            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n              final Status reply \u003d ack.getReply(i);\n              if (reply !\u003d SUCCESS) {\n                errorIndex \u003d i; // first bad datanode\n                throw new IOException(\"Bad response \" + reply +\n                    \" for block \" + block +\n                    \" from datanode \" + \n                    targets[i].getName());\n              }\n            }\n            \n            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n              \"Ack for unkown seqno should be a failed ack: \" + ack;\n            if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n              continue;\n            }\n\n            // a success ack for a data packet\n            Packet one \u003d null;\n            synchronized (dataQueue) {\n              one \u003d ackQueue.getFirst();\n            }\n            if (one.seqno !\u003d seqno) {\n              throw new IOException(\"Responseprocessor: Expecting seqno \" +\n                                    \" for block \" + block +\n                                    one.seqno + \" but received \" + seqno);\n            }\n            isLastPacketInBlock \u003d one.lastPacketInBlock;\n            // update bytesAcked\n            block.setNumBytes(one.getLastByteOffsetBlock());\n\n            synchronized (dataQueue) {\n              lastAckedSeqno \u003d seqno;\n              ackQueue.removeFirst();\n              dataQueue.notifyAll();\n            }\n          } catch (Exception e) {\n            if (!responderClosed) {\n              if (e instanceof IOException) {\n                setLastException((IOException)e);\n              }\n              hasError \u003d true;\n              errorIndex \u003d errorIndex\u003d\u003d-1 ? 0 : errorIndex;\n              synchronized (dataQueue) {\n                dataQueue.notifyAll();\n              }\n              DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                  + \" for block \" + block, e);\n              responderClosed \u003d true;\n            }\n          }\n        }\n      }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "      public void run() {\n\n        setName(\"ResponseProcessor for block \" + block);\n        PipelineAck ack \u003d new PipelineAck();\n\n        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n          // process responses from datanodes.\n          try {\n            // read an ack from the pipeline\n            ack.readFields(blockReplyStream);\n            if (DFSClient.LOG.isDebugEnabled()) {\n              DFSClient.LOG.debug(\"DFSClient \" + ack);\n            }\n            \n            long seqno \u003d ack.getSeqno();\n            // processes response status from datanodes.\n            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n              final Status reply \u003d ack.getReply(i);\n              if (reply !\u003d SUCCESS) {\n                errorIndex \u003d i; // first bad datanode\n                throw new IOException(\"Bad response \" + reply +\n                    \" for block \" + block +\n                    \" from datanode \" + \n                    targets[i].getName());\n              }\n            }\n            \n            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n              \"Ack for unkown seqno should be a failed ack: \" + ack;\n            if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n              continue;\n            }\n\n            // a success ack for a data packet\n            Packet one \u003d null;\n            synchronized (dataQueue) {\n              one \u003d ackQueue.getFirst();\n            }\n            if (one.seqno !\u003d seqno) {\n              throw new IOException(\"Responseprocessor: Expecting seqno \" +\n                                    \" for block \" + block +\n                                    one.seqno + \" but received \" + seqno);\n            }\n            isLastPacketInBlock \u003d one.lastPacketInBlock;\n            // update bytesAcked\n            block.setNumBytes(one.getLastByteOffsetBlock());\n\n            synchronized (dataQueue) {\n              lastAckedSeqno \u003d seqno;\n              ackQueue.removeFirst();\n              dataQueue.notifyAll();\n            }\n          } catch (Exception e) {\n            if (!responderClosed) {\n              if (e instanceof IOException) {\n                setLastException((IOException)e);\n              }\n              hasError \u003d true;\n              errorIndex \u003d errorIndex\u003d\u003d-1 ? 0 : errorIndex;\n              synchronized (dataQueue) {\n                dataQueue.notifyAll();\n              }\n              DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                  + \" for block \" + block, e);\n              responderClosed \u003d true;\n            }\n          }\n        }\n      }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java"
      }
    },
    "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1977. Stop using StringUtils.stringifyException(). Contributed by Bharath Mundlapudi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1145834 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/07/11 6:11 PM",
      "commitName": "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f",
      "commitAuthor": "Jitendra Nath Pandey",
      "commitDateOld": "23/06/11 4:57 PM",
      "commitNameOld": "2f48fae72aa52e6ec42264cad24fab36b6a426c2",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 19.05,
      "commitsBetweenForRepo": 56,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,69 @@\n       public void run() {\n \n         setName(\"ResponseProcessor for block \" + block);\n         PipelineAck ack \u003d new PipelineAck();\n \n         while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n           // process responses from datanodes.\n           try {\n             // read an ack from the pipeline\n             ack.readFields(blockReplyStream);\n             if (DFSClient.LOG.isDebugEnabled()) {\n               DFSClient.LOG.debug(\"DFSClient \" + ack);\n             }\n             \n             long seqno \u003d ack.getSeqno();\n             // processes response status from datanodes.\n             for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n               final Status reply \u003d ack.getReply(i);\n               if (reply !\u003d SUCCESS) {\n                 errorIndex \u003d i; // first bad datanode\n                 throw new IOException(\"Bad response \" + reply +\n                     \" for block \" + block +\n                     \" from datanode \" + \n                     targets[i].getName());\n               }\n             }\n             \n             assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n               \"Ack for unkown seqno should be a failed ack: \" + ack;\n             if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n               continue;\n             }\n \n             // a success ack for a data packet\n             Packet one \u003d null;\n             synchronized (dataQueue) {\n               one \u003d ackQueue.getFirst();\n             }\n             if (one.seqno !\u003d seqno) {\n               throw new IOException(\"Responseprocessor: Expecting seqno \" +\n                                     \" for block \" + block +\n                                     one.seqno + \" but received \" + seqno);\n             }\n             isLastPacketInBlock \u003d one.lastPacketInBlock;\n             // update bytesAcked\n             block.setNumBytes(one.getLastByteOffsetBlock());\n \n             synchronized (dataQueue) {\n               lastAckedSeqno \u003d seqno;\n               ackQueue.removeFirst();\n               dataQueue.notifyAll();\n             }\n           } catch (Exception e) {\n             if (!responderClosed) {\n               if (e instanceof IOException) {\n                 setLastException((IOException)e);\n               }\n               hasError \u003d true;\n               errorIndex \u003d errorIndex\u003d\u003d-1 ? 0 : errorIndex;\n               synchronized (dataQueue) {\n                 dataQueue.notifyAll();\n               }\n-              DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \" + \n-                  \" for block \" + block +\n-                  StringUtils.stringifyException(e));\n+              DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n+                  + \" for block \" + block, e);\n               responderClosed \u003d true;\n             }\n           }\n         }\n       }\n\\ No newline at end of file\n",
      "actualSource": "      public void run() {\n\n        setName(\"ResponseProcessor for block \" + block);\n        PipelineAck ack \u003d new PipelineAck();\n\n        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n          // process responses from datanodes.\n          try {\n            // read an ack from the pipeline\n            ack.readFields(blockReplyStream);\n            if (DFSClient.LOG.isDebugEnabled()) {\n              DFSClient.LOG.debug(\"DFSClient \" + ack);\n            }\n            \n            long seqno \u003d ack.getSeqno();\n            // processes response status from datanodes.\n            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n              final Status reply \u003d ack.getReply(i);\n              if (reply !\u003d SUCCESS) {\n                errorIndex \u003d i; // first bad datanode\n                throw new IOException(\"Bad response \" + reply +\n                    \" for block \" + block +\n                    \" from datanode \" + \n                    targets[i].getName());\n              }\n            }\n            \n            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n              \"Ack for unkown seqno should be a failed ack: \" + ack;\n            if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n              continue;\n            }\n\n            // a success ack for a data packet\n            Packet one \u003d null;\n            synchronized (dataQueue) {\n              one \u003d ackQueue.getFirst();\n            }\n            if (one.seqno !\u003d seqno) {\n              throw new IOException(\"Responseprocessor: Expecting seqno \" +\n                                    \" for block \" + block +\n                                    one.seqno + \" but received \" + seqno);\n            }\n            isLastPacketInBlock \u003d one.lastPacketInBlock;\n            // update bytesAcked\n            block.setNumBytes(one.getLastByteOffsetBlock());\n\n            synchronized (dataQueue) {\n              lastAckedSeqno \u003d seqno;\n              ackQueue.removeFirst();\n              dataQueue.notifyAll();\n            }\n          } catch (Exception e) {\n            if (!responderClosed) {\n              if (e instanceof IOException) {\n                setLastException((IOException)e);\n              }\n              hasError \u003d true;\n              errorIndex \u003d errorIndex\u003d\u003d-1 ? 0 : errorIndex;\n              synchronized (dataQueue) {\n                dataQueue.notifyAll();\n              }\n              DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \"\n                  + \" for block \" + block, e);\n              responderClosed \u003d true;\n            }\n          }\n        }\n      }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/DFSOutputStream.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,70 @@\n+      public void run() {\n+\n+        setName(\"ResponseProcessor for block \" + block);\n+        PipelineAck ack \u003d new PipelineAck();\n+\n+        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n+          // process responses from datanodes.\n+          try {\n+            // read an ack from the pipeline\n+            ack.readFields(blockReplyStream);\n+            if (DFSClient.LOG.isDebugEnabled()) {\n+              DFSClient.LOG.debug(\"DFSClient \" + ack);\n+            }\n+            \n+            long seqno \u003d ack.getSeqno();\n+            // processes response status from datanodes.\n+            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n+              final Status reply \u003d ack.getReply(i);\n+              if (reply !\u003d SUCCESS) {\n+                errorIndex \u003d i; // first bad datanode\n+                throw new IOException(\"Bad response \" + reply +\n+                    \" for block \" + block +\n+                    \" from datanode \" + \n+                    targets[i].getName());\n+              }\n+            }\n+            \n+            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n+              \"Ack for unkown seqno should be a failed ack: \" + ack;\n+            if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n+              continue;\n+            }\n+\n+            // a success ack for a data packet\n+            Packet one \u003d null;\n+            synchronized (dataQueue) {\n+              one \u003d ackQueue.getFirst();\n+            }\n+            if (one.seqno !\u003d seqno) {\n+              throw new IOException(\"Responseprocessor: Expecting seqno \" +\n+                                    \" for block \" + block +\n+                                    one.seqno + \" but received \" + seqno);\n+            }\n+            isLastPacketInBlock \u003d one.lastPacketInBlock;\n+            // update bytesAcked\n+            block.setNumBytes(one.getLastByteOffsetBlock());\n+\n+            synchronized (dataQueue) {\n+              lastAckedSeqno \u003d seqno;\n+              ackQueue.removeFirst();\n+              dataQueue.notifyAll();\n+            }\n+          } catch (Exception e) {\n+            if (!responderClosed) {\n+              if (e instanceof IOException) {\n+                setLastException((IOException)e);\n+              }\n+              hasError \u003d true;\n+              errorIndex \u003d errorIndex\u003d\u003d-1 ? 0 : errorIndex;\n+              synchronized (dataQueue) {\n+                dataQueue.notifyAll();\n+              }\n+              DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \" + \n+                  \" for block \" + block +\n+                  StringUtils.stringifyException(e));\n+              responderClosed \u003d true;\n+            }\n+          }\n+        }\n+      }\n\\ No newline at end of file\n",
      "actualSource": "      public void run() {\n\n        setName(\"ResponseProcessor for block \" + block);\n        PipelineAck ack \u003d new PipelineAck();\n\n        while (!responderClosed \u0026\u0026 dfsClient.clientRunning \u0026\u0026 !isLastPacketInBlock) {\n          // process responses from datanodes.\n          try {\n            // read an ack from the pipeline\n            ack.readFields(blockReplyStream);\n            if (DFSClient.LOG.isDebugEnabled()) {\n              DFSClient.LOG.debug(\"DFSClient \" + ack);\n            }\n            \n            long seqno \u003d ack.getSeqno();\n            // processes response status from datanodes.\n            for (int i \u003d ack.getNumOfReplies()-1; i \u003e\u003d0  \u0026\u0026 dfsClient.clientRunning; i--) {\n              final Status reply \u003d ack.getReply(i);\n              if (reply !\u003d SUCCESS) {\n                errorIndex \u003d i; // first bad datanode\n                throw new IOException(\"Bad response \" + reply +\n                    \" for block \" + block +\n                    \" from datanode \" + \n                    targets[i].getName());\n              }\n            }\n            \n            assert seqno !\u003d PipelineAck.UNKOWN_SEQNO : \n              \"Ack for unkown seqno should be a failed ack: \" + ack;\n            if (seqno \u003d\u003d Packet.HEART_BEAT_SEQNO) {  // a heartbeat ack\n              continue;\n            }\n\n            // a success ack for a data packet\n            Packet one \u003d null;\n            synchronized (dataQueue) {\n              one \u003d ackQueue.getFirst();\n            }\n            if (one.seqno !\u003d seqno) {\n              throw new IOException(\"Responseprocessor: Expecting seqno \" +\n                                    \" for block \" + block +\n                                    one.seqno + \" but received \" + seqno);\n            }\n            isLastPacketInBlock \u003d one.lastPacketInBlock;\n            // update bytesAcked\n            block.setNumBytes(one.getLastByteOffsetBlock());\n\n            synchronized (dataQueue) {\n              lastAckedSeqno \u003d seqno;\n              ackQueue.removeFirst();\n              dataQueue.notifyAll();\n            }\n          } catch (Exception e) {\n            if (!responderClosed) {\n              if (e instanceof IOException) {\n                setLastException((IOException)e);\n              }\n              hasError \u003d true;\n              errorIndex \u003d errorIndex\u003d\u003d-1 ? 0 : errorIndex;\n              synchronized (dataQueue) {\n                dataQueue.notifyAll();\n              }\n              DFSClient.LOG.warn(\"DFSOutputStream ResponseProcessor exception \" + \n                  \" for block \" + block +\n                  StringUtils.stringifyException(e));\n              responderClosed \u003d true;\n            }\n          }\n        }\n      }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/DFSOutputStream.java"
    }
  }
}