{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NativeAzureFileSystem.java",
  "functionName": "handleFilesWithDanglingTempData",
  "functionId": "handleFilesWithDanglingTempData___root-Path__handler-DanglingFileHandler",
  "sourceFilePath": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/NativeAzureFileSystem.java",
  "functionStartLine": 3816,
  "functionEndLine": 3844,
  "numCommitsSeen": 66,
  "timeTaken": 2869,
  "changeHistory": [
    "45d9568aaaf532a6da11bd7c1844ff81bf66bab1",
    "81bc395deb3ba00567dc067d6ca71bacf9e3bc82"
  ],
  "changeHistoryShort": {
    "45d9568aaaf532a6da11bd7c1844ff81bf66bab1": "Ybodychange",
    "81bc395deb3ba00567dc067d6ca71bacf9e3bc82": "Yintroduced"
  },
  "changeHistoryDetails": {
    "45d9568aaaf532a6da11bd7c1844ff81bf66bab1": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15547/ WASB: improve listStatus performance.\nContributed by Thomas Marquardt.\n\n(cherry picked from commit 749fff577ed9afb4ef8a54b8948f74be083cc620)\n",
      "commitDate": "19/07/18 12:31 PM",
      "commitName": "45d9568aaaf532a6da11bd7c1844ff81bf66bab1",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "27/06/18 10:37 PM",
      "commitNameOld": "2b2399d623539ab68e71a38fa9fbfc9a405bddb8",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 21.58,
      "commitsBetweenForRepo": 124,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,29 @@\n   private void handleFilesWithDanglingTempData(Path root,\n       DanglingFileHandler handler) throws IOException {\n     // Calculate the cut-off for when to consider a blob to be dangling.\n     long cutoffForDangling \u003d new Date().getTime()\n         - getConf().getInt(AZURE_TEMP_EXPIRY_PROPERTY_NAME,\n             AZURE_TEMP_EXPIRY_DEFAULT) * 1000;\n     // Go over all the blobs under the given root and look for blobs to\n     // recover.\n-    String priorLastKey \u003d null;\n-    do {\n-      PartialListing listing \u003d store.listAll(pathToKey(root), AZURE_LIST_ALL,\n-          AZURE_UNBOUNDED_DEPTH, priorLastKey);\n+    FileMetadata[] listing \u003d store.list(pathToKey(root), AZURE_LIST_ALL,\n+        AZURE_UNBOUNDED_DEPTH);\n \n-      for (FileMetadata file : listing.getFiles()) {\n-        if (!file.isDir()) { // We don\u0027t recover directory blobs\n-          // See if this blob has a link in it (meaning it\u0027s a place-holder\n-          // blob for when the upload to the temp blob is complete).\n-          String link \u003d store.getLinkInFileMetadata(file.getKey());\n-          if (link !\u003d null) {\n-            // It has a link, see if the temp blob it is pointing to is\n-            // existent and old enough to be considered dangling.\n-            FileMetadata linkMetadata \u003d store.retrieveMetadata(link);\n-            if (linkMetadata !\u003d null\n-                \u0026\u0026 linkMetadata.getLastModified() \u003e\u003d cutoffForDangling) {\n-              // Found one!\n-              handler.handleFile(file, linkMetadata);\n-            }\n+    for (FileMetadata file : listing) {\n+      if (!file.isDirectory()) { // We don\u0027t recover directory blobs\n+        // See if this blob has a link in it (meaning it\u0027s a place-holder\n+        // blob for when the upload to the temp blob is complete).\n+        String link \u003d store.getLinkInFileMetadata(file.getKey());\n+        if (link !\u003d null) {\n+          // It has a link, see if the temp blob it is pointing to is\n+          // existent and old enough to be considered dangling.\n+          FileMetadata linkMetadata \u003d store.retrieveMetadata(link);\n+          if (linkMetadata !\u003d null\n+              \u0026\u0026 linkMetadata.getModificationTime() \u003e\u003d cutoffForDangling) {\n+            // Found one!\n+            handler.handleFile(file, linkMetadata);\n           }\n         }\n       }\n-      priorLastKey \u003d listing.getPriorLastKey();\n-    } while (priorLastKey !\u003d null);\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void handleFilesWithDanglingTempData(Path root,\n      DanglingFileHandler handler) throws IOException {\n    // Calculate the cut-off for when to consider a blob to be dangling.\n    long cutoffForDangling \u003d new Date().getTime()\n        - getConf().getInt(AZURE_TEMP_EXPIRY_PROPERTY_NAME,\n            AZURE_TEMP_EXPIRY_DEFAULT) * 1000;\n    // Go over all the blobs under the given root and look for blobs to\n    // recover.\n    FileMetadata[] listing \u003d store.list(pathToKey(root), AZURE_LIST_ALL,\n        AZURE_UNBOUNDED_DEPTH);\n\n    for (FileMetadata file : listing) {\n      if (!file.isDirectory()) { // We don\u0027t recover directory blobs\n        // See if this blob has a link in it (meaning it\u0027s a place-holder\n        // blob for when the upload to the temp blob is complete).\n        String link \u003d store.getLinkInFileMetadata(file.getKey());\n        if (link !\u003d null) {\n          // It has a link, see if the temp blob it is pointing to is\n          // existent and old enough to be considered dangling.\n          FileMetadata linkMetadata \u003d store.retrieveMetadata(link);\n          if (linkMetadata !\u003d null\n              \u0026\u0026 linkMetadata.getModificationTime() \u003e\u003d cutoffForDangling) {\n            // Found one!\n            handler.handleFile(file, linkMetadata);\n          }\n        }\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/NativeAzureFileSystem.java",
      "extendedDetails": {}
    },
    "81bc395deb3ba00567dc067d6ca71bacf9e3bc82": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-9629. Support Windows Azure Storage - Blob as a file system in Hadoop. Contributed by Dexter Bradshaw, Mostafa Elhemali, Xi Fang, Johannes Klein, David Lao, Mike Liddell, Chuan Liu, Lengning Liu, Ivan Mitic, Michael Rys, Alexander Stojanovic, Brian Swan, and Min Wei.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1601781 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/06/14 3:26 PM",
      "commitName": "81bc395deb3ba00567dc067d6ca71bacf9e3bc82",
      "commitAuthor": "Chris Nauroth",
      "diff": "@@ -0,0 +1,33 @@\n+  private void handleFilesWithDanglingTempData(Path root,\n+      DanglingFileHandler handler) throws IOException {\n+    // Calculate the cut-off for when to consider a blob to be dangling.\n+    long cutoffForDangling \u003d new Date().getTime()\n+        - getConf().getInt(AZURE_TEMP_EXPIRY_PROPERTY_NAME,\n+            AZURE_TEMP_EXPIRY_DEFAULT) * 1000;\n+    // Go over all the blobs under the given root and look for blobs to\n+    // recover.\n+    String priorLastKey \u003d null;\n+    do {\n+      PartialListing listing \u003d store.listAll(pathToKey(root), AZURE_LIST_ALL,\n+          AZURE_UNBOUNDED_DEPTH, priorLastKey);\n+\n+      for (FileMetadata file : listing.getFiles()) {\n+        if (!file.isDir()) { // We don\u0027t recover directory blobs\n+          // See if this blob has a link in it (meaning it\u0027s a place-holder\n+          // blob for when the upload to the temp blob is complete).\n+          String link \u003d store.getLinkInFileMetadata(file.getKey());\n+          if (link !\u003d null) {\n+            // It has a link, see if the temp blob it is pointing to is\n+            // existent and old enough to be considered dangling.\n+            FileMetadata linkMetadata \u003d store.retrieveMetadata(link);\n+            if (linkMetadata !\u003d null\n+                \u0026\u0026 linkMetadata.getLastModified() \u003e\u003d cutoffForDangling) {\n+              // Found one!\n+              handler.handleFile(file, linkMetadata);\n+            }\n+          }\n+        }\n+      }\n+      priorLastKey \u003d listing.getPriorLastKey();\n+    } while (priorLastKey !\u003d null);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void handleFilesWithDanglingTempData(Path root,\n      DanglingFileHandler handler) throws IOException {\n    // Calculate the cut-off for when to consider a blob to be dangling.\n    long cutoffForDangling \u003d new Date().getTime()\n        - getConf().getInt(AZURE_TEMP_EXPIRY_PROPERTY_NAME,\n            AZURE_TEMP_EXPIRY_DEFAULT) * 1000;\n    // Go over all the blobs under the given root and look for blobs to\n    // recover.\n    String priorLastKey \u003d null;\n    do {\n      PartialListing listing \u003d store.listAll(pathToKey(root), AZURE_LIST_ALL,\n          AZURE_UNBOUNDED_DEPTH, priorLastKey);\n\n      for (FileMetadata file : listing.getFiles()) {\n        if (!file.isDir()) { // We don\u0027t recover directory blobs\n          // See if this blob has a link in it (meaning it\u0027s a place-holder\n          // blob for when the upload to the temp blob is complete).\n          String link \u003d store.getLinkInFileMetadata(file.getKey());\n          if (link !\u003d null) {\n            // It has a link, see if the temp blob it is pointing to is\n            // existent and old enough to be considered dangling.\n            FileMetadata linkMetadata \u003d store.retrieveMetadata(link);\n            if (linkMetadata !\u003d null\n                \u0026\u0026 linkMetadata.getLastModified() \u003e\u003d cutoffForDangling) {\n              // Found one!\n              handler.handleFile(file, linkMetadata);\n            }\n          }\n        }\n      }\n      priorLastKey \u003d listing.getPriorLastKey();\n    } while (priorLastKey !\u003d null);\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/NativeAzureFileSystem.java"
    }
  }
}