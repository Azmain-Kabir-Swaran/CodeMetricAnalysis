{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "addStoredBlock",
  "functionId": "addStoredBlock___block-BlockInfo(modifiers-final)__reportedBlock-Block(modifiers-final)__storageInfo-DatanodeStorageInfo__delNodeHint-DatanodeDescriptor__logEveryBlock-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 3440,
  "functionEndLine": 3548,
  "numCommitsSeen": 477,
  "timeTaken": 14177,
  "changeHistory": [
    "8053085388fec17a40856f36821c142be32aa364",
    "a7f085d6bf499edf23e650a4f7211c53a442da0e",
    "07b98e7830c2214340cb7f434df674057e89df94",
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
    "a5bb88c8e0fd4bd19b6d377fecbe1d2d441514f6",
    "8c84a2a93c22a93b4ff46dd917f6efb995675fbd",
    "5865fe2bf01284993572ea60b3ec3bf8b4492818",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
    "724d2299cd2516d90c030f6e20d814cceb439228",
    "f2ba7da4f0df6cf0fc245093aeb4500158e6ee0b",
    "47b92f2b6f2dafc129a41b247f35e77c8e47ffba",
    "972782d9568e0849484c027f27c1638ba50ec56e",
    "bd909ed9f2d853f614f04a50e2230a7932732776",
    "e53456981474d6e16e3c134e3777b3588dc6fedf",
    "796a676d18bd7cd3ed4113d002e0e69cf261d6d1",
    "a49cc74b4c72195dee1dfb6f9548e5e411dff553",
    "5411dc559d5f73e4153e76fdff94a26869c17a37"
  ],
  "changeHistoryShort": {
    "8053085388fec17a40856f36821c142be32aa364": "Ybodychange",
    "a7f085d6bf499edf23e650a4f7211c53a442da0e": "Ybodychange",
    "07b98e7830c2214340cb7f434df674057e89df94": "Ybodychange",
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": "Ybodychange",
    "a5bb88c8e0fd4bd19b6d377fecbe1d2d441514f6": "Ybodychange",
    "8c84a2a93c22a93b4ff46dd917f6efb995675fbd": "Ybodychange",
    "5865fe2bf01284993572ea60b3ec3bf8b4492818": "Ybodychange",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": "Ybodychange",
    "724d2299cd2516d90c030f6e20d814cceb439228": "Ybodychange",
    "f2ba7da4f0df6cf0fc245093aeb4500158e6ee0b": "Ybodychange",
    "47b92f2b6f2dafc129a41b247f35e77c8e47ffba": "Ybodychange",
    "972782d9568e0849484c027f27c1638ba50ec56e": "Ybodychange",
    "bd909ed9f2d853f614f04a50e2230a7932732776": "Ybodychange",
    "e53456981474d6e16e3c134e3777b3588dc6fedf": "Ybodychange",
    "796a676d18bd7cd3ed4113d002e0e69cf261d6d1": "Ybodychange",
    "a49cc74b4c72195dee1dfb6f9548e5e411dff553": "Ybodychange",
    "5411dc559d5f73e4153e76fdff94a26869c17a37": "Ybodychange"
  },
  "changeHistoryDetails": {
    "8053085388fec17a40856f36821c142be32aa364": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14429. Block remain in COMMITTED but not COMPLETE caused by Decommission. Contributed by Yicong Cai.\n",
      "commitDate": "29/07/19 2:31 PM",
      "commitName": "8053085388fec17a40856f36821c142be32aa364",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "15/07/19 7:44 PM",
      "commitNameOld": "f77d54c24343e6ca7c438d9db431cef14c3ae77b",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 13.78,
      "commitsBetweenForRepo": 98,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,109 @@\n   private Block addStoredBlock(final BlockInfo block,\n                                final Block reportedBlock,\n                                DatanodeStorageInfo storageInfo,\n                                DatanodeDescriptor delNodeHint,\n                                boolean logEveryBlock)\n   throws IOException {\n     assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n     BlockInfo storedBlock;\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     if (!block.isComplete()) {\n       //refresh our copy in case the block got completed in another thread\n       storedBlock \u003d getStoredBlock(block);\n     } else {\n       storedBlock \u003d block;\n     }\n     if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n       // If this block does not belong to anyfile, then we are done.\n       blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n           \" belong to any file\", block, node, block.getNumBytes());\n \n       // we could add this block to invalidate set of this datanode.\n       // it will happen in next block report otherwise.\n       return block;\n     }\n \n     // add block to the datanode\n     AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n \n     int curReplicaDelta;\n     if (result \u003d\u003d AddBlockResult.ADDED) {\n-      curReplicaDelta \u003d (node.isDecommissioned()) ? 0 : 1;\n+      curReplicaDelta \u003d\n+          (node.isDecommissioned() || node.isDecommissionInProgress()) ? 0 : 1;\n       if (logEveryBlock) {\n         blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n             node, storedBlock, storedBlock.getNumBytes());\n       }\n     } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n           \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n     } else {\n       // if the same block is added again and the replica was corrupt\n       // previously because of a wrong gen stamp, remove it from the\n       // corrupt block list.\n       corruptReplicas.removeFromCorruptReplicasMap(block, node,\n           Reason.GENSTAMP_MISMATCH);\n       curReplicaDelta \u003d 0;\n       blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n               + \" received for {} on node {} size {}\", storedBlock, node,\n           storedBlock.getNumBytes());\n     }\n \n     // Now check for completion of blocks and safe block count\n     NumberReplicas num \u003d countNodes(storedBlock);\n     int numLiveReplicas \u003d num.liveReplicas();\n     int pendingNum \u003d pendingReconstruction.getNumReplicas(storedBlock);\n     int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n+    int numUsableReplicas \u003d num.liveReplicas() +\n+        num.decommissioning() + num.liveEnteringMaintenanceReplicas();\n \n     if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n-        hasMinStorage(storedBlock, numLiveReplicas)) {\n+        hasMinStorage(storedBlock, numUsableReplicas)) {\n       addExpectedReplicasToPending(storedBlock);\n       completeBlock(storedBlock, null, false);\n     } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n       // check whether safe replication is reached for the block\n       // only complete blocks are counted towards that\n       // Is no-op if not in safe mode.\n       // In the case that the block just became complete above, completeBlock()\n       // handles the safe block count maintenance.\n       bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n     }\n     \n     // if block is still under construction, then done for now\n     if (!storedBlock.isCompleteOrCommitted()) {\n       return storedBlock;\n     }\n \n     // do not try to handle extra/low redundancy blocks during first safe mode\n     if (!isPopulatingReplQueues()) {\n       return storedBlock;\n     }\n \n     // handle low redundancy/extra redundancy\n     short fileRedundancy \u003d getExpectedRedundancyNum(storedBlock);\n     if (!isNeededReconstruction(storedBlock, num, pendingNum)) {\n       neededReconstruction.remove(storedBlock, numCurrentReplica,\n           num.readOnlyReplicas(), num.outOfServiceReplicas(), fileRedundancy);\n     } else {\n       updateNeededReconstructions(storedBlock, curReplicaDelta, 0);\n     }\n     if (shouldProcessExtraRedundancy(num, fileRedundancy)) {\n       processExtraRedundancyBlock(storedBlock, fileRedundancy, node,\n           delNodeHint);\n     }\n     // If the file redundancy has reached desired value\n     // we can remove any corrupt replicas the block may have\n     int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n     int numCorruptNodes \u003d num.corruptReplicas();\n     if (numCorruptNodes !\u003d corruptReplicasCount) {\n       LOG.warn(\"Inconsistent number of corrupt replicas for {}\" +\n           \". blockMap has {} but corrupt replicas map has {}\",\n           storedBlock, numCorruptNodes, corruptReplicasCount);\n     }\n     if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileRedundancy)) {\n       invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n     }\n     return storedBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Block addStoredBlock(final BlockInfo block,\n                               final Block reportedBlock,\n                               DatanodeStorageInfo storageInfo,\n                               DatanodeDescriptor delNodeHint,\n                               boolean logEveryBlock)\n  throws IOException {\n    assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n    BlockInfo storedBlock;\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    if (!block.isComplete()) {\n      //refresh our copy in case the block got completed in another thread\n      storedBlock \u003d getStoredBlock(block);\n    } else {\n      storedBlock \u003d block;\n    }\n    if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n      // If this block does not belong to anyfile, then we are done.\n      blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n          \" belong to any file\", block, node, block.getNumBytes());\n\n      // we could add this block to invalidate set of this datanode.\n      // it will happen in next block report otherwise.\n      return block;\n    }\n\n    // add block to the datanode\n    AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n\n    int curReplicaDelta;\n    if (result \u003d\u003d AddBlockResult.ADDED) {\n      curReplicaDelta \u003d\n          (node.isDecommissioned() || node.isDecommissionInProgress()) ? 0 : 1;\n      if (logEveryBlock) {\n        blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n            node, storedBlock, storedBlock.getNumBytes());\n      }\n    } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n          \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta \u003d 0;\n      blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n\n    // Now check for completion of blocks and safe block count\n    NumberReplicas num \u003d countNodes(storedBlock);\n    int numLiveReplicas \u003d num.liveReplicas();\n    int pendingNum \u003d pendingReconstruction.getNumReplicas(storedBlock);\n    int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n    int numUsableReplicas \u003d num.liveReplicas() +\n        num.decommissioning() + num.liveEnteringMaintenanceReplicas();\n\n    if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n        hasMinStorage(storedBlock, numUsableReplicas)) {\n      addExpectedReplicasToPending(storedBlock);\n      completeBlock(storedBlock, null, false);\n    } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n      // check whether safe replication is reached for the block\n      // only complete blocks are counted towards that\n      // Is no-op if not in safe mode.\n      // In the case that the block just became complete above, completeBlock()\n      // handles the safe block count maintenance.\n      bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n    }\n    \n    // if block is still under construction, then done for now\n    if (!storedBlock.isCompleteOrCommitted()) {\n      return storedBlock;\n    }\n\n    // do not try to handle extra/low redundancy blocks during first safe mode\n    if (!isPopulatingReplQueues()) {\n      return storedBlock;\n    }\n\n    // handle low redundancy/extra redundancy\n    short fileRedundancy \u003d getExpectedRedundancyNum(storedBlock);\n    if (!isNeededReconstruction(storedBlock, num, pendingNum)) {\n      neededReconstruction.remove(storedBlock, numCurrentReplica,\n          num.readOnlyReplicas(), num.outOfServiceReplicas(), fileRedundancy);\n    } else {\n      updateNeededReconstructions(storedBlock, curReplicaDelta, 0);\n    }\n    if (shouldProcessExtraRedundancy(num, fileRedundancy)) {\n      processExtraRedundancyBlock(storedBlock, fileRedundancy, node,\n          delNodeHint);\n    }\n    // If the file redundancy has reached desired value\n    // we can remove any corrupt replicas the block may have\n    int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n    int numCorruptNodes \u003d num.corruptReplicas();\n    if (numCorruptNodes !\u003d corruptReplicasCount) {\n      LOG.warn(\"Inconsistent number of corrupt replicas for {}\" +\n          \". blockMap has {} but corrupt replicas map has {}\",\n          storedBlock, numCorruptNodes, corruptReplicasCount);\n    }\n    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileRedundancy)) {\n      invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n    }\n    return storedBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "a7f085d6bf499edf23e650a4f7211c53a442da0e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11832. Switch leftover logs to slf4j format in BlockManager.java. Contributed by Hui Xu and Chen Liang.\n",
      "commitDate": "29/05/17 1:30 AM",
      "commitName": "a7f085d6bf499edf23e650a4f7211c53a442da0e",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "25/05/17 7:35 AM",
      "commitNameOld": "2e41f8803dd46d1bab16c1b206c71be72ea260a1",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 3.75,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,106 @@\n   private Block addStoredBlock(final BlockInfo block,\n                                final Block reportedBlock,\n                                DatanodeStorageInfo storageInfo,\n                                DatanodeDescriptor delNodeHint,\n                                boolean logEveryBlock)\n   throws IOException {\n     assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n     BlockInfo storedBlock;\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     if (!block.isComplete()) {\n       //refresh our copy in case the block got completed in another thread\n       storedBlock \u003d getStoredBlock(block);\n     } else {\n       storedBlock \u003d block;\n     }\n     if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n       // If this block does not belong to anyfile, then we are done.\n       blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n           \" belong to any file\", block, node, block.getNumBytes());\n \n       // we could add this block to invalidate set of this datanode.\n       // it will happen in next block report otherwise.\n       return block;\n     }\n \n     // add block to the datanode\n     AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n \n     int curReplicaDelta;\n     if (result \u003d\u003d AddBlockResult.ADDED) {\n       curReplicaDelta \u003d (node.isDecommissioned()) ? 0 : 1;\n       if (logEveryBlock) {\n         blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n             node, storedBlock, storedBlock.getNumBytes());\n       }\n     } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n           \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n     } else {\n       // if the same block is added again and the replica was corrupt\n       // previously because of a wrong gen stamp, remove it from the\n       // corrupt block list.\n       corruptReplicas.removeFromCorruptReplicasMap(block, node,\n           Reason.GENSTAMP_MISMATCH);\n       curReplicaDelta \u003d 0;\n       blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n               + \" received for {} on node {} size {}\", storedBlock, node,\n           storedBlock.getNumBytes());\n     }\n \n     // Now check for completion of blocks and safe block count\n     NumberReplicas num \u003d countNodes(storedBlock);\n     int numLiveReplicas \u003d num.liveReplicas();\n     int pendingNum \u003d pendingReconstruction.getNumReplicas(storedBlock);\n     int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n \n     if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n         hasMinStorage(storedBlock, numLiveReplicas)) {\n       addExpectedReplicasToPending(storedBlock);\n       completeBlock(storedBlock, null, false);\n     } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n       // check whether safe replication is reached for the block\n       // only complete blocks are counted towards that\n       // Is no-op if not in safe mode.\n       // In the case that the block just became complete above, completeBlock()\n       // handles the safe block count maintenance.\n       bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n     }\n     \n     // if block is still under construction, then done for now\n     if (!storedBlock.isCompleteOrCommitted()) {\n       return storedBlock;\n     }\n \n     // do not try to handle extra/low redundancy blocks during first safe mode\n     if (!isPopulatingReplQueues()) {\n       return storedBlock;\n     }\n \n     // handle low redundancy/extra redundancy\n     short fileRedundancy \u003d getExpectedRedundancyNum(storedBlock);\n     if (!isNeededReconstruction(storedBlock, num, pendingNum)) {\n       neededReconstruction.remove(storedBlock, numCurrentReplica,\n           num.readOnlyReplicas(), num.outOfServiceReplicas(), fileRedundancy);\n     } else {\n       updateNeededReconstructions(storedBlock, curReplicaDelta, 0);\n     }\n     if (shouldProcessExtraRedundancy(num, fileRedundancy)) {\n       processExtraRedundancyBlock(storedBlock, fileRedundancy, node,\n           delNodeHint);\n     }\n     // If the file redundancy has reached desired value\n     // we can remove any corrupt replicas the block may have\n     int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n     int numCorruptNodes \u003d num.corruptReplicas();\n     if (numCorruptNodes !\u003d corruptReplicasCount) {\n-      LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n-          storedBlock + \". blockMap has \" + numCorruptNodes +\n-          \" but corrupt replicas map has \" + corruptReplicasCount);\n+      LOG.warn(\"Inconsistent number of corrupt replicas for {}\" +\n+          \". blockMap has {} but corrupt replicas map has {}\",\n+          storedBlock, numCorruptNodes, corruptReplicasCount);\n     }\n     if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileRedundancy)) {\n       invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n     }\n     return storedBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Block addStoredBlock(final BlockInfo block,\n                               final Block reportedBlock,\n                               DatanodeStorageInfo storageInfo,\n                               DatanodeDescriptor delNodeHint,\n                               boolean logEveryBlock)\n  throws IOException {\n    assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n    BlockInfo storedBlock;\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    if (!block.isComplete()) {\n      //refresh our copy in case the block got completed in another thread\n      storedBlock \u003d getStoredBlock(block);\n    } else {\n      storedBlock \u003d block;\n    }\n    if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n      // If this block does not belong to anyfile, then we are done.\n      blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n          \" belong to any file\", block, node, block.getNumBytes());\n\n      // we could add this block to invalidate set of this datanode.\n      // it will happen in next block report otherwise.\n      return block;\n    }\n\n    // add block to the datanode\n    AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n\n    int curReplicaDelta;\n    if (result \u003d\u003d AddBlockResult.ADDED) {\n      curReplicaDelta \u003d (node.isDecommissioned()) ? 0 : 1;\n      if (logEveryBlock) {\n        blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n            node, storedBlock, storedBlock.getNumBytes());\n      }\n    } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n          \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta \u003d 0;\n      blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n\n    // Now check for completion of blocks and safe block count\n    NumberReplicas num \u003d countNodes(storedBlock);\n    int numLiveReplicas \u003d num.liveReplicas();\n    int pendingNum \u003d pendingReconstruction.getNumReplicas(storedBlock);\n    int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n\n    if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n        hasMinStorage(storedBlock, numLiveReplicas)) {\n      addExpectedReplicasToPending(storedBlock);\n      completeBlock(storedBlock, null, false);\n    } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n      // check whether safe replication is reached for the block\n      // only complete blocks are counted towards that\n      // Is no-op if not in safe mode.\n      // In the case that the block just became complete above, completeBlock()\n      // handles the safe block count maintenance.\n      bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n    }\n    \n    // if block is still under construction, then done for now\n    if (!storedBlock.isCompleteOrCommitted()) {\n      return storedBlock;\n    }\n\n    // do not try to handle extra/low redundancy blocks during first safe mode\n    if (!isPopulatingReplQueues()) {\n      return storedBlock;\n    }\n\n    // handle low redundancy/extra redundancy\n    short fileRedundancy \u003d getExpectedRedundancyNum(storedBlock);\n    if (!isNeededReconstruction(storedBlock, num, pendingNum)) {\n      neededReconstruction.remove(storedBlock, numCurrentReplica,\n          num.readOnlyReplicas(), num.outOfServiceReplicas(), fileRedundancy);\n    } else {\n      updateNeededReconstructions(storedBlock, curReplicaDelta, 0);\n    }\n    if (shouldProcessExtraRedundancy(num, fileRedundancy)) {\n      processExtraRedundancyBlock(storedBlock, fileRedundancy, node,\n          delNodeHint);\n    }\n    // If the file redundancy has reached desired value\n    // we can remove any corrupt replicas the block may have\n    int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n    int numCorruptNodes \u003d num.corruptReplicas();\n    if (numCorruptNodes !\u003d corruptReplicasCount) {\n      LOG.warn(\"Inconsistent number of corrupt replicas for {}\" +\n          \". blockMap has {} but corrupt replicas map has {}\",\n          storedBlock, numCorruptNodes, corruptReplicasCount);\n    }\n    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileRedundancy)) {\n      invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n    }\n    return storedBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "07b98e7830c2214340cb7f434df674057e89df94": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11609. Some blocks can be permanently lost if nodes are decommissioned while dead. Contributed by Kihwal Lee.\n",
      "commitDate": "01/05/17 12:19 PM",
      "commitName": "07b98e7830c2214340cb7f434df674057e89df94",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "25/04/17 11:57 PM",
      "commitNameOld": "2f73396b5901fd5fe29f6cd76fc1b3134b854b37",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 5.52,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,106 @@\n   private Block addStoredBlock(final BlockInfo block,\n                                final Block reportedBlock,\n                                DatanodeStorageInfo storageInfo,\n                                DatanodeDescriptor delNodeHint,\n                                boolean logEveryBlock)\n   throws IOException {\n     assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n     BlockInfo storedBlock;\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     if (!block.isComplete()) {\n       //refresh our copy in case the block got completed in another thread\n       storedBlock \u003d getStoredBlock(block);\n     } else {\n       storedBlock \u003d block;\n     }\n     if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n       // If this block does not belong to anyfile, then we are done.\n       blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n           \" belong to any file\", block, node, block.getNumBytes());\n \n       // we could add this block to invalidate set of this datanode.\n       // it will happen in next block report otherwise.\n       return block;\n     }\n \n     // add block to the datanode\n     AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n \n     int curReplicaDelta;\n     if (result \u003d\u003d AddBlockResult.ADDED) {\n-      curReplicaDelta \u003d 1;\n+      curReplicaDelta \u003d (node.isDecommissioned()) ? 0 : 1;\n       if (logEveryBlock) {\n         blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n             node, storedBlock, storedBlock.getNumBytes());\n       }\n     } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n           \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n     } else {\n       // if the same block is added again and the replica was corrupt\n       // previously because of a wrong gen stamp, remove it from the\n       // corrupt block list.\n       corruptReplicas.removeFromCorruptReplicasMap(block, node,\n           Reason.GENSTAMP_MISMATCH);\n       curReplicaDelta \u003d 0;\n       blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n               + \" received for {} on node {} size {}\", storedBlock, node,\n           storedBlock.getNumBytes());\n     }\n \n     // Now check for completion of blocks and safe block count\n     NumberReplicas num \u003d countNodes(storedBlock);\n     int numLiveReplicas \u003d num.liveReplicas();\n     int pendingNum \u003d pendingReconstruction.getNumReplicas(storedBlock);\n     int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n \n     if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n         hasMinStorage(storedBlock, numLiveReplicas)) {\n       addExpectedReplicasToPending(storedBlock);\n       completeBlock(storedBlock, null, false);\n     } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n       // check whether safe replication is reached for the block\n       // only complete blocks are counted towards that\n       // Is no-op if not in safe mode.\n       // In the case that the block just became complete above, completeBlock()\n       // handles the safe block count maintenance.\n       bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n     }\n     \n     // if block is still under construction, then done for now\n     if (!storedBlock.isCompleteOrCommitted()) {\n       return storedBlock;\n     }\n \n     // do not try to handle extra/low redundancy blocks during first safe mode\n     if (!isPopulatingReplQueues()) {\n       return storedBlock;\n     }\n \n     // handle low redundancy/extra redundancy\n     short fileRedundancy \u003d getExpectedRedundancyNum(storedBlock);\n     if (!isNeededReconstruction(storedBlock, num, pendingNum)) {\n       neededReconstruction.remove(storedBlock, numCurrentReplica,\n           num.readOnlyReplicas(), num.outOfServiceReplicas(), fileRedundancy);\n     } else {\n       updateNeededReconstructions(storedBlock, curReplicaDelta, 0);\n     }\n     if (shouldProcessExtraRedundancy(num, fileRedundancy)) {\n       processExtraRedundancyBlock(storedBlock, fileRedundancy, node,\n           delNodeHint);\n     }\n     // If the file redundancy has reached desired value\n     // we can remove any corrupt replicas the block may have\n     int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n     int numCorruptNodes \u003d num.corruptReplicas();\n     if (numCorruptNodes !\u003d corruptReplicasCount) {\n       LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n           storedBlock + \". blockMap has \" + numCorruptNodes +\n           \" but corrupt replicas map has \" + corruptReplicasCount);\n     }\n     if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileRedundancy)) {\n       invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n     }\n     return storedBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Block addStoredBlock(final BlockInfo block,\n                               final Block reportedBlock,\n                               DatanodeStorageInfo storageInfo,\n                               DatanodeDescriptor delNodeHint,\n                               boolean logEveryBlock)\n  throws IOException {\n    assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n    BlockInfo storedBlock;\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    if (!block.isComplete()) {\n      //refresh our copy in case the block got completed in another thread\n      storedBlock \u003d getStoredBlock(block);\n    } else {\n      storedBlock \u003d block;\n    }\n    if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n      // If this block does not belong to anyfile, then we are done.\n      blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n          \" belong to any file\", block, node, block.getNumBytes());\n\n      // we could add this block to invalidate set of this datanode.\n      // it will happen in next block report otherwise.\n      return block;\n    }\n\n    // add block to the datanode\n    AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n\n    int curReplicaDelta;\n    if (result \u003d\u003d AddBlockResult.ADDED) {\n      curReplicaDelta \u003d (node.isDecommissioned()) ? 0 : 1;\n      if (logEveryBlock) {\n        blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n            node, storedBlock, storedBlock.getNumBytes());\n      }\n    } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n          \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta \u003d 0;\n      blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n\n    // Now check for completion of blocks and safe block count\n    NumberReplicas num \u003d countNodes(storedBlock);\n    int numLiveReplicas \u003d num.liveReplicas();\n    int pendingNum \u003d pendingReconstruction.getNumReplicas(storedBlock);\n    int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n\n    if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n        hasMinStorage(storedBlock, numLiveReplicas)) {\n      addExpectedReplicasToPending(storedBlock);\n      completeBlock(storedBlock, null, false);\n    } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n      // check whether safe replication is reached for the block\n      // only complete blocks are counted towards that\n      // Is no-op if not in safe mode.\n      // In the case that the block just became complete above, completeBlock()\n      // handles the safe block count maintenance.\n      bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n    }\n    \n    // if block is still under construction, then done for now\n    if (!storedBlock.isCompleteOrCommitted()) {\n      return storedBlock;\n    }\n\n    // do not try to handle extra/low redundancy blocks during first safe mode\n    if (!isPopulatingReplQueues()) {\n      return storedBlock;\n    }\n\n    // handle low redundancy/extra redundancy\n    short fileRedundancy \u003d getExpectedRedundancyNum(storedBlock);\n    if (!isNeededReconstruction(storedBlock, num, pendingNum)) {\n      neededReconstruction.remove(storedBlock, numCurrentReplica,\n          num.readOnlyReplicas(), num.outOfServiceReplicas(), fileRedundancy);\n    } else {\n      updateNeededReconstructions(storedBlock, curReplicaDelta, 0);\n    }\n    if (shouldProcessExtraRedundancy(num, fileRedundancy)) {\n      processExtraRedundancyBlock(storedBlock, fileRedundancy, node,\n          delNodeHint);\n    }\n    // If the file redundancy has reached desired value\n    // we can remove any corrupt replicas the block may have\n    int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n    int numCorruptNodes \u003d num.corruptReplicas();\n    if (numCorruptNodes !\u003d corruptReplicasCount) {\n      LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n          storedBlock + \". blockMap has \" + numCorruptNodes +\n          \" but corrupt replicas map has \" + corruptReplicasCount);\n    }\n    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileRedundancy)) {\n      invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n    }\n    return storedBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
      "commitDate": "17/10/16 5:45 PM",
      "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
      "commitAuthor": "Ming Ma",
      "commitDateOld": "14/10/16 6:13 PM",
      "commitNameOld": "391ce535a739dc92cb90017d759217265a4fd969",
      "commitAuthorOld": "Vinitha Reddy Gankidi",
      "daysBetweenCommits": 2.98,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,107 +1,106 @@\n   private Block addStoredBlock(final BlockInfo block,\n                                final Block reportedBlock,\n                                DatanodeStorageInfo storageInfo,\n                                DatanodeDescriptor delNodeHint,\n                                boolean logEveryBlock)\n   throws IOException {\n     assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n     BlockInfo storedBlock;\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     if (!block.isComplete()) {\n       //refresh our copy in case the block got completed in another thread\n       storedBlock \u003d getStoredBlock(block);\n     } else {\n       storedBlock \u003d block;\n     }\n     if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n       // If this block does not belong to anyfile, then we are done.\n       blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n           \" belong to any file\", block, node, block.getNumBytes());\n \n       // we could add this block to invalidate set of this datanode.\n       // it will happen in next block report otherwise.\n       return block;\n     }\n \n     // add block to the datanode\n     AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n \n     int curReplicaDelta;\n     if (result \u003d\u003d AddBlockResult.ADDED) {\n       curReplicaDelta \u003d 1;\n       if (logEveryBlock) {\n         blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n             node, storedBlock, storedBlock.getNumBytes());\n       }\n     } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n           \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n     } else {\n       // if the same block is added again and the replica was corrupt\n       // previously because of a wrong gen stamp, remove it from the\n       // corrupt block list.\n       corruptReplicas.removeFromCorruptReplicasMap(block, node,\n           Reason.GENSTAMP_MISMATCH);\n       curReplicaDelta \u003d 0;\n       blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n               + \" received for {} on node {} size {}\", storedBlock, node,\n           storedBlock.getNumBytes());\n     }\n \n     // Now check for completion of blocks and safe block count\n     NumberReplicas num \u003d countNodes(storedBlock);\n     int numLiveReplicas \u003d num.liveReplicas();\n     int pendingNum \u003d pendingReconstruction.getNumReplicas(storedBlock);\n     int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n \n     if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n         hasMinStorage(storedBlock, numLiveReplicas)) {\n       addExpectedReplicasToPending(storedBlock);\n       completeBlock(storedBlock, null, false);\n     } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n       // check whether safe replication is reached for the block\n       // only complete blocks are counted towards that\n       // Is no-op if not in safe mode.\n       // In the case that the block just became complete above, completeBlock()\n       // handles the safe block count maintenance.\n       bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n     }\n     \n     // if block is still under construction, then done for now\n     if (!storedBlock.isCompleteOrCommitted()) {\n       return storedBlock;\n     }\n \n     // do not try to handle extra/low redundancy blocks during first safe mode\n     if (!isPopulatingReplQueues()) {\n       return storedBlock;\n     }\n \n     // handle low redundancy/extra redundancy\n     short fileRedundancy \u003d getExpectedRedundancyNum(storedBlock);\n-    if (!isNeededReconstruction(storedBlock, numCurrentReplica)) {\n+    if (!isNeededReconstruction(storedBlock, num, pendingNum)) {\n       neededReconstruction.remove(storedBlock, numCurrentReplica,\n-          num.readOnlyReplicas(),\n-          num.decommissionedAndDecommissioning(), fileRedundancy);\n+          num.readOnlyReplicas(), num.outOfServiceReplicas(), fileRedundancy);\n     } else {\n       updateNeededReconstructions(storedBlock, curReplicaDelta, 0);\n     }\n     if (shouldProcessExtraRedundancy(num, fileRedundancy)) {\n       processExtraRedundancyBlock(storedBlock, fileRedundancy, node,\n           delNodeHint);\n     }\n     // If the file redundancy has reached desired value\n     // we can remove any corrupt replicas the block may have\n     int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n     int numCorruptNodes \u003d num.corruptReplicas();\n     if (numCorruptNodes !\u003d corruptReplicasCount) {\n       LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n           storedBlock + \". blockMap has \" + numCorruptNodes +\n           \" but corrupt replicas map has \" + corruptReplicasCount);\n     }\n     if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileRedundancy)) {\n       invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n     }\n     return storedBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Block addStoredBlock(final BlockInfo block,\n                               final Block reportedBlock,\n                               DatanodeStorageInfo storageInfo,\n                               DatanodeDescriptor delNodeHint,\n                               boolean logEveryBlock)\n  throws IOException {\n    assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n    BlockInfo storedBlock;\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    if (!block.isComplete()) {\n      //refresh our copy in case the block got completed in another thread\n      storedBlock \u003d getStoredBlock(block);\n    } else {\n      storedBlock \u003d block;\n    }\n    if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n      // If this block does not belong to anyfile, then we are done.\n      blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n          \" belong to any file\", block, node, block.getNumBytes());\n\n      // we could add this block to invalidate set of this datanode.\n      // it will happen in next block report otherwise.\n      return block;\n    }\n\n    // add block to the datanode\n    AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n\n    int curReplicaDelta;\n    if (result \u003d\u003d AddBlockResult.ADDED) {\n      curReplicaDelta \u003d 1;\n      if (logEveryBlock) {\n        blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n            node, storedBlock, storedBlock.getNumBytes());\n      }\n    } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n          \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta \u003d 0;\n      blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n\n    // Now check for completion of blocks and safe block count\n    NumberReplicas num \u003d countNodes(storedBlock);\n    int numLiveReplicas \u003d num.liveReplicas();\n    int pendingNum \u003d pendingReconstruction.getNumReplicas(storedBlock);\n    int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n\n    if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n        hasMinStorage(storedBlock, numLiveReplicas)) {\n      addExpectedReplicasToPending(storedBlock);\n      completeBlock(storedBlock, null, false);\n    } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n      // check whether safe replication is reached for the block\n      // only complete blocks are counted towards that\n      // Is no-op if not in safe mode.\n      // In the case that the block just became complete above, completeBlock()\n      // handles the safe block count maintenance.\n      bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n    }\n    \n    // if block is still under construction, then done for now\n    if (!storedBlock.isCompleteOrCommitted()) {\n      return storedBlock;\n    }\n\n    // do not try to handle extra/low redundancy blocks during first safe mode\n    if (!isPopulatingReplQueues()) {\n      return storedBlock;\n    }\n\n    // handle low redundancy/extra redundancy\n    short fileRedundancy \u003d getExpectedRedundancyNum(storedBlock);\n    if (!isNeededReconstruction(storedBlock, num, pendingNum)) {\n      neededReconstruction.remove(storedBlock, numCurrentReplica,\n          num.readOnlyReplicas(), num.outOfServiceReplicas(), fileRedundancy);\n    } else {\n      updateNeededReconstructions(storedBlock, curReplicaDelta, 0);\n    }\n    if (shouldProcessExtraRedundancy(num, fileRedundancy)) {\n      processExtraRedundancyBlock(storedBlock, fileRedundancy, node,\n          delNodeHint);\n    }\n    // If the file redundancy has reached desired value\n    // we can remove any corrupt replicas the block may have\n    int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n    int numCorruptNodes \u003d num.corruptReplicas();\n    if (numCorruptNodes !\u003d corruptReplicasCount) {\n      LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n          storedBlock + \". blockMap has \" + numCorruptNodes +\n          \" but corrupt replicas map has \" + corruptReplicasCount);\n    }\n    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileRedundancy)) {\n      invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n    }\n    return storedBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "a5bb88c8e0fd4bd19b6d377fecbe1d2d441514f6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10843. Update space quota when a UC block is completed rather than committed. Contributed by Erik Krogen.",
      "commitDate": "23/09/16 10:37 AM",
      "commitName": "a5bb88c8e0fd4bd19b6d377fecbe1d2d441514f6",
      "commitAuthor": "Konstantin V Shvachko",
      "commitDateOld": "12/09/16 4:40 PM",
      "commitNameOld": "72dfb048a9a7be64b371b74478b90150bf300d35",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 10.75,
      "commitsBetweenForRepo": 60,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,107 +1,107 @@\n   private Block addStoredBlock(final BlockInfo block,\n                                final Block reportedBlock,\n                                DatanodeStorageInfo storageInfo,\n                                DatanodeDescriptor delNodeHint,\n                                boolean logEveryBlock)\n   throws IOException {\n     assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n     BlockInfo storedBlock;\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     if (!block.isComplete()) {\n       //refresh our copy in case the block got completed in another thread\n       storedBlock \u003d getStoredBlock(block);\n     } else {\n       storedBlock \u003d block;\n     }\n     if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n       // If this block does not belong to anyfile, then we are done.\n       blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n           \" belong to any file\", block, node, block.getNumBytes());\n \n       // we could add this block to invalidate set of this datanode.\n       // it will happen in next block report otherwise.\n       return block;\n     }\n \n     // add block to the datanode\n     AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n \n     int curReplicaDelta;\n     if (result \u003d\u003d AddBlockResult.ADDED) {\n       curReplicaDelta \u003d 1;\n       if (logEveryBlock) {\n         blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n             node, storedBlock, storedBlock.getNumBytes());\n       }\n     } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n           \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n     } else {\n       // if the same block is added again and the replica was corrupt\n       // previously because of a wrong gen stamp, remove it from the\n       // corrupt block list.\n       corruptReplicas.removeFromCorruptReplicasMap(block, node,\n           Reason.GENSTAMP_MISMATCH);\n       curReplicaDelta \u003d 0;\n       blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n               + \" received for {} on node {} size {}\", storedBlock, node,\n           storedBlock.getNumBytes());\n     }\n \n     // Now check for completion of blocks and safe block count\n     NumberReplicas num \u003d countNodes(storedBlock);\n     int numLiveReplicas \u003d num.liveReplicas();\n     int pendingNum \u003d pendingReconstruction.getNumReplicas(storedBlock);\n     int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n \n     if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n         hasMinStorage(storedBlock, numLiveReplicas)) {\n       addExpectedReplicasToPending(storedBlock);\n-      completeBlock(storedBlock, false);\n+      completeBlock(storedBlock, null, false);\n     } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n       // check whether safe replication is reached for the block\n       // only complete blocks are counted towards that\n       // Is no-op if not in safe mode.\n       // In the case that the block just became complete above, completeBlock()\n       // handles the safe block count maintenance.\n       bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n     }\n     \n     // if block is still under construction, then done for now\n     if (!storedBlock.isCompleteOrCommitted()) {\n       return storedBlock;\n     }\n \n     // do not try to handle extra/low redundancy blocks during first safe mode\n     if (!isPopulatingReplQueues()) {\n       return storedBlock;\n     }\n \n     // handle low redundancy/extra redundancy\n     short fileRedundancy \u003d getExpectedRedundancyNum(storedBlock);\n     if (!isNeededReconstruction(storedBlock, numCurrentReplica)) {\n       neededReconstruction.remove(storedBlock, numCurrentReplica,\n           num.readOnlyReplicas(),\n           num.decommissionedAndDecommissioning(), fileRedundancy);\n     } else {\n       updateNeededReconstructions(storedBlock, curReplicaDelta, 0);\n     }\n     if (shouldProcessExtraRedundancy(num, fileRedundancy)) {\n       processExtraRedundancyBlock(storedBlock, fileRedundancy, node,\n           delNodeHint);\n     }\n     // If the file redundancy has reached desired value\n     // we can remove any corrupt replicas the block may have\n     int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n     int numCorruptNodes \u003d num.corruptReplicas();\n     if (numCorruptNodes !\u003d corruptReplicasCount) {\n       LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n           storedBlock + \". blockMap has \" + numCorruptNodes +\n           \" but corrupt replicas map has \" + corruptReplicasCount);\n     }\n     if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileRedundancy)) {\n       invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n     }\n     return storedBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Block addStoredBlock(final BlockInfo block,\n                               final Block reportedBlock,\n                               DatanodeStorageInfo storageInfo,\n                               DatanodeDescriptor delNodeHint,\n                               boolean logEveryBlock)\n  throws IOException {\n    assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n    BlockInfo storedBlock;\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    if (!block.isComplete()) {\n      //refresh our copy in case the block got completed in another thread\n      storedBlock \u003d getStoredBlock(block);\n    } else {\n      storedBlock \u003d block;\n    }\n    if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n      // If this block does not belong to anyfile, then we are done.\n      blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n          \" belong to any file\", block, node, block.getNumBytes());\n\n      // we could add this block to invalidate set of this datanode.\n      // it will happen in next block report otherwise.\n      return block;\n    }\n\n    // add block to the datanode\n    AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n\n    int curReplicaDelta;\n    if (result \u003d\u003d AddBlockResult.ADDED) {\n      curReplicaDelta \u003d 1;\n      if (logEveryBlock) {\n        blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n            node, storedBlock, storedBlock.getNumBytes());\n      }\n    } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n          \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta \u003d 0;\n      blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n\n    // Now check for completion of blocks and safe block count\n    NumberReplicas num \u003d countNodes(storedBlock);\n    int numLiveReplicas \u003d num.liveReplicas();\n    int pendingNum \u003d pendingReconstruction.getNumReplicas(storedBlock);\n    int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n\n    if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n        hasMinStorage(storedBlock, numLiveReplicas)) {\n      addExpectedReplicasToPending(storedBlock);\n      completeBlock(storedBlock, null, false);\n    } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n      // check whether safe replication is reached for the block\n      // only complete blocks are counted towards that\n      // Is no-op if not in safe mode.\n      // In the case that the block just became complete above, completeBlock()\n      // handles the safe block count maintenance.\n      bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n    }\n    \n    // if block is still under construction, then done for now\n    if (!storedBlock.isCompleteOrCommitted()) {\n      return storedBlock;\n    }\n\n    // do not try to handle extra/low redundancy blocks during first safe mode\n    if (!isPopulatingReplQueues()) {\n      return storedBlock;\n    }\n\n    // handle low redundancy/extra redundancy\n    short fileRedundancy \u003d getExpectedRedundancyNum(storedBlock);\n    if (!isNeededReconstruction(storedBlock, numCurrentReplica)) {\n      neededReconstruction.remove(storedBlock, numCurrentReplica,\n          num.readOnlyReplicas(),\n          num.decommissionedAndDecommissioning(), fileRedundancy);\n    } else {\n      updateNeededReconstructions(storedBlock, curReplicaDelta, 0);\n    }\n    if (shouldProcessExtraRedundancy(num, fileRedundancy)) {\n      processExtraRedundancyBlock(storedBlock, fileRedundancy, node,\n          delNodeHint);\n    }\n    // If the file redundancy has reached desired value\n    // we can remove any corrupt replicas the block may have\n    int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n    int numCorruptNodes \u003d num.corruptReplicas();\n    if (numCorruptNodes !\u003d corruptReplicasCount) {\n      LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n          storedBlock + \". blockMap has \" + numCorruptNodes +\n          \" but corrupt replicas map has \" + corruptReplicasCount);\n    }\n    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileRedundancy)) {\n      invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n    }\n    return storedBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "8c84a2a93c22a93b4ff46dd917f6efb995675fbd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10236. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-3]. Contributed by Rakesh R.\n",
      "commitDate": "26/05/16 4:50 PM",
      "commitName": "8c84a2a93c22a93b4ff46dd917f6efb995675fbd",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "28/04/16 10:44 AM",
      "commitNameOld": "6243eabb48390fffada2418ade5adf9e0766afbe",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 28.25,
      "commitsBetweenForRepo": 196,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,107 +1,107 @@\n   private Block addStoredBlock(final BlockInfo block,\n                                final Block reportedBlock,\n                                DatanodeStorageInfo storageInfo,\n                                DatanodeDescriptor delNodeHint,\n                                boolean logEveryBlock)\n   throws IOException {\n     assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n     BlockInfo storedBlock;\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     if (!block.isComplete()) {\n       //refresh our copy in case the block got completed in another thread\n       storedBlock \u003d getStoredBlock(block);\n     } else {\n       storedBlock \u003d block;\n     }\n     if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n       // If this block does not belong to anyfile, then we are done.\n       blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n           \" belong to any file\", block, node, block.getNumBytes());\n \n       // we could add this block to invalidate set of this datanode.\n       // it will happen in next block report otherwise.\n       return block;\n     }\n \n     // add block to the datanode\n     AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n \n     int curReplicaDelta;\n     if (result \u003d\u003d AddBlockResult.ADDED) {\n       curReplicaDelta \u003d 1;\n       if (logEveryBlock) {\n         blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n             node, storedBlock, storedBlock.getNumBytes());\n       }\n     } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n           \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n     } else {\n       // if the same block is added again and the replica was corrupt\n       // previously because of a wrong gen stamp, remove it from the\n       // corrupt block list.\n       corruptReplicas.removeFromCorruptReplicasMap(block, node,\n           Reason.GENSTAMP_MISMATCH);\n       curReplicaDelta \u003d 0;\n       blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n               + \" received for {} on node {} size {}\", storedBlock, node,\n           storedBlock.getNumBytes());\n     }\n \n     // Now check for completion of blocks and safe block count\n     NumberReplicas num \u003d countNodes(storedBlock);\n     int numLiveReplicas \u003d num.liveReplicas();\n     int pendingNum \u003d pendingReconstruction.getNumReplicas(storedBlock);\n     int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n \n     if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n         hasMinStorage(storedBlock, numLiveReplicas)) {\n       addExpectedReplicasToPending(storedBlock);\n       completeBlock(storedBlock, false);\n     } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n       // check whether safe replication is reached for the block\n       // only complete blocks are counted towards that\n       // Is no-op if not in safe mode.\n       // In the case that the block just became complete above, completeBlock()\n       // handles the safe block count maintenance.\n       bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n     }\n     \n     // if block is still under construction, then done for now\n     if (!storedBlock.isCompleteOrCommitted()) {\n       return storedBlock;\n     }\n \n     // do not try to handle extra/low redundancy blocks during first safe mode\n     if (!isPopulatingReplQueues()) {\n       return storedBlock;\n     }\n \n     // handle low redundancy/extra redundancy\n-    short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n+    short fileRedundancy \u003d getExpectedRedundancyNum(storedBlock);\n     if (!isNeededReconstruction(storedBlock, numCurrentReplica)) {\n       neededReconstruction.remove(storedBlock, numCurrentReplica,\n           num.readOnlyReplicas(),\n-          num.decommissionedAndDecommissioning(), fileReplication);\n+          num.decommissionedAndDecommissioning(), fileRedundancy);\n     } else {\n       updateNeededReconstructions(storedBlock, curReplicaDelta, 0);\n     }\n-    if (shouldProcessExtraRedundancy(num, fileReplication)) {\n-      processExtraRedundancyBlock(storedBlock, fileReplication, node,\n+    if (shouldProcessExtraRedundancy(num, fileRedundancy)) {\n+      processExtraRedundancyBlock(storedBlock, fileRedundancy, node,\n           delNodeHint);\n     }\n     // If the file redundancy has reached desired value\n     // we can remove any corrupt replicas the block may have\n     int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n     int numCorruptNodes \u003d num.corruptReplicas();\n     if (numCorruptNodes !\u003d corruptReplicasCount) {\n       LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n           storedBlock + \". blockMap has \" + numCorruptNodes +\n           \" but corrupt replicas map has \" + corruptReplicasCount);\n     }\n-    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n+    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileRedundancy)) {\n       invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n     }\n     return storedBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Block addStoredBlock(final BlockInfo block,\n                               final Block reportedBlock,\n                               DatanodeStorageInfo storageInfo,\n                               DatanodeDescriptor delNodeHint,\n                               boolean logEveryBlock)\n  throws IOException {\n    assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n    BlockInfo storedBlock;\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    if (!block.isComplete()) {\n      //refresh our copy in case the block got completed in another thread\n      storedBlock \u003d getStoredBlock(block);\n    } else {\n      storedBlock \u003d block;\n    }\n    if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n      // If this block does not belong to anyfile, then we are done.\n      blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n          \" belong to any file\", block, node, block.getNumBytes());\n\n      // we could add this block to invalidate set of this datanode.\n      // it will happen in next block report otherwise.\n      return block;\n    }\n\n    // add block to the datanode\n    AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n\n    int curReplicaDelta;\n    if (result \u003d\u003d AddBlockResult.ADDED) {\n      curReplicaDelta \u003d 1;\n      if (logEveryBlock) {\n        blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n            node, storedBlock, storedBlock.getNumBytes());\n      }\n    } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n          \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta \u003d 0;\n      blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n\n    // Now check for completion of blocks and safe block count\n    NumberReplicas num \u003d countNodes(storedBlock);\n    int numLiveReplicas \u003d num.liveReplicas();\n    int pendingNum \u003d pendingReconstruction.getNumReplicas(storedBlock);\n    int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n\n    if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n        hasMinStorage(storedBlock, numLiveReplicas)) {\n      addExpectedReplicasToPending(storedBlock);\n      completeBlock(storedBlock, false);\n    } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n      // check whether safe replication is reached for the block\n      // only complete blocks are counted towards that\n      // Is no-op if not in safe mode.\n      // In the case that the block just became complete above, completeBlock()\n      // handles the safe block count maintenance.\n      bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n    }\n    \n    // if block is still under construction, then done for now\n    if (!storedBlock.isCompleteOrCommitted()) {\n      return storedBlock;\n    }\n\n    // do not try to handle extra/low redundancy blocks during first safe mode\n    if (!isPopulatingReplQueues()) {\n      return storedBlock;\n    }\n\n    // handle low redundancy/extra redundancy\n    short fileRedundancy \u003d getExpectedRedundancyNum(storedBlock);\n    if (!isNeededReconstruction(storedBlock, numCurrentReplica)) {\n      neededReconstruction.remove(storedBlock, numCurrentReplica,\n          num.readOnlyReplicas(),\n          num.decommissionedAndDecommissioning(), fileRedundancy);\n    } else {\n      updateNeededReconstructions(storedBlock, curReplicaDelta, 0);\n    }\n    if (shouldProcessExtraRedundancy(num, fileRedundancy)) {\n      processExtraRedundancyBlock(storedBlock, fileRedundancy, node,\n          delNodeHint);\n    }\n    // If the file redundancy has reached desired value\n    // we can remove any corrupt replicas the block may have\n    int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n    int numCorruptNodes \u003d num.corruptReplicas();\n    if (numCorruptNodes !\u003d corruptReplicasCount) {\n      LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n          storedBlock + \". blockMap has \" + numCorruptNodes +\n          \" but corrupt replicas map has \" + corruptReplicasCount);\n    }\n    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileRedundancy)) {\n      invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n    }\n    return storedBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "5865fe2bf01284993572ea60b3ec3bf8b4492818": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9869. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-2]. Contributed by Rakesh R.\n",
      "commitDate": "25/04/16 10:01 PM",
      "commitName": "5865fe2bf01284993572ea60b3ec3bf8b4492818",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "17/04/16 6:28 PM",
      "commitNameOld": "67523ffcf491f4f2db5335899c00a174d0caaa9b",
      "commitAuthorOld": "Walter Su",
      "daysBetweenCommits": 8.15,
      "commitsBetweenForRepo": 47,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,107 +1,107 @@\n   private Block addStoredBlock(final BlockInfo block,\n                                final Block reportedBlock,\n                                DatanodeStorageInfo storageInfo,\n                                DatanodeDescriptor delNodeHint,\n                                boolean logEveryBlock)\n   throws IOException {\n     assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n     BlockInfo storedBlock;\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     if (!block.isComplete()) {\n       //refresh our copy in case the block got completed in another thread\n       storedBlock \u003d getStoredBlock(block);\n     } else {\n       storedBlock \u003d block;\n     }\n     if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n       // If this block does not belong to anyfile, then we are done.\n       blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n           \" belong to any file\", block, node, block.getNumBytes());\n \n       // we could add this block to invalidate set of this datanode.\n       // it will happen in next block report otherwise.\n       return block;\n     }\n \n     // add block to the datanode\n     AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n \n     int curReplicaDelta;\n     if (result \u003d\u003d AddBlockResult.ADDED) {\n       curReplicaDelta \u003d 1;\n       if (logEveryBlock) {\n         blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n             node, storedBlock, storedBlock.getNumBytes());\n       }\n     } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n           \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n     } else {\n       // if the same block is added again and the replica was corrupt\n       // previously because of a wrong gen stamp, remove it from the\n       // corrupt block list.\n       corruptReplicas.removeFromCorruptReplicasMap(block, node,\n           Reason.GENSTAMP_MISMATCH);\n       curReplicaDelta \u003d 0;\n       blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n               + \" received for {} on node {} size {}\", storedBlock, node,\n           storedBlock.getNumBytes());\n     }\n \n     // Now check for completion of blocks and safe block count\n     NumberReplicas num \u003d countNodes(storedBlock);\n     int numLiveReplicas \u003d num.liveReplicas();\n-    int pendingNum \u003d pendingReplications.getNumReplicas(storedBlock);\n+    int pendingNum \u003d pendingReconstruction.getNumReplicas(storedBlock);\n     int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n \n     if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n         hasMinStorage(storedBlock, numLiveReplicas)) {\n       addExpectedReplicasToPending(storedBlock);\n       completeBlock(storedBlock, false);\n     } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n       // check whether safe replication is reached for the block\n       // only complete blocks are counted towards that\n       // Is no-op if not in safe mode.\n       // In the case that the block just became complete above, completeBlock()\n       // handles the safe block count maintenance.\n       bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n     }\n     \n     // if block is still under construction, then done for now\n     if (!storedBlock.isCompleteOrCommitted()) {\n       return storedBlock;\n     }\n \n     // do not try to handle extra/low redundancy blocks during first safe mode\n     if (!isPopulatingReplQueues()) {\n       return storedBlock;\n     }\n \n     // handle low redundancy/extra redundancy\n     short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n     if (!isNeededReconstruction(storedBlock, numCurrentReplica)) {\n       neededReconstruction.remove(storedBlock, numCurrentReplica,\n           num.readOnlyReplicas(),\n           num.decommissionedAndDecommissioning(), fileReplication);\n     } else {\n       updateNeededReconstructions(storedBlock, curReplicaDelta, 0);\n     }\n     if (shouldProcessExtraRedundancy(num, fileReplication)) {\n       processExtraRedundancyBlock(storedBlock, fileReplication, node,\n           delNodeHint);\n     }\n     // If the file redundancy has reached desired value\n     // we can remove any corrupt replicas the block may have\n     int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n     int numCorruptNodes \u003d num.corruptReplicas();\n     if (numCorruptNodes !\u003d corruptReplicasCount) {\n       LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n           storedBlock + \". blockMap has \" + numCorruptNodes +\n           \" but corrupt replicas map has \" + corruptReplicasCount);\n     }\n     if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n       invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n     }\n     return storedBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Block addStoredBlock(final BlockInfo block,\n                               final Block reportedBlock,\n                               DatanodeStorageInfo storageInfo,\n                               DatanodeDescriptor delNodeHint,\n                               boolean logEveryBlock)\n  throws IOException {\n    assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n    BlockInfo storedBlock;\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    if (!block.isComplete()) {\n      //refresh our copy in case the block got completed in another thread\n      storedBlock \u003d getStoredBlock(block);\n    } else {\n      storedBlock \u003d block;\n    }\n    if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n      // If this block does not belong to anyfile, then we are done.\n      blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n          \" belong to any file\", block, node, block.getNumBytes());\n\n      // we could add this block to invalidate set of this datanode.\n      // it will happen in next block report otherwise.\n      return block;\n    }\n\n    // add block to the datanode\n    AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n\n    int curReplicaDelta;\n    if (result \u003d\u003d AddBlockResult.ADDED) {\n      curReplicaDelta \u003d 1;\n      if (logEveryBlock) {\n        blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n            node, storedBlock, storedBlock.getNumBytes());\n      }\n    } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n          \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta \u003d 0;\n      blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n\n    // Now check for completion of blocks and safe block count\n    NumberReplicas num \u003d countNodes(storedBlock);\n    int numLiveReplicas \u003d num.liveReplicas();\n    int pendingNum \u003d pendingReconstruction.getNumReplicas(storedBlock);\n    int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n\n    if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n        hasMinStorage(storedBlock, numLiveReplicas)) {\n      addExpectedReplicasToPending(storedBlock);\n      completeBlock(storedBlock, false);\n    } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n      // check whether safe replication is reached for the block\n      // only complete blocks are counted towards that\n      // Is no-op if not in safe mode.\n      // In the case that the block just became complete above, completeBlock()\n      // handles the safe block count maintenance.\n      bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n    }\n    \n    // if block is still under construction, then done for now\n    if (!storedBlock.isCompleteOrCommitted()) {\n      return storedBlock;\n    }\n\n    // do not try to handle extra/low redundancy blocks during first safe mode\n    if (!isPopulatingReplQueues()) {\n      return storedBlock;\n    }\n\n    // handle low redundancy/extra redundancy\n    short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n    if (!isNeededReconstruction(storedBlock, numCurrentReplica)) {\n      neededReconstruction.remove(storedBlock, numCurrentReplica,\n          num.readOnlyReplicas(),\n          num.decommissionedAndDecommissioning(), fileReplication);\n    } else {\n      updateNeededReconstructions(storedBlock, curReplicaDelta, 0);\n    }\n    if (shouldProcessExtraRedundancy(num, fileReplication)) {\n      processExtraRedundancyBlock(storedBlock, fileReplication, node,\n          delNodeHint);\n    }\n    // If the file redundancy has reached desired value\n    // we can remove any corrupt replicas the block may have\n    int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n    int numCorruptNodes \u003d num.corruptReplicas();\n    if (numCorruptNodes !\u003d corruptReplicasCount) {\n      LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n          storedBlock + \". blockMap has \" + numCorruptNodes +\n          \" but corrupt replicas map has \" + corruptReplicasCount);\n    }\n    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n      invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n    }\n    return storedBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9857. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-1]. Contributed by Rakesh R.\n",
      "commitDate": "16/03/16 4:53 PM",
      "commitName": "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "10/03/16 7:03 PM",
      "commitNameOld": "e01c6ea688e62f25c4310e771a0cd85b53a5fb87",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 5.87,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,107 @@\n   private Block addStoredBlock(final BlockInfo block,\n                                final Block reportedBlock,\n                                DatanodeStorageInfo storageInfo,\n                                DatanodeDescriptor delNodeHint,\n                                boolean logEveryBlock)\n   throws IOException {\n     assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n     BlockInfo storedBlock;\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     if (!block.isComplete()) {\n       //refresh our copy in case the block got completed in another thread\n       storedBlock \u003d getStoredBlock(block);\n     } else {\n       storedBlock \u003d block;\n     }\n     if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n       // If this block does not belong to anyfile, then we are done.\n       blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n           \" belong to any file\", block, node, block.getNumBytes());\n \n       // we could add this block to invalidate set of this datanode.\n       // it will happen in next block report otherwise.\n       return block;\n     }\n \n     // add block to the datanode\n     AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n \n     int curReplicaDelta;\n     if (result \u003d\u003d AddBlockResult.ADDED) {\n       curReplicaDelta \u003d 1;\n       if (logEveryBlock) {\n         blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n             node, storedBlock, storedBlock.getNumBytes());\n       }\n     } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n           \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n     } else {\n       // if the same block is added again and the replica was corrupt\n       // previously because of a wrong gen stamp, remove it from the\n       // corrupt block list.\n       corruptReplicas.removeFromCorruptReplicasMap(block, node,\n           Reason.GENSTAMP_MISMATCH);\n       curReplicaDelta \u003d 0;\n       blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n               + \" received for {} on node {} size {}\", storedBlock, node,\n           storedBlock.getNumBytes());\n     }\n \n     // Now check for completion of blocks and safe block count\n     NumberReplicas num \u003d countNodes(storedBlock);\n     int numLiveReplicas \u003d num.liveReplicas();\n     int pendingNum \u003d pendingReplications.getNumReplicas(storedBlock);\n     int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n \n     if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n         hasMinStorage(storedBlock, numLiveReplicas)) {\n       addExpectedReplicasToPending(storedBlock);\n       completeBlock(storedBlock, false);\n     } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n       // check whether safe replication is reached for the block\n       // only complete blocks are counted towards that\n       // Is no-op if not in safe mode.\n       // In the case that the block just became complete above, completeBlock()\n       // handles the safe block count maintenance.\n       bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n     }\n     \n     // if block is still under construction, then done for now\n     if (!storedBlock.isCompleteOrCommitted()) {\n       return storedBlock;\n     }\n \n-    // do not try to handle over/under-replicated blocks during first safe mode\n+    // do not try to handle extra/low redundancy blocks during first safe mode\n     if (!isPopulatingReplQueues()) {\n       return storedBlock;\n     }\n \n-    // handle underReplication/overReplication\n+    // handle low redundancy/extra redundancy\n     short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n-    if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n-      neededReplications.remove(storedBlock, numCurrentReplica,\n+    if (!isNeededReconstruction(storedBlock, numCurrentReplica)) {\n+      neededReconstruction.remove(storedBlock, numCurrentReplica,\n           num.readOnlyReplicas(),\n           num.decommissionedAndDecommissioning(), fileReplication);\n     } else {\n-      updateNeededReplications(storedBlock, curReplicaDelta, 0);\n+      updateNeededReconstructions(storedBlock, curReplicaDelta, 0);\n     }\n-    if (shouldProcessOverReplicated(num, fileReplication)) {\n-      processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n+    if (shouldProcessExtraRedundancy(num, fileReplication)) {\n+      processExtraRedundancyBlock(storedBlock, fileReplication, node,\n+          delNodeHint);\n     }\n-    // If the file replication has reached desired value\n+    // If the file redundancy has reached desired value\n     // we can remove any corrupt replicas the block may have\n     int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n     int numCorruptNodes \u003d num.corruptReplicas();\n     if (numCorruptNodes !\u003d corruptReplicasCount) {\n       LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n           storedBlock + \". blockMap has \" + numCorruptNodes +\n           \" but corrupt replicas map has \" + corruptReplicasCount);\n     }\n     if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n       invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n     }\n     return storedBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Block addStoredBlock(final BlockInfo block,\n                               final Block reportedBlock,\n                               DatanodeStorageInfo storageInfo,\n                               DatanodeDescriptor delNodeHint,\n                               boolean logEveryBlock)\n  throws IOException {\n    assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n    BlockInfo storedBlock;\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    if (!block.isComplete()) {\n      //refresh our copy in case the block got completed in another thread\n      storedBlock \u003d getStoredBlock(block);\n    } else {\n      storedBlock \u003d block;\n    }\n    if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n      // If this block does not belong to anyfile, then we are done.\n      blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n          \" belong to any file\", block, node, block.getNumBytes());\n\n      // we could add this block to invalidate set of this datanode.\n      // it will happen in next block report otherwise.\n      return block;\n    }\n\n    // add block to the datanode\n    AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n\n    int curReplicaDelta;\n    if (result \u003d\u003d AddBlockResult.ADDED) {\n      curReplicaDelta \u003d 1;\n      if (logEveryBlock) {\n        blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n            node, storedBlock, storedBlock.getNumBytes());\n      }\n    } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n          \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta \u003d 0;\n      blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n\n    // Now check for completion of blocks and safe block count\n    NumberReplicas num \u003d countNodes(storedBlock);\n    int numLiveReplicas \u003d num.liveReplicas();\n    int pendingNum \u003d pendingReplications.getNumReplicas(storedBlock);\n    int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n\n    if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n        hasMinStorage(storedBlock, numLiveReplicas)) {\n      addExpectedReplicasToPending(storedBlock);\n      completeBlock(storedBlock, false);\n    } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n      // check whether safe replication is reached for the block\n      // only complete blocks are counted towards that\n      // Is no-op if not in safe mode.\n      // In the case that the block just became complete above, completeBlock()\n      // handles the safe block count maintenance.\n      bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n    }\n    \n    // if block is still under construction, then done for now\n    if (!storedBlock.isCompleteOrCommitted()) {\n      return storedBlock;\n    }\n\n    // do not try to handle extra/low redundancy blocks during first safe mode\n    if (!isPopulatingReplQueues()) {\n      return storedBlock;\n    }\n\n    // handle low redundancy/extra redundancy\n    short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n    if (!isNeededReconstruction(storedBlock, numCurrentReplica)) {\n      neededReconstruction.remove(storedBlock, numCurrentReplica,\n          num.readOnlyReplicas(),\n          num.decommissionedAndDecommissioning(), fileReplication);\n    } else {\n      updateNeededReconstructions(storedBlock, curReplicaDelta, 0);\n    }\n    if (shouldProcessExtraRedundancy(num, fileReplication)) {\n      processExtraRedundancyBlock(storedBlock, fileReplication, node,\n          delNodeHint);\n    }\n    // If the file redundancy has reached desired value\n    // we can remove any corrupt replicas the block may have\n    int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n    int numCorruptNodes \u003d num.corruptReplicas();\n    if (numCorruptNodes !\u003d corruptReplicasCount) {\n      LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n          storedBlock + \". blockMap has \" + numCorruptNodes +\n          \" but corrupt replicas map has \" + corruptReplicasCount);\n    }\n    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n      invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n    }\n    return storedBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "724d2299cd2516d90c030f6e20d814cceb439228": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9906. Remove spammy log spew when a datanode is restarted. (Contributed by Brahma Reddy Battula)\n",
      "commitDate": "07/03/16 12:19 PM",
      "commitName": "724d2299cd2516d90c030f6e20d814cceb439228",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "01/03/16 6:41 PM",
      "commitNameOld": "f2ba7da4f0df6cf0fc245093aeb4500158e6ee0b",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 5.73,
      "commitsBetweenForRepo": 30,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,106 @@\n   private Block addStoredBlock(final BlockInfo block,\n                                final Block reportedBlock,\n                                DatanodeStorageInfo storageInfo,\n                                DatanodeDescriptor delNodeHint,\n                                boolean logEveryBlock)\n   throws IOException {\n     assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n     BlockInfo storedBlock;\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     if (!block.isComplete()) {\n       //refresh our copy in case the block got completed in another thread\n       storedBlock \u003d getStoredBlock(block);\n     } else {\n       storedBlock \u003d block;\n     }\n     if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n       // If this block does not belong to anyfile, then we are done.\n       blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n           \" belong to any file\", block, node, block.getNumBytes());\n \n       // we could add this block to invalidate set of this datanode.\n       // it will happen in next block report otherwise.\n       return block;\n     }\n \n     // add block to the datanode\n     AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n \n     int curReplicaDelta;\n     if (result \u003d\u003d AddBlockResult.ADDED) {\n       curReplicaDelta \u003d 1;\n       if (logEveryBlock) {\n         blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n             node, storedBlock, storedBlock.getNumBytes());\n       }\n     } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n           \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n     } else {\n       // if the same block is added again and the replica was corrupt\n       // previously because of a wrong gen stamp, remove it from the\n       // corrupt block list.\n       corruptReplicas.removeFromCorruptReplicasMap(block, node,\n           Reason.GENSTAMP_MISMATCH);\n       curReplicaDelta \u003d 0;\n-      blockLog.warn(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n+      blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n               + \" received for {} on node {} size {}\", storedBlock, node,\n           storedBlock.getNumBytes());\n     }\n \n     // Now check for completion of blocks and safe block count\n     NumberReplicas num \u003d countNodes(storedBlock);\n     int numLiveReplicas \u003d num.liveReplicas();\n     int pendingNum \u003d pendingReplications.getNumReplicas(storedBlock);\n     int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n \n     if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n         hasMinStorage(storedBlock, numLiveReplicas)) {\n       addExpectedReplicasToPending(storedBlock);\n       completeBlock(storedBlock, false);\n     } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n       // check whether safe replication is reached for the block\n       // only complete blocks are counted towards that\n       // Is no-op if not in safe mode.\n       // In the case that the block just became complete above, completeBlock()\n       // handles the safe block count maintenance.\n       bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n     }\n     \n     // if block is still under construction, then done for now\n     if (!storedBlock.isCompleteOrCommitted()) {\n       return storedBlock;\n     }\n \n     // do not try to handle over/under-replicated blocks during first safe mode\n     if (!isPopulatingReplQueues()) {\n       return storedBlock;\n     }\n \n     // handle underReplication/overReplication\n     short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n     if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n       neededReplications.remove(storedBlock, numCurrentReplica,\n           num.readOnlyReplicas(),\n           num.decommissionedAndDecommissioning(), fileReplication);\n     } else {\n       updateNeededReplications(storedBlock, curReplicaDelta, 0);\n     }\n     if (shouldProcessOverReplicated(num, fileReplication)) {\n       processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n     }\n     // If the file replication has reached desired value\n     // we can remove any corrupt replicas the block may have\n     int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n     int numCorruptNodes \u003d num.corruptReplicas();\n     if (numCorruptNodes !\u003d corruptReplicasCount) {\n       LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n           storedBlock + \". blockMap has \" + numCorruptNodes +\n           \" but corrupt replicas map has \" + corruptReplicasCount);\n     }\n     if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n       invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n     }\n     return storedBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Block addStoredBlock(final BlockInfo block,\n                               final Block reportedBlock,\n                               DatanodeStorageInfo storageInfo,\n                               DatanodeDescriptor delNodeHint,\n                               boolean logEveryBlock)\n  throws IOException {\n    assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n    BlockInfo storedBlock;\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    if (!block.isComplete()) {\n      //refresh our copy in case the block got completed in another thread\n      storedBlock \u003d getStoredBlock(block);\n    } else {\n      storedBlock \u003d block;\n    }\n    if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n      // If this block does not belong to anyfile, then we are done.\n      blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n          \" belong to any file\", block, node, block.getNumBytes());\n\n      // we could add this block to invalidate set of this datanode.\n      // it will happen in next block report otherwise.\n      return block;\n    }\n\n    // add block to the datanode\n    AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n\n    int curReplicaDelta;\n    if (result \u003d\u003d AddBlockResult.ADDED) {\n      curReplicaDelta \u003d 1;\n      if (logEveryBlock) {\n        blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n            node, storedBlock, storedBlock.getNumBytes());\n      }\n    } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n          \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta \u003d 0;\n      blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n\n    // Now check for completion of blocks and safe block count\n    NumberReplicas num \u003d countNodes(storedBlock);\n    int numLiveReplicas \u003d num.liveReplicas();\n    int pendingNum \u003d pendingReplications.getNumReplicas(storedBlock);\n    int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n\n    if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n        hasMinStorage(storedBlock, numLiveReplicas)) {\n      addExpectedReplicasToPending(storedBlock);\n      completeBlock(storedBlock, false);\n    } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n      // check whether safe replication is reached for the block\n      // only complete blocks are counted towards that\n      // Is no-op if not in safe mode.\n      // In the case that the block just became complete above, completeBlock()\n      // handles the safe block count maintenance.\n      bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n    }\n    \n    // if block is still under construction, then done for now\n    if (!storedBlock.isCompleteOrCommitted()) {\n      return storedBlock;\n    }\n\n    // do not try to handle over/under-replicated blocks during first safe mode\n    if (!isPopulatingReplQueues()) {\n      return storedBlock;\n    }\n\n    // handle underReplication/overReplication\n    short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n    if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n      neededReplications.remove(storedBlock, numCurrentReplica,\n          num.readOnlyReplicas(),\n          num.decommissionedAndDecommissioning(), fileReplication);\n    } else {\n      updateNeededReplications(storedBlock, curReplicaDelta, 0);\n    }\n    if (shouldProcessOverReplicated(num, fileReplication)) {\n      processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n    }\n    // If the file replication has reached desired value\n    // we can remove any corrupt replicas the block may have\n    int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n    int numCorruptNodes \u003d num.corruptReplicas();\n    if (numCorruptNodes !\u003d corruptReplicasCount) {\n      LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n          storedBlock + \". blockMap has \" + numCorruptNodes +\n          \" but corrupt replicas map has \" + corruptReplicasCount);\n    }\n    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n      invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n    }\n    return storedBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "f2ba7da4f0df6cf0fc245093aeb4500158e6ee0b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9876. shouldProcessOverReplicated should not count number of pending replicas. Contributed by Jing Zhao.\n",
      "commitDate": "01/03/16 6:41 PM",
      "commitName": "f2ba7da4f0df6cf0fc245093aeb4500158e6ee0b",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "28/02/16 2:54 PM",
      "commitNameOld": "408f2c807bbaaaa37ce1b69a5dfa9d76ed427d6e",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 2.16,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,106 @@\n   private Block addStoredBlock(final BlockInfo block,\n                                final Block reportedBlock,\n                                DatanodeStorageInfo storageInfo,\n                                DatanodeDescriptor delNodeHint,\n                                boolean logEveryBlock)\n   throws IOException {\n     assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n     BlockInfo storedBlock;\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     if (!block.isComplete()) {\n       //refresh our copy in case the block got completed in another thread\n       storedBlock \u003d getStoredBlock(block);\n     } else {\n       storedBlock \u003d block;\n     }\n     if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n       // If this block does not belong to anyfile, then we are done.\n       blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n           \" belong to any file\", block, node, block.getNumBytes());\n \n       // we could add this block to invalidate set of this datanode.\n       // it will happen in next block report otherwise.\n       return block;\n     }\n \n     // add block to the datanode\n     AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n \n     int curReplicaDelta;\n     if (result \u003d\u003d AddBlockResult.ADDED) {\n       curReplicaDelta \u003d 1;\n       if (logEveryBlock) {\n         blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n             node, storedBlock, storedBlock.getNumBytes());\n       }\n     } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n           \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n     } else {\n       // if the same block is added again and the replica was corrupt\n       // previously because of a wrong gen stamp, remove it from the\n       // corrupt block list.\n       corruptReplicas.removeFromCorruptReplicasMap(block, node,\n           Reason.GENSTAMP_MISMATCH);\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n               + \" received for {} on node {} size {}\", storedBlock, node,\n           storedBlock.getNumBytes());\n     }\n \n     // Now check for completion of blocks and safe block count\n     NumberReplicas num \u003d countNodes(storedBlock);\n     int numLiveReplicas \u003d num.liveReplicas();\n     int pendingNum \u003d pendingReplications.getNumReplicas(storedBlock);\n     int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n \n     if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n         hasMinStorage(storedBlock, numLiveReplicas)) {\n       addExpectedReplicasToPending(storedBlock);\n       completeBlock(storedBlock, false);\n     } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n       // check whether safe replication is reached for the block\n       // only complete blocks are counted towards that\n       // Is no-op if not in safe mode.\n       // In the case that the block just became complete above, completeBlock()\n       // handles the safe block count maintenance.\n       bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n     }\n     \n     // if block is still under construction, then done for now\n     if (!storedBlock.isCompleteOrCommitted()) {\n       return storedBlock;\n     }\n \n     // do not try to handle over/under-replicated blocks during first safe mode\n     if (!isPopulatingReplQueues()) {\n       return storedBlock;\n     }\n \n     // handle underReplication/overReplication\n     short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n     if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n       neededReplications.remove(storedBlock, numCurrentReplica,\n           num.readOnlyReplicas(),\n           num.decommissionedAndDecommissioning(), fileReplication);\n     } else {\n       updateNeededReplications(storedBlock, curReplicaDelta, 0);\n     }\n-    if (shouldProcessOverReplicated(num, pendingNum, fileReplication)) {\n+    if (shouldProcessOverReplicated(num, fileReplication)) {\n       processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n     }\n     // If the file replication has reached desired value\n     // we can remove any corrupt replicas the block may have\n     int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n     int numCorruptNodes \u003d num.corruptReplicas();\n     if (numCorruptNodes !\u003d corruptReplicasCount) {\n       LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n           storedBlock + \". blockMap has \" + numCorruptNodes +\n           \" but corrupt replicas map has \" + corruptReplicasCount);\n     }\n     if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n       invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n     }\n     return storedBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Block addStoredBlock(final BlockInfo block,\n                               final Block reportedBlock,\n                               DatanodeStorageInfo storageInfo,\n                               DatanodeDescriptor delNodeHint,\n                               boolean logEveryBlock)\n  throws IOException {\n    assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n    BlockInfo storedBlock;\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    if (!block.isComplete()) {\n      //refresh our copy in case the block got completed in another thread\n      storedBlock \u003d getStoredBlock(block);\n    } else {\n      storedBlock \u003d block;\n    }\n    if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n      // If this block does not belong to anyfile, then we are done.\n      blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n          \" belong to any file\", block, node, block.getNumBytes());\n\n      // we could add this block to invalidate set of this datanode.\n      // it will happen in next block report otherwise.\n      return block;\n    }\n\n    // add block to the datanode\n    AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n\n    int curReplicaDelta;\n    if (result \u003d\u003d AddBlockResult.ADDED) {\n      curReplicaDelta \u003d 1;\n      if (logEveryBlock) {\n        blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n            node, storedBlock, storedBlock.getNumBytes());\n      }\n    } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n          \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n\n    // Now check for completion of blocks and safe block count\n    NumberReplicas num \u003d countNodes(storedBlock);\n    int numLiveReplicas \u003d num.liveReplicas();\n    int pendingNum \u003d pendingReplications.getNumReplicas(storedBlock);\n    int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n\n    if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n        hasMinStorage(storedBlock, numLiveReplicas)) {\n      addExpectedReplicasToPending(storedBlock);\n      completeBlock(storedBlock, false);\n    } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n      // check whether safe replication is reached for the block\n      // only complete blocks are counted towards that\n      // Is no-op if not in safe mode.\n      // In the case that the block just became complete above, completeBlock()\n      // handles the safe block count maintenance.\n      bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n    }\n    \n    // if block is still under construction, then done for now\n    if (!storedBlock.isCompleteOrCommitted()) {\n      return storedBlock;\n    }\n\n    // do not try to handle over/under-replicated blocks during first safe mode\n    if (!isPopulatingReplQueues()) {\n      return storedBlock;\n    }\n\n    // handle underReplication/overReplication\n    short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n    if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n      neededReplications.remove(storedBlock, numCurrentReplica,\n          num.readOnlyReplicas(),\n          num.decommissionedAndDecommissioning(), fileReplication);\n    } else {\n      updateNeededReplications(storedBlock, curReplicaDelta, 0);\n    }\n    if (shouldProcessOverReplicated(num, fileReplication)) {\n      processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n    }\n    // If the file replication has reached desired value\n    // we can remove any corrupt replicas the block may have\n    int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n    int numCorruptNodes \u003d num.corruptReplicas();\n    if (numCorruptNodes !\u003d corruptReplicasCount) {\n      LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n          storedBlock + \". blockMap has \" + numCorruptNodes +\n          \" but corrupt replicas map has \" + corruptReplicasCount);\n    }\n    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n      invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n    }\n    return storedBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "47b92f2b6f2dafc129a41b247f35e77c8e47ffba": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9837. BlockManager#countNodes should be able to detect duplicated internal blocks. Contributed by Jing Zhao.\n",
      "commitDate": "24/02/16 3:13 PM",
      "commitName": "47b92f2b6f2dafc129a41b247f35e77c8e47ffba",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "20/02/16 11:19 PM",
      "commitNameOld": "d5abd293a890a8a1da48a166a291ae1c5644ad57",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 3.66,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,106 @@\n   private Block addStoredBlock(final BlockInfo block,\n                                final Block reportedBlock,\n                                DatanodeStorageInfo storageInfo,\n                                DatanodeDescriptor delNodeHint,\n                                boolean logEveryBlock)\n   throws IOException {\n     assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n     BlockInfo storedBlock;\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     if (!block.isComplete()) {\n       //refresh our copy in case the block got completed in another thread\n       storedBlock \u003d getStoredBlock(block);\n     } else {\n       storedBlock \u003d block;\n     }\n     if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n       // If this block does not belong to anyfile, then we are done.\n       blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n           \" belong to any file\", block, node, block.getNumBytes());\n \n       // we could add this block to invalidate set of this datanode.\n       // it will happen in next block report otherwise.\n       return block;\n     }\n \n     // add block to the datanode\n     AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n \n     int curReplicaDelta;\n     if (result \u003d\u003d AddBlockResult.ADDED) {\n       curReplicaDelta \u003d 1;\n       if (logEveryBlock) {\n         blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n             node, storedBlock, storedBlock.getNumBytes());\n       }\n     } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n           \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n     } else {\n       // if the same block is added again and the replica was corrupt\n       // previously because of a wrong gen stamp, remove it from the\n       // corrupt block list.\n       corruptReplicas.removeFromCorruptReplicasMap(block, node,\n           Reason.GENSTAMP_MISMATCH);\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n               + \" received for {} on node {} size {}\", storedBlock, node,\n           storedBlock.getNumBytes());\n     }\n \n     // Now check for completion of blocks and safe block count\n     NumberReplicas num \u003d countNodes(storedBlock);\n     int numLiveReplicas \u003d num.liveReplicas();\n-    int numCurrentReplica \u003d numLiveReplicas\n-      + pendingReplications.getNumReplicas(storedBlock);\n+    int pendingNum \u003d pendingReplications.getNumReplicas(storedBlock);\n+    int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n \n     if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n         hasMinStorage(storedBlock, numLiveReplicas)) {\n       addExpectedReplicasToPending(storedBlock);\n       completeBlock(storedBlock, false);\n     } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n       // check whether safe replication is reached for the block\n       // only complete blocks are counted towards that\n       // Is no-op if not in safe mode.\n       // In the case that the block just became complete above, completeBlock()\n       // handles the safe block count maintenance.\n       bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n     }\n     \n     // if block is still under construction, then done for now\n     if (!storedBlock.isCompleteOrCommitted()) {\n       return storedBlock;\n     }\n \n     // do not try to handle over/under-replicated blocks during first safe mode\n     if (!isPopulatingReplQueues()) {\n       return storedBlock;\n     }\n \n     // handle underReplication/overReplication\n     short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n     if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n       neededReplications.remove(storedBlock, numCurrentReplica,\n           num.readOnlyReplicas(),\n           num.decommissionedAndDecommissioning(), fileReplication);\n     } else {\n       updateNeededReplications(storedBlock, curReplicaDelta, 0);\n     }\n-    if (numCurrentReplica \u003e fileReplication) {\n+    if (shouldProcessOverReplicated(num, pendingNum, fileReplication)) {\n       processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n     }\n     // If the file replication has reached desired value\n     // we can remove any corrupt replicas the block may have\n     int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n     int numCorruptNodes \u003d num.corruptReplicas();\n     if (numCorruptNodes !\u003d corruptReplicasCount) {\n       LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n           storedBlock + \". blockMap has \" + numCorruptNodes +\n           \" but corrupt replicas map has \" + corruptReplicasCount);\n     }\n     if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n       invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n     }\n     return storedBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Block addStoredBlock(final BlockInfo block,\n                               final Block reportedBlock,\n                               DatanodeStorageInfo storageInfo,\n                               DatanodeDescriptor delNodeHint,\n                               boolean logEveryBlock)\n  throws IOException {\n    assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n    BlockInfo storedBlock;\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    if (!block.isComplete()) {\n      //refresh our copy in case the block got completed in another thread\n      storedBlock \u003d getStoredBlock(block);\n    } else {\n      storedBlock \u003d block;\n    }\n    if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n      // If this block does not belong to anyfile, then we are done.\n      blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n          \" belong to any file\", block, node, block.getNumBytes());\n\n      // we could add this block to invalidate set of this datanode.\n      // it will happen in next block report otherwise.\n      return block;\n    }\n\n    // add block to the datanode\n    AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n\n    int curReplicaDelta;\n    if (result \u003d\u003d AddBlockResult.ADDED) {\n      curReplicaDelta \u003d 1;\n      if (logEveryBlock) {\n        blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n            node, storedBlock, storedBlock.getNumBytes());\n      }\n    } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n          \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n\n    // Now check for completion of blocks and safe block count\n    NumberReplicas num \u003d countNodes(storedBlock);\n    int numLiveReplicas \u003d num.liveReplicas();\n    int pendingNum \u003d pendingReplications.getNumReplicas(storedBlock);\n    int numCurrentReplica \u003d numLiveReplicas + pendingNum;\n\n    if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n        hasMinStorage(storedBlock, numLiveReplicas)) {\n      addExpectedReplicasToPending(storedBlock);\n      completeBlock(storedBlock, false);\n    } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n      // check whether safe replication is reached for the block\n      // only complete blocks are counted towards that\n      // Is no-op if not in safe mode.\n      // In the case that the block just became complete above, completeBlock()\n      // handles the safe block count maintenance.\n      bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n    }\n    \n    // if block is still under construction, then done for now\n    if (!storedBlock.isCompleteOrCommitted()) {\n      return storedBlock;\n    }\n\n    // do not try to handle over/under-replicated blocks during first safe mode\n    if (!isPopulatingReplQueues()) {\n      return storedBlock;\n    }\n\n    // handle underReplication/overReplication\n    short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n    if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n      neededReplications.remove(storedBlock, numCurrentReplica,\n          num.readOnlyReplicas(),\n          num.decommissionedAndDecommissioning(), fileReplication);\n    } else {\n      updateNeededReplications(storedBlock, curReplicaDelta, 0);\n    }\n    if (shouldProcessOverReplicated(num, pendingNum, fileReplication)) {\n      processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n    }\n    // If the file replication has reached desired value\n    // we can remove any corrupt replicas the block may have\n    int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n    int numCorruptNodes \u003d num.corruptReplicas();\n    if (numCorruptNodes !\u003d corruptReplicasCount) {\n      LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n          storedBlock + \". blockMap has \" + numCorruptNodes +\n          \" but corrupt replicas map has \" + corruptReplicasCount);\n    }\n    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n      invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n    }\n    return storedBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "972782d9568e0849484c027f27c1638ba50ec56e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9754. Avoid unnecessary getBlockCollection calls in BlockManager. Contributed by Jing Zhao.\n",
      "commitDate": "12/02/16 11:07 AM",
      "commitName": "972782d9568e0849484c027f27c1638ba50ec56e",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "10/02/16 9:24 PM",
      "commitNameOld": "19adb2bc641999b83e25ff0e107ba8c6edbad399",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 1.57,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,108 +1,106 @@\n   private Block addStoredBlock(final BlockInfo block,\n                                final Block reportedBlock,\n                                DatanodeStorageInfo storageInfo,\n                                DatanodeDescriptor delNodeHint,\n                                boolean logEveryBlock)\n   throws IOException {\n     assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n     BlockInfo storedBlock;\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     if (!block.isComplete()) {\n       //refresh our copy in case the block got completed in another thread\n       storedBlock \u003d getStoredBlock(block);\n     } else {\n       storedBlock \u003d block;\n     }\n     if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n       // If this block does not belong to anyfile, then we are done.\n       blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n           \" belong to any file\", block, node, block.getNumBytes());\n \n       // we could add this block to invalidate set of this datanode.\n       // it will happen in next block report otherwise.\n       return block;\n     }\n-    BlockCollection bc \u003d getBlockCollection(storedBlock);\n-    assert bc !\u003d null : \"Block must belong to a file\";\n \n     // add block to the datanode\n     AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n \n     int curReplicaDelta;\n     if (result \u003d\u003d AddBlockResult.ADDED) {\n       curReplicaDelta \u003d 1;\n       if (logEveryBlock) {\n         blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n             node, storedBlock, storedBlock.getNumBytes());\n       }\n     } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n           \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n     } else {\n       // if the same block is added again and the replica was corrupt\n       // previously because of a wrong gen stamp, remove it from the\n       // corrupt block list.\n       corruptReplicas.removeFromCorruptReplicasMap(block, node,\n           Reason.GENSTAMP_MISMATCH);\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n               + \" received for {} on node {} size {}\", storedBlock, node,\n           storedBlock.getNumBytes());\n     }\n \n     // Now check for completion of blocks and safe block count\n     NumberReplicas num \u003d countNodes(storedBlock);\n     int numLiveReplicas \u003d num.liveReplicas();\n     int numCurrentReplica \u003d numLiveReplicas\n       + pendingReplications.getNumReplicas(storedBlock);\n \n     if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n         hasMinStorage(storedBlock, numLiveReplicas)) {\n-      addExpectedReplicasToPending(storedBlock, bc);\n+      addExpectedReplicasToPending(storedBlock);\n       completeBlock(storedBlock, false);\n     } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n       // check whether safe replication is reached for the block\n       // only complete blocks are counted towards that\n       // Is no-op if not in safe mode.\n       // In the case that the block just became complete above, completeBlock()\n       // handles the safe block count maintenance.\n       bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n     }\n     \n-    // if file is under construction, then done for now\n-    if (bc.isUnderConstruction()) {\n+    // if block is still under construction, then done for now\n+    if (!storedBlock.isCompleteOrCommitted()) {\n       return storedBlock;\n     }\n \n     // do not try to handle over/under-replicated blocks during first safe mode\n     if (!isPopulatingReplQueues()) {\n       return storedBlock;\n     }\n \n     // handle underReplication/overReplication\n     short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n     if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n       neededReplications.remove(storedBlock, numCurrentReplica,\n           num.readOnlyReplicas(),\n           num.decommissionedAndDecommissioning(), fileReplication);\n     } else {\n       updateNeededReplications(storedBlock, curReplicaDelta, 0);\n     }\n     if (numCurrentReplica \u003e fileReplication) {\n       processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n     }\n     // If the file replication has reached desired value\n     // we can remove any corrupt replicas the block may have\n     int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n     int numCorruptNodes \u003d num.corruptReplicas();\n     if (numCorruptNodes !\u003d corruptReplicasCount) {\n       LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n           storedBlock + \". blockMap has \" + numCorruptNodes +\n           \" but corrupt replicas map has \" + corruptReplicasCount);\n     }\n     if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n       invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n     }\n     return storedBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Block addStoredBlock(final BlockInfo block,\n                               final Block reportedBlock,\n                               DatanodeStorageInfo storageInfo,\n                               DatanodeDescriptor delNodeHint,\n                               boolean logEveryBlock)\n  throws IOException {\n    assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n    BlockInfo storedBlock;\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    if (!block.isComplete()) {\n      //refresh our copy in case the block got completed in another thread\n      storedBlock \u003d getStoredBlock(block);\n    } else {\n      storedBlock \u003d block;\n    }\n    if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n      // If this block does not belong to anyfile, then we are done.\n      blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n          \" belong to any file\", block, node, block.getNumBytes());\n\n      // we could add this block to invalidate set of this datanode.\n      // it will happen in next block report otherwise.\n      return block;\n    }\n\n    // add block to the datanode\n    AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n\n    int curReplicaDelta;\n    if (result \u003d\u003d AddBlockResult.ADDED) {\n      curReplicaDelta \u003d 1;\n      if (logEveryBlock) {\n        blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n            node, storedBlock, storedBlock.getNumBytes());\n      }\n    } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n          \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n\n    // Now check for completion of blocks and safe block count\n    NumberReplicas num \u003d countNodes(storedBlock);\n    int numLiveReplicas \u003d num.liveReplicas();\n    int numCurrentReplica \u003d numLiveReplicas\n      + pendingReplications.getNumReplicas(storedBlock);\n\n    if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n        hasMinStorage(storedBlock, numLiveReplicas)) {\n      addExpectedReplicasToPending(storedBlock);\n      completeBlock(storedBlock, false);\n    } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n      // check whether safe replication is reached for the block\n      // only complete blocks are counted towards that\n      // Is no-op if not in safe mode.\n      // In the case that the block just became complete above, completeBlock()\n      // handles the safe block count maintenance.\n      bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n    }\n    \n    // if block is still under construction, then done for now\n    if (!storedBlock.isCompleteOrCommitted()) {\n      return storedBlock;\n    }\n\n    // do not try to handle over/under-replicated blocks during first safe mode\n    if (!isPopulatingReplQueues()) {\n      return storedBlock;\n    }\n\n    // handle underReplication/overReplication\n    short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n    if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n      neededReplications.remove(storedBlock, numCurrentReplica,\n          num.readOnlyReplicas(),\n          num.decommissionedAndDecommissioning(), fileReplication);\n    } else {\n      updateNeededReplications(storedBlock, curReplicaDelta, 0);\n    }\n    if (numCurrentReplica \u003e fileReplication) {\n      processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n    }\n    // If the file replication has reached desired value\n    // we can remove any corrupt replicas the block may have\n    int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n    int numCorruptNodes \u003d num.corruptReplicas();\n    if (numCorruptNodes !\u003d corruptReplicasCount) {\n      LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n          storedBlock + \". blockMap has \" + numCorruptNodes +\n          \" but corrupt replicas map has \" + corruptReplicasCount);\n    }\n    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n      invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n    }\n    return storedBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "bd909ed9f2d853f614f04a50e2230a7932732776": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8999. Allow a file to be closed with COMMITTED but not yet COMPLETE blocks.\n",
      "commitDate": "25/01/16 6:32 PM",
      "commitName": "bd909ed9f2d853f614f04a50e2230a7932732776",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "21/01/16 9:11 PM",
      "commitNameOld": "ae9c61ff0a90b070a5b7b2e7160d726e92c8eacf",
      "commitAuthorOld": "Masatake Iwasaki",
      "daysBetweenCommits": 3.89,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,110 +1,108 @@\n   private Block addStoredBlock(final BlockInfo block,\n                                final Block reportedBlock,\n                                DatanodeStorageInfo storageInfo,\n                                DatanodeDescriptor delNodeHint,\n                                boolean logEveryBlock)\n   throws IOException {\n     assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n     BlockInfo storedBlock;\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     if (!block.isComplete()) {\n       //refresh our copy in case the block got completed in another thread\n       storedBlock \u003d getStoredBlock(block);\n     } else {\n       storedBlock \u003d block;\n     }\n     if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n       // If this block does not belong to anyfile, then we are done.\n       blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n           \" belong to any file\", block, node, block.getNumBytes());\n \n       // we could add this block to invalidate set of this datanode.\n       // it will happen in next block report otherwise.\n       return block;\n     }\n     BlockCollection bc \u003d getBlockCollection(storedBlock);\n     assert bc !\u003d null : \"Block must belong to a file\";\n \n     // add block to the datanode\n     AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n \n     int curReplicaDelta;\n     if (result \u003d\u003d AddBlockResult.ADDED) {\n       curReplicaDelta \u003d 1;\n       if (logEveryBlock) {\n         blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n             node, storedBlock, storedBlock.getNumBytes());\n       }\n     } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n           \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n     } else {\n       // if the same block is added again and the replica was corrupt\n       // previously because of a wrong gen stamp, remove it from the\n       // corrupt block list.\n       corruptReplicas.removeFromCorruptReplicasMap(block, node,\n           Reason.GENSTAMP_MISMATCH);\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n               + \" received for {} on node {} size {}\", storedBlock, node,\n           storedBlock.getNumBytes());\n     }\n \n     // Now check for completion of blocks and safe block count\n     NumberReplicas num \u003d countNodes(storedBlock);\n     int numLiveReplicas \u003d num.liveReplicas();\n     int numCurrentReplica \u003d numLiveReplicas\n       + pendingReplications.getNumReplicas(storedBlock);\n \n     if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n         hasMinStorage(storedBlock, numLiveReplicas)) {\n-      if (!bc.isStriped()) {\n-        addExpectedReplicasToPending(storedBlock);\n-      }\n+      addExpectedReplicasToPending(storedBlock, bc);\n       completeBlock(storedBlock, false);\n     } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n       // check whether safe replication is reached for the block\n       // only complete blocks are counted towards that\n       // Is no-op if not in safe mode.\n       // In the case that the block just became complete above, completeBlock()\n       // handles the safe block count maintenance.\n       bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n     }\n     \n     // if file is under construction, then done for now\n     if (bc.isUnderConstruction()) {\n       return storedBlock;\n     }\n \n     // do not try to handle over/under-replicated blocks during first safe mode\n     if (!isPopulatingReplQueues()) {\n       return storedBlock;\n     }\n \n     // handle underReplication/overReplication\n     short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n     if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n       neededReplications.remove(storedBlock, numCurrentReplica,\n           num.readOnlyReplicas(),\n           num.decommissionedAndDecommissioning(), fileReplication);\n     } else {\n       updateNeededReplications(storedBlock, curReplicaDelta, 0);\n     }\n     if (numCurrentReplica \u003e fileReplication) {\n       processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n     }\n     // If the file replication has reached desired value\n     // we can remove any corrupt replicas the block may have\n     int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n     int numCorruptNodes \u003d num.corruptReplicas();\n     if (numCorruptNodes !\u003d corruptReplicasCount) {\n       LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n           storedBlock + \". blockMap has \" + numCorruptNodes +\n           \" but corrupt replicas map has \" + corruptReplicasCount);\n     }\n     if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n       invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n     }\n     return storedBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Block addStoredBlock(final BlockInfo block,\n                               final Block reportedBlock,\n                               DatanodeStorageInfo storageInfo,\n                               DatanodeDescriptor delNodeHint,\n                               boolean logEveryBlock)\n  throws IOException {\n    assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n    BlockInfo storedBlock;\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    if (!block.isComplete()) {\n      //refresh our copy in case the block got completed in another thread\n      storedBlock \u003d getStoredBlock(block);\n    } else {\n      storedBlock \u003d block;\n    }\n    if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n      // If this block does not belong to anyfile, then we are done.\n      blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n          \" belong to any file\", block, node, block.getNumBytes());\n\n      // we could add this block to invalidate set of this datanode.\n      // it will happen in next block report otherwise.\n      return block;\n    }\n    BlockCollection bc \u003d getBlockCollection(storedBlock);\n    assert bc !\u003d null : \"Block must belong to a file\";\n\n    // add block to the datanode\n    AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n\n    int curReplicaDelta;\n    if (result \u003d\u003d AddBlockResult.ADDED) {\n      curReplicaDelta \u003d 1;\n      if (logEveryBlock) {\n        blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n            node, storedBlock, storedBlock.getNumBytes());\n      }\n    } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n          \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n\n    // Now check for completion of blocks and safe block count\n    NumberReplicas num \u003d countNodes(storedBlock);\n    int numLiveReplicas \u003d num.liveReplicas();\n    int numCurrentReplica \u003d numLiveReplicas\n      + pendingReplications.getNumReplicas(storedBlock);\n\n    if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n        hasMinStorage(storedBlock, numLiveReplicas)) {\n      addExpectedReplicasToPending(storedBlock, bc);\n      completeBlock(storedBlock, false);\n    } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n      // check whether safe replication is reached for the block\n      // only complete blocks are counted towards that\n      // Is no-op if not in safe mode.\n      // In the case that the block just became complete above, completeBlock()\n      // handles the safe block count maintenance.\n      bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n    }\n    \n    // if file is under construction, then done for now\n    if (bc.isUnderConstruction()) {\n      return storedBlock;\n    }\n\n    // do not try to handle over/under-replicated blocks during first safe mode\n    if (!isPopulatingReplQueues()) {\n      return storedBlock;\n    }\n\n    // handle underReplication/overReplication\n    short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n    if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n      neededReplications.remove(storedBlock, numCurrentReplica,\n          num.readOnlyReplicas(),\n          num.decommissionedAndDecommissioning(), fileReplication);\n    } else {\n      updateNeededReplications(storedBlock, curReplicaDelta, 0);\n    }\n    if (numCurrentReplica \u003e fileReplication) {\n      processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n    }\n    // If the file replication has reached desired value\n    // we can remove any corrupt replicas the block may have\n    int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n    int numCorruptNodes \u003d num.corruptReplicas();\n    if (numCorruptNodes !\u003d corruptReplicasCount) {\n      LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n          storedBlock + \". blockMap has \" + numCorruptNodes +\n          \" but corrupt replicas map has \" + corruptReplicasCount);\n    }\n    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n      invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n    }\n    return storedBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "e53456981474d6e16e3c134e3777b3588dc6fedf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9535. Newly completed blocks in IBR should not be considered under-replicated too quickly. Contributed by Mingliang Liu.\n",
      "commitDate": "14/12/15 11:05 AM",
      "commitName": "e53456981474d6e16e3c134e3777b3588dc6fedf",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "11/12/15 5:57 PM",
      "commitNameOld": "796a676d18bd7cd3ed4113d002e0e69cf261d6d1",
      "commitAuthorOld": "Uma Mahesh",
      "daysBetweenCommits": 2.71,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,107 +1,110 @@\n   private Block addStoredBlock(final BlockInfo block,\n                                final Block reportedBlock,\n                                DatanodeStorageInfo storageInfo,\n                                DatanodeDescriptor delNodeHint,\n                                boolean logEveryBlock)\n   throws IOException {\n     assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n     BlockInfo storedBlock;\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     if (!block.isComplete()) {\n       //refresh our copy in case the block got completed in another thread\n       storedBlock \u003d getStoredBlock(block);\n     } else {\n       storedBlock \u003d block;\n     }\n     if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n       // If this block does not belong to anyfile, then we are done.\n       blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n           \" belong to any file\", block, node, block.getNumBytes());\n \n       // we could add this block to invalidate set of this datanode.\n       // it will happen in next block report otherwise.\n       return block;\n     }\n     BlockCollection bc \u003d getBlockCollection(storedBlock);\n     assert bc !\u003d null : \"Block must belong to a file\";\n \n     // add block to the datanode\n     AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n \n     int curReplicaDelta;\n     if (result \u003d\u003d AddBlockResult.ADDED) {\n       curReplicaDelta \u003d 1;\n       if (logEveryBlock) {\n         blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n             node, storedBlock, storedBlock.getNumBytes());\n       }\n     } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n           \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n     } else {\n       // if the same block is added again and the replica was corrupt\n       // previously because of a wrong gen stamp, remove it from the\n       // corrupt block list.\n       corruptReplicas.removeFromCorruptReplicasMap(block, node,\n           Reason.GENSTAMP_MISMATCH);\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n               + \" received for {} on node {} size {}\", storedBlock, node,\n           storedBlock.getNumBytes());\n     }\n \n     // Now check for completion of blocks and safe block count\n     NumberReplicas num \u003d countNodes(storedBlock);\n     int numLiveReplicas \u003d num.liveReplicas();\n     int numCurrentReplica \u003d numLiveReplicas\n       + pendingReplications.getNumReplicas(storedBlock);\n \n     if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n         hasMinStorage(storedBlock, numLiveReplicas)) {\n+      if (!bc.isStriped()) {\n+        addExpectedReplicasToPending(storedBlock);\n+      }\n       completeBlock(storedBlock, false);\n     } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n       // check whether safe replication is reached for the block\n       // only complete blocks are counted towards that\n       // Is no-op if not in safe mode.\n       // In the case that the block just became complete above, completeBlock()\n       // handles the safe block count maintenance.\n       bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n     }\n     \n     // if file is under construction, then done for now\n     if (bc.isUnderConstruction()) {\n       return storedBlock;\n     }\n \n     // do not try to handle over/under-replicated blocks during first safe mode\n     if (!isPopulatingReplQueues()) {\n       return storedBlock;\n     }\n \n     // handle underReplication/overReplication\n     short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n     if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n       neededReplications.remove(storedBlock, numCurrentReplica,\n           num.readOnlyReplicas(),\n           num.decommissionedAndDecommissioning(), fileReplication);\n     } else {\n       updateNeededReplications(storedBlock, curReplicaDelta, 0);\n     }\n     if (numCurrentReplica \u003e fileReplication) {\n       processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n     }\n     // If the file replication has reached desired value\n     // we can remove any corrupt replicas the block may have\n     int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n     int numCorruptNodes \u003d num.corruptReplicas();\n     if (numCorruptNodes !\u003d corruptReplicasCount) {\n       LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n           storedBlock + \". blockMap has \" + numCorruptNodes +\n           \" but corrupt replicas map has \" + corruptReplicasCount);\n     }\n     if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n       invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n     }\n     return storedBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Block addStoredBlock(final BlockInfo block,\n                               final Block reportedBlock,\n                               DatanodeStorageInfo storageInfo,\n                               DatanodeDescriptor delNodeHint,\n                               boolean logEveryBlock)\n  throws IOException {\n    assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n    BlockInfo storedBlock;\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    if (!block.isComplete()) {\n      //refresh our copy in case the block got completed in another thread\n      storedBlock \u003d getStoredBlock(block);\n    } else {\n      storedBlock \u003d block;\n    }\n    if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n      // If this block does not belong to anyfile, then we are done.\n      blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n          \" belong to any file\", block, node, block.getNumBytes());\n\n      // we could add this block to invalidate set of this datanode.\n      // it will happen in next block report otherwise.\n      return block;\n    }\n    BlockCollection bc \u003d getBlockCollection(storedBlock);\n    assert bc !\u003d null : \"Block must belong to a file\";\n\n    // add block to the datanode\n    AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n\n    int curReplicaDelta;\n    if (result \u003d\u003d AddBlockResult.ADDED) {\n      curReplicaDelta \u003d 1;\n      if (logEveryBlock) {\n        blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n            node, storedBlock, storedBlock.getNumBytes());\n      }\n    } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n          \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n\n    // Now check for completion of blocks and safe block count\n    NumberReplicas num \u003d countNodes(storedBlock);\n    int numLiveReplicas \u003d num.liveReplicas();\n    int numCurrentReplica \u003d numLiveReplicas\n      + pendingReplications.getNumReplicas(storedBlock);\n\n    if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n        hasMinStorage(storedBlock, numLiveReplicas)) {\n      if (!bc.isStriped()) {\n        addExpectedReplicasToPending(storedBlock);\n      }\n      completeBlock(storedBlock, false);\n    } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n      // check whether safe replication is reached for the block\n      // only complete blocks are counted towards that\n      // Is no-op if not in safe mode.\n      // In the case that the block just became complete above, completeBlock()\n      // handles the safe block count maintenance.\n      bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n    }\n    \n    // if file is under construction, then done for now\n    if (bc.isUnderConstruction()) {\n      return storedBlock;\n    }\n\n    // do not try to handle over/under-replicated blocks during first safe mode\n    if (!isPopulatingReplQueues()) {\n      return storedBlock;\n    }\n\n    // handle underReplication/overReplication\n    short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n    if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n      neededReplications.remove(storedBlock, numCurrentReplica,\n          num.readOnlyReplicas(),\n          num.decommissionedAndDecommissioning(), fileReplication);\n    } else {\n      updateNeededReplications(storedBlock, curReplicaDelta, 0);\n    }\n    if (numCurrentReplica \u003e fileReplication) {\n      processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n    }\n    // If the file replication has reached desired value\n    // we can remove any corrupt replicas the block may have\n    int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n    int numCorruptNodes \u003d num.corruptReplicas();\n    if (numCorruptNodes !\u003d corruptReplicasCount) {\n      LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n          storedBlock + \". blockMap has \" + numCorruptNodes +\n          \" but corrupt replicas map has \" + corruptReplicasCount);\n    }\n    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n      invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n    }\n    return storedBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "796a676d18bd7cd3ed4113d002e0e69cf261d6d1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9528. Cleanup namenode audit/log/exception messages. (szetszwo via umamahesh)\n",
      "commitDate": "11/12/15 5:57 PM",
      "commitName": "796a676d18bd7cd3ed4113d002e0e69cf261d6d1",
      "commitAuthor": "Uma Mahesh",
      "commitDateOld": "09/12/15 5:55 PM",
      "commitNameOld": "132478e805ba0f955345217b8ad87c2d17cccb2d",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 2.0,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,107 @@\n   private Block addStoredBlock(final BlockInfo block,\n                                final Block reportedBlock,\n                                DatanodeStorageInfo storageInfo,\n                                DatanodeDescriptor delNodeHint,\n                                boolean logEveryBlock)\n   throws IOException {\n     assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n     BlockInfo storedBlock;\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     if (!block.isComplete()) {\n       //refresh our copy in case the block got completed in another thread\n       storedBlock \u003d getStoredBlock(block);\n     } else {\n       storedBlock \u003d block;\n     }\n     if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n       // If this block does not belong to anyfile, then we are done.\n       blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n           \" belong to any file\", block, node, block.getNumBytes());\n \n       // we could add this block to invalidate set of this datanode.\n       // it will happen in next block report otherwise.\n       return block;\n     }\n     BlockCollection bc \u003d getBlockCollection(storedBlock);\n     assert bc !\u003d null : \"Block must belong to a file\";\n \n     // add block to the datanode\n     AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n \n     int curReplicaDelta;\n     if (result \u003d\u003d AddBlockResult.ADDED) {\n       curReplicaDelta \u003d 1;\n       if (logEveryBlock) {\n-        logAddStoredBlock(storedBlock, node);\n+        blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n+            node, storedBlock, storedBlock.getNumBytes());\n       }\n     } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n           \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n     } else {\n       // if the same block is added again and the replica was corrupt\n       // previously because of a wrong gen stamp, remove it from the\n       // corrupt block list.\n       corruptReplicas.removeFromCorruptReplicasMap(block, node,\n           Reason.GENSTAMP_MISMATCH);\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n               + \" received for {} on node {} size {}\", storedBlock, node,\n           storedBlock.getNumBytes());\n     }\n \n     // Now check for completion of blocks and safe block count\n     NumberReplicas num \u003d countNodes(storedBlock);\n     int numLiveReplicas \u003d num.liveReplicas();\n     int numCurrentReplica \u003d numLiveReplicas\n       + pendingReplications.getNumReplicas(storedBlock);\n \n     if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n         hasMinStorage(storedBlock, numLiveReplicas)) {\n       completeBlock(storedBlock, false);\n     } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n       // check whether safe replication is reached for the block\n       // only complete blocks are counted towards that\n       // Is no-op if not in safe mode.\n       // In the case that the block just became complete above, completeBlock()\n       // handles the safe block count maintenance.\n       bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n     }\n     \n     // if file is under construction, then done for now\n     if (bc.isUnderConstruction()) {\n       return storedBlock;\n     }\n \n     // do not try to handle over/under-replicated blocks during first safe mode\n     if (!isPopulatingReplQueues()) {\n       return storedBlock;\n     }\n \n     // handle underReplication/overReplication\n     short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n     if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n       neededReplications.remove(storedBlock, numCurrentReplica,\n           num.readOnlyReplicas(),\n           num.decommissionedAndDecommissioning(), fileReplication);\n     } else {\n       updateNeededReplications(storedBlock, curReplicaDelta, 0);\n     }\n     if (numCurrentReplica \u003e fileReplication) {\n       processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n     }\n     // If the file replication has reached desired value\n     // we can remove any corrupt replicas the block may have\n     int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n     int numCorruptNodes \u003d num.corruptReplicas();\n     if (numCorruptNodes !\u003d corruptReplicasCount) {\n       LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n           storedBlock + \". blockMap has \" + numCorruptNodes +\n           \" but corrupt replicas map has \" + corruptReplicasCount);\n     }\n     if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n       invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n     }\n     return storedBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Block addStoredBlock(final BlockInfo block,\n                               final Block reportedBlock,\n                               DatanodeStorageInfo storageInfo,\n                               DatanodeDescriptor delNodeHint,\n                               boolean logEveryBlock)\n  throws IOException {\n    assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n    BlockInfo storedBlock;\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    if (!block.isComplete()) {\n      //refresh our copy in case the block got completed in another thread\n      storedBlock \u003d getStoredBlock(block);\n    } else {\n      storedBlock \u003d block;\n    }\n    if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n      // If this block does not belong to anyfile, then we are done.\n      blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n          \" belong to any file\", block, node, block.getNumBytes());\n\n      // we could add this block to invalidate set of this datanode.\n      // it will happen in next block report otherwise.\n      return block;\n    }\n    BlockCollection bc \u003d getBlockCollection(storedBlock);\n    assert bc !\u003d null : \"Block must belong to a file\";\n\n    // add block to the datanode\n    AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n\n    int curReplicaDelta;\n    if (result \u003d\u003d AddBlockResult.ADDED) {\n      curReplicaDelta \u003d 1;\n      if (logEveryBlock) {\n        blockLog.debug(\"BLOCK* addStoredBlock: {} is added to {} (size\u003d{})\",\n            node, storedBlock, storedBlock.getNumBytes());\n      }\n    } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n          \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n\n    // Now check for completion of blocks and safe block count\n    NumberReplicas num \u003d countNodes(storedBlock);\n    int numLiveReplicas \u003d num.liveReplicas();\n    int numCurrentReplica \u003d numLiveReplicas\n      + pendingReplications.getNumReplicas(storedBlock);\n\n    if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n        hasMinStorage(storedBlock, numLiveReplicas)) {\n      completeBlock(storedBlock, false);\n    } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n      // check whether safe replication is reached for the block\n      // only complete blocks are counted towards that\n      // Is no-op if not in safe mode.\n      // In the case that the block just became complete above, completeBlock()\n      // handles the safe block count maintenance.\n      bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n    }\n    \n    // if file is under construction, then done for now\n    if (bc.isUnderConstruction()) {\n      return storedBlock;\n    }\n\n    // do not try to handle over/under-replicated blocks during first safe mode\n    if (!isPopulatingReplQueues()) {\n      return storedBlock;\n    }\n\n    // handle underReplication/overReplication\n    short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n    if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n      neededReplications.remove(storedBlock, numCurrentReplica,\n          num.readOnlyReplicas(),\n          num.decommissionedAndDecommissioning(), fileReplication);\n    } else {\n      updateNeededReplications(storedBlock, curReplicaDelta, 0);\n    }\n    if (numCurrentReplica \u003e fileReplication) {\n      processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n    }\n    // If the file replication has reached desired value\n    // we can remove any corrupt replicas the block may have\n    int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n    int numCorruptNodes \u003d num.corruptReplicas();\n    if (numCorruptNodes !\u003d corruptReplicasCount) {\n      LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n          storedBlock + \". blockMap has \" + numCorruptNodes +\n          \" but corrupt replicas map has \" + corruptReplicasCount);\n    }\n    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n      invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n    }\n    return storedBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "a49cc74b4c72195dee1dfb6f9548e5e411dff553": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9129. Move the safemode block count into BlockManager. Contributed by Mingliang Liu.\n",
      "commitDate": "01/12/15 4:09 PM",
      "commitName": "a49cc74b4c72195dee1dfb6f9548e5e411dff553",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "01/12/15 1:05 PM",
      "commitNameOld": "830eb252aaa4fec7ef2ec38cb66f669e8e1ecaa5",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.13,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,106 @@\n   private Block addStoredBlock(final BlockInfo block,\n                                final Block reportedBlock,\n                                DatanodeStorageInfo storageInfo,\n                                DatanodeDescriptor delNodeHint,\n                                boolean logEveryBlock)\n   throws IOException {\n     assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n     BlockInfo storedBlock;\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     if (!block.isComplete()) {\n       //refresh our copy in case the block got completed in another thread\n       storedBlock \u003d getStoredBlock(block);\n     } else {\n       storedBlock \u003d block;\n     }\n     if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n       // If this block does not belong to anyfile, then we are done.\n       blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n           \" belong to any file\", block, node, block.getNumBytes());\n \n       // we could add this block to invalidate set of this datanode.\n       // it will happen in next block report otherwise.\n       return block;\n     }\n     BlockCollection bc \u003d getBlockCollection(storedBlock);\n     assert bc !\u003d null : \"Block must belong to a file\";\n \n     // add block to the datanode\n     AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n \n     int curReplicaDelta;\n     if (result \u003d\u003d AddBlockResult.ADDED) {\n       curReplicaDelta \u003d 1;\n       if (logEveryBlock) {\n         logAddStoredBlock(storedBlock, node);\n       }\n     } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n           \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n     } else {\n       // if the same block is added again and the replica was corrupt\n       // previously because of a wrong gen stamp, remove it from the\n       // corrupt block list.\n       corruptReplicas.removeFromCorruptReplicasMap(block, node,\n           Reason.GENSTAMP_MISMATCH);\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n               + \" received for {} on node {} size {}\", storedBlock, node,\n           storedBlock.getNumBytes());\n     }\n \n     // Now check for completion of blocks and safe block count\n     NumberReplicas num \u003d countNodes(storedBlock);\n     int numLiveReplicas \u003d num.liveReplicas();\n     int numCurrentReplica \u003d numLiveReplicas\n       + pendingReplications.getNumReplicas(storedBlock);\n \n     if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n         hasMinStorage(storedBlock, numLiveReplicas)) {\n       completeBlock(storedBlock, false);\n     } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n       // check whether safe replication is reached for the block\n       // only complete blocks are counted towards that\n       // Is no-op if not in safe mode.\n       // In the case that the block just became complete above, completeBlock()\n       // handles the safe block count maintenance.\n-      namesystem.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n+      bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n     }\n     \n     // if file is under construction, then done for now\n     if (bc.isUnderConstruction()) {\n       return storedBlock;\n     }\n \n     // do not try to handle over/under-replicated blocks during first safe mode\n     if (!isPopulatingReplQueues()) {\n       return storedBlock;\n     }\n \n     // handle underReplication/overReplication\n     short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n     if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n       neededReplications.remove(storedBlock, numCurrentReplica,\n           num.readOnlyReplicas(),\n           num.decommissionedAndDecommissioning(), fileReplication);\n     } else {\n       updateNeededReplications(storedBlock, curReplicaDelta, 0);\n     }\n     if (numCurrentReplica \u003e fileReplication) {\n       processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n     }\n     // If the file replication has reached desired value\n     // we can remove any corrupt replicas the block may have\n     int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n     int numCorruptNodes \u003d num.corruptReplicas();\n     if (numCorruptNodes !\u003d corruptReplicasCount) {\n       LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n           storedBlock + \". blockMap has \" + numCorruptNodes +\n           \" but corrupt replicas map has \" + corruptReplicasCount);\n     }\n     if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n       invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n     }\n     return storedBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Block addStoredBlock(final BlockInfo block,\n                               final Block reportedBlock,\n                               DatanodeStorageInfo storageInfo,\n                               DatanodeDescriptor delNodeHint,\n                               boolean logEveryBlock)\n  throws IOException {\n    assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n    BlockInfo storedBlock;\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    if (!block.isComplete()) {\n      //refresh our copy in case the block got completed in another thread\n      storedBlock \u003d getStoredBlock(block);\n    } else {\n      storedBlock \u003d block;\n    }\n    if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n      // If this block does not belong to anyfile, then we are done.\n      blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n          \" belong to any file\", block, node, block.getNumBytes());\n\n      // we could add this block to invalidate set of this datanode.\n      // it will happen in next block report otherwise.\n      return block;\n    }\n    BlockCollection bc \u003d getBlockCollection(storedBlock);\n    assert bc !\u003d null : \"Block must belong to a file\";\n\n    // add block to the datanode\n    AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n\n    int curReplicaDelta;\n    if (result \u003d\u003d AddBlockResult.ADDED) {\n      curReplicaDelta \u003d 1;\n      if (logEveryBlock) {\n        logAddStoredBlock(storedBlock, node);\n      }\n    } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n          \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n\n    // Now check for completion of blocks and safe block count\n    NumberReplicas num \u003d countNodes(storedBlock);\n    int numLiveReplicas \u003d num.liveReplicas();\n    int numCurrentReplica \u003d numLiveReplicas\n      + pendingReplications.getNumReplicas(storedBlock);\n\n    if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n        hasMinStorage(storedBlock, numLiveReplicas)) {\n      completeBlock(storedBlock, false);\n    } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n      // check whether safe replication is reached for the block\n      // only complete blocks are counted towards that\n      // Is no-op if not in safe mode.\n      // In the case that the block just became complete above, completeBlock()\n      // handles the safe block count maintenance.\n      bmSafeMode.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n    }\n    \n    // if file is under construction, then done for now\n    if (bc.isUnderConstruction()) {\n      return storedBlock;\n    }\n\n    // do not try to handle over/under-replicated blocks during first safe mode\n    if (!isPopulatingReplQueues()) {\n      return storedBlock;\n    }\n\n    // handle underReplication/overReplication\n    short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n    if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n      neededReplications.remove(storedBlock, numCurrentReplica,\n          num.readOnlyReplicas(),\n          num.decommissionedAndDecommissioning(), fileReplication);\n    } else {\n      updateNeededReplications(storedBlock, curReplicaDelta, 0);\n    }\n    if (numCurrentReplica \u003e fileReplication) {\n      processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n    }\n    // If the file replication has reached desired value\n    // we can remove any corrupt replicas the block may have\n    int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n    int numCorruptNodes \u003d num.corruptReplicas();\n    if (numCorruptNodes !\u003d corruptReplicasCount) {\n      LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n          storedBlock + \". blockMap has \" + numCorruptNodes +\n          \" but corrupt replicas map has \" + corruptReplicasCount);\n    }\n    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n      invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n    }\n    return storedBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "5411dc559d5f73e4153e76fdff94a26869c17a37": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9205. Do not schedule corrupt blocks for replication.  (szetszwo)\n",
      "commitDate": "15/10/15 3:07 AM",
      "commitName": "5411dc559d5f73e4153e76fdff94a26869c17a37",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "14/10/15 4:17 PM",
      "commitNameOld": "be7a0add8b6561d3c566237cc0370b06e7f32bb4",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.45,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,105 +1,106 @@\n   private Block addStoredBlock(final BlockInfo block,\n                                final Block reportedBlock,\n                                DatanodeStorageInfo storageInfo,\n                                DatanodeDescriptor delNodeHint,\n                                boolean logEveryBlock)\n   throws IOException {\n     assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n     BlockInfo storedBlock;\n     DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n     if (!block.isComplete()) {\n       //refresh our copy in case the block got completed in another thread\n       storedBlock \u003d getStoredBlock(block);\n     } else {\n       storedBlock \u003d block;\n     }\n     if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n       // If this block does not belong to anyfile, then we are done.\n       blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n           \" belong to any file\", block, node, block.getNumBytes());\n \n       // we could add this block to invalidate set of this datanode.\n       // it will happen in next block report otherwise.\n       return block;\n     }\n     BlockCollection bc \u003d getBlockCollection(storedBlock);\n     assert bc !\u003d null : \"Block must belong to a file\";\n \n     // add block to the datanode\n     AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n \n     int curReplicaDelta;\n     if (result \u003d\u003d AddBlockResult.ADDED) {\n       curReplicaDelta \u003d 1;\n       if (logEveryBlock) {\n         logAddStoredBlock(storedBlock, node);\n       }\n     } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n           \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n     } else {\n       // if the same block is added again and the replica was corrupt\n       // previously because of a wrong gen stamp, remove it from the\n       // corrupt block list.\n       corruptReplicas.removeFromCorruptReplicasMap(block, node,\n           Reason.GENSTAMP_MISMATCH);\n       curReplicaDelta \u003d 0;\n       blockLog.warn(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n               + \" received for {} on node {} size {}\", storedBlock, node,\n           storedBlock.getNumBytes());\n     }\n \n     // Now check for completion of blocks and safe block count\n     NumberReplicas num \u003d countNodes(storedBlock);\n     int numLiveReplicas \u003d num.liveReplicas();\n     int numCurrentReplica \u003d numLiveReplicas\n       + pendingReplications.getNumReplicas(storedBlock);\n \n     if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n         hasMinStorage(storedBlock, numLiveReplicas)) {\n       completeBlock(storedBlock, false);\n     } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n       // check whether safe replication is reached for the block\n       // only complete blocks are counted towards that\n       // Is no-op if not in safe mode.\n       // In the case that the block just became complete above, completeBlock()\n       // handles the safe block count maintenance.\n       namesystem.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n     }\n     \n     // if file is under construction, then done for now\n     if (bc.isUnderConstruction()) {\n       return storedBlock;\n     }\n \n     // do not try to handle over/under-replicated blocks during first safe mode\n     if (!isPopulatingReplQueues()) {\n       return storedBlock;\n     }\n \n     // handle underReplication/overReplication\n     short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n     if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n       neededReplications.remove(storedBlock, numCurrentReplica,\n+          num.readOnlyReplicas(),\n           num.decommissionedAndDecommissioning(), fileReplication);\n     } else {\n       updateNeededReplications(storedBlock, curReplicaDelta, 0);\n     }\n     if (numCurrentReplica \u003e fileReplication) {\n       processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n     }\n     // If the file replication has reached desired value\n     // we can remove any corrupt replicas the block may have\n     int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n     int numCorruptNodes \u003d num.corruptReplicas();\n     if (numCorruptNodes !\u003d corruptReplicasCount) {\n       LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n           storedBlock + \". blockMap has \" + numCorruptNodes +\n           \" but corrupt replicas map has \" + corruptReplicasCount);\n     }\n     if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n       invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n     }\n     return storedBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Block addStoredBlock(final BlockInfo block,\n                               final Block reportedBlock,\n                               DatanodeStorageInfo storageInfo,\n                               DatanodeDescriptor delNodeHint,\n                               boolean logEveryBlock)\n  throws IOException {\n    assert block !\u003d null \u0026\u0026 namesystem.hasWriteLock();\n    BlockInfo storedBlock;\n    DatanodeDescriptor node \u003d storageInfo.getDatanodeDescriptor();\n    if (!block.isComplete()) {\n      //refresh our copy in case the block got completed in another thread\n      storedBlock \u003d getStoredBlock(block);\n    } else {\n      storedBlock \u003d block;\n    }\n    if (storedBlock \u003d\u003d null || storedBlock.isDeleted()) {\n      // If this block does not belong to anyfile, then we are done.\n      blockLog.debug(\"BLOCK* addStoredBlock: {} on {} size {} but it does not\" +\n          \" belong to any file\", block, node, block.getNumBytes());\n\n      // we could add this block to invalidate set of this datanode.\n      // it will happen in next block report otherwise.\n      return block;\n    }\n    BlockCollection bc \u003d getBlockCollection(storedBlock);\n    assert bc !\u003d null : \"Block must belong to a file\";\n\n    // add block to the datanode\n    AddBlockResult result \u003d storageInfo.addBlock(storedBlock, reportedBlock);\n\n    int curReplicaDelta;\n    if (result \u003d\u003d AddBlockResult.ADDED) {\n      curReplicaDelta \u003d 1;\n      if (logEveryBlock) {\n        logAddStoredBlock(storedBlock, node);\n      }\n    } else if (result \u003d\u003d AddBlockResult.REPLACED) {\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: block {} moved to storageType \" +\n          \"{} on node {}\", storedBlock, storageInfo.getStorageType(), node);\n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta \u003d 0;\n      blockLog.warn(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n\n    // Now check for completion of blocks and safe block count\n    NumberReplicas num \u003d countNodes(storedBlock);\n    int numLiveReplicas \u003d num.liveReplicas();\n    int numCurrentReplica \u003d numLiveReplicas\n      + pendingReplications.getNumReplicas(storedBlock);\n\n    if(storedBlock.getBlockUCState() \u003d\u003d BlockUCState.COMMITTED \u0026\u0026\n        hasMinStorage(storedBlock, numLiveReplicas)) {\n      completeBlock(storedBlock, false);\n    } else if (storedBlock.isComplete() \u0026\u0026 result \u003d\u003d AddBlockResult.ADDED) {\n      // check whether safe replication is reached for the block\n      // only complete blocks are counted towards that\n      // Is no-op if not in safe mode.\n      // In the case that the block just became complete above, completeBlock()\n      // handles the safe block count maintenance.\n      namesystem.incrementSafeBlockCount(numCurrentReplica, storedBlock);\n    }\n    \n    // if file is under construction, then done for now\n    if (bc.isUnderConstruction()) {\n      return storedBlock;\n    }\n\n    // do not try to handle over/under-replicated blocks during first safe mode\n    if (!isPopulatingReplQueues()) {\n      return storedBlock;\n    }\n\n    // handle underReplication/overReplication\n    short fileReplication \u003d getExpectedReplicaNum(storedBlock);\n    if (!isNeededReplication(storedBlock, numCurrentReplica)) {\n      neededReplications.remove(storedBlock, numCurrentReplica,\n          num.readOnlyReplicas(),\n          num.decommissionedAndDecommissioning(), fileReplication);\n    } else {\n      updateNeededReplications(storedBlock, curReplicaDelta, 0);\n    }\n    if (numCurrentReplica \u003e fileReplication) {\n      processOverReplicatedBlock(storedBlock, fileReplication, node, delNodeHint);\n    }\n    // If the file replication has reached desired value\n    // we can remove any corrupt replicas the block may have\n    int corruptReplicasCount \u003d corruptReplicas.numCorruptReplicas(storedBlock);\n    int numCorruptNodes \u003d num.corruptReplicas();\n    if (numCorruptNodes !\u003d corruptReplicasCount) {\n      LOG.warn(\"Inconsistent number of corrupt replicas for \" +\n          storedBlock + \". blockMap has \" + numCorruptNodes +\n          \" but corrupt replicas map has \" + corruptReplicasCount);\n    }\n    if ((corruptReplicasCount \u003e 0) \u0026\u0026 (numLiveReplicas \u003e\u003d fileReplication)) {\n      invalidateCorruptReplicas(storedBlock, reportedBlock, num);\n    }\n    return storedBlock;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    }
  }
}