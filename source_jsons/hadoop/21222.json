{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JobUnsuccessfulCompletionEvent.java",
  "functionName": "toTimelineEvent",
  "functionId": "toTimelineEvent",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobUnsuccessfulCompletionEvent.java",
  "functionStartLine": 161,
  "functionEndLine": 179,
  "numCommitsSeen": 9,
  "timeTaken": 2263,
  "changeHistory": [
    "d04f85f387e4a78816bc9966ee2b4a647ee05faf",
    "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5"
  ],
  "changeHistoryShort": {
    "d04f85f387e4a78816bc9966ee2b4a647ee05faf": "Ybodychange",
    "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d04f85f387e4a78816bc9966ee2b4a647ee05faf": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6892. Issues with the count of failed/killed tasks in the jhist file. (Peter Bacsko via Haibo Chen)\n",
      "commitDate": "30/08/17 10:07 AM",
      "commitName": "d04f85f387e4a78816bc9966ee2b4a647ee05faf",
      "commitAuthor": "Haibo Chen",
      "commitDateOld": "10/07/16 8:46 AM",
      "commitNameOld": "1ff6833bbacf5c4eeaff5e70553ac083a691bb21",
      "commitAuthorOld": "Varun Saxena",
      "daysBetweenCommits": 416.06,
      "commitsBetweenForRepo": 2599,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,19 @@\n   public TimelineEvent toTimelineEvent() {\n     TimelineEvent tEvent \u003d new TimelineEvent();\n     tEvent.setId(StringUtils.toUpperCase(getEventType().name()));\n     tEvent.addInfo(\"FINISH_TIME\", getFinishTime());\n-    tEvent.addInfo(\"NUM_MAPS\", getFinishedMaps());\n-    tEvent.addInfo(\"NUM_REDUCES\", getFinishedReduces());\n+    tEvent.addInfo(\"NUM_MAPS\", getSucceededMaps() + getFailedMaps()\n+        + getKilledMaps());\n+    tEvent.addInfo(\"NUM_REDUCES\", getSucceededReduces() + getFailedReduces()\n+        + getKilledReduces());\n     tEvent.addInfo(\"JOB_STATUS\", getStatus());\n     tEvent.addInfo(\"DIAGNOSTICS\", getDiagnostics());\n-    tEvent.addInfo(\"FINISHED_MAPS\", getFinishedMaps());\n-    tEvent.addInfo(\"FINISHED_REDUCES\", getFinishedReduces());\n+    tEvent.addInfo(\"SUCCESSFUL_MAPS\", getSucceededMaps());\n+    tEvent.addInfo(\"SUCCESSFUL_REDUCES\", getSucceededReduces());\n+    tEvent.addInfo(\"FAILED_MAPS\", getFailedMaps());\n+    tEvent.addInfo(\"FAILED_REDUCES\", getFailedReduces());\n+    tEvent.addInfo(\"KILLED_MAPS\", getKilledMaps());\n+    tEvent.addInfo(\"KILLED_REDUCES\", getKilledReduces());\n+\n     return tEvent;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public TimelineEvent toTimelineEvent() {\n    TimelineEvent tEvent \u003d new TimelineEvent();\n    tEvent.setId(StringUtils.toUpperCase(getEventType().name()));\n    tEvent.addInfo(\"FINISH_TIME\", getFinishTime());\n    tEvent.addInfo(\"NUM_MAPS\", getSucceededMaps() + getFailedMaps()\n        + getKilledMaps());\n    tEvent.addInfo(\"NUM_REDUCES\", getSucceededReduces() + getFailedReduces()\n        + getKilledReduces());\n    tEvent.addInfo(\"JOB_STATUS\", getStatus());\n    tEvent.addInfo(\"DIAGNOSTICS\", getDiagnostics());\n    tEvent.addInfo(\"SUCCESSFUL_MAPS\", getSucceededMaps());\n    tEvent.addInfo(\"SUCCESSFUL_REDUCES\", getSucceededReduces());\n    tEvent.addInfo(\"FAILED_MAPS\", getFailedMaps());\n    tEvent.addInfo(\"FAILED_REDUCES\", getFailedReduces());\n    tEvent.addInfo(\"KILLED_MAPS\", getKilledMaps());\n    tEvent.addInfo(\"KILLED_REDUCES\", getKilledReduces());\n\n    return tEvent;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobUnsuccessfulCompletionEvent.java",
      "extendedDetails": {}
    },
    "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-6327. Made MR AM use timeline service v2 API to write history events and counters. Contributed by Junping Du.\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5",
      "commitAuthor": "Zhijie Shen",
      "diff": "@@ -0,0 +1,12 @@\n+  public TimelineEvent toTimelineEvent() {\n+    TimelineEvent tEvent \u003d new TimelineEvent();\n+    tEvent.setId(StringUtils.toUpperCase(getEventType().name()));\n+    tEvent.addInfo(\"FINISH_TIME\", getFinishTime());\n+    tEvent.addInfo(\"NUM_MAPS\", getFinishedMaps());\n+    tEvent.addInfo(\"NUM_REDUCES\", getFinishedReduces());\n+    tEvent.addInfo(\"JOB_STATUS\", getStatus());\n+    tEvent.addInfo(\"DIAGNOSTICS\", getDiagnostics());\n+    tEvent.addInfo(\"FINISHED_MAPS\", getFinishedMaps());\n+    tEvent.addInfo(\"FINISHED_REDUCES\", getFinishedReduces());\n+    return tEvent;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public TimelineEvent toTimelineEvent() {\n    TimelineEvent tEvent \u003d new TimelineEvent();\n    tEvent.setId(StringUtils.toUpperCase(getEventType().name()));\n    tEvent.addInfo(\"FINISH_TIME\", getFinishTime());\n    tEvent.addInfo(\"NUM_MAPS\", getFinishedMaps());\n    tEvent.addInfo(\"NUM_REDUCES\", getFinishedReduces());\n    tEvent.addInfo(\"JOB_STATUS\", getStatus());\n    tEvent.addInfo(\"DIAGNOSTICS\", getDiagnostics());\n    tEvent.addInfo(\"FINISHED_MAPS\", getFinishedMaps());\n    tEvent.addInfo(\"FINISHED_REDUCES\", getFinishedReduces());\n    return tEvent;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobUnsuccessfulCompletionEvent.java"
    }
  }
}