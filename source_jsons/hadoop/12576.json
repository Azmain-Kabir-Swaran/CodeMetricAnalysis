{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NameNodeConnector.java",
  "functionName": "newNameNodeConnectors",
  "functionId": "newNameNodeConnectors___namenodes-Collection__URI____nsIds-Collection__String____name-String__idPath-Path__conf-Configuration__maxIdleIterations-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/NameNodeConnector.java",
  "functionStartLine": 109,
  "functionEndLine": 133,
  "numCommitsSeen": 43,
  "timeTaken": 1252,
  "changeHistory": [
    "a3f44dacc1fa19acc4eefd1e2505e54f8629e603"
  ],
  "changeHistoryShort": {
    "a3f44dacc1fa19acc4eefd1e2505e54f8629e603": "Yintroduced"
  },
  "changeHistoryDetails": {
    "a3f44dacc1fa19acc4eefd1e2505e54f8629e603": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13183. Standby NameNode process getBlocks request to reduce Active load. Contributed by Xiaoqiao He.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "18/05/20 7:09 AM",
      "commitName": "a3f44dacc1fa19acc4eefd1e2505e54f8629e603",
      "commitAuthor": "He Xiaoqiao",
      "diff": "@@ -0,0 +1,25 @@\n+  public static List\u003cNameNodeConnector\u003e newNameNodeConnectors(\n+      Collection\u003cURI\u003e namenodes, Collection\u003cString\u003e nsIds, String name,\n+      Path idPath, Configuration conf, int maxIdleIterations)\n+      throws IOException {\n+    final List\u003cNameNodeConnector\u003e connectors \u003d new ArrayList\u003cNameNodeConnector\u003e(\n+        namenodes.size());\n+    Map\u003cURI, String\u003e uriToNsId \u003d new HashMap\u003c\u003e();\n+    if (nsIds !\u003d null) {\n+      for (URI uri : namenodes) {\n+        for (String nsId : nsIds) {\n+          if (uri.getAuthority().equals(nsId)) {\n+            uriToNsId.put(uri, nsId);\n+          }\n+        }\n+      }\n+    }\n+    for (URI uri : namenodes) {\n+      String nsId \u003d uriToNsId.get(uri);\n+      NameNodeConnector nnc \u003d new NameNodeConnector(name, uri, nsId, idPath,\n+          null, conf, maxIdleIterations);\n+      nnc.getKeyManager().startBlockKeyUpdater();\n+      connectors.add(nnc);\n+    }\n+    return connectors;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static List\u003cNameNodeConnector\u003e newNameNodeConnectors(\n      Collection\u003cURI\u003e namenodes, Collection\u003cString\u003e nsIds, String name,\n      Path idPath, Configuration conf, int maxIdleIterations)\n      throws IOException {\n    final List\u003cNameNodeConnector\u003e connectors \u003d new ArrayList\u003cNameNodeConnector\u003e(\n        namenodes.size());\n    Map\u003cURI, String\u003e uriToNsId \u003d new HashMap\u003c\u003e();\n    if (nsIds !\u003d null) {\n      for (URI uri : namenodes) {\n        for (String nsId : nsIds) {\n          if (uri.getAuthority().equals(nsId)) {\n            uriToNsId.put(uri, nsId);\n          }\n        }\n      }\n    }\n    for (URI uri : namenodes) {\n      String nsId \u003d uriToNsId.get(uri);\n      NameNodeConnector nnc \u003d new NameNodeConnector(name, uri, nsId, idPath,\n          null, conf, maxIdleIterations);\n      nnc.getKeyManager().startBlockKeyUpdater();\n      connectors.add(nnc);\n    }\n    return connectors;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/NameNodeConnector.java"
    }
  }
}