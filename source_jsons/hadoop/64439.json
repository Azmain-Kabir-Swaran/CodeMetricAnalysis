{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3AInputStream.java",
  "functionName": "read",
  "functionId": "read",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
  "functionStartLine": 378,
  "functionEndLine": 421,
  "numCommitsSeen": 28,
  "timeTaken": 2537,
  "changeHistory": [
    "d503f65b6689b19278ec2a0cf9da5a8762539de8",
    "8110d6a0d59e7dc2ddb25fa424fab188c5e9ce35",
    "39ec1515a205952eda7e171408a8b83eceb4abde",
    "27c4e90efce04e1b1302f668b5eb22412e00d033",
    "b9e3eff62a7415d8666656a75db69ff3e43f8e7e",
    "843ee8d59d8bacbca0d87ccf0790772e39d16138",
    "6ba52d88ec11444cbac946ffadbc645acd0657de",
    "24d920b80eb3626073925a1d0b6dcf148add8cc0"
  ],
  "changeHistoryShort": {
    "d503f65b6689b19278ec2a0cf9da5a8762539de8": "Ybodychange",
    "8110d6a0d59e7dc2ddb25fa424fab188c5e9ce35": "Ybodychange",
    "39ec1515a205952eda7e171408a8b83eceb4abde": "Ybodychange",
    "27c4e90efce04e1b1302f668b5eb22412e00d033": "Ybodychange",
    "b9e3eff62a7415d8666656a75db69ff3e43f8e7e": "Ybodychange",
    "843ee8d59d8bacbca0d87ccf0790772e39d16138": "Ybodychange",
    "6ba52d88ec11444cbac946ffadbc645acd0657de": "Ybodychange",
    "24d920b80eb3626073925a1d0b6dcf148add8cc0": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d503f65b6689b19278ec2a0cf9da5a8762539de8": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15541. [s3a] Shouldn\u0027t try to drain stream before aborting\nconnection in case of timeout.\n",
      "commitDate": "10/07/18 8:52 AM",
      "commitName": "d503f65b6689b19278ec2a0cf9da5a8762539de8",
      "commitAuthor": "Sean Mackrory",
      "commitDateOld": "27/06/18 10:37 PM",
      "commitNameOld": "2b2399d623539ab68e71a38fa9fbfc9a405bddb8",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 12.43,
      "commitsBetweenForRepo": 75,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,44 @@\n   public synchronized int read() throws IOException {\n     checkNotClosed();\n     if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n       return -1;\n     }\n \n     try {\n       lazySeek(nextReadPos, 1);\n     } catch (EOFException e) {\n       return -1;\n     }\n \n     // With S3Guard, the metadatastore gave us metadata for the file in\n     // open(), so we use a slightly different retry policy.\n     // read() may not be likely to fail, but reopen() does a GET which\n     // certainly could.\n     Invoker invoker \u003d context.getReadInvoker();\n     int byteRead \u003d invoker.retry(\"read\", pathStr, true,\n         () -\u003e {\n           int b;\n           try {\n             b \u003d wrappedStream.read();\n           } catch (EOFException e) {\n             return -1;\n+          } catch (SocketTimeoutException e) {\n+            onReadFailure(e, 1, true);\n+            b \u003d wrappedStream.read();\n           } catch (IOException e) {\n-            onReadFailure(e, 1);\n+            onReadFailure(e, 1, false);\n             b \u003d wrappedStream.read();\n           }\n           return b;\n         });\n \n     if (byteRead \u003e\u003d 0) {\n       pos++;\n       nextReadPos++;\n     }\n \n     if (byteRead \u003e\u003d 0) {\n       incrementBytesRead(1);\n     }\n     return byteRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read() throws IOException {\n    checkNotClosed();\n    if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n      return -1;\n    }\n\n    try {\n      lazySeek(nextReadPos, 1);\n    } catch (EOFException e) {\n      return -1;\n    }\n\n    // With S3Guard, the metadatastore gave us metadata for the file in\n    // open(), so we use a slightly different retry policy.\n    // read() may not be likely to fail, but reopen() does a GET which\n    // certainly could.\n    Invoker invoker \u003d context.getReadInvoker();\n    int byteRead \u003d invoker.retry(\"read\", pathStr, true,\n        () -\u003e {\n          int b;\n          try {\n            b \u003d wrappedStream.read();\n          } catch (EOFException e) {\n            return -1;\n          } catch (SocketTimeoutException e) {\n            onReadFailure(e, 1, true);\n            b \u003d wrappedStream.read();\n          } catch (IOException e) {\n            onReadFailure(e, 1, false);\n            b \u003d wrappedStream.read();\n          }\n          return b;\n        });\n\n    if (byteRead \u003e\u003d 0) {\n      pos++;\n      nextReadPos++;\n    }\n\n    if (byteRead \u003e\u003d 0) {\n      incrementBytesRead(1);\n    }\n    return byteRead;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
      "extendedDetails": {}
    },
    "8110d6a0d59e7dc2ddb25fa424fab188c5e9ce35": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13761. S3Guard: implement retries for DDB failures and throttling; translate exceptions.\nContributed by Aaron Fabbri.\n",
      "commitDate": "05/03/18 6:06 AM",
      "commitName": "8110d6a0d59e7dc2ddb25fa424fab188c5e9ce35",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "20/12/17 10:25 AM",
      "commitNameOld": "1ba491ff907fc5d2618add980734a3534e2be098",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 74.82,
      "commitsBetweenForRepo": 402,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,41 @@\n   public synchronized int read() throws IOException {\n     checkNotClosed();\n     if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n       return -1;\n     }\n \n-    int byteRead;\n     try {\n       lazySeek(nextReadPos, 1);\n-      byteRead \u003d wrappedStream.read();\n     } catch (EOFException e) {\n       return -1;\n-    } catch (IOException e) {\n-      onReadFailure(e, 1);\n-      byteRead \u003d wrappedStream.read();\n     }\n \n+    // With S3Guard, the metadatastore gave us metadata for the file in\n+    // open(), so we use a slightly different retry policy.\n+    // read() may not be likely to fail, but reopen() does a GET which\n+    // certainly could.\n+    Invoker invoker \u003d context.getReadInvoker();\n+    int byteRead \u003d invoker.retry(\"read\", pathStr, true,\n+        () -\u003e {\n+          int b;\n+          try {\n+            b \u003d wrappedStream.read();\n+          } catch (EOFException e) {\n+            return -1;\n+          } catch (IOException e) {\n+            onReadFailure(e, 1);\n+            b \u003d wrappedStream.read();\n+          }\n+          return b;\n+        });\n+\n     if (byteRead \u003e\u003d 0) {\n       pos++;\n       nextReadPos++;\n     }\n \n     if (byteRead \u003e\u003d 0) {\n       incrementBytesRead(1);\n     }\n     return byteRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read() throws IOException {\n    checkNotClosed();\n    if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n      return -1;\n    }\n\n    try {\n      lazySeek(nextReadPos, 1);\n    } catch (EOFException e) {\n      return -1;\n    }\n\n    // With S3Guard, the metadatastore gave us metadata for the file in\n    // open(), so we use a slightly different retry policy.\n    // read() may not be likely to fail, but reopen() does a GET which\n    // certainly could.\n    Invoker invoker \u003d context.getReadInvoker();\n    int byteRead \u003d invoker.retry(\"read\", pathStr, true,\n        () -\u003e {\n          int b;\n          try {\n            b \u003d wrappedStream.read();\n          } catch (EOFException e) {\n            return -1;\n          } catch (IOException e) {\n            onReadFailure(e, 1);\n            b \u003d wrappedStream.read();\n          }\n          return b;\n        });\n\n    if (byteRead \u003e\u003d 0) {\n      pos++;\n      nextReadPos++;\n    }\n\n    if (byteRead \u003e\u003d 0) {\n      incrementBytesRead(1);\n    }\n    return byteRead;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
      "extendedDetails": {}
    },
    "39ec1515a205952eda7e171408a8b83eceb4abde": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13130. s3a failures can surface as RTEs, not IOEs. (Steve Loughran)\n",
      "commitDate": "21/05/16 8:39 AM",
      "commitName": "39ec1515a205952eda7e171408a8b83eceb4abde",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "12/05/16 11:24 AM",
      "commitNameOld": "27c4e90efce04e1b1302f668b5eb22412e00d033",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 8.89,
      "commitsBetweenForRepo": 74,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n   public synchronized int read() throws IOException {\n     checkNotClosed();\n     if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n       return -1;\n     }\n \n-    lazySeek(nextReadPos, 1);\n \n     int byteRead;\n     try {\n+      lazySeek(nextReadPos, 1);\n       byteRead \u003d wrappedStream.read();\n     } catch (EOFException e) {\n       return -1;\n     } catch (IOException e) {\n       onReadFailure(e, 1);\n       byteRead \u003d wrappedStream.read();\n     }\n \n     if (byteRead \u003e\u003d 0) {\n       pos++;\n       nextReadPos++;\n     }\n \n     if (byteRead \u003e\u003d 0) {\n       incrementBytesRead(1);\n     }\n     return byteRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read() throws IOException {\n    checkNotClosed();\n    if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n      return -1;\n    }\n\n\n    int byteRead;\n    try {\n      lazySeek(nextReadPos, 1);\n      byteRead \u003d wrappedStream.read();\n    } catch (EOFException e) {\n      return -1;\n    } catch (IOException e) {\n      onReadFailure(e, 1);\n      byteRead \u003d wrappedStream.read();\n    }\n\n    if (byteRead \u003e\u003d 0) {\n      pos++;\n      nextReadPos++;\n    }\n\n    if (byteRead \u003e\u003d 0) {\n      incrementBytesRead(1);\n    }\n    return byteRead;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
      "extendedDetails": {}
    },
    "27c4e90efce04e1b1302f668b5eb22412e00d033": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13028 add low level counter metrics for S3A; use in read performance tests. contributed by: stevel\npatch includes\nHADOOP-12844 Recover when S3A fails on IOException in read()\nHADOOP-13058 S3A FS fails during init against a read-only FS if multipart purge\nHADOOP-13047 S3a Forward seek in stream length to be configurable\n",
      "commitDate": "12/05/16 11:24 AM",
      "commitName": "27c4e90efce04e1b1302f668b5eb22412e00d033",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "09/04/16 3:25 AM",
      "commitNameOld": "b9e3eff62a7415d8666656a75db69ff3e43f8e7e",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 33.33,
      "commitsBetweenForRepo": 203,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,28 @@\n   public synchronized int read() throws IOException {\n     checkNotClosed();\n     if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n       return -1;\n     }\n \n     lazySeek(nextReadPos, 1);\n \n     int byteRead;\n     try {\n       byteRead \u003d wrappedStream.read();\n-    } catch (SocketTimeoutException | SocketException e) {\n-      LOG.info(\"Got exception while trying to read from stream,\"\n-          + \" trying to recover \" + e);\n-      reopen(pos, 1);\n-      byteRead \u003d wrappedStream.read();\n     } catch (EOFException e) {\n       return -1;\n+    } catch (IOException e) {\n+      onReadFailure(e, 1);\n+      byteRead \u003d wrappedStream.read();\n     }\n \n     if (byteRead \u003e\u003d 0) {\n       pos++;\n       nextReadPos++;\n     }\n \n-    if (stats !\u003d null \u0026\u0026 byteRead \u003e\u003d 0) {\n-      stats.incrementBytesRead(1);\n+    if (byteRead \u003e\u003d 0) {\n+      incrementBytesRead(1);\n     }\n     return byteRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read() throws IOException {\n    checkNotClosed();\n    if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n      return -1;\n    }\n\n    lazySeek(nextReadPos, 1);\n\n    int byteRead;\n    try {\n      byteRead \u003d wrappedStream.read();\n    } catch (EOFException e) {\n      return -1;\n    } catch (IOException e) {\n      onReadFailure(e, 1);\n      byteRead \u003d wrappedStream.read();\n    }\n\n    if (byteRead \u003e\u003d 0) {\n      pos++;\n      nextReadPos++;\n    }\n\n    if (byteRead \u003e\u003d 0) {\n      incrementBytesRead(1);\n    }\n    return byteRead;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
      "extendedDetails": {}
    },
    "b9e3eff62a7415d8666656a75db69ff3e43f8e7e": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12444 Support lazy seek in S3AInputStream. Rajesh Balamohan via stevel\n",
      "commitDate": "09/04/16 3:25 AM",
      "commitName": "b9e3eff62a7415d8666656a75db69ff3e43f8e7e",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "08/04/16 1:36 PM",
      "commitNameOld": "843ee8d59d8bacbca0d87ccf0790772e39d16138",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 0.58,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,30 @@\n   public synchronized int read() throws IOException {\n     checkNotClosed();\n+    if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n+      return -1;\n+    }\n \n-    openIfNeeded();\n+    lazySeek(nextReadPos, 1);\n \n     int byteRead;\n     try {\n       byteRead \u003d wrappedStream.read();\n-    } catch (SocketTimeoutException e) {\n-      LOG.info(\"Got timeout while trying to read from stream, trying to recover \" + e);\n-      reopen(pos);\n-      byteRead \u003d wrappedStream.read();\n-    } catch (SocketException e) {\n-      LOG.info(\"Got socket exception while trying to read from stream, trying to recover \" + e);\n-      reopen(pos);\n+    } catch (SocketTimeoutException | SocketException e) {\n+      LOG.info(\"Got exception while trying to read from stream,\"\n+          + \" trying to recover \" + e);\n+      reopen(pos, 1);\n       byteRead \u003d wrappedStream.read();\n     } catch (EOFException e) {\n       return -1;\n     }\n \n     if (byteRead \u003e\u003d 0) {\n       pos++;\n+      nextReadPos++;\n     }\n \n     if (stats !\u003d null \u0026\u0026 byteRead \u003e\u003d 0) {\n       stats.incrementBytesRead(1);\n     }\n     return byteRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read() throws IOException {\n    checkNotClosed();\n    if (this.contentLength \u003d\u003d 0 || (nextReadPos \u003e\u003d contentLength)) {\n      return -1;\n    }\n\n    lazySeek(nextReadPos, 1);\n\n    int byteRead;\n    try {\n      byteRead \u003d wrappedStream.read();\n    } catch (SocketTimeoutException | SocketException e) {\n      LOG.info(\"Got exception while trying to read from stream,\"\n          + \" trying to recover \" + e);\n      reopen(pos, 1);\n      byteRead \u003d wrappedStream.read();\n    } catch (EOFException e) {\n      return -1;\n    }\n\n    if (byteRead \u003e\u003d 0) {\n      pos++;\n      nextReadPos++;\n    }\n\n    if (stats !\u003d null \u0026\u0026 byteRead \u003e\u003d 0) {\n      stats.incrementBytesRead(1);\n    }\n    return byteRead;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
      "extendedDetails": {}
    },
    "843ee8d59d8bacbca0d87ccf0790772e39d16138": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12994. Specify PositionedReadable, add contract tests, fix problems. Contributed by Steve Loughran.\n",
      "commitDate": "08/04/16 1:36 PM",
      "commitName": "843ee8d59d8bacbca0d87ccf0790772e39d16138",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "17/02/15 8:36 AM",
      "commitNameOld": "826267f789df657c62f7f5909e5a0b1a7b102c34",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 416.17,
      "commitsBetweenForRepo": 3204,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,29 @@\n   public synchronized int read() throws IOException {\n     checkNotClosed();\n \n     openIfNeeded();\n \n     int byteRead;\n     try {\n       byteRead \u003d wrappedStream.read();\n     } catch (SocketTimeoutException e) {\n       LOG.info(\"Got timeout while trying to read from stream, trying to recover \" + e);\n       reopen(pos);\n       byteRead \u003d wrappedStream.read();\n     } catch (SocketException e) {\n       LOG.info(\"Got socket exception while trying to read from stream, trying to recover \" + e);\n       reopen(pos);\n       byteRead \u003d wrappedStream.read();\n+    } catch (EOFException e) {\n+      return -1;\n     }\n \n     if (byteRead \u003e\u003d 0) {\n       pos++;\n     }\n \n     if (stats !\u003d null \u0026\u0026 byteRead \u003e\u003d 0) {\n       stats.incrementBytesRead(1);\n     }\n     return byteRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read() throws IOException {\n    checkNotClosed();\n\n    openIfNeeded();\n\n    int byteRead;\n    try {\n      byteRead \u003d wrappedStream.read();\n    } catch (SocketTimeoutException e) {\n      LOG.info(\"Got timeout while trying to read from stream, trying to recover \" + e);\n      reopen(pos);\n      byteRead \u003d wrappedStream.read();\n    } catch (SocketException e) {\n      LOG.info(\"Got socket exception while trying to read from stream, trying to recover \" + e);\n      reopen(pos);\n      byteRead \u003d wrappedStream.read();\n    } catch (EOFException e) {\n      return -1;\n    }\n\n    if (byteRead \u003e\u003d 0) {\n      pos++;\n    }\n\n    if (stats !\u003d null \u0026\u0026 byteRead \u003e\u003d 0) {\n      stats.incrementBytesRead(1);\n    }\n    return byteRead;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
      "extendedDetails": {}
    },
    "6ba52d88ec11444cbac946ffadbc645acd0657de": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10714. AmazonS3Client.deleteObjects() need to be limited to 1000 entries per call. Contributed by Juan Yu.\n",
      "commitDate": "05/11/14 5:17 PM",
      "commitName": "6ba52d88ec11444cbac946ffadbc645acd0657de",
      "commitAuthor": "Aaron T. Myers",
      "commitDateOld": "15/09/14 8:27 AM",
      "commitNameOld": "24d920b80eb3626073925a1d0b6dcf148add8cc0",
      "commitAuthorOld": "Aaron T. Myers",
      "daysBetweenCommits": 51.41,
      "commitsBetweenForRepo": 545,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,27 @@\n   public synchronized int read() throws IOException {\n-    if (closed) {\n-      throw new IOException(\"Stream closed\");\n-    }\n+    checkNotClosed();\n \n     openIfNeeded();\n \n     int byteRead;\n     try {\n       byteRead \u003d wrappedStream.read();\n     } catch (SocketTimeoutException e) {\n       LOG.info(\"Got timeout while trying to read from stream, trying to recover \" + e);\n       reopen(pos);\n       byteRead \u003d wrappedStream.read();\n     } catch (SocketException e) {\n       LOG.info(\"Got socket exception while trying to read from stream, trying to recover \" + e);\n       reopen(pos);\n       byteRead \u003d wrappedStream.read();\n     }\n \n     if (byteRead \u003e\u003d 0) {\n       pos++;\n     }\n \n     if (stats !\u003d null \u0026\u0026 byteRead \u003e\u003d 0) {\n       stats.incrementBytesRead(1);\n     }\n     return byteRead;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read() throws IOException {\n    checkNotClosed();\n\n    openIfNeeded();\n\n    int byteRead;\n    try {\n      byteRead \u003d wrappedStream.read();\n    } catch (SocketTimeoutException e) {\n      LOG.info(\"Got timeout while trying to read from stream, trying to recover \" + e);\n      reopen(pos);\n      byteRead \u003d wrappedStream.read();\n    } catch (SocketException e) {\n      LOG.info(\"Got socket exception while trying to read from stream, trying to recover \" + e);\n      reopen(pos);\n      byteRead \u003d wrappedStream.read();\n    }\n\n    if (byteRead \u003e\u003d 0) {\n      pos++;\n    }\n\n    if (stats !\u003d null \u0026\u0026 byteRead \u003e\u003d 0) {\n      stats.incrementBytesRead(1);\n    }\n    return byteRead;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java",
      "extendedDetails": {}
    },
    "24d920b80eb3626073925a1d0b6dcf148add8cc0": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-10400. Incorporate new S3A FileSystem implementation. Contributed by Jordan Mendelson and Dave Wang.\n",
      "commitDate": "15/09/14 8:27 AM",
      "commitName": "24d920b80eb3626073925a1d0b6dcf148add8cc0",
      "commitAuthor": "Aaron T. Myers",
      "diff": "@@ -0,0 +1,29 @@\n+  public synchronized int read() throws IOException {\n+    if (closed) {\n+      throw new IOException(\"Stream closed\");\n+    }\n+\n+    openIfNeeded();\n+\n+    int byteRead;\n+    try {\n+      byteRead \u003d wrappedStream.read();\n+    } catch (SocketTimeoutException e) {\n+      LOG.info(\"Got timeout while trying to read from stream, trying to recover \" + e);\n+      reopen(pos);\n+      byteRead \u003d wrappedStream.read();\n+    } catch (SocketException e) {\n+      LOG.info(\"Got socket exception while trying to read from stream, trying to recover \" + e);\n+      reopen(pos);\n+      byteRead \u003d wrappedStream.read();\n+    }\n+\n+    if (byteRead \u003e\u003d 0) {\n+      pos++;\n+    }\n+\n+    if (stats !\u003d null \u0026\u0026 byteRead \u003e\u003d 0) {\n+      stats.incrementBytesRead(1);\n+    }\n+    return byteRead;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized int read() throws IOException {\n    if (closed) {\n      throw new IOException(\"Stream closed\");\n    }\n\n    openIfNeeded();\n\n    int byteRead;\n    try {\n      byteRead \u003d wrappedStream.read();\n    } catch (SocketTimeoutException e) {\n      LOG.info(\"Got timeout while trying to read from stream, trying to recover \" + e);\n      reopen(pos);\n      byteRead \u003d wrappedStream.read();\n    } catch (SocketException e) {\n      LOG.info(\"Got socket exception while trying to read from stream, trying to recover \" + e);\n      reopen(pos);\n      byteRead \u003d wrappedStream.read();\n    }\n\n    if (byteRead \u003e\u003d 0) {\n      pos++;\n    }\n\n    if (stats !\u003d null \u0026\u0026 byteRead \u003e\u003d 0) {\n      stats.incrementBytesRead(1);\n    }\n    return byteRead;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AInputStream.java"
    }
  }
}